Dec 20 04:02:17.574: INFO: Overriding default scale value of zero to 1
Dec 20 04:02:17.575: INFO: Overriding default milliseconds value of zero to 5000
I1220 04:02:18.089331      18 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-617439060
I1220 04:02:18.089461      18 e2e.go:304] Starting e2e run "0a8ff007-040c-11e9-acdd-0a580ac80107" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1545278537 - Will randomize all specs
Will run 188 of 1814 specs

Dec 20 04:02:18.255: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:02:18.258: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 20 04:02:18.558: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 20 04:02:18.772: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 20 04:02:18.772: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Dec 20 04:02:18.772: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 20 04:02:18.781: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'fluent-bit' (0 seconds elapsed)
Dec 20 04:02:18.781: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Dec 20 04:02:18.781: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy-ds' (0 seconds elapsed)
Dec 20 04:02:18.781: INFO: e2e test version: v1.12.1
Dec 20 04:02:18.782: INFO: kube-apiserver version: v1.12.3
S
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:02:18.783: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
Dec 20 04:02:18.840: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:02:18.847: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0b5f26e5-040c-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-p8smz" to be "success or failure"
Dec 20 04:02:18.850: INFO: Pod "downwardapi-volume-0b5f26e5-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.336839ms
Dec 20 04:02:20.853: INFO: Pod "downwardapi-volume-0b5f26e5-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006082819s
Dec 20 04:02:22.857: INFO: Pod "downwardapi-volume-0b5f26e5-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009598866s
Dec 20 04:02:24.909: INFO: Pod "downwardapi-volume-0b5f26e5-040c-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.061897519s
STEP: Saw pod success
Dec 20 04:02:24.909: INFO: Pod "downwardapi-volume-0b5f26e5-040c-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:02:24.957: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod downwardapi-volume-0b5f26e5-040c-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:02:25.028: INFO: Waiting for pod downwardapi-volume-0b5f26e5-040c-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:02:25.032: INFO: Pod downwardapi-volume-0b5f26e5-040c-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:02:25.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p8smz" for this suite.
Dec 20 04:02:31.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:02:31.382: INFO: namespace: e2e-tests-projected-p8smz, resource: bindings, ignored listing per whitelist
Dec 20 04:02:31.396: INFO: namespace e2e-tests-projected-p8smz deletion completed in 6.122192869s

• [SLOW TEST:12.613 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:02:31.396: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:03:31.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fsh6z" for this suite.
Dec 20 04:03:59.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:03:59.772: INFO: namespace: e2e-tests-container-probe-fsh6z, resource: bindings, ignored listing per whitelist
Dec 20 04:03:59.775: INFO: namespace e2e-tests-container-probe-fsh6z deletion completed in 28.304881526s

• [SLOW TEST:88.379 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:03:59.775: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-47bd1cf4-040c-11e9-acdd-0a580ac80107
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-47bd1cf4-040c-11e9-acdd-0a580ac80107
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:05:19.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vbbv9" for this suite.
Dec 20 04:05:41.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:05:41.805: INFO: namespace: e2e-tests-projected-vbbv9, resource: bindings, ignored listing per whitelist
Dec 20 04:05:41.847: INFO: namespace e2e-tests-projected-vbbv9 deletion completed in 22.296692983s

• [SLOW TEST:102.072 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:05:41.847: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:05:42.150: INFO: Waiting up to 5m0s for pod "downwardapi-volume-848ba787-040c-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-cw8sf" to be "success or failure"
Dec 20 04:05:42.154: INFO: Pod "downwardapi-volume-848ba787-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.315059ms
Dec 20 04:05:44.157: INFO: Pod "downwardapi-volume-848ba787-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006692232s
Dec 20 04:05:46.161: INFO: Pod "downwardapi-volume-848ba787-040c-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010612684s
STEP: Saw pod success
Dec 20 04:05:46.161: INFO: Pod "downwardapi-volume-848ba787-040c-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:05:46.164: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod downwardapi-volume-848ba787-040c-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:05:46.182: INFO: Waiting for pod downwardapi-volume-848ba787-040c-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:05:46.184: INFO: Pod downwardapi-volume-848ba787-040c-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:05:46.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cw8sf" for this suite.
Dec 20 04:05:52.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:05:52.231: INFO: namespace: e2e-tests-downward-api-cw8sf, resource: bindings, ignored listing per whitelist
Dec 20 04:05:52.295: INFO: namespace e2e-tests-downward-api-cw8sf deletion completed in 6.107574477s

• [SLOW TEST:10.448 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:05:52.295: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:05:52.359: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8aa25a0d-040c-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-qb5c2" to be "success or failure"
Dec 20 04:05:52.365: INFO: Pod "downwardapi-volume-8aa25a0d-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007498ms
Dec 20 04:05:54.368: INFO: Pod "downwardapi-volume-8aa25a0d-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00917799s
Dec 20 04:05:56.423: INFO: Pod "downwardapi-volume-8aa25a0d-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063656892s
Dec 20 04:05:58.485: INFO: Pod "downwardapi-volume-8aa25a0d-040c-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.125682567s
STEP: Saw pod success
Dec 20 04:05:58.485: INFO: Pod "downwardapi-volume-8aa25a0d-040c-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:05:58.536: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod downwardapi-volume-8aa25a0d-040c-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:05:58.601: INFO: Waiting for pod downwardapi-volume-8aa25a0d-040c-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:05:58.604: INFO: Pod downwardapi-volume-8aa25a0d-040c-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:05:58.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qb5c2" for this suite.
Dec 20 04:06:04.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:06:04.879: INFO: namespace: e2e-tests-projected-qb5c2, resource: bindings, ignored listing per whitelist
Dec 20 04:06:04.939: INFO: namespace e2e-tests-projected-qb5c2 deletion completed in 6.103352709s

• [SLOW TEST:12.643 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:06:04.939: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec 20 04:06:09.041: INFO: Pod pod-hostip-922e86d3-040c-11e9-acdd-0a580ac80107 has hostIP: 10.40.154.55
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:06:09.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-p8swg" for this suite.
Dec 20 04:06:31.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:06:31.325: INFO: namespace: e2e-tests-pods-p8swg, resource: bindings, ignored listing per whitelist
Dec 20 04:06:31.330: INFO: namespace e2e-tests-pods-p8swg deletion completed in 22.28616586s

• [SLOW TEST:26.391 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:06:31.330: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 20 04:06:31.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:32.079: INFO: stderr: ""
Dec 20 04:06:32.079: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 04:06:32.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:32.219: INFO: stderr: ""
Dec 20 04:06:32.219: INFO: stdout: "update-demo-nautilus-6gsk8 update-demo-nautilus-nxgbm "
Dec 20 04:06:32.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-6gsk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:32.328: INFO: stderr: ""
Dec 20 04:06:32.328: INFO: stdout: ""
Dec 20 04:06:32.328: INFO: update-demo-nautilus-6gsk8 is created but not running
Dec 20 04:06:37.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:37.533: INFO: stderr: ""
Dec 20 04:06:37.533: INFO: stdout: "update-demo-nautilus-6gsk8 update-demo-nautilus-nxgbm "
Dec 20 04:06:37.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-6gsk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:37.739: INFO: stderr: ""
Dec 20 04:06:37.739: INFO: stdout: "true"
Dec 20 04:06:37.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-6gsk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:37.933: INFO: stderr: ""
Dec 20 04:06:37.934: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 04:06:37.934: INFO: validating pod update-demo-nautilus-6gsk8
Dec 20 04:06:37.938: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 04:06:37.938: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 04:06:37.938: INFO: update-demo-nautilus-6gsk8 is verified up and running
Dec 20 04:06:37.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-nxgbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:38.146: INFO: stderr: ""
Dec 20 04:06:38.146: INFO: stdout: "true"
Dec 20 04:06:38.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-nxgbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:38.351: INFO: stderr: ""
Dec 20 04:06:38.351: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 04:06:38.351: INFO: validating pod update-demo-nautilus-nxgbm
Dec 20 04:06:38.356: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 04:06:38.356: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 04:06:38.356: INFO: update-demo-nautilus-nxgbm is verified up and running
STEP: scaling down the replication controller
Dec 20 04:06:38.358: INFO: scanned /root for discovery docs: <nil>
Dec 20 04:06:38.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:39.492: INFO: stderr: ""
Dec 20 04:06:39.492: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 04:06:39.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:39.594: INFO: stderr: ""
Dec 20 04:06:39.594: INFO: stdout: "update-demo-nautilus-6gsk8 update-demo-nautilus-nxgbm "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 20 04:06:44.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:44.801: INFO: stderr: ""
Dec 20 04:06:44.801: INFO: stdout: "update-demo-nautilus-6gsk8 update-demo-nautilus-nxgbm "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 20 04:06:49.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:50.020: INFO: stderr: ""
Dec 20 04:06:50.020: INFO: stdout: "update-demo-nautilus-6gsk8 "
Dec 20 04:06:50.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-6gsk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:50.226: INFO: stderr: ""
Dec 20 04:06:50.226: INFO: stdout: "true"
Dec 20 04:06:50.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-6gsk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:50.415: INFO: stderr: ""
Dec 20 04:06:50.415: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 04:06:50.415: INFO: validating pod update-demo-nautilus-6gsk8
Dec 20 04:06:50.419: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 04:06:50.419: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 04:06:50.419: INFO: update-demo-nautilus-6gsk8 is verified up and running
STEP: scaling up the replication controller
Dec 20 04:06:50.420: INFO: scanned /root for discovery docs: <nil>
Dec 20 04:06:50.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:51.599: INFO: stderr: ""
Dec 20 04:06:51.599: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 04:06:51.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:51.796: INFO: stderr: ""
Dec 20 04:06:51.796: INFO: stdout: "update-demo-nautilus-6gsk8 update-demo-nautilus-clp9k "
Dec 20 04:06:51.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-6gsk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:51.891: INFO: stderr: ""
Dec 20 04:06:51.891: INFO: stdout: "true"
Dec 20 04:06:51.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-6gsk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:51.987: INFO: stderr: ""
Dec 20 04:06:51.987: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 04:06:51.987: INFO: validating pod update-demo-nautilus-6gsk8
Dec 20 04:06:51.990: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 04:06:51.990: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 04:06:51.990: INFO: update-demo-nautilus-6gsk8 is verified up and running
Dec 20 04:06:51.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-clp9k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:52.091: INFO: stderr: ""
Dec 20 04:06:52.091: INFO: stdout: ""
Dec 20 04:06:52.091: INFO: update-demo-nautilus-clp9k is created but not running
Dec 20 04:06:57.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:57.294: INFO: stderr: ""
Dec 20 04:06:57.294: INFO: stdout: "update-demo-nautilus-6gsk8 update-demo-nautilus-clp9k "
Dec 20 04:06:57.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-6gsk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:57.502: INFO: stderr: ""
Dec 20 04:06:57.502: INFO: stdout: "true"
Dec 20 04:06:57.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-6gsk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:57.700: INFO: stderr: ""
Dec 20 04:06:57.700: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 04:06:57.700: INFO: validating pod update-demo-nautilus-6gsk8
Dec 20 04:06:57.703: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 04:06:57.703: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 04:06:57.703: INFO: update-demo-nautilus-6gsk8 is verified up and running
Dec 20 04:06:57.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-clp9k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:57.891: INFO: stderr: ""
Dec 20 04:06:57.891: INFO: stdout: "true"
Dec 20 04:06:57.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-clp9k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:58.090: INFO: stderr: ""
Dec 20 04:06:58.090: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 04:06:58.090: INFO: validating pod update-demo-nautilus-clp9k
Dec 20 04:06:58.094: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 04:06:58.094: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 04:06:58.094: INFO: update-demo-nautilus-clp9k is verified up and running
STEP: using delete to clean up resources
Dec 20 04:06:58.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:58.198: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 04:06:58.198: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 20 04:06:58.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-dfjvr'
Dec 20 04:06:58.332: INFO: stderr: "No resources found.\n"
Dec 20 04:06:58.332: INFO: stdout: ""
Dec 20 04:06:58.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -l name=update-demo --namespace=e2e-tests-kubectl-dfjvr -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 20 04:06:58.451: INFO: stderr: ""
Dec 20 04:06:58.451: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:06:58.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dfjvr" for this suite.
Dec 20 04:07:20.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:07:20.705: INFO: namespace: e2e-tests-kubectl-dfjvr, resource: bindings, ignored listing per whitelist
Dec 20 04:07:20.743: INFO: namespace e2e-tests-kubectl-dfjvr deletion completed in 22.28893162s

• [SLOW TEST:49.413 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:07:20.743: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-kc6fz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 20 04:07:20.939: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 20 04:07:45.031: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.200.1.11 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-kc6fz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:07:45.031: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:07:46.150: INFO: Found all expected endpoints: [netserver-0]
Dec 20 04:07:46.153: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.200.2.13 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-kc6fz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:07:46.153: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:07:47.264: INFO: Found all expected endpoints: [netserver-1]
Dec 20 04:07:47.267: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.200.3.10 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-kc6fz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:07:47.267: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:07:48.485: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:07:48.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-kc6fz" for this suite.
Dec 20 04:08:10.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:08:10.763: INFO: namespace: e2e-tests-pod-network-test-kc6fz, resource: bindings, ignored listing per whitelist
Dec 20 04:08:10.827: INFO: namespace e2e-tests-pod-network-test-kc6fz deletion completed in 22.151009951s

• [SLOW TEST:50.084 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:08:10.828: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec 20 04:08:10.896: INFO: Waiting up to 5m0s for pod "client-containers-dd34fc81-040c-11e9-acdd-0a580ac80107" in namespace "e2e-tests-containers-tg2rn" to be "success or failure"
Dec 20 04:08:10.899: INFO: Pod "client-containers-dd34fc81-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.817406ms
Dec 20 04:08:12.903: INFO: Pod "client-containers-dd34fc81-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006918841s
Dec 20 04:08:14.906: INFO: Pod "client-containers-dd34fc81-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010408346s
Dec 20 04:08:16.910: INFO: Pod "client-containers-dd34fc81-040c-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013912146s
STEP: Saw pod success
Dec 20 04:08:16.910: INFO: Pod "client-containers-dd34fc81-040c-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:08:16.912: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod client-containers-dd34fc81-040c-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 04:08:16.930: INFO: Waiting for pod client-containers-dd34fc81-040c-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:08:16.932: INFO: Pod client-containers-dd34fc81-040c-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:08:16.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-tg2rn" for this suite.
Dec 20 04:08:23.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:08:23.160: INFO: namespace: e2e-tests-containers-tg2rn, resource: bindings, ignored listing per whitelist
Dec 20 04:08:23.229: INFO: namespace e2e-tests-containers-tg2rn deletion completed in 6.103745056s

• [SLOW TEST:12.402 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:08:23.229: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-5rf2j
Dec 20 04:08:29.305: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-5rf2j
STEP: checking the pod's current state and verifying that restartCount is present
Dec 20 04:08:29.307: INFO: Initial restart count of pod liveness-http is 0
Dec 20 04:08:47.418: INFO: Restart count of pod e2e-tests-container-probe-5rf2j/liveness-http is now 1 (18.110245591s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:08:47.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5rf2j" for this suite.
Dec 20 04:08:53.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:08:53.821: INFO: namespace: e2e-tests-container-probe-5rf2j, resource: bindings, ignored listing per whitelist
Dec 20 04:08:53.852: INFO: namespace e2e-tests-container-probe-5rf2j deletion completed in 6.111329998s

• [SLOW TEST:30.623 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:08:53.852: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 04:08:59.941: INFO: Waiting up to 5m0s for pod "client-envvars-fa7120c5-040c-11e9-acdd-0a580ac80107" in namespace "e2e-tests-pods-g2v4p" to be "success or failure"
Dec 20 04:08:59.950: INFO: Pod "client-envvars-fa7120c5-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 9.182274ms
Dec 20 04:09:01.954: INFO: Pod "client-envvars-fa7120c5-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013167174s
Dec 20 04:09:03.958: INFO: Pod "client-envvars-fa7120c5-040c-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01690683s
Dec 20 04:09:05.962: INFO: Pod "client-envvars-fa7120c5-040c-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020761554s
STEP: Saw pod success
Dec 20 04:09:05.962: INFO: Pod "client-envvars-fa7120c5-040c-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:09:05.964: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod client-envvars-fa7120c5-040c-11e9-acdd-0a580ac80107 container env3cont: <nil>
STEP: delete the pod
Dec 20 04:09:05.987: INFO: Waiting for pod client-envvars-fa7120c5-040c-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:09:05.989: INFO: Pod client-envvars-fa7120c5-040c-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:09:05.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-g2v4p" for this suite.
Dec 20 04:09:48.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:09:48.410: INFO: namespace: e2e-tests-pods-g2v4p, resource: bindings, ignored listing per whitelist
Dec 20 04:09:48.499: INFO: namespace e2e-tests-pods-g2v4p deletion completed in 42.334656514s

• [SLOW TEST:54.647 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:09:48.499: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec 20 04:09:48.602: INFO: Waiting up to 5m0s for pod "client-containers-177219a6-040d-11e9-acdd-0a580ac80107" in namespace "e2e-tests-containers-zk47r" to be "success or failure"
Dec 20 04:09:48.606: INFO: Pod "client-containers-177219a6-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.17624ms
Dec 20 04:09:50.609: INFO: Pod "client-containers-177219a6-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006740695s
Dec 20 04:09:52.613: INFO: Pod "client-containers-177219a6-040d-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010487087s
STEP: Saw pod success
Dec 20 04:09:52.613: INFO: Pod "client-containers-177219a6-040d-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:09:52.615: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod client-containers-177219a6-040d-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 04:09:52.636: INFO: Waiting for pod client-containers-177219a6-040d-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:09:52.638: INFO: Pod client-containers-177219a6-040d-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:09:52.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-zk47r" for this suite.
Dec 20 04:09:58.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:09:58.676: INFO: namespace: e2e-tests-containers-zk47r, resource: bindings, ignored listing per whitelist
Dec 20 04:09:58.743: INFO: namespace e2e-tests-containers-zk47r deletion completed in 6.100923881s

• [SLOW TEST:10.244 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:09:58.743: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 20 04:09:58.822: INFO: Waiting up to 5m0s for pod "pod-1d8925d8-040d-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-jz9tq" to be "success or failure"
Dec 20 04:09:58.825: INFO: Pod "pod-1d8925d8-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.218086ms
Dec 20 04:10:00.829: INFO: Pod "pod-1d8925d8-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007323185s
Dec 20 04:10:02.834: INFO: Pod "pod-1d8925d8-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011672567s
Dec 20 04:10:04.884: INFO: Pod "pod-1d8925d8-040d-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.061820389s
STEP: Saw pod success
Dec 20 04:10:04.884: INFO: Pod "pod-1d8925d8-040d-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:10:04.933: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-1d8925d8-040d-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 04:10:04.998: INFO: Waiting for pod pod-1d8925d8-040d-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:10:05.002: INFO: Pod pod-1d8925d8-040d-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:10:05.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jz9tq" for this suite.
Dec 20 04:10:11.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:10:11.377: INFO: namespace: e2e-tests-emptydir-jz9tq, resource: bindings, ignored listing per whitelist
Dec 20 04:10:11.437: INFO: namespace e2e-tests-emptydir-jz9tq deletion completed in 6.111006593s

• [SLOW TEST:12.694 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:10:11.437: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2517cd63-040d-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 04:10:11.534: INFO: Waiting up to 5m0s for pod "pod-secrets-251ce03f-040d-11e9-acdd-0a580ac80107" in namespace "e2e-tests-secrets-qf67v" to be "success or failure"
Dec 20 04:10:11.538: INFO: Pod "pod-secrets-251ce03f-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.320445ms
Dec 20 04:10:13.542: INFO: Pod "pod-secrets-251ce03f-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007904332s
Dec 20 04:10:15.595: INFO: Pod "pod-secrets-251ce03f-040d-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061300398s
STEP: Saw pod success
Dec 20 04:10:15.595: INFO: Pod "pod-secrets-251ce03f-040d-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:10:15.645: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-secrets-251ce03f-040d-11e9-acdd-0a580ac80107 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 04:10:15.720: INFO: Waiting for pod pod-secrets-251ce03f-040d-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:10:15.723: INFO: Pod pod-secrets-251ce03f-040d-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:10:15.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qf67v" for this suite.
Dec 20 04:10:22.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:10:22.109: INFO: namespace: e2e-tests-secrets-qf67v, resource: bindings, ignored listing per whitelist
Dec 20 04:10:22.175: INFO: namespace e2e-tests-secrets-qf67v deletion completed in 6.11056781s
STEP: Destroying namespace "e2e-tests-secret-namespace-jz8kh" for this suite.
Dec 20 04:10:28.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:10:28.241: INFO: namespace: e2e-tests-secret-namespace-jz8kh, resource: bindings, ignored listing per whitelist
Dec 20 04:10:28.280: INFO: namespace e2e-tests-secret-namespace-jz8kh deletion completed in 6.104832276s

• [SLOW TEST:16.843 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:10:28.281: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 20 04:10:28.340: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:10:35.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4lntf" for this suite.
Dec 20 04:10:57.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:10:57.618: INFO: namespace: e2e-tests-init-container-4lntf, resource: bindings, ignored listing per whitelist
Dec 20 04:10:57.634: INFO: namespace e2e-tests-init-container-4lntf deletion completed in 22.309034424s

• [SLOW TEST:29.353 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:10:57.634: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 20 04:10:57.749: INFO: Waiting up to 5m0s for pod "pod-40a8da3e-040d-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-q6tj2" to be "success or failure"
Dec 20 04:10:57.753: INFO: Pod "pod-40a8da3e-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.627667ms
Dec 20 04:10:59.756: INFO: Pod "pod-40a8da3e-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006913035s
Dec 20 04:11:01.803: INFO: Pod "pod-40a8da3e-040d-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053706438s
STEP: Saw pod success
Dec 20 04:11:01.803: INFO: Pod "pod-40a8da3e-040d-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:11:01.851: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-40a8da3e-040d-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 04:11:01.911: INFO: Waiting for pod pod-40a8da3e-040d-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:11:01.914: INFO: Pod pod-40a8da3e-040d-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:11:01.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q6tj2" for this suite.
Dec 20 04:11:08.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:11:08.302: INFO: namespace: e2e-tests-emptydir-q6tj2, resource: bindings, ignored listing per whitelist
Dec 20 04:11:08.347: INFO: namespace e2e-tests-emptydir-q6tj2 deletion completed in 6.111387569s

• [SLOW TEST:10.713 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:11:08.347: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-47057c4c-040d-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 04:11:08.426: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-47063a29-040d-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-8p9ss" to be "success or failure"
Dec 20 04:11:08.433: INFO: Pod "pod-projected-secrets-47063a29-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 6.027248ms
Dec 20 04:11:10.436: INFO: Pod "pod-projected-secrets-47063a29-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009576229s
Dec 20 04:11:12.488: INFO: Pod "pod-projected-secrets-47063a29-040d-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061126433s
STEP: Saw pod success
Dec 20 04:11:12.488: INFO: Pod "pod-projected-secrets-47063a29-040d-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:11:12.536: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-projected-secrets-47063a29-040d-11e9-acdd-0a580ac80107 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 20 04:11:12.607: INFO: Waiting for pod pod-projected-secrets-47063a29-040d-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:11:12.609: INFO: Pod pod-projected-secrets-47063a29-040d-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:11:12.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8p9ss" for this suite.
Dec 20 04:11:18.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:11:19.024: INFO: namespace: e2e-tests-projected-8p9ss, resource: bindings, ignored listing per whitelist
Dec 20 04:11:19.072: INFO: namespace e2e-tests-projected-8p9ss deletion completed in 6.119724997s

• [SLOW TEST:10.725 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:11:19.072: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 20 04:11:19.144: INFO: Waiting up to 5m0s for pod "downward-api-4d699016-040d-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-d56j7" to be "success or failure"
Dec 20 04:11:19.149: INFO: Pod "downward-api-4d699016-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.387799ms
Dec 20 04:11:21.153: INFO: Pod "downward-api-4d699016-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008354955s
Dec 20 04:11:23.156: INFO: Pod "downward-api-4d699016-040d-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011729647s
STEP: Saw pod success
Dec 20 04:11:23.156: INFO: Pod "downward-api-4d699016-040d-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:11:23.159: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod downward-api-4d699016-040d-11e9-acdd-0a580ac80107 container dapi-container: <nil>
STEP: delete the pod
Dec 20 04:11:23.222: INFO: Waiting for pod downward-api-4d699016-040d-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:11:23.225: INFO: Pod downward-api-4d699016-040d-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:11:23.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d56j7" for this suite.
Dec 20 04:11:29.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:11:29.644: INFO: namespace: e2e-tests-downward-api-d56j7, resource: bindings, ignored listing per whitelist
Dec 20 04:11:29.687: INFO: namespace e2e-tests-downward-api-d56j7 deletion completed in 6.114225326s

• [SLOW TEST:10.615 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:11:29.687: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-53bd3b8c-040d-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 04:11:29.766: INFO: Waiting up to 5m0s for pod "pod-secrets-53be362d-040d-11e9-acdd-0a580ac80107" in namespace "e2e-tests-secrets-lxljh" to be "success or failure"
Dec 20 04:11:29.771: INFO: Pod "pod-secrets-53be362d-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.137207ms
Dec 20 04:11:31.775: INFO: Pod "pod-secrets-53be362d-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008709462s
Dec 20 04:11:33.827: INFO: Pod "pod-secrets-53be362d-040d-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060206594s
STEP: Saw pod success
Dec 20 04:11:33.827: INFO: Pod "pod-secrets-53be362d-040d-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:11:33.873: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-secrets-53be362d-040d-11e9-acdd-0a580ac80107 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 04:11:33.941: INFO: Waiting for pod pod-secrets-53be362d-040d-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:11:33.944: INFO: Pod pod-secrets-53be362d-040d-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:11:33.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lxljh" for this suite.
Dec 20 04:11:40.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:11:40.404: INFO: namespace: e2e-tests-secrets-lxljh, resource: bindings, ignored listing per whitelist
Dec 20 04:11:40.425: INFO: namespace e2e-tests-secrets-lxljh deletion completed in 6.102384987s

• [SLOW TEST:10.738 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:11:40.425: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec 20 04:11:46.505: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-5a231daf-040d-11e9-acdd-0a580ac80107", GenerateName:"", Namespace:"e2e-tests-pods-mh9pw", SelfLink:"/api/v1/namespaces/e2e-tests-pods-mh9pw/pods/pod-submit-remove-5a231daf-040d-11e9-acdd-0a580ac80107", UID:"5a23eb0f-040d-11e9-9da8-506b8da7f7e6", ResourceVersion:"6075", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63680875900, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"484760022"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-9pzrc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420d8cd80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9pzrc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc420fc6368), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"acsk8s-3f716c-k8s-worker-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc420a61500), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680875900, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680875905, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680875905, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680875900, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.154.55", PodIP:"10.200.1.17", StartTime:(*v1.Time)(0xc421a1d0a0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc421a1d0c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/nginx:1.14-alpine", ImageID:"docker-pullable://docker.io/nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6", ContainerID:"docker://5e02d3e0fb462010434971345118c44d72430c8019404207ea7eddee52062082"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 20 04:11:51.907: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:11:51.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mh9pw" for this suite.
Dec 20 04:11:57.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:11:58.181: INFO: namespace: e2e-tests-pods-mh9pw, resource: bindings, ignored listing per whitelist
Dec 20 04:11:58.245: INFO: namespace e2e-tests-pods-mh9pw deletion completed in 6.330458894s

• [SLOW TEST:17.820 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:11:58.245: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:11:58.487: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64dcea26-040d-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-k76l8" to be "success or failure"
Dec 20 04:11:58.493: INFO: Pod "downwardapi-volume-64dcea26-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.140325ms
Dec 20 04:12:00.496: INFO: Pod "downwardapi-volume-64dcea26-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008917289s
Dec 20 04:12:02.500: INFO: Pod "downwardapi-volume-64dcea26-040d-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012110432s
STEP: Saw pod success
Dec 20 04:12:02.500: INFO: Pod "downwardapi-volume-64dcea26-040d-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:12:02.502: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod downwardapi-volume-64dcea26-040d-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:12:02.531: INFO: Waiting for pod downwardapi-volume-64dcea26-040d-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:12:02.534: INFO: Pod downwardapi-volume-64dcea26-040d-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:12:02.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k76l8" for this suite.
Dec 20 04:12:08.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:12:08.585: INFO: namespace: e2e-tests-downward-api-k76l8, resource: bindings, ignored listing per whitelist
Dec 20 04:12:08.657: INFO: namespace e2e-tests-downward-api-k76l8 deletion completed in 6.119357974s

• [SLOW TEST:10.412 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:12:08.657: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:12:14.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-tk7wv" for this suite.
Dec 20 04:12:20.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:12:20.844: INFO: namespace: e2e-tests-namespaces-tk7wv, resource: bindings, ignored listing per whitelist
Dec 20 04:12:20.920: INFO: namespace e2e-tests-namespaces-tk7wv deletion completed in 6.104596678s
STEP: Destroying namespace "e2e-tests-nsdeletetest-rh6hd" for this suite.
Dec 20 04:12:20.923: INFO: Namespace e2e-tests-nsdeletetest-rh6hd was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-j47jq" for this suite.
Dec 20 04:12:26.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:12:26.968: INFO: namespace: e2e-tests-nsdeletetest-j47jq, resource: bindings, ignored listing per whitelist
Dec 20 04:12:27.045: INFO: namespace e2e-tests-nsdeletetest-j47jq deletion completed in 6.12274702s

• [SLOW TEST:18.388 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:12:27.046: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec 20 04:12:27.109: INFO: Waiting up to 5m0s for pod "var-expansion-75ec53c5-040d-11e9-acdd-0a580ac80107" in namespace "e2e-tests-var-expansion-nnxbk" to be "success or failure"
Dec 20 04:12:27.113: INFO: Pod "var-expansion-75ec53c5-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.325502ms
Dec 20 04:12:29.116: INFO: Pod "var-expansion-75ec53c5-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0075543s
Dec 20 04:12:31.119: INFO: Pod "var-expansion-75ec53c5-040d-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010740893s
STEP: Saw pod success
Dec 20 04:12:31.119: INFO: Pod "var-expansion-75ec53c5-040d-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:12:31.122: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod var-expansion-75ec53c5-040d-11e9-acdd-0a580ac80107 container dapi-container: <nil>
STEP: delete the pod
Dec 20 04:12:31.141: INFO: Waiting for pod var-expansion-75ec53c5-040d-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:12:31.143: INFO: Pod var-expansion-75ec53c5-040d-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:12:31.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-nnxbk" for this suite.
Dec 20 04:12:37.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:12:37.384: INFO: namespace: e2e-tests-var-expansion-nnxbk, resource: bindings, ignored listing per whitelist
Dec 20 04:12:37.441: INFO: namespace e2e-tests-var-expansion-nnxbk deletion completed in 6.109110104s

• [SLOW TEST:10.395 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:12:37.441: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec 20 04:12:37.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 --namespace=e2e-tests-kubectl-vwc2h run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 20 04:12:39.989: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 20 04:12:39.989: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:12:41.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vwc2h" for this suite.
Dec 20 04:12:50.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:12:50.324: INFO: namespace: e2e-tests-kubectl-vwc2h, resource: bindings, ignored listing per whitelist
Dec 20 04:12:50.332: INFO: namespace e2e-tests-kubectl-vwc2h deletion completed in 8.101645909s

• [SLOW TEST:12.891 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:12:50.332: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec 20 04:12:50.900: INFO: Waiting up to 5m0s for pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-nfth4" in namespace "e2e-tests-svcaccounts-gwphl" to be "success or failure"
Dec 20 04:12:50.903: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-nfth4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.293498ms
Dec 20 04:12:52.951: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-nfth4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050883473s
Dec 20 04:12:55.002: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-nfth4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.101688462s
STEP: Saw pod success
Dec 20 04:12:55.002: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-nfth4" satisfied condition "success or failure"
Dec 20 04:12:55.055: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-nfth4 container token-test: <nil>
STEP: delete the pod
Dec 20 04:12:55.125: INFO: Waiting for pod pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-nfth4 to disappear
Dec 20 04:12:55.127: INFO: Pod pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-nfth4 no longer exists
STEP: Creating a pod to test consume service account root CA
Dec 20 04:12:55.132: INFO: Waiting up to 5m0s for pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-qvbzq" in namespace "e2e-tests-svcaccounts-gwphl" to be "success or failure"
Dec 20 04:12:55.134: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-qvbzq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.282839ms
Dec 20 04:12:57.185: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-qvbzq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053326162s
Dec 20 04:12:59.246: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-qvbzq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.114270323s
STEP: Saw pod success
Dec 20 04:12:59.246: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-qvbzq" satisfied condition "success or failure"
Dec 20 04:12:59.303: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-qvbzq container root-ca-test: <nil>
STEP: delete the pod
Dec 20 04:12:59.439: INFO: Waiting for pod pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-qvbzq to disappear
Dec 20 04:12:59.442: INFO: Pod pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-qvbzq no longer exists
STEP: Creating a pod to test consume service account namespace
Dec 20 04:12:59.448: INFO: Waiting up to 5m0s for pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-7zdzl" in namespace "e2e-tests-svcaccounts-gwphl" to be "success or failure"
Dec 20 04:12:59.451: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-7zdzl": Phase="Pending", Reason="", readiness=false. Elapsed: 3.054058ms
Dec 20 04:13:01.454: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-7zdzl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006663049s
Dec 20 04:13:03.458: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-7zdzl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010167091s
STEP: Saw pod success
Dec 20 04:13:03.458: INFO: Pod "pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-7zdzl" satisfied condition "success or failure"
Dec 20 04:13:03.460: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-7zdzl container namespace-test: <nil>
STEP: delete the pod
Dec 20 04:13:03.485: INFO: Waiting for pod pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-7zdzl to disappear
Dec 20 04:13:03.488: INFO: Pod pod-service-account-841a8b2d-040d-11e9-acdd-0a580ac80107-7zdzl no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:13:03.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-gwphl" for this suite.
Dec 20 04:13:09.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:13:09.550: INFO: namespace: e2e-tests-svcaccounts-gwphl, resource: bindings, ignored listing per whitelist
Dec 20 04:13:09.603: INFO: namespace e2e-tests-svcaccounts-gwphl deletion completed in 6.109374948s

• [SLOW TEST:19.271 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:13:09.604: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-8f4b734b-040d-11e9-acdd-0a580ac80107
STEP: Creating configMap with name cm-test-opt-upd-8f4b73a3-040d-11e9-acdd-0a580ac80107
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-8f4b734b-040d-11e9-acdd-0a580ac80107
STEP: Updating configmap cm-test-opt-upd-8f4b73a3-040d-11e9-acdd-0a580ac80107
STEP: Creating configMap with name cm-test-opt-create-8f4b73ca-040d-11e9-acdd-0a580ac80107
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:13:17.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fnnfr" for this suite.
Dec 20 04:13:39.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:13:40.162: INFO: namespace: e2e-tests-configmap-fnnfr, resource: bindings, ignored listing per whitelist
Dec 20 04:13:40.254: INFO: namespace e2e-tests-configmap-fnnfr deletion completed in 22.367109098s

• [SLOW TEST:30.651 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:13:40.254: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 20 04:13:40.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-dk9sv'
Dec 20 04:13:40.628: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 20 04:13:40.628: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec 20 04:13:40.659: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 20 04:13:40.665: INFO: scanned /root for discovery docs: <nil>
Dec 20 04:13:40.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-dk9sv'
Dec 20 04:13:56.577: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 20 04:13:56.577: INFO: stdout: "Created e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17\nScaling up e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec 20 04:13:56.577: INFO: stdout: "Created e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17\nScaling up e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec 20 04:13:56.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dk9sv'
Dec 20 04:13:56.784: INFO: stderr: ""
Dec 20 04:13:56.784: INFO: stdout: "e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17-sq576 "
Dec 20 04:13:56.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17-sq576 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dk9sv'
Dec 20 04:13:56.970: INFO: stderr: ""
Dec 20 04:13:56.970: INFO: stdout: "true"
Dec 20 04:13:56.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17-sq576 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dk9sv'
Dec 20 04:13:57.164: INFO: stderr: ""
Dec 20 04:13:57.164: INFO: stdout: "docker.io/nginx:1.14-alpine"
Dec 20 04:13:57.164: INFO: e2e-test-nginx-rc-27cee854ce8ef6fa1d5cb5e7b4179d17-sq576 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Dec 20 04:13:57.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dk9sv'
Dec 20 04:13:57.316: INFO: stderr: ""
Dec 20 04:13:57.316: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:13:57.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dk9sv" for this suite.
Dec 20 04:14:03.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:14:03.516: INFO: namespace: e2e-tests-kubectl-dk9sv, resource: bindings, ignored listing per whitelist
Dec 20 04:14:03.565: INFO: namespace e2e-tests-kubectl-dk9sv deletion completed in 6.117082327s

• [SLOW TEST:23.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:14:03.565: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 20 04:14:03.629: INFO: PodSpec: initContainers in spec.initContainers
Dec 20 04:14:43.985: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-af754006-040d-11e9-acdd-0a580ac80107", GenerateName:"", Namespace:"e2e-tests-init-container-fwsfp", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-fwsfp/pods/pod-init-af754006-040d-11e9-acdd-0a580ac80107", UID:"af75ac40-040d-11e9-9da8-506b8da7f7e6", ResourceVersion:"6728", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63680876043, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"629382604"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-zlh55", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42116fe00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-zlh55", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-zlh55", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-zlh55", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc420c74558), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"acsk8s-3f716c-k8s-worker-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421f4a660), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876043, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876043, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876043, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876043, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.154.55", PodIP:"10.200.1.20", StartTime:(*v1.Time)(0xc420d647a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc420d647e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420b3ea80)}, Ready:false, RestartCount:3, Image:"docker.io/busybox:1.29", ImageID:"docker-pullable://docker.io/busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://7379b345e0cce565d323decd9a194a52dd711153845caf64eae6ff22b505db6b"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420d64840), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420d647c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:14:43.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-fwsfp" for this suite.
Dec 20 04:15:06.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:15:06.571: INFO: namespace: e2e-tests-init-container-fwsfp, resource: bindings, ignored listing per whitelist
Dec 20 04:15:06.622: INFO: namespace e2e-tests-init-container-fwsfp deletion completed in 22.300607443s

• [SLOW TEST:63.057 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:15:06.622: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-d534d5dc-040d-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 04:15:06.971: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d5356e5d-040d-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-cdcwc" to be "success or failure"
Dec 20 04:15:06.974: INFO: Pod "pod-projected-secrets-d5356e5d-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.429919ms
Dec 20 04:15:08.977: INFO: Pod "pod-projected-secrets-d5356e5d-040d-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005926826s
Dec 20 04:15:10.981: INFO: Pod "pod-projected-secrets-d5356e5d-040d-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009652324s
STEP: Saw pod success
Dec 20 04:15:10.981: INFO: Pod "pod-projected-secrets-d5356e5d-040d-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:15:10.984: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-projected-secrets-d5356e5d-040d-11e9-acdd-0a580ac80107 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 20 04:15:11.006: INFO: Waiting for pod pod-projected-secrets-d5356e5d-040d-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:15:11.009: INFO: Pod pod-projected-secrets-d5356e5d-040d-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:15:11.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cdcwc" for this suite.
Dec 20 04:15:17.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:15:17.081: INFO: namespace: e2e-tests-projected-cdcwc, resource: bindings, ignored listing per whitelist
Dec 20 04:15:17.116: INFO: namespace e2e-tests-projected-cdcwc deletion completed in 6.102847887s

• [SLOW TEST:10.494 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:15:17.116: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 20 04:15:17.181: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qz9vv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qz9vv/configmaps/e2e-watch-test-watch-closed,UID:db4abfc5-040d-11e9-9da8-506b8da7f7e6,ResourceVersion:6825,Generation:0,CreationTimestamp:2018-12-20 04:15:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 20 04:15:17.181: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qz9vv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qz9vv/configmaps/e2e-watch-test-watch-closed,UID:db4abfc5-040d-11e9-9da8-506b8da7f7e6,ResourceVersion:6826,Generation:0,CreationTimestamp:2018-12-20 04:15:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 20 04:15:17.195: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qz9vv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qz9vv/configmaps/e2e-watch-test-watch-closed,UID:db4abfc5-040d-11e9-9da8-506b8da7f7e6,ResourceVersion:6827,Generation:0,CreationTimestamp:2018-12-20 04:15:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 20 04:15:17.195: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qz9vv,SelfLink:/api/v1/namespaces/e2e-tests-watch-qz9vv/configmaps/e2e-watch-test-watch-closed,UID:db4abfc5-040d-11e9-9da8-506b8da7f7e6,ResourceVersion:6828,Generation:0,CreationTimestamp:2018-12-20 04:15:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:15:17.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qz9vv" for this suite.
Dec 20 04:15:23.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:15:23.245: INFO: namespace: e2e-tests-watch-qz9vv, resource: bindings, ignored listing per whitelist
Dec 20 04:15:23.310: INFO: namespace e2e-tests-watch-qz9vv deletion completed in 6.111417972s

• [SLOW TEST:6.194 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:15:23.310: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-nzc5n A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-nzc5n;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-nzc5n A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-nzc5n;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-nzc5n.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-nzc5n.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-nzc5n.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-nzc5n.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-nzc5n.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-nzc5n.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-nzc5n.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-nzc5n.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-nzc5n.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-nzc5n.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-nzc5n.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-nzc5n.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-nzc5n.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 33.0.32.10.in-addr.arpa. PTR)" && echo OK > /results/10.32.0.33_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 33.0.32.10.in-addr.arpa. PTR)" && echo OK > /results/10.32.0.33_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-nzc5n A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-nzc5n;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-nzc5n A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-nzc5n;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-nzc5n.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-nzc5n.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-nzc5n.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-nzc5n.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-nzc5n.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-nzc5n.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-nzc5n.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-nzc5n.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-nzc5n.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-nzc5n.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-nzc5n.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-nzc5n.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-nzc5n.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 33.0.32.10.in-addr.arpa. PTR)" && echo OK > /results/10.32.0.33_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 33.0.32.10.in-addr.arpa. PTR)" && echo OK > /results/10.32.0.33_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 20 04:15:47.692: INFO: DNS probes using e2e-tests-dns-nzc5n/dns-test-defef40f-040d-11e9-acdd-0a580ac80107 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:15:47.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-nzc5n" for this suite.
Dec 20 04:15:53.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:15:53.845: INFO: namespace: e2e-tests-dns-nzc5n, resource: bindings, ignored listing per whitelist
Dec 20 04:15:53.866: INFO: namespace e2e-tests-dns-nzc5n deletion completed in 6.10169596s

• [SLOW TEST:30.556 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:15:53.866: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lgbf4
Dec 20 04:15:59.967: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lgbf4
STEP: checking the pod's current state and verifying that restartCount is present
Dec 20 04:15:59.969: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:20:00.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lgbf4" for this suite.
Dec 20 04:20:07.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:20:07.128: INFO: namespace: e2e-tests-container-probe-lgbf4, resource: bindings, ignored listing per whitelist
Dec 20 04:20:07.131: INFO: namespace e2e-tests-container-probe-lgbf4 deletion completed in 6.109216837s

• [SLOW TEST:253.265 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:20:07.131: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 20 04:20:11.204: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-8827438c-040e-11e9-acdd-0a580ac80107,GenerateName:,Namespace:e2e-tests-events-xsn28,SelfLink:/api/v1/namespaces/e2e-tests-events-xsn28/pods/send-events-8827438c-040e-11e9-acdd-0a580ac80107,UID:88277cae-040e-11e9-9da8-506b8da7f7e6,ResourceVersion:7370,Generation:0,CreationTimestamp:2018-12-20 04:20:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 183868073,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4b4rk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4b4rk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-4b4rk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:20:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:20:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:20:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:20:07 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.53,PodIP:10.200.3.26,StartTime:2018-12-20 04:20:07 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-20 04:20:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://cc774f3596af42569bd2416aeaf144679ebe3e757786833bd0558f868a8b971e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec 20 04:20:13.209: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 20 04:20:15.270: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:20:15.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-xsn28" for this suite.
Dec 20 04:21:01.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:21:01.847: INFO: namespace: e2e-tests-events-xsn28, resource: bindings, ignored listing per whitelist
Dec 20 04:21:01.920: INFO: namespace e2e-tests-events-xsn28 deletion completed in 46.35502424s

• [SLOW TEST:54.789 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:21:01.920: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:21:02.235: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8f60cf3-040e-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-bv9vp" to be "success or failure"
Dec 20 04:21:02.238: INFO: Pod "downwardapi-volume-a8f60cf3-040e-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.494834ms
Dec 20 04:21:04.244: INFO: Pod "downwardapi-volume-a8f60cf3-040e-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009076703s
Dec 20 04:21:06.248: INFO: Pod "downwardapi-volume-a8f60cf3-040e-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012866709s
STEP: Saw pod success
Dec 20 04:21:06.248: INFO: Pod "downwardapi-volume-a8f60cf3-040e-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:21:06.250: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downwardapi-volume-a8f60cf3-040e-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:21:06.271: INFO: Waiting for pod downwardapi-volume-a8f60cf3-040e-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:21:06.274: INFO: Pod downwardapi-volume-a8f60cf3-040e-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:21:06.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bv9vp" for this suite.
Dec 20 04:21:12.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:21:12.333: INFO: namespace: e2e-tests-downward-api-bv9vp, resource: bindings, ignored listing per whitelist
Dec 20 04:21:12.390: INFO: namespace e2e-tests-downward-api-bv9vp deletion completed in 6.112425253s

• [SLOW TEST:10.470 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:21:12.391: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1220 04:21:52.898019      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 20 04:21:52.898: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:21:52.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wg86q" for this suite.
Dec 20 04:21:58.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:21:59.146: INFO: namespace: e2e-tests-gc-wg86q, resource: bindings, ignored listing per whitelist
Dec 20 04:21:59.149: INFO: namespace e2e-tests-gc-wg86q deletion completed in 6.24802081s

• [SLOW TEST:46.759 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:21:59.149: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-2c29w/secret-test-caed67f4-040e-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 04:21:59.229: INFO: Waiting up to 5m0s for pod "pod-configmaps-caeee0ca-040e-11e9-acdd-0a580ac80107" in namespace "e2e-tests-secrets-2c29w" to be "success or failure"
Dec 20 04:21:59.233: INFO: Pod "pod-configmaps-caeee0ca-040e-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.888126ms
Dec 20 04:22:01.236: INFO: Pod "pod-configmaps-caeee0ca-040e-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007332675s
Dec 20 04:22:03.241: INFO: Pod "pod-configmaps-caeee0ca-040e-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012083429s
STEP: Saw pod success
Dec 20 04:22:03.241: INFO: Pod "pod-configmaps-caeee0ca-040e-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:22:03.243: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-configmaps-caeee0ca-040e-11e9-acdd-0a580ac80107 container env-test: <nil>
STEP: delete the pod
Dec 20 04:22:03.274: INFO: Waiting for pod pod-configmaps-caeee0ca-040e-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:22:03.279: INFO: Pod pod-configmaps-caeee0ca-040e-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:22:03.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2c29w" for this suite.
Dec 20 04:22:09.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:22:09.378: INFO: namespace: e2e-tests-secrets-2c29w, resource: bindings, ignored listing per whitelist
Dec 20 04:22:09.396: INFO: namespace e2e-tests-secrets-2c29w deletion completed in 6.113020614s

• [SLOW TEST:10.247 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:22:09.396: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 04:22:09.465: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Dec 20 04:22:09.474: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4285r/daemonsets","resourceVersion":"7813"},"items":null}

Dec 20 04:22:09.476: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4285r/pods","resourceVersion":"7813"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:22:09.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4285r" for this suite.
Dec 20 04:22:15.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:22:15.589: INFO: namespace: e2e-tests-daemonsets-4285r, resource: bindings, ignored listing per whitelist
Dec 20 04:22:15.593: INFO: namespace e2e-tests-daemonsets-4285r deletion completed in 6.104239239s

S [SKIPPING] [6.197 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec 20 04:22:09.465: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:22:15.594: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:22:15.663: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4ba341e-040e-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-nlm5v" to be "success or failure"
Dec 20 04:22:15.668: INFO: Pod "downwardapi-volume-d4ba341e-040e-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.959251ms
Dec 20 04:22:17.672: INFO: Pod "downwardapi-volume-d4ba341e-040e-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008668831s
Dec 20 04:22:19.728: INFO: Pod "downwardapi-volume-d4ba341e-040e-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065016167s
STEP: Saw pod success
Dec 20 04:22:19.728: INFO: Pod "downwardapi-volume-d4ba341e-040e-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:22:19.791: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downwardapi-volume-d4ba341e-040e-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:22:19.865: INFO: Waiting for pod downwardapi-volume-d4ba341e-040e-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:22:19.869: INFO: Pod downwardapi-volume-d4ba341e-040e-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:22:19.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nlm5v" for this suite.
Dec 20 04:22:26.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:22:26.272: INFO: namespace: e2e-tests-projected-nlm5v, resource: bindings, ignored listing per whitelist
Dec 20 04:22:26.303: INFO: namespace e2e-tests-projected-nlm5v deletion completed in 6.102720715s

• [SLOW TEST:10.710 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:22:26.303: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 04:22:26.360: INFO: Creating deployment "test-recreate-deployment"
Dec 20 04:22:26.366: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 20 04:22:26.384: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 20 04:22:28.392: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 20 04:22:28.394: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876546, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876546, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 04:22:30.399: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876546, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876546, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680876546, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 04:22:32.398: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 20 04:22:32.408: INFO: Updating deployment test-recreate-deployment
Dec 20 04:22:32.408: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 20 04:22:32.485: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-fbnvs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fbnvs/deployments/test-recreate-deployment,UID:db1be1a1-040e-11e9-9da8-506b8da7f7e6,ResourceVersion:7922,Generation:2,CreationTimestamp:2018-12-20 04:22:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-20 04:22:32 +0000 UTC 2018-12-20 04:22:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-20 04:22:32 +0000 UTC 2018-12-20 04:22:26 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec 20 04:22:32.537: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-fbnvs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fbnvs/replicasets/test-recreate-deployment-7cf749666b,UID:debbae68-040e-11e9-9da8-506b8da7f7e6,ResourceVersion:7921,Generation:1,CreationTimestamp:2018-12-20 04:22:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment db1be1a1-040e-11e9-9da8-506b8da7f7e6 0xc422afe9e7 0xc422afe9e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 20 04:22:32.537: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 20 04:22:32.537: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-fbnvs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fbnvs/replicasets/test-recreate-deployment-79f694ff59,UID:db1cb831-040e-11e9-9da8-506b8da7f7e6,ResourceVersion:7911,Generation:2,CreationTimestamp:2018-12-20 04:22:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment db1be1a1-040e-11e9-9da8-506b8da7f7e6 0xc422afe917 0xc422afe918}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 20 04:22:32.542: INFO: Pod "test-recreate-deployment-7cf749666b-8dfnx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-8dfnx,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-fbnvs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fbnvs/pods/test-recreate-deployment-7cf749666b-8dfnx,UID:debc80c8-040e-11e9-9da8-506b8da7f7e6,ResourceVersion:7917,Generation:0,CreationTimestamp:2018-12-20 04:22:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b debbae68-040e-11e9-9da8-506b8da7f7e6 0xc422aff467 0xc422aff468}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrfwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrfwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrfwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:22:32 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:22:32.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fbnvs" for this suite.
Dec 20 04:22:38.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:22:38.927: INFO: namespace: e2e-tests-deployment-fbnvs, resource: bindings, ignored listing per whitelist
Dec 20 04:22:38.978: INFO: namespace e2e-tests-deployment-fbnvs deletion completed in 6.111722385s

• [SLOW TEST:12.675 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:22:38.978: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:22:39.043: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2aa1982-040e-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-sbk77" to be "success or failure"
Dec 20 04:22:39.045: INFO: Pod "downwardapi-volume-e2aa1982-040e-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.546134ms
Dec 20 04:22:41.049: INFO: Pod "downwardapi-volume-e2aa1982-040e-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006790243s
Dec 20 04:22:43.053: INFO: Pod "downwardapi-volume-e2aa1982-040e-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010780507s
STEP: Saw pod success
Dec 20 04:22:43.054: INFO: Pod "downwardapi-volume-e2aa1982-040e-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:22:43.056: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downwardapi-volume-e2aa1982-040e-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:22:43.131: INFO: Waiting for pod downwardapi-volume-e2aa1982-040e-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:22:43.135: INFO: Pod downwardapi-volume-e2aa1982-040e-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:22:43.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sbk77" for this suite.
Dec 20 04:22:49.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:22:49.601: INFO: namespace: e2e-tests-projected-sbk77, resource: bindings, ignored listing per whitelist
Dec 20 04:22:49.659: INFO: namespace e2e-tests-projected-sbk77 deletion completed in 6.140971681s

• [SLOW TEST:10.680 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:22:49.659: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 20 04:22:49.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-hqcpz'
Dec 20 04:22:50.091: INFO: stderr: ""
Dec 20 04:22:50.091: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 04:22:50.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hqcpz'
Dec 20 04:22:50.215: INFO: stderr: ""
Dec 20 04:22:50.215: INFO: stdout: "update-demo-nautilus-8xpcg update-demo-nautilus-9mb8r "
Dec 20 04:22:50.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-8xpcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqcpz'
Dec 20 04:22:50.322: INFO: stderr: ""
Dec 20 04:22:50.322: INFO: stdout: ""
Dec 20 04:22:50.322: INFO: update-demo-nautilus-8xpcg is created but not running
Dec 20 04:22:55.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hqcpz'
Dec 20 04:22:55.664: INFO: stderr: ""
Dec 20 04:22:55.664: INFO: stdout: "update-demo-nautilus-8xpcg update-demo-nautilus-9mb8r "
Dec 20 04:22:55.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-8xpcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqcpz'
Dec 20 04:22:55.936: INFO: stderr: ""
Dec 20 04:22:55.936: INFO: stdout: "true"
Dec 20 04:22:55.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-8xpcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqcpz'
Dec 20 04:22:56.038: INFO: stderr: ""
Dec 20 04:22:56.038: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 04:22:56.038: INFO: validating pod update-demo-nautilus-8xpcg
Dec 20 04:22:56.042: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 04:22:56.042: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 04:22:56.042: INFO: update-demo-nautilus-8xpcg is verified up and running
Dec 20 04:22:56.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-9mb8r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqcpz'
Dec 20 04:22:56.151: INFO: stderr: ""
Dec 20 04:22:56.151: INFO: stdout: "true"
Dec 20 04:22:56.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-9mb8r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hqcpz'
Dec 20 04:22:56.248: INFO: stderr: ""
Dec 20 04:22:56.248: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 04:22:56.248: INFO: validating pod update-demo-nautilus-9mb8r
Dec 20 04:22:56.252: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 04:22:56.252: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 04:22:56.252: INFO: update-demo-nautilus-9mb8r is verified up and running
STEP: using delete to clean up resources
Dec 20 04:22:56.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqcpz'
Dec 20 04:22:56.348: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 04:22:56.348: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 20 04:22:56.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-hqcpz'
Dec 20 04:22:56.488: INFO: stderr: "No resources found.\n"
Dec 20 04:22:56.488: INFO: stdout: ""
Dec 20 04:22:56.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -l name=update-demo --namespace=e2e-tests-kubectl-hqcpz -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 20 04:22:56.599: INFO: stderr: ""
Dec 20 04:22:56.599: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:22:56.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hqcpz" for this suite.
Dec 20 04:23:18.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:23:18.859: INFO: namespace: e2e-tests-kubectl-hqcpz, resource: bindings, ignored listing per whitelist
Dec 20 04:23:18.887: INFO: namespace e2e-tests-kubectl-hqcpz deletion completed in 22.284378723s

• [SLOW TEST:29.229 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:23:18.887: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 20 04:23:19.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-b5l7l'
Dec 20 04:23:19.218: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 20 04:23:19.218: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec 20 04:23:19.231: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-nf2xh]
Dec 20 04:23:19.231: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-nf2xh" in namespace "e2e-tests-kubectl-b5l7l" to be "running and ready"
Dec 20 04:23:19.234: INFO: Pod "e2e-test-nginx-rc-nf2xh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.38469ms
Dec 20 04:23:21.236: INFO: Pod "e2e-test-nginx-rc-nf2xh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005175323s
Dec 20 04:23:23.240: INFO: Pod "e2e-test-nginx-rc-nf2xh": Phase="Running", Reason="", readiness=true. Elapsed: 4.008670668s
Dec 20 04:23:23.240: INFO: Pod "e2e-test-nginx-rc-nf2xh" satisfied condition "running and ready"
Dec 20 04:23:23.240: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-nf2xh]
Dec 20 04:23:23.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-b5l7l'
Dec 20 04:23:23.481: INFO: stderr: ""
Dec 20 04:23:23.481: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Dec 20 04:23:23.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-b5l7l'
Dec 20 04:23:23.648: INFO: stderr: ""
Dec 20 04:23:23.648: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:23:23.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b5l7l" for this suite.
Dec 20 04:23:29.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:23:29.855: INFO: namespace: e2e-tests-kubectl-b5l7l, resource: bindings, ignored listing per whitelist
Dec 20 04:23:29.933: INFO: namespace e2e-tests-kubectl-b5l7l deletion completed in 6.114446335s

• [SLOW TEST:11.045 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:23:29.933: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-965kf/configmap-test-0109568a-040f-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 04:23:30.006: INFO: Waiting up to 5m0s for pod "pod-configmaps-010a1dbe-040f-11e9-acdd-0a580ac80107" in namespace "e2e-tests-configmap-965kf" to be "success or failure"
Dec 20 04:23:30.011: INFO: Pod "pod-configmaps-010a1dbe-040f-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.694077ms
Dec 20 04:23:32.016: INFO: Pod "pod-configmaps-010a1dbe-040f-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010044315s
STEP: Saw pod success
Dec 20 04:23:32.016: INFO: Pod "pod-configmaps-010a1dbe-040f-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:23:32.019: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-configmaps-010a1dbe-040f-11e9-acdd-0a580ac80107 container env-test: <nil>
STEP: delete the pod
Dec 20 04:23:32.040: INFO: Waiting for pod pod-configmaps-010a1dbe-040f-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:23:32.043: INFO: Pod pod-configmaps-010a1dbe-040f-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:23:32.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-965kf" for this suite.
Dec 20 04:23:38.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:23:38.142: INFO: namespace: e2e-tests-configmap-965kf, resource: bindings, ignored listing per whitelist
Dec 20 04:23:38.154: INFO: namespace e2e-tests-configmap-965kf deletion completed in 6.106671692s

• [SLOW TEST:8.222 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:23:38.154: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-05eeb2cb-040f-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 04:23:38.217: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-05ef8539-040f-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-xtr4m" to be "success or failure"
Dec 20 04:23:38.220: INFO: Pod "pod-projected-configmaps-05ef8539-040f-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.939145ms
Dec 20 04:23:40.224: INFO: Pod "pod-projected-configmaps-05ef8539-040f-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006597174s
Dec 20 04:23:42.288: INFO: Pod "pod-projected-configmaps-05ef8539-040f-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070812869s
STEP: Saw pod success
Dec 20 04:23:42.288: INFO: Pod "pod-projected-configmaps-05ef8539-040f-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:23:42.337: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-projected-configmaps-05ef8539-040f-11e9-acdd-0a580ac80107 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 04:23:42.403: INFO: Waiting for pod pod-projected-configmaps-05ef8539-040f-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:23:42.406: INFO: Pod pod-projected-configmaps-05ef8539-040f-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:23:42.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xtr4m" for this suite.
Dec 20 04:23:48.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:23:48.760: INFO: namespace: e2e-tests-projected-xtr4m, resource: bindings, ignored listing per whitelist
Dec 20 04:23:48.842: INFO: namespace e2e-tests-projected-xtr4m deletion completed in 6.103310925s

• [SLOW TEST:10.688 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:23:48.842: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 04:23:48.904: INFO: Creating ReplicaSet my-hostname-basic-0c4f32ee-040f-11e9-acdd-0a580ac80107
Dec 20 04:23:48.914: INFO: Pod name my-hostname-basic-0c4f32ee-040f-11e9-acdd-0a580ac80107: Found 0 pods out of 1
Dec 20 04:23:53.977: INFO: Pod name my-hostname-basic-0c4f32ee-040f-11e9-acdd-0a580ac80107: Found 1 pods out of 1
Dec 20 04:23:53.977: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0c4f32ee-040f-11e9-acdd-0a580ac80107" is running
Dec 20 04:23:54.026: INFO: Pod "my-hostname-basic-0c4f32ee-040f-11e9-acdd-0a580ac80107-p9nqq" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-20 04:23:48 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-20 04:23:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-20 04:23:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-20 04:23:48 +0000 UTC Reason: Message:}])
Dec 20 04:23:54.027: INFO: Trying to dial the pod
Dec 20 04:23:59.085: INFO: Controller my-hostname-basic-0c4f32ee-040f-11e9-acdd-0a580ac80107: Got expected result from replica 1 [my-hostname-basic-0c4f32ee-040f-11e9-acdd-0a580ac80107-p9nqq]: "my-hostname-basic-0c4f32ee-040f-11e9-acdd-0a580ac80107-p9nqq", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:23:59.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-gn9ph" for this suite.
Dec 20 04:24:05.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:24:05.523: INFO: namespace: e2e-tests-replicaset-gn9ph, resource: bindings, ignored listing per whitelist
Dec 20 04:24:05.535: INFO: namespace e2e-tests-replicaset-gn9ph deletion completed in 6.123711041s

• [SLOW TEST:16.693 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:24:05.535: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1641c679-040f-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 04:24:05.609: INFO: Waiting up to 5m0s for pod "pod-secrets-16429c12-040f-11e9-acdd-0a580ac80107" in namespace "e2e-tests-secrets-fvvth" to be "success or failure"
Dec 20 04:24:05.614: INFO: Pod "pod-secrets-16429c12-040f-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.024392ms
Dec 20 04:24:07.617: INFO: Pod "pod-secrets-16429c12-040f-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008008248s
Dec 20 04:24:09.620: INFO: Pod "pod-secrets-16429c12-040f-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011615795s
STEP: Saw pod success
Dec 20 04:24:09.620: INFO: Pod "pod-secrets-16429c12-040f-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:24:09.623: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-secrets-16429c12-040f-11e9-acdd-0a580ac80107 container secret-env-test: <nil>
STEP: delete the pod
Dec 20 04:24:09.641: INFO: Waiting for pod pod-secrets-16429c12-040f-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:24:09.644: INFO: Pod pod-secrets-16429c12-040f-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:24:09.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fvvth" for this suite.
Dec 20 04:24:15.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:24:15.901: INFO: namespace: e2e-tests-secrets-fvvth, resource: bindings, ignored listing per whitelist
Dec 20 04:24:15.957: INFO: namespace e2e-tests-secrets-fvvth deletion completed in 6.109093263s

• [SLOW TEST:10.423 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:24:15.958: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-59pg2
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 20 04:24:16.014: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 20 04:24:42.142: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.2.37:8080/dial?request=hostName&protocol=udp&host=10.200.3.35&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-59pg2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:24:42.142: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:24:42.266: INFO: Waiting for endpoints: map[]
Dec 20 04:24:42.269: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.2.37:8080/dial?request=hostName&protocol=udp&host=10.200.2.36&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-59pg2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:24:42.269: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:24:42.383: INFO: Waiting for endpoints: map[]
Dec 20 04:24:42.386: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.2.37:8080/dial?request=hostName&protocol=udp&host=10.200.1.33&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-59pg2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:24:42.386: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:24:42.506: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:24:42.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-59pg2" for this suite.
Dec 20 04:25:04.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:25:05.036: INFO: namespace: e2e-tests-pod-network-test-59pg2, resource: bindings, ignored listing per whitelist
Dec 20 04:25:05.079: INFO: namespace e2e-tests-pod-network-test-59pg2 deletion completed in 22.395131873s

• [SLOW TEST:49.121 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:25:05.079: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-q94mx
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-q94mx
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-q94mx
Dec 20 04:25:05.365: INFO: Found 0 stateful pods, waiting for 1
Dec 20 04:25:15.369: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 20 04:25:15.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 20 04:25:15.709: INFO: stderr: ""
Dec 20 04:25:15.709: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 20 04:25:15.709: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 20 04:25:15.713: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 20 04:25:25.763: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 04:25:25.764: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 04:25:25.821: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 20 04:25:25.821: INFO: ss-0  acsk8s-3f716c-k8s-worker-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  }]
Dec 20 04:25:25.821: INFO: 
Dec 20 04:25:25.821: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 20 04:25:26.871: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.953036346s
Dec 20 04:25:27.923: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.903493622s
Dec 20 04:25:28.982: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.851205623s
Dec 20 04:25:30.034: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.791664627s
Dec 20 04:25:31.081: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.740478842s
Dec 20 04:25:32.131: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.693220044s
Dec 20 04:25:33.182: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.643119917s
Dec 20 04:25:34.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.592343802s
Dec 20 04:25:35.279: INFO: Verifying statefulset ss doesn't scale past 3 for another 545.010459ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-q94mx
Dec 20 04:25:36.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:25:36.649: INFO: stderr: ""
Dec 20 04:25:36.649: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 20 04:25:36.649: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 20 04:25:36.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:25:36.858: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 20 04:25:36.858: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 20 04:25:36.858: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 20 04:25:36.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:25:37.026: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 20 04:25:37.026: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 20 04:25:37.026: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 20 04:25:37.031: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec 20 04:25:47.035: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 04:25:47.035: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 04:25:47.035: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 20 04:25:47.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 20 04:25:47.203: INFO: stderr: ""
Dec 20 04:25:47.203: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 20 04:25:47.203: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 20 04:25:47.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 20 04:25:47.369: INFO: stderr: ""
Dec 20 04:25:47.369: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 20 04:25:47.369: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 20 04:25:47.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 20 04:25:47.586: INFO: stderr: ""
Dec 20 04:25:47.586: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 20 04:25:47.586: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 20 04:25:47.586: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 04:25:47.589: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec 20 04:25:57.644: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 04:25:57.644: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 04:25:57.644: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 04:25:57.705: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 20 04:25:57.705: INFO: ss-0  acsk8s-3f716c-k8s-worker-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  }]
Dec 20 04:25:57.705: INFO: ss-1  acsk8s-3f716c-k8s-worker-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:25:57.705: INFO: ss-2  acsk8s-3f716c-k8s-worker-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:25:57.705: INFO: 
Dec 20 04:25:57.705: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 20 04:25:58.759: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 20 04:25:58.759: INFO: ss-0  acsk8s-3f716c-k8s-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  }]
Dec 20 04:25:58.759: INFO: ss-1  acsk8s-3f716c-k8s-worker-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:25:58.759: INFO: ss-2  acsk8s-3f716c-k8s-worker-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:25:58.759: INFO: 
Dec 20 04:25:58.759: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 20 04:25:59.809: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 20 04:25:59.809: INFO: ss-0  acsk8s-3f716c-k8s-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  }]
Dec 20 04:25:59.809: INFO: ss-1  acsk8s-3f716c-k8s-worker-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:25:59.809: INFO: ss-2  acsk8s-3f716c-k8s-worker-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:25:59.809: INFO: 
Dec 20 04:25:59.809: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 20 04:26:00.859: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 20 04:26:00.859: INFO: ss-0  acsk8s-3f716c-k8s-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  }]
Dec 20 04:26:00.859: INFO: ss-2  acsk8s-3f716c-k8s-worker-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:26:00.859: INFO: 
Dec 20 04:26:00.859: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 20 04:26:01.910: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 20 04:26:01.910: INFO: ss-0  acsk8s-3f716c-k8s-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  }]
Dec 20 04:26:01.910: INFO: ss-2  acsk8s-3f716c-k8s-worker-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:26:01.910: INFO: 
Dec 20 04:26:01.910: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 20 04:26:02.965: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 20 04:26:02.965: INFO: ss-0  acsk8s-3f716c-k8s-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  }]
Dec 20 04:26:02.965: INFO: ss-2  acsk8s-3f716c-k8s-worker-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:26:02.965: INFO: 
Dec 20 04:26:02.965: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 20 04:26:04.015: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 20 04:26:04.015: INFO: ss-0  acsk8s-3f716c-k8s-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  }]
Dec 20 04:26:04.015: INFO: ss-2  acsk8s-3f716c-k8s-worker-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:26:04.015: INFO: 
Dec 20 04:26:04.015: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 20 04:26:05.066: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 20 04:26:05.066: INFO: ss-0  acsk8s-3f716c-k8s-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  }]
Dec 20 04:26:05.066: INFO: ss-2  acsk8s-3f716c-k8s-worker-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:26:05.066: INFO: 
Dec 20 04:26:05.066: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 20 04:26:06.117: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 20 04:26:06.117: INFO: ss-0  acsk8s-3f716c-k8s-worker-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:05 +0000 UTC  }]
Dec 20 04:26:06.117: INFO: ss-2  acsk8s-3f716c-k8s-worker-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:26:06.117: INFO: 
Dec 20 04:26:06.117: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 20 04:26:07.167: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 20 04:26:07.167: INFO: ss-2  acsk8s-3f716c-k8s-worker-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:25:25 +0000 UTC  }]
Dec 20 04:26:07.167: INFO: 
Dec 20 04:26:07.167: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-q94mx
Dec 20 04:26:08.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:26:08.289: INFO: rc: 1
Dec 20 04:26:08.289: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc4217c93b0 exit status 1 <nil> <nil> true [0xc420847a18 0xc420847ab0 0xc420847b50] [0xc420847a18 0xc420847ab0 0xc420847b50] [0xc420847a88 0xc420847b38] [0x8fd520 0x8fd520] 0xc4227904e0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Dec 20 04:26:18.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:26:18.432: INFO: rc: 1
Dec 20 04:26:18.432: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421a66420 exit status 1 <nil> <nil> true [0xc420da0000 0xc420da0060 0xc420da0088] [0xc420da0000 0xc420da0060 0xc420da0088] [0xc420da0040 0xc420da0080] [0x8fd520 0x8fd520] 0xc420d70060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:26:28.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:26:28.582: INFO: rc: 1
Dec 20 04:26:28.582: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42126de30 exit status 1 <nil> <nil> true [0xc420910358 0xc420910418 0xc420910480] [0xc420910358 0xc420910418 0xc420910480] [0xc4209103b8 0xc420910470] [0x8fd520 0x8fd520] 0xc4228ca600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:26:38.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:26:38.728: INFO: rc: 1
Dec 20 04:26:38.728: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42190a240 exit status 1 <nil> <nil> true [0xc4209104a8 0xc420910510 0xc420910588] [0xc4209104a8 0xc420910510 0xc420910588] [0xc4209104f0 0xc420910578] [0x8fd520 0x8fd520] 0xc4228ca780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:26:48.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:26:48.870: INFO: rc: 1
Dec 20 04:26:48.870: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421a66810 exit status 1 <nil> <nil> true [0xc420da0090 0xc420da00c8 0xc420da00e0] [0xc420da0090 0xc420da00c8 0xc420da00e0] [0xc420da00b0 0xc420da00d8] [0x8fd520 0x8fd520] 0xc420d70180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:26:58.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:26:59.010: INFO: rc: 1
Dec 20 04:26:59.010: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42190a720 exit status 1 <nil> <nil> true [0xc420910598 0xc420910600 0xc420910678] [0xc420910598 0xc420910600 0xc420910678] [0xc4209105e8 0xc420910648] [0x8fd520 0x8fd520] 0xc4228ca8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:27:09.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:27:09.152: INFO: rc: 1
Dec 20 04:27:09.152: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4217c98c0 exit status 1 <nil> <nil> true [0xc420847b68 0xc420847c48 0xc420847e30] [0xc420847b68 0xc420847c48 0xc420847e30] [0xc420847bf0 0xc420847d98] [0x8fd520 0x8fd520] 0xc422790600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:27:19.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:27:19.295: INFO: rc: 1
Dec 20 04:27:19.295: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4217c9cb0 exit status 1 <nil> <nil> true [0xc420847ee8 0xc420847f40 0xc420847fa0] [0xc420847ee8 0xc420847f40 0xc420847fa0] [0xc420847f38 0xc420847f88] [0x8fd520 0x8fd520] 0xc422790720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:27:29.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:27:29.434: INFO: rc: 1
Dec 20 04:27:29.434: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4210b41b0 exit status 1 <nil> <nil> true [0xc420a6afd0 0xc420a6b030 0xc420a6b080] [0xc420a6afd0 0xc420a6b030 0xc420a6b080] [0xc420a6b020 0xc420a6b048] [0x8fd520 0x8fd520] 0xc422376c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:27:39.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:27:39.570: INFO: rc: 1
Dec 20 04:27:39.570: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42190acc0 exit status 1 <nil> <nil> true [0xc420910680 0xc4209106d8 0xc420910720] [0xc420910680 0xc4209106d8 0xc420910720] [0xc4209106c8 0xc420910718] [0x8fd520 0x8fd520] 0xc4228ca9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:27:49.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:27:49.715: INFO: rc: 1
Dec 20 04:27:49.715: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4210b45a0 exit status 1 <nil> <nil> true [0xc420a6b0a8 0xc420a6b0f8 0xc420a6b1d0] [0xc420a6b0a8 0xc420a6b0f8 0xc420a6b1d0] [0xc420a6b0e0 0xc420a6b1a0] [0x8fd520 0x8fd520] 0xc422376d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:27:59.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:27:59.855: INFO: rc: 1
Dec 20 04:27:59.855: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42126c960 exit status 1 <nil> <nil> true [0xc4200e6138 0xc4200e61f8 0xc4200e6278] [0xc4200e6138 0xc4200e61f8 0xc4200e6278] [0xc4200e61e8 0xc4200e6248] [0x8fd520 0x8fd520] 0xc420d70060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:28:09.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:28:09.994: INFO: rc: 1
Dec 20 04:28:09.994: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ecc2d0 exit status 1 <nil> <nil> true [0xc420da0000 0xc420da0060 0xc420da0088] [0xc420da0000 0xc420da0060 0xc420da0088] [0xc420da0040 0xc420da0080] [0x8fd520 0x8fd520] 0xc422790060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:28:19.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:28:20.129: INFO: rc: 1
Dec 20 04:28:20.130: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42126cd80 exit status 1 <nil> <nil> true [0xc4200e62a8 0xc4200e62e8 0xc420847720] [0xc4200e62a8 0xc4200e62e8 0xc420847720] [0xc4200e62d8 0xc420847708] [0x8fd520 0x8fd520] 0xc420d70180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:28:30.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:28:30.275: INFO: rc: 1
Dec 20 04:28:30.275: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42126d260 exit status 1 <nil> <nil> true [0xc420847748 0xc4208477d8 0xc4208478a0] [0xc420847748 0xc4208477d8 0xc4208478a0] [0xc4208477c8 0xc420847880] [0x8fd520 0x8fd520] 0xc420d702a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:28:40.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:28:40.422: INFO: rc: 1
Dec 20 04:28:40.423: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ecc750 exit status 1 <nil> <nil> true [0xc420da0090 0xc420da00c8 0xc420da00e0] [0xc420da0090 0xc420da00c8 0xc420da00e0] [0xc420da00b0 0xc420da00d8] [0x8fd520 0x8fd520] 0xc422790180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:28:50.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:28:50.573: INFO: rc: 1
Dec 20 04:28:50.573: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42126d710 exit status 1 <nil> <nil> true [0xc4208478c8 0xc420847950 0xc420847a18] [0xc4208478c8 0xc420847950 0xc420847a18] [0xc4208478e8 0xc4208479d8] [0x8fd520 0x8fd520] 0xc422376060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:29:00.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:29:00.709: INFO: rc: 1
Dec 20 04:29:00.709: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421eccb10 exit status 1 <nil> <nil> true [0xc420da00e8 0xc420da0100 0xc420da0140] [0xc420da00e8 0xc420da0100 0xc420da0140] [0xc420da00f8 0xc420da0120] [0x8fd520 0x8fd520] 0xc4227902a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:29:10.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:29:10.798: INFO: rc: 1
Dec 20 04:29:10.799: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ecced0 exit status 1 <nil> <nil> true [0xc420da0158 0xc420da0170 0xc420da0190] [0xc420da0158 0xc420da0170 0xc420da0190] [0xc420da0168 0xc420da0180] [0x8fd520 0x8fd520] 0xc4227903c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:29:20.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:29:20.936: INFO: rc: 1
Dec 20 04:29:20.936: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ecd2c0 exit status 1 <nil> <nil> true [0xc420da01b0 0xc420da0210 0xc420da0268] [0xc420da01b0 0xc420da0210 0xc420da0268] [0xc420da01f0 0xc420da0250] [0x8fd520 0x8fd520] 0xc422790540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:29:30.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:29:31.072: INFO: rc: 1
Dec 20 04:29:31.072: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42126dbc0 exit status 1 <nil> <nil> true [0xc420847a48 0xc420847af0 0xc420847b68] [0xc420847a48 0xc420847af0 0xc420847b68] [0xc420847ab0 0xc420847b50] [0x8fd520 0x8fd520] 0xc422376180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:29:41.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:29:41.237: INFO: rc: 1
Dec 20 04:29:41.238: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421a66480 exit status 1 <nil> <nil> true [0xc420a6a0b8 0xc420a6a1e8 0xc420a6a228] [0xc420a6a0b8 0xc420a6a1e8 0xc420a6a228] [0xc420a6a1c8 0xc420a6a208] [0x8fd520 0x8fd520] 0xc4228ca060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:29:51.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:29:51.381: INFO: rc: 1
Dec 20 04:29:51.381: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ecd6b0 exit status 1 <nil> <nil> true [0xc420da0270 0xc420da0298 0xc420da02c0] [0xc420da0270 0xc420da0298 0xc420da02c0] [0xc420da0280 0xc420da02b8] [0x8fd520 0x8fd520] 0xc422790660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:30:01.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:30:01.535: INFO: rc: 1
Dec 20 04:30:01.535: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421a668a0 exit status 1 <nil> <nil> true [0xc420a6a418 0xc420a6a6b0 0xc420a6a828] [0xc420a6a418 0xc420a6a6b0 0xc420a6a828] [0xc420a6a608 0xc420a6a7e8] [0x8fd520 0x8fd520] 0xc4228ca180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:30:11.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:30:11.683: INFO: rc: 1
Dec 20 04:30:11.683: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42126c720 exit status 1 <nil> <nil> true [0xc4200e60e8 0xc4200e61e8 0xc4200e6248] [0xc4200e60e8 0xc4200e61e8 0xc4200e6248] [0xc4200e6198 0xc4200e6218] [0x8fd520 0x8fd520] 0xc420d70060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:30:21.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:30:21.834: INFO: rc: 1
Dec 20 04:30:21.835: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421a66420 exit status 1 <nil> <nil> true [0xc420847708 0xc420847798 0xc420847870] [0xc420847708 0xc420847798 0xc420847870] [0xc420847748 0xc4208477d8] [0x8fd520 0x8fd520] 0xc422376060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:30:31.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:30:31.976: INFO: rc: 1
Dec 20 04:30:31.976: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42126ccf0 exit status 1 <nil> <nil> true [0xc4200e6278 0xc4200e62d8 0xc420da0000] [0xc4200e6278 0xc4200e62d8 0xc420da0000] [0xc4200e62b8 0xc4200e71d8] [0x8fd520 0x8fd520] 0xc420d70180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:30:41.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:30:42.116: INFO: rc: 1
Dec 20 04:30:42.116: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42126d200 exit status 1 <nil> <nil> true [0xc420da0020 0xc420da0078 0xc420da0090] [0xc420da0020 0xc420da0078 0xc420da0090] [0xc420da0060 0xc420da0088] [0x8fd520 0x8fd520] 0xc420d702a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:30:52.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:30:52.257: INFO: rc: 1
Dec 20 04:30:52.257: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ecc3f0 exit status 1 <nil> <nil> true [0xc420a6a0b8 0xc420a6a1e8 0xc420a6a228] [0xc420a6a0b8 0xc420a6a1e8 0xc420a6a228] [0xc420a6a1c8 0xc420a6a208] [0x8fd520 0x8fd520] 0xc422790060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:31:02.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:31:02.404: INFO: rc: 1
Dec 20 04:31:02.404: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4217c84b0 exit status 1 <nil> <nil> true [0xc420910048 0xc420910110 0xc420910150] [0xc420910048 0xc420910110 0xc420910150] [0xc4209100f0 0xc420910138] [0x8fd520 0x8fd520] 0xc4228ca060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 20 04:31:12.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-q94mx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 04:31:12.541: INFO: rc: 1
Dec 20 04:31:12.542: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Dec 20 04:31:12.542: INFO: Scaling statefulset ss to 0
Dec 20 04:31:12.551: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 20 04:31:12.554: INFO: Deleting all statefulset in ns e2e-tests-statefulset-q94mx
Dec 20 04:31:12.557: INFO: Scaling statefulset ss to 0
Dec 20 04:31:12.565: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 04:31:12.568: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:31:12.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-q94mx" for this suite.
Dec 20 04:31:18.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:31:18.944: INFO: namespace: e2e-tests-statefulset-q94mx, resource: bindings, ignored listing per whitelist
Dec 20 04:31:19.004: INFO: namespace e2e-tests-statefulset-q94mx deletion completed in 6.109000728s

• [SLOW TEST:373.925 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:31:19.004: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 20 04:31:23.702: INFO: Successfully updated pod "annotationupdate18a0e7fe-0410-11e9-acdd-0a580ac80107"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:31:25.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5vtrj" for this suite.
Dec 20 04:31:48.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:31:48.345: INFO: namespace: e2e-tests-downward-api-5vtrj, resource: bindings, ignored listing per whitelist
Dec 20 04:31:48.348: INFO: namespace e2e-tests-downward-api-5vtrj deletion completed in 22.314638523s

• [SLOW TEST:29.344 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:31:48.348: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-5ztbj
Dec 20 04:31:52.653: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-5ztbj
STEP: checking the pod's current state and verifying that restartCount is present
Dec 20 04:31:52.655: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:35:53.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5ztbj" for this suite.
Dec 20 04:35:59.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:35:59.511: INFO: namespace: e2e-tests-container-probe-5ztbj, resource: bindings, ignored listing per whitelist
Dec 20 04:35:59.546: INFO: namespace e2e-tests-container-probe-5ztbj deletion completed in 6.108696236s

• [SLOW TEST:251.198 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:35:59.546: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 20 04:35:59.620: INFO: Waiting up to 5m0s for pod "pod-bfd864a8-0410-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-dfb2t" to be "success or failure"
Dec 20 04:35:59.626: INFO: Pod "pod-bfd864a8-0410-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 6.187402ms
Dec 20 04:36:01.630: INFO: Pod "pod-bfd864a8-0410-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010520242s
Dec 20 04:36:03.634: INFO: Pod "pod-bfd864a8-0410-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01435217s
STEP: Saw pod success
Dec 20 04:36:03.634: INFO: Pod "pod-bfd864a8-0410-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:36:03.637: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-bfd864a8-0410-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 04:36:03.658: INFO: Waiting for pod pod-bfd864a8-0410-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:36:03.661: INFO: Pod pod-bfd864a8-0410-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:36:03.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dfb2t" for this suite.
Dec 20 04:36:09.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:36:09.751: INFO: namespace: e2e-tests-emptydir-dfb2t, resource: bindings, ignored listing per whitelist
Dec 20 04:36:09.778: INFO: namespace e2e-tests-emptydir-dfb2t deletion completed in 6.113585951s

• [SLOW TEST:10.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:36:09.778: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 20 04:36:09.833: INFO: namespace e2e-tests-kubectl-hqkcb
Dec 20 04:36:09.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-hqkcb'
Dec 20 04:36:10.247: INFO: stderr: ""
Dec 20 04:36:10.247: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 20 04:36:11.251: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 04:36:11.251: INFO: Found 0 / 1
Dec 20 04:36:12.251: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 04:36:12.251: INFO: Found 0 / 1
Dec 20 04:36:13.252: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 04:36:13.252: INFO: Found 1 / 1
Dec 20 04:36:13.252: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 20 04:36:13.255: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 04:36:13.255: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 20 04:36:13.255: INFO: wait on redis-master startup in e2e-tests-kubectl-hqkcb 
Dec 20 04:36:13.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 logs redis-master-jcthd redis-master --namespace=e2e-tests-kubectl-hqkcb'
Dec 20 04:36:13.373: INFO: stderr: ""
Dec 20 04:36:13.373: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Dec 04:36:12.116 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Dec 04:36:12.116 # Server started, Redis version 3.2.12\n1:M 20 Dec 04:36:12.116 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Dec 04:36:12.116 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec 20 04:36:13.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-hqkcb'
Dec 20 04:36:13.505: INFO: stderr: ""
Dec 20 04:36:13.505: INFO: stdout: "service/rm2 exposed\n"
Dec 20 04:36:13.520: INFO: Service rm2 in namespace e2e-tests-kubectl-hqkcb found.
STEP: exposing service
Dec 20 04:36:15.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-hqkcb'
Dec 20 04:36:15.703: INFO: stderr: ""
Dec 20 04:36:15.703: INFO: stdout: "service/rm3 exposed\n"
Dec 20 04:36:15.710: INFO: Service rm3 in namespace e2e-tests-kubectl-hqkcb found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:36:17.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hqkcb" for this suite.
Dec 20 04:36:39.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:36:40.314: INFO: namespace: e2e-tests-kubectl-hqkcb, resource: bindings, ignored listing per whitelist
Dec 20 04:36:40.318: INFO: namespace e2e-tests-kubectl-hqkcb deletion completed in 22.36880183s

• [SLOW TEST:30.540 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:36:40.318: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-msld6 in namespace e2e-tests-proxy-9k7qs
I1220 04:36:40.493271      18 runners.go:180] Created replication controller with name: proxy-service-msld6, namespace: e2e-tests-proxy-9k7qs, replica count: 1
I1220 04:36:41.543906      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 04:36:42.544142      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 04:36:43.544380      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 04:36:44.544612      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 04:36:45.544821      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1220 04:36:46.545074      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1220 04:36:47.545328      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1220 04:36:48.545519      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1220 04:36:49.545680      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1220 04:36:50.545883      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1220 04:36:51.546105      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1220 04:36:52.546449      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1220 04:36:53.546671      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1220 04:36:54.546847      18 runners.go:180] proxy-service-msld6 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 20 04:36:54.550: INFO: setup took 14.072124081s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 20 04:36:54.556: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 6.039393ms)
Dec 20 04:36:54.556: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 6.44137ms)
Dec 20 04:36:54.557: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 6.526172ms)
Dec 20 04:36:54.557: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 7.024576ms)
Dec 20 04:36:54.563: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 13.042583ms)
Dec 20 04:36:54.563: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 13.096237ms)
Dec 20 04:36:54.563: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 13.080057ms)
Dec 20 04:36:54.563: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 13.151191ms)
Dec 20 04:36:54.563: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 13.536505ms)
Dec 20 04:36:54.564: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 13.45104ms)
Dec 20 04:36:54.564: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 14.254195ms)
Dec 20 04:36:54.565: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 14.473228ms)
Dec 20 04:36:54.565: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 14.551465ms)
Dec 20 04:36:54.569: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 18.676956ms)
Dec 20 04:36:54.570: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 19.696215ms)
Dec 20 04:36:54.573: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 22.598845ms)
Dec 20 04:36:54.576: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.396614ms)
Dec 20 04:36:54.577: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 3.675287ms)
Dec 20 04:36:54.577: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 4.106831ms)
Dec 20 04:36:54.577: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.219833ms)
Dec 20 04:36:54.577: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 4.097656ms)
Dec 20 04:36:54.577: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.499843ms)
Dec 20 04:36:54.578: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.836401ms)
Dec 20 04:36:54.578: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 4.949629ms)
Dec 20 04:36:54.579: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 5.841128ms)
Dec 20 04:36:54.579: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 5.519061ms)
Dec 20 04:36:54.579: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 6.029997ms)
Dec 20 04:36:54.579: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 5.638499ms)
Dec 20 04:36:54.579: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 6.396446ms)
Dec 20 04:36:54.580: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 6.629819ms)
Dec 20 04:36:54.581: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 7.632971ms)
Dec 20 04:36:54.581: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 7.330175ms)
Dec 20 04:36:54.584: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 2.976969ms)
Dec 20 04:36:54.584: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.405174ms)
Dec 20 04:36:54.584: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 3.283104ms)
Dec 20 04:36:54.584: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 3.678511ms)
Dec 20 04:36:54.586: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 4.733176ms)
Dec 20 04:36:54.586: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.760137ms)
Dec 20 04:36:54.586: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 5.133393ms)
Dec 20 04:36:54.586: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 4.940297ms)
Dec 20 04:36:54.586: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 5.008092ms)
Dec 20 04:36:54.586: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 5.6669ms)
Dec 20 04:36:54.586: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 5.361715ms)
Dec 20 04:36:54.587: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 5.547174ms)
Dec 20 04:36:54.587: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 6.229629ms)
Dec 20 04:36:54.587: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 6.198996ms)
Dec 20 04:36:54.588: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 6.599032ms)
Dec 20 04:36:54.588: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 7.062448ms)
Dec 20 04:36:54.590: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 2.644559ms)
Dec 20 04:36:54.591: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 2.822278ms)
Dec 20 04:36:54.592: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 3.446545ms)
Dec 20 04:36:54.593: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 4.634992ms)
Dec 20 04:36:54.593: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 5.251368ms)
Dec 20 04:36:54.593: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 4.880592ms)
Dec 20 04:36:54.594: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 4.965926ms)
Dec 20 04:36:54.594: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 5.481425ms)
Dec 20 04:36:54.594: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 5.26273ms)
Dec 20 04:36:54.594: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 5.254646ms)
Dec 20 04:36:54.594: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 5.588562ms)
Dec 20 04:36:54.594: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 5.938988ms)
Dec 20 04:36:54.594: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 5.655355ms)
Dec 20 04:36:54.595: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 6.016964ms)
Dec 20 04:36:54.595: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 6.318776ms)
Dec 20 04:36:54.595: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 6.847697ms)
Dec 20 04:36:54.599: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 2.913627ms)
Dec 20 04:36:54.599: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 3.150762ms)
Dec 20 04:36:54.600: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.135322ms)
Dec 20 04:36:54.600: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.149594ms)
Dec 20 04:36:54.600: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 4.156388ms)
Dec 20 04:36:54.600: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 4.67035ms)
Dec 20 04:36:54.601: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 4.838312ms)
Dec 20 04:36:54.601: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 5.181131ms)
Dec 20 04:36:54.601: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 5.335517ms)
Dec 20 04:36:54.601: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 5.832633ms)
Dec 20 04:36:54.602: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 6.310861ms)
Dec 20 04:36:54.602: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 6.210249ms)
Dec 20 04:36:54.602: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 6.198379ms)
Dec 20 04:36:54.602: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 6.513025ms)
Dec 20 04:36:54.602: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 6.47038ms)
Dec 20 04:36:54.603: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 6.812486ms)
Dec 20 04:36:54.606: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 2.763063ms)
Dec 20 04:36:54.607: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 3.816227ms)
Dec 20 04:36:54.607: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 4.049987ms)
Dec 20 04:36:54.607: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.71509ms)
Dec 20 04:36:54.607: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.418372ms)
Dec 20 04:36:54.608: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.353009ms)
Dec 20 04:36:54.608: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 5.323841ms)
Dec 20 04:36:54.608: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 5.168743ms)
Dec 20 04:36:54.608: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 4.830263ms)
Dec 20 04:36:54.608: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 4.992047ms)
Dec 20 04:36:54.608: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 4.941671ms)
Dec 20 04:36:54.608: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 4.980835ms)
Dec 20 04:36:54.609: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 5.550319ms)
Dec 20 04:36:54.609: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 5.676781ms)
Dec 20 04:36:54.609: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 5.650153ms)
Dec 20 04:36:54.609: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 5.686517ms)
Dec 20 04:36:54.612: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 3.411011ms)
Dec 20 04:36:54.613: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 3.539879ms)
Dec 20 04:36:54.613: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 3.469447ms)
Dec 20 04:36:54.613: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 3.681582ms)
Dec 20 04:36:54.614: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.895291ms)
Dec 20 04:36:54.614: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 4.297996ms)
Dec 20 04:36:54.614: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.11683ms)
Dec 20 04:36:54.614: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 4.784683ms)
Dec 20 04:36:54.614: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.595032ms)
Dec 20 04:36:54.615: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 5.207762ms)
Dec 20 04:36:54.616: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 6.918554ms)
Dec 20 04:36:54.617: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 7.282026ms)
Dec 20 04:36:54.617: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 7.430865ms)
Dec 20 04:36:54.617: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 7.052962ms)
Dec 20 04:36:54.617: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 7.601403ms)
Dec 20 04:36:54.617: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 7.89863ms)
Dec 20 04:36:54.619: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 2.278706ms)
Dec 20 04:36:54.621: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 3.647055ms)
Dec 20 04:36:54.621: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 3.849548ms)
Dec 20 04:36:54.621: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 4.016844ms)
Dec 20 04:36:54.622: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 4.063828ms)
Dec 20 04:36:54.623: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.994824ms)
Dec 20 04:36:54.623: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 5.068798ms)
Dec 20 04:36:54.623: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 5.367047ms)
Dec 20 04:36:54.623: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 5.645738ms)
Dec 20 04:36:54.623: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 5.778578ms)
Dec 20 04:36:54.624: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 5.76101ms)
Dec 20 04:36:54.624: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 5.96886ms)
Dec 20 04:36:54.624: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 6.507449ms)
Dec 20 04:36:54.624: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 6.188009ms)
Dec 20 04:36:54.624: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 6.557949ms)
Dec 20 04:36:54.625: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 7.127697ms)
Dec 20 04:36:54.628: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 3.035316ms)
Dec 20 04:36:54.628: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 3.043582ms)
Dec 20 04:36:54.629: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 3.452412ms)
Dec 20 04:36:54.629: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 3.371939ms)
Dec 20 04:36:54.630: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 4.264683ms)
Dec 20 04:36:54.630: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.892954ms)
Dec 20 04:36:54.630: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.978421ms)
Dec 20 04:36:54.630: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 4.02569ms)
Dec 20 04:36:54.630: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.071944ms)
Dec 20 04:36:54.630: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 5.473488ms)
Dec 20 04:36:54.630: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 5.349144ms)
Dec 20 04:36:54.631: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 5.643664ms)
Dec 20 04:36:54.631: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 4.913351ms)
Dec 20 04:36:54.631: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 5.197967ms)
Dec 20 04:36:54.631: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 5.353373ms)
Dec 20 04:36:54.631: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 5.448584ms)
Dec 20 04:36:54.634: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 2.519683ms)
Dec 20 04:36:54.635: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 3.349218ms)
Dec 20 04:36:54.635: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 3.686064ms)
Dec 20 04:36:54.635: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 3.168531ms)
Dec 20 04:36:54.636: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.887777ms)
Dec 20 04:36:54.636: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.032302ms)
Dec 20 04:36:54.636: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.40881ms)
Dec 20 04:36:54.636: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 4.47916ms)
Dec 20 04:36:54.636: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 4.344073ms)
Dec 20 04:36:54.637: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 4.599011ms)
Dec 20 04:36:54.637: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 4.995693ms)
Dec 20 04:36:54.637: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 5.387669ms)
Dec 20 04:36:54.638: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 6.055984ms)
Dec 20 04:36:54.638: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 5.990478ms)
Dec 20 04:36:54.638: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 6.183056ms)
Dec 20 04:36:54.638: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 6.350775ms)
Dec 20 04:36:54.642: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 3.92032ms)
Dec 20 04:36:54.642: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 3.527325ms)
Dec 20 04:36:54.643: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.302332ms)
Dec 20 04:36:54.643: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 3.469321ms)
Dec 20 04:36:54.643: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 3.564048ms)
Dec 20 04:36:54.643: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 4.0375ms)
Dec 20 04:36:54.643: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 4.27658ms)
Dec 20 04:36:54.644: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 5.155229ms)
Dec 20 04:36:54.644: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 4.240676ms)
Dec 20 04:36:54.644: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 4.392571ms)
Dec 20 04:36:54.644: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.678044ms)
Dec 20 04:36:54.645: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 5.778101ms)
Dec 20 04:36:54.645: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 6.478933ms)
Dec 20 04:36:54.645: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 5.506677ms)
Dec 20 04:36:54.645: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 6.179288ms)
Dec 20 04:36:54.646: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 6.321434ms)
Dec 20 04:36:54.650: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 4.804483ms)
Dec 20 04:36:54.650: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 4.152077ms)
Dec 20 04:36:54.651: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.970368ms)
Dec 20 04:36:54.651: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 4.584436ms)
Dec 20 04:36:54.651: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 3.752092ms)
Dec 20 04:36:54.651: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.475978ms)
Dec 20 04:36:54.651: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.733615ms)
Dec 20 04:36:54.652: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 4.633607ms)
Dec 20 04:36:54.652: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 6.695029ms)
Dec 20 04:36:54.653: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 6.079844ms)
Dec 20 04:36:54.653: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 5.851072ms)
Dec 20 04:36:54.653: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 6.405539ms)
Dec 20 04:36:54.653: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 6.14684ms)
Dec 20 04:36:54.653: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 7.398886ms)
Dec 20 04:36:54.654: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 6.421911ms)
Dec 20 04:36:54.654: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 6.867446ms)
Dec 20 04:36:54.657: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.214713ms)
Dec 20 04:36:54.657: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 3.170922ms)
Dec 20 04:36:54.658: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 3.742803ms)
Dec 20 04:36:54.659: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 3.847649ms)
Dec 20 04:36:54.660: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 4.816473ms)
Dec 20 04:36:54.660: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 5.300202ms)
Dec 20 04:36:54.660: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 5.918658ms)
Dec 20 04:36:54.660: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 5.293037ms)
Dec 20 04:36:54.660: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 5.568021ms)
Dec 20 04:36:54.661: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 6.115015ms)
Dec 20 04:36:54.661: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 6.596697ms)
Dec 20 04:36:54.661: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 5.683718ms)
Dec 20 04:36:54.661: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 5.785916ms)
Dec 20 04:36:54.661: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 6.262728ms)
Dec 20 04:36:54.661: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 5.883097ms)
Dec 20 04:36:54.661: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 5.942898ms)
Dec 20 04:36:54.664: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 2.870987ms)
Dec 20 04:36:54.666: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 4.005942ms)
Dec 20 04:36:54.666: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.488007ms)
Dec 20 04:36:54.666: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 4.511205ms)
Dec 20 04:36:54.666: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 4.909331ms)
Dec 20 04:36:54.666: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 3.861565ms)
Dec 20 04:36:54.666: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 4.781667ms)
Dec 20 04:36:54.666: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 5.221875ms)
Dec 20 04:36:54.667: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 4.263007ms)
Dec 20 04:36:54.667: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.480531ms)
Dec 20 04:36:54.667: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 5.34412ms)
Dec 20 04:36:54.667: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 5.308702ms)
Dec 20 04:36:54.667: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 5.293218ms)
Dec 20 04:36:54.667: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 5.226714ms)
Dec 20 04:36:54.668: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 5.558564ms)
Dec 20 04:36:54.668: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 5.857569ms)
Dec 20 04:36:54.673: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 4.039175ms)
Dec 20 04:36:54.673: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.248181ms)
Dec 20 04:36:54.674: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 4.276572ms)
Dec 20 04:36:54.674: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 5.270259ms)
Dec 20 04:36:54.674: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.338643ms)
Dec 20 04:36:54.674: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 5.046118ms)
Dec 20 04:36:54.674: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 4.134948ms)
Dec 20 04:36:54.674: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 4.099282ms)
Dec 20 04:36:54.674: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.991641ms)
Dec 20 04:36:54.674: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 5.237482ms)
Dec 20 04:36:54.675: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 4.718157ms)
Dec 20 04:36:54.675: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 5.345056ms)
Dec 20 04:36:54.675: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 6.598713ms)
Dec 20 04:36:54.675: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 5.556189ms)
Dec 20 04:36:54.675: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 5.579984ms)
Dec 20 04:36:54.675: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 6.332354ms)
Dec 20 04:36:54.679: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 3.021505ms)
Dec 20 04:36:54.679: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.682178ms)
Dec 20 04:36:54.679: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 3.808534ms)
Dec 20 04:36:54.679: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 3.361868ms)
Dec 20 04:36:54.680: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.247235ms)
Dec 20 04:36:54.680: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 3.366112ms)
Dec 20 04:36:54.680: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 3.543592ms)
Dec 20 04:36:54.680: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 4.247213ms)
Dec 20 04:36:54.680: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 4.901895ms)
Dec 20 04:36:54.681: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.34973ms)
Dec 20 04:36:54.681: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 4.31013ms)
Dec 20 04:36:54.682: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 5.509535ms)
Dec 20 04:36:54.682: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 5.511693ms)
Dec 20 04:36:54.682: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 5.892432ms)
Dec 20 04:36:54.683: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 6.711434ms)
Dec 20 04:36:54.683: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 6.696873ms)
Dec 20 04:36:54.687: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.420893ms)
Dec 20 04:36:54.688: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.905727ms)
Dec 20 04:36:54.688: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 4.907622ms)
Dec 20 04:36:54.688: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.8958ms)
Dec 20 04:36:54.688: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 5.216439ms)
Dec 20 04:36:54.688: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 5.385873ms)
Dec 20 04:36:54.688: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 5.408996ms)
Dec 20 04:36:54.688: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 5.216115ms)
Dec 20 04:36:54.688: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 5.642961ms)
Dec 20 04:36:54.689: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 5.761062ms)
Dec 20 04:36:54.689: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 5.840762ms)
Dec 20 04:36:54.689: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 5.953941ms)
Dec 20 04:36:54.690: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 6.846414ms)
Dec 20 04:36:54.690: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 7.258429ms)
Dec 20 04:36:54.691: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 7.579754ms)
Dec 20 04:36:54.691: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 7.938571ms)
Dec 20 04:36:54.693: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 2.529777ms)
Dec 20 04:36:54.694: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 3.294495ms)
Dec 20 04:36:54.695: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 3.73073ms)
Dec 20 04:36:54.696: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 4.916637ms)
Dec 20 04:36:54.696: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.961851ms)
Dec 20 04:36:54.696: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 5.65976ms)
Dec 20 04:36:54.697: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 5.945058ms)
Dec 20 04:36:54.697: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 6.126926ms)
Dec 20 04:36:54.698: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 7.215078ms)
Dec 20 04:36:54.698: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 7.443753ms)
Dec 20 04:36:54.698: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 7.402496ms)
Dec 20 04:36:54.698: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 7.419504ms)
Dec 20 04:36:54.699: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 7.541686ms)
Dec 20 04:36:54.699: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 7.942016ms)
Dec 20 04:36:54.699: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 7.949869ms)
Dec 20 04:36:54.699: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 8.47839ms)
Dec 20 04:36:54.703: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 3.291228ms)
Dec 20 04:36:54.704: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 4.244811ms)
Dec 20 04:36:54.704: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 4.470954ms)
Dec 20 04:36:54.704: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.047044ms)
Dec 20 04:36:54.704: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 4.204637ms)
Dec 20 04:36:54.704: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.355934ms)
Dec 20 04:36:54.705: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 4.653379ms)
Dec 20 04:36:54.705: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 4.735627ms)
Dec 20 04:36:54.705: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 4.587185ms)
Dec 20 04:36:54.705: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 4.908494ms)
Dec 20 04:36:54.706: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 5.932786ms)
Dec 20 04:36:54.706: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 6.186464ms)
Dec 20 04:36:54.706: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 5.99345ms)
Dec 20 04:36:54.707: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 6.824296ms)
Dec 20 04:36:54.708: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 7.804007ms)
Dec 20 04:36:54.708: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 7.578083ms)
Dec 20 04:36:54.711: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:160/proxy/: foo (200; 2.994132ms)
Dec 20 04:36:54.711: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:162/proxy/: bar (200; 3.058917ms)
Dec 20 04:36:54.714: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss/proxy/rewriteme"... (200; 4.283944ms)
Dec 20 04:36:54.714: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:1080/proxy/... (200; 5.739404ms)
Dec 20 04:36:54.714: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:460/proxy/: tls baz (200; 5.654394ms)
Dec 20 04:36:54.714: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:443/proxy/... (200; 5.740783ms)
Dec 20 04:36:54.715: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/proxy-service-msld6-c8dss:1080/proxy/rewri... (200; 5.84244ms)
Dec 20 04:36:54.715: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:160/proxy/: foo (200; 5.767397ms)
Dec 20 04:36:54.716: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname2/proxy/: bar (200; 7.251311ms)
Dec 20 04:36:54.716: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/http:proxy-service-msld6-c8dss:162/proxy/: bar (200; 6.433867ms)
Dec 20 04:36:54.716: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/pods/https:proxy-service-msld6-c8dss:462/proxy/: tls qux (200; 6.721594ms)
Dec 20 04:36:54.716: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname2/proxy/: bar (200; 7.780069ms)
Dec 20 04:36:54.716: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/proxy-service-msld6:portname1/proxy/: foo (200; 8.032463ms)
Dec 20 04:36:54.716: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/http:proxy-service-msld6:portname1/proxy/: foo (200; 8.030249ms)
Dec 20 04:36:54.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname1/proxy/: tls baz (200; 7.85169ms)
Dec 20 04:36:54.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9k7qs/services/https:proxy-service-msld6:tlsportname2/proxy/: tls qux (200; 8.135321ms)
STEP: deleting { ReplicationController} proxy-service-msld6 in namespace e2e-tests-proxy-9k7qs, will wait for the garbage collector to delete the pods
Dec 20 04:36:54.778: INFO: Deleting { ReplicationController} proxy-service-msld6 took: 7.825863ms
Dec 20 04:36:54.878: INFO: Terminating { ReplicationController} proxy-service-msld6 pods took: 100.216955ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:37:07.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9k7qs" for this suite.
Dec 20 04:37:13.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:37:13.869: INFO: namespace: e2e-tests-proxy-9k7qs, resource: bindings, ignored listing per whitelist
Dec 20 04:37:13.883: INFO: namespace e2e-tests-proxy-9k7qs deletion completed in 6.101173337s

• [SLOW TEST:33.564 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:37:13.883: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 20 04:37:13.944: INFO: Waiting up to 5m0s for pod "pod-ec259ce3-0410-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-2p9bb" to be "success or failure"
Dec 20 04:37:13.948: INFO: Pod "pod-ec259ce3-0410-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.211148ms
Dec 20 04:37:15.953: INFO: Pod "pod-ec259ce3-0410-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008705316s
Dec 20 04:37:17.956: INFO: Pod "pod-ec259ce3-0410-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012376368s
Dec 20 04:37:20.007: INFO: Pod "pod-ec259ce3-0410-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.062979218s
STEP: Saw pod success
Dec 20 04:37:20.007: INFO: Pod "pod-ec259ce3-0410-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:37:20.057: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-ec259ce3-0410-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 04:37:20.116: INFO: Waiting for pod pod-ec259ce3-0410-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:37:20.119: INFO: Pod pod-ec259ce3-0410-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:37:20.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2p9bb" for this suite.
Dec 20 04:37:26.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:37:26.581: INFO: namespace: e2e-tests-emptydir-2p9bb, resource: bindings, ignored listing per whitelist
Dec 20 04:37:26.586: INFO: namespace e2e-tests-emptydir-2p9bb deletion completed in 6.107287989s

• [SLOW TEST:12.703 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:37:26.586: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-n6cmx
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-n6cmx to expose endpoints map[]
Dec 20 04:37:26.653: INFO: Get endpoints failed (4.654538ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 20 04:37:27.657: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-n6cmx exposes endpoints map[] (1.008398878s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-n6cmx
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-n6cmx to expose endpoints map[pod1:[100]]
Dec 20 04:37:29.687: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-n6cmx exposes endpoints map[pod1:[100]] (2.021717681s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-n6cmx
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-n6cmx to expose endpoints map[pod1:[100] pod2:[101]]
Dec 20 04:37:32.742: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-n6cmx exposes endpoints map[pod1:[100] pod2:[101]] (3.051010449s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-n6cmx
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-n6cmx to expose endpoints map[pod2:[101]]
Dec 20 04:37:33.762: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-n6cmx exposes endpoints map[pod2:[101]] (1.011911635s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-n6cmx
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-n6cmx to expose endpoints map[]
Dec 20 04:37:34.777: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-n6cmx exposes endpoints map[] (1.008122677s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:37:34.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-n6cmx" for this suite.
Dec 20 04:37:41.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:37:41.086: INFO: namespace: e2e-tests-services-n6cmx, resource: bindings, ignored listing per whitelist
Dec 20 04:37:41.116: INFO: namespace e2e-tests-services-n6cmx deletion completed in 6.112854021s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:14.530 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:37:41.116: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 20 04:37:41.181: INFO: Waiting up to 5m0s for pod "downward-api-fc617f63-0410-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-djz7j" to be "success or failure"
Dec 20 04:37:41.185: INFO: Pod "downward-api-fc617f63-0410-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.197551ms
Dec 20 04:37:43.190: INFO: Pod "downward-api-fc617f63-0410-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008615687s
Dec 20 04:37:45.239: INFO: Pod "downward-api-fc617f63-0410-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058516404s
STEP: Saw pod success
Dec 20 04:37:45.240: INFO: Pod "downward-api-fc617f63-0410-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:37:45.284: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downward-api-fc617f63-0410-11e9-acdd-0a580ac80107 container dapi-container: <nil>
STEP: delete the pod
Dec 20 04:37:45.351: INFO: Waiting for pod downward-api-fc617f63-0410-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:37:45.353: INFO: Pod downward-api-fc617f63-0410-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:37:45.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-djz7j" for this suite.
Dec 20 04:37:51.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:37:51.683: INFO: namespace: e2e-tests-downward-api-djz7j, resource: bindings, ignored listing per whitelist
Dec 20 04:37:51.734: INFO: namespace e2e-tests-downward-api-djz7j deletion completed in 6.106921529s

• [SLOW TEST:10.618 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:37:51.734: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-svjxz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 20 04:37:51.787: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 20 04:38:11.910: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.2.43:8080/dial?request=hostName&protocol=http&host=10.200.3.39&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-svjxz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:38:11.910: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:38:12.028: INFO: Waiting for endpoints: map[]
Dec 20 04:38:12.031: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.2.43:8080/dial?request=hostName&protocol=http&host=10.200.1.42&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-svjxz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:38:12.031: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:38:12.146: INFO: Waiting for endpoints: map[]
Dec 20 04:38:12.149: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.200.2.43:8080/dial?request=hostName&protocol=http&host=10.200.2.42&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-svjxz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:38:12.149: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:38:12.269: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:38:12.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-svjxz" for this suite.
Dec 20 04:38:34.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:38:34.736: INFO: namespace: e2e-tests-pod-network-test-svjxz, resource: bindings, ignored listing per whitelist
Dec 20 04:38:34.812: INFO: namespace e2e-tests-pod-network-test-svjxz deletion completed in 22.325748247s

• [SLOW TEST:43.077 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:38:34.812: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-96nz
STEP: Creating a pod to test atomic-volume-subpath
Dec 20 04:38:35.101: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-96nz" in namespace "e2e-tests-subpath-4jkz2" to be "success or failure"
Dec 20 04:38:35.113: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Pending", Reason="", readiness=false. Elapsed: 10.682675ms
Dec 20 04:38:37.116: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014073741s
Dec 20 04:38:39.120: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017905661s
Dec 20 04:38:41.177: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Running", Reason="", readiness=false. Elapsed: 6.074728021s
Dec 20 04:38:43.226: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Running", Reason="", readiness=false. Elapsed: 8.123886076s
Dec 20 04:38:45.275: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Running", Reason="", readiness=false. Elapsed: 10.1729183s
Dec 20 04:38:47.324: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Running", Reason="", readiness=false. Elapsed: 12.222368408s
Dec 20 04:38:49.381: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Running", Reason="", readiness=false. Elapsed: 14.278653058s
Dec 20 04:38:51.429: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Running", Reason="", readiness=false. Elapsed: 16.327238648s
Dec 20 04:38:53.482: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Running", Reason="", readiness=false. Elapsed: 18.37995958s
Dec 20 04:38:55.531: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Running", Reason="", readiness=false. Elapsed: 20.429395648s
Dec 20 04:38:57.581: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Running", Reason="", readiness=false. Elapsed: 22.479075906s
Dec 20 04:38:59.631: INFO: Pod "pod-subpath-test-secret-96nz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.528976156s
STEP: Saw pod success
Dec 20 04:38:59.631: INFO: Pod "pod-subpath-test-secret-96nz" satisfied condition "success or failure"
Dec 20 04:38:59.680: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-subpath-test-secret-96nz container test-container-subpath-secret-96nz: <nil>
STEP: delete the pod
Dec 20 04:38:59.759: INFO: Waiting for pod pod-subpath-test-secret-96nz to disappear
Dec 20 04:38:59.763: INFO: Pod pod-subpath-test-secret-96nz no longer exists
STEP: Deleting pod pod-subpath-test-secret-96nz
Dec 20 04:38:59.763: INFO: Deleting pod "pod-subpath-test-secret-96nz" in namespace "e2e-tests-subpath-4jkz2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:38:59.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4jkz2" for this suite.
Dec 20 04:39:06.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:39:06.152: INFO: namespace: e2e-tests-subpath-4jkz2, resource: bindings, ignored listing per whitelist
Dec 20 04:39:06.157: INFO: namespace e2e-tests-subpath-4jkz2 deletion completed in 6.12960148s

• [SLOW TEST:31.345 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:39:06.157: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-2f1326c9-0411-11e9-acdd-0a580ac80107
STEP: Creating secret with name s-test-opt-upd-2f132713-0411-11e9-acdd-0a580ac80107
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2f1326c9-0411-11e9-acdd-0a580ac80107
STEP: Updating secret s-test-opt-upd-2f132713-0411-11e9-acdd-0a580ac80107
STEP: Creating secret with name s-test-opt-create-2f13272d-0411-11e9-acdd-0a580ac80107
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:40:24.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rvkbf" for this suite.
Dec 20 04:40:46.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:40:47.211: INFO: namespace: e2e-tests-projected-rvkbf, resource: bindings, ignored listing per whitelist
Dec 20 04:40:47.241: INFO: namespace e2e-tests-projected-rvkbf deletion completed in 22.298980958s

• [SLOW TEST:101.085 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:40:47.242: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-6b74f6c4-0411-11e9-acdd-0a580ac80107
STEP: Creating secret with name s-test-opt-upd-6b74f70e-0411-11e9-acdd-0a580ac80107
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6b74f6c4-0411-11e9-acdd-0a580ac80107
STEP: Updating secret s-test-opt-upd-6b74f70e-0411-11e9-acdd-0a580ac80107
STEP: Creating secret with name s-test-opt-create-6b74f723-0411-11e9-acdd-0a580ac80107
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:42:11.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t24q2" for this suite.
Dec 20 04:42:33.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:42:33.957: INFO: namespace: e2e-tests-secrets-t24q2, resource: bindings, ignored listing per whitelist
Dec 20 04:42:34.038: INFO: namespace e2e-tests-secrets-t24q2 deletion completed in 22.31737669s

• [SLOW TEST:106.797 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:42:34.039: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec 20 04:42:34.349: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-d6fhd" to be "success or failure"
Dec 20 04:42:34.351: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.364456ms
Dec 20 04:42:36.355: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006326676s
Dec 20 04:42:38.359: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009692803s
STEP: Saw pod success
Dec 20 04:42:38.359: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 20 04:42:38.361: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 20 04:42:38.378: INFO: Waiting for pod pod-host-path-test to disappear
Dec 20 04:42:38.380: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:42:38.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-d6fhd" for this suite.
Dec 20 04:42:44.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:42:44.410: INFO: namespace: e2e-tests-hostpath-d6fhd, resource: bindings, ignored listing per whitelist
Dec 20 04:42:44.497: INFO: namespace e2e-tests-hostpath-d6fhd deletion completed in 6.112968979s

• [SLOW TEST:10.458 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:42:44.497: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:42:44.561: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b1353041-0411-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-w5prk" to be "success or failure"
Dec 20 04:42:44.564: INFO: Pod "downwardapi-volume-b1353041-0411-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.931129ms
Dec 20 04:42:46.567: INFO: Pod "downwardapi-volume-b1353041-0411-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005513433s
Dec 20 04:42:48.617: INFO: Pod "downwardapi-volume-b1353041-0411-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056379473s
STEP: Saw pod success
Dec 20 04:42:48.618: INFO: Pod "downwardapi-volume-b1353041-0411-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:42:48.663: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod downwardapi-volume-b1353041-0411-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:42:48.743: INFO: Waiting for pod downwardapi-volume-b1353041-0411-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:42:48.746: INFO: Pod downwardapi-volume-b1353041-0411-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:42:48.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w5prk" for this suite.
Dec 20 04:42:55.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:42:55.387: INFO: namespace: e2e-tests-downward-api-w5prk, resource: bindings, ignored listing per whitelist
Dec 20 04:42:55.416: INFO: namespace e2e-tests-downward-api-w5prk deletion completed in 6.329580337s

• [SLOW TEST:10.919 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:42:55.416: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 20 04:42:55.669: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:42:59.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-p5n8k" for this suite.
Dec 20 04:43:05.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:43:05.419: INFO: namespace: e2e-tests-init-container-p5n8k, resource: bindings, ignored listing per whitelist
Dec 20 04:43:05.501: INFO: namespace e2e-tests-init-container-p5n8k deletion completed in 6.105103904s

• [SLOW TEST:10.085 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:43:05.501: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 20 04:43:05.558: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:43:10.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4rtzt" for this suite.
Dec 20 04:43:16.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:43:16.456: INFO: namespace: e2e-tests-init-container-4rtzt, resource: bindings, ignored listing per whitelist
Dec 20 04:43:16.505: INFO: namespace e2e-tests-init-container-4rtzt deletion completed in 6.10386208s

• [SLOW TEST:11.004 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:43:16.506: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 04:43:16.569: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 20 04:43:21.573: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 20 04:43:21.573: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 20 04:43:21.595: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-n9vdl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-n9vdl/deployments/test-cleanup-deployment,UID:c746a0e4-0411-11e9-9da8-506b8da7f7e6,ResourceVersion:10937,Generation:1,CreationTimestamp:2018-12-20 04:43:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec 20 04:43:21.600: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec 20 04:43:21.600: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 20 04:43:21.600: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-n9vdl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-n9vdl/replicasets/test-cleanup-controller,UID:c4494451-0411-11e9-9da8-506b8da7f7e6,ResourceVersion:10938,Generation:1,CreationTimestamp:2018-12-20 04:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c746a0e4-0411-11e9-9da8-506b8da7f7e6 0xc422ae48f7 0xc422ae48f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 20 04:43:21.608: INFO: Pod "test-cleanup-controller-8t87d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-8t87d,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-n9vdl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-n9vdl/pods/test-cleanup-controller-8t87d,UID:c44a81f0-0411-11e9-9da8-506b8da7f7e6,ResourceVersion:10930,Generation:0,CreationTimestamp:2018-12-20 04:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller c4494451-0411-11e9-9da8-506b8da7f7e6 0xc422ae4e57 0xc422ae4e58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-pms67 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pms67,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pms67 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:43:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:43:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:43:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.54,PodIP:10.200.2.48,StartTime:2018-12-20 04:43:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-20 04:43:18 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://83dbac488a7aca23252dd19171830a74d2491be44ad4de6713638c7c82ce766d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:43:21.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-n9vdl" for this suite.
Dec 20 04:43:27.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:43:27.884: INFO: namespace: e2e-tests-deployment-n9vdl, resource: bindings, ignored listing per whitelist
Dec 20 04:43:27.939: INFO: namespace e2e-tests-deployment-n9vdl deletion completed in 6.095255204s

• [SLOW TEST:11.433 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:43:27.939: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-5zxm7
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-5zxm7
STEP: Deleting pre-stop pod
Dec 20 04:43:43.035: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:43:43.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-5zxm7" for this suite.
Dec 20 04:44:21.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:44:21.426: INFO: namespace: e2e-tests-prestop-5zxm7, resource: bindings, ignored listing per whitelist
Dec 20 04:44:21.468: INFO: namespace e2e-tests-prestop-5zxm7 deletion completed in 38.229110493s

• [SLOW TEST:53.529 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:44:21.468: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 20 04:44:21.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-lmk5k'
Dec 20 04:44:21.960: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 20 04:44:21.960: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Dec 20 04:44:21.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-lmk5k'
Dec 20 04:44:22.079: INFO: stderr: ""
Dec 20 04:44:22.079: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:44:22.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lmk5k" for this suite.
Dec 20 04:44:44.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:44:44.355: INFO: namespace: e2e-tests-kubectl-lmk5k, resource: bindings, ignored listing per whitelist
Dec 20 04:44:44.398: INFO: namespace e2e-tests-kubectl-lmk5k deletion completed in 22.313136342s

• [SLOW TEST:22.930 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:44:44.398: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-qbfc
STEP: Creating a pod to test atomic-volume-subpath
Dec 20 04:44:44.762: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qbfc" in namespace "e2e-tests-subpath-6hwhd" to be "success or failure"
Dec 20 04:44:44.768: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.919647ms
Dec 20 04:44:46.772: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010040348s
Dec 20 04:44:48.776: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Running", Reason="", readiness=false. Elapsed: 4.013863851s
Dec 20 04:44:50.827: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Running", Reason="", readiness=false. Elapsed: 6.06451832s
Dec 20 04:44:52.876: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Running", Reason="", readiness=false. Elapsed: 8.113879832s
Dec 20 04:44:54.927: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Running", Reason="", readiness=false. Elapsed: 10.164552167s
Dec 20 04:44:56.974: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Running", Reason="", readiness=false. Elapsed: 12.212190841s
Dec 20 04:44:59.027: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Running", Reason="", readiness=false. Elapsed: 14.264631779s
Dec 20 04:45:01.030: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Running", Reason="", readiness=false. Elapsed: 16.268102089s
Dec 20 04:45:03.034: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Running", Reason="", readiness=false. Elapsed: 18.272294915s
Dec 20 04:45:05.087: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Running", Reason="", readiness=false. Elapsed: 20.324914351s
Dec 20 04:45:07.137: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Running", Reason="", readiness=false. Elapsed: 22.375070397s
Dec 20 04:45:09.184: INFO: Pod "pod-subpath-test-configmap-qbfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.421620693s
STEP: Saw pod success
Dec 20 04:45:09.184: INFO: Pod "pod-subpath-test-configmap-qbfc" satisfied condition "success or failure"
Dec 20 04:45:09.237: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-subpath-test-configmap-qbfc container test-container-subpath-configmap-qbfc: <nil>
STEP: delete the pod
Dec 20 04:45:09.299: INFO: Waiting for pod pod-subpath-test-configmap-qbfc to disappear
Dec 20 04:45:09.303: INFO: Pod pod-subpath-test-configmap-qbfc no longer exists
STEP: Deleting pod pod-subpath-test-configmap-qbfc
Dec 20 04:45:09.303: INFO: Deleting pod "pod-subpath-test-configmap-qbfc" in namespace "e2e-tests-subpath-6hwhd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:45:09.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6hwhd" for this suite.
Dec 20 04:45:15.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:45:15.453: INFO: namespace: e2e-tests-subpath-6hwhd, resource: bindings, ignored listing per whitelist
Dec 20 04:45:15.509: INFO: namespace e2e-tests-subpath-6hwhd deletion completed in 6.106756458s

• [SLOW TEST:31.110 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:45:15.509: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec 20 04:45:15.569: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-617439060 proxy --unix-socket=/tmp/kubectl-proxy-unix875491491/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:45:15.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7kccq" for this suite.
Dec 20 04:45:21.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:45:21.668: INFO: namespace: e2e-tests-kubectl-7kccq, resource: bindings, ignored listing per whitelist
Dec 20 04:45:21.751: INFO: namespace e2e-tests-kubectl-7kccq deletion completed in 6.102440305s

• [SLOW TEST:6.242 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:45:21.751: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 04:45:21.812: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 20 04:45:26.816: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 20 04:45:26.816: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 20 04:45:28.820: INFO: Creating deployment "test-rollover-deployment"
Dec 20 04:45:28.829: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 20 04:45:30.837: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 20 04:45:30.888: INFO: Ensure that both replica sets have 1 created replica
Dec 20 04:45:30.941: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 20 04:45:30.952: INFO: Updating deployment test-rollover-deployment
Dec 20 04:45:30.952: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 20 04:45:32.962: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 20 04:45:33.017: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 20 04:45:33.070: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 04:45:33.071: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877931, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 04:45:35.123: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 04:45:35.123: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877931, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 04:45:37.120: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 04:45:37.121: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877935, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 04:45:39.128: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 04:45:39.128: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877935, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 04:45:41.134: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 04:45:41.134: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877935, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 04:45:43.124: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 04:45:43.124: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877935, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 04:45:45.124: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 04:45:45.125: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877935, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680877928, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 04:45:47.121: INFO: 
Dec 20 04:45:47.121: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 20 04:45:47.131: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-gr2hn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gr2hn/deployments/test-rollover-deployment,UID:131e8d8c-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:11386,Generation:2,CreationTimestamp:2018-12-20 04:45:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-20 04:45:28 +0000 UTC 2018-12-20 04:45:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-20 04:45:45 +0000 UTC 2018-12-20 04:45:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 20 04:45:47.181: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-gr2hn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gr2hn/replicasets/test-rollover-deployment-5b76ff8c4,UID:1463c629-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:11377,Generation:2,CreationTimestamp:2018-12-20 04:45:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 131e8d8c-0412-11e9-9da8-506b8da7f7e6 0xc422066b67 0xc422066b68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 20 04:45:47.181: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 20 04:45:47.181: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-gr2hn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gr2hn/replicasets/test-rollover-controller,UID:0eefc376-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:11385,Generation:2,CreationTimestamp:2018-12-20 04:45:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 131e8d8c-0412-11e9-9da8-506b8da7f7e6 0xc422066a9e 0xc422066a9f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 20 04:45:47.181: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-gr2hn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gr2hn/replicasets/test-rollover-deployment-6975f4fb87,UID:13207f05-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:11342,Generation:2,CreationTimestamp:2018-12-20 04:45:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 131e8d8c-0412-11e9-9da8-506b8da7f7e6 0xc422066c27 0xc422066c28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 20 04:45:47.185: INFO: Pod "test-rollover-deployment-5b76ff8c4-cjktq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-cjktq,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-gr2hn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gr2hn/pods/test-rollover-deployment-5b76ff8c4-cjktq,UID:1467e433-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:11359,Generation:0,CreationTimestamp:2018-12-20 04:45:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 1463c629-0412-11e9-9da8-506b8da7f7e6 0xc422067710 0xc422067711}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nmhx4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmhx4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nmhx4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:45:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:45:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:45:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 04:45:30 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.55,PodIP:10.200.1.48,StartTime:2018-12-20 04:45:31 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-20 04:45:35 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://810ea930b092653bcf8b1c69c5b22d030946735a97d4887b91a96daf6b493c4f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:45:47.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gr2hn" for this suite.
Dec 20 04:45:53.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:45:53.586: INFO: namespace: e2e-tests-deployment-gr2hn, resource: bindings, ignored listing per whitelist
Dec 20 04:45:53.593: INFO: namespace e2e-tests-deployment-gr2hn deletion completed in 6.102895828s

• [SLOW TEST:31.842 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:45:53.593: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-21eaf5f9-0412-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 04:45:53.660: INFO: Waiting up to 5m0s for pod "pod-configmaps-21ebf120-0412-11e9-acdd-0a580ac80107" in namespace "e2e-tests-configmap-hx4wj" to be "success or failure"
Dec 20 04:45:53.663: INFO: Pod "pod-configmaps-21ebf120-0412-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.621523ms
Dec 20 04:45:55.666: INFO: Pod "pod-configmaps-21ebf120-0412-11e9-acdd-0a580ac80107": Phase="Running", Reason="", readiness=true. Elapsed: 2.006030087s
Dec 20 04:45:57.669: INFO: Pod "pod-configmaps-21ebf120-0412-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008999106s
STEP: Saw pod success
Dec 20 04:45:57.669: INFO: Pod "pod-configmaps-21ebf120-0412-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:45:57.724: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-configmaps-21ebf120-0412-11e9-acdd-0a580ac80107 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 04:45:57.791: INFO: Waiting for pod pod-configmaps-21ebf120-0412-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:45:57.794: INFO: Pod pod-configmaps-21ebf120-0412-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:45:57.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hx4wj" for this suite.
Dec 20 04:46:04.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:46:04.238: INFO: namespace: e2e-tests-configmap-hx4wj, resource: bindings, ignored listing per whitelist
Dec 20 04:46:04.308: INFO: namespace e2e-tests-configmap-hx4wj deletion completed in 6.117725281s

• [SLOW TEST:10.715 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:46:04.308: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec 20 04:46:04.376: INFO: Waiting up to 5m0s for pod "var-expansion-284ed702-0412-11e9-acdd-0a580ac80107" in namespace "e2e-tests-var-expansion-6c7n9" to be "success or failure"
Dec 20 04:46:04.382: INFO: Pod "var-expansion-284ed702-0412-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.724502ms
Dec 20 04:46:06.385: INFO: Pod "var-expansion-284ed702-0412-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009416089s
Dec 20 04:46:08.389: INFO: Pod "var-expansion-284ed702-0412-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012957818s
STEP: Saw pod success
Dec 20 04:46:08.389: INFO: Pod "var-expansion-284ed702-0412-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:46:08.391: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod var-expansion-284ed702-0412-11e9-acdd-0a580ac80107 container dapi-container: <nil>
STEP: delete the pod
Dec 20 04:46:08.418: INFO: Waiting for pod var-expansion-284ed702-0412-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:46:08.420: INFO: Pod var-expansion-284ed702-0412-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:46:08.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6c7n9" for this suite.
Dec 20 04:46:14.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:46:14.475: INFO: namespace: e2e-tests-var-expansion-6c7n9, resource: bindings, ignored listing per whitelist
Dec 20 04:46:14.522: INFO: namespace e2e-tests-var-expansion-6c7n9 deletion completed in 6.09894468s

• [SLOW TEST:10.215 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:46:14.523: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 20 04:46:19.104: INFO: Successfully updated pod "pod-update-2e64418d-0412-11e9-acdd-0a580ac80107"
STEP: verifying the updated pod is in kubernetes
Dec 20 04:46:19.109: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:46:19.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-htvv5" for this suite.
Dec 20 04:46:41.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:46:41.545: INFO: namespace: e2e-tests-pods-htvv5, resource: bindings, ignored listing per whitelist
Dec 20 04:46:41.612: INFO: namespace e2e-tests-pods-htvv5 deletion completed in 22.27881505s

• [SLOW TEST:27.090 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:46:41.613: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:46:41.954: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3eb43431-0412-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-5dczc" to be "success or failure"
Dec 20 04:46:41.961: INFO: Pod "downwardapi-volume-3eb43431-0412-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 6.697449ms
Dec 20 04:46:43.964: INFO: Pod "downwardapi-volume-3eb43431-0412-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009658534s
Dec 20 04:46:45.968: INFO: Pod "downwardapi-volume-3eb43431-0412-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013542479s
STEP: Saw pod success
Dec 20 04:46:45.968: INFO: Pod "downwardapi-volume-3eb43431-0412-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:46:45.971: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod downwardapi-volume-3eb43431-0412-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:46:45.995: INFO: Waiting for pod downwardapi-volume-3eb43431-0412-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:46:46.001: INFO: Pod downwardapi-volume-3eb43431-0412-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:46:46.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5dczc" for this suite.
Dec 20 04:46:52.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:46:52.040: INFO: namespace: e2e-tests-projected-5dczc, resource: bindings, ignored listing per whitelist
Dec 20 04:46:52.116: INFO: namespace e2e-tests-projected-5dczc deletion completed in 6.110130569s

• [SLOW TEST:10.503 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:46:52.116: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 04:46:52.177: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 20 04:46:52.188: INFO: Number of nodes with available pods: 0
Dec 20 04:46:52.188: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 20 04:46:52.204: INFO: Number of nodes with available pods: 0
Dec 20 04:46:52.204: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:46:53.207: INFO: Number of nodes with available pods: 0
Dec 20 04:46:53.207: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:46:54.207: INFO: Number of nodes with available pods: 1
Dec 20 04:46:54.207: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 20 04:46:54.223: INFO: Number of nodes with available pods: 1
Dec 20 04:46:54.223: INFO: Number of running nodes: 0, number of available pods: 1
Dec 20 04:46:55.228: INFO: Number of nodes with available pods: 0
Dec 20 04:46:55.228: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 20 04:46:55.245: INFO: Number of nodes with available pods: 0
Dec 20 04:46:55.245: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:46:56.297: INFO: Number of nodes with available pods: 0
Dec 20 04:46:56.297: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:46:57.295: INFO: Number of nodes with available pods: 0
Dec 20 04:46:57.295: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:46:58.298: INFO: Number of nodes with available pods: 0
Dec 20 04:46:58.298: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:46:59.295: INFO: Number of nodes with available pods: 0
Dec 20 04:46:59.295: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:00.295: INFO: Number of nodes with available pods: 0
Dec 20 04:47:00.295: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:01.294: INFO: Number of nodes with available pods: 0
Dec 20 04:47:01.294: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:02.294: INFO: Number of nodes with available pods: 0
Dec 20 04:47:02.294: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:03.295: INFO: Number of nodes with available pods: 0
Dec 20 04:47:03.295: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:04.296: INFO: Number of nodes with available pods: 0
Dec 20 04:47:04.296: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:05.295: INFO: Number of nodes with available pods: 0
Dec 20 04:47:05.295: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:06.295: INFO: Number of nodes with available pods: 0
Dec 20 04:47:06.295: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:07.306: INFO: Number of nodes with available pods: 0
Dec 20 04:47:07.306: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:08.249: INFO: Number of nodes with available pods: 0
Dec 20 04:47:08.249: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:09.301: INFO: Number of nodes with available pods: 0
Dec 20 04:47:09.301: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:10.296: INFO: Number of nodes with available pods: 0
Dec 20 04:47:10.296: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:11.297: INFO: Number of nodes with available pods: 0
Dec 20 04:47:11.297: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:12.297: INFO: Number of nodes with available pods: 0
Dec 20 04:47:12.297: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:13.295: INFO: Number of nodes with available pods: 0
Dec 20 04:47:13.295: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:14.294: INFO: Number of nodes with available pods: 0
Dec 20 04:47:14.294: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:15.294: INFO: Number of nodes with available pods: 0
Dec 20 04:47:15.294: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:16.313: INFO: Number of nodes with available pods: 0
Dec 20 04:47:16.313: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:17.298: INFO: Number of nodes with available pods: 0
Dec 20 04:47:17.298: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:18.291: INFO: Number of nodes with available pods: 0
Dec 20 04:47:18.291: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:19.300: INFO: Number of nodes with available pods: 0
Dec 20 04:47:19.300: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:20.302: INFO: Number of nodes with available pods: 0
Dec 20 04:47:20.302: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:21.292: INFO: Number of nodes with available pods: 0
Dec 20 04:47:21.292: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:22.298: INFO: Number of nodes with available pods: 0
Dec 20 04:47:22.298: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:23.294: INFO: Number of nodes with available pods: 0
Dec 20 04:47:23.294: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:24.296: INFO: Number of nodes with available pods: 0
Dec 20 04:47:24.296: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:25.298: INFO: Number of nodes with available pods: 0
Dec 20 04:47:25.298: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:26.304: INFO: Number of nodes with available pods: 0
Dec 20 04:47:26.304: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:27.296: INFO: Number of nodes with available pods: 0
Dec 20 04:47:27.296: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:28.297: INFO: Number of nodes with available pods: 0
Dec 20 04:47:28.297: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:29.300: INFO: Number of nodes with available pods: 0
Dec 20 04:47:29.300: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:47:30.294: INFO: Number of nodes with available pods: 1
Dec 20 04:47:30.295: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-5wbfc, will wait for the garbage collector to delete the pods
Dec 20 04:47:30.362: INFO: Deleting {extensions DaemonSet} daemon-set took: 7.342325ms
Dec 20 04:47:30.462: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.25749ms
Dec 20 04:48:03.465: INFO: Number of nodes with available pods: 0
Dec 20 04:48:03.465: INFO: Number of running nodes: 0, number of available pods: 0
Dec 20 04:48:03.468: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-5wbfc/daemonsets","resourceVersion":"11788"},"items":null}

Dec 20 04:48:03.471: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-5wbfc/pods","resourceVersion":"11788"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:48:03.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-5wbfc" for this suite.
Dec 20 04:48:09.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:48:09.860: INFO: namespace: e2e-tests-daemonsets-5wbfc, resource: bindings, ignored listing per whitelist
Dec 20 04:48:09.939: INFO: namespace e2e-tests-daemonsets-5wbfc deletion completed in 6.118687718s

• [SLOW TEST:77.823 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:48:09.939: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-ffsc
STEP: Creating a pod to test atomic-volume-subpath
Dec 20 04:48:10.026: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ffsc" in namespace "e2e-tests-subpath-nbfzt" to be "success or failure"
Dec 20 04:48:10.032: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.328506ms
Dec 20 04:48:12.035: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009734654s
Dec 20 04:48:14.099: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Running", Reason="", readiness=false. Elapsed: 4.073771906s
Dec 20 04:48:16.151: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Running", Reason="", readiness=false. Elapsed: 6.125776677s
Dec 20 04:48:18.200: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Running", Reason="", readiness=false. Elapsed: 8.174898919s
Dec 20 04:48:20.251: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Running", Reason="", readiness=false. Elapsed: 10.225784034s
Dec 20 04:48:22.304: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Running", Reason="", readiness=false. Elapsed: 12.278283978s
Dec 20 04:48:24.356: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Running", Reason="", readiness=false. Elapsed: 14.330650146s
Dec 20 04:48:26.402: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Running", Reason="", readiness=false. Elapsed: 16.376587793s
Dec 20 04:48:28.457: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Running", Reason="", readiness=false. Elapsed: 18.43110147s
Dec 20 04:48:30.513: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Running", Reason="", readiness=false. Elapsed: 20.487912499s
Dec 20 04:48:32.561: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Running", Reason="", readiness=false. Elapsed: 22.535194755s
Dec 20 04:48:34.607: INFO: Pod "pod-subpath-test-downwardapi-ffsc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.581454814s
STEP: Saw pod success
Dec 20 04:48:34.607: INFO: Pod "pod-subpath-test-downwardapi-ffsc" satisfied condition "success or failure"
Dec 20 04:48:34.657: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-subpath-test-downwardapi-ffsc container test-container-subpath-downwardapi-ffsc: <nil>
STEP: delete the pod
Dec 20 04:48:34.739: INFO: Waiting for pod pod-subpath-test-downwardapi-ffsc to disappear
Dec 20 04:48:34.742: INFO: Pod pod-subpath-test-downwardapi-ffsc no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ffsc
Dec 20 04:48:34.742: INFO: Deleting pod "pod-subpath-test-downwardapi-ffsc" in namespace "e2e-tests-subpath-nbfzt"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:48:34.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-nbfzt" for this suite.
Dec 20 04:48:40.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:48:41.008: INFO: namespace: e2e-tests-subpath-nbfzt, resource: bindings, ignored listing per whitelist
Dec 20 04:48:41.033: INFO: namespace e2e-tests-subpath-nbfzt deletion completed in 6.107433774s

• [SLOW TEST:31.094 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:48:41.033: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 20 04:48:41.098: INFO: Waiting up to 5m0s for pod "pod-85b8a8cb-0412-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-25pc6" to be "success or failure"
Dec 20 04:48:41.101: INFO: Pod "pod-85b8a8cb-0412-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.7003ms
Dec 20 04:48:43.106: INFO: Pod "pod-85b8a8cb-0412-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007997685s
Dec 20 04:48:45.110: INFO: Pod "pod-85b8a8cb-0412-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011694057s
STEP: Saw pod success
Dec 20 04:48:45.110: INFO: Pod "pod-85b8a8cb-0412-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:48:45.113: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-85b8a8cb-0412-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 04:48:45.132: INFO: Waiting for pod pod-85b8a8cb-0412-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:48:45.135: INFO: Pod pod-85b8a8cb-0412-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:48:45.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-25pc6" for this suite.
Dec 20 04:48:51.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:48:51.489: INFO: namespace: e2e-tests-emptydir-25pc6, resource: bindings, ignored listing per whitelist
Dec 20 04:48:51.504: INFO: namespace e2e-tests-emptydir-25pc6 deletion completed in 6.365474687s

• [SLOW TEST:10.471 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:48:51.504: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec 20 04:48:51.760: INFO: Waiting up to 5m0s for pod "client-containers-8c13bc35-0412-11e9-acdd-0a580ac80107" in namespace "e2e-tests-containers-z7kbn" to be "success or failure"
Dec 20 04:48:51.762: INFO: Pod "client-containers-8c13bc35-0412-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.557077ms
Dec 20 04:48:53.766: INFO: Pod "client-containers-8c13bc35-0412-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006428829s
Dec 20 04:48:55.770: INFO: Pod "client-containers-8c13bc35-0412-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009969615s
STEP: Saw pod success
Dec 20 04:48:55.770: INFO: Pod "client-containers-8c13bc35-0412-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:48:55.772: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod client-containers-8c13bc35-0412-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 04:48:55.790: INFO: Waiting for pod client-containers-8c13bc35-0412-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:48:55.792: INFO: Pod client-containers-8c13bc35-0412-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:48:55.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-z7kbn" for this suite.
Dec 20 04:49:01.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:49:01.904: INFO: namespace: e2e-tests-containers-z7kbn, resource: bindings, ignored listing per whitelist
Dec 20 04:49:01.916: INFO: namespace e2e-tests-containers-z7kbn deletion completed in 6.120617341s

• [SLOW TEST:10.412 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:49:01.916: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:49:01.989: INFO: Waiting up to 5m0s for pod "downwardapi-volume-922c2b28-0412-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-6hdrn" to be "success or failure"
Dec 20 04:49:01.993: INFO: Pod "downwardapi-volume-922c2b28-0412-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.111526ms
Dec 20 04:49:03.997: INFO: Pod "downwardapi-volume-922c2b28-0412-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007191547s
Dec 20 04:49:06.046: INFO: Pod "downwardapi-volume-922c2b28-0412-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05696671s
STEP: Saw pod success
Dec 20 04:49:06.046: INFO: Pod "downwardapi-volume-922c2b28-0412-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:49:06.100: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod downwardapi-volume-922c2b28-0412-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:49:06.168: INFO: Waiting for pod downwardapi-volume-922c2b28-0412-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:49:06.173: INFO: Pod downwardapi-volume-922c2b28-0412-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:49:06.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6hdrn" for this suite.
Dec 20 04:49:12.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:49:12.525: INFO: namespace: e2e-tests-downward-api-6hdrn, resource: bindings, ignored listing per whitelist
Dec 20 04:49:12.589: INFO: namespace e2e-tests-downward-api-6hdrn deletion completed in 6.096794769s

• [SLOW TEST:10.673 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:49:12.589: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 20 04:49:12.652: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-a,UID:9887ea0d-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12033,Generation:0,CreationTimestamp:2018-12-20 04:49:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 20 04:49:12.652: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-a,UID:9887ea0d-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12033,Generation:0,CreationTimestamp:2018-12-20 04:49:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 20 04:49:22.661: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-a,UID:9887ea0d-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12049,Generation:0,CreationTimestamp:2018-12-20 04:49:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 20 04:49:22.661: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-a,UID:9887ea0d-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12049,Generation:0,CreationTimestamp:2018-12-20 04:49:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 20 04:49:32.671: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-a,UID:9887ea0d-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12065,Generation:0,CreationTimestamp:2018-12-20 04:49:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 20 04:49:32.671: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-a,UID:9887ea0d-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12065,Generation:0,CreationTimestamp:2018-12-20 04:49:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 20 04:49:42.679: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-a,UID:9887ea0d-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12081,Generation:0,CreationTimestamp:2018-12-20 04:49:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 20 04:49:42.679: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-a,UID:9887ea0d-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12081,Generation:0,CreationTimestamp:2018-12-20 04:49:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 20 04:49:52.687: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-b,UID:b0644a89-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12097,Generation:0,CreationTimestamp:2018-12-20 04:49:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 20 04:49:52.687: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-b,UID:b0644a89-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12097,Generation:0,CreationTimestamp:2018-12-20 04:49:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 20 04:50:02.695: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-b,UID:b0644a89-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12113,Generation:0,CreationTimestamp:2018-12-20 04:49:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 20 04:50:02.695: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m7kdx,SelfLink:/api/v1/namespaces/e2e-tests-watch-m7kdx/configmaps/e2e-watch-test-configmap-b,UID:b0644a89-0412-11e9-9da8-506b8da7f7e6,ResourceVersion:12113,Generation:0,CreationTimestamp:2018-12-20 04:49:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:50:12.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-m7kdx" for this suite.
Dec 20 04:50:18.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:50:18.934: INFO: namespace: e2e-tests-watch-m7kdx, resource: bindings, ignored listing per whitelist
Dec 20 04:50:18.941: INFO: namespace e2e-tests-watch-m7kdx deletion completed in 6.108301351s

• [SLOW TEST:66.352 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:50:18.941: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 20 04:50:25.049: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 04:50:25.100: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 04:50:27.100: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 04:50:27.150: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 04:50:29.100: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 04:50:29.154: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 04:50:31.100: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 04:50:31.151: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 04:50:33.100: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 04:50:33.147: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 04:50:35.100: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 04:50:35.159: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 04:50:37.100: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 04:50:37.156: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 04:50:39.100: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 04:50:39.150: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 04:50:41.100: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 04:50:41.149: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 04:50:43.100: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 04:50:43.103: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 04:50:45.100: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 04:50:45.104: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:50:45.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-dsg5f" for this suite.
Dec 20 04:51:07.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:51:07.389: INFO: namespace: e2e-tests-container-lifecycle-hook-dsg5f, resource: bindings, ignored listing per whitelist
Dec 20 04:51:07.439: INFO: namespace e2e-tests-container-lifecycle-hook-dsg5f deletion completed in 22.322554261s

• [SLOW TEST:48.498 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:51:07.439: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-b64td
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 20 04:51:07.735: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 20 04:51:35.815: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.200.3.50:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-b64td PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:51:35.815: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:51:35.931: INFO: Found all expected endpoints: [netserver-0]
Dec 20 04:51:35.934: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.200.1.54:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-b64td PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:51:35.934: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:51:36.053: INFO: Found all expected endpoints: [netserver-1]
Dec 20 04:51:36.056: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.200.2.57:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-b64td PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 04:51:36.056: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 04:51:36.192: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:51:36.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-b64td" for this suite.
Dec 20 04:51:58.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:51:58.628: INFO: namespace: e2e-tests-pod-network-test-b64td, resource: bindings, ignored listing per whitelist
Dec 20 04:51:58.666: INFO: namespace e2e-tests-pod-network-test-b64td deletion completed in 22.330424983s

• [SLOW TEST:51.226 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:51:58.666: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 04:51:58.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 version --client'
Dec 20 04:51:59.044: INFO: stderr: ""
Dec 20 04:51:59.044: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec 20 04:51:59.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-nt8cl'
Dec 20 04:51:59.410: INFO: stderr: ""
Dec 20 04:51:59.410: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 20 04:51:59.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-nt8cl'
Dec 20 04:51:59.608: INFO: stderr: ""
Dec 20 04:51:59.608: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 20 04:52:00.611: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 04:52:00.611: INFO: Found 0 / 1
Dec 20 04:52:01.612: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 04:52:01.612: INFO: Found 0 / 1
Dec 20 04:52:02.612: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 04:52:02.612: INFO: Found 0 / 1
Dec 20 04:52:03.612: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 04:52:03.612: INFO: Found 1 / 1
Dec 20 04:52:03.612: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 20 04:52:03.615: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 04:52:03.615: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 20 04:52:03.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 describe pod redis-master-zkjc2 --namespace=e2e-tests-kubectl-nt8cl'
Dec 20 04:52:03.925: INFO: stderr: ""
Dec 20 04:52:03.925: INFO: stdout: "Name:           redis-master-zkjc2\nNamespace:      e2e-tests-kubectl-nt8cl\nNode:           acsk8s-3f716c-k8s-worker-2/10.40.154.53\nStart Time:     Thu, 20 Dec 2018 04:51:59 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.200.3.52\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://8ac5e2d0e11ac240801b0d1172f94c22e99c09bac0e9c8747e68124b20e2b041\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 20 Dec 2018 04:52:01 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-86smb (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-86smb:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-86smb\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     <none>\nEvents:\n  Type    Reason     Age   From                                 Message\n  ----    ------     ----  ----                                 -------\n  Normal  Scheduled  4s    default-scheduler                    Successfully assigned e2e-tests-kubectl-nt8cl/redis-master-zkjc2 to acsk8s-3f716c-k8s-worker-2\n  Normal  Pulled     2s    kubelet, acsk8s-3f716c-k8s-worker-2  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, acsk8s-3f716c-k8s-worker-2  Created container\n  Normal  Started    1s    kubelet, acsk8s-3f716c-k8s-worker-2  Started container\n"
Dec 20 04:52:03.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 describe rc redis-master --namespace=e2e-tests-kubectl-nt8cl'
Dec 20 04:52:04.185: INFO: stderr: ""
Dec 20 04:52:04.185: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-nt8cl\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  5s    replication-controller  Created pod: redis-master-zkjc2\n"
Dec 20 04:52:04.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 describe service redis-master --namespace=e2e-tests-kubectl-nt8cl'
Dec 20 04:52:04.354: INFO: stderr: ""
Dec 20 04:52:04.354: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-nt8cl\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.32.0.18\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.200.3.52:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 20 04:52:04.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 describe node acsk8s-3f716c-k8s-master-0'
Dec 20 04:52:04.627: INFO: stderr: ""
Dec 20 04:52:04.627: INFO: stdout: "Name:               acsk8s-3f716c-k8s-master-0\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=acsk8s-3f716c-k8s-master-0\n                    kubernetes.io/nodepool=acsk8s-3f716c-k8s-master\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"46:e2:92:dc:12:ea\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.40.154.56\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 20 Dec 2018 03:23:22 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Thu, 20 Dec 2018 04:52:01 +0000   Thu, 20 Dec 2018 03:23:13 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Thu, 20 Dec 2018 04:52:01 +0000   Thu, 20 Dec 2018 03:23:13 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 20 Dec 2018 04:52:01 +0000   Thu, 20 Dec 2018 03:23:13 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 20 Dec 2018 04:52:01 +0000   Thu, 20 Dec 2018 03:23:13 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 20 Dec 2018 04:52:01 +0000   Thu, 20 Dec 2018 03:23:13 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.40.154.56\n  Hostname:    acsk8s-3f716c-k8s-master-0\nCapacity:\n cpu:                4\n ephemeral-storage:  124769260Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3847612Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  114987349826\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3745212Ki\n pods:               110\nSystem Info:\n Machine ID:                 57cf84d535f1423fb9658cd78e0685f2\n System UUID:                BEED7BF4-0C66-4E87-AAD3-604B920B0DFA\n Boot ID:                    2e164c5f-8809-4d7a-826c-c9a9932a9052\n Kernel Version:             3.10.0-862.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://1.13.1\n Kubelet Version:            v1.12.3\n Kube-Proxy Version:         v1.12.3\nPodCIDR:                     10.200.0.0/24\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-dx25v    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                fluent-bit-7rmxj                                           100m (2%)     0 (0%)      200Mi (5%)       200Mi (5%)\n  kube-system                kube-apiserver-acsk8s-3f716c-k8s-master-0                  300m (7%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-dns-d94f8cc-zkzgv                                     260m (6%)     0 (0%)      110Mi (3%)       170Mi (4%)\n  kube-system                kube-flannel-ds-pnkg2                                      100m (2%)     100m (2%)   50Mi (1%)        50Mi (1%)\n  kube-system                kube-proxy-ds-vps67                                        100m (2%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                nutanixabs-provisioner-687b5bff8d-q9558                    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  monitoring                 node-exporter-vph5b                                        112m (2%)     122m (3%)   200Mi (5%)       220Mi (6%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests     Limits\n  --------  --------     ------\n  cpu       972m (24%)   222m (5%)\n  memory    560Mi (15%)  640Mi (17%)\nEvents:     <none>\n"
Dec 20 04:52:04.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 describe namespace e2e-tests-kubectl-nt8cl'
Dec 20 04:52:04.741: INFO: stderr: ""
Dec 20 04:52:04.741: INFO: stdout: "Name:         e2e-tests-kubectl-nt8cl\nLabels:       e2e-framework=kubectl\n              e2e-run=0a8ff007-040c-11e9-acdd-0a580ac80107\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:52:04.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nt8cl" for this suite.
Dec 20 04:52:26.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:52:27.052: INFO: namespace: e2e-tests-kubectl-nt8cl, resource: bindings, ignored listing per whitelist
Dec 20 04:52:27.079: INFO: namespace e2e-tests-kubectl-nt8cl deletion completed in 22.334695578s

• [SLOW TEST:28.413 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:52:27.079: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 04:52:47.404: INFO: Container started at 2018-12-20 04:52:30 +0000 UTC, pod became ready at 2018-12-20 04:52:47 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:52:47.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2wxnf" for this suite.
Dec 20 04:53:09.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:53:09.804: INFO: namespace: e2e-tests-container-probe-2wxnf, resource: bindings, ignored listing per whitelist
Dec 20 04:53:09.824: INFO: namespace e2e-tests-container-probe-2wxnf deletion completed in 22.101622708s

• [SLOW TEST:42.745 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:53:09.824: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-7cxg4/configmap-test-25ef852f-0413-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 04:53:09.898: INFO: Waiting up to 5m0s for pod "pod-configmaps-25f04cbd-0413-11e9-acdd-0a580ac80107" in namespace "e2e-tests-configmap-7cxg4" to be "success or failure"
Dec 20 04:53:09.903: INFO: Pod "pod-configmaps-25f04cbd-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.926103ms
Dec 20 04:53:11.907: INFO: Pod "pod-configmaps-25f04cbd-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008496203s
Dec 20 04:53:13.911: INFO: Pod "pod-configmaps-25f04cbd-0413-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012315564s
STEP: Saw pod success
Dec 20 04:53:13.911: INFO: Pod "pod-configmaps-25f04cbd-0413-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:53:13.913: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-configmaps-25f04cbd-0413-11e9-acdd-0a580ac80107 container env-test: <nil>
STEP: delete the pod
Dec 20 04:53:13.931: INFO: Waiting for pod pod-configmaps-25f04cbd-0413-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:53:13.934: INFO: Pod pod-configmaps-25f04cbd-0413-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:53:13.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7cxg4" for this suite.
Dec 20 04:53:20.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:53:20.340: INFO: namespace: e2e-tests-configmap-7cxg4, resource: bindings, ignored listing per whitelist
Dec 20 04:53:20.385: INFO: namespace e2e-tests-configmap-7cxg4 deletion completed in 6.107447536s

• [SLOW TEST:10.561 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:53:20.385: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-2c395661-0413-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 04:53:20.446: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2c39ecba-0413-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-vkbs2" to be "success or failure"
Dec 20 04:53:20.448: INFO: Pod "pod-projected-configmaps-2c39ecba-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.111953ms
Dec 20 04:53:22.453: INFO: Pod "pod-projected-configmaps-2c39ecba-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006461793s
Dec 20 04:53:24.457: INFO: Pod "pod-projected-configmaps-2c39ecba-0413-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01071533s
STEP: Saw pod success
Dec 20 04:53:24.457: INFO: Pod "pod-projected-configmaps-2c39ecba-0413-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:53:24.460: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-projected-configmaps-2c39ecba-0413-11e9-acdd-0a580ac80107 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 04:53:24.529: INFO: Waiting for pod pod-projected-configmaps-2c39ecba-0413-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:53:24.532: INFO: Pod pod-projected-configmaps-2c39ecba-0413-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:53:24.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vkbs2" for this suite.
Dec 20 04:53:30.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:53:30.893: INFO: namespace: e2e-tests-projected-vkbs2, resource: bindings, ignored listing per whitelist
Dec 20 04:53:30.929: INFO: namespace e2e-tests-projected-vkbs2 deletion completed in 6.091690736s

• [SLOW TEST:10.544 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:53:30.929: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 20 04:53:31.047: INFO: Waiting up to 5m0s for pod "pod-328b38a8-0413-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-x4glk" to be "success or failure"
Dec 20 04:53:31.054: INFO: Pod "pod-328b38a8-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 6.526019ms
Dec 20 04:53:33.057: INFO: Pod "pod-328b38a8-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009997174s
Dec 20 04:53:35.108: INFO: Pod "pod-328b38a8-0413-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061169271s
STEP: Saw pod success
Dec 20 04:53:35.108: INFO: Pod "pod-328b38a8-0413-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:53:35.155: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-328b38a8-0413-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 04:53:35.223: INFO: Waiting for pod pod-328b38a8-0413-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:53:35.227: INFO: Pod pod-328b38a8-0413-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:53:35.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x4glk" for this suite.
Dec 20 04:53:41.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:53:41.626: INFO: namespace: e2e-tests-emptydir-x4glk, resource: bindings, ignored listing per whitelist
Dec 20 04:53:41.667: INFO: namespace e2e-tests-emptydir-x4glk deletion completed in 6.110329789s

• [SLOW TEST:10.738 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:53:41.667: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:53:41.739: INFO: Waiting up to 5m0s for pod "downwardapi-volume-38e951b0-0413-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-wd9j2" to be "success or failure"
Dec 20 04:53:41.742: INFO: Pod "downwardapi-volume-38e951b0-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.487008ms
Dec 20 04:53:43.746: INFO: Pod "downwardapi-volume-38e951b0-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007046795s
Dec 20 04:53:45.797: INFO: Pod "downwardapi-volume-38e951b0-0413-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058047688s
STEP: Saw pod success
Dec 20 04:53:45.797: INFO: Pod "downwardapi-volume-38e951b0-0413-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:53:45.846: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downwardapi-volume-38e951b0-0413-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:53:45.912: INFO: Waiting for pod downwardapi-volume-38e951b0-0413-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:53:45.915: INFO: Pod downwardapi-volume-38e951b0-0413-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:53:45.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wd9j2" for this suite.
Dec 20 04:53:52.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:53:52.259: INFO: namespace: e2e-tests-downward-api-wd9j2, resource: bindings, ignored listing per whitelist
Dec 20 04:53:52.343: INFO: namespace e2e-tests-downward-api-wd9j2 deletion completed in 6.105905273s

• [SLOW TEST:10.676 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:53:52.343: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 20 04:53:52.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-sp7lc'
Dec 20 04:53:52.522: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 20 04:53:52.522: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Dec 20 04:53:54.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-sp7lc'
Dec 20 04:53:54.648: INFO: stderr: ""
Dec 20 04:53:54.648: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:53:54.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sp7lc" for this suite.
Dec 20 04:54:16.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:54:16.896: INFO: namespace: e2e-tests-kubectl-sp7lc, resource: bindings, ignored listing per whitelist
Dec 20 04:54:16.950: INFO: namespace e2e-tests-kubectl-sp7lc deletion completed in 22.299132016s

• [SLOW TEST:24.607 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:54:16.951: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:54:17.294: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e1bfca4-0413-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-pcspg" to be "success or failure"
Dec 20 04:54:17.297: INFO: Pod "downwardapi-volume-4e1bfca4-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.591348ms
Dec 20 04:54:19.300: INFO: Pod "downwardapi-volume-4e1bfca4-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006180546s
Dec 20 04:54:21.305: INFO: Pod "downwardapi-volume-4e1bfca4-0413-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010511849s
STEP: Saw pod success
Dec 20 04:54:21.305: INFO: Pod "downwardapi-volume-4e1bfca4-0413-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:54:21.307: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod downwardapi-volume-4e1bfca4-0413-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:54:21.325: INFO: Waiting for pod downwardapi-volume-4e1bfca4-0413-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:54:21.327: INFO: Pod downwardapi-volume-4e1bfca4-0413-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:54:21.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pcspg" for this suite.
Dec 20 04:54:27.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:54:27.407: INFO: namespace: e2e-tests-downward-api-pcspg, resource: bindings, ignored listing per whitelist
Dec 20 04:54:27.447: INFO: namespace e2e-tests-downward-api-pcspg deletion completed in 6.116487275s

• [SLOW TEST:10.496 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:54:27.447: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-54331b23-0413-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 04:54:27.512: INFO: Waiting up to 5m0s for pod "pod-configmaps-5433aa5d-0413-11e9-acdd-0a580ac80107" in namespace "e2e-tests-configmap-8tf84" to be "success or failure"
Dec 20 04:54:27.514: INFO: Pod "pod-configmaps-5433aa5d-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 1.917469ms
Dec 20 04:54:29.518: INFO: Pod "pod-configmaps-5433aa5d-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005537077s
Dec 20 04:54:31.522: INFO: Pod "pod-configmaps-5433aa5d-0413-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009480211s
STEP: Saw pod success
Dec 20 04:54:31.522: INFO: Pod "pod-configmaps-5433aa5d-0413-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:54:31.525: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-configmaps-5433aa5d-0413-11e9-acdd-0a580ac80107 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 04:54:31.590: INFO: Waiting for pod pod-configmaps-5433aa5d-0413-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:54:31.594: INFO: Pod pod-configmaps-5433aa5d-0413-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:54:31.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8tf84" for this suite.
Dec 20 04:54:37.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:54:37.882: INFO: namespace: e2e-tests-configmap-8tf84, resource: bindings, ignored listing per whitelist
Dec 20 04:54:37.959: INFO: namespace e2e-tests-configmap-8tf84 deletion completed in 6.101221871s

• [SLOW TEST:10.512 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:54:37.959: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 04:54:38.028: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a77a59b-0413-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-r4s4c" to be "success or failure"
Dec 20 04:54:38.031: INFO: Pod "downwardapi-volume-5a77a59b-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.554601ms
Dec 20 04:54:40.035: INFO: Pod "downwardapi-volume-5a77a59b-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006711275s
Dec 20 04:54:42.094: INFO: Pod "downwardapi-volume-5a77a59b-0413-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065230241s
STEP: Saw pod success
Dec 20 04:54:42.094: INFO: Pod "downwardapi-volume-5a77a59b-0413-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:54:42.144: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downwardapi-volume-5a77a59b-0413-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 04:54:42.216: INFO: Waiting for pod downwardapi-volume-5a77a59b-0413-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:54:42.219: INFO: Pod downwardapi-volume-5a77a59b-0413-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:54:42.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r4s4c" for this suite.
Dec 20 04:54:48.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:54:48.627: INFO: namespace: e2e-tests-downward-api-r4s4c, resource: bindings, ignored listing per whitelist
Dec 20 04:54:48.638: INFO: namespace e2e-tests-downward-api-r4s4c deletion completed in 6.103756108s

• [SLOW TEST:10.679 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:54:48.639: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-60d49fba-0413-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 04:54:48.710: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-60d5d610-0413-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-djc5q" to be "success or failure"
Dec 20 04:54:48.715: INFO: Pod "pod-projected-configmaps-60d5d610-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.629065ms
Dec 20 04:54:50.718: INFO: Pod "pod-projected-configmaps-60d5d610-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008241886s
Dec 20 04:54:52.771: INFO: Pod "pod-projected-configmaps-60d5d610-0413-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060497647s
STEP: Saw pod success
Dec 20 04:54:52.771: INFO: Pod "pod-projected-configmaps-60d5d610-0413-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:54:52.816: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-projected-configmaps-60d5d610-0413-11e9-acdd-0a580ac80107 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 04:54:52.882: INFO: Waiting for pod pod-projected-configmaps-60d5d610-0413-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:54:52.885: INFO: Pod pod-projected-configmaps-60d5d610-0413-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:54:52.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-djc5q" for this suite.
Dec 20 04:54:59.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:54:59.268: INFO: namespace: e2e-tests-projected-djc5q, resource: bindings, ignored listing per whitelist
Dec 20 04:54:59.327: INFO: namespace e2e-tests-projected-djc5q deletion completed in 6.106781153s

• [SLOW TEST:10.688 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:54:59.327: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 20 04:54:59.408: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:54:59.410: INFO: Number of nodes with available pods: 0
Dec 20 04:54:59.410: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:55:00.415: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:00.418: INFO: Number of nodes with available pods: 0
Dec 20 04:55:00.418: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:55:01.414: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:01.417: INFO: Number of nodes with available pods: 0
Dec 20 04:55:01.417: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 04:55:02.415: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:02.418: INFO: Number of nodes with available pods: 2
Dec 20 04:55:02.418: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:03.653: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:03.753: INFO: Number of nodes with available pods: 2
Dec 20 04:55:03.753: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:04.565: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:04.568: INFO: Number of nodes with available pods: 3
Dec 20 04:55:04.568: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 20 04:55:04.585: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:04.588: INFO: Number of nodes with available pods: 2
Dec 20 04:55:04.588: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:05.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:05.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:05.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:06.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:06.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:06.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:07.600: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:07.605: INFO: Number of nodes with available pods: 2
Dec 20 04:55:07.605: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:08.867: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:08.962: INFO: Number of nodes with available pods: 2
Dec 20 04:55:08.962: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:09.694: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:09.697: INFO: Number of nodes with available pods: 2
Dec 20 04:55:09.697: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:10.592: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:10.595: INFO: Number of nodes with available pods: 2
Dec 20 04:55:10.595: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:11.594: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:11.597: INFO: Number of nodes with available pods: 2
Dec 20 04:55:11.597: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:12.592: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:12.595: INFO: Number of nodes with available pods: 2
Dec 20 04:55:12.595: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:13.592: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:13.595: INFO: Number of nodes with available pods: 2
Dec 20 04:55:13.595: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:14.861: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:14.961: INFO: Number of nodes with available pods: 2
Dec 20 04:55:14.961: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:15.684: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:15.687: INFO: Number of nodes with available pods: 2
Dec 20 04:55:15.687: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:16.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:16.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:16.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:17.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:17.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:17.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:18.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:18.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:18.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:19.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:19.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:19.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:20.822: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:20.917: INFO: Number of nodes with available pods: 2
Dec 20 04:55:20.917: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:21.731: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:21.734: INFO: Number of nodes with available pods: 2
Dec 20 04:55:21.734: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:22.594: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:22.597: INFO: Number of nodes with available pods: 2
Dec 20 04:55:22.597: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:23.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:23.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:23.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:24.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:24.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:24.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:25.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:25.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:25.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:26.868: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:26.963: INFO: Number of nodes with available pods: 2
Dec 20 04:55:26.963: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:27.685: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:27.689: INFO: Number of nodes with available pods: 2
Dec 20 04:55:27.689: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:28.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:28.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:28.597: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:29.592: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:29.595: INFO: Number of nodes with available pods: 2
Dec 20 04:55:29.595: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:30.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:30.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:30.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:31.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:31.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:31.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:32.823: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:32.911: INFO: Number of nodes with available pods: 2
Dec 20 04:55:32.911: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:33.756: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:33.762: INFO: Number of nodes with available pods: 2
Dec 20 04:55:33.762: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:34.592: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:34.595: INFO: Number of nodes with available pods: 2
Dec 20 04:55:34.595: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:35.592: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:35.595: INFO: Number of nodes with available pods: 2
Dec 20 04:55:35.595: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:36.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:36.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:36.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:37.592: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:37.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:37.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:38.876: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:38.972: INFO: Number of nodes with available pods: 2
Dec 20 04:55:38.972: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:39.688: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:39.691: INFO: Number of nodes with available pods: 2
Dec 20 04:55:39.691: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:40.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:40.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:40.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:41.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:41.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:41.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:42.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:42.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:42.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:43.592: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:43.595: INFO: Number of nodes with available pods: 2
Dec 20 04:55:43.595: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:44.845: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:44.933: INFO: Number of nodes with available pods: 2
Dec 20 04:55:44.933: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:45.731: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:45.735: INFO: Number of nodes with available pods: 2
Dec 20 04:55:45.735: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:46.592: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:46.595: INFO: Number of nodes with available pods: 2
Dec 20 04:55:46.595: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:47.594: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:47.597: INFO: Number of nodes with available pods: 2
Dec 20 04:55:47.597: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:48.592: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:48.595: INFO: Number of nodes with available pods: 2
Dec 20 04:55:48.595: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:49.593: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:49.596: INFO: Number of nodes with available pods: 2
Dec 20 04:55:49.596: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 04:55:50.828: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 04:55:50.923: INFO: Number of nodes with available pods: 3
Dec 20 04:55:50.923: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-26tb4, will wait for the garbage collector to delete the pods
Dec 20 04:55:51.036: INFO: Deleting {extensions DaemonSet} daemon-set took: 7.638099ms
Dec 20 04:55:51.136: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.220064ms
Dec 20 04:56:28.940: INFO: Number of nodes with available pods: 0
Dec 20 04:56:28.940: INFO: Number of running nodes: 0, number of available pods: 0
Dec 20 04:56:28.943: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-26tb4/daemonsets","resourceVersion":"13208"},"items":null}

Dec 20 04:56:28.946: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-26tb4/pods","resourceVersion":"13208"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:56:29.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-26tb4" for this suite.
Dec 20 04:56:35.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:56:35.318: INFO: namespace: e2e-tests-daemonsets-26tb4, resource: bindings, ignored listing per whitelist
Dec 20 04:56:35.342: INFO: namespace e2e-tests-daemonsets-26tb4 deletion completed in 6.119401934s

• [SLOW TEST:96.015 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:56:35.342: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-a06e393d-0413-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 04:56:35.411: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a06f17a6-0413-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-7wsfq" to be "success or failure"
Dec 20 04:56:35.417: INFO: Pod "pod-projected-secrets-a06f17a6-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.496308ms
Dec 20 04:56:37.420: INFO: Pod "pod-projected-secrets-a06f17a6-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008624698s
Dec 20 04:56:39.423: INFO: Pod "pod-projected-secrets-a06f17a6-0413-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012078029s
STEP: Saw pod success
Dec 20 04:56:39.423: INFO: Pod "pod-projected-secrets-a06f17a6-0413-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:56:39.426: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-projected-secrets-a06f17a6-0413-11e9-acdd-0a580ac80107 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 20 04:56:39.443: INFO: Waiting for pod pod-projected-secrets-a06f17a6-0413-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:56:39.446: INFO: Pod pod-projected-secrets-a06f17a6-0413-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:56:39.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7wsfq" for this suite.
Dec 20 04:56:45.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:56:45.515: INFO: namespace: e2e-tests-projected-7wsfq, resource: bindings, ignored listing per whitelist
Dec 20 04:56:45.557: INFO: namespace e2e-tests-projected-7wsfq deletion completed in 6.108379974s

• [SLOW TEST:10.215 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:56:45.557: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 20 04:56:50.346: INFO: Successfully updated pod "labelsupdatea68542d1-0413-11e9-acdd-0a580ac80107"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:56:52.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-22tl8" for this suite.
Dec 20 04:57:14.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:57:14.799: INFO: namespace: e2e-tests-downward-api-22tl8, resource: bindings, ignored listing per whitelist
Dec 20 04:57:14.847: INFO: namespace e2e-tests-downward-api-22tl8 deletion completed in 22.30865578s

• [SLOW TEST:29.289 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:57:14.847: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-b826fb69-0413-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 04:57:15.209: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b8279c59-0413-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-zrkcn" to be "success or failure"
Dec 20 04:57:15.214: INFO: Pod "pod-projected-secrets-b8279c59-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.94511ms
Dec 20 04:57:17.217: INFO: Pod "pod-projected-secrets-b8279c59-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00832434s
Dec 20 04:57:19.221: INFO: Pod "pod-projected-secrets-b8279c59-0413-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01219629s
STEP: Saw pod success
Dec 20 04:57:19.221: INFO: Pod "pod-projected-secrets-b8279c59-0413-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:57:19.224: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-projected-secrets-b8279c59-0413-11e9-acdd-0a580ac80107 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 20 04:57:19.242: INFO: Waiting for pod pod-projected-secrets-b8279c59-0413-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:57:19.245: INFO: Pod pod-projected-secrets-b8279c59-0413-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:57:19.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zrkcn" for this suite.
Dec 20 04:57:25.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:57:25.285: INFO: namespace: e2e-tests-projected-zrkcn, resource: bindings, ignored listing per whitelist
Dec 20 04:57:25.354: INFO: namespace e2e-tests-projected-zrkcn deletion completed in 6.104401798s

• [SLOW TEST:10.507 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:57:25.354: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:57:25.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dtp8h" for this suite.
Dec 20 04:57:47.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:57:47.689: INFO: namespace: e2e-tests-pods-dtp8h, resource: bindings, ignored listing per whitelist
Dec 20 04:57:47.763: INFO: namespace e2e-tests-pods-dtp8h deletion completed in 22.329879791s

• [SLOW TEST:22.409 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:57:47.763: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-cbb8b206-0413-11e9-acdd-0a580ac80107
Dec 20 04:57:48.041: INFO: Pod name my-hostname-basic-cbb8b206-0413-11e9-acdd-0a580ac80107: Found 0 pods out of 1
Dec 20 04:57:53.107: INFO: Pod name my-hostname-basic-cbb8b206-0413-11e9-acdd-0a580ac80107: Found 1 pods out of 1
Dec 20 04:57:53.107: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-cbb8b206-0413-11e9-acdd-0a580ac80107" are running
Dec 20 04:57:53.160: INFO: Pod "my-hostname-basic-cbb8b206-0413-11e9-acdd-0a580ac80107-jqcj2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-20 04:57:48 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-20 04:57:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-20 04:57:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-20 04:57:48 +0000 UTC Reason: Message:}])
Dec 20 04:57:53.160: INFO: Trying to dial the pod
Dec 20 04:57:58.218: INFO: Controller my-hostname-basic-cbb8b206-0413-11e9-acdd-0a580ac80107: Got expected result from replica 1 [my-hostname-basic-cbb8b206-0413-11e9-acdd-0a580ac80107-jqcj2]: "my-hostname-basic-cbb8b206-0413-11e9-acdd-0a580ac80107-jqcj2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:57:58.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-gjqk6" for this suite.
Dec 20 04:58:04.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:58:04.570: INFO: namespace: e2e-tests-replication-controller-gjqk6, resource: bindings, ignored listing per whitelist
Dec 20 04:58:04.665: INFO: namespace e2e-tests-replication-controller-gjqk6 deletion completed in 6.13010417s

• [SLOW TEST:16.902 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:58:04.665: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1220 04:58:15.411989      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 20 04:58:15.412: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:58:15.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xmk2b" for this suite.
Dec 20 04:58:21.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:58:21.434: INFO: namespace: e2e-tests-gc-xmk2b, resource: bindings, ignored listing per whitelist
Dec 20 04:58:21.516: INFO: namespace e2e-tests-gc-xmk2b deletion completed in 6.10092228s

• [SLOW TEST:16.851 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:58:21.516: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec 20 04:58:21.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:21.762: INFO: stderr: ""
Dec 20 04:58:21.762: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 04:58:21.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:21.880: INFO: stderr: ""
Dec 20 04:58:21.880: INFO: stdout: "update-demo-nautilus-r7xdp update-demo-nautilus-s6jk6 "
Dec 20 04:58:21.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-r7xdp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:21.982: INFO: stderr: ""
Dec 20 04:58:21.982: INFO: stdout: ""
Dec 20 04:58:21.983: INFO: update-demo-nautilus-r7xdp is created but not running
Dec 20 04:58:26.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:27.177: INFO: stderr: ""
Dec 20 04:58:27.178: INFO: stdout: "update-demo-nautilus-r7xdp update-demo-nautilus-s6jk6 "
Dec 20 04:58:27.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-r7xdp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:27.377: INFO: stderr: ""
Dec 20 04:58:27.377: INFO: stdout: "true"
Dec 20 04:58:27.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-r7xdp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:27.588: INFO: stderr: ""
Dec 20 04:58:27.588: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 04:58:27.588: INFO: validating pod update-demo-nautilus-r7xdp
Dec 20 04:58:27.592: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 04:58:27.592: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 04:58:27.592: INFO: update-demo-nautilus-r7xdp is verified up and running
Dec 20 04:58:27.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-s6jk6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:27.778: INFO: stderr: ""
Dec 20 04:58:27.778: INFO: stdout: "true"
Dec 20 04:58:27.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-nautilus-s6jk6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:27.925: INFO: stderr: ""
Dec 20 04:58:27.925: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 04:58:27.925: INFO: validating pod update-demo-nautilus-s6jk6
Dec 20 04:58:27.929: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 04:58:27.929: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 04:58:27.929: INFO: update-demo-nautilus-s6jk6 is verified up and running
STEP: rolling-update to new replication controller
Dec 20 04:58:27.930: INFO: scanned /root for discovery docs: <nil>
Dec 20 04:58:27.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:51.731: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 20 04:58:51.731: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 04:58:51.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:51.931: INFO: stderr: ""
Dec 20 04:58:51.931: INFO: stdout: "update-demo-kitten-mznr8 update-demo-kitten-tqxds "
Dec 20 04:58:51.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-kitten-mznr8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:52.144: INFO: stderr: ""
Dec 20 04:58:52.144: INFO: stdout: "true"
Dec 20 04:58:52.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-kitten-mznr8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:52.349: INFO: stderr: ""
Dec 20 04:58:52.349: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 20 04:58:52.349: INFO: validating pod update-demo-kitten-mznr8
Dec 20 04:58:52.354: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 20 04:58:52.354: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 20 04:58:52.354: INFO: update-demo-kitten-mznr8 is verified up and running
Dec 20 04:58:52.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-kitten-tqxds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:52.557: INFO: stderr: ""
Dec 20 04:58:52.557: INFO: stdout: "true"
Dec 20 04:58:52.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods update-demo-kitten-tqxds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9b6jk'
Dec 20 04:58:52.752: INFO: stderr: ""
Dec 20 04:58:52.752: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 20 04:58:52.752: INFO: validating pod update-demo-kitten-tqxds
Dec 20 04:58:52.757: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 20 04:58:52.757: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 20 04:58:52.757: INFO: update-demo-kitten-tqxds is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:58:52.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9b6jk" for this suite.
Dec 20 04:59:14.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:59:15.012: INFO: namespace: e2e-tests-kubectl-9b6jk, resource: bindings, ignored listing per whitelist
Dec 20 04:59:15.085: INFO: namespace e2e-tests-kubectl-9b6jk deletion completed in 22.322929435s

• [SLOW TEST:53.569 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:59:15.085: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ffbb5312-0413-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 04:59:15.299: INFO: Waiting up to 5m0s for pod "pod-configmaps-ffbbfed7-0413-11e9-acdd-0a580ac80107" in namespace "e2e-tests-configmap-j928m" to be "success or failure"
Dec 20 04:59:15.304: INFO: Pod "pod-configmaps-ffbbfed7-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.25756ms
Dec 20 04:59:17.307: INFO: Pod "pod-configmaps-ffbbfed7-0413-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008658584s
Dec 20 04:59:19.311: INFO: Pod "pod-configmaps-ffbbfed7-0413-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01210571s
STEP: Saw pod success
Dec 20 04:59:19.311: INFO: Pod "pod-configmaps-ffbbfed7-0413-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:59:19.313: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-configmaps-ffbbfed7-0413-11e9-acdd-0a580ac80107 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 04:59:19.342: INFO: Waiting for pod pod-configmaps-ffbbfed7-0413-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:59:19.346: INFO: Pod pod-configmaps-ffbbfed7-0413-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:59:19.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-j928m" for this suite.
Dec 20 04:59:25.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:59:25.455: INFO: namespace: e2e-tests-configmap-j928m, resource: bindings, ignored listing per whitelist
Dec 20 04:59:25.455: INFO: namespace e2e-tests-configmap-j928m deletion completed in 6.105808883s

• [SLOW TEST:10.370 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:59:25.455: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec 20 04:59:25.520: INFO: Waiting up to 5m0s for pod "var-expansion-05d3cfca-0414-11e9-acdd-0a580ac80107" in namespace "e2e-tests-var-expansion-mvmkj" to be "success or failure"
Dec 20 04:59:25.522: INFO: Pod "var-expansion-05d3cfca-0414-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.158297ms
Dec 20 04:59:27.526: INFO: Pod "var-expansion-05d3cfca-0414-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005765653s
Dec 20 04:59:29.529: INFO: Pod "var-expansion-05d3cfca-0414-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008932859s
STEP: Saw pod success
Dec 20 04:59:29.529: INFO: Pod "var-expansion-05d3cfca-0414-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 04:59:29.531: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod var-expansion-05d3cfca-0414-11e9-acdd-0a580ac80107 container dapi-container: <nil>
STEP: delete the pod
Dec 20 04:59:29.600: INFO: Waiting for pod var-expansion-05d3cfca-0414-11e9-acdd-0a580ac80107 to disappear
Dec 20 04:59:29.603: INFO: Pod var-expansion-05d3cfca-0414-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:59:29.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-mvmkj" for this suite.
Dec 20 04:59:35.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 04:59:36.059: INFO: namespace: e2e-tests-var-expansion-mvmkj, resource: bindings, ignored listing per whitelist
Dec 20 04:59:36.073: INFO: namespace e2e-tests-var-expansion-mvmkj deletion completed in 6.116401415s

• [SLOW TEST:10.618 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 04:59:36.074: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-0c298179-0414-11e9-acdd-0a580ac80107
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 04:59:40.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7fsbk" for this suite.
Dec 20 05:00:02.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:00:02.710: INFO: namespace: e2e-tests-configmap-7fsbk, resource: bindings, ignored listing per whitelist
Dec 20 05:00:02.810: INFO: namespace e2e-tests-configmap-7fsbk deletion completed in 22.392893291s

• [SLOW TEST:26.737 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:00:02.811: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Dec 20 05:00:03.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-d5cmj'
Dec 20 05:00:03.323: INFO: stderr: ""
Dec 20 05:00:03.323: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec 20 05:00:04.330: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 05:00:04.330: INFO: Found 0 / 1
Dec 20 05:00:05.329: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 05:00:05.329: INFO: Found 0 / 1
Dec 20 05:00:06.329: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 05:00:06.329: INFO: Found 1 / 1
Dec 20 05:00:06.329: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 20 05:00:06.332: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 05:00:06.332: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec 20 05:00:06.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 logs redis-master-428k9 redis-master --namespace=e2e-tests-kubectl-d5cmj'
Dec 20 05:00:06.589: INFO: stderr: ""
Dec 20 05:00:06.589: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Dec 05:00:05.329 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Dec 05:00:05.329 # Server started, Redis version 3.2.12\n1:M 20 Dec 05:00:05.329 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Dec 05:00:05.329 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec 20 05:00:06.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 log redis-master-428k9 redis-master --namespace=e2e-tests-kubectl-d5cmj --tail=1'
Dec 20 05:00:06.800: INFO: stderr: ""
Dec 20 05:00:06.800: INFO: stdout: "1:M 20 Dec 05:00:05.329 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec 20 05:00:06.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 log redis-master-428k9 redis-master --namespace=e2e-tests-kubectl-d5cmj --limit-bytes=1'
Dec 20 05:00:07.026: INFO: stderr: ""
Dec 20 05:00:07.026: INFO: stdout: " "
STEP: exposing timestamps
Dec 20 05:00:07.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 log redis-master-428k9 redis-master --namespace=e2e-tests-kubectl-d5cmj --tail=1 --timestamps'
Dec 20 05:00:07.252: INFO: stderr: ""
Dec 20 05:00:07.252: INFO: stdout: "2018-12-20T05:00:05.329756352Z 1:M 20 Dec 05:00:05.329 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec 20 05:00:09.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 log redis-master-428k9 redis-master --namespace=e2e-tests-kubectl-d5cmj --since=1s'
Dec 20 05:00:09.915: INFO: stderr: ""
Dec 20 05:00:09.915: INFO: stdout: ""
Dec 20 05:00:09.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 log redis-master-428k9 redis-master --namespace=e2e-tests-kubectl-d5cmj --since=24h'
Dec 20 05:00:10.049: INFO: stderr: ""
Dec 20 05:00:10.049: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 20 Dec 05:00:05.329 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Dec 05:00:05.329 # Server started, Redis version 3.2.12\n1:M 20 Dec 05:00:05.329 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Dec 05:00:05.329 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Dec 20 05:00:10.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-d5cmj'
Dec 20 05:00:10.185: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 05:00:10.185: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec 20 05:00:10.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-d5cmj'
Dec 20 05:00:10.310: INFO: stderr: "No resources found.\n"
Dec 20 05:00:10.310: INFO: stdout: ""
Dec 20 05:00:10.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -l name=nginx --namespace=e2e-tests-kubectl-d5cmj -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 20 05:00:10.426: INFO: stderr: ""
Dec 20 05:00:10.426: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:00:10.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d5cmj" for this suite.
Dec 20 05:00:32.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:00:32.471: INFO: namespace: e2e-tests-kubectl-d5cmj, resource: bindings, ignored listing per whitelist
Dec 20 05:00:32.553: INFO: namespace e2e-tests-kubectl-d5cmj deletion completed in 22.121622863s

• [SLOW TEST:29.743 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:00:32.553: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6q5gk
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec 20 05:00:32.637: INFO: Found 0 stateful pods, waiting for 3
Dec 20 05:00:42.693: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 05:00:42.693: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 05:00:42.693: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 05:00:42.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-6q5gk ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 20 05:00:43.055: INFO: stderr: ""
Dec 20 05:00:43.055: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 20 05:00:43.055: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 20 05:00:53.189: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 20 05:00:53.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-6q5gk ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 05:00:53.501: INFO: stderr: ""
Dec 20 05:00:53.501: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 20 05:00:53.501: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 20 05:01:03.576: INFO: Waiting for StatefulSet e2e-tests-statefulset-6q5gk/ss2 to complete update
Dec 20 05:01:03.576: INFO: Waiting for Pod e2e-tests-statefulset-6q5gk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 20 05:01:03.576: INFO: Waiting for Pod e2e-tests-statefulset-6q5gk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 20 05:01:13.583: INFO: Waiting for StatefulSet e2e-tests-statefulset-6q5gk/ss2 to complete update
Dec 20 05:01:13.584: INFO: Waiting for Pod e2e-tests-statefulset-6q5gk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 20 05:01:13.584: INFO: Waiting for Pod e2e-tests-statefulset-6q5gk/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 20 05:01:23.585: INFO: Waiting for StatefulSet e2e-tests-statefulset-6q5gk/ss2 to complete update
Dec 20 05:01:23.585: INFO: Waiting for Pod e2e-tests-statefulset-6q5gk/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Dec 20 05:01:33.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-6q5gk ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 20 05:01:33.935: INFO: stderr: ""
Dec 20 05:01:33.935: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 20 05:01:33.935: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 20 05:01:44.063: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 20 05:01:44.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-6q5gk ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 05:01:44.378: INFO: stderr: ""
Dec 20 05:01:44.378: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 20 05:01:44.378: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 20 05:02:04.506: INFO: Waiting for StatefulSet e2e-tests-statefulset-6q5gk/ss2 to complete update
Dec 20 05:02:04.506: INFO: Waiting for Pod e2e-tests-statefulset-6q5gk/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 20 05:02:14.513: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6q5gk
Dec 20 05:02:14.516: INFO: Scaling statefulset ss2 to 0
Dec 20 05:02:44.533: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 05:02:44.536: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:02:44.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6q5gk" for this suite.
Dec 20 05:02:50.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:02:51.019: INFO: namespace: e2e-tests-statefulset-6q5gk, resource: bindings, ignored listing per whitelist
Dec 20 05:02:51.027: INFO: namespace e2e-tests-statefulset-6q5gk deletion completed in 6.112152747s

• [SLOW TEST:138.473 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:02:51.027: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 20 05:02:51.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-8t9br'
Dec 20 05:02:51.345: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 20 05:02:51.345: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Dec 20 05:02:53.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-8t9br'
Dec 20 05:02:53.517: INFO: stderr: ""
Dec 20 05:02:53.517: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:02:53.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8t9br" for this suite.
Dec 20 05:02:59.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:02:59.581: INFO: namespace: e2e-tests-kubectl-8t9br, resource: bindings, ignored listing per whitelist
Dec 20 05:02:59.650: INFO: namespace e2e-tests-kubectl-8t9br deletion completed in 6.127562392s

• [SLOW TEST:8.624 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:02:59.651: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-85815cf3-0414-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 05:02:59.735: INFO: Waiting up to 5m0s for pod "pod-configmaps-858216e3-0414-11e9-acdd-0a580ac80107" in namespace "e2e-tests-configmap-m6nt5" to be "success or failure"
Dec 20 05:02:59.739: INFO: Pod "pod-configmaps-858216e3-0414-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.795183ms
Dec 20 05:03:01.743: INFO: Pod "pod-configmaps-858216e3-0414-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007859048s
Dec 20 05:03:03.747: INFO: Pod "pod-configmaps-858216e3-0414-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011676793s
STEP: Saw pod success
Dec 20 05:03:03.747: INFO: Pod "pod-configmaps-858216e3-0414-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:03:03.749: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-configmaps-858216e3-0414-11e9-acdd-0a580ac80107 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 05:03:03.817: INFO: Waiting for pod pod-configmaps-858216e3-0414-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:03:03.820: INFO: Pod pod-configmaps-858216e3-0414-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:03:03.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m6nt5" for this suite.
Dec 20 05:03:10.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:03:10.193: INFO: namespace: e2e-tests-configmap-m6nt5, resource: bindings, ignored listing per whitelist
Dec 20 05:03:10.262: INFO: namespace e2e-tests-configmap-m6nt5 deletion completed in 6.109090914s

• [SLOW TEST:10.612 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:03:10.262: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-8bdaaa27-0414-11e9-acdd-0a580ac80107
STEP: Creating configMap with name cm-test-opt-upd-8bdaab09-0414-11e9-acdd-0a580ac80107
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-8bdaaa27-0414-11e9-acdd-0a580ac80107
STEP: Updating configmap cm-test-opt-upd-8bdaab09-0414-11e9-acdd-0a580ac80107
STEP: Creating configMap with name cm-test-opt-create-8bdaab37-0414-11e9-acdd-0a580ac80107
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:03:18.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-46kxk" for this suite.
Dec 20 05:03:40.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:03:40.888: INFO: namespace: e2e-tests-projected-46kxk, resource: bindings, ignored listing per whitelist
Dec 20 05:03:40.958: INFO: namespace e2e-tests-projected-46kxk deletion completed in 22.300972862s

• [SLOW TEST:30.696 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:03:40.959: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 20 05:03:41.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-bc789'
Dec 20 05:03:41.434: INFO: stderr: ""
Dec 20 05:03:41.434: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec 20 05:03:46.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-bc789 -o json'
Dec 20 05:03:46.688: INFO: stderr: ""
Dec 20 05:03:46.688: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-12-20T05:03:41Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-bc789\",\n        \"resourceVersion\": \"14996\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-bc789/pods/e2e-test-nginx-pod\",\n        \"uid\": \"9e5a192a-0414-11e9-9da8-506b8da7f7e6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-2q5qq\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"acsk8s-3f716c-k8s-worker-2\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-2q5qq\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-2q5qq\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-20T05:03:41Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-20T05:03:44Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-20T05:03:44Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-20T05:03:41Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://1160cec3c3ada02a9847b979dc94994e035555df738fb243b5b0f27fcdec953f\",\n                \"image\": \"docker.io/nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://docker.io/nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-20T05:03:43Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.40.154.53\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.200.3.74\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-20T05:03:41Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 20 05:03:46.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 replace -f - --namespace=e2e-tests-kubectl-bc789'
Dec 20 05:03:46.978: INFO: stderr: ""
Dec 20 05:03:46.978: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Dec 20 05:03:46.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-bc789'
Dec 20 05:03:57.406: INFO: stderr: ""
Dec 20 05:03:57.406: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:03:57.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bc789" for this suite.
Dec 20 05:04:03.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:04:03.804: INFO: namespace: e2e-tests-kubectl-bc789, resource: bindings, ignored listing per whitelist
Dec 20 05:04:03.819: INFO: namespace e2e-tests-kubectl-bc789 deletion completed in 6.10306711s

• [SLOW TEST:22.861 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:04:03.819: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 05:04:03.888: INFO: Waiting up to 5m0s for pod "downwardapi-volume-abbf25d6-0414-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-d2jfs" to be "success or failure"
Dec 20 05:04:03.894: INFO: Pod "downwardapi-volume-abbf25d6-0414-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 6.198943ms
Dec 20 05:04:05.898: INFO: Pod "downwardapi-volume-abbf25d6-0414-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009520508s
Dec 20 05:04:07.955: INFO: Pod "downwardapi-volume-abbf25d6-0414-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067334147s
STEP: Saw pod success
Dec 20 05:04:07.956: INFO: Pod "downwardapi-volume-abbf25d6-0414-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:04:08.011: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downwardapi-volume-abbf25d6-0414-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 05:04:08.078: INFO: Waiting for pod downwardapi-volume-abbf25d6-0414-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:04:08.082: INFO: Pod downwardapi-volume-abbf25d6-0414-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:04:08.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d2jfs" for this suite.
Dec 20 05:04:14.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:04:14.436: INFO: namespace: e2e-tests-projected-d2jfs, resource: bindings, ignored listing per whitelist
Dec 20 05:04:14.511: INFO: namespace e2e-tests-projected-d2jfs deletion completed in 6.101178236s

• [SLOW TEST:10.692 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:04:14.511: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-j5pc2
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-j5pc2
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-j5pc2
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-j5pc2
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-j5pc2
Dec 20 05:04:18.612: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-j5pc2, name: ss-0, uid: b40d4651-0414-11e9-9da8-506b8da7f7e6, status phase: Pending. Waiting for statefulset controller to delete.
Dec 20 05:04:18.803: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-j5pc2, name: ss-0, uid: b40d4651-0414-11e9-9da8-506b8da7f7e6, status phase: Failed. Waiting for statefulset controller to delete.
Dec 20 05:04:18.809: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-j5pc2, name: ss-0, uid: b40d4651-0414-11e9-9da8-506b8da7f7e6, status phase: Failed. Waiting for statefulset controller to delete.
Dec 20 05:04:18.812: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-j5pc2
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-j5pc2
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-j5pc2 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 20 05:04:22.834: INFO: Deleting all statefulset in ns e2e-tests-statefulset-j5pc2
Dec 20 05:04:22.837: INFO: Scaling statefulset ss to 0
Dec 20 05:04:32.853: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 05:04:32.856: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:04:32.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-j5pc2" for this suite.
Dec 20 05:04:39.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:04:39.186: INFO: namespace: e2e-tests-statefulset-j5pc2, resource: bindings, ignored listing per whitelist
Dec 20 05:04:39.191: INFO: namespace e2e-tests-statefulset-j5pc2 deletion completed in 6.104697008s

• [SLOW TEST:24.680 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:04:39.191: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec 20 05:04:39.249: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 20 05:04:39.256: INFO: Waiting for terminating namespaces to be deleted...
Dec 20 05:04:39.258: INFO: 
Logging pods the kubelet thinks is on node acsk8s-3f716c-k8s-worker-0 before test
Dec 20 05:04:39.264: INFO: kibana-logging-557ddfb798-25hl8 from ntnx-logging started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.264: INFO: 	Container kibana-logging ready: true, restart count 0
Dec 20 05:04:39.264: INFO: prometheus-operator-6494c4f69b-rz2bs from monitoring started at 2018-12-20 03:31:49 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.264: INFO: 	Container prometheus-operator ready: true, restart count 0
Dec 20 05:04:39.264: INFO: node-exporter-6bq8k from monitoring started at 2018-12-20 03:31:50 +0000 UTC (2 container statuses recorded)
Dec 20 05:04:39.264: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 20 05:04:39.264: INFO: 	Container node-exporter ready: true, restart count 0
Dec 20 05:04:39.264: INFO: sonobuoy-e2e-job-8437e4dc2d8146dc from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:04:39.264: INFO: 	Container e2e ready: true, restart count 0
Dec 20 05:04:39.264: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 20 05:04:39.264: INFO: sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-7j587 from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:04:39.264: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 20 05:04:39.264: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 20 05:04:39.264: INFO: kube-proxy-ds-fcgv7 from kube-system started at 2018-12-20 03:28:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.264: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 05:04:39.264: INFO: fluent-bit-9jlsp from kube-system started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.264: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 20 05:04:39.264: INFO: alertmanager-main-2 from monitoring started at 2018-12-20 03:32:25 +0000 UTC (2 container statuses recorded)
Dec 20 05:04:39.264: INFO: 	Container alertmanager ready: true, restart count 0
Dec 20 05:04:39.264: INFO: 	Container config-reloader ready: true, restart count 0
Dec 20 05:04:39.264: INFO: kube-flannel-ds-hgmsk from kube-system started at 2018-12-20 03:28:31 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.264: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 20 05:04:39.264: INFO: prometheus-k8s-0 from monitoring started at 2018-12-20 03:32:08 +0000 UTC (3 container statuses recorded)
Dec 20 05:04:39.264: INFO: 	Container prometheus ready: true, restart count 1
Dec 20 05:04:39.264: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Dec 20 05:04:39.264: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Dec 20 05:04:39.264: INFO: 
Logging pods the kubelet thinks is on node acsk8s-3f716c-k8s-worker-1 before test
Dec 20 05:04:39.271: INFO: fluent-bit-tpqjx from kube-system started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.271: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 20 05:04:39.271: INFO: elasticsearch-logging-0 from ntnx-logging started at 2018-12-20 03:29:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.271: INFO: 	Container elasticsearch-logging ready: true, restart count 0
Dec 20 05:04:39.271: INFO: prometheus-k8s-1 from monitoring started at 2018-12-20 03:32:25 +0000 UTC (3 container statuses recorded)
Dec 20 05:04:39.271: INFO: 	Container prometheus ready: true, restart count 1
Dec 20 05:04:39.271: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Dec 20 05:04:39.271: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Dec 20 05:04:39.271: INFO: node-exporter-qp54z from monitoring started at 2018-12-20 03:31:50 +0000 UTC (2 container statuses recorded)
Dec 20 05:04:39.271: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 20 05:04:39.271: INFO: 	Container node-exporter ready: true, restart count 0
Dec 20 05:04:39.271: INFO: sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-9jw8w from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:04:39.271: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 20 05:04:39.271: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 20 05:04:39.271: INFO: kube-flannel-ds-jsn8t from kube-system started at 2018-12-20 03:28:31 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.271: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 20 05:04:39.271: INFO: alertmanager-main-1 from monitoring started at 2018-12-20 03:32:14 +0000 UTC (2 container statuses recorded)
Dec 20 05:04:39.271: INFO: 	Container alertmanager ready: true, restart count 0
Dec 20 05:04:39.271: INFO: 	Container config-reloader ready: true, restart count 0
Dec 20 05:04:39.271: INFO: kube-proxy-ds-8spq8 from kube-system started at 2018-12-20 03:28:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.271: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 05:04:39.271: INFO: 
Logging pods the kubelet thinks is on node acsk8s-3f716c-k8s-worker-2 before test
Dec 20 05:04:39.277: INFO: kube-proxy-ds-6h5q6 from kube-system started at 2018-12-20 03:28:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.277: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 05:04:39.277: INFO: kube-flannel-ds-dgwvj from kube-system started at 2018-12-20 03:28:31 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.277: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 20 05:04:39.277: INFO: fluent-bit-7v27c from kube-system started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.277: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 20 05:04:39.278: INFO: sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-g55ds from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:04:39.278: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 20 05:04:39.278: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 20 05:04:39.278: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-20 04:01:45 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.278: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 20 05:04:39.278: INFO: kubernetes-events-printer-57f7df584d-zdrps from ntnx-logging started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:04:39.278: INFO: 	Container kubernetes-events-printer ready: true, restart count 0
Dec 20 05:04:39.278: INFO: node-exporter-g96wx from monitoring started at 2018-12-20 03:31:50 +0000 UTC (2 container statuses recorded)
Dec 20 05:04:39.278: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 20 05:04:39.278: INFO: 	Container node-exporter ready: true, restart count 0
Dec 20 05:04:39.278: INFO: alertmanager-main-0 from monitoring started at 2018-12-20 03:32:00 +0000 UTC (2 container statuses recorded)
Dec 20 05:04:39.278: INFO: 	Container alertmanager ready: true, restart count 0
Dec 20 05:04:39.278: INFO: 	Container config-reloader ready: true, restart count 0
Dec 20 05:04:39.278: INFO: kube-state-metrics-58649d5448-bwppx from monitoring started at 2018-12-20 03:32:09 +0000 UTC (4 container statuses recorded)
Dec 20 05:04:39.278: INFO: 	Container addon-resizer ready: true, restart count 0
Dec 20 05:04:39.278: INFO: 	Container kube-rbac-proxy-main ready: true, restart count 0
Dec 20 05:04:39.278: INFO: 	Container kube-rbac-proxy-self ready: true, restart count 0
Dec 20 05:04:39.278: INFO: 	Container kube-state-metrics ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-c33edb74-0414-11e9-acdd-0a580ac80107 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-c33edb74-0414-11e9-acdd-0a580ac80107 off the node acsk8s-3f716c-k8s-worker-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-c33edb74-0414-11e9-acdd-0a580ac80107
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:04:47.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-8njzc" for this suite.
Dec 20 05:05:01.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:05:02.081: INFO: namespace: e2e-tests-sched-pred-8njzc, resource: bindings, ignored listing per whitelist
Dec 20 05:05:02.172: INFO: namespace e2e-tests-sched-pred-8njzc deletion completed in 14.352266486s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:22.982 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:05:02.173: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 05:05:02.482: INFO: (0) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 5.196908ms)
Dec 20 05:05:02.486: INFO: (1) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 4.242974ms)
Dec 20 05:05:02.490: INFO: (2) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 4.141989ms)
Dec 20 05:05:02.495: INFO: (3) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 4.602118ms)
Dec 20 05:05:02.499: INFO: (4) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 4.012712ms)
Dec 20 05:05:02.502: INFO: (5) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.471165ms)
Dec 20 05:05:02.506: INFO: (6) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.343792ms)
Dec 20 05:05:02.509: INFO: (7) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.390008ms)
Dec 20 05:05:02.513: INFO: (8) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.53697ms)
Dec 20 05:05:02.516: INFO: (9) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.38594ms)
Dec 20 05:05:02.520: INFO: (10) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.378437ms)
Dec 20 05:05:02.523: INFO: (11) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.38616ms)
Dec 20 05:05:02.526: INFO: (12) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.457371ms)
Dec 20 05:05:02.530: INFO: (13) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.519946ms)
Dec 20 05:05:02.534: INFO: (14) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.55389ms)
Dec 20 05:05:02.537: INFO: (15) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.217708ms)
Dec 20 05:05:02.541: INFO: (16) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.669506ms)
Dec 20 05:05:02.544: INFO: (17) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.619823ms)
Dec 20 05:05:02.551: INFO: (18) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 6.48664ms)
Dec 20 05:05:02.556: INFO: (19) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0:10250/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 5.467545ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:05:02.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-xc8kb" for this suite.
Dec 20 05:05:08.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:05:08.616: INFO: namespace: e2e-tests-proxy-xc8kb, resource: bindings, ignored listing per whitelist
Dec 20 05:05:08.680: INFO: namespace e2e-tests-proxy-xc8kb deletion completed in 6.120023385s

• [SLOW TEST:6.507 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:05:08.680: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d267671c-0414-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 05:05:08.747: INFO: Waiting up to 5m0s for pod "pod-secrets-d26827c8-0414-11e9-acdd-0a580ac80107" in namespace "e2e-tests-secrets-pnvfh" to be "success or failure"
Dec 20 05:05:08.753: INFO: Pod "pod-secrets-d26827c8-0414-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.788703ms
Dec 20 05:05:10.757: INFO: Pod "pod-secrets-d26827c8-0414-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010041276s
Dec 20 05:05:12.761: INFO: Pod "pod-secrets-d26827c8-0414-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013774352s
STEP: Saw pod success
Dec 20 05:05:12.761: INFO: Pod "pod-secrets-d26827c8-0414-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:05:12.818: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-secrets-d26827c8-0414-11e9-acdd-0a580ac80107 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 05:05:12.884: INFO: Waiting for pod pod-secrets-d26827c8-0414-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:05:12.888: INFO: Pod pod-secrets-d26827c8-0414-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:05:12.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pnvfh" for this suite.
Dec 20 05:05:19.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:05:19.309: INFO: namespace: e2e-tests-secrets-pnvfh, resource: bindings, ignored listing per whitelist
Dec 20 05:05:19.372: INFO: namespace e2e-tests-secrets-pnvfh deletion completed in 6.111385847s

• [SLOW TEST:10.691 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:05:19.372: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 05:05:19.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 version'
Dec 20 05:05:19.514: INFO: stderr: ""
Dec 20 05:05:19.514: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:46:57Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:05:19.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m5n7w" for this suite.
Dec 20 05:05:25.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:05:25.600: INFO: namespace: e2e-tests-kubectl-m5n7w, resource: bindings, ignored listing per whitelist
Dec 20 05:05:25.623: INFO: namespace e2e-tests-kubectl-m5n7w deletion completed in 6.103976949s

• [SLOW TEST:6.251 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:05:25.623: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 20 05:05:31.731: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 20 05:05:31.777: INFO: Pod pod-with-poststart-http-hook still exists
Dec 20 05:05:33.777: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 20 05:05:33.822: INFO: Pod pod-with-poststart-http-hook still exists
Dec 20 05:05:35.777: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 20 05:05:35.843: INFO: Pod pod-with-poststart-http-hook still exists
Dec 20 05:05:37.777: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 20 05:05:37.781: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:05:37.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-pvj2s" for this suite.
Dec 20 05:06:00.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:06:00.350: INFO: namespace: e2e-tests-container-lifecycle-hook-pvj2s, resource: bindings, ignored listing per whitelist
Dec 20 05:06:00.394: INFO: namespace e2e-tests-container-lifecycle-hook-pvj2s deletion completed in 22.280835789s

• [SLOW TEST:34.771 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:06:00.394: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mshh2
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec 20 05:06:00.705: INFO: Found 0 stateful pods, waiting for 3
Dec 20 05:06:10.761: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 05:06:10.761: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 05:06:10.761: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 20 05:06:10.981: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 20 05:06:11.012: INFO: Updating stateful set ss2
Dec 20 05:06:11.022: INFO: Waiting for Pod e2e-tests-statefulset-mshh2/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec 20 05:06:21.420: INFO: Found 2 stateful pods, waiting for 3
Dec 20 05:06:31.476: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 05:06:31.476: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 05:06:31.476: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 20 05:06:31.743: INFO: Updating stateful set ss2
Dec 20 05:06:31.753: INFO: Waiting for Pod e2e-tests-statefulset-mshh2/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 20 05:06:42.016: INFO: Updating stateful set ss2
Dec 20 05:06:42.023: INFO: Waiting for StatefulSet e2e-tests-statefulset-mshh2/ss2 to complete update
Dec 20 05:06:42.023: INFO: Waiting for Pod e2e-tests-statefulset-mshh2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 20 05:06:52.031: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mshh2
Dec 20 05:06:52.035: INFO: Scaling statefulset ss2 to 0
Dec 20 05:07:22.243: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 05:07:22.246: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:07:22.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mshh2" for this suite.
Dec 20 05:07:28.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:07:28.568: INFO: namespace: e2e-tests-statefulset-mshh2, resource: bindings, ignored listing per whitelist
Dec 20 05:07:28.598: INFO: namespace e2e-tests-statefulset-mshh2 deletion completed in 6.114940056s

• [SLOW TEST:88.204 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:07:28.599: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 05:07:28.668: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25ce4d01-0415-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-sggdj" to be "success or failure"
Dec 20 05:07:28.673: INFO: Pod "downwardapi-volume-25ce4d01-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.113474ms
Dec 20 05:07:30.677: INFO: Pod "downwardapi-volume-25ce4d01-0415-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009068253s
STEP: Saw pod success
Dec 20 05:07:30.677: INFO: Pod "downwardapi-volume-25ce4d01-0415-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:07:30.680: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod downwardapi-volume-25ce4d01-0415-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 05:07:30.701: INFO: Waiting for pod downwardapi-volume-25ce4d01-0415-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:07:30.703: INFO: Pod downwardapi-volume-25ce4d01-0415-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:07:30.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sggdj" for this suite.
Dec 20 05:07:36.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:07:36.810: INFO: namespace: e2e-tests-projected-sggdj, resource: bindings, ignored listing per whitelist
Dec 20 05:07:36.816: INFO: namespace e2e-tests-projected-sggdj deletion completed in 6.10746667s

• [SLOW TEST:8.217 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:07:36.816: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-2ab3451c-0415-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 05:07:36.883: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2ab3deb2-0415-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-mnfbt" to be "success or failure"
Dec 20 05:07:36.886: INFO: Pod "pod-projected-secrets-2ab3deb2-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.014773ms
Dec 20 05:07:38.890: INFO: Pod "pod-projected-secrets-2ab3deb2-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006216414s
Dec 20 05:07:40.939: INFO: Pod "pod-projected-secrets-2ab3deb2-0415-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056020996s
STEP: Saw pod success
Dec 20 05:07:40.939: INFO: Pod "pod-projected-secrets-2ab3deb2-0415-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:07:40.989: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-projected-secrets-2ab3deb2-0415-11e9-acdd-0a580ac80107 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 05:07:41.057: INFO: Waiting for pod pod-projected-secrets-2ab3deb2-0415-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:07:41.060: INFO: Pod pod-projected-secrets-2ab3deb2-0415-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:07:41.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mnfbt" for this suite.
Dec 20 05:07:47.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:07:47.403: INFO: namespace: e2e-tests-projected-mnfbt, resource: bindings, ignored listing per whitelist
Dec 20 05:07:47.475: INFO: namespace e2e-tests-projected-mnfbt deletion completed in 6.104538294s

• [SLOW TEST:10.659 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:07:47.476: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 20 05:07:47.538: INFO: Waiting up to 5m0s for pod "pod-310d8c59-0415-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-4rv5g" to be "success or failure"
Dec 20 05:07:47.543: INFO: Pod "pod-310d8c59-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.352738ms
Dec 20 05:07:49.546: INFO: Pod "pod-310d8c59-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007613275s
Dec 20 05:07:51.550: INFO: Pod "pod-310d8c59-0415-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011346986s
STEP: Saw pod success
Dec 20 05:07:51.550: INFO: Pod "pod-310d8c59-0415-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:07:51.552: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-310d8c59-0415-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 05:07:51.635: INFO: Waiting for pod pod-310d8c59-0415-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:07:51.638: INFO: Pod pod-310d8c59-0415-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:07:51.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4rv5g" for this suite.
Dec 20 05:07:58.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:07:58.070: INFO: namespace: e2e-tests-emptydir-4rv5g, resource: bindings, ignored listing per whitelist
Dec 20 05:07:58.128: INFO: namespace e2e-tests-emptydir-4rv5g deletion completed in 6.12527527s

• [SLOW TEST:10.652 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:07:58.128: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec 20 05:07:58.186: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-617439060 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:07:58.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6bbbg" for this suite.
Dec 20 05:08:04.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:08:04.328: INFO: namespace: e2e-tests-kubectl-6bbbg, resource: bindings, ignored listing per whitelist
Dec 20 05:08:04.394: INFO: namespace e2e-tests-kubectl-6bbbg deletion completed in 6.109628784s

• [SLOW TEST:6.266 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:08:04.394: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3b246878-0415-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 05:08:04.471: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b2578d5-0415-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-l6mdf" to be "success or failure"
Dec 20 05:08:04.476: INFO: Pod "pod-projected-configmaps-3b2578d5-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.204884ms
Dec 20 05:08:06.481: INFO: Pod "pod-projected-configmaps-3b2578d5-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009469577s
Dec 20 05:08:08.531: INFO: Pod "pod-projected-configmaps-3b2578d5-0415-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060157605s
STEP: Saw pod success
Dec 20 05:08:08.531: INFO: Pod "pod-projected-configmaps-3b2578d5-0415-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:08:08.581: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-projected-configmaps-3b2578d5-0415-11e9-acdd-0a580ac80107 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 05:08:08.658: INFO: Waiting for pod pod-projected-configmaps-3b2578d5-0415-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:08:08.661: INFO: Pod pod-projected-configmaps-3b2578d5-0415-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:08:08.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l6mdf" for this suite.
Dec 20 05:08:14.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:08:15.044: INFO: namespace: e2e-tests-projected-l6mdf, resource: bindings, ignored listing per whitelist
Dec 20 05:08:15.082: INFO: namespace e2e-tests-projected-l6mdf deletion completed in 6.111435991s

• [SLOW TEST:10.688 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:08:15.082: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 05:08:15.189: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4187b018-0415-11e9-9da8-506b8da7f7e6", Controller:(*bool)(0xc42268a246), BlockOwnerDeletion:(*bool)(0xc42268a247)}}
Dec 20 05:08:15.204: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"41860e4e-0415-11e9-9da8-506b8da7f7e6", Controller:(*bool)(0xc4227eb30e), BlockOwnerDeletion:(*bool)(0xc4227eb30f)}}
Dec 20 05:08:15.212: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4186fe4a-0415-11e9-9da8-506b8da7f7e6", Controller:(*bool)(0xc422c3c86e), BlockOwnerDeletion:(*bool)(0xc422c3c86f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:08:20.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-r7bh9" for this suite.
Dec 20 05:08:26.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:08:26.534: INFO: namespace: e2e-tests-gc-r7bh9, resource: bindings, ignored listing per whitelist
Dec 20 05:08:26.599: INFO: namespace e2e-tests-gc-r7bh9 deletion completed in 6.100770096s

• [SLOW TEST:11.516 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:08:26.599: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-485ee73f-0415-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 05:08:26.664: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-485fda4b-0415-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-pwk7v" to be "success or failure"
Dec 20 05:08:26.671: INFO: Pod "pod-projected-configmaps-485fda4b-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 6.900223ms
Dec 20 05:08:28.674: INFO: Pod "pod-projected-configmaps-485fda4b-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01037484s
Dec 20 05:08:30.678: INFO: Pod "pod-projected-configmaps-485fda4b-0415-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013803408s
STEP: Saw pod success
Dec 20 05:08:30.678: INFO: Pod "pod-projected-configmaps-485fda4b-0415-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:08:30.680: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-projected-configmaps-485fda4b-0415-11e9-acdd-0a580ac80107 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 05:08:30.698: INFO: Waiting for pod pod-projected-configmaps-485fda4b-0415-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:08:30.700: INFO: Pod pod-projected-configmaps-485fda4b-0415-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:08:30.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pwk7v" for this suite.
Dec 20 05:08:36.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:08:36.781: INFO: namespace: e2e-tests-projected-pwk7v, resource: bindings, ignored listing per whitelist
Dec 20 05:08:36.812: INFO: namespace e2e-tests-projected-pwk7v deletion completed in 6.108190525s

• [SLOW TEST:10.213 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:08:36.812: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 05:08:36.877: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e76079a-0415-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-zwhtc" to be "success or failure"
Dec 20 05:08:36.879: INFO: Pod "downwardapi-volume-4e76079a-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.952765ms
Dec 20 05:08:38.883: INFO: Pod "downwardapi-volume-4e76079a-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006263114s
Dec 20 05:08:40.934: INFO: Pod "downwardapi-volume-4e76079a-0415-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057039163s
STEP: Saw pod success
Dec 20 05:08:40.934: INFO: Pod "downwardapi-volume-4e76079a-0415-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:08:40.983: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downwardapi-volume-4e76079a-0415-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 05:08:41.043: INFO: Waiting for pod downwardapi-volume-4e76079a-0415-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:08:41.045: INFO: Pod downwardapi-volume-4e76079a-0415-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:08:41.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zwhtc" for this suite.
Dec 20 05:08:47.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:08:47.394: INFO: namespace: e2e-tests-projected-zwhtc, resource: bindings, ignored listing per whitelist
Dec 20 05:08:47.484: INFO: namespace e2e-tests-projected-zwhtc deletion completed in 6.11253623s

• [SLOW TEST:10.673 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:08:47.485: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1220 05:08:57.984199      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 20 05:08:57.984: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:08:57.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9rvlq" for this suite.
Dec 20 05:09:04.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:09:04.115: INFO: namespace: e2e-tests-gc-9rvlq, resource: bindings, ignored listing per whitelist
Dec 20 05:09:04.140: INFO: namespace e2e-tests-gc-9rvlq deletion completed in 6.105604595s

• [SLOW TEST:16.655 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:09:04.140: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 05:09:04.207: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 20 05:09:04.218: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:04.221: INFO: Number of nodes with available pods: 0
Dec 20 05:09:04.221: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 05:09:05.225: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:05.228: INFO: Number of nodes with available pods: 0
Dec 20 05:09:05.228: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 05:09:06.226: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:06.229: INFO: Number of nodes with available pods: 0
Dec 20 05:09:06.229: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 05:09:07.225: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:07.228: INFO: Number of nodes with available pods: 2
Dec 20 05:09:07.228: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 05:09:08.435: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:08.535: INFO: Number of nodes with available pods: 3
Dec 20 05:09:08.535: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 20 05:09:08.740: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:08.741: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:08.741: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:08.744: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:09.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:09.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:09.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:09.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:10.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:10.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:10.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:10.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:11.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:11.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:11.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:11.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:12.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:12.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:12.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:12.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:13.795: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:13.795: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:13.795: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:14.169: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:14.791: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:14.791: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:14.791: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:14.794: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:15.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:15.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:15.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:15.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:16.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:16.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:16.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:16.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:17.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:17.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:17.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:17.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:18.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:18.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:18.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:18.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:19.795: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:19.795: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:19.795: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:20.151: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:20.792: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:20.792: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:20.792: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:20.797: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:21.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:21.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:21.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:21.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:22.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:22.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:22.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:22.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:23.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:23.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:23.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:23.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:24.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:24.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:24.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:24.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:25.796: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:25.796: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:25.796: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:26.191: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:26.803: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:26.803: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:26.803: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:26.807: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:27.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:27.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:27.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:27.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:28.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:28.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:28.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:28.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:29.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:29.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:29.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:29.754: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:30.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:30.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:30.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:30.754: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:31.795: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:31.795: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:31.795: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:32.153: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:32.806: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:32.806: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:32.806: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:32.810: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:33.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:33.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:33.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:33.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:34.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:34.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:34.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:34.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:35.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:35.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:35.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:35.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:36.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:36.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:36.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:36.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:37.802: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:37.802: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:37.802: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:38.136: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:38.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:38.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:38.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:38.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:39.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:39.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:39.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:39.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:40.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:40.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:40.748: INFO: Pod daemon-set-ftmr9 is not available
Dec 20 05:09:40.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:40.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:41.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:41.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:41.748: INFO: Pod daemon-set-ftmr9 is not available
Dec 20 05:09:41.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:41.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:42.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:42.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:42.748: INFO: Pod daemon-set-ftmr9 is not available
Dec 20 05:09:42.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:42.988: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:43.845: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:43.845: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:43.845: INFO: Pod daemon-set-ftmr9 is not available
Dec 20 05:09:43.845: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:43.988: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:44.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:44.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:44.749: INFO: Pod daemon-set-ftmr9 is not available
Dec 20 05:09:44.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:44.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:45.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:45.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:45.749: INFO: Pod daemon-set-ftmr9 is not available
Dec 20 05:09:45.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:45.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:46.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:46.749: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:46.749: INFO: Pod daemon-set-ftmr9 is not available
Dec 20 05:09:46.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:46.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:47.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:47.748: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:47.748: INFO: Pod daemon-set-ftmr9 is not available
Dec 20 05:09:47.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:47.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:48.792: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:48.792: INFO: Wrong image for pod: daemon-set-ftmr9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:48.792: INFO: Pod daemon-set-ftmr9 is not available
Dec 20 05:09:48.792: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:49.186: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:49.750: INFO: Pod daemon-set-76tbh is not available
Dec 20 05:09:49.750: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:49.750: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:49.754: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:50.748: INFO: Pod daemon-set-76tbh is not available
Dec 20 05:09:50.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:50.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:50.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:51.748: INFO: Pod daemon-set-76tbh is not available
Dec 20 05:09:51.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:51.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:51.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:52.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:52.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:52.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:53.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:53.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:53.986: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:54.840: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:54.840: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:54.983: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:55.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:55.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:55.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:56.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:56.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:56.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:57.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:57.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:57.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:58.750: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:58.750: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:58.754: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:09:59.796: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:09:59.796: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:00.180: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:00.794: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:00.794: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:00.799: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:01.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:01.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:01.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:02.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:02.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:02.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:03.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:03.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:03.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:04.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:04.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:04.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:05.794: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:05.794: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:06.148: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:06.794: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:06.794: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:06.797: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:07.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:07.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:07.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:08.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:08.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:08.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:09.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:09.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:09.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:10.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:10.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:10.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:11.795: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:11.795: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:12.173: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:12.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:12.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:12.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:13.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:13.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:13.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:14.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:14.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:14.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:15.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:15.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:15.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:16.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:16.749: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:16.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:17.795: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:17.795: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:18.130: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:18.795: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:18.795: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:18.799: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:19.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:19.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:19.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:20.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:20.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:20.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:21.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:21.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:21.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:22.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:22.748: INFO: Wrong image for pod: daemon-set-glz2f. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:22.748: INFO: Pod daemon-set-glz2f is not available
Dec 20 05:10:22.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:23.794: INFO: Pod daemon-set-47t8j is not available
Dec 20 05:10:23.794: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:24.152: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:24.796: INFO: Pod daemon-set-47t8j is not available
Dec 20 05:10:24.796: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:24.800: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:25.748: INFO: Pod daemon-set-47t8j is not available
Dec 20 05:10:25.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:25.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:26.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:26.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:27.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:27.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:28.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:28.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:29.794: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:30.187: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:30.795: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:30.800: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:31.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:31.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:32.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:32.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:33.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:33.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:34.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:34.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:35.793: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:36.161: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:36.796: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:36.800: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:37.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:37.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:38.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:38.751: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:39.752: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:39.758: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:40.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:40.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:41.797: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:42.120: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:42.840: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:42.844: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:43.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:43.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:44.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:44.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:45.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:45.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:46.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:46.754: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:47.807: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:48.235: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:48.796: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:48.801: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:49.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:49.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:50.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:50.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:51.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:51.754: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:52.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:52.754: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:53.795: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:54.123: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:54.857: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:54.865: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:55.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:55.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:56.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:56.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:57.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:57.749: INFO: Pod daemon-set-9xv7w is not available
Dec 20 05:10:57.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:58.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:58.749: INFO: Pod daemon-set-9xv7w is not available
Dec 20 05:10:58.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:10:59.796: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:10:59.796: INFO: Pod daemon-set-9xv7w is not available
Dec 20 05:11:00.203: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:11:00.795: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:11:00.795: INFO: Pod daemon-set-9xv7w is not available
Dec 20 05:11:00.799: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:11:01.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:11:01.749: INFO: Pod daemon-set-9xv7w is not available
Dec 20 05:11:01.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:11:02.749: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:11:02.749: INFO: Pod daemon-set-9xv7w is not available
Dec 20 05:11:02.753: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:11:03.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:11:03.749: INFO: Pod daemon-set-9xv7w is not available
Dec 20 05:11:03.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:11:04.748: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:11:04.748: INFO: Pod daemon-set-9xv7w is not available
Dec 20 05:11:04.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:11:05.796: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:11:05.796: INFO: Pod daemon-set-9xv7w is not available
Dec 20 05:11:06.185: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:11:06.796: INFO: Wrong image for pod: daemon-set-9xv7w. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 20 05:11:06.796: INFO: Pod daemon-set-9xv7w is not available
Dec 20 05:11:06.801: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:11:07.748: INFO: Pod daemon-set-8lprp is not available
Dec 20 05:11:07.752: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 20 05:11:07.756: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:11:07.759: INFO: Number of nodes with available pods: 2
Dec 20 05:11:07.759: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 05:11:08.764: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:11:08.768: INFO: Number of nodes with available pods: 2
Dec 20 05:11:08.768: INFO: Node acsk8s-3f716c-k8s-worker-1 is running more than one daemon pod
Dec 20 05:11:09.764: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:11:09.767: INFO: Number of nodes with available pods: 3
Dec 20 05:11:09.767: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-dbckk, will wait for the garbage collector to delete the pods
Dec 20 05:11:09.848: INFO: Deleting {extensions DaemonSet} daemon-set took: 14.363211ms
Dec 20 05:11:09.948: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.239216ms
Dec 20 05:11:17.452: INFO: Number of nodes with available pods: 0
Dec 20 05:11:17.452: INFO: Number of running nodes: 0, number of available pods: 0
Dec 20 05:11:17.455: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dbckk/daemonsets","resourceVersion":"16609"},"items":null}

Dec 20 05:11:17.457: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dbckk/pods","resourceVersion":"16609"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:11:17.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dbckk" for this suite.
Dec 20 05:11:23.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:11:23.876: INFO: namespace: e2e-tests-daemonsets-dbckk, resource: bindings, ignored listing per whitelist
Dec 20 05:11:23.920: INFO: namespace e2e-tests-daemonsets-dbckk deletion completed in 6.102722976s

• [SLOW TEST:139.780 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:11:23.920: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 20 05:11:23.982: INFO: Waiting up to 5m0s for pod "downward-api-b21074b0-0415-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-v94p2" to be "success or failure"
Dec 20 05:11:23.984: INFO: Pod "downward-api-b21074b0-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.46466ms
Dec 20 05:11:25.988: INFO: Pod "downward-api-b21074b0-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006020337s
Dec 20 05:11:28.045: INFO: Pod "downward-api-b21074b0-0415-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063176514s
STEP: Saw pod success
Dec 20 05:11:28.045: INFO: Pod "downward-api-b21074b0-0415-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:11:28.090: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downward-api-b21074b0-0415-11e9-acdd-0a580ac80107 container dapi-container: <nil>
STEP: delete the pod
Dec 20 05:11:28.156: INFO: Waiting for pod downward-api-b21074b0-0415-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:11:28.159: INFO: Pod downward-api-b21074b0-0415-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:11:28.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v94p2" for this suite.
Dec 20 05:11:34.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:11:34.537: INFO: namespace: e2e-tests-downward-api-v94p2, resource: bindings, ignored listing per whitelist
Dec 20 05:11:34.593: INFO: namespace e2e-tests-downward-api-v94p2 deletion completed in 6.105050113s

• [SLOW TEST:10.673 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:11:34.593: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1220 05:12:05.063347      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 20 05:12:05.063: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:12:05.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jtnm8" for this suite.
Dec 20 05:12:11.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:12:11.146: INFO: namespace: e2e-tests-gc-jtnm8, resource: bindings, ignored listing per whitelist
Dec 20 05:12:11.178: INFO: namespace e2e-tests-gc-jtnm8 deletion completed in 6.109474231s

• [SLOW TEST:36.585 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:12:11.178: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ce3c15db-0415-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 05:12:11.250: INFO: Waiting up to 5m0s for pod "pod-secrets-ce3cc3af-0415-11e9-acdd-0a580ac80107" in namespace "e2e-tests-secrets-4rwvr" to be "success or failure"
Dec 20 05:12:11.256: INFO: Pod "pod-secrets-ce3cc3af-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.262226ms
Dec 20 05:12:13.259: INFO: Pod "pod-secrets-ce3cc3af-0415-11e9-acdd-0a580ac80107": Phase="Running", Reason="", readiness=true. Elapsed: 2.008694475s
Dec 20 05:12:15.263: INFO: Pod "pod-secrets-ce3cc3af-0415-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013059248s
STEP: Saw pod success
Dec 20 05:12:15.263: INFO: Pod "pod-secrets-ce3cc3af-0415-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:12:15.266: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-secrets-ce3cc3af-0415-11e9-acdd-0a580ac80107 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 05:12:15.287: INFO: Waiting for pod pod-secrets-ce3cc3af-0415-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:12:15.289: INFO: Pod pod-secrets-ce3cc3af-0415-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:12:15.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4rwvr" for this suite.
Dec 20 05:12:21.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:12:21.383: INFO: namespace: e2e-tests-secrets-4rwvr, resource: bindings, ignored listing per whitelist
Dec 20 05:12:21.395: INFO: namespace e2e-tests-secrets-4rwvr deletion completed in 6.096414393s

• [SLOW TEST:10.217 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:12:21.395: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec 20 05:12:21.449: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 20 05:12:21.454: INFO: Waiting for terminating namespaces to be deleted...
Dec 20 05:12:21.456: INFO: 
Logging pods the kubelet thinks is on node acsk8s-3f716c-k8s-worker-0 before test
Dec 20 05:12:21.462: INFO: kube-flannel-ds-hgmsk from kube-system started at 2018-12-20 03:28:31 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.462: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 20 05:12:21.462: INFO: prometheus-k8s-0 from monitoring started at 2018-12-20 03:32:08 +0000 UTC (3 container statuses recorded)
Dec 20 05:12:21.462: INFO: 	Container prometheus ready: true, restart count 1
Dec 20 05:12:21.463: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Dec 20 05:12:21.463: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Dec 20 05:12:21.463: INFO: alertmanager-main-2 from monitoring started at 2018-12-20 03:32:25 +0000 UTC (2 container statuses recorded)
Dec 20 05:12:21.463: INFO: 	Container alertmanager ready: true, restart count 0
Dec 20 05:12:21.463: INFO: 	Container config-reloader ready: true, restart count 0
Dec 20 05:12:21.463: INFO: kube-proxy-ds-fcgv7 from kube-system started at 2018-12-20 03:28:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.463: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 05:12:21.463: INFO: fluent-bit-9jlsp from kube-system started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.463: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 20 05:12:21.463: INFO: kibana-logging-557ddfb798-25hl8 from ntnx-logging started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.463: INFO: 	Container kibana-logging ready: true, restart count 0
Dec 20 05:12:21.463: INFO: prometheus-operator-6494c4f69b-rz2bs from monitoring started at 2018-12-20 03:31:49 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.463: INFO: 	Container prometheus-operator ready: true, restart count 0
Dec 20 05:12:21.463: INFO: node-exporter-6bq8k from monitoring started at 2018-12-20 03:31:50 +0000 UTC (2 container statuses recorded)
Dec 20 05:12:21.463: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 20 05:12:21.463: INFO: 	Container node-exporter ready: true, restart count 0
Dec 20 05:12:21.463: INFO: sonobuoy-e2e-job-8437e4dc2d8146dc from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:12:21.463: INFO: 	Container e2e ready: true, restart count 0
Dec 20 05:12:21.463: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 20 05:12:21.463: INFO: sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-7j587 from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:12:21.463: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 20 05:12:21.463: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 20 05:12:21.463: INFO: 
Logging pods the kubelet thinks is on node acsk8s-3f716c-k8s-worker-1 before test
Dec 20 05:12:21.469: INFO: alertmanager-main-1 from monitoring started at 2018-12-20 03:32:14 +0000 UTC (2 container statuses recorded)
Dec 20 05:12:21.469: INFO: 	Container alertmanager ready: true, restart count 0
Dec 20 05:12:21.469: INFO: 	Container config-reloader ready: true, restart count 0
Dec 20 05:12:21.469: INFO: kube-proxy-ds-8spq8 from kube-system started at 2018-12-20 03:28:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.469: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 05:12:21.469: INFO: fluent-bit-tpqjx from kube-system started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.469: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 20 05:12:21.469: INFO: elasticsearch-logging-0 from ntnx-logging started at 2018-12-20 03:29:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.469: INFO: 	Container elasticsearch-logging ready: true, restart count 0
Dec 20 05:12:21.469: INFO: prometheus-k8s-1 from monitoring started at 2018-12-20 03:32:25 +0000 UTC (3 container statuses recorded)
Dec 20 05:12:21.469: INFO: 	Container prometheus ready: true, restart count 1
Dec 20 05:12:21.469: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Dec 20 05:12:21.469: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Dec 20 05:12:21.469: INFO: node-exporter-qp54z from monitoring started at 2018-12-20 03:31:50 +0000 UTC (2 container statuses recorded)
Dec 20 05:12:21.469: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 20 05:12:21.469: INFO: 	Container node-exporter ready: true, restart count 0
Dec 20 05:12:21.469: INFO: sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-9jw8w from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:12:21.469: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 20 05:12:21.469: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 20 05:12:21.469: INFO: kube-flannel-ds-jsn8t from kube-system started at 2018-12-20 03:28:31 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.469: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 20 05:12:21.469: INFO: 
Logging pods the kubelet thinks is on node acsk8s-3f716c-k8s-worker-2 before test
Dec 20 05:12:21.499: INFO: kube-proxy-ds-6h5q6 from kube-system started at 2018-12-20 03:28:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.499: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 05:12:21.499: INFO: kube-flannel-ds-dgwvj from kube-system started at 2018-12-20 03:28:31 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.499: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 20 05:12:21.499: INFO: fluent-bit-7v27c from kube-system started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.499: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 20 05:12:21.499: INFO: sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-g55ds from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:12:21.499: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 20 05:12:21.499: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 20 05:12:21.499: INFO: kubernetes-events-printer-57f7df584d-zdrps from ntnx-logging started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.499: INFO: 	Container kubernetes-events-printer ready: true, restart count 0
Dec 20 05:12:21.499: INFO: node-exporter-g96wx from monitoring started at 2018-12-20 03:31:50 +0000 UTC (2 container statuses recorded)
Dec 20 05:12:21.499: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 20 05:12:21.499: INFO: 	Container node-exporter ready: true, restart count 0
Dec 20 05:12:21.499: INFO: alertmanager-main-0 from monitoring started at 2018-12-20 03:32:00 +0000 UTC (2 container statuses recorded)
Dec 20 05:12:21.499: INFO: 	Container alertmanager ready: true, restart count 0
Dec 20 05:12:21.499: INFO: 	Container config-reloader ready: true, restart count 0
Dec 20 05:12:21.499: INFO: kube-state-metrics-58649d5448-bwppx from monitoring started at 2018-12-20 03:32:09 +0000 UTC (4 container statuses recorded)
Dec 20 05:12:21.499: INFO: 	Container addon-resizer ready: true, restart count 0
Dec 20 05:12:21.499: INFO: 	Container kube-rbac-proxy-main ready: true, restart count 0
Dec 20 05:12:21.499: INFO: 	Container kube-rbac-proxy-self ready: true, restart count 0
Dec 20 05:12:21.499: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec 20 05:12:21.499: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-20 04:01:45 +0000 UTC (1 container statuses recorded)
Dec 20 05:12:21.499: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1571f27755ea1c77], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:12:22.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-shrzs" for this suite.
Dec 20 05:12:28.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:12:28.624: INFO: namespace: e2e-tests-sched-pred-shrzs, resource: bindings, ignored listing per whitelist
Dec 20 05:12:28.641: INFO: namespace e2e-tests-sched-pred-shrzs deletion completed in 6.110044181s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.246 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:12:28.641: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d8a4b582-0415-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 05:12:28.713: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d8a5911c-0415-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-g4g74" to be "success or failure"
Dec 20 05:12:28.718: INFO: Pod "pod-projected-configmaps-d8a5911c-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.807631ms
Dec 20 05:12:30.721: INFO: Pod "pod-projected-configmaps-d8a5911c-0415-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008235298s
Dec 20 05:12:32.784: INFO: Pod "pod-projected-configmaps-d8a5911c-0415-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071692154s
STEP: Saw pod success
Dec 20 05:12:32.784: INFO: Pod "pod-projected-configmaps-d8a5911c-0415-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:12:32.831: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-projected-configmaps-d8a5911c-0415-11e9-acdd-0a580ac80107 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 05:12:32.912: INFO: Waiting for pod pod-projected-configmaps-d8a5911c-0415-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:12:32.914: INFO: Pod pod-projected-configmaps-d8a5911c-0415-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:12:32.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g4g74" for this suite.
Dec 20 05:12:39.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:12:39.299: INFO: namespace: e2e-tests-projected-g4g74, resource: bindings, ignored listing per whitelist
Dec 20 05:12:39.368: INFO: namespace e2e-tests-projected-g4g74 deletion completed in 6.116386158s

• [SLOW TEST:10.727 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:12:39.368: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-gccbh
Dec 20 05:12:43.438: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-gccbh
STEP: checking the pod's current state and verifying that restartCount is present
Dec 20 05:12:43.440: INFO: Initial restart count of pod liveness-exec is 0
Dec 20 05:13:33.531: INFO: Restart count of pod e2e-tests-container-probe-gccbh/liveness-exec is now 1 (50.09151867s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:13:33.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gccbh" for this suite.
Dec 20 05:13:39.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:13:39.827: INFO: namespace: e2e-tests-container-probe-gccbh, resource: bindings, ignored listing per whitelist
Dec 20 05:13:39.881: INFO: namespace e2e-tests-container-probe-gccbh deletion completed in 6.102108959s

• [SLOW TEST:60.513 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:13:39.881: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Dec 20 05:13:39.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-6ddx8'
Dec 20 05:13:40.302: INFO: stderr: ""
Dec 20 05:13:40.302: INFO: stdout: "pod/pause created\n"
Dec 20 05:13:40.302: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 20 05:13:40.302: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-6ddx8" to be "running and ready"
Dec 20 05:13:40.305: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.181116ms
Dec 20 05:13:42.308: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006287249s
Dec 20 05:13:44.313: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.010575514s
Dec 20 05:13:44.313: INFO: Pod "pause" satisfied condition "running and ready"
Dec 20 05:13:44.313: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 20 05:13:44.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-6ddx8'
Dec 20 05:13:44.564: INFO: stderr: ""
Dec 20 05:13:44.564: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 20 05:13:44.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6ddx8'
Dec 20 05:13:44.761: INFO: stderr: ""
Dec 20 05:13:44.761: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 20 05:13:44.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 label pods pause testing-label- --namespace=e2e-tests-kubectl-6ddx8'
Dec 20 05:13:45.023: INFO: stderr: ""
Dec 20 05:13:45.023: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 20 05:13:45.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6ddx8'
Dec 20 05:13:45.220: INFO: stderr: ""
Dec 20 05:13:45.220: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Dec 20 05:13:45.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6ddx8'
Dec 20 05:13:45.337: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 05:13:45.337: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 20 05:13:45.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-6ddx8'
Dec 20 05:13:45.456: INFO: stderr: "No resources found.\n"
Dec 20 05:13:45.456: INFO: stdout: ""
Dec 20 05:13:45.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 get pods -l name=pause --namespace=e2e-tests-kubectl-6ddx8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 20 05:13:45.563: INFO: stderr: ""
Dec 20 05:13:45.564: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:13:45.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6ddx8" for this suite.
Dec 20 05:13:51.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:13:51.587: INFO: namespace: e2e-tests-kubectl-6ddx8, resource: bindings, ignored listing per whitelist
Dec 20 05:13:51.673: INFO: namespace e2e-tests-kubectl-6ddx8 deletion completed in 6.10600105s

• [SLOW TEST:11.792 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:13:51.673: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-x4wq5
I1220 05:13:51.737257      18 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-x4wq5, replica count: 1
I1220 05:13:52.787724      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 05:13:53.787899      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 05:13:54.788112      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 20 05:13:54.905: INFO: Created: latency-svc-vmrtt
Dec 20 05:13:54.917: INFO: Got endpoints: latency-svc-vmrtt [29.165137ms]
Dec 20 05:13:54.928: INFO: Created: latency-svc-qmg4g
Dec 20 05:13:54.938: INFO: Created: latency-svc-j4gq9
Dec 20 05:13:54.938: INFO: Got endpoints: latency-svc-qmg4g [20.393956ms]
Dec 20 05:13:54.946: INFO: Got endpoints: latency-svc-j4gq9 [28.299762ms]
Dec 20 05:13:54.949: INFO: Created: latency-svc-7vdj9
Dec 20 05:13:54.955: INFO: Got endpoints: latency-svc-7vdj9 [37.198384ms]
Dec 20 05:13:54.961: INFO: Created: latency-svc-4nfj9
Dec 20 05:13:54.970: INFO: Created: latency-svc-dq862
Dec 20 05:13:54.976: INFO: Got endpoints: latency-svc-4nfj9 [58.186997ms]
Dec 20 05:13:54.980: INFO: Got endpoints: latency-svc-dq862 [61.901224ms]
Dec 20 05:13:54.982: INFO: Created: latency-svc-5slk4
Dec 20 05:13:54.991: INFO: Got endpoints: latency-svc-5slk4 [73.44542ms]
Dec 20 05:13:54.994: INFO: Created: latency-svc-qz4gj
Dec 20 05:13:55.004: INFO: Got endpoints: latency-svc-qz4gj [86.080368ms]
Dec 20 05:13:55.006: INFO: Created: latency-svc-jw2qq
Dec 20 05:13:55.015: INFO: Got endpoints: latency-svc-jw2qq [97.17451ms]
Dec 20 05:13:55.016: INFO: Created: latency-svc-9xcj8
Dec 20 05:13:55.027: INFO: Got endpoints: latency-svc-9xcj8 [109.050141ms]
Dec 20 05:13:55.030: INFO: Created: latency-svc-rjnjb
Dec 20 05:13:55.037: INFO: Got endpoints: latency-svc-rjnjb [118.779774ms]
Dec 20 05:13:55.038: INFO: Created: latency-svc-kgnlq
Dec 20 05:13:55.050: INFO: Created: latency-svc-92pjd
Dec 20 05:13:55.050: INFO: Got endpoints: latency-svc-kgnlq [132.092114ms]
Dec 20 05:13:55.062: INFO: Got endpoints: latency-svc-92pjd [144.555003ms]
Dec 20 05:13:55.065: INFO: Created: latency-svc-b57wg
Dec 20 05:13:55.078: INFO: Got endpoints: latency-svc-b57wg [160.121844ms]
Dec 20 05:13:55.081: INFO: Created: latency-svc-fnw9l
Dec 20 05:13:55.092: INFO: Got endpoints: latency-svc-fnw9l [174.191727ms]
Dec 20 05:13:55.105: INFO: Created: latency-svc-9pp27
Dec 20 05:13:55.106: INFO: Created: latency-svc-87hv4
Dec 20 05:13:55.107: INFO: Got endpoints: latency-svc-9pp27 [189.40403ms]
Dec 20 05:13:55.118: INFO: Got endpoints: latency-svc-87hv4 [179.613093ms]
Dec 20 05:13:55.126: INFO: Created: latency-svc-4p4km
Dec 20 05:13:55.136: INFO: Created: latency-svc-7dbqn
Dec 20 05:13:55.137: INFO: Got endpoints: latency-svc-4p4km [191.693629ms]
Dec 20 05:13:55.149: INFO: Got endpoints: latency-svc-7dbqn [194.135016ms]
Dec 20 05:13:55.150: INFO: Created: latency-svc-xf94m
Dec 20 05:13:55.157: INFO: Got endpoints: latency-svc-xf94m [180.862784ms]
Dec 20 05:13:55.162: INFO: Created: latency-svc-mnhfk
Dec 20 05:13:55.169: INFO: Got endpoints: latency-svc-mnhfk [189.694697ms]
Dec 20 05:13:55.174: INFO: Created: latency-svc-vkmc7
Dec 20 05:13:55.183: INFO: Got endpoints: latency-svc-vkmc7 [191.381777ms]
Dec 20 05:13:55.185: INFO: Created: latency-svc-c9ddc
Dec 20 05:13:55.191: INFO: Got endpoints: latency-svc-c9ddc [186.940246ms]
Dec 20 05:13:55.204: INFO: Created: latency-svc-rjs6s
Dec 20 05:13:55.212: INFO: Got endpoints: latency-svc-rjs6s [197.153411ms]
Dec 20 05:13:55.216: INFO: Created: latency-svc-7w55r
Dec 20 05:13:55.219: INFO: Created: latency-svc-kdhj9
Dec 20 05:13:55.221: INFO: Got endpoints: latency-svc-7w55r [193.938359ms]
Dec 20 05:13:55.229: INFO: Got endpoints: latency-svc-kdhj9 [192.192827ms]
Dec 20 05:13:55.234: INFO: Created: latency-svc-6lb8v
Dec 20 05:13:55.249: INFO: Created: latency-svc-rn7bv
Dec 20 05:13:55.249: INFO: Got endpoints: latency-svc-rn7bv [186.618317ms]
Dec 20 05:13:55.249: INFO: Got endpoints: latency-svc-6lb8v [199.077596ms]
Dec 20 05:13:55.255: INFO: Created: latency-svc-bq897
Dec 20 05:13:55.261: INFO: Got endpoints: latency-svc-bq897 [182.834163ms]
Dec 20 05:13:55.263: INFO: Created: latency-svc-qn5j6
Dec 20 05:13:55.274: INFO: Created: latency-svc-59j4d
Dec 20 05:13:55.274: INFO: Got endpoints: latency-svc-qn5j6 [181.982038ms]
Dec 20 05:13:55.284: INFO: Got endpoints: latency-svc-59j4d [176.333834ms]
Dec 20 05:13:55.290: INFO: Created: latency-svc-vg222
Dec 20 05:13:55.294: INFO: Got endpoints: latency-svc-vg222 [176.452826ms]
Dec 20 05:13:55.299: INFO: Created: latency-svc-lz9nc
Dec 20 05:13:55.306: INFO: Got endpoints: latency-svc-lz9nc [169.124577ms]
Dec 20 05:13:55.308: INFO: Created: latency-svc-rdt22
Dec 20 05:13:55.317: INFO: Got endpoints: latency-svc-rdt22 [168.125849ms]
Dec 20 05:13:55.319: INFO: Created: latency-svc-47vzl
Dec 20 05:13:55.327: INFO: Created: latency-svc-dqz8w
Dec 20 05:13:55.334: INFO: Created: latency-svc-tj4vg
Dec 20 05:13:55.337: INFO: Got endpoints: latency-svc-47vzl [180.574412ms]
Dec 20 05:13:55.344: INFO: Got endpoints: latency-svc-tj4vg [160.759433ms]
Dec 20 05:13:55.344: INFO: Got endpoints: latency-svc-dqz8w [174.085072ms]
Dec 20 05:13:55.347: INFO: Created: latency-svc-gpcxf
Dec 20 05:13:55.354: INFO: Got endpoints: latency-svc-gpcxf [162.819292ms]
Dec 20 05:13:55.359: INFO: Created: latency-svc-25lsz
Dec 20 05:13:55.365: INFO: Got endpoints: latency-svc-25lsz [152.610689ms]
Dec 20 05:13:55.374: INFO: Created: latency-svc-t954q
Dec 20 05:13:55.384: INFO: Created: latency-svc-x4ckn
Dec 20 05:13:55.392: INFO: Created: latency-svc-9l8zd
Dec 20 05:13:55.402: INFO: Created: latency-svc-6rf7p
Dec 20 05:13:55.407: INFO: Created: latency-svc-p8rbb
Dec 20 05:13:55.418: INFO: Got endpoints: latency-svc-t954q [197.347382ms]
Dec 20 05:13:55.422: INFO: Created: latency-svc-hpv4m
Dec 20 05:13:55.426: INFO: Created: latency-svc-fhf55
Dec 20 05:13:55.437: INFO: Created: latency-svc-b826r
Dec 20 05:13:55.446: INFO: Created: latency-svc-8psbp
Dec 20 05:13:55.452: INFO: Created: latency-svc-spqwb
Dec 20 05:13:55.466: INFO: Got endpoints: latency-svc-x4ckn [236.695182ms]
Dec 20 05:13:55.466: INFO: Created: latency-svc-bz4dj
Dec 20 05:13:55.475: INFO: Created: latency-svc-t2m6k
Dec 20 05:13:55.484: INFO: Created: latency-svc-ldg6r
Dec 20 05:13:55.495: INFO: Created: latency-svc-w8ksd
Dec 20 05:13:55.502: INFO: Created: latency-svc-wh26f
Dec 20 05:13:55.507: INFO: Created: latency-svc-fbnsz
Dec 20 05:13:55.518: INFO: Created: latency-svc-x9drt
Dec 20 05:13:55.519: INFO: Got endpoints: latency-svc-9l8zd [269.610494ms]
Dec 20 05:13:55.532: INFO: Created: latency-svc-8f6qz
Dec 20 05:13:55.562: INFO: Got endpoints: latency-svc-6rf7p [312.881915ms]
Dec 20 05:13:55.577: INFO: Created: latency-svc-kd69w
Dec 20 05:13:55.618: INFO: Got endpoints: latency-svc-p8rbb [356.70892ms]
Dec 20 05:13:55.633: INFO: Created: latency-svc-bh8vn
Dec 20 05:13:55.662: INFO: Got endpoints: latency-svc-hpv4m [387.721151ms]
Dec 20 05:13:55.677: INFO: Created: latency-svc-x2qb8
Dec 20 05:13:55.712: INFO: Got endpoints: latency-svc-fhf55 [427.807738ms]
Dec 20 05:13:55.723: INFO: Created: latency-svc-wsqtq
Dec 20 05:13:55.763: INFO: Got endpoints: latency-svc-b826r [469.078478ms]
Dec 20 05:13:55.778: INFO: Created: latency-svc-7sbh9
Dec 20 05:13:55.812: INFO: Got endpoints: latency-svc-8psbp [505.147514ms]
Dec 20 05:13:55.829: INFO: Created: latency-svc-q7cmw
Dec 20 05:13:55.861: INFO: Got endpoints: latency-svc-spqwb [543.762246ms]
Dec 20 05:13:55.882: INFO: Created: latency-svc-lmqmj
Dec 20 05:13:55.916: INFO: Got endpoints: latency-svc-bz4dj [578.154427ms]
Dec 20 05:13:55.949: INFO: Created: latency-svc-fkk72
Dec 20 05:13:55.961: INFO: Got endpoints: latency-svc-t2m6k [617.749921ms]
Dec 20 05:13:55.972: INFO: Created: latency-svc-6btbn
Dec 20 05:13:56.016: INFO: Got endpoints: latency-svc-ldg6r [672.138711ms]
Dec 20 05:13:56.032: INFO: Created: latency-svc-4mvd9
Dec 20 05:13:56.064: INFO: Got endpoints: latency-svc-w8ksd [710.429355ms]
Dec 20 05:13:56.076: INFO: Created: latency-svc-xczmv
Dec 20 05:13:56.113: INFO: Got endpoints: latency-svc-wh26f [748.147117ms]
Dec 20 05:13:56.126: INFO: Created: latency-svc-j5s2l
Dec 20 05:13:56.171: INFO: Got endpoints: latency-svc-fbnsz [752.468297ms]
Dec 20 05:13:56.185: INFO: Created: latency-svc-tgqnq
Dec 20 05:13:56.213: INFO: Got endpoints: latency-svc-x9drt [747.509812ms]
Dec 20 05:13:56.229: INFO: Created: latency-svc-948t5
Dec 20 05:13:56.263: INFO: Got endpoints: latency-svc-8f6qz [744.373977ms]
Dec 20 05:13:56.276: INFO: Created: latency-svc-r6hqt
Dec 20 05:13:56.315: INFO: Got endpoints: latency-svc-kd69w [752.840878ms]
Dec 20 05:13:56.333: INFO: Created: latency-svc-bxccv
Dec 20 05:13:56.366: INFO: Got endpoints: latency-svc-bh8vn [747.979518ms]
Dec 20 05:13:56.384: INFO: Created: latency-svc-dq6v2
Dec 20 05:13:56.411: INFO: Got endpoints: latency-svc-x2qb8 [749.435326ms]
Dec 20 05:13:56.423: INFO: Created: latency-svc-xp42c
Dec 20 05:13:56.464: INFO: Got endpoints: latency-svc-wsqtq [752.579439ms]
Dec 20 05:13:56.480: INFO: Created: latency-svc-rcv6p
Dec 20 05:13:56.511: INFO: Got endpoints: latency-svc-7sbh9 [748.22867ms]
Dec 20 05:13:56.528: INFO: Created: latency-svc-t7sdq
Dec 20 05:13:56.563: INFO: Got endpoints: latency-svc-q7cmw [751.566984ms]
Dec 20 05:13:56.580: INFO: Created: latency-svc-79hl9
Dec 20 05:13:56.611: INFO: Got endpoints: latency-svc-lmqmj [750.083245ms]
Dec 20 05:13:56.623: INFO: Created: latency-svc-2csq9
Dec 20 05:13:56.661: INFO: Got endpoints: latency-svc-fkk72 [745.73538ms]
Dec 20 05:13:56.674: INFO: Created: latency-svc-5vbc9
Dec 20 05:13:56.715: INFO: Got endpoints: latency-svc-6btbn [753.92611ms]
Dec 20 05:13:56.730: INFO: Created: latency-svc-wfnrk
Dec 20 05:13:56.764: INFO: Got endpoints: latency-svc-4mvd9 [747.729359ms]
Dec 20 05:13:56.788: INFO: Created: latency-svc-pvsbc
Dec 20 05:13:56.813: INFO: Got endpoints: latency-svc-xczmv [748.470292ms]
Dec 20 05:13:56.826: INFO: Created: latency-svc-r8nq7
Dec 20 05:13:56.868: INFO: Got endpoints: latency-svc-j5s2l [755.290484ms]
Dec 20 05:13:56.883: INFO: Created: latency-svc-vtnf5
Dec 20 05:13:56.918: INFO: Got endpoints: latency-svc-tgqnq [746.993992ms]
Dec 20 05:13:56.934: INFO: Created: latency-svc-fw8jp
Dec 20 05:13:56.967: INFO: Got endpoints: latency-svc-948t5 [753.375936ms]
Dec 20 05:13:56.989: INFO: Created: latency-svc-5hj4d
Dec 20 05:13:57.017: INFO: Got endpoints: latency-svc-r6hqt [753.913276ms]
Dec 20 05:13:57.037: INFO: Created: latency-svc-j6bz4
Dec 20 05:13:57.070: INFO: Got endpoints: latency-svc-bxccv [755.401143ms]
Dec 20 05:13:57.090: INFO: Created: latency-svc-ffxlv
Dec 20 05:13:57.115: INFO: Got endpoints: latency-svc-dq6v2 [749.505071ms]
Dec 20 05:13:57.132: INFO: Created: latency-svc-mwd4t
Dec 20 05:13:57.162: INFO: Got endpoints: latency-svc-xp42c [750.092345ms]
Dec 20 05:13:57.174: INFO: Created: latency-svc-kt6hg
Dec 20 05:13:57.213: INFO: Got endpoints: latency-svc-rcv6p [749.11465ms]
Dec 20 05:13:57.231: INFO: Created: latency-svc-htm45
Dec 20 05:13:57.261: INFO: Got endpoints: latency-svc-t7sdq [749.495965ms]
Dec 20 05:13:57.275: INFO: Created: latency-svc-phz8g
Dec 20 05:13:57.312: INFO: Got endpoints: latency-svc-79hl9 [748.860068ms]
Dec 20 05:13:57.325: INFO: Created: latency-svc-dtxkf
Dec 20 05:13:57.365: INFO: Got endpoints: latency-svc-2csq9 [753.316384ms]
Dec 20 05:13:57.381: INFO: Created: latency-svc-tclsl
Dec 20 05:13:57.414: INFO: Got endpoints: latency-svc-5vbc9 [752.695269ms]
Dec 20 05:13:57.437: INFO: Created: latency-svc-7qbgs
Dec 20 05:13:57.462: INFO: Got endpoints: latency-svc-wfnrk [746.73145ms]
Dec 20 05:13:57.481: INFO: Created: latency-svc-7r2z2
Dec 20 05:13:57.513: INFO: Got endpoints: latency-svc-pvsbc [749.549194ms]
Dec 20 05:13:57.528: INFO: Created: latency-svc-44l4p
Dec 20 05:13:57.561: INFO: Got endpoints: latency-svc-r8nq7 [748.234675ms]
Dec 20 05:13:57.573: INFO: Created: latency-svc-47p4m
Dec 20 05:13:57.614: INFO: Got endpoints: latency-svc-vtnf5 [745.5347ms]
Dec 20 05:13:57.626: INFO: Created: latency-svc-pdll5
Dec 20 05:13:57.669: INFO: Got endpoints: latency-svc-fw8jp [750.991133ms]
Dec 20 05:13:57.680: INFO: Created: latency-svc-8nrst
Dec 20 05:13:57.714: INFO: Got endpoints: latency-svc-5hj4d [747.066524ms]
Dec 20 05:13:57.725: INFO: Created: latency-svc-lxqxj
Dec 20 05:13:57.763: INFO: Got endpoints: latency-svc-j6bz4 [745.622842ms]
Dec 20 05:13:57.779: INFO: Created: latency-svc-sbm4w
Dec 20 05:13:57.812: INFO: Got endpoints: latency-svc-ffxlv [741.750782ms]
Dec 20 05:13:57.825: INFO: Created: latency-svc-cx96c
Dec 20 05:13:57.863: INFO: Got endpoints: latency-svc-mwd4t [747.861017ms]
Dec 20 05:13:57.873: INFO: Created: latency-svc-vmcqd
Dec 20 05:13:57.919: INFO: Got endpoints: latency-svc-kt6hg [756.986652ms]
Dec 20 05:13:57.943: INFO: Created: latency-svc-8kh5p
Dec 20 05:13:57.963: INFO: Got endpoints: latency-svc-htm45 [749.46099ms]
Dec 20 05:13:57.976: INFO: Created: latency-svc-cl5gt
Dec 20 05:13:58.014: INFO: Got endpoints: latency-svc-phz8g [753.203492ms]
Dec 20 05:13:58.032: INFO: Created: latency-svc-t5fn8
Dec 20 05:13:58.067: INFO: Got endpoints: latency-svc-dtxkf [754.752077ms]
Dec 20 05:13:58.084: INFO: Created: latency-svc-tcbz5
Dec 20 05:13:58.113: INFO: Got endpoints: latency-svc-tclsl [748.703869ms]
Dec 20 05:13:58.131: INFO: Created: latency-svc-xmhxs
Dec 20 05:13:58.163: INFO: Got endpoints: latency-svc-7qbgs [748.731589ms]
Dec 20 05:13:58.176: INFO: Created: latency-svc-grbrc
Dec 20 05:13:58.213: INFO: Got endpoints: latency-svc-7r2z2 [750.75602ms]
Dec 20 05:13:58.226: INFO: Created: latency-svc-zcxfs
Dec 20 05:13:58.263: INFO: Got endpoints: latency-svc-44l4p [749.704059ms]
Dec 20 05:13:58.276: INFO: Created: latency-svc-f59p5
Dec 20 05:13:58.313: INFO: Got endpoints: latency-svc-47p4m [752.189309ms]
Dec 20 05:13:58.326: INFO: Created: latency-svc-zhzx9
Dec 20 05:13:58.362: INFO: Got endpoints: latency-svc-pdll5 [747.686299ms]
Dec 20 05:13:58.375: INFO: Created: latency-svc-x2qlp
Dec 20 05:13:58.414: INFO: Got endpoints: latency-svc-8nrst [744.729079ms]
Dec 20 05:13:58.427: INFO: Created: latency-svc-lmq5r
Dec 20 05:13:58.464: INFO: Got endpoints: latency-svc-lxqxj [749.87568ms]
Dec 20 05:13:58.477: INFO: Created: latency-svc-8ttcs
Dec 20 05:13:58.512: INFO: Got endpoints: latency-svc-sbm4w [749.182007ms]
Dec 20 05:13:58.528: INFO: Created: latency-svc-zhh2v
Dec 20 05:13:58.563: INFO: Got endpoints: latency-svc-cx96c [750.424069ms]
Dec 20 05:13:58.581: INFO: Created: latency-svc-h7v68
Dec 20 05:13:58.614: INFO: Got endpoints: latency-svc-vmcqd [750.735537ms]
Dec 20 05:13:58.628: INFO: Created: latency-svc-jxtzm
Dec 20 05:13:58.663: INFO: Got endpoints: latency-svc-8kh5p [744.317131ms]
Dec 20 05:13:58.677: INFO: Created: latency-svc-mf757
Dec 20 05:13:58.713: INFO: Got endpoints: latency-svc-cl5gt [749.820696ms]
Dec 20 05:13:58.726: INFO: Created: latency-svc-zrhv9
Dec 20 05:13:58.765: INFO: Got endpoints: latency-svc-t5fn8 [750.951397ms]
Dec 20 05:13:58.783: INFO: Created: latency-svc-fxxsm
Dec 20 05:13:58.813: INFO: Got endpoints: latency-svc-tcbz5 [745.56471ms]
Dec 20 05:13:58.832: INFO: Created: latency-svc-p598k
Dec 20 05:13:58.864: INFO: Got endpoints: latency-svc-xmhxs [750.218054ms]
Dec 20 05:13:58.880: INFO: Created: latency-svc-qcjjr
Dec 20 05:13:58.949: INFO: Got endpoints: latency-svc-grbrc [786.362323ms]
Dec 20 05:13:58.964: INFO: Got endpoints: latency-svc-zcxfs [750.808784ms]
Dec 20 05:13:58.971: INFO: Created: latency-svc-wxpvz
Dec 20 05:13:58.979: INFO: Created: latency-svc-nq9sp
Dec 20 05:13:59.014: INFO: Got endpoints: latency-svc-f59p5 [751.435172ms]
Dec 20 05:13:59.042: INFO: Created: latency-svc-ghgm7
Dec 20 05:13:59.063: INFO: Got endpoints: latency-svc-zhzx9 [749.119737ms]
Dec 20 05:13:59.078: INFO: Created: latency-svc-pk4s7
Dec 20 05:13:59.116: INFO: Got endpoints: latency-svc-x2qlp [754.448213ms]
Dec 20 05:13:59.131: INFO: Created: latency-svc-nwq8r
Dec 20 05:13:59.165: INFO: Got endpoints: latency-svc-lmq5r [751.140561ms]
Dec 20 05:13:59.177: INFO: Created: latency-svc-dn2xz
Dec 20 05:13:59.212: INFO: Got endpoints: latency-svc-8ttcs [747.850031ms]
Dec 20 05:13:59.231: INFO: Created: latency-svc-zlt7v
Dec 20 05:13:59.262: INFO: Got endpoints: latency-svc-zhh2v [749.635718ms]
Dec 20 05:13:59.285: INFO: Created: latency-svc-vvqcl
Dec 20 05:13:59.315: INFO: Got endpoints: latency-svc-h7v68 [752.278303ms]
Dec 20 05:13:59.333: INFO: Created: latency-svc-crgfd
Dec 20 05:13:59.363: INFO: Got endpoints: latency-svc-jxtzm [748.997659ms]
Dec 20 05:13:59.377: INFO: Created: latency-svc-lnrlz
Dec 20 05:13:59.415: INFO: Got endpoints: latency-svc-mf757 [751.847899ms]
Dec 20 05:13:59.426: INFO: Created: latency-svc-fhpk7
Dec 20 05:13:59.462: INFO: Got endpoints: latency-svc-zrhv9 [748.892356ms]
Dec 20 05:13:59.473: INFO: Created: latency-svc-p68td
Dec 20 05:13:59.513: INFO: Got endpoints: latency-svc-fxxsm [748.131905ms]
Dec 20 05:13:59.533: INFO: Created: latency-svc-r4khx
Dec 20 05:13:59.565: INFO: Got endpoints: latency-svc-p598k [752.347418ms]
Dec 20 05:13:59.584: INFO: Created: latency-svc-69pg8
Dec 20 05:13:59.613: INFO: Got endpoints: latency-svc-qcjjr [749.773857ms]
Dec 20 05:13:59.634: INFO: Created: latency-svc-8q9tm
Dec 20 05:13:59.662: INFO: Got endpoints: latency-svc-wxpvz [712.608547ms]
Dec 20 05:13:59.676: INFO: Created: latency-svc-wwwzs
Dec 20 05:13:59.713: INFO: Got endpoints: latency-svc-nq9sp [749.013229ms]
Dec 20 05:13:59.728: INFO: Created: latency-svc-hvnv8
Dec 20 05:13:59.765: INFO: Got endpoints: latency-svc-ghgm7 [750.56399ms]
Dec 20 05:13:59.780: INFO: Created: latency-svc-c4969
Dec 20 05:13:59.811: INFO: Got endpoints: latency-svc-pk4s7 [748.392198ms]
Dec 20 05:13:59.830: INFO: Created: latency-svc-7gt76
Dec 20 05:13:59.864: INFO: Got endpoints: latency-svc-nwq8r [747.55743ms]
Dec 20 05:13:59.882: INFO: Created: latency-svc-6jjm6
Dec 20 05:13:59.916: INFO: Got endpoints: latency-svc-dn2xz [751.225811ms]
Dec 20 05:13:59.939: INFO: Created: latency-svc-cpq54
Dec 20 05:13:59.974: INFO: Got endpoints: latency-svc-zlt7v [762.456233ms]
Dec 20 05:14:00.018: INFO: Created: latency-svc-n8vh4
Dec 20 05:14:00.024: INFO: Got endpoints: latency-svc-vvqcl [762.100399ms]
Dec 20 05:14:00.044: INFO: Created: latency-svc-qlm57
Dec 20 05:14:00.062: INFO: Got endpoints: latency-svc-crgfd [746.634274ms]
Dec 20 05:14:00.074: INFO: Created: latency-svc-qlhs6
Dec 20 05:14:00.118: INFO: Got endpoints: latency-svc-lnrlz [754.881745ms]
Dec 20 05:14:00.134: INFO: Created: latency-svc-t498k
Dec 20 05:14:00.163: INFO: Got endpoints: latency-svc-fhpk7 [747.650286ms]
Dec 20 05:14:00.176: INFO: Created: latency-svc-7x6qs
Dec 20 05:14:00.212: INFO: Got endpoints: latency-svc-p68td [750.165411ms]
Dec 20 05:14:00.224: INFO: Created: latency-svc-c2h9c
Dec 20 05:14:00.263: INFO: Got endpoints: latency-svc-r4khx [749.765378ms]
Dec 20 05:14:00.279: INFO: Created: latency-svc-7g85h
Dec 20 05:14:00.314: INFO: Got endpoints: latency-svc-69pg8 [748.642291ms]
Dec 20 05:14:00.330: INFO: Created: latency-svc-nnzpz
Dec 20 05:14:00.362: INFO: Got endpoints: latency-svc-8q9tm [748.717216ms]
Dec 20 05:14:00.377: INFO: Created: latency-svc-w6cpr
Dec 20 05:14:00.413: INFO: Got endpoints: latency-svc-wwwzs [751.394061ms]
Dec 20 05:14:00.432: INFO: Created: latency-svc-np8hr
Dec 20 05:14:00.463: INFO: Got endpoints: latency-svc-hvnv8 [750.136291ms]
Dec 20 05:14:00.477: INFO: Created: latency-svc-7xbkx
Dec 20 05:14:00.513: INFO: Got endpoints: latency-svc-c4969 [748.261565ms]
Dec 20 05:14:00.531: INFO: Created: latency-svc-v6kph
Dec 20 05:14:00.568: INFO: Got endpoints: latency-svc-7gt76 [756.68652ms]
Dec 20 05:14:00.582: INFO: Created: latency-svc-m2c2n
Dec 20 05:14:00.613: INFO: Got endpoints: latency-svc-6jjm6 [748.889121ms]
Dec 20 05:14:00.633: INFO: Created: latency-svc-6z4jc
Dec 20 05:14:00.664: INFO: Got endpoints: latency-svc-cpq54 [747.298833ms]
Dec 20 05:14:00.678: INFO: Created: latency-svc-9pmfk
Dec 20 05:14:00.711: INFO: Got endpoints: latency-svc-n8vh4 [737.216275ms]
Dec 20 05:14:00.726: INFO: Created: latency-svc-jk9zr
Dec 20 05:14:00.764: INFO: Got endpoints: latency-svc-qlm57 [738.640353ms]
Dec 20 05:14:00.775: INFO: Created: latency-svc-58tzz
Dec 20 05:14:00.813: INFO: Got endpoints: latency-svc-qlhs6 [750.786611ms]
Dec 20 05:14:00.824: INFO: Created: latency-svc-vqp2c
Dec 20 05:14:00.862: INFO: Got endpoints: latency-svc-t498k [743.496894ms]
Dec 20 05:14:00.873: INFO: Created: latency-svc-bdzjw
Dec 20 05:14:00.910: INFO: Got endpoints: latency-svc-7x6qs [747.754713ms]
Dec 20 05:14:00.921: INFO: Created: latency-svc-86422
Dec 20 05:14:00.969: INFO: Got endpoints: latency-svc-c2h9c [756.690923ms]
Dec 20 05:14:00.995: INFO: Created: latency-svc-z4q7r
Dec 20 05:14:01.013: INFO: Got endpoints: latency-svc-7g85h [749.170499ms]
Dec 20 05:14:01.034: INFO: Created: latency-svc-gjp77
Dec 20 05:14:01.068: INFO: Got endpoints: latency-svc-nnzpz [753.798965ms]
Dec 20 05:14:01.081: INFO: Created: latency-svc-jbwss
Dec 20 05:14:01.111: INFO: Got endpoints: latency-svc-w6cpr [749.117494ms]
Dec 20 05:14:01.122: INFO: Created: latency-svc-mfc2d
Dec 20 05:14:01.162: INFO: Got endpoints: latency-svc-np8hr [748.487254ms]
Dec 20 05:14:01.175: INFO: Created: latency-svc-qg2qj
Dec 20 05:14:01.212: INFO: Got endpoints: latency-svc-7xbkx [748.685367ms]
Dec 20 05:14:01.224: INFO: Created: latency-svc-68ckv
Dec 20 05:14:01.263: INFO: Got endpoints: latency-svc-v6kph [749.285708ms]
Dec 20 05:14:01.275: INFO: Created: latency-svc-wm2x9
Dec 20 05:14:01.316: INFO: Got endpoints: latency-svc-m2c2n [747.628236ms]
Dec 20 05:14:01.329: INFO: Created: latency-svc-9mzj8
Dec 20 05:14:01.363: INFO: Got endpoints: latency-svc-6z4jc [749.972553ms]
Dec 20 05:14:01.375: INFO: Created: latency-svc-2nl2j
Dec 20 05:14:01.411: INFO: Got endpoints: latency-svc-9pmfk [747.354111ms]
Dec 20 05:14:01.424: INFO: Created: latency-svc-n2rn5
Dec 20 05:14:01.463: INFO: Got endpoints: latency-svc-jk9zr [751.809882ms]
Dec 20 05:14:01.478: INFO: Created: latency-svc-4m2b2
Dec 20 05:14:01.517: INFO: Got endpoints: latency-svc-58tzz [753.07643ms]
Dec 20 05:14:01.534: INFO: Created: latency-svc-7cpdq
Dec 20 05:14:01.571: INFO: Got endpoints: latency-svc-vqp2c [757.870137ms]
Dec 20 05:14:01.590: INFO: Created: latency-svc-967gs
Dec 20 05:14:01.613: INFO: Got endpoints: latency-svc-bdzjw [751.475509ms]
Dec 20 05:14:01.624: INFO: Created: latency-svc-svx77
Dec 20 05:14:01.665: INFO: Got endpoints: latency-svc-86422 [754.995509ms]
Dec 20 05:14:01.678: INFO: Created: latency-svc-w58l5
Dec 20 05:14:01.713: INFO: Got endpoints: latency-svc-z4q7r [744.105393ms]
Dec 20 05:14:01.734: INFO: Created: latency-svc-7mg5d
Dec 20 05:14:01.766: INFO: Got endpoints: latency-svc-gjp77 [753.388398ms]
Dec 20 05:14:01.789: INFO: Created: latency-svc-5rfdc
Dec 20 05:14:01.814: INFO: Got endpoints: latency-svc-jbwss [746.025561ms]
Dec 20 05:14:01.826: INFO: Created: latency-svc-b4x6c
Dec 20 05:14:01.862: INFO: Got endpoints: latency-svc-mfc2d [750.657148ms]
Dec 20 05:14:01.880: INFO: Created: latency-svc-8hzpq
Dec 20 05:14:01.914: INFO: Got endpoints: latency-svc-qg2qj [751.561976ms]
Dec 20 05:14:01.930: INFO: Created: latency-svc-slwz9
Dec 20 05:14:01.975: INFO: Got endpoints: latency-svc-68ckv [762.639631ms]
Dec 20 05:14:01.992: INFO: Created: latency-svc-6fgfg
Dec 20 05:14:02.018: INFO: Got endpoints: latency-svc-wm2x9 [755.489837ms]
Dec 20 05:14:02.040: INFO: Created: latency-svc-rxv8t
Dec 20 05:14:02.065: INFO: Got endpoints: latency-svc-9mzj8 [749.452288ms]
Dec 20 05:14:02.086: INFO: Created: latency-svc-plvtj
Dec 20 05:14:02.114: INFO: Got endpoints: latency-svc-2nl2j [750.659112ms]
Dec 20 05:14:02.136: INFO: Created: latency-svc-7jxkg
Dec 20 05:14:02.162: INFO: Got endpoints: latency-svc-n2rn5 [750.940874ms]
Dec 20 05:14:02.177: INFO: Created: latency-svc-wnxs5
Dec 20 05:14:02.213: INFO: Got endpoints: latency-svc-4m2b2 [750.048621ms]
Dec 20 05:14:02.230: INFO: Created: latency-svc-rx64h
Dec 20 05:14:02.261: INFO: Got endpoints: latency-svc-7cpdq [744.498714ms]
Dec 20 05:14:02.287: INFO: Created: latency-svc-d7dch
Dec 20 05:14:02.318: INFO: Got endpoints: latency-svc-967gs [747.467617ms]
Dec 20 05:14:02.332: INFO: Created: latency-svc-cppfv
Dec 20 05:14:02.366: INFO: Got endpoints: latency-svc-svx77 [753.254745ms]
Dec 20 05:14:02.384: INFO: Created: latency-svc-6z8gp
Dec 20 05:14:02.415: INFO: Got endpoints: latency-svc-w58l5 [749.112692ms]
Dec 20 05:14:02.431: INFO: Created: latency-svc-gp9qn
Dec 20 05:14:02.469: INFO: Got endpoints: latency-svc-7mg5d [755.858252ms]
Dec 20 05:14:02.489: INFO: Created: latency-svc-59r2g
Dec 20 05:14:02.519: INFO: Got endpoints: latency-svc-5rfdc [752.824865ms]
Dec 20 05:14:02.533: INFO: Created: latency-svc-qjtww
Dec 20 05:14:02.565: INFO: Got endpoints: latency-svc-b4x6c [751.243538ms]
Dec 20 05:14:02.580: INFO: Created: latency-svc-2vp6t
Dec 20 05:14:02.616: INFO: Got endpoints: latency-svc-8hzpq [754.320697ms]
Dec 20 05:14:02.641: INFO: Created: latency-svc-hxv75
Dec 20 05:14:02.664: INFO: Got endpoints: latency-svc-slwz9 [750.152453ms]
Dec 20 05:14:02.682: INFO: Created: latency-svc-s2r85
Dec 20 05:14:02.716: INFO: Got endpoints: latency-svc-6fgfg [741.295677ms]
Dec 20 05:14:02.730: INFO: Created: latency-svc-fxbht
Dec 20 05:14:02.769: INFO: Got endpoints: latency-svc-rxv8t [750.353621ms]
Dec 20 05:14:02.813: INFO: Got endpoints: latency-svc-plvtj [748.28166ms]
Dec 20 05:14:02.864: INFO: Got endpoints: latency-svc-7jxkg [750.804442ms]
Dec 20 05:14:02.917: INFO: Got endpoints: latency-svc-wnxs5 [755.32368ms]
Dec 20 05:14:02.966: INFO: Got endpoints: latency-svc-rx64h [752.849633ms]
Dec 20 05:14:03.017: INFO: Got endpoints: latency-svc-d7dch [755.061968ms]
Dec 20 05:14:03.064: INFO: Got endpoints: latency-svc-cppfv [746.346046ms]
Dec 20 05:14:03.116: INFO: Got endpoints: latency-svc-6z8gp [749.60046ms]
Dec 20 05:14:03.165: INFO: Got endpoints: latency-svc-gp9qn [750.145825ms]
Dec 20 05:14:03.214: INFO: Got endpoints: latency-svc-59r2g [745.456533ms]
Dec 20 05:14:03.264: INFO: Got endpoints: latency-svc-qjtww [744.671317ms]
Dec 20 05:14:03.313: INFO: Got endpoints: latency-svc-2vp6t [748.164412ms]
Dec 20 05:14:03.362: INFO: Got endpoints: latency-svc-hxv75 [745.801137ms]
Dec 20 05:14:03.415: INFO: Got endpoints: latency-svc-s2r85 [751.138593ms]
Dec 20 05:14:03.466: INFO: Got endpoints: latency-svc-fxbht [749.801628ms]
Dec 20 05:14:03.466: INFO: Latencies: [20.393956ms 28.299762ms 37.198384ms 58.186997ms 61.901224ms 73.44542ms 86.080368ms 97.17451ms 109.050141ms 118.779774ms 132.092114ms 144.555003ms 152.610689ms 160.121844ms 160.759433ms 162.819292ms 168.125849ms 169.124577ms 174.085072ms 174.191727ms 176.333834ms 176.452826ms 179.613093ms 180.574412ms 180.862784ms 181.982038ms 182.834163ms 186.618317ms 186.940246ms 189.40403ms 189.694697ms 191.381777ms 191.693629ms 192.192827ms 193.938359ms 194.135016ms 197.153411ms 197.347382ms 199.077596ms 236.695182ms 269.610494ms 312.881915ms 356.70892ms 387.721151ms 427.807738ms 469.078478ms 505.147514ms 543.762246ms 578.154427ms 617.749921ms 672.138711ms 710.429355ms 712.608547ms 737.216275ms 738.640353ms 741.295677ms 741.750782ms 743.496894ms 744.105393ms 744.317131ms 744.373977ms 744.498714ms 744.671317ms 744.729079ms 745.456533ms 745.5347ms 745.56471ms 745.622842ms 745.73538ms 745.801137ms 746.025561ms 746.346046ms 746.634274ms 746.73145ms 746.993992ms 747.066524ms 747.298833ms 747.354111ms 747.467617ms 747.509812ms 747.55743ms 747.628236ms 747.650286ms 747.686299ms 747.729359ms 747.754713ms 747.850031ms 747.861017ms 747.979518ms 748.131905ms 748.147117ms 748.164412ms 748.22867ms 748.234675ms 748.261565ms 748.28166ms 748.392198ms 748.470292ms 748.487254ms 748.642291ms 748.685367ms 748.703869ms 748.717216ms 748.731589ms 748.860068ms 748.889121ms 748.892356ms 748.997659ms 749.013229ms 749.112692ms 749.11465ms 749.117494ms 749.119737ms 749.170499ms 749.182007ms 749.285708ms 749.435326ms 749.452288ms 749.46099ms 749.495965ms 749.505071ms 749.549194ms 749.60046ms 749.635718ms 749.704059ms 749.765378ms 749.773857ms 749.801628ms 749.820696ms 749.87568ms 749.972553ms 750.048621ms 750.083245ms 750.092345ms 750.136291ms 750.145825ms 750.152453ms 750.165411ms 750.218054ms 750.353621ms 750.424069ms 750.56399ms 750.657148ms 750.659112ms 750.735537ms 750.75602ms 750.786611ms 750.804442ms 750.808784ms 750.940874ms 750.951397ms 750.991133ms 751.138593ms 751.140561ms 751.225811ms 751.243538ms 751.394061ms 751.435172ms 751.475509ms 751.561976ms 751.566984ms 751.809882ms 751.847899ms 752.189309ms 752.278303ms 752.347418ms 752.468297ms 752.579439ms 752.695269ms 752.824865ms 752.840878ms 752.849633ms 753.07643ms 753.203492ms 753.254745ms 753.316384ms 753.375936ms 753.388398ms 753.798965ms 753.913276ms 753.92611ms 754.320697ms 754.448213ms 754.752077ms 754.881745ms 754.995509ms 755.061968ms 755.290484ms 755.32368ms 755.401143ms 755.489837ms 755.858252ms 756.68652ms 756.690923ms 756.986652ms 757.870137ms 762.100399ms 762.456233ms 762.639631ms 786.362323ms]
Dec 20 05:14:03.466: INFO: 50 %ile: 748.685367ms
Dec 20 05:14:03.466: INFO: 90 %ile: 753.92611ms
Dec 20 05:14:03.466: INFO: 99 %ile: 762.639631ms
Dec 20 05:14:03.466: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:14:03.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-x4wq5" for this suite.
Dec 20 05:14:27.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:14:27.944: INFO: namespace: e2e-tests-svc-latency-x4wq5, resource: bindings, ignored listing per whitelist
Dec 20 05:14:27.950: INFO: namespace e2e-tests-svc-latency-x4wq5 deletion completed in 24.104279806s

• [SLOW TEST:36.277 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:14:27.950: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec 20 05:14:28.011: INFO: Waiting up to 5m0s for pod "client-containers-1fc0e71f-0416-11e9-acdd-0a580ac80107" in namespace "e2e-tests-containers-2w8gg" to be "success or failure"
Dec 20 05:14:28.018: INFO: Pod "client-containers-1fc0e71f-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 6.989016ms
Dec 20 05:14:30.021: INFO: Pod "client-containers-1fc0e71f-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010826413s
Dec 20 05:14:32.025: INFO: Pod "client-containers-1fc0e71f-0416-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014389385s
STEP: Saw pod success
Dec 20 05:14:32.025: INFO: Pod "client-containers-1fc0e71f-0416-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:14:32.028: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod client-containers-1fc0e71f-0416-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 05:14:32.045: INFO: Waiting for pod client-containers-1fc0e71f-0416-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:14:32.048: INFO: Pod client-containers-1fc0e71f-0416-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:14:32.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2w8gg" for this suite.
Dec 20 05:14:38.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:14:38.396: INFO: namespace: e2e-tests-containers-2w8gg, resource: bindings, ignored listing per whitelist
Dec 20 05:14:38.420: INFO: namespace e2e-tests-containers-2w8gg deletion completed in 6.103552863s

• [SLOW TEST:10.469 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:14:38.420: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-25fe565b-0416-11e9-acdd-0a580ac80107
STEP: Creating secret with name secret-projected-all-test-volume-25fe563f-0416-11e9-acdd-0a580ac80107
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 20 05:14:38.488: INFO: Waiting up to 5m0s for pod "projected-volume-25fe55ef-0416-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-fxwq6" to be "success or failure"
Dec 20 05:14:38.492: INFO: Pod "projected-volume-25fe55ef-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.54848ms
Dec 20 05:14:40.496: INFO: Pod "projected-volume-25fe55ef-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007588883s
Dec 20 05:14:42.553: INFO: Pod "projected-volume-25fe55ef-0416-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064952487s
STEP: Saw pod success
Dec 20 05:14:42.553: INFO: Pod "projected-volume-25fe55ef-0416-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:14:42.602: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod projected-volume-25fe55ef-0416-11e9-acdd-0a580ac80107 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 20 05:14:42.664: INFO: Waiting for pod projected-volume-25fe55ef-0416-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:14:42.667: INFO: Pod projected-volume-25fe55ef-0416-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:14:42.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fxwq6" for this suite.
Dec 20 05:14:49.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:14:49.024: INFO: namespace: e2e-tests-projected-fxwq6, resource: bindings, ignored listing per whitelist
Dec 20 05:14:49.108: INFO: namespace e2e-tests-projected-fxwq6 deletion completed in 6.119701137s

• [SLOW TEST:10.688 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:14:49.109: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:14:49.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-htdzj" for this suite.
Dec 20 05:14:55.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:14:55.188: INFO: namespace: e2e-tests-services-htdzj, resource: bindings, ignored listing per whitelist
Dec 20 05:14:55.260: INFO: namespace e2e-tests-services-htdzj deletion completed in 6.090993246s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.152 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:14:55.261: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec 20 05:14:55.833: INFO: created pod pod-service-account-defaultsa
Dec 20 05:14:55.833: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 20 05:14:55.840: INFO: created pod pod-service-account-mountsa
Dec 20 05:14:55.840: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 20 05:14:55.848: INFO: created pod pod-service-account-nomountsa
Dec 20 05:14:55.848: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 20 05:14:55.856: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 20 05:14:55.856: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 20 05:14:55.876: INFO: created pod pod-service-account-mountsa-mountspec
Dec 20 05:14:55.876: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 20 05:14:55.883: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 20 05:14:55.883: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 20 05:14:55.899: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 20 05:14:55.899: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 20 05:14:55.908: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 20 05:14:55.908: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 20 05:14:55.918: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 20 05:14:55.918: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:14:55.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-j2974" for this suite.
Dec 20 05:15:01.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:15:02.010: INFO: namespace: e2e-tests-svcaccounts-j2974, resource: bindings, ignored listing per whitelist
Dec 20 05:15:02.051: INFO: namespace e2e-tests-svcaccounts-j2974 deletion completed in 6.123878324s

• [SLOW TEST:6.790 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:15:02.051: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-34168512-0416-11e9-acdd-0a580ac80107
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-34168512-0416-11e9-acdd-0a580ac80107
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:15:10.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xjp8j" for this suite.
Dec 20 05:15:32.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:15:32.490: INFO: namespace: e2e-tests-configmap-xjp8j, resource: bindings, ignored listing per whitelist
Dec 20 05:15:32.559: INFO: namespace e2e-tests-configmap-xjp8j deletion completed in 22.284017707s

• [SLOW TEST:30.508 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:15:32.559: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-z99b5.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-z99b5.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-z99b5.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-z99b5.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-z99b5.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-z99b5.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 20 05:15:55.156: INFO: DNS probes using e2e-tests-dns-z99b5/dns-test-466ddd9b-0416-11e9-acdd-0a580ac80107 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:15:55.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-z99b5" for this suite.
Dec 20 05:16:01.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:16:01.725: INFO: namespace: e2e-tests-dns-z99b5, resource: bindings, ignored listing per whitelist
Dec 20 05:16:01.733: INFO: namespace e2e-tests-dns-z99b5 deletion completed in 6.112177994s

• [SLOW TEST:29.174 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:16:01.733: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 05:16:01.802: INFO: Waiting up to 5m0s for pod "downwardapi-volume-57a822f5-0416-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-6kpb2" to be "success or failure"
Dec 20 05:16:01.807: INFO: Pod "downwardapi-volume-57a822f5-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.641342ms
Dec 20 05:16:03.811: INFO: Pod "downwardapi-volume-57a822f5-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008615825s
Dec 20 05:16:05.867: INFO: Pod "downwardapi-volume-57a822f5-0416-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064305451s
STEP: Saw pod success
Dec 20 05:16:05.867: INFO: Pod "downwardapi-volume-57a822f5-0416-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:16:05.915: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downwardapi-volume-57a822f5-0416-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 05:16:05.978: INFO: Waiting for pod downwardapi-volume-57a822f5-0416-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:16:05.980: INFO: Pod downwardapi-volume-57a822f5-0416-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:16:05.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6kpb2" for this suite.
Dec 20 05:16:12.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:16:12.382: INFO: namespace: e2e-tests-downward-api-6kpb2, resource: bindings, ignored listing per whitelist
Dec 20 05:16:12.382: INFO: namespace e2e-tests-downward-api-6kpb2 deletion completed in 6.100920319s

• [SLOW TEST:10.649 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:16:12.382: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 20 05:16:12.438: INFO: Waiting up to 5m0s for pod "pod-5dff7736-0416-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-c87qg" to be "success or failure"
Dec 20 05:16:12.441: INFO: Pod "pod-5dff7736-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.152446ms
Dec 20 05:16:14.444: INFO: Pod "pod-5dff7736-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005421999s
Dec 20 05:16:16.448: INFO: Pod "pod-5dff7736-0416-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009391378s
STEP: Saw pod success
Dec 20 05:16:16.448: INFO: Pod "pod-5dff7736-0416-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:16:16.451: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-5dff7736-0416-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 05:16:16.522: INFO: Waiting for pod pod-5dff7736-0416-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:16:16.525: INFO: Pod pod-5dff7736-0416-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:16:16.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c87qg" for this suite.
Dec 20 05:16:22.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:16:22.978: INFO: namespace: e2e-tests-emptydir-c87qg, resource: bindings, ignored listing per whitelist
Dec 20 05:16:23.024: INFO: namespace e2e-tests-emptydir-c87qg deletion completed in 6.122083656s

• [SLOW TEST:10.642 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:16:23.025: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec 20 05:16:23.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 cluster-info'
Dec 20 05:16:23.199: INFO: stderr: ""
Dec 20 05:16:23.199: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:16:23.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hvv99" for this suite.
Dec 20 05:16:29.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:16:29.290: INFO: namespace: e2e-tests-kubectl-hvv99, resource: bindings, ignored listing per whitelist
Dec 20 05:16:29.321: INFO: namespace e2e-tests-kubectl-hvv99 deletion completed in 6.118330278s

• [SLOW TEST:6.296 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:16:29.321: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 20 05:16:37.421: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:37.477: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 05:16:39.478: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:39.538: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 05:16:41.478: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:41.529: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 05:16:43.478: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:43.525: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 05:16:45.478: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:45.528: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 05:16:47.478: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:47.526: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 05:16:49.478: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:49.524: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 05:16:51.478: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:51.528: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 05:16:53.478: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:53.527: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 05:16:55.478: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:55.527: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 05:16:57.478: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:57.527: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 05:16:59.478: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 05:16:59.482: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:16:59.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-22jd5" for this suite.
Dec 20 05:17:21.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:17:22.079: INFO: namespace: e2e-tests-container-lifecycle-hook-22jd5, resource: bindings, ignored listing per whitelist
Dec 20 05:17:22.136: INFO: namespace e2e-tests-container-lifecycle-hook-22jd5 deletion completed in 22.332431824s

• [SLOW TEST:52.815 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:17:22.136: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-87b7c80f-0416-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 05:17:22.440: INFO: Waiting up to 5m0s for pod "pod-configmaps-87b87d87-0416-11e9-acdd-0a580ac80107" in namespace "e2e-tests-configmap-hg2nb" to be "success or failure"
Dec 20 05:17:22.443: INFO: Pod "pod-configmaps-87b87d87-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.632166ms
Dec 20 05:17:24.447: INFO: Pod "pod-configmaps-87b87d87-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006883862s
Dec 20 05:17:26.451: INFO: Pod "pod-configmaps-87b87d87-0416-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010885017s
STEP: Saw pod success
Dec 20 05:17:26.451: INFO: Pod "pod-configmaps-87b87d87-0416-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:17:26.453: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-configmaps-87b87d87-0416-11e9-acdd-0a580ac80107 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 05:17:26.472: INFO: Waiting for pod pod-configmaps-87b87d87-0416-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:17:26.475: INFO: Pod pod-configmaps-87b87d87-0416-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:17:26.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hg2nb" for this suite.
Dec 20 05:17:32.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:17:32.550: INFO: namespace: e2e-tests-configmap-hg2nb, resource: bindings, ignored listing per whitelist
Dec 20 05:17:32.572: INFO: namespace e2e-tests-configmap-hg2nb deletion completed in 6.093409125s

• [SLOW TEST:10.436 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:17:32.572: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 20 05:17:32.676: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-pqp29,SelfLink:/api/v1/namespaces/e2e-tests-watch-pqp29/configmaps/e2e-watch-test-resource-version,UID:8dccfa8c-0416-11e9-9da8-506b8da7f7e6,ResourceVersion:19026,Generation:0,CreationTimestamp:2018-12-20 05:17:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 20 05:17:32.676: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-pqp29,SelfLink:/api/v1/namespaces/e2e-tests-watch-pqp29/configmaps/e2e-watch-test-resource-version,UID:8dccfa8c-0416-11e9-9da8-506b8da7f7e6,ResourceVersion:19027,Generation:0,CreationTimestamp:2018-12-20 05:17:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:17:32.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-pqp29" for this suite.
Dec 20 05:17:38.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:17:38.770: INFO: namespace: e2e-tests-watch-pqp29, resource: bindings, ignored listing per whitelist
Dec 20 05:17:38.785: INFO: namespace e2e-tests-watch-pqp29 deletion completed in 6.10565389s

• [SLOW TEST:6.213 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:17:38.785: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-91825718-0416-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 05:17:38.868: INFO: Waiting up to 5m0s for pod "pod-configmaps-91836faf-0416-11e9-acdd-0a580ac80107" in namespace "e2e-tests-configmap-g4627" to be "success or failure"
Dec 20 05:17:38.871: INFO: Pod "pod-configmaps-91836faf-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.614802ms
Dec 20 05:17:40.875: INFO: Pod "pod-configmaps-91836faf-0416-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006374452s
STEP: Saw pod success
Dec 20 05:17:40.875: INFO: Pod "pod-configmaps-91836faf-0416-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:17:40.877: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-configmaps-91836faf-0416-11e9-acdd-0a580ac80107 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 05:17:40.897: INFO: Waiting for pod pod-configmaps-91836faf-0416-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:17:40.900: INFO: Pod pod-configmaps-91836faf-0416-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:17:40.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g4627" for this suite.
Dec 20 05:17:46.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:17:46.969: INFO: namespace: e2e-tests-configmap-g4627, resource: bindings, ignored listing per whitelist
Dec 20 05:17:47.014: INFO: namespace e2e-tests-configmap-g4627 deletion completed in 6.110638863s

• [SLOW TEST:8.229 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:17:47.015: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 20 05:17:47.081: INFO: Waiting up to 5m0s for pod "pod-96689286-0416-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-8jb9m" to be "success or failure"
Dec 20 05:17:47.087: INFO: Pod "pod-96689286-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.766614ms
Dec 20 05:17:49.090: INFO: Pod "pod-96689286-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008999118s
Dec 20 05:17:51.141: INFO: Pod "pod-96689286-0416-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059999085s
STEP: Saw pod success
Dec 20 05:17:51.141: INFO: Pod "pod-96689286-0416-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:17:51.187: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-96689286-0416-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 05:17:51.256: INFO: Waiting for pod pod-96689286-0416-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:17:51.259: INFO: Pod pod-96689286-0416-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:17:51.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8jb9m" for this suite.
Dec 20 05:17:57.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:17:57.642: INFO: namespace: e2e-tests-emptydir-8jb9m, resource: bindings, ignored listing per whitelist
Dec 20 05:17:57.684: INFO: namespace e2e-tests-emptydir-8jb9m deletion completed in 6.106036598s

• [SLOW TEST:10.670 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:17:57.684: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 20 05:17:57.757: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l6kvt,SelfLink:/api/v1/namespaces/e2e-tests-watch-l6kvt/configmaps/e2e-watch-test-label-changed,UID:9cc423a1-0416-11e9-9da8-506b8da7f7e6,ResourceVersion:19127,Generation:0,CreationTimestamp:2018-12-20 05:17:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 20 05:17:57.757: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l6kvt,SelfLink:/api/v1/namespaces/e2e-tests-watch-l6kvt/configmaps/e2e-watch-test-label-changed,UID:9cc423a1-0416-11e9-9da8-506b8da7f7e6,ResourceVersion:19128,Generation:0,CreationTimestamp:2018-12-20 05:17:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 20 05:17:57.758: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l6kvt,SelfLink:/api/v1/namespaces/e2e-tests-watch-l6kvt/configmaps/e2e-watch-test-label-changed,UID:9cc423a1-0416-11e9-9da8-506b8da7f7e6,ResourceVersion:19129,Generation:0,CreationTimestamp:2018-12-20 05:17:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 20 05:18:07.794: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l6kvt,SelfLink:/api/v1/namespaces/e2e-tests-watch-l6kvt/configmaps/e2e-watch-test-label-changed,UID:9cc423a1-0416-11e9-9da8-506b8da7f7e6,ResourceVersion:19146,Generation:0,CreationTimestamp:2018-12-20 05:17:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 20 05:18:07.794: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l6kvt,SelfLink:/api/v1/namespaces/e2e-tests-watch-l6kvt/configmaps/e2e-watch-test-label-changed,UID:9cc423a1-0416-11e9-9da8-506b8da7f7e6,ResourceVersion:19147,Generation:0,CreationTimestamp:2018-12-20 05:17:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 20 05:18:07.794: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l6kvt,SelfLink:/api/v1/namespaces/e2e-tests-watch-l6kvt/configmaps/e2e-watch-test-label-changed,UID:9cc423a1-0416-11e9-9da8-506b8da7f7e6,ResourceVersion:19148,Generation:0,CreationTimestamp:2018-12-20 05:17:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:18:07.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-l6kvt" for this suite.
Dec 20 05:18:14.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:18:14.267: INFO: namespace: e2e-tests-watch-l6kvt, resource: bindings, ignored listing per whitelist
Dec 20 05:18:14.270: INFO: namespace e2e-tests-watch-l6kvt deletion completed in 6.098808345s

• [SLOW TEST:16.586 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:18:14.270: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a6a73321-0416-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 05:18:14.342: INFO: Waiting up to 5m0s for pod "pod-secrets-a6a84269-0416-11e9-acdd-0a580ac80107" in namespace "e2e-tests-secrets-mb2j8" to be "success or failure"
Dec 20 05:18:14.346: INFO: Pod "pod-secrets-a6a84269-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.8474ms
Dec 20 05:18:16.349: INFO: Pod "pod-secrets-a6a84269-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007598789s
Dec 20 05:18:18.354: INFO: Pod "pod-secrets-a6a84269-0416-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0116839s
STEP: Saw pod success
Dec 20 05:18:18.354: INFO: Pod "pod-secrets-a6a84269-0416-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:18:18.356: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-secrets-a6a84269-0416-11e9-acdd-0a580ac80107 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 05:18:18.423: INFO: Waiting for pod pod-secrets-a6a84269-0416-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:18:18.426: INFO: Pod pod-secrets-a6a84269-0416-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:18:18.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mb2j8" for this suite.
Dec 20 05:18:24.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:18:24.866: INFO: namespace: e2e-tests-secrets-mb2j8, resource: bindings, ignored listing per whitelist
Dec 20 05:18:24.866: INFO: namespace e2e-tests-secrets-mb2j8 deletion completed in 6.11389644s

• [SLOW TEST:10.595 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:18:24.866: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 20 05:18:24.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-pwbq9'
Dec 20 05:18:25.053: INFO: stderr: ""
Dec 20 05:18:25.053: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Dec 20 05:18:25.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pwbq9'
Dec 20 05:18:27.299: INFO: stderr: ""
Dec 20 05:18:27.299: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:18:27.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pwbq9" for this suite.
Dec 20 05:18:33.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:18:33.350: INFO: namespace: e2e-tests-kubectl-pwbq9, resource: bindings, ignored listing per whitelist
Dec 20 05:18:33.401: INFO: namespace e2e-tests-kubectl-pwbq9 deletion completed in 6.09719378s

• [SLOW TEST:8.535 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:18:33.401: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 20 05:18:33.463: INFO: Waiting up to 5m0s for pod "downward-api-b20df3c1-0416-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-rcxq2" to be "success or failure"
Dec 20 05:18:33.469: INFO: Pod "downward-api-b20df3c1-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.727116ms
Dec 20 05:18:35.473: INFO: Pod "downward-api-b20df3c1-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009948596s
Dec 20 05:18:37.528: INFO: Pod "downward-api-b20df3c1-0416-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064809816s
STEP: Saw pod success
Dec 20 05:18:37.528: INFO: Pod "downward-api-b20df3c1-0416-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:18:37.578: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downward-api-b20df3c1-0416-11e9-acdd-0a580ac80107 container dapi-container: <nil>
STEP: delete the pod
Dec 20 05:18:37.655: INFO: Waiting for pod downward-api-b20df3c1-0416-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:18:37.658: INFO: Pod downward-api-b20df3c1-0416-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:18:37.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rcxq2" for this suite.
Dec 20 05:18:44.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:18:44.073: INFO: namespace: e2e-tests-downward-api-rcxq2, resource: bindings, ignored listing per whitelist
Dec 20 05:18:44.124: INFO: namespace e2e-tests-downward-api-rcxq2 deletion completed in 6.122353754s

• [SLOW TEST:10.723 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:18:44.124: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 20 05:18:48.706: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b8725c50-0416-11e9-acdd-0a580ac80107"
Dec 20 05:18:48.706: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b8725c50-0416-11e9-acdd-0a580ac80107" in namespace "e2e-tests-pods-f729z" to be "terminated due to deadline exceeded"
Dec 20 05:18:48.708: INFO: Pod "pod-update-activedeadlineseconds-b8725c50-0416-11e9-acdd-0a580ac80107": Phase="Running", Reason="", readiness=true. Elapsed: 2.130462ms
Dec 20 05:18:50.712: INFO: Pod "pod-update-activedeadlineseconds-b8725c50-0416-11e9-acdd-0a580ac80107": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.006330395s
Dec 20 05:18:50.712: INFO: Pod "pod-update-activedeadlineseconds-b8725c50-0416-11e9-acdd-0a580ac80107" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:18:50.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f729z" for this suite.
Dec 20 05:18:56.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:18:56.998: INFO: namespace: e2e-tests-pods-f729z, resource: bindings, ignored listing per whitelist
Dec 20 05:18:57.071: INFO: namespace e2e-tests-pods-f729z deletion completed in 6.115093044s

• [SLOW TEST:12.947 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:18:57.072: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 20 05:18:57.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-hgmc7'
Dec 20 05:18:57.343: INFO: stderr: ""
Dec 20 05:18:57.343: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 20 05:18:58.348: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 05:18:58.348: INFO: Found 0 / 1
Dec 20 05:18:59.347: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 05:18:59.347: INFO: Found 1 / 1
Dec 20 05:18:59.347: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 20 05:18:59.350: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 05:18:59.350: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 20 05:18:59.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 patch pod redis-master-7rl9c --namespace=e2e-tests-kubectl-hgmc7 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 20 05:18:59.469: INFO: stderr: ""
Dec 20 05:18:59.469: INFO: stdout: "pod/redis-master-7rl9c patched\n"
STEP: checking annotations
Dec 20 05:18:59.472: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 05:18:59.472: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:18:59.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hgmc7" for this suite.
Dec 20 05:19:21.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:19:21.568: INFO: namespace: e2e-tests-kubectl-hgmc7, resource: bindings, ignored listing per whitelist
Dec 20 05:19:21.582: INFO: namespace e2e-tests-kubectl-hgmc7 deletion completed in 22.106997462s

• [SLOW TEST:24.511 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:19:21.583: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cec5195c-0416-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 05:19:21.646: INFO: Waiting up to 5m0s for pod "pod-configmaps-cec60a41-0416-11e9-acdd-0a580ac80107" in namespace "e2e-tests-configmap-x8gf2" to be "success or failure"
Dec 20 05:19:21.650: INFO: Pod "pod-configmaps-cec60a41-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.567426ms
Dec 20 05:19:23.653: INFO: Pod "pod-configmaps-cec60a41-0416-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007463865s
Dec 20 05:19:25.709: INFO: Pod "pod-configmaps-cec60a41-0416-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063372301s
STEP: Saw pod success
Dec 20 05:19:25.709: INFO: Pod "pod-configmaps-cec60a41-0416-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:19:25.758: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-configmaps-cec60a41-0416-11e9-acdd-0a580ac80107 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 05:19:25.821: INFO: Waiting for pod pod-configmaps-cec60a41-0416-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:19:25.824: INFO: Pod pod-configmaps-cec60a41-0416-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:19:25.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x8gf2" for this suite.
Dec 20 05:19:32.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:19:32.191: INFO: namespace: e2e-tests-configmap-x8gf2, resource: bindings, ignored listing per whitelist
Dec 20 05:19:32.249: INFO: namespace e2e-tests-configmap-x8gf2 deletion completed in 6.101200567s

• [SLOW TEST:10.666 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:19:32.249: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9g4hj
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-9g4hj
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-9g4hj
Dec 20 05:19:32.326: INFO: Found 0 stateful pods, waiting for 1
Dec 20 05:19:42.330: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 20 05:19:42.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-9g4hj ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 20 05:19:42.637: INFO: stderr: ""
Dec 20 05:19:42.638: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 20 05:19:42.638: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 20 05:19:42.641: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 20 05:19:52.691: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 05:19:52.691: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 05:19:52.889: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999672s
Dec 20 05:19:53.941: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.951664043s
Dec 20 05:19:54.992: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.898890316s
Dec 20 05:19:56.039: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.8486664s
Dec 20 05:19:57.090: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.800884042s
Dec 20 05:19:58.140: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.750644285s
Dec 20 05:19:59.191: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.700285706s
Dec 20 05:20:00.241: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.649284835s
Dec 20 05:20:01.293: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.599695269s
Dec 20 05:20:02.340: INFO: Verifying statefulset ss doesn't scale past 1 for another 547.765102ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-9g4hj
Dec 20 05:20:03.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-9g4hj ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 05:20:03.705: INFO: stderr: ""
Dec 20 05:20:03.705: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 20 05:20:03.705: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 20 05:20:03.766: INFO: Found 1 stateful pods, waiting for 3
Dec 20 05:20:13.817: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 05:20:13.817: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 05:20:13.817: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 20 05:20:13.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-9g4hj ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 20 05:20:14.203: INFO: stderr: ""
Dec 20 05:20:14.203: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 20 05:20:14.203: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 20 05:20:14.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-9g4hj ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 20 05:20:14.577: INFO: stderr: ""
Dec 20 05:20:14.577: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 20 05:20:14.577: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 20 05:20:14.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-9g4hj ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 20 05:20:14.856: INFO: stderr: ""
Dec 20 05:20:14.856: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 20 05:20:14.856: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 20 05:20:14.856: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 05:20:14.859: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 20 05:20:24.935: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 05:20:24.935: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 05:20:24.935: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 05:20:24.998: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999623s
Dec 20 05:20:26.053: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.948425607s
Dec 20 05:20:27.114: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.893764488s
Dec 20 05:20:28.168: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.832784417s
Dec 20 05:20:29.172: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.778823441s
Dec 20 05:20:30.219: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.774803642s
Dec 20 05:20:31.280: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.726927066s
Dec 20 05:20:32.333: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.665724596s
Dec 20 05:20:33.382: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.613663225s
Dec 20 05:20:34.435: INFO: Verifying statefulset ss doesn't scale past 3 for another 564.049585ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-9g4hj
Dec 20 05:20:35.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-9g4hj ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 05:20:35.825: INFO: stderr: ""
Dec 20 05:20:35.825: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 20 05:20:35.825: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 20 05:20:35.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-9g4hj ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 05:20:36.049: INFO: stderr: ""
Dec 20 05:20:36.049: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 20 05:20:36.049: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 20 05:20:36.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 exec --namespace=e2e-tests-statefulset-9g4hj ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 20 05:20:36.235: INFO: stderr: ""
Dec 20 05:20:36.235: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 20 05:20:36.235: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 20 05:20:36.235: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 20 05:20:56.297: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9g4hj
Dec 20 05:20:56.301: INFO: Scaling statefulset ss to 0
Dec 20 05:20:56.309: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 05:20:56.312: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:20:56.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9g4hj" for this suite.
Dec 20 05:21:02.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:21:02.761: INFO: namespace: e2e-tests-statefulset-9g4hj, resource: bindings, ignored listing per whitelist
Dec 20 05:21:02.801: INFO: namespace e2e-tests-statefulset-9g4hj deletion completed in 6.154001605s

• [SLOW TEST:90.552 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:21:02.801: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-0b1d627c-0417-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 05:21:02.887: INFO: Waiting up to 5m0s for pod "pod-secrets-0b1e58e0-0417-11e9-acdd-0a580ac80107" in namespace "e2e-tests-secrets-4k2fr" to be "success or failure"
Dec 20 05:21:02.890: INFO: Pod "pod-secrets-0b1e58e0-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.941306ms
Dec 20 05:21:04.894: INFO: Pod "pod-secrets-0b1e58e0-0417-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006182378s
STEP: Saw pod success
Dec 20 05:21:04.894: INFO: Pod "pod-secrets-0b1e58e0-0417-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:21:04.896: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-secrets-0b1e58e0-0417-11e9-acdd-0a580ac80107 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 05:21:04.916: INFO: Waiting for pod pod-secrets-0b1e58e0-0417-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:21:04.918: INFO: Pod pod-secrets-0b1e58e0-0417-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:21:04.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4k2fr" for this suite.
Dec 20 05:21:10.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:21:10.953: INFO: namespace: e2e-tests-secrets-4k2fr, resource: bindings, ignored listing per whitelist
Dec 20 05:21:11.036: INFO: namespace e2e-tests-secrets-4k2fr deletion completed in 6.114346414s

• [SLOW TEST:8.235 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:21:11.036: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 20 05:21:11.097: INFO: Waiting up to 5m0s for pod "downward-api-100324cb-0417-11e9-acdd-0a580ac80107" in namespace "e2e-tests-downward-api-kn7rs" to be "success or failure"
Dec 20 05:21:11.100: INFO: Pod "downward-api-100324cb-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.158286ms
Dec 20 05:21:13.104: INFO: Pod "downward-api-100324cb-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007143666s
Dec 20 05:21:15.155: INFO: Pod "downward-api-100324cb-0417-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057514584s
STEP: Saw pod success
Dec 20 05:21:15.155: INFO: Pod "downward-api-100324cb-0417-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:21:15.202: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod downward-api-100324cb-0417-11e9-acdd-0a580ac80107 container dapi-container: <nil>
STEP: delete the pod
Dec 20 05:21:15.280: INFO: Waiting for pod downward-api-100324cb-0417-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:21:15.283: INFO: Pod downward-api-100324cb-0417-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:21:15.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kn7rs" for this suite.
Dec 20 05:21:21.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:21:21.649: INFO: namespace: e2e-tests-downward-api-kn7rs, resource: bindings, ignored listing per whitelist
Dec 20 05:21:21.728: INFO: namespace e2e-tests-downward-api-kn7rs deletion completed in 6.105661876s

• [SLOW TEST:10.692 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:21:21.728: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-16630a9a-0417-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 05:21:21.799: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1663f3df-0417-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-9mlmx" to be "success or failure"
Dec 20 05:21:21.804: INFO: Pod "pod-projected-secrets-1663f3df-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.946702ms
Dec 20 05:21:23.808: INFO: Pod "pod-projected-secrets-1663f3df-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009471105s
Dec 20 05:21:25.865: INFO: Pod "pod-projected-secrets-1663f3df-0417-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06630337s
STEP: Saw pod success
Dec 20 05:21:25.865: INFO: Pod "pod-projected-secrets-1663f3df-0417-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:21:25.923: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-projected-secrets-1663f3df-0417-11e9-acdd-0a580ac80107 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 20 05:21:25.989: INFO: Waiting for pod pod-projected-secrets-1663f3df-0417-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:21:25.992: INFO: Pod pod-projected-secrets-1663f3df-0417-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:21:25.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9mlmx" for this suite.
Dec 20 05:21:32.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:21:32.332: INFO: namespace: e2e-tests-projected-9mlmx, resource: bindings, ignored listing per whitelist
Dec 20 05:21:32.404: INFO: namespace e2e-tests-projected-9mlmx deletion completed in 6.103340437s

• [SLOW TEST:10.676 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:21:32.404: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 20 05:21:40.492: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 05:21:40.542: INFO: Pod pod-with-prestop-http-hook still exists
Dec 20 05:21:42.542: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 05:21:42.593: INFO: Pod pod-with-prestop-http-hook still exists
Dec 20 05:21:44.542: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 05:21:44.607: INFO: Pod pod-with-prestop-http-hook still exists
Dec 20 05:21:46.542: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 05:21:46.593: INFO: Pod pod-with-prestop-http-hook still exists
Dec 20 05:21:48.542: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 05:21:48.546: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:21:48.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gms9h" for this suite.
Dec 20 05:22:10.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:22:11.261: INFO: namespace: e2e-tests-container-lifecycle-hook-gms9h, resource: bindings, ignored listing per whitelist
Dec 20 05:22:11.290: INFO: namespace e2e-tests-container-lifecycle-hook-gms9h deletion completed in 22.362657195s

• [SLOW TEST:38.886 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:22:11.290: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 20 05:22:11.465: INFO: Waiting up to 5m0s for pod "pod-33fe5c1a-0417-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-wf44t" to be "success or failure"
Dec 20 05:22:11.467: INFO: Pod "pod-33fe5c1a-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.134298ms
Dec 20 05:22:13.470: INFO: Pod "pod-33fe5c1a-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005522632s
Dec 20 05:22:15.474: INFO: Pod "pod-33fe5c1a-0417-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0091905s
STEP: Saw pod success
Dec 20 05:22:15.474: INFO: Pod "pod-33fe5c1a-0417-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:22:15.476: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-33fe5c1a-0417-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 05:22:15.496: INFO: Waiting for pod pod-33fe5c1a-0417-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:22:15.498: INFO: Pod pod-33fe5c1a-0417-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:22:15.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wf44t" for this suite.
Dec 20 05:22:21.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:22:21.608: INFO: namespace: e2e-tests-emptydir-wf44t, resource: bindings, ignored listing per whitelist
Dec 20 05:22:21.610: INFO: namespace e2e-tests-emptydir-wf44t deletion completed in 6.108988242s

• [SLOW TEST:10.320 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:22:21.611: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec 20 05:22:21.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 api-versions'
Dec 20 05:22:21.775: INFO: stderr: ""
Dec 20 05:22:21.775: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmonitoring.coreos.com/v1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:22:21.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pdlgf" for this suite.
Dec 20 05:22:27.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:22:27.797: INFO: namespace: e2e-tests-kubectl-pdlgf, resource: bindings, ignored listing per whitelist
Dec 20 05:22:27.885: INFO: namespace e2e-tests-kubectl-pdlgf deletion completed in 6.105730737s

• [SLOW TEST:6.274 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:22:27.885: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 05:22:27.941: INFO: Creating deployment "nginx-deployment"
Dec 20 05:22:27.948: INFO: Waiting for observed generation 1
Dec 20 05:22:29.956: INFO: Waiting for all required pods to come up
Dec 20 05:22:29.963: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 20 05:22:32.018: INFO: Waiting for deployment "nginx-deployment" to complete
Dec 20 05:22:32.026: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec 20 05:22:32.040: INFO: Updating deployment nginx-deployment
Dec 20 05:22:32.041: INFO: Waiting for observed generation 2
Dec 20 05:22:34.052: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 20 05:22:34.055: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 20 05:22:34.057: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 20 05:22:34.116: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 20 05:22:34.116: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 20 05:22:34.120: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 20 05:22:34.125: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec 20 05:22:34.125: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec 20 05:22:34.131: INFO: Updating deployment nginx-deployment
Dec 20 05:22:34.132: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec 20 05:22:34.138: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 20 05:22:34.149: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 20 05:22:34.188: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cg7xv/deployments/nginx-deployment,UID:3dd177da-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20266,Generation:3,CreationTimestamp:2018-12-20 05:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2018-12-20 05:22:32 +0000 UTC 2018-12-20 05:22:27 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2018-12-20 05:22:34 +0000 UTC 2018-12-20 05:22:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec 20 05:22:34.280: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cg7xv/replicasets/nginx-deployment-7dc8f79789,UID:4042fb63-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20245,Generation:3,CreationTimestamp:2018-12-20 05:22:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3dd177da-0417-11e9-9da8-506b8da7f7e6 0xc4221d4f17 0xc4221d4f18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 20 05:22:34.280: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec 20 05:22:34.280: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cg7xv/replicasets/nginx-deployment-7f9675fb8b,UID:3dd25b12-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20290,Generation:3,CreationTimestamp:2018-12-20 05:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3dd177da-0417-11e9-9da8-506b8da7f7e6 0xc4221d4fd7 0xc4221d4fd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec 20 05:22:34.685: INFO: Pod "nginx-deployment-7dc8f79789-6wx7x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-6wx7x,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-6wx7x,UID:41875334-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20284,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d98617 0xc422d98618}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.685: INFO: Pod "nginx-deployment-7dc8f79789-8nzjz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-8nzjz,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-8nzjz,UID:41874362-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20285,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d98740 0xc422d98741}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.686: INFO: Pod "nginx-deployment-7dc8f79789-9sztd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9sztd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-9sztd,UID:40444143-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20207,Generation:0,CreationTimestamp:2018-12-20 05:22:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d98800 0xc422d98801}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.54,PodIP:,StartTime:2018-12-20 05:22:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.686: INFO: Pod "nginx-deployment-7dc8f79789-bnpb2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bnpb2,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-bnpb2,UID:404e81c7-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20231,Generation:0,CreationTimestamp:2018-12-20 05:22:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d98a50 0xc422d98a51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.54,PodIP:,StartTime:2018-12-20 05:22:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.686: INFO: Pod "nginx-deployment-7dc8f79789-bxq76" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bxq76,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-bxq76,UID:4045588d-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20212,Generation:0,CreationTimestamp:2018-12-20 05:22:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d98f70 0xc422d98f71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.53,PodIP:,StartTime:2018-12-20 05:22:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.686: INFO: Pod "nginx-deployment-7dc8f79789-c5qvx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-c5qvx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-c5qvx,UID:41855ed9-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20306,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d99150 0xc422d99151}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.53,PodIP:,StartTime:2018-12-20 05:22:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.686: INFO: Pod "nginx-deployment-7dc8f79789-djv9h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-djv9h,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-djv9h,UID:40456bd7-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20211,Generation:0,CreationTimestamp:2018-12-20 05:22:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d99330 0xc422d99331}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.55,PodIP:,StartTime:2018-12-20 05:22:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.687: INFO: Pod "nginx-deployment-7dc8f79789-j2lzg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-j2lzg,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-j2lzg,UID:41873a0a-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20286,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d994c0 0xc422d994c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.687: INFO: Pod "nginx-deployment-7dc8f79789-npk7s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-npk7s,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-npk7s,UID:41895caf-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20298,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d99580 0xc422d99581}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.687: INFO: Pod "nginx-deployment-7dc8f79789-prnt8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-prnt8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-prnt8,UID:41843f42-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20291,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d99820 0xc422d99821}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.53,PodIP:,StartTime:2018-12-20 05:22:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.687: INFO: Pod "nginx-deployment-7dc8f79789-ttv5h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-ttv5h,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-ttv5h,UID:4050675c-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20235,Generation:0,CreationTimestamp:2018-12-20 05:22:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d99930 0xc422d99931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:32 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.55,PodIP:,StartTime:2018-12-20 05:22:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.687: INFO: Pod "nginx-deployment-7dc8f79789-vg2dh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vg2dh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-vg2dh,UID:418719d9-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20287,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d99bd0 0xc422d99bd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.687: INFO: Pod "nginx-deployment-7dc8f79789-zxj76" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zxj76,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7dc8f79789-zxj76,UID:41859fb3-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20271,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 4042fb63-0417-11e9-9da8-506b8da7f7e6 0xc422d99ca0 0xc422d99ca1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.688: INFO: Pod "nginx-deployment-7f9675fb8b-2zqcp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2zqcp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-2zqcp,UID:4188bcd6-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20292,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc422d99d60 0xc422d99d61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.688: INFO: Pod "nginx-deployment-7f9675fb8b-67dcp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-67dcp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-67dcp,UID:4188d205-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20294,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d72020 0xc420d72021}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.689: INFO: Pod "nginx-deployment-7f9675fb8b-7rs5h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7rs5h,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-7rs5h,UID:3dd5041e-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20180,Generation:0,CreationTimestamp:2018-12-20 05:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d720d0 0xc420d720d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.55,PodIP:10.200.1.110,StartTime:2018-12-20 05:22:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-20 05:22:30 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://eec1c104c1589a6e04ea8b32c3f68d0bd517f2cd20190b4f51aaf48cea99ce5a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.689: INFO: Pod "nginx-deployment-7f9675fb8b-8k9lm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8k9lm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-8k9lm,UID:4185f876-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20276,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d72287 0xc420d72288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.689: INFO: Pod "nginx-deployment-7f9675fb8b-9gppf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9gppf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-9gppf,UID:3dd6d0f9-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20138,Generation:0,CreationTimestamp:2018-12-20 05:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d723b0 0xc420d723b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.54,PodIP:10.200.2.107,StartTime:2018-12-20 05:22:28 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-20 05:22:29 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://49eb4a7b11bd3a707ac93d177912a26088144d8e67ed255f8acf0efca8f5d721}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.690: INFO: Pod "nginx-deployment-7f9675fb8b-c9xks" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-c9xks,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-c9xks,UID:3dd8cc98-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20166,Generation:0,CreationTimestamp:2018-12-20 05:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d725f7 0xc420d725f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.53,PodIP:10.200.3.111,StartTime:2018-12-20 05:22:28 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-20 05:22:30 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://798838dda3f9df3e0e65b7616a341149e74de7d612c9a224deff54a56b8e7d0d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.690: INFO: Pod "nginx-deployment-7f9675fb8b-ckm68" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ckm68,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-ckm68,UID:4188e12e-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20293,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d72707 0xc420d72708}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.690: INFO: Pod "nginx-deployment-7f9675fb8b-ddmf9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ddmf9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-ddmf9,UID:4185b58b-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20272,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d72840 0xc420d72841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.690: INFO: Pod "nginx-deployment-7f9675fb8b-dw277" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dw277,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-dw277,UID:3dd97594-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20172,Generation:0,CreationTimestamp:2018-12-20 05:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d729d0 0xc420d729d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:28 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.53,PodIP:10.200.3.112,StartTime:2018-12-20 05:22:28 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-20 05:22:30 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://83558862af6d6e7a1afe1de75f40695c517318ac0118157199dc90fe9c00304c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.691: INFO: Pod "nginx-deployment-7f9675fb8b-fzvf5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fzvf5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-fzvf5,UID:4185dfed-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20273,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d72ad7 0xc420d72ad8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.691: INFO: Pod "nginx-deployment-7f9675fb8b-gl677" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gl677,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-gl677,UID:3dd4e82d-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20168,Generation:0,CreationTimestamp:2018-12-20 05:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d72d50 0xc420d72d51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.53,PodIP:10.200.3.109,StartTime:2018-12-20 05:22:27 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-20 05:22:30 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://60503e45eb8f1423bc370903f0f4b166618b279a3c06ff0ea8a19082117c2669}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.691: INFO: Pod "nginx-deployment-7f9675fb8b-hf594" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hf594,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-hf594,UID:41846a2e-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20299,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d72e77 0xc420d72e78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.54,PodIP:,StartTime:2018-12-20 05:22:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.691: INFO: Pod "nginx-deployment-7f9675fb8b-j2gq4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-j2gq4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-j2gq4,UID:4188e840-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20295,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d72f77 0xc420d72f78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.691: INFO: Pod "nginx-deployment-7f9675fb8b-jjws6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jjws6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-jjws6,UID:3dd8e950-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20177,Generation:0,CreationTimestamp:2018-12-20 05:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d73030 0xc420d73031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.55,PodIP:10.200.1.112,StartTime:2018-12-20 05:22:28 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-20 05:22:30 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://281bb87eaca6387a9b8741a72eeebf37c16e1fee2b93373b770dd392aa9a5e46}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.691: INFO: Pod "nginx-deployment-7f9675fb8b-k9ssx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-k9ssx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-k9ssx,UID:418618f9-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20283,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d73147 0xc420d73148}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.692: INFO: Pod "nginx-deployment-7f9675fb8b-pr878" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pr878,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-pr878,UID:4188c77b-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20296,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d73200 0xc420d73201}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.692: INFO: Pod "nginx-deployment-7f9675fb8b-rd6vk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rd6vk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-rd6vk,UID:41833d72-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20275,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d732b0 0xc420d732b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.54,PodIP:,StartTime:2018-12-20 05:22:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.692: INFO: Pod "nginx-deployment-7f9675fb8b-ss5df" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ss5df,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-ss5df,UID:3dd6cf79-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20131,Generation:0,CreationTimestamp:2018-12-20 05:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d733a7 0xc420d733a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.55,PodIP:10.200.1.111,StartTime:2018-12-20 05:22:28 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-20 05:22:29 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://8f52f0cbdc66eb409c5c9e409581f51ca878652212af7e4ee484e96f6a530274}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.692: INFO: Pod "nginx-deployment-7f9675fb8b-zflq7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zflq7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-zflq7,UID:41847561-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20300,Generation:0,CreationTimestamp:2018-12-20 05:22:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d734b7 0xc420d734b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:34 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.55,PodIP:,StartTime:2018-12-20 05:22:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 20 05:22:34.692: INFO: Pod "nginx-deployment-7f9675fb8b-zjwxh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zjwxh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-cg7xv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cg7xv/pods/nginx-deployment-7f9675fb8b-zjwxh,UID:3dd6e797-0417-11e9-9da8-506b8da7f7e6,ResourceVersion:20163,Generation:0,CreationTimestamp:2018-12-20 05:22:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 3dd25b12-0417-11e9-9da8-506b8da7f7e6 0xc420d735b7 0xc420d735b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lpwx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lpwx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lpwx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:22:27 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.53,PodIP:10.200.3.110,StartTime:2018-12-20 05:22:28 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-20 05:22:30 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://33dc5a295aa296795effa67bfdf1435547962dbe72cb9b52ccbb4773e3a3042d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:22:34.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-cg7xv" for this suite.
Dec 20 05:22:42.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:22:42.769: INFO: namespace: e2e-tests-deployment-cg7xv, resource: bindings, ignored listing per whitelist
Dec 20 05:22:42.866: INFO: namespace e2e-tests-deployment-cg7xv deletion completed in 8.159773441s

• [SLOW TEST:14.981 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:22:42.866: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec 20 05:22:42.927: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 20 05:22:42.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:22:43.156: INFO: stderr: ""
Dec 20 05:22:43.156: INFO: stdout: "service/redis-slave created\n"
Dec 20 05:22:43.156: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 20 05:22:43.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:22:43.387: INFO: stderr: ""
Dec 20 05:22:43.387: INFO: stdout: "service/redis-master created\n"
Dec 20 05:22:43.387: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 20 05:22:43.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:22:43.632: INFO: stderr: ""
Dec 20 05:22:43.632: INFO: stdout: "service/frontend created\n"
Dec 20 05:22:43.633: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 20 05:22:43.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:22:43.853: INFO: stderr: ""
Dec 20 05:22:43.853: INFO: stdout: "deployment.extensions/frontend created\n"
Dec 20 05:22:43.853: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 20 05:22:43.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:22:44.088: INFO: stderr: ""
Dec 20 05:22:44.088: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec 20 05:22:44.088: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 20 05:22:44.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 create -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:22:44.320: INFO: stderr: ""
Dec 20 05:22:44.320: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec 20 05:22:44.321: INFO: Waiting for all frontend pods to be Running.
Dec 20 05:22:59.372: INFO: Waiting for frontend to serve content.
Dec 20 05:23:04.399: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec 20 05:23:09.415: INFO: Trying to add a new entry to the guestbook.
Dec 20 05:23:09.428: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 20 05:23:09.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:23:09.612: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 05:23:09.612: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 20 05:23:09.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:23:09.758: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 05:23:09.758: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 20 05:23:09.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:23:09.900: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 05:23:09.900: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 20 05:23:09.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:23:10.019: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 05:23:10.019: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 20 05:23:10.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:23:10.154: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 05:23:10.154: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 20 05:23:10.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-617439060 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gvkg7'
Dec 20 05:23:10.295: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 05:23:10.295: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:23:10.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gvkg7" for this suite.
Dec 20 05:23:54.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:23:54.641: INFO: namespace: e2e-tests-kubectl-gvkg7, resource: bindings, ignored listing per whitelist
Dec 20 05:23:54.650: INFO: namespace e2e-tests-kubectl-gvkg7 deletion completed in 44.34622345s

• [SLOW TEST:71.783 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:23:54.650: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jdszp
Dec 20 05:24:00.922: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jdszp
STEP: checking the pod's current state and verifying that restartCount is present
Dec 20 05:24:00.925: INFO: Initial restart count of pod liveness-http is 0
Dec 20 05:24:18.961: INFO: Restart count of pod e2e-tests-container-probe-jdszp/liveness-http is now 1 (18.03597663s elapsed)
Dec 20 05:24:38.999: INFO: Restart count of pod e2e-tests-container-probe-jdszp/liveness-http is now 2 (38.073903278s elapsed)
Dec 20 05:24:59.040: INFO: Restart count of pod e2e-tests-container-probe-jdszp/liveness-http is now 3 (58.114482786s elapsed)
Dec 20 05:25:43.547: INFO: Restart count of pod e2e-tests-container-probe-jdszp/liveness-http is now 4 (1m42.621484841s elapsed)
Dec 20 05:25:59.575: INFO: Restart count of pod e2e-tests-container-probe-jdszp/liveness-http is now 5 (1m58.650175513s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:25:59.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jdszp" for this suite.
Dec 20 05:26:05.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:26:05.891: INFO: namespace: e2e-tests-container-probe-jdszp, resource: bindings, ignored listing per whitelist
Dec 20 05:26:05.974: INFO: namespace e2e-tests-container-probe-jdszp deletion completed in 6.116110467s

• [SLOW TEST:131.324 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:26:05.974: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 20 05:26:06.036: INFO: Waiting up to 5m0s for pod "pod-bfcf4631-0417-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-bwdh4" to be "success or failure"
Dec 20 05:26:06.040: INFO: Pod "pod-bfcf4631-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.389134ms
Dec 20 05:26:08.044: INFO: Pod "pod-bfcf4631-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008097264s
Dec 20 05:26:10.047: INFO: Pod "pod-bfcf4631-0417-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011451051s
STEP: Saw pod success
Dec 20 05:26:10.047: INFO: Pod "pod-bfcf4631-0417-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:26:10.050: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-bfcf4631-0417-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 05:26:10.113: INFO: Waiting for pod pod-bfcf4631-0417-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:26:10.116: INFO: Pod pod-bfcf4631-0417-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:26:10.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bwdh4" for this suite.
Dec 20 05:26:16.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:26:16.652: INFO: namespace: e2e-tests-emptydir-bwdh4, resource: bindings, ignored listing per whitelist
Dec 20 05:26:16.659: INFO: namespace e2e-tests-emptydir-bwdh4 deletion completed in 6.107844773s

• [SLOW TEST:10.685 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:26:16.659: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1220 05:26:17.758656      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 20 05:26:17.758: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:26:17.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jwcw5" for this suite.
Dec 20 05:26:23.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:26:23.813: INFO: namespace: e2e-tests-gc-jwcw5, resource: bindings, ignored listing per whitelist
Dec 20 05:26:23.863: INFO: namespace e2e-tests-gc-jwcw5 deletion completed in 6.10070945s

• [SLOW TEST:7.203 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:26:23.863: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 20 05:26:26.556: INFO: Successfully updated pod "annotationupdateca79c33b-0417-11e9-acdd-0a580ac80107"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:26:30.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wbhc6" for this suite.
Dec 20 05:26:52.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:26:53.194: INFO: namespace: e2e-tests-projected-wbhc6, resource: bindings, ignored listing per whitelist
Dec 20 05:26:53.262: INFO: namespace e2e-tests-projected-wbhc6 deletion completed in 22.325663139s

• [SLOW TEST:29.400 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:26:53.263: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-jg25z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-jg25z to expose endpoints map[]
Dec 20 05:26:53.583: INFO: Get endpoints failed (9.296823ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 20 05:26:54.587: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-jg25z exposes endpoints map[] (1.013158195s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-jg25z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-jg25z to expose endpoints map[pod1:[80]]
Dec 20 05:26:57.626: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-jg25z exposes endpoints map[pod1:[80]] (3.030662661s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-jg25z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-jg25z to expose endpoints map[pod1:[80] pod2:[80]]
Dec 20 05:27:00.670: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-jg25z exposes endpoints map[pod1:[80] pod2:[80]] (3.040109289s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-jg25z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-jg25z to expose endpoints map[pod2:[80]]
Dec 20 05:27:01.703: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-jg25z exposes endpoints map[pod2:[80]] (1.022663264s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-jg25z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-jg25z to expose endpoints map[]
Dec 20 05:27:02.721: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-jg25z exposes endpoints map[] (1.010602546s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:27:02.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-jg25z" for this suite.
Dec 20 05:27:09.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:27:09.170: INFO: namespace: e2e-tests-services-jg25z, resource: bindings, ignored listing per whitelist
Dec 20 05:27:09.187: INFO: namespace e2e-tests-services-jg25z deletion completed in 6.107097218s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:15.924 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:27:09.187: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 20 05:27:09.252: INFO: Waiting up to 5m0s for pod "pod-e57cbe78-0417-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-sbprc" to be "success or failure"
Dec 20 05:27:09.254: INFO: Pod "pod-e57cbe78-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.621628ms
Dec 20 05:27:11.257: INFO: Pod "pod-e57cbe78-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005531727s
Dec 20 05:27:13.260: INFO: Pod "pod-e57cbe78-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0088728s
Dec 20 05:27:15.315: INFO: Pod "pod-e57cbe78-0417-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.063880686s
STEP: Saw pod success
Dec 20 05:27:15.316: INFO: Pod "pod-e57cbe78-0417-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:27:15.368: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-e57cbe78-0417-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 05:27:15.435: INFO: Waiting for pod pod-e57cbe78-0417-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:27:15.438: INFO: Pod pod-e57cbe78-0417-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:27:15.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sbprc" for this suite.
Dec 20 05:27:21.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:27:21.769: INFO: namespace: e2e-tests-emptydir-sbprc, resource: bindings, ignored listing per whitelist
Dec 20 05:27:21.854: INFO: namespace e2e-tests-emptydir-sbprc deletion completed in 6.106979372s

• [SLOW TEST:12.667 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:27:21.854: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-khq5
STEP: Creating a pod to test atomic-volume-subpath
Dec 20 05:27:21.925: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-khq5" in namespace "e2e-tests-subpath-9pgg2" to be "success or failure"
Dec 20 05:27:21.928: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.243846ms
Dec 20 05:27:23.933: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007605989s
Dec 20 05:27:25.936: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011283587s
Dec 20 05:27:27.987: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Running", Reason="", readiness=false. Elapsed: 6.061800153s
Dec 20 05:27:30.036: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Running", Reason="", readiness=false. Elapsed: 8.111182148s
Dec 20 05:27:32.088: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Running", Reason="", readiness=false. Elapsed: 10.162975912s
Dec 20 05:27:34.137: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Running", Reason="", readiness=false. Elapsed: 12.212244336s
Dec 20 05:27:36.186: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Running", Reason="", readiness=false. Elapsed: 14.260970946s
Dec 20 05:27:38.235: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Running", Reason="", readiness=false. Elapsed: 16.309844369s
Dec 20 05:27:40.286: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Running", Reason="", readiness=false. Elapsed: 18.360377596s
Dec 20 05:27:42.334: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Running", Reason="", readiness=false. Elapsed: 20.40919754s
Dec 20 05:27:44.384: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Running", Reason="", readiness=false. Elapsed: 22.459071101s
Dec 20 05:27:46.436: INFO: Pod "pod-subpath-test-projected-khq5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.510599638s
STEP: Saw pod success
Dec 20 05:27:46.436: INFO: Pod "pod-subpath-test-projected-khq5" satisfied condition "success or failure"
Dec 20 05:27:46.488: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-subpath-test-projected-khq5 container test-container-subpath-projected-khq5: <nil>
STEP: delete the pod
Dec 20 05:27:46.558: INFO: Waiting for pod pod-subpath-test-projected-khq5 to disappear
Dec 20 05:27:46.561: INFO: Pod pod-subpath-test-projected-khq5 no longer exists
STEP: Deleting pod pod-subpath-test-projected-khq5
Dec 20 05:27:46.561: INFO: Deleting pod "pod-subpath-test-projected-khq5" in namespace "e2e-tests-subpath-9pgg2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:27:46.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9pgg2" for this suite.
Dec 20 05:27:52.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:27:52.875: INFO: namespace: e2e-tests-subpath-9pgg2, resource: bindings, ignored listing per whitelist
Dec 20 05:27:52.951: INFO: namespace e2e-tests-subpath-9pgg2 deletion completed in 6.106829306s

• [SLOW TEST:31.097 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:27:52.951: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 20 05:27:53.016: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ff92abca-0417-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-6qplj" to be "success or failure"
Dec 20 05:27:53.020: INFO: Pod "downwardapi-volume-ff92abca-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 4.265105ms
Dec 20 05:27:55.025: INFO: Pod "downwardapi-volume-ff92abca-0417-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009492141s
Dec 20 05:27:57.029: INFO: Pod "downwardapi-volume-ff92abca-0417-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01300288s
STEP: Saw pod success
Dec 20 05:27:57.029: INFO: Pod "downwardapi-volume-ff92abca-0417-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:27:57.031: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod downwardapi-volume-ff92abca-0417-11e9-acdd-0a580ac80107 container client-container: <nil>
STEP: delete the pod
Dec 20 05:27:57.050: INFO: Waiting for pod downwardapi-volume-ff92abca-0417-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:27:57.052: INFO: Pod downwardapi-volume-ff92abca-0417-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:27:57.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6qplj" for this suite.
Dec 20 05:28:03.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:28:03.098: INFO: namespace: e2e-tests-projected-6qplj, resource: bindings, ignored listing per whitelist
Dec 20 05:28:03.163: INFO: namespace e2e-tests-projected-6qplj deletion completed in 6.106908371s

• [SLOW TEST:10.211 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:28:03.163: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 20 05:28:03.245: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:28:03.248: INFO: Number of nodes with available pods: 0
Dec 20 05:28:03.248: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 05:28:04.253: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:28:04.257: INFO: Number of nodes with available pods: 0
Dec 20 05:28:04.257: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 05:28:05.253: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:28:05.257: INFO: Number of nodes with available pods: 0
Dec 20 05:28:05.257: INFO: Node acsk8s-3f716c-k8s-worker-0 is running more than one daemon pod
Dec 20 05:28:06.252: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:28:06.256: INFO: Number of nodes with available pods: 3
Dec 20 05:28:06.256: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 20 05:28:06.270: INFO: DaemonSet pods can't tolerate node acsk8s-3f716c-k8s-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 05:28:06.275: INFO: Number of nodes with available pods: 3
Dec 20 05:28:06.275: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-fcj66, will wait for the garbage collector to delete the pods
Dec 20 05:28:07.349: INFO: Deleting {extensions DaemonSet} daemon-set took: 8.914907ms
Dec 20 05:28:07.549: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.256001ms
Dec 20 05:28:47.453: INFO: Number of nodes with available pods: 0
Dec 20 05:28:47.453: INFO: Number of running nodes: 0, number of available pods: 0
Dec 20 05:28:47.456: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fcj66/daemonsets","resourceVersion":"21727"},"items":null}

Dec 20 05:28:47.458: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fcj66/pods","resourceVersion":"21727"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:28:47.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fcj66" for this suite.
Dec 20 05:28:53.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:28:53.919: INFO: namespace: e2e-tests-daemonsets-fcj66, resource: bindings, ignored listing per whitelist
Dec 20 05:28:53.943: INFO: namespace e2e-tests-daemonsets-fcj66 deletion completed in 6.109969513s

• [SLOW TEST:50.780 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:28:53.943: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec 20 05:28:58.056: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:29:22.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-2zm7v" for this suite.
Dec 20 05:29:28.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:29:28.532: INFO: namespace: e2e-tests-namespaces-2zm7v, resource: bindings, ignored listing per whitelist
Dec 20 05:29:28.592: INFO: namespace e2e-tests-namespaces-2zm7v deletion completed in 6.11441338s
STEP: Destroying namespace "e2e-tests-nsdeletetest-r4w4q" for this suite.
Dec 20 05:29:28.594: INFO: Namespace e2e-tests-nsdeletetest-r4w4q was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-j4fdb" for this suite.
Dec 20 05:29:34.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:29:34.628: INFO: namespace: e2e-tests-nsdeletetest-j4fdb, resource: bindings, ignored listing per whitelist
Dec 20 05:29:34.701: INFO: namespace e2e-tests-nsdeletetest-j4fdb deletion completed in 6.106175583s

• [SLOW TEST:40.757 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:29:34.701: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-3c38de9d-0418-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume secrets
Dec 20 05:29:34.775: INFO: Waiting up to 5m0s for pod "pod-secrets-3c39d1e8-0418-11e9-acdd-0a580ac80107" in namespace "e2e-tests-secrets-p99v2" to be "success or failure"
Dec 20 05:29:34.781: INFO: Pod "pod-secrets-3c39d1e8-0418-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 5.899979ms
Dec 20 05:29:36.783: INFO: Pod "pod-secrets-3c39d1e8-0418-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008740026s
Dec 20 05:29:38.840: INFO: Pod "pod-secrets-3c39d1e8-0418-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064949577s
STEP: Saw pod success
Dec 20 05:29:38.840: INFO: Pod "pod-secrets-3c39d1e8-0418-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:29:38.886: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-secrets-3c39d1e8-0418-11e9-acdd-0a580ac80107 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 05:29:38.948: INFO: Waiting for pod pod-secrets-3c39d1e8-0418-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:29:38.951: INFO: Pod pod-secrets-3c39d1e8-0418-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:29:38.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-p99v2" for this suite.
Dec 20 05:29:45.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:29:45.399: INFO: namespace: e2e-tests-secrets-p99v2, resource: bindings, ignored listing per whitelist
Dec 20 05:29:45.402: INFO: namespace e2e-tests-secrets-p99v2 deletion completed in 6.104154725s

• [SLOW TEST:10.701 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:29:45.402: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 05:29:45.459: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:29:46.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-g4pck" for this suite.
Dec 20 05:29:52.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:29:52.782: INFO: namespace: e2e-tests-custom-resource-definition-g4pck, resource: bindings, ignored listing per whitelist
Dec 20 05:29:52.796: INFO: namespace e2e-tests-custom-resource-definition-g4pck deletion completed in 6.283772864s

• [SLOW TEST:7.394 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:29:52.796: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 20 05:29:59.231: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wf7pp PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 05:29:59.231: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 05:29:59.340: INFO: Exec stderr: ""
Dec 20 05:29:59.340: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wf7pp PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 05:29:59.340: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 05:29:59.450: INFO: Exec stderr: ""
Dec 20 05:29:59.450: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wf7pp PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 05:29:59.450: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 05:29:59.561: INFO: Exec stderr: ""
Dec 20 05:29:59.562: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wf7pp PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 05:29:59.562: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 05:29:59.671: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 20 05:29:59.671: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wf7pp PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 05:29:59.671: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 05:29:59.788: INFO: Exec stderr: ""
Dec 20 05:29:59.788: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wf7pp PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 05:29:59.788: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 05:29:59.900: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 20 05:29:59.900: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wf7pp PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 05:29:59.900: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 05:30:00.011: INFO: Exec stderr: ""
Dec 20 05:30:00.011: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wf7pp PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 05:30:00.011: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 05:30:00.130: INFO: Exec stderr: ""
Dec 20 05:30:00.131: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wf7pp PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 05:30:00.131: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 05:30:00.194: INFO: Exec stderr: ""
Dec 20 05:30:00.194: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-wf7pp PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 05:30:00.194: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
Dec 20 05:30:00.258: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:30:00.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-wf7pp" for this suite.
Dec 20 05:30:50.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:30:50.516: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-wf7pp, resource: bindings, ignored listing per whitelist
Dec 20 05:30:50.590: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-wf7pp deletion completed in 50.328933091s

• [SLOW TEST:57.794 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:30:50.591: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 20 05:30:50.845: INFO: Waiting up to 5m0s for pod "pod-69916c1b-0418-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-fzwxv" to be "success or failure"
Dec 20 05:30:50.856: INFO: Pod "pod-69916c1b-0418-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 11.155838ms
Dec 20 05:30:52.860: INFO: Pod "pod-69916c1b-0418-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014867338s
Dec 20 05:30:54.864: INFO: Pod "pod-69916c1b-0418-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01892823s
STEP: Saw pod success
Dec 20 05:30:54.864: INFO: Pod "pod-69916c1b-0418-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:30:54.866: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-0 pod pod-69916c1b-0418-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 05:30:54.885: INFO: Waiting for pod pod-69916c1b-0418-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:30:54.889: INFO: Pod pod-69916c1b-0418-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:30:54.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fzwxv" for this suite.
Dec 20 05:31:00.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:31:00.986: INFO: namespace: e2e-tests-emptydir-fzwxv, resource: bindings, ignored listing per whitelist
Dec 20 05:31:00.990: INFO: namespace e2e-tests-emptydir-fzwxv deletion completed in 6.097817619s

• [SLOW TEST:10.400 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:31:00.991: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1220 05:31:07.475180      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 20 05:31:07.475: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:31:07.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-v4b4k" for this suite.
Dec 20 05:31:13.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:31:13.609: INFO: namespace: e2e-tests-gc-v4b4k, resource: bindings, ignored listing per whitelist
Dec 20 05:31:13.674: INFO: namespace e2e-tests-gc-v4b4k deletion completed in 6.1099448s

• [SLOW TEST:12.684 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:31:13.674: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 05:31:13.745: INFO: (0) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.319857ms)
Dec 20 05:31:13.748: INFO: (1) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.115203ms)
Dec 20 05:31:13.751: INFO: (2) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.341338ms)
Dec 20 05:31:13.754: INFO: (3) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 2.839608ms)
Dec 20 05:31:13.757: INFO: (4) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.275127ms)
Dec 20 05:31:13.760: INFO: (5) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.225832ms)
Dec 20 05:31:13.765: INFO: (6) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 4.235332ms)
Dec 20 05:31:13.768: INFO: (7) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 2.87043ms)
Dec 20 05:31:13.771: INFO: (8) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.291897ms)
Dec 20 05:31:13.774: INFO: (9) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.126159ms)
Dec 20 05:31:13.777: INFO: (10) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.083505ms)
Dec 20 05:31:13.780: INFO: (11) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 2.831424ms)
Dec 20 05:31:13.783: INFO: (12) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 2.867026ms)
Dec 20 05:31:13.786: INFO: (13) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 2.900337ms)
Dec 20 05:31:13.789: INFO: (14) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.473065ms)
Dec 20 05:31:13.792: INFO: (15) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.063415ms)
Dec 20 05:31:13.796: INFO: (16) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.65802ms)
Dec 20 05:31:13.799: INFO: (17) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.275173ms)
Dec 20 05:31:13.803: INFO: (18) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 3.275359ms)
Dec 20 05:31:13.806: INFO: (19) /api/v1/nodes/acsk8s-3f716c-k8s-worker-0/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="chrony/">chrony/</a>
<a hr... (200; 2.928552ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:31:13.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-cp589" for this suite.
Dec 20 05:31:19.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:31:19.914: INFO: namespace: e2e-tests-proxy-cp589, resource: bindings, ignored listing per whitelist
Dec 20 05:31:19.916: INFO: namespace e2e-tests-proxy-cp589 deletion completed in 6.106797802s

• [SLOW TEST:6.242 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:31:19.916: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-7aeede91-0418-11e9-acdd-0a580ac80107
STEP: Creating a pod to test consume configMaps
Dec 20 05:31:19.982: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7aef8729-0418-11e9-acdd-0a580ac80107" in namespace "e2e-tests-projected-54rx6" to be "success or failure"
Dec 20 05:31:19.986: INFO: Pod "pod-projected-configmaps-7aef8729-0418-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.147489ms
Dec 20 05:31:21.989: INFO: Pod "pod-projected-configmaps-7aef8729-0418-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006181865s
Dec 20 05:31:24.040: INFO: Pod "pod-projected-configmaps-7aef8729-0418-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057471942s
STEP: Saw pod success
Dec 20 05:31:24.040: INFO: Pod "pod-projected-configmaps-7aef8729-0418-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:31:24.084: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-projected-configmaps-7aef8729-0418-11e9-acdd-0a580ac80107 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 05:31:24.151: INFO: Waiting for pod pod-projected-configmaps-7aef8729-0418-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:31:24.153: INFO: Pod pod-projected-configmaps-7aef8729-0418-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:31:24.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-54rx6" for this suite.
Dec 20 05:31:30.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:31:30.550: INFO: namespace: e2e-tests-projected-54rx6, resource: bindings, ignored listing per whitelist
Dec 20 05:31:30.564: INFO: namespace e2e-tests-projected-54rx6 deletion completed in 6.100978289s

• [SLOW TEST:10.648 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:31:30.565: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 20 05:31:30.619: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 20 05:31:30.627: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 20 05:31:35.630: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 20 05:31:35.630: INFO: Creating deployment "test-rolling-update-deployment"
Dec 20 05:31:35.636: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 20 05:31:35.644: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 20 05:31:37.704: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 20 05:31:37.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680880695, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680880695, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680880695, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680880695, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 05:31:39.712: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 20 05:31:39.770: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-v6dff,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v6dff/deployments/test-rolling-update-deployment,UID:844427c9-0418-11e9-9da8-506b8da7f7e6,ResourceVersion:22504,Generation:1,CreationTimestamp:2018-12-20 05:31:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-20 05:31:35 +0000 UTC 2018-12-20 05:31:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-20 05:31:37 +0000 UTC 2018-12-20 05:31:35 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 20 05:31:39.820: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-v6dff,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v6dff/replicasets/test-rolling-update-deployment-65b7695dcf,UID:84463ddf-0418-11e9-9da8-506b8da7f7e6,ResourceVersion:22495,Generation:1,CreationTimestamp:2018-12-20 05:31:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 844427c9-0418-11e9-9da8-506b8da7f7e6 0xc422ef2d27 0xc422ef2d28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 20 05:31:39.820: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 20 05:31:39.820: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-v6dff,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v6dff/replicasets/test-rolling-update-controller,UID:81478763-0418-11e9-9da8-506b8da7f7e6,ResourceVersion:22503,Generation:2,CreationTimestamp:2018-12-20 05:31:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 844427c9-0418-11e9-9da8-506b8da7f7e6 0xc422ef2c4e 0xc422ef2c4f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 20 05:31:39.872: INFO: Pod "test-rolling-update-deployment-65b7695dcf-vzxtd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-vzxtd,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-v6dff,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v6dff/pods/test-rolling-update-deployment-65b7695dcf-vzxtd,UID:8446e928-0418-11e9-9da8-506b8da7f7e6,ResourceVersion:22494,Generation:0,CreationTimestamp:2018-12-20 05:31:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 84463ddf-0418-11e9-9da8-506b8da7f7e6 0xc422ef3597 0xc422ef3598}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-z7qls {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z7qls,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-z7qls true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:acsk8s-3f716c-k8s-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:31:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:31:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:31:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-20 05:31:35 +0000 UTC  }],Message:,Reason:,HostIP:10.40.154.54,PodIP:10.200.2.146,StartTime:2018-12-20 05:31:35 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-20 05:31:37 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://198b6db8a63290408fab9dc7cc15890eba77a5c7d7c63a7187d32f6af05f43a8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:31:39.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-v6dff" for this suite.
Dec 20 05:31:46.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:31:46.276: INFO: namespace: e2e-tests-deployment-v6dff, resource: bindings, ignored listing per whitelist
Dec 20 05:31:46.283: INFO: namespace e2e-tests-deployment-v6dff deletion completed in 6.113302795s

• [SLOW TEST:15.719 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:31:46.283: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-ppmt
STEP: Creating a pod to test atomic-volume-subpath
Dec 20 05:31:46.369: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ppmt" in namespace "e2e-tests-subpath-b4fp4" to be "success or failure"
Dec 20 05:31:46.375: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Pending", Reason="", readiness=false. Elapsed: 5.883986ms
Dec 20 05:31:48.379: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009928788s
Dec 20 05:31:50.383: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013943703s
Dec 20 05:31:52.436: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Running", Reason="", readiness=false. Elapsed: 6.066725796s
Dec 20 05:31:54.486: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Running", Reason="", readiness=false. Elapsed: 8.116528587s
Dec 20 05:31:56.539: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Running", Reason="", readiness=false. Elapsed: 10.169788546s
Dec 20 05:31:58.591: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Running", Reason="", readiness=false. Elapsed: 12.221703019s
Dec 20 05:32:00.646: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Running", Reason="", readiness=false. Elapsed: 14.276292575s
Dec 20 05:32:02.695: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Running", Reason="", readiness=false. Elapsed: 16.325476322s
Dec 20 05:32:04.741: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Running", Reason="", readiness=false. Elapsed: 18.371401072s
Dec 20 05:32:06.788: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Running", Reason="", readiness=false. Elapsed: 20.418124811s
Dec 20 05:32:08.792: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Running", Reason="", readiness=false. Elapsed: 22.422846187s
Dec 20 05:32:10.796: INFO: Pod "pod-subpath-test-configmap-ppmt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.426441817s
STEP: Saw pod success
Dec 20 05:32:10.796: INFO: Pod "pod-subpath-test-configmap-ppmt" satisfied condition "success or failure"
Dec 20 05:32:10.798: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-2 pod pod-subpath-test-configmap-ppmt container test-container-subpath-configmap-ppmt: <nil>
STEP: delete the pod
Dec 20 05:32:10.820: INFO: Waiting for pod pod-subpath-test-configmap-ppmt to disappear
Dec 20 05:32:10.822: INFO: Pod pod-subpath-test-configmap-ppmt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ppmt
Dec 20 05:32:10.822: INFO: Deleting pod "pod-subpath-test-configmap-ppmt" in namespace "e2e-tests-subpath-b4fp4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:32:10.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-b4fp4" for this suite.
Dec 20 05:32:16.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:32:16.926: INFO: namespace: e2e-tests-subpath-b4fp4, resource: bindings, ignored listing per whitelist
Dec 20 05:32:16.929: INFO: namespace e2e-tests-subpath-b4fp4 deletion completed in 6.099299262s

• [SLOW TEST:30.646 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:32:16.929: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 20 05:32:21.718: INFO: Successfully updated pod "labelsupdate9ceb17f8-0418-11e9-acdd-0a580ac80107"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:32:23.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rqc85" for this suite.
Dec 20 05:32:46.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:32:46.350: INFO: namespace: e2e-tests-projected-rqc85, resource: bindings, ignored listing per whitelist
Dec 20 05:32:46.422: INFO: namespace e2e-tests-projected-rqc85 deletion completed in 22.377618973s

• [SLOW TEST:29.493 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:32:46.423: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 20 05:32:46.777: INFO: Waiting up to 5m0s for pod "pod-aeab68bb-0418-11e9-acdd-0a580ac80107" in namespace "e2e-tests-emptydir-xfrmd" to be "success or failure"
Dec 20 05:32:46.780: INFO: Pod "pod-aeab68bb-0418-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 3.035367ms
Dec 20 05:32:48.784: INFO: Pod "pod-aeab68bb-0418-11e9-acdd-0a580ac80107": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006690916s
Dec 20 05:32:50.788: INFO: Pod "pod-aeab68bb-0418-11e9-acdd-0a580ac80107": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010516871s
STEP: Saw pod success
Dec 20 05:32:50.788: INFO: Pod "pod-aeab68bb-0418-11e9-acdd-0a580ac80107" satisfied condition "success or failure"
Dec 20 05:32:50.790: INFO: Trying to get logs from node acsk8s-3f716c-k8s-worker-1 pod pod-aeab68bb-0418-11e9-acdd-0a580ac80107 container test-container: <nil>
STEP: delete the pod
Dec 20 05:32:50.816: INFO: Waiting for pod pod-aeab68bb-0418-11e9-acdd-0a580ac80107 to disappear
Dec 20 05:32:50.819: INFO: Pod pod-aeab68bb-0418-11e9-acdd-0a580ac80107 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:32:50.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xfrmd" for this suite.
Dec 20 05:32:56.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:32:56.865: INFO: namespace: e2e-tests-emptydir-xfrmd, resource: bindings, ignored listing per whitelist
Dec 20 05:32:56.936: INFO: namespace e2e-tests-emptydir-xfrmd deletion completed in 6.112495466s

• [SLOW TEST:10.513 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 20 05:32:56.936: INFO: >>> kubeConfig: /tmp/kubeconfig-617439060
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec 20 05:32:56.991: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 20 05:32:56.998: INFO: Waiting for terminating namespaces to be deleted...
Dec 20 05:32:57.001: INFO: 
Logging pods the kubelet thinks is on node acsk8s-3f716c-k8s-worker-0 before test
Dec 20 05:32:57.009: INFO: prometheus-k8s-0 from monitoring started at 2018-12-20 03:32:08 +0000 UTC (3 container statuses recorded)
Dec 20 05:32:57.009: INFO: 	Container prometheus ready: true, restart count 1
Dec 20 05:32:57.009: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Dec 20 05:32:57.009: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Dec 20 05:32:57.009: INFO: alertmanager-main-2 from monitoring started at 2018-12-20 03:32:25 +0000 UTC (2 container statuses recorded)
Dec 20 05:32:57.009: INFO: 	Container alertmanager ready: true, restart count 0
Dec 20 05:32:57.009: INFO: 	Container config-reloader ready: true, restart count 0
Dec 20 05:32:57.009: INFO: prometheus-operator-6494c4f69b-rz2bs from monitoring started at 2018-12-20 03:31:49 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.009: INFO: 	Container prometheus-operator ready: true, restart count 0
Dec 20 05:32:57.009: INFO: sonobuoy-e2e-job-8437e4dc2d8146dc from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:32:57.009: INFO: 	Container e2e ready: true, restart count 0
Dec 20 05:32:57.009: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 20 05:32:57.009: INFO: kube-proxy-ds-fcgv7 from kube-system started at 2018-12-20 03:28:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.009: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 05:32:57.009: INFO: kibana-logging-557ddfb798-25hl8 from ntnx-logging started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.009: INFO: 	Container kibana-logging ready: true, restart count 0
Dec 20 05:32:57.009: INFO: kube-flannel-ds-hgmsk from kube-system started at 2018-12-20 03:28:31 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.009: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 20 05:32:57.009: INFO: sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-7j587 from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:32:57.009: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 20 05:32:57.009: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 20 05:32:57.009: INFO: fluent-bit-9jlsp from kube-system started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.009: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 20 05:32:57.009: INFO: node-exporter-6bq8k from monitoring started at 2018-12-20 03:31:50 +0000 UTC (2 container statuses recorded)
Dec 20 05:32:57.009: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 20 05:32:57.009: INFO: 	Container node-exporter ready: true, restart count 0
Dec 20 05:32:57.009: INFO: 
Logging pods the kubelet thinks is on node acsk8s-3f716c-k8s-worker-1 before test
Dec 20 05:32:57.015: INFO: kube-flannel-ds-jsn8t from kube-system started at 2018-12-20 03:28:31 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.015: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 20 05:32:57.015: INFO: fluent-bit-tpqjx from kube-system started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.015: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 20 05:32:57.015: INFO: kube-proxy-ds-8spq8 from kube-system started at 2018-12-20 03:28:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.015: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 05:32:57.015: INFO: alertmanager-main-1 from monitoring started at 2018-12-20 03:32:14 +0000 UTC (2 container statuses recorded)
Dec 20 05:32:57.015: INFO: 	Container alertmanager ready: true, restart count 0
Dec 20 05:32:57.015: INFO: 	Container config-reloader ready: true, restart count 0
Dec 20 05:32:57.015: INFO: sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-9jw8w from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:32:57.015: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 20 05:32:57.015: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 20 05:32:57.015: INFO: elasticsearch-logging-0 from ntnx-logging started at 2018-12-20 03:29:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.015: INFO: 	Container elasticsearch-logging ready: true, restart count 0
Dec 20 05:32:57.015: INFO: prometheus-k8s-1 from monitoring started at 2018-12-20 03:32:25 +0000 UTC (3 container statuses recorded)
Dec 20 05:32:57.015: INFO: 	Container prometheus ready: true, restart count 1
Dec 20 05:32:57.015: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Dec 20 05:32:57.015: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Dec 20 05:32:57.015: INFO: node-exporter-qp54z from monitoring started at 2018-12-20 03:31:50 +0000 UTC (2 container statuses recorded)
Dec 20 05:32:57.015: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 20 05:32:57.015: INFO: 	Container node-exporter ready: true, restart count 0
Dec 20 05:32:57.015: INFO: 
Logging pods the kubelet thinks is on node acsk8s-3f716c-k8s-worker-2 before test
Dec 20 05:32:57.021: INFO: sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-g55ds from heptio-sonobuoy started at 2018-12-20 04:01:51 +0000 UTC (2 container statuses recorded)
Dec 20 05:32:57.021: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 20 05:32:57.021: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 20 05:32:57.021: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-20 04:01:45 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.021: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 20 05:32:57.021: INFO: kube-proxy-ds-6h5q6 from kube-system started at 2018-12-20 03:28:26 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.021: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 05:32:57.021: INFO: kube-flannel-ds-dgwvj from kube-system started at 2018-12-20 03:28:31 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.021: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 20 05:32:57.021: INFO: fluent-bit-7v27c from kube-system started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.021: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 20 05:32:57.021: INFO: kubernetes-events-printer-57f7df584d-zdrps from ntnx-logging started at 2018-12-20 03:29:07 +0000 UTC (1 container statuses recorded)
Dec 20 05:32:57.021: INFO: 	Container kubernetes-events-printer ready: true, restart count 0
Dec 20 05:32:57.021: INFO: node-exporter-g96wx from monitoring started at 2018-12-20 03:31:50 +0000 UTC (2 container statuses recorded)
Dec 20 05:32:57.021: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 20 05:32:57.021: INFO: 	Container node-exporter ready: true, restart count 0
Dec 20 05:32:57.021: INFO: alertmanager-main-0 from monitoring started at 2018-12-20 03:32:00 +0000 UTC (2 container statuses recorded)
Dec 20 05:32:57.021: INFO: 	Container alertmanager ready: true, restart count 0
Dec 20 05:32:57.021: INFO: 	Container config-reloader ready: true, restart count 0
Dec 20 05:32:57.021: INFO: kube-state-metrics-58649d5448-bwppx from monitoring started at 2018-12-20 03:32:09 +0000 UTC (4 container statuses recorded)
Dec 20 05:32:57.021: INFO: 	Container addon-resizer ready: true, restart count 0
Dec 20 05:32:57.021: INFO: 	Container kube-rbac-proxy-main ready: true, restart count 0
Dec 20 05:32:57.021: INFO: 	Container kube-rbac-proxy-self ready: true, restart count 0
Dec 20 05:32:57.021: INFO: 	Container kube-state-metrics ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node acsk8s-3f716c-k8s-worker-0
STEP: verifying the node has the label node acsk8s-3f716c-k8s-worker-1
STEP: verifying the node has the label node acsk8s-3f716c-k8s-worker-2
Dec 20 05:32:57.067: INFO: Pod sonobuoy requesting resource cpu=0m on Node acsk8s-3f716c-k8s-worker-2
Dec 20 05:32:57.067: INFO: Pod sonobuoy-e2e-job-8437e4dc2d8146dc requesting resource cpu=0m on Node acsk8s-3f716c-k8s-worker-0
Dec 20 05:32:57.067: INFO: Pod sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-7j587 requesting resource cpu=0m on Node acsk8s-3f716c-k8s-worker-0
Dec 20 05:32:57.067: INFO: Pod sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-9jw8w requesting resource cpu=0m on Node acsk8s-3f716c-k8s-worker-1
Dec 20 05:32:57.067: INFO: Pod sonobuoy-systemd-logs-daemon-set-19cb8bcc8728477d-g55ds requesting resource cpu=0m on Node acsk8s-3f716c-k8s-worker-2
Dec 20 05:32:57.067: INFO: Pod fluent-bit-7v27c requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-2
Dec 20 05:32:57.067: INFO: Pod fluent-bit-9jlsp requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-0
Dec 20 05:32:57.067: INFO: Pod fluent-bit-tpqjx requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-1
Dec 20 05:32:57.067: INFO: Pod kube-flannel-ds-dgwvj requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-2
Dec 20 05:32:57.067: INFO: Pod kube-flannel-ds-hgmsk requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-0
Dec 20 05:32:57.067: INFO: Pod kube-flannel-ds-jsn8t requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-1
Dec 20 05:32:57.067: INFO: Pod kube-proxy-ds-6h5q6 requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-2
Dec 20 05:32:57.067: INFO: Pod kube-proxy-ds-8spq8 requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-1
Dec 20 05:32:57.067: INFO: Pod kube-proxy-ds-fcgv7 requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-0
Dec 20 05:32:57.067: INFO: Pod alertmanager-main-0 requesting resource cpu=5m on Node acsk8s-3f716c-k8s-worker-2
Dec 20 05:32:57.067: INFO: Pod alertmanager-main-1 requesting resource cpu=5m on Node acsk8s-3f716c-k8s-worker-1
Dec 20 05:32:57.067: INFO: Pod alertmanager-main-2 requesting resource cpu=5m on Node acsk8s-3f716c-k8s-worker-0
Dec 20 05:32:57.067: INFO: Pod kube-state-metrics-58649d5448-bwppx requesting resource cpu=138m on Node acsk8s-3f716c-k8s-worker-2
Dec 20 05:32:57.067: INFO: Pod node-exporter-6bq8k requesting resource cpu=112m on Node acsk8s-3f716c-k8s-worker-0
Dec 20 05:32:57.067: INFO: Pod node-exporter-g96wx requesting resource cpu=112m on Node acsk8s-3f716c-k8s-worker-2
Dec 20 05:32:57.067: INFO: Pod node-exporter-qp54z requesting resource cpu=112m on Node acsk8s-3f716c-k8s-worker-1
Dec 20 05:32:57.067: INFO: Pod prometheus-k8s-0 requesting resource cpu=15m on Node acsk8s-3f716c-k8s-worker-0
Dec 20 05:32:57.067: INFO: Pod prometheus-k8s-1 requesting resource cpu=15m on Node acsk8s-3f716c-k8s-worker-1
Dec 20 05:32:57.067: INFO: Pod prometheus-operator-6494c4f69b-rz2bs requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-0
Dec 20 05:32:57.067: INFO: Pod elasticsearch-logging-0 requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-1
Dec 20 05:32:57.067: INFO: Pod kibana-logging-557ddfb798-25hl8 requesting resource cpu=100m on Node acsk8s-3f716c-k8s-worker-0
Dec 20 05:32:57.067: INFO: Pod kubernetes-events-printer-57f7df584d-zdrps requesting resource cpu=0m on Node acsk8s-3f716c-k8s-worker-2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4cea645-0418-11e9-acdd-0a580ac80107.1571f39702eb82b3], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-spwpl/filler-pod-b4cea645-0418-11e9-acdd-0a580ac80107 to acsk8s-3f716c-k8s-worker-0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4cea645-0418-11e9-acdd-0a580ac80107.1571f3976bdc9d98], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4cea645-0418-11e9-acdd-0a580ac80107.1571f3976dcb896c], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4cea645-0418-11e9-acdd-0a580ac80107.1571f3977491aec4], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4cfba6e-0418-11e9-acdd-0a580ac80107.1571f397032f835c], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-spwpl/filler-pod-b4cfba6e-0418-11e9-acdd-0a580ac80107 to acsk8s-3f716c-k8s-worker-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4cfba6e-0418-11e9-acdd-0a580ac80107.1571f39785ea0eb7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4cfba6e-0418-11e9-acdd-0a580ac80107.1571f39788121184], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4cfba6e-0418-11e9-acdd-0a580ac80107.1571f3978eb0e3b9], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4d0a3e4-0418-11e9-acdd-0a580ac80107.1571f397039457ed], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-spwpl/filler-pod-b4d0a3e4-0418-11e9-acdd-0a580ac80107 to acsk8s-3f716c-k8s-worker-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4d0a3e4-0418-11e9-acdd-0a580ac80107.1571f3977f43370d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4d0a3e4-0418-11e9-acdd-0a580ac80107.1571f3978177c5b6], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b4d0a3e4-0418-11e9-acdd-0a580ac80107.1571f39787f2d1da], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1571f397f6780f7f], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu.]
STEP: removing the label node off the node acsk8s-3f716c-k8s-worker-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node acsk8s-3f716c-k8s-worker-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node acsk8s-3f716c-k8s-worker-0
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 20 05:33:02.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-spwpl" for this suite.
Dec 20 05:33:08.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 05:33:08.692: INFO: namespace: e2e-tests-sched-pred-spwpl, resource: bindings, ignored listing per whitelist
Dec 20 05:33:08.747: INFO: namespace e2e-tests-sched-pred-spwpl deletion completed in 6.096435629s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.811 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSDec 20 05:33:08.747: INFO: Running AfterSuite actions on all node
Dec 20 05:33:08.747: INFO: Running AfterSuite actions on node 1
Dec 20 05:33:08.747: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5450.492 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h30m51.412935336s
Test Suite Passed
