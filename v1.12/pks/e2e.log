Jan 16 05:28:31.779: INFO: Overriding default scale value of zero to 1
Jan 16 05:28:31.779: INFO: Overriding default milliseconds value of zero to 5000
I0116 05:28:32.278129      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-014349168
I0116 05:28:32.278539      15 e2e.go:304] Starting e2e run "8fc6ae03-194f-11e9-af83-025056002014" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1547616511 - Will randomize all specs
Will run 188 of 1814 specs

Jan 16 05:28:32.427: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 05:28:32.429: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 16 05:28:32.442: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 16 05:28:32.467: INFO: 6 / 6 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 16 05:28:32.467: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Jan 16 05:28:32.467: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 16 05:28:32.473: INFO: e2e test version: v1.12.1
Jan 16 05:28:32.474: INFO: kube-apiserver version: v1.12.4
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:28:32.475: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename container-probe
Jan 16 05:28:32.563: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Jan 16 05:28:32.580: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-m9wg9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-m9wg9
Jan 16 05:28:44.733: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-m9wg9
STEP: checking the pod's current state and verifying that restartCount is present
Jan 16 05:28:44.744: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:32:45.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-m9wg9" for this suite.
Jan 16 05:32:51.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:32:51.386: INFO: namespace: e2e-tests-container-probe-m9wg9, resource: bindings, ignored listing per whitelist
Jan 16 05:32:51.397: INFO: namespace e2e-tests-container-probe-m9wg9 deletion completed in 6.103775898s

• [SLOW TEST:258.922 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:32:51.397: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-hng2r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan 16 05:32:51.587: INFO: Waiting up to 5m0s for pod "client-containers-2ab0b010-1950-11e9-af83-025056002014" in namespace "e2e-tests-containers-hng2r" to be "success or failure"
Jan 16 05:32:51.600: INFO: Pod "client-containers-2ab0b010-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 12.244057ms
Jan 16 05:32:53.603: INFO: Pod "client-containers-2ab0b010-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016045159s
Jan 16 05:32:55.610: INFO: Pod "client-containers-2ab0b010-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023106022s
Jan 16 05:32:57.614: INFO: Pod "client-containers-2ab0b010-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026891215s
Jan 16 05:32:59.618: INFO: Pod "client-containers-2ab0b010-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.030240829s
Jan 16 05:33:01.622: INFO: Pod "client-containers-2ab0b010-1950-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.03440291s
STEP: Saw pod success
Jan 16 05:33:01.622: INFO: Pod "client-containers-2ab0b010-1950-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:33:01.624: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod client-containers-2ab0b010-1950-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 05:33:01.643: INFO: Waiting for pod client-containers-2ab0b010-1950-11e9-af83-025056002014 to disappear
Jan 16 05:33:01.649: INFO: Pod client-containers-2ab0b010-1950-11e9-af83-025056002014 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:33:01.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-hng2r" for this suite.
Jan 16 05:33:07.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:33:07.708: INFO: namespace: e2e-tests-containers-hng2r, resource: bindings, ignored listing per whitelist
Jan 16 05:33:07.766: INFO: namespace e2e-tests-containers-hng2r deletion completed in 6.112420278s

• [SLOW TEST:16.369 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:33:07.771: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-rq78b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-rq78b
Jan 16 05:33:11.996: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-rq78b
STEP: checking the pod's current state and verifying that restartCount is present
Jan 16 05:33:11.999: INFO: Initial restart count of pod liveness-exec is 0
Jan 16 05:34:04.118: INFO: Restart count of pod e2e-tests-container-probe-rq78b/liveness-exec is now 1 (52.119125459s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:34:04.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rq78b" for this suite.
Jan 16 05:34:10.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:34:10.212: INFO: namespace: e2e-tests-container-probe-rq78b, resource: bindings, ignored listing per whitelist
Jan 16 05:34:10.266: INFO: namespace e2e-tests-container-probe-rq78b deletion completed in 6.109430577s

• [SLOW TEST:62.495 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:34:10.266: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-nr2t4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-nr2t4
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-nr2t4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-nr2t4
Jan 16 05:34:10.494: INFO: Found 0 stateful pods, waiting for 1
Jan 16 05:34:20.499: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan 16 05:34:20.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-nr2t4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 16 05:34:20.720: INFO: stderr: ""
Jan 16 05:34:20.720: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 16 05:34:20.720: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 16 05:34:20.723: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 16 05:34:30.727: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 16 05:34:30.727: INFO: Waiting for statefulset status.replicas updated to 0
Jan 16 05:34:30.750: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999761s
Jan 16 05:34:31.753: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990430447s
Jan 16 05:34:32.757: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987205695s
Jan 16 05:34:33.760: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983119646s
Jan 16 05:34:34.764: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.97987722s
Jan 16 05:34:35.768: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.975743957s
Jan 16 05:34:36.771: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.972001812s
Jan 16 05:34:37.775: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.968793108s
Jan 16 05:34:38.779: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.964997804s
Jan 16 05:34:39.782: INFO: Verifying statefulset ss doesn't scale past 1 for another 961.536653ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-nr2t4
Jan 16 05:34:40.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-nr2t4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 05:34:40.968: INFO: stderr: ""
Jan 16 05:34:40.968: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 16 05:34:40.968: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 16 05:34:40.971: INFO: Found 1 stateful pods, waiting for 3
Jan 16 05:34:50.976: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 05:34:50.976: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 05:34:50.976: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Jan 16 05:35:00.977: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 05:35:00.977: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 05:35:00.977: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan 16 05:35:00.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-nr2t4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 16 05:35:01.284: INFO: stderr: ""
Jan 16 05:35:01.284: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 16 05:35:01.287: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 16 05:35:01.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-nr2t4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 16 05:35:01.525: INFO: stderr: ""
Jan 16 05:35:01.525: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 16 05:35:01.525: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 16 05:35:01.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-nr2t4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 16 05:35:01.789: INFO: stderr: ""
Jan 16 05:35:01.789: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 16 05:35:01.789: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 16 05:35:01.789: INFO: Waiting for statefulset status.replicas updated to 0
Jan 16 05:35:01.793: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jan 16 05:35:11.801: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 16 05:35:11.801: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 16 05:35:11.801: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 16 05:35:11.813: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999975s
Jan 16 05:35:12.818: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995851182s
Jan 16 05:35:13.822: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991267886s
Jan 16 05:35:14.827: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986426631s
Jan 16 05:35:15.832: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981589453s
Jan 16 05:35:16.836: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976716331s
Jan 16 05:35:17.841: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972689859s
Jan 16 05:35:18.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96819317s
Jan 16 05:35:19.851: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963005998s
Jan 16 05:35:20.855: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.909502ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-nr2t4
Jan 16 05:35:21.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-nr2t4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 05:35:22.097: INFO: stderr: ""
Jan 16 05:35:22.097: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 16 05:35:22.097: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 16 05:35:22.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-nr2t4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 05:35:22.275: INFO: stderr: ""
Jan 16 05:35:22.275: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 16 05:35:22.275: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 16 05:35:22.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-nr2t4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 05:35:22.458: INFO: stderr: ""
Jan 16 05:35:22.458: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 16 05:35:22.458: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 16 05:35:22.458: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 16 05:35:42.474: INFO: Deleting all statefulset in ns e2e-tests-statefulset-nr2t4
Jan 16 05:35:42.477: INFO: Scaling statefulset ss to 0
Jan 16 05:35:42.484: INFO: Waiting for statefulset status.replicas updated to 0
Jan 16 05:35:42.486: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:35:42.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-nr2t4" for this suite.
Jan 16 05:35:48.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:35:48.589: INFO: namespace: e2e-tests-statefulset-nr2t4, resource: bindings, ignored listing per whitelist
Jan 16 05:35:48.607: INFO: namespace e2e-tests-statefulset-nr2t4 deletion completed in 6.100558293s

• [SLOW TEST:98.341 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:35:48.607: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5lfxr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 05:35:48.821: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9453f253-1950-11e9-af83-025056002014" in namespace "e2e-tests-projected-5lfxr" to be "success or failure"
Jan 16 05:35:48.835: INFO: Pod "downwardapi-volume-9453f253-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 14.215266ms
Jan 16 05:35:50.839: INFO: Pod "downwardapi-volume-9453f253-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017583849s
Jan 16 05:35:52.842: INFO: Pod "downwardapi-volume-9453f253-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0211046s
Jan 16 05:35:54.846: INFO: Pod "downwardapi-volume-9453f253-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024946551s
Jan 16 05:35:56.853: INFO: Pod "downwardapi-volume-9453f253-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.032004192s
Jan 16 05:35:58.857: INFO: Pod "downwardapi-volume-9453f253-1950-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.036503852s
STEP: Saw pod success
Jan 16 05:35:58.858: INFO: Pod "downwardapi-volume-9453f253-1950-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:35:58.861: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-9453f253-1950-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 05:35:58.890: INFO: Waiting for pod downwardapi-volume-9453f253-1950-11e9-af83-025056002014 to disappear
Jan 16 05:35:58.892: INFO: Pod downwardapi-volume-9453f253-1950-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:35:58.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5lfxr" for this suite.
Jan 16 05:36:04.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:36:04.923: INFO: namespace: e2e-tests-projected-5lfxr, resource: bindings, ignored listing per whitelist
Jan 16 05:36:04.991: INFO: namespace e2e-tests-projected-5lfxr deletion completed in 6.095018782s

• [SLOW TEST:16.384 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:36:04.991: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-f74n6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-9e1e640e-1950-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 05:36:05.258: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9e1ef7c3-1950-11e9-af83-025056002014" in namespace "e2e-tests-projected-f74n6" to be "success or failure"
Jan 16 05:36:05.267: INFO: Pod "pod-projected-secrets-9e1ef7c3-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.598202ms
Jan 16 05:36:07.270: INFO: Pod "pod-projected-secrets-9e1ef7c3-1950-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012064258s
STEP: Saw pod success
Jan 16 05:36:07.270: INFO: Pod "pod-projected-secrets-9e1ef7c3-1950-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:36:07.272: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-secrets-9e1ef7c3-1950-11e9-af83-025056002014 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 16 05:36:07.301: INFO: Waiting for pod pod-projected-secrets-9e1ef7c3-1950-11e9-af83-025056002014 to disappear
Jan 16 05:36:07.305: INFO: Pod pod-projected-secrets-9e1ef7c3-1950-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:36:07.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f74n6" for this suite.
Jan 16 05:36:13.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:36:13.402: INFO: namespace: e2e-tests-projected-f74n6, resource: bindings, ignored listing per whitelist
Jan 16 05:36:13.447: INFO: namespace e2e-tests-projected-f74n6 deletion completed in 6.139223037s

• [SLOW TEST:8.456 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:36:13.447: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-m8mck
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a32739c0-1950-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 05:36:13.694: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014" in namespace "e2e-tests-projected-m8mck" to be "success or failure"
Jan 16 05:36:13.719: INFO: Pod "pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 25.231877ms
Jan 16 05:36:15.723: INFO: Pod "pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028948716s
Jan 16 05:36:17.727: INFO: Pod "pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032484758s
Jan 16 05:36:19.730: INFO: Pod "pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03624748s
Jan 16 05:36:21.735: INFO: Pod "pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040652685s
Jan 16 05:36:23.739: INFO: Pod "pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 10.044481656s
Jan 16 05:36:25.743: INFO: Pod "pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.048466085s
STEP: Saw pod success
Jan 16 05:36:25.743: INFO: Pod "pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:36:25.746: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 05:36:25.765: INFO: Waiting for pod pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014 to disappear
Jan 16 05:36:25.768: INFO: Pod pod-projected-configmaps-a327c6b6-1950-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:36:25.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m8mck" for this suite.
Jan 16 05:36:31.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:36:31.840: INFO: namespace: e2e-tests-projected-m8mck, resource: bindings, ignored listing per whitelist
Jan 16 05:36:31.890: INFO: namespace e2e-tests-projected-m8mck deletion completed in 6.117746964s

• [SLOW TEST:18.442 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:36:31.891: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-ws2fw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 16 05:36:46.149: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 16 05:36:46.154: INFO: Pod pod-with-poststart-http-hook still exists
Jan 16 05:36:48.154: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 16 05:36:48.159: INFO: Pod pod-with-poststart-http-hook still exists
Jan 16 05:36:50.154: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 16 05:36:50.159: INFO: Pod pod-with-poststart-http-hook still exists
Jan 16 05:36:52.154: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 16 05:36:52.160: INFO: Pod pod-with-poststart-http-hook still exists
Jan 16 05:36:54.154: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 16 05:36:54.159: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:36:54.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-ws2fw" for this suite.
Jan 16 05:37:16.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:37:16.240: INFO: namespace: e2e-tests-container-lifecycle-hook-ws2fw, resource: bindings, ignored listing per whitelist
Jan 16 05:37:16.260: INFO: namespace e2e-tests-container-lifecycle-hook-ws2fw deletion completed in 22.097374771s

• [SLOW TEST:44.369 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:37:16.261: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qlt7b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 05:37:16.452: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c88fbfee-1950-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-qlt7b" to be "success or failure"
Jan 16 05:37:16.460: INFO: Pod "downwardapi-volume-c88fbfee-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.059368ms
Jan 16 05:37:18.464: INFO: Pod "downwardapi-volume-c88fbfee-1950-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012324824s
STEP: Saw pod success
Jan 16 05:37:18.464: INFO: Pod "downwardapi-volume-c88fbfee-1950-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:37:18.468: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-c88fbfee-1950-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 05:37:18.490: INFO: Waiting for pod downwardapi-volume-c88fbfee-1950-11e9-af83-025056002014 to disappear
Jan 16 05:37:18.496: INFO: Pod downwardapi-volume-c88fbfee-1950-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:37:18.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qlt7b" for this suite.
Jan 16 05:37:24.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:37:24.614: INFO: namespace: e2e-tests-downward-api-qlt7b, resource: bindings, ignored listing per whitelist
Jan 16 05:37:24.620: INFO: namespace e2e-tests-downward-api-qlt7b deletion completed in 6.119651222s

• [SLOW TEST:8.359 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:37:24.623: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-m2p4c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-cd8c4b90-1950-11e9-af83-025056002014
Jan 16 05:37:24.821: INFO: Pod name my-hostname-basic-cd8c4b90-1950-11e9-af83-025056002014: Found 0 pods out of 1
Jan 16 05:37:29.826: INFO: Pod name my-hostname-basic-cd8c4b90-1950-11e9-af83-025056002014: Found 1 pods out of 1
Jan 16 05:37:29.826: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-cd8c4b90-1950-11e9-af83-025056002014" are running
Jan 16 05:37:29.829: INFO: Pod "my-hostname-basic-cd8c4b90-1950-11e9-af83-025056002014-dfwq9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-16 05:37:24 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-16 05:37:29 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-16 05:37:29 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-16 05:37:24 +0000 UTC Reason: Message:}])
Jan 16 05:37:29.829: INFO: Trying to dial the pod
Jan 16 05:37:34.841: INFO: Controller my-hostname-basic-cd8c4b90-1950-11e9-af83-025056002014: Got expected result from replica 1 [my-hostname-basic-cd8c4b90-1950-11e9-af83-025056002014-dfwq9]: "my-hostname-basic-cd8c4b90-1950-11e9-af83-025056002014-dfwq9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:37:34.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-m2p4c" for this suite.
Jan 16 05:37:40.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:37:40.883: INFO: namespace: e2e-tests-replication-controller-m2p4c, resource: bindings, ignored listing per whitelist
Jan 16 05:37:40.937: INFO: namespace e2e-tests-replication-controller-m2p4c deletion completed in 6.093333559s

• [SLOW TEST:16.314 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:37:40.938: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-df6tp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 05:37:41.176: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d74b85fa-1950-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-df6tp" to be "success or failure"
Jan 16 05:37:41.185: INFO: Pod "downwardapi-volume-d74b85fa-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 9.660429ms
Jan 16 05:37:43.189: INFO: Pod "downwardapi-volume-d74b85fa-1950-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013504375s
STEP: Saw pod success
Jan 16 05:37:43.189: INFO: Pod "downwardapi-volume-d74b85fa-1950-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:37:43.192: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-d74b85fa-1950-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 05:37:43.210: INFO: Waiting for pod downwardapi-volume-d74b85fa-1950-11e9-af83-025056002014 to disappear
Jan 16 05:37:43.215: INFO: Pod downwardapi-volume-d74b85fa-1950-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:37:43.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-df6tp" for this suite.
Jan 16 05:37:49.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:37:49.275: INFO: namespace: e2e-tests-downward-api-df6tp, resource: bindings, ignored listing per whitelist
Jan 16 05:37:49.314: INFO: namespace e2e-tests-downward-api-df6tp deletion completed in 6.09463904s

• [SLOW TEST:8.376 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:37:49.315: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2rmkf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 16 05:37:49.502: INFO: Waiting up to 5m0s for pod "downward-api-dc42ff82-1950-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-2rmkf" to be "success or failure"
Jan 16 05:37:49.505: INFO: Pod "downward-api-dc42ff82-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.47616ms
Jan 16 05:37:51.509: INFO: Pod "downward-api-dc42ff82-1950-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006912246s
STEP: Saw pod success
Jan 16 05:37:51.509: INFO: Pod "downward-api-dc42ff82-1950-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:37:51.512: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downward-api-dc42ff82-1950-11e9-af83-025056002014 container dapi-container: <nil>
STEP: delete the pod
Jan 16 05:37:51.537: INFO: Waiting for pod downward-api-dc42ff82-1950-11e9-af83-025056002014 to disappear
Jan 16 05:37:51.556: INFO: Pod downward-api-dc42ff82-1950-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:37:51.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2rmkf" for this suite.
Jan 16 05:37:57.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:37:57.616: INFO: namespace: e2e-tests-downward-api-2rmkf, resource: bindings, ignored listing per whitelist
Jan 16 05:37:57.673: INFO: namespace e2e-tests-downward-api-2rmkf deletion completed in 6.111944312s

• [SLOW TEST:8.359 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:37:57.674: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-jdfpv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan 16 05:37:57.885: INFO: Waiting up to 5m0s for pod "var-expansion-e14221a8-1950-11e9-af83-025056002014" in namespace "e2e-tests-var-expansion-jdfpv" to be "success or failure"
Jan 16 05:37:57.904: INFO: Pod "var-expansion-e14221a8-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 18.768743ms
Jan 16 05:37:59.908: INFO: Pod "var-expansion-e14221a8-1950-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022677075s
Jan 16 05:38:01.913: INFO: Pod "var-expansion-e14221a8-1950-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027514489s
STEP: Saw pod success
Jan 16 05:38:01.913: INFO: Pod "var-expansion-e14221a8-1950-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:38:01.918: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod var-expansion-e14221a8-1950-11e9-af83-025056002014 container dapi-container: <nil>
STEP: delete the pod
Jan 16 05:38:01.946: INFO: Waiting for pod var-expansion-e14221a8-1950-11e9-af83-025056002014 to disappear
Jan 16 05:38:01.949: INFO: Pod var-expansion-e14221a8-1950-11e9-af83-025056002014 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:38:01.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-jdfpv" for this suite.
Jan 16 05:38:07.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:38:08.017: INFO: namespace: e2e-tests-var-expansion-jdfpv, resource: bindings, ignored listing per whitelist
Jan 16 05:38:08.051: INFO: namespace e2e-tests-var-expansion-jdfpv deletion completed in 6.097875251s

• [SLOW TEST:10.378 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:38:08.054: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-w5bd6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-w5bd6
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-w5bd6
STEP: Deleting pre-stop pod
Jan 16 05:38:25.299: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:38:25.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-w5bd6" for this suite.
Jan 16 05:39:03.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:39:03.344: INFO: namespace: e2e-tests-prestop-w5bd6, resource: bindings, ignored listing per whitelist
Jan 16 05:39:03.429: INFO: namespace e2e-tests-prestop-w5bd6 deletion completed in 38.115847334s

• [SLOW TEST:55.376 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:39:03.430: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-sl98w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0116 05:39:34.159457      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 16 05:39:34.159: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:39:34.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-sl98w" for this suite.
Jan 16 05:39:40.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:39:40.205: INFO: namespace: e2e-tests-gc-sl98w, resource: bindings, ignored listing per whitelist
Jan 16 05:39:40.310: INFO: namespace e2e-tests-gc-sl98w deletion completed in 6.147154301s

• [SLOW TEST:36.880 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:39:40.310: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4dkjf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 16 05:39:40.508: INFO: Waiting up to 5m0s for pod "downward-api-1e6ce634-1951-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-4dkjf" to be "success or failure"
Jan 16 05:39:40.535: INFO: Pod "downward-api-1e6ce634-1951-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 26.833298ms
Jan 16 05:39:42.540: INFO: Pod "downward-api-1e6ce634-1951-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031191524s
Jan 16 05:39:44.543: INFO: Pod "downward-api-1e6ce634-1951-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035078174s
STEP: Saw pod success
Jan 16 05:39:44.543: INFO: Pod "downward-api-1e6ce634-1951-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:39:44.546: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downward-api-1e6ce634-1951-11e9-af83-025056002014 container dapi-container: <nil>
STEP: delete the pod
Jan 16 05:39:44.566: INFO: Waiting for pod downward-api-1e6ce634-1951-11e9-af83-025056002014 to disappear
Jan 16 05:39:44.572: INFO: Pod downward-api-1e6ce634-1951-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:39:44.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4dkjf" for this suite.
Jan 16 05:39:50.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:39:50.618: INFO: namespace: e2e-tests-downward-api-4dkjf, resource: bindings, ignored listing per whitelist
Jan 16 05:39:50.671: INFO: namespace e2e-tests-downward-api-4dkjf deletion completed in 6.095731934s

• [SLOW TEST:10.361 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:39:50.671: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-5m7t2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 16 05:39:50.873: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 16 05:39:50.881: INFO: Waiting for terminating namespaces to be deleted...
Jan 16 05:39:50.883: INFO: 
Logging pods the kubelet thinks is on node 1f5a976a-5eac-4984-8510-5241ae82643f before test
Jan 16 05:39:50.894: INFO: fluent-bit-gqggz from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 05:39:50.894: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 16 05:39:50.894: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 05:39:50.894: INFO: wavefront-proxy-9d76d4d76-7wtjn from kube-system started at 2019-01-16 04:46:50 +0000 UTC (4 container statuses recorded)
Jan 16 05:39:50.894: INFO: 	Container heapster ready: true, restart count 0
Jan 16 05:39:50.894: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jan 16 05:39:50.894: INFO: 	Container telegraf ready: true, restart count 0
Jan 16 05:39:50.894: INFO: 	Container wavefront-proxy ready: true, restart count 0
Jan 16 05:39:50.894: INFO: sonobuoy-e2e-job-b9d0f91747af40b1 from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 05:39:50.894: INFO: 	Container e2e ready: true, restart count 0
Jan 16 05:39:50.894: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 16 05:39:50.894: INFO: sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-jgpvg from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 05:39:50.894: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 16 05:39:50.894: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 16 05:39:50.894: INFO: metrics-server-555d98886f-6xwrt from kube-system started at 2019-01-16 04:44:05 +0000 UTC (1 container statuses recorded)
Jan 16 05:39:50.894: INFO: 	Container metrics-server ready: true, restart count 0
Jan 16 05:39:50.894: INFO: kubernetes-dashboard-5f4b59b97f-ghd2b from kube-system started at 2019-01-16 04:44:12 +0000 UTC (1 container statuses recorded)
Jan 16 05:39:50.894: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan 16 05:39:50.894: INFO: cert-generator-v0.11-zbjrk from pks-system started at 2019-01-16 04:44:16 +0000 UTC (1 container statuses recorded)
Jan 16 05:39:50.894: INFO: 	Container cert-generator ready: false, restart count 0
Jan 16 05:39:50.894: INFO: 
Logging pods the kubelet thinks is on node 91937149-2f02-4975-a6bd-87cb9213a67c before test
Jan 16 05:39:50.905: INFO: heapster-85647cf566-jcxn9 from kube-system started at 2019-01-16 04:44:07 +0000 UTC (1 container statuses recorded)
Jan 16 05:39:50.905: INFO: 	Container heapster ready: true, restart count 0
Jan 16 05:39:50.905: INFO: monitoring-influxdb-cdcf4674-h6vzj from kube-system started at 2019-01-16 04:44:10 +0000 UTC (1 container statuses recorded)
Jan 16 05:39:50.906: INFO: 	Container influxdb ready: true, restart count 0
Jan 16 05:39:50.906: INFO: event-controller-6c77ddd949-gr5mj from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 05:39:50.906: INFO: 	Container event-controller ready: true, restart count 1
Jan 16 05:39:50.906: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 05:39:50.906: INFO: fluent-bit-hdwdt from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 05:39:50.906: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 16 05:39:50.907: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 05:39:50.907: INFO: sink-controller-65595c498b-sc2km from pks-system started at 2019-01-16 04:44:17 +0000 UTC (1 container statuses recorded)
Jan 16 05:39:50.907: INFO: 	Container sink-controller ready: true, restart count 0
Jan 16 05:39:50.907: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-16 05:26:47 +0000 UTC (1 container statuses recorded)
Jan 16 05:39:50.907: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 16 05:39:50.907: INFO: sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-5hgsc from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 05:39:50.907: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 16 05:39:50.908: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 16 05:39:50.908: INFO: 
Logging pods the kubelet thinks is on node d02c56a1-5f5a-4edd-b080-4296aa47afb8 before test
Jan 16 05:39:50.914: INFO: kube-dns-7559c96fc4-lvv79 from kube-system started at 2019-01-16 04:43:43 +0000 UTC (3 container statuses recorded)
Jan 16 05:39:50.914: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 16 05:39:50.914: INFO: 	Container kubedns ready: true, restart count 0
Jan 16 05:39:50.914: INFO: 	Container sidecar ready: true, restart count 0
Jan 16 05:39:50.915: INFO: fluent-bit-dztw2 from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 05:39:50.915: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 16 05:39:50.915: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 05:39:50.915: INFO: telemetry-agent-559f9c8855-6fx4v from pks-system started at 2019-01-16 04:49:49 +0000 UTC (1 container statuses recorded)
Jan 16 05:39:50.915: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 16 05:39:50.915: INFO: sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-x5bmd from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 05:39:50.915: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 16 05:39:50.915: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.157a3da2b1c0c5eb], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:39:51.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-5m7t2" for this suite.
Jan 16 05:39:57.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:39:58.006: INFO: namespace: e2e-tests-sched-pred-5m7t2, resource: bindings, ignored listing per whitelist
Jan 16 05:39:58.039: INFO: namespace e2e-tests-sched-pred-5m7t2 deletion completed in 6.101181264s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.368 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:39:58.041: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-brrx7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-brrx7
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 16 05:39:58.237: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 16 05:40:38.430: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.5.5:8080/dial?request=hostName&protocol=http&host=40.0.5.2&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-brrx7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 05:40:38.430: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 05:40:38.542: INFO: Waiting for endpoints: map[]
Jan 16 05:40:38.545: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.5.5:8080/dial?request=hostName&protocol=http&host=40.0.5.3&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-brrx7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 05:40:38.545: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 05:40:38.646: INFO: Waiting for endpoints: map[]
Jan 16 05:40:38.649: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.5.5:8080/dial?request=hostName&protocol=http&host=40.0.5.4&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-brrx7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 05:40:38.650: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 05:40:38.760: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:40:38.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-brrx7" for this suite.
Jan 16 05:41:00.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:41:00.837: INFO: namespace: e2e-tests-pod-network-test-brrx7, resource: bindings, ignored listing per whitelist
Jan 16 05:41:00.922: INFO: namespace e2e-tests-pod-network-test-brrx7 deletion completed in 22.154259074s

• [SLOW TEST:62.882 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:41:00.925: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7bjls
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 16 05:41:05.685: INFO: Successfully updated pod "labelsupdate4e7ba2f4-1951-11e9-af83-025056002014"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:42:10.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7bjls" for this suite.
Jan 16 05:42:32.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:42:32.173: INFO: namespace: e2e-tests-downward-api-7bjls, resource: bindings, ignored listing per whitelist
Jan 16 05:42:32.180: INFO: namespace e2e-tests-downward-api-7bjls deletion completed in 22.103281912s

• [SLOW TEST:91.256 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:42:32.183: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-tgtdq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-84dff652-1951-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 05:42:32.396: INFO: Waiting up to 5m0s for pod "pod-secrets-84e091c4-1951-11e9-af83-025056002014" in namespace "e2e-tests-secrets-tgtdq" to be "success or failure"
Jan 16 05:42:32.400: INFO: Pod "pod-secrets-84e091c4-1951-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.196874ms
Jan 16 05:42:34.404: INFO: Pod "pod-secrets-84e091c4-1951-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008540083s
STEP: Saw pod success
Jan 16 05:42:34.405: INFO: Pod "pod-secrets-84e091c4-1951-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:42:34.408: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-secrets-84e091c4-1951-11e9-af83-025056002014 container secret-env-test: <nil>
STEP: delete the pod
Jan 16 05:42:34.432: INFO: Waiting for pod pod-secrets-84e091c4-1951-11e9-af83-025056002014 to disappear
Jan 16 05:42:34.434: INFO: Pod pod-secrets-84e091c4-1951-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:42:34.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tgtdq" for this suite.
Jan 16 05:42:40.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:42:40.530: INFO: namespace: e2e-tests-secrets-tgtdq, resource: bindings, ignored listing per whitelist
Jan 16 05:42:40.538: INFO: namespace e2e-tests-secrets-tgtdq deletion completed in 6.099786427s

• [SLOW TEST:8.356 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:42:40.538: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4jf4r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-89db2aa1-1951-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 05:42:40.749: INFO: Waiting up to 5m0s for pod "pod-configmaps-89dbbc51-1951-11e9-af83-025056002014" in namespace "e2e-tests-configmap-4jf4r" to be "success or failure"
Jan 16 05:42:40.751: INFO: Pod "pod-configmaps-89dbbc51-1951-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020821ms
Jan 16 05:42:42.755: INFO: Pod "pod-configmaps-89dbbc51-1951-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005997476s
Jan 16 05:42:44.759: INFO: Pod "pod-configmaps-89dbbc51-1951-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009579166s
STEP: Saw pod success
Jan 16 05:42:44.759: INFO: Pod "pod-configmaps-89dbbc51-1951-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:42:44.761: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-configmaps-89dbbc51-1951-11e9-af83-025056002014 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 05:42:44.782: INFO: Waiting for pod pod-configmaps-89dbbc51-1951-11e9-af83-025056002014 to disappear
Jan 16 05:42:44.786: INFO: Pod pod-configmaps-89dbbc51-1951-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:42:44.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4jf4r" for this suite.
Jan 16 05:42:50.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:42:50.864: INFO: namespace: e2e-tests-configmap-4jf4r, resource: bindings, ignored listing per whitelist
Jan 16 05:42:50.904: INFO: namespace e2e-tests-configmap-4jf4r deletion completed in 6.113773052s

• [SLOW TEST:10.365 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:42:50.908: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-w77lg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-w77lg
Jan 16 05:42:59.134: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-w77lg
STEP: checking the pod's current state and verifying that restartCount is present
Jan 16 05:42:59.137: INFO: Initial restart count of pod liveness-http is 0
Jan 16 05:43:17.189: INFO: Restart count of pod e2e-tests-container-probe-w77lg/liveness-http is now 1 (18.052366093s elapsed)
Jan 16 05:43:39.230: INFO: Restart count of pod e2e-tests-container-probe-w77lg/liveness-http is now 2 (40.092964229s elapsed)
Jan 16 05:43:59.271: INFO: Restart count of pod e2e-tests-container-probe-w77lg/liveness-http is now 3 (1m0.134233206s elapsed)
Jan 16 05:44:19.309: INFO: Restart count of pod e2e-tests-container-probe-w77lg/liveness-http is now 4 (1m20.171697442s elapsed)
Jan 16 05:45:19.436: INFO: Restart count of pod e2e-tests-container-probe-w77lg/liveness-http is now 5 (2m20.298896736s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:45:19.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-w77lg" for this suite.
Jan 16 05:45:25.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:45:25.513: INFO: namespace: e2e-tests-container-probe-w77lg, resource: bindings, ignored listing per whitelist
Jan 16 05:45:25.557: INFO: namespace e2e-tests-container-probe-w77lg deletion completed in 6.103604562s

• [SLOW TEST:154.650 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:45:25.559: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-lj7lm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 05:45:25.750: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 16 05:45:25.760: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 16 05:45:30.767: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 16 05:45:30.768: INFO: Creating deployment "test-rolling-update-deployment"
Jan 16 05:45:30.773: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 16 05:45:30.780: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 16 05:45:32.787: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 16 05:45:32.789: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683214330, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683214330, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683214330, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683214330, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 05:45:34.793: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683214330, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683214330, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683214330, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683214330, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 05:45:36.792: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 16 05:45:36.801: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-lj7lm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lj7lm/deployments/test-rolling-update-deployment,UID:ef33897d-1951-11e9-ba24-0050568f491d,ResourceVersion:8174,Generation:1,CreationTimestamp:2019-01-16 05:45:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-16 05:45:30 +0000 UTC 2019-01-16 05:45:30 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-16 05:45:35 +0000 UTC 2019-01-16 05:45:30 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 16 05:45:36.804: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-lj7lm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lj7lm/replicasets/test-rolling-update-deployment-65b7695dcf,UID:ef361b40-1951-11e9-ba24-0050568f491d,ResourceVersion:8165,Generation:1,CreationTimestamp:2019-01-16 05:45:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ef33897d-1951-11e9-ba24-0050568f491d 0xc420e405f7 0xc420e405f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 16 05:45:36.804: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 16 05:45:36.805: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-lj7lm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lj7lm/replicasets/test-rolling-update-controller,UID:ec361dd8-1951-11e9-ba24-0050568f491d,ResourceVersion:8173,Generation:2,CreationTimestamp:2019-01-16 05:45:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ef33897d-1951-11e9-ba24-0050568f491d 0xc420e404d7 0xc420e404d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 16 05:45:36.808: INFO: Pod "test-rolling-update-deployment-65b7695dcf-5dsvz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-5dsvz,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-lj7lm,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lj7lm/pods/test-rolling-update-deployment-65b7695dcf-5dsvz,UID:ef36f573-1951-11e9-ba24-0050568f491d,ResourceVersion:8164,Generation:0,CreationTimestamp:2019-01-16 05:45:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf ef361b40-1951-11e9-ba24-0050568f491d 0xc420e418a7 0xc420e418a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fvqgs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fvqgs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fvqgs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:91937149-2f02-4975-a6bd-87cb9213a67c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420e41a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420e41a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 05:45:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 05:45:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 05:45:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 05:45:30 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:40.0.11.3,StartTime:2019-01-16 05:45:30 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-16 05:45:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://56601edf6d0acd3161c48f804d31f8ad75d37bcda7dc1ca0ea3f7b5a86d7b068}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:45:36.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lj7lm" for this suite.
Jan 16 05:45:42.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:45:42.872: INFO: namespace: e2e-tests-deployment-lj7lm, resource: bindings, ignored listing per whitelist
Jan 16 05:45:42.915: INFO: namespace e2e-tests-deployment-lj7lm deletion completed in 6.104203924s

• [SLOW TEST:17.357 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:45:42.916: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-68chl
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan 16 05:45:43.116: INFO: Waiting up to 5m0s for pod "pod-f68d3417-1951-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-68chl" to be "success or failure"
Jan 16 05:45:43.126: INFO: Pod "pod-f68d3417-1951-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 9.934512ms
Jan 16 05:45:45.130: INFO: Pod "pod-f68d3417-1951-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014124454s
Jan 16 05:45:47.134: INFO: Pod "pod-f68d3417-1951-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018524704s
STEP: Saw pod success
Jan 16 05:45:47.134: INFO: Pod "pod-f68d3417-1951-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:45:47.137: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-f68d3417-1951-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 05:45:47.159: INFO: Waiting for pod pod-f68d3417-1951-11e9-af83-025056002014 to disappear
Jan 16 05:45:47.164: INFO: Pod pod-f68d3417-1951-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:45:47.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-68chl" for this suite.
Jan 16 05:45:53.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:45:53.247: INFO: namespace: e2e-tests-emptydir-68chl, resource: bindings, ignored listing per whitelist
Jan 16 05:45:53.282: INFO: namespace e2e-tests-emptydir-68chl deletion completed in 6.112581989s

• [SLOW TEST:10.367 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:45:53.287: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-bj95f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bj95f
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan 16 05:45:53.510: INFO: Found 0 stateful pods, waiting for 3
Jan 16 05:46:03.514: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 05:46:03.514: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 05:46:03.514: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 16 05:46:03.539: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 16 05:46:13.575: INFO: Updating stateful set ss2
Jan 16 05:46:13.596: INFO: Waiting for Pod e2e-tests-statefulset-bj95f/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan 16 05:46:23.692: INFO: Found 1 stateful pods, waiting for 3
Jan 16 05:46:33.697: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 05:46:33.697: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 05:46:33.697: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 16 05:46:33.720: INFO: Updating stateful set ss2
Jan 16 05:46:33.727: INFO: Waiting for Pod e2e-tests-statefulset-bj95f/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 16 05:46:43.753: INFO: Updating stateful set ss2
Jan 16 05:46:43.762: INFO: Waiting for StatefulSet e2e-tests-statefulset-bj95f/ss2 to complete update
Jan 16 05:46:43.762: INFO: Waiting for Pod e2e-tests-statefulset-bj95f/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 16 05:46:53.768: INFO: Waiting for StatefulSet e2e-tests-statefulset-bj95f/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 16 05:47:03.769: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bj95f
Jan 16 05:47:03.773: INFO: Scaling statefulset ss2 to 0
Jan 16 05:47:23.806: INFO: Waiting for statefulset status.replicas updated to 0
Jan 16 05:47:23.810: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:47:23.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bj95f" for this suite.
Jan 16 05:47:29.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:47:29.911: INFO: namespace: e2e-tests-statefulset-bj95f, resource: bindings, ignored listing per whitelist
Jan 16 05:47:29.957: INFO: namespace e2e-tests-statefulset-bj95f deletion completed in 6.121996127s

• [SLOW TEST:96.671 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:47:29.961: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-8n8gg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 16 05:47:34.692: INFO: Successfully updated pod "pod-update-activedeadlineseconds-365d6f2d-1952-11e9-af83-025056002014"
Jan 16 05:47:34.692: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-365d6f2d-1952-11e9-af83-025056002014" in namespace "e2e-tests-pods-8n8gg" to be "terminated due to deadline exceeded"
Jan 16 05:47:34.697: INFO: Pod "pod-update-activedeadlineseconds-365d6f2d-1952-11e9-af83-025056002014": Phase="Running", Reason="", readiness=true. Elapsed: 4.559844ms
Jan 16 05:47:36.700: INFO: Pod "pod-update-activedeadlineseconds-365d6f2d-1952-11e9-af83-025056002014": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.008476163s
Jan 16 05:47:36.700: INFO: Pod "pod-update-activedeadlineseconds-365d6f2d-1952-11e9-af83-025056002014" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:47:36.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8n8gg" for this suite.
Jan 16 05:47:42.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:47:42.782: INFO: namespace: e2e-tests-pods-8n8gg, resource: bindings, ignored listing per whitelist
Jan 16 05:47:42.806: INFO: namespace e2e-tests-pods-8n8gg deletion completed in 6.101898478s

• [SLOW TEST:12.845 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:47:42.807: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-lbmc8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 16 05:47:42.993: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 16 05:47:43.001: INFO: Waiting for terminating namespaces to be deleted...
Jan 16 05:47:43.004: INFO: 
Logging pods the kubelet thinks is on node 1f5a976a-5eac-4984-8510-5241ae82643f before test
Jan 16 05:47:43.013: INFO: kubernetes-dashboard-5f4b59b97f-ghd2b from kube-system started at 2019-01-16 04:44:12 +0000 UTC (1 container statuses recorded)
Jan 16 05:47:43.013: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan 16 05:47:43.014: INFO: wavefront-proxy-9d76d4d76-7wtjn from kube-system started at 2019-01-16 04:46:50 +0000 UTC (4 container statuses recorded)
Jan 16 05:47:43.014: INFO: 	Container heapster ready: true, restart count 0
Jan 16 05:47:43.014: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jan 16 05:47:43.014: INFO: 	Container telegraf ready: true, restart count 0
Jan 16 05:47:43.014: INFO: 	Container wavefront-proxy ready: true, restart count 0
Jan 16 05:47:43.014: INFO: sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-jgpvg from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 05:47:43.014: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 16 05:47:43.014: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 16 05:47:43.014: INFO: metrics-server-555d98886f-6xwrt from kube-system started at 2019-01-16 04:44:05 +0000 UTC (1 container statuses recorded)
Jan 16 05:47:43.014: INFO: 	Container metrics-server ready: true, restart count 0
Jan 16 05:47:43.014: INFO: cert-generator-v0.11-zbjrk from pks-system started at 2019-01-16 04:44:16 +0000 UTC (1 container statuses recorded)
Jan 16 05:47:43.015: INFO: 	Container cert-generator ready: false, restart count 0
Jan 16 05:47:43.015: INFO: fluent-bit-gqggz from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 05:47:43.015: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 16 05:47:43.015: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 05:47:43.015: INFO: sonobuoy-e2e-job-b9d0f91747af40b1 from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 05:47:43.015: INFO: 	Container e2e ready: true, restart count 0
Jan 16 05:47:43.015: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 16 05:47:43.015: INFO: 
Logging pods the kubelet thinks is on node 91937149-2f02-4975-a6bd-87cb9213a67c before test
Jan 16 05:47:43.024: INFO: heapster-85647cf566-jcxn9 from kube-system started at 2019-01-16 04:44:07 +0000 UTC (1 container statuses recorded)
Jan 16 05:47:43.024: INFO: 	Container heapster ready: true, restart count 0
Jan 16 05:47:43.024: INFO: monitoring-influxdb-cdcf4674-h6vzj from kube-system started at 2019-01-16 04:44:10 +0000 UTC (1 container statuses recorded)
Jan 16 05:47:43.024: INFO: 	Container influxdb ready: true, restart count 0
Jan 16 05:47:43.024: INFO: event-controller-6c77ddd949-gr5mj from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 05:47:43.024: INFO: 	Container event-controller ready: true, restart count 1
Jan 16 05:47:43.024: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 05:47:43.024: INFO: fluent-bit-hdwdt from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 05:47:43.024: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 16 05:47:43.024: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 05:47:43.024: INFO: sink-controller-65595c498b-sc2km from pks-system started at 2019-01-16 04:44:17 +0000 UTC (1 container statuses recorded)
Jan 16 05:47:43.024: INFO: 	Container sink-controller ready: true, restart count 0
Jan 16 05:47:43.024: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-16 05:26:47 +0000 UTC (1 container statuses recorded)
Jan 16 05:47:43.024: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 16 05:47:43.024: INFO: sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-5hgsc from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 05:47:43.024: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 16 05:47:43.024: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 16 05:47:43.024: INFO: 
Logging pods the kubelet thinks is on node d02c56a1-5f5a-4edd-b080-4296aa47afb8 before test
Jan 16 05:47:43.038: INFO: sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-x5bmd from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 05:47:43.038: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 16 05:47:43.038: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 16 05:47:43.038: INFO: kube-dns-7559c96fc4-lvv79 from kube-system started at 2019-01-16 04:43:43 +0000 UTC (3 container statuses recorded)
Jan 16 05:47:43.039: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 16 05:47:43.039: INFO: 	Container kubedns ready: true, restart count 0
Jan 16 05:47:43.039: INFO: 	Container sidecar ready: true, restart count 0
Jan 16 05:47:43.039: INFO: fluent-bit-dztw2 from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 05:47:43.039: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 16 05:47:43.039: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 05:47:43.039: INFO: telemetry-agent-559f9c8855-6fx4v from pks-system started at 2019-01-16 04:49:49 +0000 UTC (1 container statuses recorded)
Jan 16 05:47:43.039: INFO: 	Container fluent-bit ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 1f5a976a-5eac-4984-8510-5241ae82643f
STEP: verifying the node has the label node 91937149-2f02-4975-a6bd-87cb9213a67c
STEP: verifying the node has the label node d02c56a1-5f5a-4edd-b080-4296aa47afb8
Jan 16 05:47:43.091: INFO: Pod sonobuoy requesting resource cpu=0m on Node 91937149-2f02-4975-a6bd-87cb9213a67c
Jan 16 05:47:43.092: INFO: Pod sonobuoy-e2e-job-b9d0f91747af40b1 requesting resource cpu=0m on Node 1f5a976a-5eac-4984-8510-5241ae82643f
Jan 16 05:47:43.092: INFO: Pod sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-5hgsc requesting resource cpu=0m on Node 91937149-2f02-4975-a6bd-87cb9213a67c
Jan 16 05:47:43.092: INFO: Pod sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-jgpvg requesting resource cpu=0m on Node 1f5a976a-5eac-4984-8510-5241ae82643f
Jan 16 05:47:43.092: INFO: Pod sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-x5bmd requesting resource cpu=0m on Node d02c56a1-5f5a-4edd-b080-4296aa47afb8
Jan 16 05:47:43.092: INFO: Pod heapster-85647cf566-jcxn9 requesting resource cpu=0m on Node 91937149-2f02-4975-a6bd-87cb9213a67c
Jan 16 05:47:43.092: INFO: Pod kube-dns-7559c96fc4-lvv79 requesting resource cpu=260m on Node d02c56a1-5f5a-4edd-b080-4296aa47afb8
Jan 16 05:47:43.092: INFO: Pod kubernetes-dashboard-5f4b59b97f-ghd2b requesting resource cpu=50m on Node 1f5a976a-5eac-4984-8510-5241ae82643f
Jan 16 05:47:43.093: INFO: Pod metrics-server-555d98886f-6xwrt requesting resource cpu=0m on Node 1f5a976a-5eac-4984-8510-5241ae82643f
Jan 16 05:47:43.093: INFO: Pod monitoring-influxdb-cdcf4674-h6vzj requesting resource cpu=0m on Node 91937149-2f02-4975-a6bd-87cb9213a67c
Jan 16 05:47:43.093: INFO: Pod wavefront-proxy-9d76d4d76-7wtjn requesting resource cpu=0m on Node 1f5a976a-5eac-4984-8510-5241ae82643f
Jan 16 05:47:43.093: INFO: Pod event-controller-6c77ddd949-gr5mj requesting resource cpu=0m on Node 91937149-2f02-4975-a6bd-87cb9213a67c
Jan 16 05:47:43.093: INFO: Pod fluent-bit-dztw2 requesting resource cpu=0m on Node d02c56a1-5f5a-4edd-b080-4296aa47afb8
Jan 16 05:47:43.093: INFO: Pod fluent-bit-gqggz requesting resource cpu=0m on Node 1f5a976a-5eac-4984-8510-5241ae82643f
Jan 16 05:47:43.093: INFO: Pod fluent-bit-hdwdt requesting resource cpu=0m on Node 91937149-2f02-4975-a6bd-87cb9213a67c
Jan 16 05:47:43.093: INFO: Pod sink-controller-65595c498b-sc2km requesting resource cpu=0m on Node 91937149-2f02-4975-a6bd-87cb9213a67c
Jan 16 05:47:43.093: INFO: Pod telemetry-agent-559f9c8855-6fx4v requesting resource cpu=0m on Node d02c56a1-5f5a-4edd-b080-4296aa47afb8
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e12c86c-1952-11e9-af83-025056002014.157a3e10a18bdbe1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-lbmc8/filler-pod-3e12c86c-1952-11e9-af83-025056002014 to 1f5a976a-5eac-4984-8510-5241ae82643f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e12c86c-1952-11e9-af83-025056002014.157a3e1120804853], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e12c86c-1952-11e9-af83-025056002014.157a3e11291af5f6], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e12c86c-1952-11e9-af83-025056002014.157a3e113341981c], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e13dc01-1952-11e9-af83-025056002014.157a3e10a2d19b30], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-lbmc8/filler-pod-3e13dc01-1952-11e9-af83-025056002014 to 91937149-2f02-4975-a6bd-87cb9213a67c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e13dc01-1952-11e9-af83-025056002014.157a3e112c6ffbd8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e13dc01-1952-11e9-af83-025056002014.157a3e113125bd76], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e13dc01-1952-11e9-af83-025056002014.157a3e113c7a3abc], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e15fef6-1952-11e9-af83-025056002014.157a3e10a4a4663e], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-lbmc8/filler-pod-3e15fef6-1952-11e9-af83-025056002014 to d02c56a1-5f5a-4edd-b080-4296aa47afb8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e15fef6-1952-11e9-af83-025056002014.157a3e112154f34b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e15fef6-1952-11e9-af83-025056002014.157a3e1128e78725], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3e15fef6-1952-11e9-af83-025056002014.157a3e11360ef110], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.157a3e119436682f], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 1f5a976a-5eac-4984-8510-5241ae82643f
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 91937149-2f02-4975-a6bd-87cb9213a67c
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node d02c56a1-5f5a-4edd-b080-4296aa47afb8
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:47:48.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-lbmc8" for this suite.
Jan 16 05:47:54.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:47:54.321: INFO: namespace: e2e-tests-sched-pred-lbmc8, resource: bindings, ignored listing per whitelist
Jan 16 05:47:54.345: INFO: namespace e2e-tests-sched-pred-lbmc8 deletion completed in 6.103000638s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.538 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:47:54.345: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8scls
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-44e79d97-1952-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 05:47:54.577: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-44e8d415-1952-11e9-af83-025056002014" in namespace "e2e-tests-projected-8scls" to be "success or failure"
Jan 16 05:47:54.585: INFO: Pod "pod-projected-secrets-44e8d415-1952-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 7.726993ms
Jan 16 05:47:56.589: INFO: Pod "pod-projected-secrets-44e8d415-1952-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011727003s
Jan 16 05:47:58.593: INFO: Pod "pod-projected-secrets-44e8d415-1952-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015506731s
STEP: Saw pod success
Jan 16 05:47:58.593: INFO: Pod "pod-projected-secrets-44e8d415-1952-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:47:58.596: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-secrets-44e8d415-1952-11e9-af83-025056002014 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 16 05:47:58.617: INFO: Waiting for pod pod-projected-secrets-44e8d415-1952-11e9-af83-025056002014 to disappear
Jan 16 05:47:58.621: INFO: Pod pod-projected-secrets-44e8d415-1952-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:47:58.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8scls" for this suite.
Jan 16 05:48:04.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:48:04.670: INFO: namespace: e2e-tests-projected-8scls, resource: bindings, ignored listing per whitelist
Jan 16 05:48:04.890: INFO: namespace e2e-tests-projected-8scls deletion completed in 6.266488099s

• [SLOW TEST:10.545 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:48:04.892: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5s2k7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-4b44ea4b-1952-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 05:48:05.249: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4b458cee-1952-11e9-af83-025056002014" in namespace "e2e-tests-projected-5s2k7" to be "success or failure"
Jan 16 05:48:05.255: INFO: Pod "pod-projected-configmaps-4b458cee-1952-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.396134ms
Jan 16 05:48:07.259: INFO: Pod "pod-projected-configmaps-4b458cee-1952-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010034813s
Jan 16 05:48:09.262: INFO: Pod "pod-projected-configmaps-4b458cee-1952-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013485968s
STEP: Saw pod success
Jan 16 05:48:09.263: INFO: Pod "pod-projected-configmaps-4b458cee-1952-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:48:09.265: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-configmaps-4b458cee-1952-11e9-af83-025056002014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 05:48:09.289: INFO: Waiting for pod pod-projected-configmaps-4b458cee-1952-11e9-af83-025056002014 to disappear
Jan 16 05:48:09.292: INFO: Pod pod-projected-configmaps-4b458cee-1952-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:48:09.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5s2k7" for this suite.
Jan 16 05:48:15.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:48:15.351: INFO: namespace: e2e-tests-projected-5s2k7, resource: bindings, ignored listing per whitelist
Jan 16 05:48:15.435: INFO: namespace e2e-tests-projected-5s2k7 deletion completed in 6.137449251s

• [SLOW TEST:10.544 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:48:15.440: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4fhzf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 16 05:48:15.668: INFO: Waiting up to 5m0s for pod "downward-api-517ba055-1952-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-4fhzf" to be "success or failure"
Jan 16 05:48:15.682: INFO: Pod "downward-api-517ba055-1952-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 13.630826ms
Jan 16 05:48:17.686: INFO: Pod "downward-api-517ba055-1952-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017541115s
Jan 16 05:48:19.690: INFO: Pod "downward-api-517ba055-1952-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021429112s
STEP: Saw pod success
Jan 16 05:48:19.690: INFO: Pod "downward-api-517ba055-1952-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:48:19.692: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downward-api-517ba055-1952-11e9-af83-025056002014 container dapi-container: <nil>
STEP: delete the pod
Jan 16 05:48:19.710: INFO: Waiting for pod downward-api-517ba055-1952-11e9-af83-025056002014 to disappear
Jan 16 05:48:19.713: INFO: Pod downward-api-517ba055-1952-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:48:19.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4fhzf" for this suite.
Jan 16 05:48:25.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:48:25.776: INFO: namespace: e2e-tests-downward-api-4fhzf, resource: bindings, ignored listing per whitelist
Jan 16 05:48:25.826: INFO: namespace e2e-tests-downward-api-4fhzf deletion completed in 6.106931851s

• [SLOW TEST:10.387 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:48:25.832: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-rzfxj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 16 05:48:26.032: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:48:30.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rzfxj" for this suite.
Jan 16 05:48:36.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:48:36.067: INFO: namespace: e2e-tests-init-container-rzfxj, resource: bindings, ignored listing per whitelist
Jan 16 05:48:36.121: INFO: namespace e2e-tests-init-container-rzfxj deletion completed in 6.105334773s

• [SLOW TEST:10.290 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:48:36.134: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-mdhz7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-w922
STEP: Creating a pod to test atomic-volume-subpath
Jan 16 05:48:36.349: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-w922" in namespace "e2e-tests-subpath-mdhz7" to be "success or failure"
Jan 16 05:48:36.358: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Pending", Reason="", readiness=false. Elapsed: 8.936169ms
Jan 16 05:48:38.362: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012842823s
Jan 16 05:48:40.366: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017347794s
Jan 16 05:48:42.370: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020914843s
Jan 16 05:48:44.374: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024982041s
Jan 16 05:48:46.377: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Pending", Reason="", readiness=false. Elapsed: 10.028011301s
Jan 16 05:48:48.383: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Running", Reason="", readiness=false. Elapsed: 12.034263931s
Jan 16 05:48:50.388: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Running", Reason="", readiness=false. Elapsed: 14.038690121s
Jan 16 05:48:52.392: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Running", Reason="", readiness=false. Elapsed: 16.042858824s
Jan 16 05:48:54.396: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Running", Reason="", readiness=false. Elapsed: 18.04656247s
Jan 16 05:48:56.400: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Running", Reason="", readiness=false. Elapsed: 20.050508027s
Jan 16 05:48:58.403: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Running", Reason="", readiness=false. Elapsed: 22.054095788s
Jan 16 05:49:00.407: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Running", Reason="", readiness=false. Elapsed: 24.058337263s
Jan 16 05:49:02.411: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Running", Reason="", readiness=false. Elapsed: 26.062322122s
Jan 16 05:49:04.415: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Running", Reason="", readiness=false. Elapsed: 28.066429054s
Jan 16 05:49:06.419: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Running", Reason="", readiness=false. Elapsed: 30.069712216s
Jan 16 05:49:08.422: INFO: Pod "pod-subpath-test-configmap-w922": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.073165079s
STEP: Saw pod success
Jan 16 05:49:08.422: INFO: Pod "pod-subpath-test-configmap-w922" satisfied condition "success or failure"
Jan 16 05:49:08.426: INFO: Trying to get logs from node 1f5a976a-5eac-4984-8510-5241ae82643f pod pod-subpath-test-configmap-w922 container test-container-subpath-configmap-w922: <nil>
STEP: delete the pod
Jan 16 05:49:08.449: INFO: Waiting for pod pod-subpath-test-configmap-w922 to disappear
Jan 16 05:49:08.453: INFO: Pod pod-subpath-test-configmap-w922 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-w922
Jan 16 05:49:08.453: INFO: Deleting pod "pod-subpath-test-configmap-w922" in namespace "e2e-tests-subpath-mdhz7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:49:08.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-mdhz7" for this suite.
Jan 16 05:49:14.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:49:14.555: INFO: namespace: e2e-tests-subpath-mdhz7, resource: bindings, ignored listing per whitelist
Jan 16 05:49:14.560: INFO: namespace e2e-tests-subpath-mdhz7 deletion completed in 6.101780395s

• [SLOW TEST:38.426 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:49:14.562: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-m7p5f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-74b583c2-1952-11e9-af83-025056002014
STEP: Creating secret with name secret-projected-all-test-volume-74b583b3-1952-11e9-af83-025056002014
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan 16 05:49:14.773: INFO: Waiting up to 5m0s for pod "projected-volume-74b5838a-1952-11e9-af83-025056002014" in namespace "e2e-tests-projected-m7p5f" to be "success or failure"
Jan 16 05:49:14.778: INFO: Pod "projected-volume-74b5838a-1952-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 5.009986ms
Jan 16 05:49:16.782: INFO: Pod "projected-volume-74b5838a-1952-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008626778s
STEP: Saw pod success
Jan 16 05:49:16.782: INFO: Pod "projected-volume-74b5838a-1952-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:49:16.784: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod projected-volume-74b5838a-1952-11e9-af83-025056002014 container projected-all-volume-test: <nil>
STEP: delete the pod
Jan 16 05:49:16.804: INFO: Waiting for pod projected-volume-74b5838a-1952-11e9-af83-025056002014 to disappear
Jan 16 05:49:16.810: INFO: Pod projected-volume-74b5838a-1952-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:49:16.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m7p5f" for this suite.
Jan 16 05:49:22.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:49:22.904: INFO: namespace: e2e-tests-projected-m7p5f, resource: bindings, ignored listing per whitelist
Jan 16 05:49:22.910: INFO: namespace e2e-tests-projected-m7p5f deletion completed in 6.096568594s

• [SLOW TEST:8.348 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:49:22.914: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bjwdf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 05:49:23.149: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79b4c811-1952-11e9-af83-025056002014" in namespace "e2e-tests-projected-bjwdf" to be "success or failure"
Jan 16 05:49:23.160: INFO: Pod "downwardapi-volume-79b4c811-1952-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 11.411276ms
Jan 16 05:49:25.165: INFO: Pod "downwardapi-volume-79b4c811-1952-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015637943s
Jan 16 05:49:27.169: INFO: Pod "downwardapi-volume-79b4c811-1952-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020011462s
STEP: Saw pod success
Jan 16 05:49:27.169: INFO: Pod "downwardapi-volume-79b4c811-1952-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:49:27.172: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-79b4c811-1952-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 05:49:27.195: INFO: Waiting for pod downwardapi-volume-79b4c811-1952-11e9-af83-025056002014 to disappear
Jan 16 05:49:27.198: INFO: Pod downwardapi-volume-79b4c811-1952-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:49:27.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bjwdf" for this suite.
Jan 16 05:49:33.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:49:33.263: INFO: namespace: e2e-tests-projected-bjwdf, resource: bindings, ignored listing per whitelist
Jan 16 05:49:33.313: INFO: namespace e2e-tests-projected-bjwdf deletion completed in 6.110311682s

• [SLOW TEST:10.400 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:49:33.314: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-msgs4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7fe5c302-1952-11e9-af83-025056002014
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-7fe5c302-1952-11e9-af83-025056002014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:50:53.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-msgs4" for this suite.
Jan 16 05:51:15.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:51:16.061: INFO: namespace: e2e-tests-projected-msgs4, resource: bindings, ignored listing per whitelist
Jan 16 05:51:16.077: INFO: namespace e2e-tests-projected-msgs4 deletion completed in 22.1079864s

• [SLOW TEST:102.763 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:51:16.078: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mskxm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 05:51:16.316: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd23033d-1952-11e9-af83-025056002014" in namespace "e2e-tests-projected-mskxm" to be "success or failure"
Jan 16 05:51:16.338: INFO: Pod "downwardapi-volume-bd23033d-1952-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 21.779821ms
Jan 16 05:51:18.342: INFO: Pod "downwardapi-volume-bd23033d-1952-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025781132s
Jan 16 05:51:20.346: INFO: Pod "downwardapi-volume-bd23033d-1952-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029945017s
STEP: Saw pod success
Jan 16 05:51:20.346: INFO: Pod "downwardapi-volume-bd23033d-1952-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:51:20.350: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-bd23033d-1952-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 05:51:20.376: INFO: Waiting for pod downwardapi-volume-bd23033d-1952-11e9-af83-025056002014 to disappear
Jan 16 05:51:20.380: INFO: Pod downwardapi-volume-bd23033d-1952-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:51:20.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mskxm" for this suite.
Jan 16 05:51:26.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:51:26.449: INFO: namespace: e2e-tests-projected-mskxm, resource: bindings, ignored listing per whitelist
Jan 16 05:51:26.481: INFO: namespace e2e-tests-projected-mskxm deletion completed in 6.097619038s

• [SLOW TEST:10.403 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:51:26.482: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5vfzm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 16 05:51:26.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5vfzm'
Jan 16 05:51:27.608: INFO: stderr: ""
Jan 16 05:51:27.609: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Jan 16 05:51:27.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-5vfzm'
Jan 16 05:51:32.182: INFO: stderr: ""
Jan 16 05:51:32.182: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:51:32.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5vfzm" for this suite.
Jan 16 05:51:38.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:51:38.228: INFO: namespace: e2e-tests-kubectl-5vfzm, resource: bindings, ignored listing per whitelist
Jan 16 05:51:38.288: INFO: namespace e2e-tests-kubectl-5vfzm deletion completed in 6.098557403s

• [SLOW TEST:11.806 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:51:38.289: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fxswp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-ca60706d-1952-11e9-af83-025056002014
STEP: Creating configMap with name cm-test-opt-upd-ca6070a3-1952-11e9-af83-025056002014
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ca60706d-1952-11e9-af83-025056002014
STEP: Updating configmap cm-test-opt-upd-ca6070a3-1952-11e9-af83-025056002014
STEP: Creating configMap with name cm-test-opt-create-ca6070b5-1952-11e9-af83-025056002014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:53:09.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fxswp" for this suite.
Jan 16 05:53:29.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:53:29.084: INFO: namespace: e2e-tests-projected-fxswp, resource: bindings, ignored listing per whitelist
Jan 16 05:53:29.138: INFO: namespace e2e-tests-projected-fxswp deletion completed in 20.089792318s

• [SLOW TEST:110.849 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:53:29.139: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-fr7nw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-0c728797-1953-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 05:53:29.345: INFO: Waiting up to 5m0s for pod "pod-configmaps-0c732e09-1953-11e9-af83-025056002014" in namespace "e2e-tests-configmap-fr7nw" to be "success or failure"
Jan 16 05:53:29.367: INFO: Pod "pod-configmaps-0c732e09-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 21.782238ms
Jan 16 05:53:31.370: INFO: Pod "pod-configmaps-0c732e09-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025114577s
Jan 16 05:53:33.374: INFO: Pod "pod-configmaps-0c732e09-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02879321s
Jan 16 05:53:35.379: INFO: Pod "pod-configmaps-0c732e09-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03389507s
Jan 16 05:53:37.383: INFO: Pod "pod-configmaps-0c732e09-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.037712316s
Jan 16 05:53:39.386: INFO: Pod "pod-configmaps-0c732e09-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.040915383s
STEP: Saw pod success
Jan 16 05:53:39.386: INFO: Pod "pod-configmaps-0c732e09-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:53:39.388: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-configmaps-0c732e09-1953-11e9-af83-025056002014 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 05:53:39.408: INFO: Waiting for pod pod-configmaps-0c732e09-1953-11e9-af83-025056002014 to disappear
Jan 16 05:53:39.411: INFO: Pod pod-configmaps-0c732e09-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:53:39.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fr7nw" for this suite.
Jan 16 05:53:45.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:53:45.488: INFO: namespace: e2e-tests-configmap-fr7nw, resource: bindings, ignored listing per whitelist
Jan 16 05:53:45.505: INFO: namespace e2e-tests-configmap-fr7nw deletion completed in 6.090725448s

• [SLOW TEST:16.367 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:53:45.510: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-gbk4q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 16 05:53:45.735: INFO: Number of nodes with available pods: 0
Jan 16 05:53:45.735: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:46.746: INFO: Number of nodes with available pods: 0
Jan 16 05:53:46.746: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:47.744: INFO: Number of nodes with available pods: 0
Jan 16 05:53:47.744: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:48.742: INFO: Number of nodes with available pods: 1
Jan 16 05:53:48.742: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:49.742: INFO: Number of nodes with available pods: 1
Jan 16 05:53:49.742: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:50.743: INFO: Number of nodes with available pods: 1
Jan 16 05:53:50.743: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:51.743: INFO: Number of nodes with available pods: 1
Jan 16 05:53:51.743: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:52.744: INFO: Number of nodes with available pods: 1
Jan 16 05:53:52.744: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:53.743: INFO: Number of nodes with available pods: 1
Jan 16 05:53:53.743: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:54.744: INFO: Number of nodes with available pods: 1
Jan 16 05:53:54.744: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:55.754: INFO: Number of nodes with available pods: 3
Jan 16 05:53:55.754: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan 16 05:53:55.784: INFO: Number of nodes with available pods: 2
Jan 16 05:53:55.784: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:56.792: INFO: Number of nodes with available pods: 2
Jan 16 05:53:56.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:57.792: INFO: Number of nodes with available pods: 2
Jan 16 05:53:57.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:58.793: INFO: Number of nodes with available pods: 2
Jan 16 05:53:58.793: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:53:59.791: INFO: Number of nodes with available pods: 2
Jan 16 05:53:59.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:00.791: INFO: Number of nodes with available pods: 2
Jan 16 05:54:00.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:01.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:01.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:02.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:02.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:03.793: INFO: Number of nodes with available pods: 2
Jan 16 05:54:03.793: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:04.793: INFO: Number of nodes with available pods: 2
Jan 16 05:54:04.793: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:05.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:05.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:06.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:06.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:07.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:07.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:08.793: INFO: Number of nodes with available pods: 2
Jan 16 05:54:08.793: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:09.794: INFO: Number of nodes with available pods: 2
Jan 16 05:54:09.794: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:10.791: INFO: Number of nodes with available pods: 2
Jan 16 05:54:10.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:11.791: INFO: Number of nodes with available pods: 2
Jan 16 05:54:11.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:12.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:12.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:13.791: INFO: Number of nodes with available pods: 2
Jan 16 05:54:13.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:14.791: INFO: Number of nodes with available pods: 2
Jan 16 05:54:14.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:15.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:15.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:16.803: INFO: Number of nodes with available pods: 2
Jan 16 05:54:16.804: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:17.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:17.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:18.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:18.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:19.791: INFO: Number of nodes with available pods: 2
Jan 16 05:54:19.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:20.791: INFO: Number of nodes with available pods: 2
Jan 16 05:54:20.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:21.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:21.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:22.791: INFO: Number of nodes with available pods: 2
Jan 16 05:54:22.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:23.790: INFO: Number of nodes with available pods: 2
Jan 16 05:54:23.790: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:24.791: INFO: Number of nodes with available pods: 2
Jan 16 05:54:24.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:25.791: INFO: Number of nodes with available pods: 2
Jan 16 05:54:25.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:26.793: INFO: Number of nodes with available pods: 2
Jan 16 05:54:26.793: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:27.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:27.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:28.798: INFO: Number of nodes with available pods: 2
Jan 16 05:54:28.798: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:29.792: INFO: Number of nodes with available pods: 2
Jan 16 05:54:29.792: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:30.793: INFO: Number of nodes with available pods: 2
Jan 16 05:54:30.793: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:31.791: INFO: Number of nodes with available pods: 2
Jan 16 05:54:31.791: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 05:54:32.792: INFO: Number of nodes with available pods: 3
Jan 16 05:54:32.792: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-gbk4q, will wait for the garbage collector to delete the pods
Jan 16 05:54:32.853: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.939318ms
Jan 16 05:54:32.954: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.311874ms
Jan 16 05:55:17.458: INFO: Number of nodes with available pods: 0
Jan 16 05:55:17.458: INFO: Number of running nodes: 0, number of available pods: 0
Jan 16 05:55:17.463: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gbk4q/daemonsets","resourceVersion":"9855"},"items":null}

Jan 16 05:55:17.465: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gbk4q/pods","resourceVersion":"9855"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:55:17.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gbk4q" for this suite.
Jan 16 05:55:23.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:55:23.529: INFO: namespace: e2e-tests-daemonsets-gbk4q, resource: bindings, ignored listing per whitelist
Jan 16 05:55:23.574: INFO: namespace e2e-tests-daemonsets-gbk4q deletion completed in 6.094741074s

• [SLOW TEST:98.065 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:55:23.576: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-8mssb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0116 05:55:24.817093      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 16 05:55:24.817: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:55:24.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8mssb" for this suite.
Jan 16 05:55:30.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:55:30.877: INFO: namespace: e2e-tests-gc-8mssb, resource: bindings, ignored listing per whitelist
Jan 16 05:55:30.931: INFO: namespace e2e-tests-gc-8mssb deletion completed in 6.111678775s

• [SLOW TEST:7.356 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:55:30.932: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-svp25
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5509f648-1953-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 05:55:31.133: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-550a9408-1953-11e9-af83-025056002014" in namespace "e2e-tests-projected-svp25" to be "success or failure"
Jan 16 05:55:31.141: INFO: Pod "pod-projected-configmaps-550a9408-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 7.832291ms
Jan 16 05:55:33.145: INFO: Pod "pod-projected-configmaps-550a9408-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012013955s
Jan 16 05:55:35.148: INFO: Pod "pod-projected-configmaps-550a9408-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014905283s
STEP: Saw pod success
Jan 16 05:55:35.148: INFO: Pod "pod-projected-configmaps-550a9408-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:55:35.150: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-configmaps-550a9408-1953-11e9-af83-025056002014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 05:55:35.170: INFO: Waiting for pod pod-projected-configmaps-550a9408-1953-11e9-af83-025056002014 to disappear
Jan 16 05:55:35.174: INFO: Pod pod-projected-configmaps-550a9408-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:55:35.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-svp25" for this suite.
Jan 16 05:55:41.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:55:41.264: INFO: namespace: e2e-tests-projected-svp25, resource: bindings, ignored listing per whitelist
Jan 16 05:55:41.297: INFO: namespace e2e-tests-projected-svp25 deletion completed in 6.119595891s

• [SLOW TEST:10.365 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:55:41.300: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rg9qh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 05:55:41.499: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b3886dc-1953-11e9-af83-025056002014" in namespace "e2e-tests-projected-rg9qh" to be "success or failure"
Jan 16 05:55:41.502: INFO: Pod "downwardapi-volume-5b3886dc-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 3.256083ms
Jan 16 05:55:43.506: INFO: Pod "downwardapi-volume-5b3886dc-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007586828s
Jan 16 05:55:45.511: INFO: Pod "downwardapi-volume-5b3886dc-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011796594s
STEP: Saw pod success
Jan 16 05:55:45.511: INFO: Pod "downwardapi-volume-5b3886dc-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:55:45.513: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-5b3886dc-1953-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 05:55:45.537: INFO: Waiting for pod downwardapi-volume-5b3886dc-1953-11e9-af83-025056002014 to disappear
Jan 16 05:55:45.540: INFO: Pod downwardapi-volume-5b3886dc-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:55:45.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rg9qh" for this suite.
Jan 16 05:55:51.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:55:51.569: INFO: namespace: e2e-tests-projected-rg9qh, resource: bindings, ignored listing per whitelist
Jan 16 05:55:51.636: INFO: namespace e2e-tests-projected-rg9qh deletion completed in 6.09314182s

• [SLOW TEST:10.336 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:55:51.636: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5bv67
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 16 05:55:56.381: INFO: Successfully updated pod "annotationupdate6161cd49-1953-11e9-af83-025056002014"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:55:58.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5bv67" for this suite.
Jan 16 05:56:20.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:56:20.437: INFO: namespace: e2e-tests-downward-api-5bv67, resource: bindings, ignored listing per whitelist
Jan 16 05:56:20.510: INFO: namespace e2e-tests-downward-api-5bv67 deletion completed in 22.100811802s

• [SLOW TEST:28.874 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:56:20.511: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gsqfh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-729915a8-1953-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 05:56:20.747: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-729a187c-1953-11e9-af83-025056002014" in namespace "e2e-tests-projected-gsqfh" to be "success or failure"
Jan 16 05:56:20.754: INFO: Pod "pod-projected-secrets-729a187c-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.83667ms
Jan 16 05:56:22.758: INFO: Pod "pod-projected-secrets-729a187c-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011034842s
Jan 16 05:56:24.764: INFO: Pod "pod-projected-secrets-729a187c-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016744764s
Jan 16 05:56:26.767: INFO: Pod "pod-projected-secrets-729a187c-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019907988s
STEP: Saw pod success
Jan 16 05:56:26.767: INFO: Pod "pod-projected-secrets-729a187c-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:56:26.770: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-secrets-729a187c-1953-11e9-af83-025056002014 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 16 05:56:26.792: INFO: Waiting for pod pod-projected-secrets-729a187c-1953-11e9-af83-025056002014 to disappear
Jan 16 05:56:26.795: INFO: Pod pod-projected-secrets-729a187c-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:56:26.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gsqfh" for this suite.
Jan 16 05:56:32.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:56:32.857: INFO: namespace: e2e-tests-projected-gsqfh, resource: bindings, ignored listing per whitelist
Jan 16 05:56:32.911: INFO: namespace e2e-tests-projected-gsqfh deletion completed in 6.1105311s

• [SLOW TEST:12.401 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:56:32.919: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2gpbd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 16 05:56:33.125: INFO: Waiting up to 5m0s for pod "pod-79fdeb09-1953-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-2gpbd" to be "success or failure"
Jan 16 05:56:33.135: INFO: Pod "pod-79fdeb09-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 9.103568ms
Jan 16 05:56:35.149: INFO: Pod "pod-79fdeb09-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023220205s
Jan 16 05:56:37.152: INFO: Pod "pod-79fdeb09-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026341677s
STEP: Saw pod success
Jan 16 05:56:37.152: INFO: Pod "pod-79fdeb09-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:56:37.155: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-79fdeb09-1953-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 05:56:37.177: INFO: Waiting for pod pod-79fdeb09-1953-11e9-af83-025056002014 to disappear
Jan 16 05:56:37.183: INFO: Pod pod-79fdeb09-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:56:37.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2gpbd" for this suite.
Jan 16 05:56:43.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:56:43.263: INFO: namespace: e2e-tests-emptydir-2gpbd, resource: bindings, ignored listing per whitelist
Jan 16 05:56:43.312: INFO: namespace e2e-tests-emptydir-2gpbd deletion completed in 6.124935942s

• [SLOW TEST:10.394 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:56:43.317: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2pxjz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 05:56:43.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-802e86cf-1953-11e9-af83-025056002014" in namespace "e2e-tests-projected-2pxjz" to be "success or failure"
Jan 16 05:56:43.514: INFO: Pod "downwardapi-volume-802e86cf-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 5.307494ms
Jan 16 05:56:45.518: INFO: Pod "downwardapi-volume-802e86cf-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009435848s
Jan 16 05:56:47.522: INFO: Pod "downwardapi-volume-802e86cf-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013502683s
STEP: Saw pod success
Jan 16 05:56:47.522: INFO: Pod "downwardapi-volume-802e86cf-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:56:47.524: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-802e86cf-1953-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 05:56:47.551: INFO: Waiting for pod downwardapi-volume-802e86cf-1953-11e9-af83-025056002014 to disappear
Jan 16 05:56:47.556: INFO: Pod downwardapi-volume-802e86cf-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:56:47.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2pxjz" for this suite.
Jan 16 05:56:53.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:56:53.619: INFO: namespace: e2e-tests-projected-2pxjz, resource: bindings, ignored listing per whitelist
Jan 16 05:56:53.680: INFO: namespace e2e-tests-projected-2pxjz deletion completed in 6.120384191s

• [SLOW TEST:10.364 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:56:53.681: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-fzxvz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 05:56:53.938: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"86617b94-1953-11e9-ba24-0050568f491d", Controller:(*bool)(0xc422d2c7c6), BlockOwnerDeletion:(*bool)(0xc422d2c7c7)}}
Jan 16 05:56:53.964: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"865d9cdf-1953-11e9-ba24-0050568f491d", Controller:(*bool)(0xc422b7b38e), BlockOwnerDeletion:(*bool)(0xc422b7b38f)}}
Jan 16 05:56:53.987: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"865e6e58-1953-11e9-ba24-0050568f491d", Controller:(*bool)(0xc422d2c9a6), BlockOwnerDeletion:(*bool)(0xc422d2c9a7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:56:59.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fzxvz" for this suite.
Jan 16 05:57:05.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:57:05.101: INFO: namespace: e2e-tests-gc-fzxvz, resource: bindings, ignored listing per whitelist
Jan 16 05:57:05.181: INFO: namespace e2e-tests-gc-fzxvz deletion completed in 6.144575845s

• [SLOW TEST:11.500 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:57:05.182: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-lklc8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 16 05:57:05.406: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-lklc8,SelfLink:/api/v1/namespaces/e2e-tests-watch-lklc8/configmaps/e2e-watch-test-resource-version,UID:8d387b9d-1953-11e9-ba24-0050568f491d,ResourceVersion:10296,Generation:0,CreationTimestamp:2019-01-16 05:57:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 16 05:57:05.406: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-lklc8,SelfLink:/api/v1/namespaces/e2e-tests-watch-lklc8/configmaps/e2e-watch-test-resource-version,UID:8d387b9d-1953-11e9-ba24-0050568f491d,ResourceVersion:10297,Generation:0,CreationTimestamp:2019-01-16 05:57:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:57:05.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-lklc8" for this suite.
Jan 16 05:57:11.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:57:11.435: INFO: namespace: e2e-tests-watch-lklc8, resource: bindings, ignored listing per whitelist
Jan 16 05:57:11.521: INFO: namespace e2e-tests-watch-lklc8 deletion completed in 6.109472163s

• [SLOW TEST:6.339 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:57:11.521: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-fdjgp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-gdg25
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-htpxh
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:57:18.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-fdjgp" for this suite.
Jan 16 05:57:24.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:57:24.118: INFO: namespace: e2e-tests-namespaces-fdjgp, resource: bindings, ignored listing per whitelist
Jan 16 05:57:24.171: INFO: namespace e2e-tests-namespaces-fdjgp deletion completed in 6.103093049s
STEP: Destroying namespace "e2e-tests-nsdeletetest-gdg25" for this suite.
Jan 16 05:57:24.174: INFO: Namespace e2e-tests-nsdeletetest-gdg25 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-htpxh" for this suite.
Jan 16 05:57:30.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:57:30.223: INFO: namespace: e2e-tests-nsdeletetest-htpxh, resource: bindings, ignored listing per whitelist
Jan 16 05:57:30.302: INFO: namespace e2e-tests-nsdeletetest-htpxh deletion completed in 6.127624763s

• [SLOW TEST:18.781 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:57:30.302: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-665sc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-9c31f961-1953-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 05:57:30.510: INFO: Waiting up to 5m0s for pod "pod-secrets-9c327fb0-1953-11e9-af83-025056002014" in namespace "e2e-tests-secrets-665sc" to be "success or failure"
Jan 16 05:57:30.514: INFO: Pod "pod-secrets-9c327fb0-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.989601ms
Jan 16 05:57:32.518: INFO: Pod "pod-secrets-9c327fb0-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007182759s
Jan 16 05:57:34.522: INFO: Pod "pod-secrets-9c327fb0-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010448372s
STEP: Saw pod success
Jan 16 05:57:34.522: INFO: Pod "pod-secrets-9c327fb0-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:57:34.524: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-secrets-9c327fb0-1953-11e9-af83-025056002014 container secret-volume-test: <nil>
STEP: delete the pod
Jan 16 05:57:34.550: INFO: Waiting for pod pod-secrets-9c327fb0-1953-11e9-af83-025056002014 to disappear
Jan 16 05:57:34.552: INFO: Pod pod-secrets-9c327fb0-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:57:34.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-665sc" for this suite.
Jan 16 05:57:40.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:57:40.651: INFO: namespace: e2e-tests-secrets-665sc, resource: bindings, ignored listing per whitelist
Jan 16 05:57:40.664: INFO: namespace e2e-tests-secrets-665sc deletion completed in 6.108762932s

• [SLOW TEST:10.362 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:57:40.665: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-b5wqd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0116 05:58:20.906101      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 16 05:58:20.906: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:58:20.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-b5wqd" for this suite.
Jan 16 05:58:26.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:58:27.047: INFO: namespace: e2e-tests-gc-b5wqd, resource: bindings, ignored listing per whitelist
Jan 16 05:58:27.072: INFO: namespace e2e-tests-gc-b5wqd deletion completed in 6.162289899s

• [SLOW TEST:46.407 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:58:27.074: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rh8mx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-be07ff8d-1953-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 05:58:27.291: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-be098f49-1953-11e9-af83-025056002014" in namespace "e2e-tests-projected-rh8mx" to be "success or failure"
Jan 16 05:58:27.313: INFO: Pod "pod-projected-secrets-be098f49-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 22.237506ms
Jan 16 05:58:29.316: INFO: Pod "pod-projected-secrets-be098f49-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025880773s
Jan 16 05:58:31.322: INFO: Pod "pod-projected-secrets-be098f49-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031921195s
STEP: Saw pod success
Jan 16 05:58:31.323: INFO: Pod "pod-projected-secrets-be098f49-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:58:31.329: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-secrets-be098f49-1953-11e9-af83-025056002014 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 16 05:58:31.369: INFO: Waiting for pod pod-projected-secrets-be098f49-1953-11e9-af83-025056002014 to disappear
Jan 16 05:58:31.373: INFO: Pod pod-projected-secrets-be098f49-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:58:31.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rh8mx" for this suite.
Jan 16 05:58:37.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:58:37.472: INFO: namespace: e2e-tests-projected-rh8mx, resource: bindings, ignored listing per whitelist
Jan 16 05:58:37.496: INFO: namespace e2e-tests-projected-rh8mx deletion completed in 6.1193299s

• [SLOW TEST:10.423 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:58:37.497: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-pcgg5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 16 05:58:37.708: INFO: Waiting up to 5m0s for pod "pod-c43f966f-1953-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-pcgg5" to be "success or failure"
Jan 16 05:58:37.715: INFO: Pod "pod-c43f966f-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.995938ms
Jan 16 05:58:39.720: INFO: Pod "pod-c43f966f-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01134057s
Jan 16 05:58:41.724: INFO: Pod "pod-c43f966f-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015087401s
STEP: Saw pod success
Jan 16 05:58:41.724: INFO: Pod "pod-c43f966f-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:58:41.726: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-c43f966f-1953-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 05:58:41.745: INFO: Waiting for pod pod-c43f966f-1953-11e9-af83-025056002014 to disappear
Jan 16 05:58:41.755: INFO: Pod pod-c43f966f-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:58:41.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pcgg5" for this suite.
Jan 16 05:58:47.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:58:47.823: INFO: namespace: e2e-tests-emptydir-pcgg5, resource: bindings, ignored listing per whitelist
Jan 16 05:58:47.875: INFO: namespace e2e-tests-emptydir-pcgg5 deletion completed in 6.117118056s

• [SLOW TEST:10.379 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:58:47.878: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7qz8w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ca709355-1953-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 05:58:48.095: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ca712242-1953-11e9-af83-025056002014" in namespace "e2e-tests-projected-7qz8w" to be "success or failure"
Jan 16 05:58:48.109: INFO: Pod "pod-projected-configmaps-ca712242-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 13.970534ms
Jan 16 05:58:50.125: INFO: Pod "pod-projected-configmaps-ca712242-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029564476s
Jan 16 05:58:52.128: INFO: Pod "pod-projected-configmaps-ca712242-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032820147s
STEP: Saw pod success
Jan 16 05:58:52.128: INFO: Pod "pod-projected-configmaps-ca712242-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:58:52.130: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-configmaps-ca712242-1953-11e9-af83-025056002014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 05:58:52.150: INFO: Waiting for pod pod-projected-configmaps-ca712242-1953-11e9-af83-025056002014 to disappear
Jan 16 05:58:52.156: INFO: Pod pod-projected-configmaps-ca712242-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:58:52.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7qz8w" for this suite.
Jan 16 05:58:58.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:58:58.254: INFO: namespace: e2e-tests-projected-7qz8w, resource: bindings, ignored listing per whitelist
Jan 16 05:58:58.266: INFO: namespace e2e-tests-projected-7qz8w deletion completed in 6.105490068s

• [SLOW TEST:10.388 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:58:58.266: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lvswr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 05:58:58.473: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d09df274-1953-11e9-af83-025056002014" in namespace "e2e-tests-projected-lvswr" to be "success or failure"
Jan 16 05:58:58.476: INFO: Pod "downwardapi-volume-d09df274-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 3.210527ms
Jan 16 05:59:00.480: INFO: Pod "downwardapi-volume-d09df274-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006796798s
Jan 16 05:59:02.485: INFO: Pod "downwardapi-volume-d09df274-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011545131s
STEP: Saw pod success
Jan 16 05:59:02.485: INFO: Pod "downwardapi-volume-d09df274-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:59:02.489: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-d09df274-1953-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 05:59:02.532: INFO: Waiting for pod downwardapi-volume-d09df274-1953-11e9-af83-025056002014 to disappear
Jan 16 05:59:02.539: INFO: Pod downwardapi-volume-d09df274-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:59:02.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lvswr" for this suite.
Jan 16 05:59:08.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:59:08.616: INFO: namespace: e2e-tests-projected-lvswr, resource: bindings, ignored listing per whitelist
Jan 16 05:59:08.648: INFO: namespace e2e-tests-projected-lvswr deletion completed in 6.103859098s

• [SLOW TEST:10.382 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:59:08.648: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wd4hn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-d6d09bc7-1953-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 05:59:08.861: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d6d12358-1953-11e9-af83-025056002014" in namespace "e2e-tests-projected-wd4hn" to be "success or failure"
Jan 16 05:59:08.880: INFO: Pod "pod-projected-configmaps-d6d12358-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 18.352427ms
Jan 16 05:59:10.883: INFO: Pod "pod-projected-configmaps-d6d12358-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021627093s
Jan 16 05:59:12.887: INFO: Pod "pod-projected-configmaps-d6d12358-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025261771s
STEP: Saw pod success
Jan 16 05:59:12.887: INFO: Pod "pod-projected-configmaps-d6d12358-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 05:59:12.889: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-configmaps-d6d12358-1953-11e9-af83-025056002014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 05:59:12.908: INFO: Waiting for pod pod-projected-configmaps-d6d12358-1953-11e9-af83-025056002014 to disappear
Jan 16 05:59:12.913: INFO: Pod pod-projected-configmaps-d6d12358-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:59:12.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wd4hn" for this suite.
Jan 16 05:59:18.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:59:18.962: INFO: namespace: e2e-tests-projected-wd4hn, resource: bindings, ignored listing per whitelist
Jan 16 05:59:19.033: INFO: namespace e2e-tests-projected-wd4hn deletion completed in 6.11400133s

• [SLOW TEST:10.385 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:59:19.035: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fhqkm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan 16 05:59:19.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 api-versions'
Jan 16 05:59:19.386: INFO: stderr: ""
Jan 16 05:59:19.386: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps.pivotal.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:59:19.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fhqkm" for this suite.
Jan 16 05:59:25.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:59:25.474: INFO: namespace: e2e-tests-kubectl-fhqkm, resource: bindings, ignored listing per whitelist
Jan 16 05:59:25.492: INFO: namespace e2e-tests-kubectl-fhqkm deletion completed in 6.101873956s

• [SLOW TEST:6.457 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:59:25.504: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-5x4lb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 05:59:25.697: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 16 05:59:30.702: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 16 05:59:30.702: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 16 05:59:30.720: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-5x4lb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5x4lb/deployments/test-cleanup-deployment,UID:e3d7f718-1953-11e9-ba24-0050568f491d,ResourceVersion:10952,Generation:1,CreationTimestamp:2019-01-16 05:59:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan 16 05:59:30.724: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Jan 16 05:59:30.724: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan 16 05:59:30.725: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-5x4lb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5x4lb/replicasets/test-cleanup-controller,UID:e0da2c37-1953-11e9-ba24-0050568f491d,ResourceVersion:10953,Generation:1,CreationTimestamp:2019-01-16 05:59:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment e3d7f718-1953-11e9-ba24-0050568f491d 0xc422e73aa7 0xc422e73aa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 16 05:59:30.738: INFO: Pod "test-cleanup-controller-k67x9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-k67x9,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-5x4lb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5x4lb/pods/test-cleanup-controller-k67x9,UID:e0dbdeae-1953-11e9-ba24-0050568f491d,ResourceVersion:10947,Generation:0,CreationTimestamp:2019-01-16 05:59:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller e0da2c37-1953-11e9-ba24-0050568f491d 0xc422ca60e7 0xc422ca60e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xn89l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xn89l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xn89l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ca6150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ca6170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 05:59:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 05:59:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 05:59:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 05:59:25 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.5.2,StartTime:2019-01-16 05:59:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-16 05:59:28 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://0a58ba9a45310f4760076cf9583fea503cdbb46dd0dfbfc78acd11bc6774b129}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:59:30.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5x4lb" for this suite.
Jan 16 05:59:36.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 05:59:36.878: INFO: namespace: e2e-tests-deployment-5x4lb, resource: bindings, ignored listing per whitelist
Jan 16 05:59:36.878: INFO: namespace e2e-tests-deployment-5x4lb deletion completed in 6.122616088s

• [SLOW TEST:11.385 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 05:59:36.879: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-6frlg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 16 05:59:37.068: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 05:59:42.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6frlg" for this suite.
Jan 16 06:00:04.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:00:04.414: INFO: namespace: e2e-tests-init-container-6frlg, resource: bindings, ignored listing per whitelist
Jan 16 06:00:04.476: INFO: namespace e2e-tests-init-container-6frlg deletion completed in 22.127563763s

• [SLOW TEST:27.598 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:00:04.483: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cnfbd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 06:00:04.722: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f81bea0a-1953-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-cnfbd" to be "success or failure"
Jan 16 06:00:04.732: INFO: Pod "downwardapi-volume-f81bea0a-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 10.577372ms
Jan 16 06:00:06.735: INFO: Pod "downwardapi-volume-f81bea0a-1953-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013441991s
Jan 16 06:00:08.739: INFO: Pod "downwardapi-volume-f81bea0a-1953-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016891467s
STEP: Saw pod success
Jan 16 06:00:08.739: INFO: Pod "downwardapi-volume-f81bea0a-1953-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:00:08.741: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-f81bea0a-1953-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 06:00:08.773: INFO: Waiting for pod downwardapi-volume-f81bea0a-1953-11e9-af83-025056002014 to disappear
Jan 16 06:00:08.776: INFO: Pod downwardapi-volume-f81bea0a-1953-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:00:08.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cnfbd" for this suite.
Jan 16 06:00:14.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:00:14.853: INFO: namespace: e2e-tests-downward-api-cnfbd, resource: bindings, ignored listing per whitelist
Jan 16 06:00:14.909: INFO: namespace e2e-tests-downward-api-cnfbd deletion completed in 6.128606394s

• [SLOW TEST:10.426 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:00:14.911: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-4fsqp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 16 06:00:15.100: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 16 06:00:15.107: INFO: Waiting for terminating namespaces to be deleted...
Jan 16 06:00:15.110: INFO: 
Logging pods the kubelet thinks is on node 1f5a976a-5eac-4984-8510-5241ae82643f before test
Jan 16 06:00:15.119: INFO: sonobuoy-e2e-job-b9d0f91747af40b1 from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 06:00:15.119: INFO: 	Container e2e ready: true, restart count 0
Jan 16 06:00:15.119: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 16 06:00:15.119: INFO: metrics-server-555d98886f-6xwrt from kube-system started at 2019-01-16 04:44:05 +0000 UTC (1 container statuses recorded)
Jan 16 06:00:15.119: INFO: 	Container metrics-server ready: true, restart count 0
Jan 16 06:00:15.119: INFO: cert-generator-v0.11-zbjrk from pks-system started at 2019-01-16 04:44:16 +0000 UTC (1 container statuses recorded)
Jan 16 06:00:15.119: INFO: 	Container cert-generator ready: false, restart count 0
Jan 16 06:00:15.119: INFO: fluent-bit-gqggz from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 06:00:15.119: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 16 06:00:15.119: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 06:00:15.119: INFO: kubernetes-dashboard-5f4b59b97f-ghd2b from kube-system started at 2019-01-16 04:44:12 +0000 UTC (1 container statuses recorded)
Jan 16 06:00:15.119: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan 16 06:00:15.119: INFO: wavefront-proxy-9d76d4d76-7wtjn from kube-system started at 2019-01-16 04:46:50 +0000 UTC (4 container statuses recorded)
Jan 16 06:00:15.119: INFO: 	Container heapster ready: true, restart count 0
Jan 16 06:00:15.119: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jan 16 06:00:15.119: INFO: 	Container telegraf ready: true, restart count 0
Jan 16 06:00:15.119: INFO: 	Container wavefront-proxy ready: true, restart count 0
Jan 16 06:00:15.119: INFO: sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-jgpvg from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 06:00:15.119: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 16 06:00:15.119: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 16 06:00:15.119: INFO: 
Logging pods the kubelet thinks is on node 91937149-2f02-4975-a6bd-87cb9213a67c before test
Jan 16 06:00:15.128: INFO: event-controller-6c77ddd949-gr5mj from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 06:00:15.128: INFO: 	Container event-controller ready: true, restart count 1
Jan 16 06:00:15.128: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 06:00:15.128: INFO: fluent-bit-hdwdt from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 06:00:15.128: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 16 06:00:15.128: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 06:00:15.128: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-16 05:26:47 +0000 UTC (1 container statuses recorded)
Jan 16 06:00:15.128: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 16 06:00:15.128: INFO: sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-5hgsc from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 06:00:15.128: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 16 06:00:15.128: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 16 06:00:15.128: INFO: heapster-85647cf566-jcxn9 from kube-system started at 2019-01-16 04:44:07 +0000 UTC (1 container statuses recorded)
Jan 16 06:00:15.128: INFO: 	Container heapster ready: true, restart count 0
Jan 16 06:00:15.128: INFO: monitoring-influxdb-cdcf4674-h6vzj from kube-system started at 2019-01-16 04:44:10 +0000 UTC (1 container statuses recorded)
Jan 16 06:00:15.128: INFO: 	Container influxdb ready: true, restart count 0
Jan 16 06:00:15.128: INFO: sink-controller-65595c498b-sc2km from pks-system started at 2019-01-16 04:44:17 +0000 UTC (1 container statuses recorded)
Jan 16 06:00:15.128: INFO: 	Container sink-controller ready: true, restart count 0
Jan 16 06:00:15.129: INFO: 
Logging pods the kubelet thinks is on node d02c56a1-5f5a-4edd-b080-4296aa47afb8 before test
Jan 16 06:00:15.143: INFO: kube-dns-7559c96fc4-lvv79 from kube-system started at 2019-01-16 04:43:43 +0000 UTC (3 container statuses recorded)
Jan 16 06:00:15.143: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 16 06:00:15.143: INFO: 	Container kubedns ready: true, restart count 0
Jan 16 06:00:15.143: INFO: 	Container sidecar ready: true, restart count 0
Jan 16 06:00:15.143: INFO: fluent-bit-dztw2 from pks-system started at 2019-01-16 04:44:16 +0000 UTC (2 container statuses recorded)
Jan 16 06:00:15.143: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 16 06:00:15.143: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 16 06:00:15.143: INFO: telemetry-agent-559f9c8855-6fx4v from pks-system started at 2019-01-16 04:49:49 +0000 UTC (1 container statuses recorded)
Jan 16 06:00:15.144: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 16 06:00:15.144: INFO: sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-x5bmd from heptio-sonobuoy started at 2019-01-16 05:27:12 +0000 UTC (2 container statuses recorded)
Jan 16 06:00:15.144: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 16 06:00:15.144: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-01ef7f53-1954-11e9-af83-025056002014 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-01ef7f53-1954-11e9-af83-025056002014 off the node d02c56a1-5f5a-4edd-b080-4296aa47afb8
STEP: verifying the node doesn't have the label kubernetes.io/e2e-01ef7f53-1954-11e9-af83-025056002014
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:00:25.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4fsqp" for this suite.
Jan 16 06:00:33.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:00:33.350: INFO: namespace: e2e-tests-sched-pred-4fsqp, resource: bindings, ignored listing per whitelist
Jan 16 06:00:33.407: INFO: namespace e2e-tests-sched-pred-4fsqp deletion completed in 8.151386268s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:18.497 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:00:33.407: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-8685v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:00:33.618: INFO: (0) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.618463ms)
Jan 16 06:00:33.622: INFO: (1) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.879584ms)
Jan 16 06:00:33.626: INFO: (2) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.581045ms)
Jan 16 06:00:33.630: INFO: (3) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.229556ms)
Jan 16 06:00:33.635: INFO: (4) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.232761ms)
Jan 16 06:00:33.639: INFO: (5) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.710853ms)
Jan 16 06:00:33.642: INFO: (6) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.399906ms)
Jan 16 06:00:33.646: INFO: (7) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.500744ms)
Jan 16 06:00:33.650: INFO: (8) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.111241ms)
Jan 16 06:00:33.656: INFO: (9) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.248352ms)
Jan 16 06:00:33.660: INFO: (10) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.289145ms)
Jan 16 06:00:33.664: INFO: (11) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.830838ms)
Jan 16 06:00:33.668: INFO: (12) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.979803ms)
Jan 16 06:00:33.673: INFO: (13) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.464794ms)
Jan 16 06:00:33.676: INFO: (14) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.398062ms)
Jan 16 06:00:33.680: INFO: (15) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.729826ms)
Jan 16 06:00:33.684: INFO: (16) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.470347ms)
Jan 16 06:00:33.689: INFO: (17) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.9663ms)
Jan 16 06:00:33.699: INFO: (18) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.771349ms)
Jan 16 06:00:33.703: INFO: (19) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.868544ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:00:33.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-8685v" for this suite.
Jan 16 06:00:39.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:00:39.797: INFO: namespace: e2e-tests-proxy-8685v, resource: bindings, ignored listing per whitelist
Jan 16 06:00:39.909: INFO: namespace e2e-tests-proxy-8685v deletion completed in 6.202719697s

• [SLOW TEST:6.502 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:00:39.910: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-p8wqp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-p8wqp
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-p8wqp
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-p8wqp
Jan 16 06:00:40.192: INFO: Found 0 stateful pods, waiting for 1
Jan 16 06:00:50.197: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan 16 06:00:50.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 16 06:00:50.419: INFO: stderr: ""
Jan 16 06:00:50.419: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 16 06:00:50.419: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 16 06:00:50.424: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 16 06:01:00.429: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 16 06:01:00.429: INFO: Waiting for statefulset status.replicas updated to 0
Jan 16 06:01:00.458: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 16 06:01:00.458: INFO: ss-0  d02c56a1-5f5a-4edd-b080-4296aa47afb8  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  }]
Jan 16 06:01:00.458: INFO: ss-1                                        Pending         []
Jan 16 06:01:00.458: INFO: 
Jan 16 06:01:00.458: INFO: StatefulSet ss has not reached scale 3, at 2
Jan 16 06:01:01.468: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.984665849s
Jan 16 06:01:02.473: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.974960853s
Jan 16 06:01:03.483: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.969574219s
Jan 16 06:01:04.488: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.959785909s
Jan 16 06:01:05.493: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.954417213s
Jan 16 06:01:06.498: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.949126536s
Jan 16 06:01:07.502: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.944625393s
Jan 16 06:01:08.507: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.940503862s
Jan 16 06:01:09.511: INFO: Verifying statefulset ss doesn't scale past 3 for another 936.221716ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-p8wqp
Jan 16 06:01:10.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:01:10.698: INFO: stderr: ""
Jan 16 06:01:10.698: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 16 06:01:10.698: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 16 06:01:10.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:01:10.899: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 16 06:01:10.899: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 16 06:01:10.899: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 16 06:01:10.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:01:11.112: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 16 06:01:11.112: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 16 06:01:11.112: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 16 06:01:11.117: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 06:01:11.117: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 06:01:11.117: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan 16 06:01:11.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 16 06:01:11.331: INFO: stderr: ""
Jan 16 06:01:11.331: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 16 06:01:11.331: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 16 06:01:11.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 16 06:01:11.540: INFO: stderr: ""
Jan 16 06:01:11.540: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 16 06:01:11.540: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 16 06:01:11.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 16 06:01:11.726: INFO: stderr: ""
Jan 16 06:01:11.726: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 16 06:01:11.726: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 16 06:01:11.726: INFO: Waiting for statefulset status.replicas updated to 0
Jan 16 06:01:11.729: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jan 16 06:01:21.735: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 16 06:01:21.735: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 16 06:01:21.735: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 16 06:01:21.748: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 16 06:01:21.748: INFO: ss-0  d02c56a1-5f5a-4edd-b080-4296aa47afb8  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  }]
Jan 16 06:01:21.748: INFO: ss-1  91937149-2f02-4975-a6bd-87cb9213a67c  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:00 +0000 UTC  }]
Jan 16 06:01:21.748: INFO: ss-2  1f5a976a-5eac-4984-8510-5241ae82643f  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:00 +0000 UTC  }]
Jan 16 06:01:21.748: INFO: 
Jan 16 06:01:21.748: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 16 06:01:22.752: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 16 06:01:22.752: INFO: ss-0  d02c56a1-5f5a-4edd-b080-4296aa47afb8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  }]
Jan 16 06:01:22.752: INFO: ss-1  91937149-2f02-4975-a6bd-87cb9213a67c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:00 +0000 UTC  }]
Jan 16 06:01:22.752: INFO: ss-2  1f5a976a-5eac-4984-8510-5241ae82643f  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:00 +0000 UTC  }]
Jan 16 06:01:22.752: INFO: 
Jan 16 06:01:22.752: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 16 06:01:23.756: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 16 06:01:23.756: INFO: ss-0  d02c56a1-5f5a-4edd-b080-4296aa47afb8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  }]
Jan 16 06:01:23.756: INFO: 
Jan 16 06:01:23.756: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 16 06:01:24.761: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 16 06:01:24.761: INFO: ss-0  d02c56a1-5f5a-4edd-b080-4296aa47afb8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  }]
Jan 16 06:01:24.761: INFO: 
Jan 16 06:01:24.761: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 16 06:01:25.765: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 16 06:01:25.765: INFO: ss-0  d02c56a1-5f5a-4edd-b080-4296aa47afb8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  }]
Jan 16 06:01:25.765: INFO: 
Jan 16 06:01:25.765: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 16 06:01:26.769: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 16 06:01:26.769: INFO: ss-0  d02c56a1-5f5a-4edd-b080-4296aa47afb8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  }]
Jan 16 06:01:26.770: INFO: 
Jan 16 06:01:26.770: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 16 06:01:27.774: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 16 06:01:27.774: INFO: ss-0  d02c56a1-5f5a-4edd-b080-4296aa47afb8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  }]
Jan 16 06:01:27.774: INFO: 
Jan 16 06:01:27.774: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 16 06:01:28.778: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 16 06:01:28.778: INFO: ss-0  d02c56a1-5f5a-4edd-b080-4296aa47afb8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  }]
Jan 16 06:01:28.779: INFO: 
Jan 16 06:01:28.779: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 16 06:01:29.784: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 16 06:01:29.784: INFO: ss-0  d02c56a1-5f5a-4edd-b080-4296aa47afb8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  }]
Jan 16 06:01:29.784: INFO: 
Jan 16 06:01:29.784: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 16 06:01:30.788: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 16 06:01:30.788: INFO: ss-0  d02c56a1-5f5a-4edd-b080-4296aa47afb8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:01:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:00:40 +0000 UTC  }]
Jan 16 06:01:30.788: INFO: 
Jan 16 06:01:30.789: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-p8wqp
Jan 16 06:01:31.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:01:31.941: INFO: rc: 1
Jan 16 06:01:31.941: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc420f90450 exit status 1 <nil> <nil> true [0xc4216cae38 0xc4216cae80 0xc4216caeb0] [0xc4216cae38 0xc4216cae80 0xc4216caeb0] [0xc4216cae70 0xc4216caea0] [0x8fd520 0x8fd520] 0xc421b968a0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Jan 16 06:01:41.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:01:42.041: INFO: rc: 1
Jan 16 06:01:42.041: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f909f0 exit status 1 <nil> <nil> true [0xc4216caec0 0xc4216caf00 0xc4216caf38] [0xc4216caec0 0xc4216caf00 0xc4216caf38] [0xc4216caef0 0xc4216caf20] [0x8fd520 0x8fd520] 0xc421b969c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:01:52.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:01:52.143: INFO: rc: 1
Jan 16 06:01:52.143: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f90e70 exit status 1 <nil> <nil> true [0xc4216caf48 0xc4216caf88 0xc4216cafc0] [0xc4216caf48 0xc4216caf88 0xc4216cafc0] [0xc4216caf70 0xc4216cafb0] [0x8fd520 0x8fd520] 0xc421b96ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:02:02.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:02:02.249: INFO: rc: 1
Jan 16 06:02:02.249: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4220446f0 exit status 1 <nil> <nil> true [0xc422d4e898 0xc422d4e8b0 0xc422d4e8c8] [0xc422d4e898 0xc422d4e8b0 0xc422d4e8c8] [0xc422d4e8a8 0xc422d4e8c0] [0x8fd520 0x8fd520] 0xc421f9b020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:02:12.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:02:12.339: INFO: rc: 1
Jan 16 06:02:12.339: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420eb45a0 exit status 1 <nil> <nil> true [0xc420de8008 0xc420de8020 0xc420de8038] [0xc420de8008 0xc420de8020 0xc420de8038] [0xc420de8018 0xc420de8030] [0x8fd520 0x8fd520] 0xc422102060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:02:22.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:02:22.433: INFO: rc: 1
Jan 16 06:02:22.433: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420eb4a20 exit status 1 <nil> <nil> true [0xc420de8040 0xc420de8058 0xc420de8070] [0xc420de8040 0xc420de8058 0xc420de8070] [0xc420de8050 0xc420de8068] [0x8fd520 0x8fd520] 0xc422102180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:02:32.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:02:32.530: INFO: rc: 1
Jan 16 06:02:32.531: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420eb5050 exit status 1 <nil> <nil> true [0xc420de8078 0xc420de8090 0xc420de80a8] [0xc420de8078 0xc420de8090 0xc420de80a8] [0xc420de8088 0xc420de80a0] [0x8fd520 0x8fd520] 0xc4221022a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:02:42.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:02:42.652: INFO: rc: 1
Jan 16 06:02:42.652: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420eb5560 exit status 1 <nil> <nil> true [0xc420de80b0 0xc420de80c8 0xc420de80e0] [0xc420de80b0 0xc420de80c8 0xc420de80e0] [0xc420de80c0 0xc420de80d8] [0x8fd520 0x8fd520] 0xc4221023c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:02:52.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:02:52.749: INFO: rc: 1
Jan 16 06:02:52.749: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217ca510 exit status 1 <nil> <nil> true [0xc4206c2498 0xc4206c26c8 0xc4206c2860] [0xc4206c2498 0xc4206c26c8 0xc4206c2860] [0xc4206c2540 0xc4206c2800] [0x8fd520 0x8fd520] 0xc422bc8060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:03:02.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:03:02.844: INFO: rc: 1
Jan 16 06:03:02.845: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420eb5980 exit status 1 <nil> <nil> true [0xc420de80e8 0xc420de8100 0xc420de8118] [0xc420de80e8 0xc420de8100 0xc420de8118] [0xc420de80f8 0xc420de8110] [0x8fd520 0x8fd520] 0xc4221024e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:03:12.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:03:12.945: INFO: rc: 1
Jan 16 06:03:12.945: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217ca8d0 exit status 1 <nil> <nil> true [0xc4206c2878 0xc4206c2900 0xc4206c2b98] [0xc4206c2878 0xc4206c2900 0xc4206c2b98] [0xc4206c28b0 0xc4206c2b40] [0x8fd520 0x8fd520] 0xc422bc8180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:03:22.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:03:23.039: INFO: rc: 1
Jan 16 06:03:23.039: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217cad20 exit status 1 <nil> <nil> true [0xc4206c2bb8 0xc4206c2d70 0xc4206c2e70] [0xc4206c2bb8 0xc4206c2d70 0xc4206c2e70] [0xc4206c2ce0 0xc4206c2df8] [0x8fd520 0x8fd520] 0xc422bc82a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:03:33.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:03:33.132: INFO: rc: 1
Jan 16 06:03:33.133: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217cb200 exit status 1 <nil> <nil> true [0xc4206c2ea8 0xc4206c2fa0 0xc4206c3048] [0xc4206c2ea8 0xc4206c2fa0 0xc4206c3048] [0xc4206c2f48 0xc4206c3040] [0x8fd520 0x8fd520] 0xc422bc83c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:03:43.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:03:43.236: INFO: rc: 1
Jan 16 06:03:43.236: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420eb5e00 exit status 1 <nil> <nil> true [0xc420de8120 0xc420de8138 0xc420de8150] [0xc420de8120 0xc420de8138 0xc420de8150] [0xc420de8130 0xc420de8148] [0x8fd520 0x8fd520] 0xc422102600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:03:53.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:03:53.338: INFO: rc: 1
Jan 16 06:03:53.338: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f7c1b0 exit status 1 <nil> <nil> true [0xc420de8158 0xc420de8170 0xc420de8188] [0xc420de8158 0xc420de8170 0xc420de8188] [0xc420de8168 0xc420de8180] [0x8fd520 0x8fd520] 0xc422102720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:04:03.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:04:03.434: INFO: rc: 1
Jan 16 06:04:03.434: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217cb710 exit status 1 <nil> <nil> true [0xc4206c3098 0xc4206c31c0 0xc4206c3258] [0xc4206c3098 0xc4206c31c0 0xc4206c3258] [0xc4206c3178 0xc4206c3250] [0x8fd520 0x8fd520] 0xc422bc84e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:04:13.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:04:13.531: INFO: rc: 1
Jan 16 06:04:13.531: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420eb45d0 exit status 1 <nil> <nil> true [0xc4206c2508 0xc4206c2780 0xc4206c2878] [0xc4206c2508 0xc4206c2780 0xc4206c2878] [0xc4206c26c8 0xc4206c2860] [0x8fd520 0x8fd520] 0xc422bc8060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:04:23.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:04:23.625: INFO: rc: 1
Jan 16 06:04:23.625: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217ca540 exit status 1 <nil> <nil> true [0xc420de8000 0xc420de8018 0xc420de8030] [0xc420de8000 0xc420de8018 0xc420de8030] [0xc420de8010 0xc420de8028] [0x8fd520 0x8fd520] 0xc422102060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:04:33.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:04:33.715: INFO: rc: 1
Jan 16 06:04:33.715: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217ca930 exit status 1 <nil> <nil> true [0xc420de8038 0xc420de8050 0xc420de8068] [0xc420de8038 0xc420de8050 0xc420de8068] [0xc420de8048 0xc420de8060] [0x8fd520 0x8fd520] 0xc422102180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:04:43.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:04:43.822: INFO: rc: 1
Jan 16 06:04:43.822: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420eb4ab0 exit status 1 <nil> <nil> true [0xc4206c2888 0xc4206c2b30 0xc4206c2bb8] [0xc4206c2888 0xc4206c2b30 0xc4206c2bb8] [0xc4206c2900 0xc4206c2b98] [0x8fd520 0x8fd520] 0xc422bc8180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:04:53.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:04:53.925: INFO: rc: 1
Jan 16 06:04:53.925: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420eb5140 exit status 1 <nil> <nil> true [0xc4206c2c08 0xc4206c2da0 0xc4206c2ea8] [0xc4206c2c08 0xc4206c2da0 0xc4206c2ea8] [0xc4206c2d70 0xc4206c2e70] [0x8fd520 0x8fd520] 0xc422bc82a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:05:03.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:05:04.042: INFO: rc: 1
Jan 16 06:05:04.043: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420eb5680 exit status 1 <nil> <nil> true [0xc4206c2ef8 0xc4206c3018 0xc4206c3098] [0xc4206c2ef8 0xc4206c3018 0xc4206c3098] [0xc4206c2fa0 0xc4206c3048] [0x8fd520 0x8fd520] 0xc422bc83c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:05:14.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:05:14.130: INFO: rc: 1
Jan 16 06:05:14.130: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217cadb0 exit status 1 <nil> <nil> true [0xc420de8070 0xc420de8088 0xc420de80a0] [0xc420de8070 0xc420de8088 0xc420de80a0] [0xc420de8080 0xc420de8098] [0x8fd520 0x8fd520] 0xc4221022a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:05:24.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:05:24.228: INFO: rc: 1
Jan 16 06:05:24.228: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217cb260 exit status 1 <nil> <nil> true [0xc420de80a8 0xc420de80c0 0xc420de80d8] [0xc420de80a8 0xc420de80c0 0xc420de80d8] [0xc420de80b8 0xc420de80d0] [0x8fd520 0x8fd520] 0xc4221023c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:05:34.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:05:34.324: INFO: rc: 1
Jan 16 06:05:34.324: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420eb5b90 exit status 1 <nil> <nil> true [0xc4206c3120 0xc4206c3218 0xc4206c3270] [0xc4206c3120 0xc4206c3218 0xc4206c3270] [0xc4206c31c0 0xc4206c3258] [0x8fd520 0x8fd520] 0xc422bc84e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:05:44.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:05:44.425: INFO: rc: 1
Jan 16 06:05:44.425: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217cb740 exit status 1 <nil> <nil> true [0xc420de80e0 0xc420de80f8 0xc420de8110] [0xc420de80e0 0xc420de80f8 0xc420de8110] [0xc420de80f0 0xc420de8108] [0x8fd520 0x8fd520] 0xc4221024e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:05:54.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:05:54.505: INFO: rc: 1
Jan 16 06:05:54.505: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217cbb60 exit status 1 <nil> <nil> true [0xc420de8118 0xc420de8130 0xc420de8148] [0xc420de8118 0xc420de8130 0xc420de8148] [0xc420de8128 0xc420de8140] [0x8fd520 0x8fd520] 0xc422102600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:06:04.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:06:04.597: INFO: rc: 1
Jan 16 06:06:04.598: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f7c000 exit status 1 <nil> <nil> true [0xc4206c3278 0xc4206c3300 0xc4206c3350] [0xc4206c3278 0xc4206c3300 0xc4206c3350] [0xc4206c3290 0xc4206c3348] [0x8fd520 0x8fd520] 0xc422bc8600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:06:14.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:06:14.713: INFO: rc: 1
Jan 16 06:06:14.713: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421b04030 exit status 1 <nil> <nil> true [0xc420de8158 0xc420de8170 0xc420de8188] [0xc420de8158 0xc420de8170 0xc420de8188] [0xc420de8168 0xc420de8180] [0x8fd520 0x8fd520] 0xc4221026c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:06:24.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:06:24.821: INFO: rc: 1
Jan 16 06:06:24.821: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4217ca4e0 exit status 1 <nil> <nil> true [0xc420de8000 0xc420de8018 0xc420de8030] [0xc420de8000 0xc420de8018 0xc420de8030] [0xc420de8010 0xc420de8028] [0x8fd520 0x8fd520] 0xc422102060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Jan 16 06:06:34.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-p8wqp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 06:06:34.932: INFO: rc: 1
Jan 16 06:06:34.932: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Jan 16 06:06:34.932: INFO: Scaling statefulset ss to 0
Jan 16 06:06:34.941: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 16 06:06:34.943: INFO: Deleting all statefulset in ns e2e-tests-statefulset-p8wqp
Jan 16 06:06:34.946: INFO: Scaling statefulset ss to 0
Jan 16 06:06:34.952: INFO: Waiting for statefulset status.replicas updated to 0
Jan 16 06:06:34.954: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:06:34.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-p8wqp" for this suite.
Jan 16 06:06:40.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:06:41.058: INFO: namespace: e2e-tests-statefulset-p8wqp, resource: bindings, ignored listing per whitelist
Jan 16 06:06:41.109: INFO: namespace e2e-tests-statefulset-p8wqp deletion completed in 6.134200547s

• [SLOW TEST:361.199 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:06:41.111: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-hz24n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:06:41.305: INFO: Creating ReplicaSet my-hostname-basic-e48000ea-1954-11e9-af83-025056002014
Jan 16 06:06:41.321: INFO: Pod name my-hostname-basic-e48000ea-1954-11e9-af83-025056002014: Found 0 pods out of 1
Jan 16 06:06:46.326: INFO: Pod name my-hostname-basic-e48000ea-1954-11e9-af83-025056002014: Found 1 pods out of 1
Jan 16 06:06:46.326: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e48000ea-1954-11e9-af83-025056002014" is running
Jan 16 06:06:46.329: INFO: Pod "my-hostname-basic-e48000ea-1954-11e9-af83-025056002014-8fpms" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-16 06:06:41 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-16 06:06:44 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-16 06:06:44 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-16 06:06:41 +0000 UTC Reason: Message:}])
Jan 16 06:06:46.329: INFO: Trying to dial the pod
Jan 16 06:06:51.350: INFO: Controller my-hostname-basic-e48000ea-1954-11e9-af83-025056002014: Got expected result from replica 1 [my-hostname-basic-e48000ea-1954-11e9-af83-025056002014-8fpms]: "my-hostname-basic-e48000ea-1954-11e9-af83-025056002014-8fpms", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:06:51.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-hz24n" for this suite.
Jan 16 06:06:57.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:06:57.468: INFO: namespace: e2e-tests-replicaset-hz24n, resource: bindings, ignored listing per whitelist
Jan 16 06:06:57.468: INFO: namespace e2e-tests-replicaset-hz24n deletion completed in 6.109071452s

• [SLOW TEST:16.357 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:06:57.471: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7qrcf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 16 06:06:57.674: INFO: Waiting up to 5m0s for pod "pod-ee408d6d-1954-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-7qrcf" to be "success or failure"
Jan 16 06:06:57.683: INFO: Pod "pod-ee408d6d-1954-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 9.600822ms
Jan 16 06:06:59.687: INFO: Pod "pod-ee408d6d-1954-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013066527s
Jan 16 06:07:01.692: INFO: Pod "pod-ee408d6d-1954-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017895502s
Jan 16 06:07:03.696: INFO: Pod "pod-ee408d6d-1954-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022169357s
STEP: Saw pod success
Jan 16 06:07:03.697: INFO: Pod "pod-ee408d6d-1954-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:07:03.699: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-ee408d6d-1954-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:07:03.730: INFO: Waiting for pod pod-ee408d6d-1954-11e9-af83-025056002014 to disappear
Jan 16 06:07:03.732: INFO: Pod pod-ee408d6d-1954-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:07:03.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7qrcf" for this suite.
Jan 16 06:07:09.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:07:09.774: INFO: namespace: e2e-tests-emptydir-7qrcf, resource: bindings, ignored listing per whitelist
Jan 16 06:07:09.845: INFO: namespace e2e-tests-emptydir-7qrcf deletion completed in 6.108550762s

• [SLOW TEST:12.374 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:07:09.845: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-knqr6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 16 06:07:10.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-knqr6'
Jan 16 06:07:10.900: INFO: stderr: ""
Jan 16 06:07:10.900: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan 16 06:07:15.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-knqr6 -o json'
Jan 16 06:07:16.064: INFO: stderr: ""
Jan 16 06:07:16.064: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-01-16T06:07:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-knqr6\",\n        \"resourceVersion\": \"12005\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-knqr6/pods/e2e-test-nginx-pod\",\n        \"uid\": \"f621f84a-1954-11e9-ba24-0050568f491d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-5zjdr\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"d02c56a1-5f5a-4edd-b080-4296aa47afb8\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-5zjdr\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-5zjdr\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-16T06:07:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-16T06:07:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-16T06:07:12Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-16T06:07:10Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://a81cc9d5e4dd439d6f0d65a3bb152b25bd46695ac5d2c35b449f9e8d503c30a9\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-16T06:07:12Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"30.0.3.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"40.0.5.2\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-16T06:07:10Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan 16 06:07:16.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 replace -f - --namespace=e2e-tests-kubectl-knqr6'
Jan 16 06:07:24.392: INFO: stderr: ""
Jan 16 06:07:24.392: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Jan 16 06:07:24.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-knqr6'
Jan 16 06:07:32.187: INFO: stderr: ""
Jan 16 06:07:32.187: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:07:32.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-knqr6" for this suite.
Jan 16 06:07:38.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:07:38.262: INFO: namespace: e2e-tests-kubectl-knqr6, resource: bindings, ignored listing per whitelist
Jan 16 06:07:38.301: INFO: namespace e2e-tests-kubectl-knqr6 deletion completed in 6.11068888s

• [SLOW TEST:28.456 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:07:38.303: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kf25k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 16 06:07:38.512: INFO: Waiting up to 5m0s for pod "pod-06962863-1955-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-kf25k" to be "success or failure"
Jan 16 06:07:38.527: INFO: Pod "pod-06962863-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 14.875401ms
Jan 16 06:07:40.531: INFO: Pod "pod-06962863-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018654509s
Jan 16 06:07:42.537: INFO: Pod "pod-06962863-1955-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024498497s
STEP: Saw pod success
Jan 16 06:07:42.537: INFO: Pod "pod-06962863-1955-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:07:42.539: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-06962863-1955-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:07:42.559: INFO: Waiting for pod pod-06962863-1955-11e9-af83-025056002014 to disappear
Jan 16 06:07:42.567: INFO: Pod pod-06962863-1955-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:07:42.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kf25k" for this suite.
Jan 16 06:07:48.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:07:48.663: INFO: namespace: e2e-tests-emptydir-kf25k, resource: bindings, ignored listing per whitelist
Jan 16 06:07:48.702: INFO: namespace e2e-tests-emptydir-kf25k deletion completed in 6.129630583s

• [SLOW TEST:10.400 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:07:48.703: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-fgp87
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0ccac67e-1955-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 06:07:48.922: INFO: Waiting up to 5m0s for pod "pod-secrets-0ccbc6c0-1955-11e9-af83-025056002014" in namespace "e2e-tests-secrets-fgp87" to be "success or failure"
Jan 16 06:07:48.928: INFO: Pod "pod-secrets-0ccbc6c0-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 5.806254ms
Jan 16 06:07:50.932: INFO: Pod "pod-secrets-0ccbc6c0-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010145923s
Jan 16 06:07:52.936: INFO: Pod "pod-secrets-0ccbc6c0-1955-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013777853s
STEP: Saw pod success
Jan 16 06:07:52.936: INFO: Pod "pod-secrets-0ccbc6c0-1955-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:07:52.938: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-secrets-0ccbc6c0-1955-11e9-af83-025056002014 container secret-volume-test: <nil>
STEP: delete the pod
Jan 16 06:07:52.966: INFO: Waiting for pod pod-secrets-0ccbc6c0-1955-11e9-af83-025056002014 to disappear
Jan 16 06:07:52.968: INFO: Pod pod-secrets-0ccbc6c0-1955-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:07:52.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fgp87" for this suite.
Jan 16 06:07:58.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:07:59.016: INFO: namespace: e2e-tests-secrets-fgp87, resource: bindings, ignored listing per whitelist
Jan 16 06:07:59.096: INFO: namespace e2e-tests-secrets-fgp87 deletion completed in 6.124813555s

• [SLOW TEST:10.394 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:07:59.098: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7k7gm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-12fd77ad-1955-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 06:07:59.318: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014" in namespace "e2e-tests-projected-7k7gm" to be "success or failure"
Jan 16 06:07:59.329: INFO: Pod "pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 10.500001ms
Jan 16 06:08:01.333: INFO: Pod "pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015182359s
Jan 16 06:08:03.339: INFO: Pod "pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021039645s
Jan 16 06:08:05.342: INFO: Pod "pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024405835s
Jan 16 06:08:07.347: INFO: Pod "pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.028953266s
Jan 16 06:08:09.358: INFO: Pod "pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 10.039552339s
Jan 16 06:08:11.365: INFO: Pod "pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.047055139s
STEP: Saw pod success
Jan 16 06:08:11.365: INFO: Pod "pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:08:11.368: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 06:08:11.398: INFO: Waiting for pod pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014 to disappear
Jan 16 06:08:11.400: INFO: Pod pod-projected-configmaps-12fe6c39-1955-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:08:11.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7k7gm" for this suite.
Jan 16 06:08:17.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:08:17.508: INFO: namespace: e2e-tests-projected-7k7gm, resource: bindings, ignored listing per whitelist
Jan 16 06:08:17.523: INFO: namespace e2e-tests-projected-7k7gm deletion completed in 6.111436621s

• [SLOW TEST:18.426 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:08:17.524: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-rqjf5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:08:17.725: INFO: Creating deployment "test-recreate-deployment"
Jan 16 06:08:17.731: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 16 06:08:17.743: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jan 16 06:08:19.750: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 16 06:08:19.753: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:08:21.757: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:08:23.756: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:08:25.757: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:08:27.757: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:08:29.756: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:08:31.758: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683215697, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:08:33.758: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 16 06:08:33.764: INFO: Updating deployment test-recreate-deployment
Jan 16 06:08:33.764: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 16 06:08:33.890: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-rqjf5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rqjf5/deployments/test-recreate-deployment,UID:1df8b22c-1955-11e9-ba24-0050568f491d,ResourceVersion:12271,Generation:2,CreationTimestamp:2019-01-16 06:08:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-16 06:08:33 +0000 UTC 2019-01-16 06:08:33 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-16 06:08:33 +0000 UTC 2019-01-16 06:08:17 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan 16 06:08:33.894: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-rqjf5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rqjf5/replicasets/test-recreate-deployment-7cf749666b,UID:278e2a04-1955-11e9-ba24-0050568f491d,ResourceVersion:12269,Generation:1,CreationTimestamp:2019-01-16 06:08:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1df8b22c-1955-11e9-ba24-0050568f491d 0xc4214dc4f7 0xc4214dc4f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 16 06:08:33.894: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 16 06:08:33.894: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-rqjf5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rqjf5/replicasets/test-recreate-deployment-79f694ff59,UID:1df9ea70-1955-11e9-ba24-0050568f491d,ResourceVersion:12259,Generation:2,CreationTimestamp:2019-01-16 06:08:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1df8b22c-1955-11e9-ba24-0050568f491d 0xc4214dc437 0xc4214dc438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 16 06:08:33.897: INFO: Pod "test-recreate-deployment-7cf749666b-skrfr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-skrfr,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-rqjf5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rqjf5/pods/test-recreate-deployment-7cf749666b-skrfr,UID:278ea260-1955-11e9-ba24-0050568f491d,ResourceVersion:12268,Generation:0,CreationTimestamp:2019-01-16 06:08:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 278e2a04-1955-11e9-ba24-0050568f491d 0xc4214dcdc7 0xc4214dcdc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tsbzf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tsbzf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tsbzf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214dce30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4214dce50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:08:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:08:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:08:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:08:33 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:,StartTime:2019-01-16 06:08:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:08:33.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rqjf5" for this suite.
Jan 16 06:08:39.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:08:39.946: INFO: namespace: e2e-tests-deployment-rqjf5, resource: bindings, ignored listing per whitelist
Jan 16 06:08:40.003: INFO: namespace e2e-tests-deployment-rqjf5 deletion completed in 6.101281094s

• [SLOW TEST:22.479 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:08:40.003: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-j7nm4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 16 06:08:40.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:08:53.721: INFO: stderr: ""
Jan 16 06:08:53.721: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 16 06:08:53.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:08:53.848: INFO: stderr: ""
Jan 16 06:08:53.848: INFO: stdout: "update-demo-nautilus-2jpvl update-demo-nautilus-nwvw6 "
Jan 16 06:08:53.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-2jpvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:08:53.947: INFO: stderr: ""
Jan 16 06:08:53.947: INFO: stdout: ""
Jan 16 06:08:53.947: INFO: update-demo-nautilus-2jpvl is created but not running
Jan 16 06:08:58.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:08:59.092: INFO: stderr: ""
Jan 16 06:08:59.092: INFO: stdout: "update-demo-nautilus-2jpvl update-demo-nautilus-nwvw6 "
Jan 16 06:08:59.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-2jpvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:08:59.187: INFO: stderr: ""
Jan 16 06:08:59.187: INFO: stdout: ""
Jan 16 06:08:59.187: INFO: update-demo-nautilus-2jpvl is created but not running
Jan 16 06:09:04.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:09:04.297: INFO: stderr: ""
Jan 16 06:09:04.297: INFO: stdout: "update-demo-nautilus-2jpvl update-demo-nautilus-nwvw6 "
Jan 16 06:09:04.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-2jpvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:09:04.432: INFO: stderr: ""
Jan 16 06:09:04.432: INFO: stdout: ""
Jan 16 06:09:04.432: INFO: update-demo-nautilus-2jpvl is created but not running
Jan 16 06:09:09.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:09:09.542: INFO: stderr: ""
Jan 16 06:09:09.542: INFO: stdout: "update-demo-nautilus-2jpvl update-demo-nautilus-nwvw6 "
Jan 16 06:09:09.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-2jpvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:09:09.653: INFO: stderr: ""
Jan 16 06:09:09.653: INFO: stdout: "true"
Jan 16 06:09:09.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-2jpvl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:09:09.758: INFO: stderr: ""
Jan 16 06:09:09.758: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 16 06:09:09.759: INFO: validating pod update-demo-nautilus-2jpvl
Jan 16 06:09:09.765: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 16 06:09:09.765: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 16 06:09:09.765: INFO: update-demo-nautilus-2jpvl is verified up and running
Jan 16 06:09:09.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-nwvw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:09:09.871: INFO: stderr: ""
Jan 16 06:09:09.871: INFO: stdout: "true"
Jan 16 06:09:09.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-nwvw6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:09:09.960: INFO: stderr: ""
Jan 16 06:09:09.960: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 16 06:09:09.960: INFO: validating pod update-demo-nautilus-nwvw6
Jan 16 06:09:09.965: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 16 06:09:09.965: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 16 06:09:09.965: INFO: update-demo-nautilus-nwvw6 is verified up and running
STEP: using delete to clean up resources
Jan 16 06:09:09.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:09:10.077: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 16 06:09:10.078: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 16 06:09:10.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-j7nm4'
Jan 16 06:09:10.261: INFO: stderr: "No resources found.\n"
Jan 16 06:09:10.261: INFO: stdout: ""
Jan 16 06:09:10.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -l name=update-demo --namespace=e2e-tests-kubectl-j7nm4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 16 06:09:10.451: INFO: stderr: ""
Jan 16 06:09:10.451: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:09:10.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j7nm4" for this suite.
Jan 16 06:09:16.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:09:16.511: INFO: namespace: e2e-tests-kubectl-j7nm4, resource: bindings, ignored listing per whitelist
Jan 16 06:09:16.543: INFO: namespace e2e-tests-kubectl-j7nm4 deletion completed in 6.087479831s

• [SLOW TEST:36.540 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:09:16.544: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-khnx2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 06:09:16.731: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41233dd2-1955-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-khnx2" to be "success or failure"
Jan 16 06:09:16.734: INFO: Pod "downwardapi-volume-41233dd2-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.264126ms
Jan 16 06:09:18.737: INFO: Pod "downwardapi-volume-41233dd2-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005864686s
Jan 16 06:09:20.741: INFO: Pod "downwardapi-volume-41233dd2-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009100977s
Jan 16 06:09:22.744: INFO: Pod "downwardapi-volume-41233dd2-1955-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012500871s
STEP: Saw pod success
Jan 16 06:09:22.744: INFO: Pod "downwardapi-volume-41233dd2-1955-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:09:22.747: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-41233dd2-1955-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 06:09:22.766: INFO: Waiting for pod downwardapi-volume-41233dd2-1955-11e9-af83-025056002014 to disappear
Jan 16 06:09:22.772: INFO: Pod downwardapi-volume-41233dd2-1955-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:09:22.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-khnx2" for this suite.
Jan 16 06:09:28.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:09:28.858: INFO: namespace: e2e-tests-downward-api-khnx2, resource: bindings, ignored listing per whitelist
Jan 16 06:09:28.880: INFO: namespace e2e-tests-downward-api-khnx2 deletion completed in 6.104972163s

• [SLOW TEST:12.336 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:09:28.888: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-l8mn9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-xbt8
STEP: Creating a pod to test atomic-volume-subpath
Jan 16 06:09:29.094: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-xbt8" in namespace "e2e-tests-subpath-l8mn9" to be "success or failure"
Jan 16 06:09:29.100: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.279454ms
Jan 16 06:09:31.104: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01001329s
Jan 16 06:09:33.108: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Running", Reason="", readiness=false. Elapsed: 4.014173733s
Jan 16 06:09:35.115: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Running", Reason="", readiness=false. Elapsed: 6.021159695s
Jan 16 06:09:37.120: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Running", Reason="", readiness=false. Elapsed: 8.02575262s
Jan 16 06:09:39.123: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Running", Reason="", readiness=false. Elapsed: 10.029451164s
Jan 16 06:09:41.128: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Running", Reason="", readiness=false. Elapsed: 12.033729207s
Jan 16 06:09:43.132: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Running", Reason="", readiness=false. Elapsed: 14.037612902s
Jan 16 06:09:45.135: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Running", Reason="", readiness=false. Elapsed: 16.041164712s
Jan 16 06:09:47.139: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Running", Reason="", readiness=false. Elapsed: 18.045385713s
Jan 16 06:09:49.144: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Running", Reason="", readiness=false. Elapsed: 20.049990048s
Jan 16 06:09:51.148: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Running", Reason="", readiness=false. Elapsed: 22.053693029s
Jan 16 06:09:53.152: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Running", Reason="", readiness=false. Elapsed: 24.057627008s
Jan 16 06:09:55.155: INFO: Pod "pod-subpath-test-secret-xbt8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.061490821s
STEP: Saw pod success
Jan 16 06:09:55.156: INFO: Pod "pod-subpath-test-secret-xbt8" satisfied condition "success or failure"
Jan 16 06:09:55.159: INFO: Trying to get logs from node 1f5a976a-5eac-4984-8510-5241ae82643f pod pod-subpath-test-secret-xbt8 container test-container-subpath-secret-xbt8: <nil>
STEP: delete the pod
Jan 16 06:09:55.184: INFO: Waiting for pod pod-subpath-test-secret-xbt8 to disappear
Jan 16 06:09:55.187: INFO: Pod pod-subpath-test-secret-xbt8 no longer exists
STEP: Deleting pod pod-subpath-test-secret-xbt8
Jan 16 06:09:55.188: INFO: Deleting pod "pod-subpath-test-secret-xbt8" in namespace "e2e-tests-subpath-l8mn9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:09:55.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-l8mn9" for this suite.
Jan 16 06:10:01.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:10:01.262: INFO: namespace: e2e-tests-subpath-l8mn9, resource: bindings, ignored listing per whitelist
Jan 16 06:10:01.304: INFO: namespace e2e-tests-subpath-l8mn9 deletion completed in 6.111009777s

• [SLOW TEST:32.417 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:10:01.306: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-snqd8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-5bd560c9-1955-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 06:10:01.530: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5bd61064-1955-11e9-af83-025056002014" in namespace "e2e-tests-projected-snqd8" to be "success or failure"
Jan 16 06:10:01.542: INFO: Pod "pod-projected-configmaps-5bd61064-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 12.544115ms
Jan 16 06:10:03.547: INFO: Pod "pod-projected-configmaps-5bd61064-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016967111s
Jan 16 06:10:05.550: INFO: Pod "pod-projected-configmaps-5bd61064-1955-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0200192s
STEP: Saw pod success
Jan 16 06:10:05.550: INFO: Pod "pod-projected-configmaps-5bd61064-1955-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:10:05.552: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-configmaps-5bd61064-1955-11e9-af83-025056002014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 06:10:05.577: INFO: Waiting for pod pod-projected-configmaps-5bd61064-1955-11e9-af83-025056002014 to disappear
Jan 16 06:10:05.582: INFO: Pod pod-projected-configmaps-5bd61064-1955-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:10:05.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-snqd8" for this suite.
Jan 16 06:10:11.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:10:11.635: INFO: namespace: e2e-tests-projected-snqd8, resource: bindings, ignored listing per whitelist
Jan 16 06:10:11.701: INFO: namespace e2e-tests-projected-snqd8 deletion completed in 6.116014714s

• [SLOW TEST:10.396 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:10:11.702: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-pnpmf
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:10:11.898: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:10:12.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-pnpmf" for this suite.
Jan 16 06:10:18.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:10:18.541: INFO: namespace: e2e-tests-custom-resource-definition-pnpmf, resource: bindings, ignored listing per whitelist
Jan 16 06:10:18.564: INFO: namespace e2e-tests-custom-resource-definition-pnpmf deletion completed in 6.087561195s

• [SLOW TEST:6.862 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:10:18.565: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-52ks2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 16 06:10:28.844: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 16 06:10:28.847: INFO: Pod pod-with-prestop-http-hook still exists
Jan 16 06:10:30.847: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 16 06:10:30.851: INFO: Pod pod-with-prestop-http-hook still exists
Jan 16 06:10:32.847: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 16 06:10:32.853: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:10:32.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-52ks2" for this suite.
Jan 16 06:10:54.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:10:54.948: INFO: namespace: e2e-tests-container-lifecycle-hook-52ks2, resource: bindings, ignored listing per whitelist
Jan 16 06:10:54.966: INFO: namespace e2e-tests-container-lifecycle-hook-52ks2 deletion completed in 22.100470026s

• [SLOW TEST:36.401 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:10:54.966: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-4vjzx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:10:55.159: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan 16 06:10:55.168: INFO: Number of nodes with available pods: 0
Jan 16 06:10:55.168: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan 16 06:10:55.195: INFO: Number of nodes with available pods: 0
Jan 16 06:10:55.195: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:10:56.200: INFO: Number of nodes with available pods: 0
Jan 16 06:10:56.200: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:10:57.199: INFO: Number of nodes with available pods: 0
Jan 16 06:10:57.199: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:10:58.200: INFO: Number of nodes with available pods: 1
Jan 16 06:10:58.200: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan 16 06:10:58.217: INFO: Number of nodes with available pods: 1
Jan 16 06:10:58.217: INFO: Number of running nodes: 0, number of available pods: 1
Jan 16 06:10:59.223: INFO: Number of nodes with available pods: 0
Jan 16 06:10:59.223: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan 16 06:10:59.235: INFO: Number of nodes with available pods: 0
Jan 16 06:10:59.236: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:00.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:00.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:01.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:01.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:02.242: INFO: Number of nodes with available pods: 0
Jan 16 06:11:02.242: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:03.241: INFO: Number of nodes with available pods: 0
Jan 16 06:11:03.241: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:04.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:04.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:05.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:05.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:06.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:06.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:07.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:07.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:08.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:08.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:09.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:09.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:10.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:10.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:11.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:11.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:12.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:12.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:13.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:13.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:14.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:14.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:15.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:15.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:16.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:16.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:17.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:17.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:18.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:18.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:19.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:19.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:20.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:20.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:21.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:21.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:22.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:22.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:23.241: INFO: Number of nodes with available pods: 0
Jan 16 06:11:23.241: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:24.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:24.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:25.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:25.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:26.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:26.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:27.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:27.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:28.277: INFO: Number of nodes with available pods: 0
Jan 16 06:11:28.277: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:29.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:29.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:30.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:30.239: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:31.239: INFO: Number of nodes with available pods: 0
Jan 16 06:11:31.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:32.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:32.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:33.241: INFO: Number of nodes with available pods: 0
Jan 16 06:11:33.242: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:34.246: INFO: Number of nodes with available pods: 0
Jan 16 06:11:34.246: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:35.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:35.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:36.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:36.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:37.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:37.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:38.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:38.241: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:39.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:39.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:40.240: INFO: Number of nodes with available pods: 0
Jan 16 06:11:40.240: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:11:41.240: INFO: Number of nodes with available pods: 1
Jan 16 06:11:41.240: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-4vjzx, will wait for the garbage collector to delete the pods
Jan 16 06:11:41.307: INFO: Deleting {extensions DaemonSet} daemon-set took: 9.816403ms
Jan 16 06:11:41.408: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.23751ms
Jan 16 06:12:17.421: INFO: Number of nodes with available pods: 0
Jan 16 06:12:17.421: INFO: Number of running nodes: 0, number of available pods: 0
Jan 16 06:12:17.424: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4vjzx/daemonsets","resourceVersion":"12898"},"items":null}

Jan 16 06:12:17.428: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4vjzx/pods","resourceVersion":"12898"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:12:17.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4vjzx" for this suite.
Jan 16 06:12:23.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:12:23.530: INFO: namespace: e2e-tests-daemonsets-4vjzx, resource: bindings, ignored listing per whitelist
Jan 16 06:12:23.558: INFO: namespace e2e-tests-daemonsets-4vjzx deletion completed in 6.103684248s

• [SLOW TEST:88.592 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:12:23.560: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-nrq4r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan 16 06:12:23.754: INFO: Waiting up to 5m0s for pod "client-containers-b09c9140-1955-11e9-af83-025056002014" in namespace "e2e-tests-containers-nrq4r" to be "success or failure"
Jan 16 06:12:23.762: INFO: Pod "client-containers-b09c9140-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 7.836573ms
Jan 16 06:12:25.766: INFO: Pod "client-containers-b09c9140-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011672348s
Jan 16 06:12:27.770: INFO: Pod "client-containers-b09c9140-1955-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01530688s
STEP: Saw pod success
Jan 16 06:12:27.770: INFO: Pod "client-containers-b09c9140-1955-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:12:27.773: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod client-containers-b09c9140-1955-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:12:27.800: INFO: Waiting for pod client-containers-b09c9140-1955-11e9-af83-025056002014 to disappear
Jan 16 06:12:27.803: INFO: Pod client-containers-b09c9140-1955-11e9-af83-025056002014 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:12:27.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nrq4r" for this suite.
Jan 16 06:12:33.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:12:33.850: INFO: namespace: e2e-tests-containers-nrq4r, resource: bindings, ignored listing per whitelist
Jan 16 06:12:33.913: INFO: namespace e2e-tests-containers-nrq4r deletion completed in 6.106225088s

• [SLOW TEST:10.353 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:12:33.913: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-t45k2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 16 06:12:34.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:34.361: INFO: stderr: ""
Jan 16 06:12:34.361: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 16 06:12:34.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:34.492: INFO: stderr: ""
Jan 16 06:12:34.492: INFO: stdout: "update-demo-nautilus-25hgr update-demo-nautilus-rr8vd "
Jan 16 06:12:34.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-25hgr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:34.603: INFO: stderr: ""
Jan 16 06:12:34.603: INFO: stdout: ""
Jan 16 06:12:34.603: INFO: update-demo-nautilus-25hgr is created but not running
Jan 16 06:12:39.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:39.698: INFO: stderr: ""
Jan 16 06:12:39.698: INFO: stdout: "update-demo-nautilus-25hgr update-demo-nautilus-rr8vd "
Jan 16 06:12:39.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-25hgr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:39.804: INFO: stderr: ""
Jan 16 06:12:39.804: INFO: stdout: "true"
Jan 16 06:12:39.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-25hgr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:39.902: INFO: stderr: ""
Jan 16 06:12:39.902: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 16 06:12:39.902: INFO: validating pod update-demo-nautilus-25hgr
Jan 16 06:12:39.909: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 16 06:12:39.909: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 16 06:12:39.909: INFO: update-demo-nautilus-25hgr is verified up and running
Jan 16 06:12:39.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-rr8vd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:39.994: INFO: stderr: ""
Jan 16 06:12:39.994: INFO: stdout: "true"
Jan 16 06:12:39.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-rr8vd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:40.101: INFO: stderr: ""
Jan 16 06:12:40.101: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 16 06:12:40.101: INFO: validating pod update-demo-nautilus-rr8vd
Jan 16 06:12:40.106: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 16 06:12:40.106: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 16 06:12:40.106: INFO: update-demo-nautilus-rr8vd is verified up and running
STEP: scaling down the replication controller
Jan 16 06:12:40.108: INFO: scanned /root for discovery docs: <nil>
Jan 16 06:12:40.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:41.258: INFO: stderr: ""
Jan 16 06:12:41.258: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 16 06:12:41.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:41.406: INFO: stderr: ""
Jan 16 06:12:41.406: INFO: stdout: "update-demo-nautilus-25hgr update-demo-nautilus-rr8vd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 16 06:12:46.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:46.500: INFO: stderr: ""
Jan 16 06:12:46.500: INFO: stdout: "update-demo-nautilus-25hgr update-demo-nautilus-rr8vd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 16 06:12:51.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:51.625: INFO: stderr: ""
Jan 16 06:12:51.625: INFO: stdout: "update-demo-nautilus-rr8vd "
Jan 16 06:12:51.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-rr8vd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:51.740: INFO: stderr: ""
Jan 16 06:12:51.740: INFO: stdout: "true"
Jan 16 06:12:51.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-rr8vd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:51.843: INFO: stderr: ""
Jan 16 06:12:51.843: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 16 06:12:51.843: INFO: validating pod update-demo-nautilus-rr8vd
Jan 16 06:12:51.848: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 16 06:12:51.848: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 16 06:12:51.848: INFO: update-demo-nautilus-rr8vd is verified up and running
STEP: scaling up the replication controller
Jan 16 06:12:51.850: INFO: scanned /root for discovery docs: <nil>
Jan 16 06:12:51.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:52.978: INFO: stderr: ""
Jan 16 06:12:52.978: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 16 06:12:52.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:53.066: INFO: stderr: ""
Jan 16 06:12:53.067: INFO: stdout: "update-demo-nautilus-lxv7v update-demo-nautilus-rr8vd "
Jan 16 06:12:53.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-lxv7v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:53.156: INFO: stderr: ""
Jan 16 06:12:53.156: INFO: stdout: ""
Jan 16 06:12:53.157: INFO: update-demo-nautilus-lxv7v is created but not running
Jan 16 06:12:58.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:58.269: INFO: stderr: ""
Jan 16 06:12:58.269: INFO: stdout: "update-demo-nautilus-lxv7v update-demo-nautilus-rr8vd "
Jan 16 06:12:58.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-lxv7v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:12:58.374: INFO: stderr: ""
Jan 16 06:12:58.374: INFO: stdout: ""
Jan 16 06:12:58.374: INFO: update-demo-nautilus-lxv7v is created but not running
Jan 16 06:13:03.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:13:03.480: INFO: stderr: ""
Jan 16 06:13:03.480: INFO: stdout: "update-demo-nautilus-lxv7v update-demo-nautilus-rr8vd "
Jan 16 06:13:03.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-lxv7v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:13:03.581: INFO: stderr: ""
Jan 16 06:13:03.581: INFO: stdout: "true"
Jan 16 06:13:03.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-lxv7v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:13:03.689: INFO: stderr: ""
Jan 16 06:13:03.689: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 16 06:13:03.689: INFO: validating pod update-demo-nautilus-lxv7v
Jan 16 06:13:03.694: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 16 06:13:03.695: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 16 06:13:03.695: INFO: update-demo-nautilus-lxv7v is verified up and running
Jan 16 06:13:03.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-rr8vd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:13:03.809: INFO: stderr: ""
Jan 16 06:13:03.810: INFO: stdout: "true"
Jan 16 06:13:03.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-rr8vd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:13:03.919: INFO: stderr: ""
Jan 16 06:13:03.919: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 16 06:13:03.919: INFO: validating pod update-demo-nautilus-rr8vd
Jan 16 06:13:03.924: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 16 06:13:03.924: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 16 06:13:03.924: INFO: update-demo-nautilus-rr8vd is verified up and running
STEP: using delete to clean up resources
Jan 16 06:13:03.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:13:04.012: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 16 06:13:04.012: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 16 06:13:04.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-t45k2'
Jan 16 06:13:04.133: INFO: stderr: "No resources found.\n"
Jan 16 06:13:04.133: INFO: stdout: ""
Jan 16 06:13:04.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -l name=update-demo --namespace=e2e-tests-kubectl-t45k2 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 16 06:13:04.239: INFO: stderr: ""
Jan 16 06:13:04.239: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:13:04.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t45k2" for this suite.
Jan 16 06:13:26.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:13:26.340: INFO: namespace: e2e-tests-kubectl-t45k2, resource: bindings, ignored listing per whitelist
Jan 16 06:13:26.343: INFO: namespace e2e-tests-kubectl-t45k2 deletion completed in 22.100077826s

• [SLOW TEST:52.430 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:13:26.344: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-xtfkw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0116 06:13:32.572184      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 16 06:13:32.572: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:13:32.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xtfkw" for this suite.
Jan 16 06:13:38.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:13:38.677: INFO: namespace: e2e-tests-gc-xtfkw, resource: bindings, ignored listing per whitelist
Jan 16 06:13:38.701: INFO: namespace e2e-tests-gc-xtfkw deletion completed in 6.118308603s

• [SLOW TEST:12.358 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:13:38.703: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6zz25
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-dd68a807-1955-11e9-af83-025056002014
STEP: Creating secret with name s-test-opt-upd-dd68a853-1955-11e9-af83-025056002014
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-dd68a807-1955-11e9-af83-025056002014
STEP: Updating secret s-test-opt-upd-dd68a853-1955-11e9-af83-025056002014
STEP: Creating secret with name s-test-opt-create-dd68a867-1955-11e9-af83-025056002014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:13:49.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6zz25" for this suite.
Jan 16 06:14:11.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:14:11.125: INFO: namespace: e2e-tests-projected-6zz25, resource: bindings, ignored listing per whitelist
Jan 16 06:14:11.143: INFO: namespace e2e-tests-projected-6zz25 deletion completed in 22.114666629s

• [SLOW TEST:32.440 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:14:11.144: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-nh2j7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-cbnsq in namespace e2e-tests-proxy-nh2j7
I0116 06:14:11.361554      15 runners.go:180] Created replication controller with name: proxy-service-cbnsq, namespace: e2e-tests-proxy-nh2j7, replica count: 1
I0116 06:14:12.412247      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0116 06:14:13.412526      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0116 06:14:14.412802      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0116 06:14:15.413165      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0116 06:14:16.413515      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0116 06:14:17.413851      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0116 06:14:18.414176      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0116 06:14:19.414429      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0116 06:14:20.414720      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0116 06:14:21.415012      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0116 06:14:22.415375      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0116 06:14:23.415668      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0116 06:14:24.416107      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0116 06:14:25.416451      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0116 06:14:26.416739      15 runners.go:180] proxy-service-cbnsq Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 16 06:14:26.419: INFO: setup took 15.080743729s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan 16 06:14:26.432: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 12.350748ms)
Jan 16 06:14:26.436: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 15.797838ms)
Jan 16 06:14:26.437: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 17.588651ms)
Jan 16 06:14:26.437: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 17.750984ms)
Jan 16 06:14:26.438: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 17.498697ms)
Jan 16 06:14:26.438: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 18.216936ms)
Jan 16 06:14:26.440: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 19.525281ms)
Jan 16 06:14:26.440: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 20.177536ms)
Jan 16 06:14:26.441: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 20.177247ms)
Jan 16 06:14:26.444: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 23.468298ms)
Jan 16 06:14:26.446: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 25.50742ms)
Jan 16 06:14:26.447: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 27.874477ms)
Jan 16 06:14:26.448: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 27.157059ms)
Jan 16 06:14:26.448: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 28.294256ms)
Jan 16 06:14:26.450: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 28.95946ms)
Jan 16 06:14:26.453: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 31.958476ms)
Jan 16 06:14:26.462: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 9.184414ms)
Jan 16 06:14:26.464: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 9.335474ms)
Jan 16 06:14:26.465: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 11.659413ms)
Jan 16 06:14:26.465: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 11.439486ms)
Jan 16 06:14:26.465: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 11.314418ms)
Jan 16 06:14:26.467: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 12.303431ms)
Jan 16 06:14:26.468: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 14.626938ms)
Jan 16 06:14:26.469: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 14.212847ms)
Jan 16 06:14:26.469: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 15.977253ms)
Jan 16 06:14:26.469: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 14.346945ms)
Jan 16 06:14:26.470: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 16.151151ms)
Jan 16 06:14:26.470: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 15.371263ms)
Jan 16 06:14:26.470: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 15.807534ms)
Jan 16 06:14:26.470: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 16.939663ms)
Jan 16 06:14:26.471: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 16.311075ms)
Jan 16 06:14:26.471: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 17.894868ms)
Jan 16 06:14:26.486: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 14.692566ms)
Jan 16 06:14:26.489: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 17.744521ms)
Jan 16 06:14:26.490: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 18.110398ms)
Jan 16 06:14:26.490: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 18.601008ms)
Jan 16 06:14:26.491: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 19.132415ms)
Jan 16 06:14:26.491: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 19.098672ms)
Jan 16 06:14:26.492: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 19.814745ms)
Jan 16 06:14:26.492: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 19.624774ms)
Jan 16 06:14:26.492: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 19.847253ms)
Jan 16 06:14:26.492: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 20.041857ms)
Jan 16 06:14:26.492: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 20.774541ms)
Jan 16 06:14:26.493: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 20.314807ms)
Jan 16 06:14:26.497: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 24.574504ms)
Jan 16 06:14:26.497: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 25.976686ms)
Jan 16 06:14:26.497: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 25.634216ms)
Jan 16 06:14:26.498: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 26.264112ms)
Jan 16 06:14:26.502: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 3.773897ms)
Jan 16 06:14:26.503: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 5.035141ms)
Jan 16 06:14:26.503: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 5.234203ms)
Jan 16 06:14:26.509: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 10.597039ms)
Jan 16 06:14:26.510: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 11.79388ms)
Jan 16 06:14:26.511: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 12.498742ms)
Jan 16 06:14:26.511: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 12.544071ms)
Jan 16 06:14:26.511: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 12.778603ms)
Jan 16 06:14:26.513: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 14.52416ms)
Jan 16 06:14:26.514: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 14.875167ms)
Jan 16 06:14:26.514: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 14.984035ms)
Jan 16 06:14:26.515: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 16.20443ms)
Jan 16 06:14:26.515: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 15.702957ms)
Jan 16 06:14:26.515: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 15.996068ms)
Jan 16 06:14:26.516: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 16.022939ms)
Jan 16 06:14:26.516: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 16.329629ms)
Jan 16 06:14:26.523: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 7.164696ms)
Jan 16 06:14:26.526: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 9.979559ms)
Jan 16 06:14:26.527: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 9.603508ms)
Jan 16 06:14:26.527: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 11.038465ms)
Jan 16 06:14:26.527: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 10.76583ms)
Jan 16 06:14:26.527: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 10.957672ms)
Jan 16 06:14:26.528: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 11.038878ms)
Jan 16 06:14:26.528: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 11.249678ms)
Jan 16 06:14:26.528: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 11.079952ms)
Jan 16 06:14:26.529: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 11.198184ms)
Jan 16 06:14:26.529: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 12.869259ms)
Jan 16 06:14:26.529: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 12.046256ms)
Jan 16 06:14:26.530: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 12.850978ms)
Jan 16 06:14:26.530: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 13.979465ms)
Jan 16 06:14:26.533: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 16.211847ms)
Jan 16 06:14:26.533: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 15.688006ms)
Jan 16 06:14:26.541: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 7.955826ms)
Jan 16 06:14:26.542: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 8.726409ms)
Jan 16 06:14:26.542: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 8.722455ms)
Jan 16 06:14:26.542: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 9.414733ms)
Jan 16 06:14:26.543: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 9.77734ms)
Jan 16 06:14:26.543: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 9.364429ms)
Jan 16 06:14:26.544: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 9.591642ms)
Jan 16 06:14:26.544: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 10.047787ms)
Jan 16 06:14:26.544: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 10.389419ms)
Jan 16 06:14:26.544: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 10.318032ms)
Jan 16 06:14:26.545: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 10.87096ms)
Jan 16 06:14:26.546: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 11.885506ms)
Jan 16 06:14:26.546: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 12.860771ms)
Jan 16 06:14:26.547: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 12.71126ms)
Jan 16 06:14:26.547: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 12.658646ms)
Jan 16 06:14:26.547: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 13.68077ms)
Jan 16 06:14:26.552: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 4.76811ms)
Jan 16 06:14:26.555: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 6.444252ms)
Jan 16 06:14:26.555: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 6.627314ms)
Jan 16 06:14:26.557: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 7.702623ms)
Jan 16 06:14:26.558: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 9.509481ms)
Jan 16 06:14:26.558: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 9.961667ms)
Jan 16 06:14:26.559: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 10.729039ms)
Jan 16 06:14:26.561: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 12.362315ms)
Jan 16 06:14:26.563: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 15.538438ms)
Jan 16 06:14:26.563: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 14.413757ms)
Jan 16 06:14:26.563: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 15.303699ms)
Jan 16 06:14:26.563: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 14.877063ms)
Jan 16 06:14:26.563: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 15.423045ms)
Jan 16 06:14:26.563: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 13.980902ms)
Jan 16 06:14:26.564: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 14.581448ms)
Jan 16 06:14:26.564: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 16.143317ms)
Jan 16 06:14:26.577: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 12.548046ms)
Jan 16 06:14:26.578: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 13.116823ms)
Jan 16 06:14:26.578: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 14.036886ms)
Jan 16 06:14:26.578: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 12.763401ms)
Jan 16 06:14:26.581: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 16.00545ms)
Jan 16 06:14:26.582: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 16.124188ms)
Jan 16 06:14:26.582: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 18.042226ms)
Jan 16 06:14:26.583: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 17.387423ms)
Jan 16 06:14:26.583: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 18.05975ms)
Jan 16 06:14:26.584: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 19.584858ms)
Jan 16 06:14:26.585: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 18.587645ms)
Jan 16 06:14:26.585: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 21.099566ms)
Jan 16 06:14:26.586: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 19.959518ms)
Jan 16 06:14:26.586: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 19.915672ms)
Jan 16 06:14:26.586: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 20.176001ms)
Jan 16 06:14:26.586: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 20.268039ms)
Jan 16 06:14:26.591: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 4.855642ms)
Jan 16 06:14:26.598: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 10.842032ms)
Jan 16 06:14:26.599: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 12.352233ms)
Jan 16 06:14:26.600: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 12.475308ms)
Jan 16 06:14:26.600: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 13.295996ms)
Jan 16 06:14:26.602: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 14.273749ms)
Jan 16 06:14:26.602: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 14.198626ms)
Jan 16 06:14:26.602: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 14.480519ms)
Jan 16 06:14:26.604: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 16.338185ms)
Jan 16 06:14:26.605: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 16.795622ms)
Jan 16 06:14:26.605: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 17.077654ms)
Jan 16 06:14:26.605: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 17.751816ms)
Jan 16 06:14:26.606: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 17.096684ms)
Jan 16 06:14:26.607: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 17.896296ms)
Jan 16 06:14:26.607: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 18.21364ms)
Jan 16 06:14:26.608: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 19.284904ms)
Jan 16 06:14:26.614: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 5.528142ms)
Jan 16 06:14:26.616: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 7.037465ms)
Jan 16 06:14:26.620: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 10.797398ms)
Jan 16 06:14:26.621: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 11.404176ms)
Jan 16 06:14:26.621: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 12.357053ms)
Jan 16 06:14:26.622: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 13.004979ms)
Jan 16 06:14:26.622: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 12.823626ms)
Jan 16 06:14:26.624: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 15.063826ms)
Jan 16 06:14:26.624: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 14.642817ms)
Jan 16 06:14:26.624: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 14.781158ms)
Jan 16 06:14:26.625: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 15.132996ms)
Jan 16 06:14:26.626: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 16.276458ms)
Jan 16 06:14:26.626: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 16.740393ms)
Jan 16 06:14:26.627: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 18.633358ms)
Jan 16 06:14:26.627: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 17.91949ms)
Jan 16 06:14:26.627: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 19.1304ms)
Jan 16 06:14:26.641: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 13.298119ms)
Jan 16 06:14:26.641: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 13.646615ms)
Jan 16 06:14:26.642: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 14.003084ms)
Jan 16 06:14:26.642: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 13.950484ms)
Jan 16 06:14:26.645: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 16.455285ms)
Jan 16 06:14:26.645: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 17.212301ms)
Jan 16 06:14:26.647: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 19.149177ms)
Jan 16 06:14:26.647: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 19.125678ms)
Jan 16 06:14:26.647: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 19.804008ms)
Jan 16 06:14:26.647: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 20.066957ms)
Jan 16 06:14:26.647: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 19.41881ms)
Jan 16 06:14:26.647: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 19.043748ms)
Jan 16 06:14:26.649: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 20.207799ms)
Jan 16 06:14:26.649: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 20.12078ms)
Jan 16 06:14:26.649: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 20.406414ms)
Jan 16 06:14:26.649: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 20.626353ms)
Jan 16 06:14:26.655: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 5.518938ms)
Jan 16 06:14:26.656: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 6.835246ms)
Jan 16 06:14:26.657: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 7.258412ms)
Jan 16 06:14:26.659: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 9.275197ms)
Jan 16 06:14:26.659: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 9.5014ms)
Jan 16 06:14:26.659: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 9.451793ms)
Jan 16 06:14:26.660: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 10.017009ms)
Jan 16 06:14:26.663: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 13.893789ms)
Jan 16 06:14:26.664: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 13.6371ms)
Jan 16 06:14:26.665: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 14.169368ms)
Jan 16 06:14:26.665: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 14.783269ms)
Jan 16 06:14:26.665: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 14.61019ms)
Jan 16 06:14:26.666: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 15.213139ms)
Jan 16 06:14:26.666: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 15.921427ms)
Jan 16 06:14:26.666: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 15.801098ms)
Jan 16 06:14:26.666: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 16.166014ms)
Jan 16 06:14:26.677: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 10.562391ms)
Jan 16 06:14:26.681: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 12.888694ms)
Jan 16 06:14:26.681: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 13.353431ms)
Jan 16 06:14:26.681: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 14.352457ms)
Jan 16 06:14:26.681: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 13.622934ms)
Jan 16 06:14:26.681: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 13.544022ms)
Jan 16 06:14:26.686: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 18.628622ms)
Jan 16 06:14:26.691: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 23.979475ms)
Jan 16 06:14:26.695: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 27.049451ms)
Jan 16 06:14:26.695: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 27.021899ms)
Jan 16 06:14:26.695: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 28.125439ms)
Jan 16 06:14:26.698: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 30.232583ms)
Jan 16 06:14:26.699: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 31.848699ms)
Jan 16 06:14:26.699: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 31.547652ms)
Jan 16 06:14:26.699: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 31.843031ms)
Jan 16 06:14:26.699: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 32.094272ms)
Jan 16 06:14:26.706: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 6.29121ms)
Jan 16 06:14:26.707: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 7.268479ms)
Jan 16 06:14:26.708: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 7.207654ms)
Jan 16 06:14:26.708: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 8.6486ms)
Jan 16 06:14:26.708: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 8.160413ms)
Jan 16 06:14:26.710: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 8.829757ms)
Jan 16 06:14:26.710: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 8.985774ms)
Jan 16 06:14:26.712: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 12.623428ms)
Jan 16 06:14:26.713: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 11.863057ms)
Jan 16 06:14:26.714: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 12.298424ms)
Jan 16 06:14:26.714: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 13.172462ms)
Jan 16 06:14:26.714: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 12.273469ms)
Jan 16 06:14:26.714: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 12.417625ms)
Jan 16 06:14:26.714: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 14.226764ms)
Jan 16 06:14:26.714: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 13.917092ms)
Jan 16 06:14:26.715: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 13.519348ms)
Jan 16 06:14:26.724: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 8.895528ms)
Jan 16 06:14:26.724: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 8.854811ms)
Jan 16 06:14:26.724: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 8.887314ms)
Jan 16 06:14:26.725: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 9.486417ms)
Jan 16 06:14:26.725: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 9.909493ms)
Jan 16 06:14:26.726: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 10.878606ms)
Jan 16 06:14:26.726: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 10.509414ms)
Jan 16 06:14:26.727: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 11.830989ms)
Jan 16 06:14:26.727: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 12.236754ms)
Jan 16 06:14:26.727: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 12.534827ms)
Jan 16 06:14:26.728: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 12.500298ms)
Jan 16 06:14:26.728: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 12.624269ms)
Jan 16 06:14:26.728: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 12.936494ms)
Jan 16 06:14:26.728: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 13.416097ms)
Jan 16 06:14:26.728: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 13.533187ms)
Jan 16 06:14:26.728: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 13.496167ms)
Jan 16 06:14:26.735: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 6.837545ms)
Jan 16 06:14:26.736: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 6.827427ms)
Jan 16 06:14:26.738: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 8.952168ms)
Jan 16 06:14:26.740: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 10.624642ms)
Jan 16 06:14:26.740: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 11.290578ms)
Jan 16 06:14:26.740: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 11.047976ms)
Jan 16 06:14:26.741: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 11.872431ms)
Jan 16 06:14:26.741: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 11.996022ms)
Jan 16 06:14:26.741: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 12.219591ms)
Jan 16 06:14:26.741: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 12.08764ms)
Jan 16 06:14:26.741: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 12.237013ms)
Jan 16 06:14:26.741: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 12.288783ms)
Jan 16 06:14:26.741: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 12.702831ms)
Jan 16 06:14:26.743: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 13.849557ms)
Jan 16 06:14:26.743: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 14.011489ms)
Jan 16 06:14:26.744: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 14.627103ms)
Jan 16 06:14:26.751: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 7.017239ms)
Jan 16 06:14:26.751: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 7.462534ms)
Jan 16 06:14:26.756: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 11.237559ms)
Jan 16 06:14:26.756: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 11.536935ms)
Jan 16 06:14:26.756: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 12.067309ms)
Jan 16 06:14:26.756: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 12.063489ms)
Jan 16 06:14:26.756: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 11.879493ms)
Jan 16 06:14:26.762: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 17.208229ms)
Jan 16 06:14:26.762: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 17.573638ms)
Jan 16 06:14:26.762: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 18.224785ms)
Jan 16 06:14:26.762: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 18.180766ms)
Jan 16 06:14:26.762: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 18.254359ms)
Jan 16 06:14:26.762: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 17.878326ms)
Jan 16 06:14:26.763: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 18.759796ms)
Jan 16 06:14:26.763: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 19.139484ms)
Jan 16 06:14:26.763: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 19.352127ms)
Jan 16 06:14:26.774: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 10.240723ms)
Jan 16 06:14:26.775: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 10.477427ms)
Jan 16 06:14:26.775: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 10.713202ms)
Jan 16 06:14:26.778: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 14.349502ms)
Jan 16 06:14:26.779: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 13.942655ms)
Jan 16 06:14:26.779: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 14.197695ms)
Jan 16 06:14:26.779: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 14.284019ms)
Jan 16 06:14:26.779: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 15.135999ms)
Jan 16 06:14:26.779: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 14.49744ms)
Jan 16 06:14:26.780: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 14.918871ms)
Jan 16 06:14:26.780: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 16.013136ms)
Jan 16 06:14:26.780: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 16.185306ms)
Jan 16 06:14:26.780: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 16.356207ms)
Jan 16 06:14:26.781: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 15.962929ms)
Jan 16 06:14:26.781: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 16.557967ms)
Jan 16 06:14:26.781: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 16.690113ms)
Jan 16 06:14:26.787: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 6.169556ms)
Jan 16 06:14:26.789: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 7.517734ms)
Jan 16 06:14:26.789: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 7.406019ms)
Jan 16 06:14:26.791: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 9.924032ms)
Jan 16 06:14:26.791: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 9.879972ms)
Jan 16 06:14:26.792: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 10.914414ms)
Jan 16 06:14:26.794: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 13.087486ms)
Jan 16 06:14:26.796: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 14.932259ms)
Jan 16 06:14:26.797: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 15.618058ms)
Jan 16 06:14:26.797: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 15.661133ms)
Jan 16 06:14:26.797: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 16.084718ms)
Jan 16 06:14:26.797: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 16.118487ms)
Jan 16 06:14:26.798: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 16.534701ms)
Jan 16 06:14:26.799: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 17.263811ms)
Jan 16 06:14:26.799: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 17.455541ms)
Jan 16 06:14:26.798: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 16.340117ms)
Jan 16 06:14:26.805: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:462/proxy/: tls qux (200; 6.182226ms)
Jan 16 06:14:26.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname1/proxy/: tls baz (200; 6.763143ms)
Jan 16 06:14:26.808: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:1080/proxy/... (200; 8.707896ms)
Jan 16 06:14:26.808: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd/proxy/rewriteme"... (200; 8.847707ms)
Jan 16 06:14:26.809: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 9.737197ms)
Jan 16 06:14:26.810: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname2/proxy/: bar (200; 10.160013ms)
Jan 16 06:14:26.811: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname1/proxy/: foo (200; 11.666882ms)
Jan 16 06:14:26.812: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/https:proxy-service-cbnsq:tlsportname2/proxy/: tls qux (200; 12.668553ms)
Jan 16 06:14:26.812: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 12.819033ms)
Jan 16 06:14:26.813: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:1080/proxy/rewri... (200; 13.373494ms)
Jan 16 06:14:26.813: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/http:proxy-service-cbnsq:portname2/proxy/: bar (200; 13.502488ms)
Jan 16 06:14:26.813: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:443/proxy/... (200; 13.619326ms)
Jan 16 06:14:26.813: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/https:proxy-service-cbnsq-dfgcd:460/proxy/: tls baz (200; 13.657794ms)
Jan 16 06:14:26.814: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/http:proxy-service-cbnsq-dfgcd:162/proxy/: bar (200; 14.339414ms)
Jan 16 06:14:26.814: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/pods/proxy-service-cbnsq-dfgcd:160/proxy/: foo (200; 14.543645ms)
Jan 16 06:14:26.814: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nh2j7/services/proxy-service-cbnsq:portname1/proxy/: foo (200; 14.636937ms)
STEP: deleting { ReplicationController} proxy-service-cbnsq in namespace e2e-tests-proxy-nh2j7, will wait for the garbage collector to delete the pods
Jan 16 06:14:26.873: INFO: Deleting { ReplicationController} proxy-service-cbnsq took: 6.244411ms
Jan 16 06:14:26.973: INFO: Terminating { ReplicationController} proxy-service-cbnsq pods took: 100.40075ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:14:28.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-nh2j7" for this suite.
Jan 16 06:14:34.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:14:34.630: INFO: namespace: e2e-tests-proxy-nh2j7, resource: bindings, ignored listing per whitelist
Jan 16 06:14:34.686: INFO: namespace e2e-tests-proxy-nh2j7 deletion completed in 6.107630074s

• [SLOW TEST:23.543 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:14:34.687: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-78l2c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 16 06:14:34.903: INFO: Waiting up to 5m0s for pod "pod-fec82fdf-1955-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-78l2c" to be "success or failure"
Jan 16 06:14:34.909: INFO: Pod "pod-fec82fdf-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 5.914074ms
Jan 16 06:14:36.912: INFO: Pod "pod-fec82fdf-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009659188s
Jan 16 06:14:38.916: INFO: Pod "pod-fec82fdf-1955-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013418249s
Jan 16 06:14:40.920: INFO: Pod "pod-fec82fdf-1955-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016987469s
STEP: Saw pod success
Jan 16 06:14:40.920: INFO: Pod "pod-fec82fdf-1955-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:14:40.923: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-fec82fdf-1955-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:14:40.941: INFO: Waiting for pod pod-fec82fdf-1955-11e9-af83-025056002014 to disappear
Jan 16 06:14:40.949: INFO: Pod pod-fec82fdf-1955-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:14:40.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-78l2c" for this suite.
Jan 16 06:14:46.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:14:47.022: INFO: namespace: e2e-tests-emptydir-78l2c, resource: bindings, ignored listing per whitelist
Jan 16 06:14:47.055: INFO: namespace e2e-tests-emptydir-78l2c deletion completed in 6.1009062s

• [SLOW TEST:12.368 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:14:47.055: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-cgx6v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:14:51.295: INFO: Waiting up to 5m0s for pod "client-envvars-088cf9e1-1956-11e9-af83-025056002014" in namespace "e2e-tests-pods-cgx6v" to be "success or failure"
Jan 16 06:14:51.311: INFO: Pod "client-envvars-088cf9e1-1956-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 16.336486ms
Jan 16 06:14:53.315: INFO: Pod "client-envvars-088cf9e1-1956-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020468274s
STEP: Saw pod success
Jan 16 06:14:53.316: INFO: Pod "client-envvars-088cf9e1-1956-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:14:53.318: INFO: Trying to get logs from node 1f5a976a-5eac-4984-8510-5241ae82643f pod client-envvars-088cf9e1-1956-11e9-af83-025056002014 container env3cont: <nil>
STEP: delete the pod
Jan 16 06:14:53.338: INFO: Waiting for pod client-envvars-088cf9e1-1956-11e9-af83-025056002014 to disappear
Jan 16 06:14:53.344: INFO: Pod client-envvars-088cf9e1-1956-11e9-af83-025056002014 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:14:53.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-cgx6v" for this suite.
Jan 16 06:15:31.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:15:31.403: INFO: namespace: e2e-tests-pods-cgx6v, resource: bindings, ignored listing per whitelist
Jan 16 06:15:31.455: INFO: namespace e2e-tests-pods-cgx6v deletion completed in 38.106003435s

• [SLOW TEST:44.400 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:15:31.456: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9dd9b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan 16 06:15:31.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 cluster-info'
Jan 16 06:15:31.768: INFO: stderr: ""
Jan 16 06:15:31.768: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mmonitoring-influxdb\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/monitoring-influxdb/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:15:31.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9dd9b" for this suite.
Jan 16 06:15:37.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:15:37.809: INFO: namespace: e2e-tests-kubectl-9dd9b, resource: bindings, ignored listing per whitelist
Jan 16 06:15:37.878: INFO: namespace e2e-tests-kubectl-9dd9b deletion completed in 6.105166599s

• [SLOW TEST:6.422 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:15:37.878: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-62k4r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2478a218-1956-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 06:15:38.136: INFO: Waiting up to 5m0s for pod "pod-secrets-24792aaa-1956-11e9-af83-025056002014" in namespace "e2e-tests-secrets-62k4r" to be "success or failure"
Jan 16 06:15:38.142: INFO: Pod "pod-secrets-24792aaa-1956-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 5.522975ms
Jan 16 06:15:40.145: INFO: Pod "pod-secrets-24792aaa-1956-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008138436s
Jan 16 06:15:42.148: INFO: Pod "pod-secrets-24792aaa-1956-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011883734s
STEP: Saw pod success
Jan 16 06:15:42.148: INFO: Pod "pod-secrets-24792aaa-1956-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:15:42.151: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-secrets-24792aaa-1956-11e9-af83-025056002014 container secret-volume-test: <nil>
STEP: delete the pod
Jan 16 06:15:42.181: INFO: Waiting for pod pod-secrets-24792aaa-1956-11e9-af83-025056002014 to disappear
Jan 16 06:15:42.186: INFO: Pod pod-secrets-24792aaa-1956-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:15:42.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-62k4r" for this suite.
Jan 16 06:15:48.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:15:48.238: INFO: namespace: e2e-tests-secrets-62k4r, resource: bindings, ignored listing per whitelist
Jan 16 06:15:48.304: INFO: namespace e2e-tests-secrets-62k4r deletion completed in 6.107983948s

• [SLOW TEST:10.425 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:15:48.304: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-db44k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:15:48.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 version'
Jan 16 06:15:48.627: INFO: stderr: ""
Jan 16 06:15:48.627: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.4\", GitCommit:\"f49fa022dbe63faafd0da106ef7e05a29721d3f1\", GitTreeState:\"clean\", BuildDate:\"2018-12-14T06:59:37Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:15:48.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-db44k" for this suite.
Jan 16 06:15:54.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:15:54.662: INFO: namespace: e2e-tests-kubectl-db44k, resource: bindings, ignored listing per whitelist
Jan 16 06:15:54.724: INFO: namespace e2e-tests-kubectl-db44k deletion completed in 6.093637262s

• [SLOW TEST:6.421 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:15:54.729: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fvtj4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 16 06:15:54.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-fvtj4'
Jan 16 06:15:55.029: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 16 06:15:55.029: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Jan 16 06:15:57.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-fvtj4'
Jan 16 06:15:57.151: INFO: stderr: ""
Jan 16 06:15:57.151: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:15:57.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fvtj4" for this suite.
Jan 16 06:17:19.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:17:19.235: INFO: namespace: e2e-tests-kubectl-fvtj4, resource: bindings, ignored listing per whitelist
Jan 16 06:17:19.259: INFO: namespace e2e-tests-kubectl-fvtj4 deletion completed in 1m22.104242674s

• [SLOW TEST:84.531 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:17:19.260: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-jmh9m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan 16 06:17:21.465: INFO: Pod pod-hostip-60dcce3a-1956-11e9-af83-025056002014 has hostIP: 30.0.3.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:17:21.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jmh9m" for this suite.
Jan 16 06:17:43.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:17:43.511: INFO: namespace: e2e-tests-pods-jmh9m, resource: bindings, ignored listing per whitelist
Jan 16 06:17:43.576: INFO: namespace e2e-tests-pods-jmh9m deletion completed in 22.106849587s

• [SLOW TEST:24.316 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:17:43.578: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-j2tmp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan 16 06:17:43.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:17:44.755: INFO: stderr: ""
Jan 16 06:17:44.755: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 16 06:17:44.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:17:44.870: INFO: stderr: ""
Jan 16 06:17:44.870: INFO: stdout: "update-demo-nautilus-7cd6w update-demo-nautilus-vfrqk "
Jan 16 06:17:44.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-7cd6w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:17:44.974: INFO: stderr: ""
Jan 16 06:17:44.974: INFO: stdout: ""
Jan 16 06:17:44.974: INFO: update-demo-nautilus-7cd6w is created but not running
Jan 16 06:17:49.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:17:50.069: INFO: stderr: ""
Jan 16 06:17:50.069: INFO: stdout: "update-demo-nautilus-7cd6w update-demo-nautilus-vfrqk "
Jan 16 06:17:50.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-7cd6w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:17:50.157: INFO: stderr: ""
Jan 16 06:17:50.157: INFO: stdout: "true"
Jan 16 06:17:50.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-7cd6w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:17:50.267: INFO: stderr: ""
Jan 16 06:17:50.268: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 16 06:17:50.268: INFO: validating pod update-demo-nautilus-7cd6w
Jan 16 06:17:50.274: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 16 06:17:50.274: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 16 06:17:50.274: INFO: update-demo-nautilus-7cd6w is verified up and running
Jan 16 06:17:50.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-vfrqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:17:50.391: INFO: stderr: ""
Jan 16 06:17:50.391: INFO: stdout: "true"
Jan 16 06:17:50.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-nautilus-vfrqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:17:50.474: INFO: stderr: ""
Jan 16 06:17:50.474: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 16 06:17:50.475: INFO: validating pod update-demo-nautilus-vfrqk
Jan 16 06:17:50.480: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 16 06:17:50.480: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 16 06:17:50.480: INFO: update-demo-nautilus-vfrqk is verified up and running
STEP: rolling-update to new replication controller
Jan 16 06:17:50.482: INFO: scanned /root for discovery docs: <nil>
Jan 16 06:17:50.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:18:13.943: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 16 06:18:13.943: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 16 06:18:13.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:18:14.049: INFO: stderr: ""
Jan 16 06:18:14.049: INFO: stdout: "update-demo-kitten-5r9sh update-demo-kitten-77p4s "
Jan 16 06:18:14.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-kitten-5r9sh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:18:14.144: INFO: stderr: ""
Jan 16 06:18:14.144: INFO: stdout: "true"
Jan 16 06:18:14.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-kitten-5r9sh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:18:14.258: INFO: stderr: ""
Jan 16 06:18:14.258: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 16 06:18:14.258: INFO: validating pod update-demo-kitten-5r9sh
Jan 16 06:18:14.265: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 16 06:18:14.265: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 16 06:18:14.265: INFO: update-demo-kitten-5r9sh is verified up and running
Jan 16 06:18:14.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-kitten-77p4s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:18:14.366: INFO: stderr: ""
Jan 16 06:18:14.366: INFO: stdout: "true"
Jan 16 06:18:14.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods update-demo-kitten-77p4s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j2tmp'
Jan 16 06:18:14.453: INFO: stderr: ""
Jan 16 06:18:14.453: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 16 06:18:14.453: INFO: validating pod update-demo-kitten-77p4s
Jan 16 06:18:14.460: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 16 06:18:14.460: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 16 06:18:14.460: INFO: update-demo-kitten-77p4s is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:18:14.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j2tmp" for this suite.
Jan 16 06:18:46.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:18:46.560: INFO: namespace: e2e-tests-kubectl-j2tmp, resource: bindings, ignored listing per whitelist
Jan 16 06:18:46.566: INFO: namespace e2e-tests-kubectl-j2tmp deletion completed in 32.101673162s

• [SLOW TEST:62.988 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:18:46.567: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-v9t2c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 06:18:46.782: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94e84374-1956-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-v9t2c" to be "success or failure"
Jan 16 06:18:46.801: INFO: Pod "downwardapi-volume-94e84374-1956-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 18.197295ms
Jan 16 06:18:48.805: INFO: Pod "downwardapi-volume-94e84374-1956-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022703939s
Jan 16 06:18:50.809: INFO: Pod "downwardapi-volume-94e84374-1956-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026539271s
STEP: Saw pod success
Jan 16 06:18:50.809: INFO: Pod "downwardapi-volume-94e84374-1956-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:18:50.813: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-94e84374-1956-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 06:18:50.838: INFO: Waiting for pod downwardapi-volume-94e84374-1956-11e9-af83-025056002014 to disappear
Jan 16 06:18:50.841: INFO: Pod downwardapi-volume-94e84374-1956-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:18:50.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v9t2c" for this suite.
Jan 16 06:18:56.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:18:56.887: INFO: namespace: e2e-tests-downward-api-v9t2c, resource: bindings, ignored listing per whitelist
Jan 16 06:18:56.969: INFO: namespace e2e-tests-downward-api-v9t2c deletion completed in 6.124013922s

• [SLOW TEST:10.403 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:18:56.970: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8d2l6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 16 06:18:57.219: INFO: namespace e2e-tests-kubectl-8d2l6
Jan 16 06:18:57.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-8d2l6'
Jan 16 06:18:57.426: INFO: stderr: ""
Jan 16 06:18:57.426: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 16 06:18:58.430: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:18:58.430: INFO: Found 0 / 1
Jan 16 06:18:59.431: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:18:59.431: INFO: Found 0 / 1
Jan 16 06:19:00.429: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:19:00.429: INFO: Found 1 / 1
Jan 16 06:19:00.429: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 16 06:19:00.431: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:19:00.431: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 16 06:19:00.431: INFO: wait on redis-master startup in e2e-tests-kubectl-8d2l6 
Jan 16 06:19:00.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 logs redis-master-2ldnb redis-master --namespace=e2e-tests-kubectl-8d2l6'
Jan 16 06:19:00.568: INFO: stderr: ""
Jan 16 06:19:00.568: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 16 Jan 06:18:59.282 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 16 Jan 06:18:59.282 # Server started, Redis version 3.2.12\n1:M 16 Jan 06:18:59.282 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 16 Jan 06:18:59.282 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan 16 06:19:00.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-8d2l6'
Jan 16 06:19:00.689: INFO: stderr: ""
Jan 16 06:19:00.689: INFO: stdout: "service/rm2 exposed\n"
Jan 16 06:19:00.707: INFO: Service rm2 in namespace e2e-tests-kubectl-8d2l6 found.
STEP: exposing service
Jan 16 06:19:02.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-8d2l6'
Jan 16 06:19:02.833: INFO: stderr: ""
Jan 16 06:19:02.833: INFO: stdout: "service/rm3 exposed\n"
Jan 16 06:19:02.840: INFO: Service rm3 in namespace e2e-tests-kubectl-8d2l6 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:19:04.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8d2l6" for this suite.
Jan 16 06:19:26.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:19:26.892: INFO: namespace: e2e-tests-kubectl-8d2l6, resource: bindings, ignored listing per whitelist
Jan 16 06:19:26.977: INFO: namespace e2e-tests-kubectl-8d2l6 deletion completed in 22.119636804s

• [SLOW TEST:30.007 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:19:26.980: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-mq8m2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan 16 06:19:27.184: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-mq8m2,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq8m2/configmaps/e2e-watch-test-watch-closed,UID:acfe9d07-1956-11e9-ba24-0050568f491d,ResourceVersion:14356,Generation:0,CreationTimestamp:2019-01-16 06:19:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 16 06:19:27.184: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-mq8m2,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq8m2/configmaps/e2e-watch-test-watch-closed,UID:acfe9d07-1956-11e9-ba24-0050568f491d,ResourceVersion:14357,Generation:0,CreationTimestamp:2019-01-16 06:19:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan 16 06:19:27.196: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-mq8m2,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq8m2/configmaps/e2e-watch-test-watch-closed,UID:acfe9d07-1956-11e9-ba24-0050568f491d,ResourceVersion:14358,Generation:0,CreationTimestamp:2019-01-16 06:19:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 16 06:19:27.196: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-mq8m2,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq8m2/configmaps/e2e-watch-test-watch-closed,UID:acfe9d07-1956-11e9-ba24-0050568f491d,ResourceVersion:14359,Generation:0,CreationTimestamp:2019-01-16 06:19:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:19:27.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-mq8m2" for this suite.
Jan 16 06:19:33.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:19:33.288: INFO: namespace: e2e-tests-watch-mq8m2, resource: bindings, ignored listing per whitelist
Jan 16 06:19:33.298: INFO: namespace e2e-tests-watch-mq8m2 deletion completed in 6.093396401s

• [SLOW TEST:6.319 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:19:33.301: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xt9bb
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-b0c17732-1956-11e9-af83-025056002014
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:19:37.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xt9bb" for this suite.
Jan 16 06:19:59.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:19:59.583: INFO: namespace: e2e-tests-configmap-xt9bb, resource: bindings, ignored listing per whitelist
Jan 16 06:19:59.647: INFO: namespace e2e-tests-configmap-xt9bb deletion completed in 22.12414179s

• [SLOW TEST:26.347 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:19:59.648: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-nk4xs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:20:59.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nk4xs" for this suite.
Jan 16 06:21:21.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:21:21.897: INFO: namespace: e2e-tests-container-probe-nk4xs, resource: bindings, ignored listing per whitelist
Jan 16 06:21:21.957: INFO: namespace e2e-tests-container-probe-nk4xs deletion completed in 22.089398084s

• [SLOW TEST:82.310 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:21:21.958: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-jbz7w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 16 06:21:22.139: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:21:27.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-jbz7w" for this suite.
Jan 16 06:21:33.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:21:33.530: INFO: namespace: e2e-tests-init-container-jbz7w, resource: bindings, ignored listing per whitelist
Jan 16 06:21:33.600: INFO: namespace e2e-tests-init-container-jbz7w deletion completed in 6.099217983s

• [SLOW TEST:11.642 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:21:33.601: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-8g2wm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 16 06:21:33.830: INFO: Number of nodes with available pods: 0
Jan 16 06:21:33.830: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:21:34.838: INFO: Number of nodes with available pods: 0
Jan 16 06:21:34.839: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:21:35.842: INFO: Number of nodes with available pods: 1
Jan 16 06:21:35.842: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:21:36.838: INFO: Number of nodes with available pods: 2
Jan 16 06:21:36.839: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:21:37.841: INFO: Number of nodes with available pods: 3
Jan 16 06:21:37.841: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan 16 06:21:37.881: INFO: Number of nodes with available pods: 2
Jan 16 06:21:37.881: INFO: Node d02c56a1-5f5a-4edd-b080-4296aa47afb8 is running more than one daemon pod
Jan 16 06:21:38.889: INFO: Number of nodes with available pods: 2
Jan 16 06:21:38.889: INFO: Node d02c56a1-5f5a-4edd-b080-4296aa47afb8 is running more than one daemon pod
Jan 16 06:21:39.896: INFO: Number of nodes with available pods: 3
Jan 16 06:21:39.896: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-8g2wm, will wait for the garbage collector to delete the pods
Jan 16 06:21:39.969: INFO: Deleting {extensions DaemonSet} daemon-set took: 9.703821ms
Jan 16 06:21:40.070: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 101.195737ms
Jan 16 06:22:23.074: INFO: Number of nodes with available pods: 0
Jan 16 06:22:23.074: INFO: Number of running nodes: 0, number of available pods: 0
Jan 16 06:22:23.076: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8g2wm/daemonsets","resourceVersion":"14790"},"items":null}

Jan 16 06:22:23.078: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8g2wm/pods","resourceVersion":"14790"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:22:23.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8g2wm" for this suite.
Jan 16 06:22:29.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:22:29.183: INFO: namespace: e2e-tests-daemonsets-8g2wm, resource: bindings, ignored listing per whitelist
Jan 16 06:22:29.193: INFO: namespace e2e-tests-daemonsets-8g2wm deletion completed in 6.096205932s

• [SLOW TEST:55.592 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:22:29.193: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-vc7j8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 06:22:29.392: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-vc7j8" to be "success or failure"
Jan 16 06:22:29.401: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.904639ms
Jan 16 06:22:31.405: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013075694s
Jan 16 06:22:33.409: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016639615s
Jan 16 06:22:35.412: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020291718s
Jan 16 06:22:37.416: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.023693734s
Jan 16 06:22:39.419: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 10.027199802s
Jan 16 06:22:41.423: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 12.030363564s
Jan 16 06:22:43.426: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 14.034107124s
Jan 16 06:22:45.430: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 16.037860998s
Jan 16 06:22:47.433: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 18.041139992s
Jan 16 06:22:49.437: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 20.044665103s
Jan 16 06:22:51.441: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 22.048554813s
Jan 16 06:22:53.445: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 24.052338417s
Jan 16 06:22:55.448: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 26.055565598s
Jan 16 06:22:57.452: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 28.05968382s
Jan 16 06:22:59.457: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.064302052s
STEP: Saw pod success
Jan 16 06:22:59.457: INFO: Pod "downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:22:59.460: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 06:22:59.483: INFO: Waiting for pod downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014 to disappear
Jan 16 06:22:59.487: INFO: Pod downwardapi-volume-1999c5ac-1957-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:22:59.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vc7j8" for this suite.
Jan 16 06:23:05.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:23:05.559: INFO: namespace: e2e-tests-downward-api-vc7j8, resource: bindings, ignored listing per whitelist
Jan 16 06:23:05.592: INFO: namespace e2e-tests-downward-api-vc7j8 deletion completed in 6.099193565s

• [SLOW TEST:36.399 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:23:05.596: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-xmhhb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 16 06:23:05.797: INFO: PodSpec: initContainers in spec.initContainers
Jan 16 06:23:49.500: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-2f4d8a23-1957-11e9-af83-025056002014", GenerateName:"", Namespace:"e2e-tests-init-container-xmhhb", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-xmhhb/pods/pod-init-2f4d8a23-1957-11e9-af83-025056002014", UID:"2f4e312f-1957-11e9-ba24-0050568f491d", ResourceVersion:"15003", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683216585, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"797076199"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-2lvpg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422070080), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2lvpg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2lvpg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2lvpg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc422b34a38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"d02c56a1-5f5a-4edd-b080-4296aa47afb8", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc42124e8a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc422b34ba0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc422b34bc0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc422b34bc8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683216585, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683216585, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683216585, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683216585, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"30.0.3.3", PodIP:"40.0.11.2", StartTime:(*v1.Time)(0xc420b622c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4218ba230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4218ba2a0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://ed8416c1a6c350909fa7dce3ca6c1ad1ef2bb42b09411850efb1c00a64151c63"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420b624e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420b62300), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:23:49.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xmhhb" for this suite.
Jan 16 06:24:11.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:24:11.546: INFO: namespace: e2e-tests-init-container-xmhhb, resource: bindings, ignored listing per whitelist
Jan 16 06:24:11.610: INFO: namespace e2e-tests-init-container-xmhhb deletion completed in 22.09696042s

• [SLOW TEST:66.015 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:24:11.611: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-q28r6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 16 06:24:11.817: INFO: Waiting up to 5m0s for pod "pod-56a624ac-1957-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-q28r6" to be "success or failure"
Jan 16 06:24:11.834: INFO: Pod "pod-56a624ac-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 16.782324ms
Jan 16 06:24:13.839: INFO: Pod "pod-56a624ac-1957-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02200196s
STEP: Saw pod success
Jan 16 06:24:13.839: INFO: Pod "pod-56a624ac-1957-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:24:13.842: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-56a624ac-1957-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:24:13.869: INFO: Waiting for pod pod-56a624ac-1957-11e9-af83-025056002014 to disappear
Jan 16 06:24:13.873: INFO: Pod pod-56a624ac-1957-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:24:13.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q28r6" for this suite.
Jan 16 06:24:19.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:24:19.964: INFO: namespace: e2e-tests-emptydir-q28r6, resource: bindings, ignored listing per whitelist
Jan 16 06:24:19.994: INFO: namespace e2e-tests-emptydir-q28r6 deletion completed in 6.116934656s

• [SLOW TEST:8.383 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:24:19.995: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-lb4pq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lb4pq
Jan 16 06:24:24.205: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lb4pq
STEP: checking the pod's current state and verifying that restartCount is present
Jan 16 06:24:24.207: INFO: Initial restart count of pod liveness-http is 0
Jan 16 06:24:42.245: INFO: Restart count of pod e2e-tests-container-probe-lb4pq/liveness-http is now 1 (18.038016931s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:24:42.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lb4pq" for this suite.
Jan 16 06:24:48.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:24:48.357: INFO: namespace: e2e-tests-container-probe-lb4pq, resource: bindings, ignored listing per whitelist
Jan 16 06:24:48.373: INFO: namespace e2e-tests-container-probe-lb4pq deletion completed in 6.106244818s

• [SLOW TEST:28.378 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:24:48.373: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-r6tgt
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-6c8eab22-1957-11e9-af83-025056002014
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-6c8eab22-1957-11e9-af83-025056002014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:24:54.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r6tgt" for this suite.
Jan 16 06:25:16.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:25:16.683: INFO: namespace: e2e-tests-configmap-r6tgt, resource: bindings, ignored listing per whitelist
Jan 16 06:25:16.725: INFO: namespace e2e-tests-configmap-r6tgt deletion completed in 22.09858996s

• [SLOW TEST:28.352 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:25:16.727: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-lfr9l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 16 06:25:16.916: INFO: Waiting up to 5m0s for pod "downward-api-7d73b510-1957-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-lfr9l" to be "success or failure"
Jan 16 06:25:16.923: INFO: Pod "downward-api-7d73b510-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.067274ms
Jan 16 06:25:18.926: INFO: Pod "downward-api-7d73b510-1957-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009776503s
STEP: Saw pod success
Jan 16 06:25:18.926: INFO: Pod "downward-api-7d73b510-1957-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:25:18.929: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downward-api-7d73b510-1957-11e9-af83-025056002014 container dapi-container: <nil>
STEP: delete the pod
Jan 16 06:25:18.965: INFO: Waiting for pod downward-api-7d73b510-1957-11e9-af83-025056002014 to disappear
Jan 16 06:25:18.967: INFO: Pod downward-api-7d73b510-1957-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:25:18.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lfr9l" for this suite.
Jan 16 06:25:24.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:25:25.004: INFO: namespace: e2e-tests-downward-api-lfr9l, resource: bindings, ignored listing per whitelist
Jan 16 06:25:25.064: INFO: namespace e2e-tests-downward-api-lfr9l deletion completed in 6.092306624s

• [SLOW TEST:8.338 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:25:25.067: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-btqzq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-6zm65
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Jan 16 06:25:29.431: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-vgp6q
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:25:53.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-btqzq" for this suite.
Jan 16 06:25:59.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:25:59.622: INFO: namespace: e2e-tests-namespaces-btqzq, resource: bindings, ignored listing per whitelist
Jan 16 06:25:59.698: INFO: namespace e2e-tests-namespaces-btqzq deletion completed in 6.10379536s
STEP: Destroying namespace "e2e-tests-nsdeletetest-6zm65" for this suite.
Jan 16 06:25:59.701: INFO: Namespace e2e-tests-nsdeletetest-6zm65 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-vgp6q" for this suite.
Jan 16 06:26:05.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:26:05.746: INFO: namespace: e2e-tests-nsdeletetest-vgp6q, resource: bindings, ignored listing per whitelist
Jan 16 06:26:05.797: INFO: namespace e2e-tests-nsdeletetest-vgp6q deletion completed in 6.096445441s

• [SLOW TEST:40.730 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:26:05.799: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-dcws8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan 16 06:26:06.513: INFO: created pod pod-service-account-defaultsa
Jan 16 06:26:06.513: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 16 06:26:06.527: INFO: created pod pod-service-account-mountsa
Jan 16 06:26:06.528: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 16 06:26:06.534: INFO: created pod pod-service-account-nomountsa
Jan 16 06:26:06.534: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 16 06:26:06.555: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 16 06:26:06.555: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 16 06:26:06.582: INFO: created pod pod-service-account-mountsa-mountspec
Jan 16 06:26:06.582: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 16 06:26:06.595: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 16 06:26:06.595: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 16 06:26:06.601: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 16 06:26:06.601: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 16 06:26:06.615: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 16 06:26:06.615: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 16 06:26:06.624: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 16 06:26:06.624: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:26:06.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-dcws8" for this suite.
Jan 16 06:26:28.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:26:28.757: INFO: namespace: e2e-tests-svcaccounts-dcws8, resource: bindings, ignored listing per whitelist
Jan 16 06:26:28.764: INFO: namespace e2e-tests-svcaccounts-dcws8 deletion completed in 22.121989584s

• [SLOW TEST:22.965 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:26:28.765: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kq2tw
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-a86a3af6-1957-11e9-af83-025056002014
STEP: Creating configMap with name cm-test-opt-upd-a86a3b3b-1957-11e9-af83-025056002014
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a86a3af6-1957-11e9-af83-025056002014
STEP: Updating configmap cm-test-opt-upd-a86a3b3b-1957-11e9-af83-025056002014
STEP: Creating configMap with name cm-test-opt-create-a86a3b53-1957-11e9-af83-025056002014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:27:49.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kq2tw" for this suite.
Jan 16 06:28:11.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:28:11.592: INFO: namespace: e2e-tests-configmap-kq2tw, resource: bindings, ignored listing per whitelist
Jan 16 06:28:11.634: INFO: namespace e2e-tests-configmap-kq2tw deletion completed in 22.117006896s

• [SLOW TEST:102.869 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:28:11.635: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nb5kr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan 16 06:28:11.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 --namespace=e2e-tests-kubectl-nb5kr run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan 16 06:28:15.775: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan 16 06:28:15.775: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:28:30.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nb5kr" for this suite.
Jan 16 06:28:36.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:28:36.074: INFO: namespace: e2e-tests-kubectl-nb5kr, resource: bindings, ignored listing per whitelist
Jan 16 06:28:36.125: INFO: namespace e2e-tests-kubectl-nb5kr deletion completed in 6.103411974s

• [SLOW TEST:24.490 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:28:36.127: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-g4bcw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-g4bcw/configmap-test-f4512f15-1957-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 06:28:36.345: INFO: Waiting up to 5m0s for pod "pod-configmaps-f451b887-1957-11e9-af83-025056002014" in namespace "e2e-tests-configmap-g4bcw" to be "success or failure"
Jan 16 06:28:36.361: INFO: Pod "pod-configmaps-f451b887-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 16.598604ms
Jan 16 06:28:38.365: INFO: Pod "pod-configmaps-f451b887-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020439801s
Jan 16 06:28:40.369: INFO: Pod "pod-configmaps-f451b887-1957-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024047922s
STEP: Saw pod success
Jan 16 06:28:40.369: INFO: Pod "pod-configmaps-f451b887-1957-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:28:40.372: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-configmaps-f451b887-1957-11e9-af83-025056002014 container env-test: <nil>
STEP: delete the pod
Jan 16 06:28:40.398: INFO: Waiting for pod pod-configmaps-f451b887-1957-11e9-af83-025056002014 to disappear
Jan 16 06:28:40.401: INFO: Pod pod-configmaps-f451b887-1957-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:28:40.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g4bcw" for this suite.
Jan 16 06:28:46.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:28:46.484: INFO: namespace: e2e-tests-configmap-g4bcw, resource: bindings, ignored listing per whitelist
Jan 16 06:28:46.532: INFO: namespace e2e-tests-configmap-g4bcw deletion completed in 6.126359025s

• [SLOW TEST:10.405 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:28:46.533: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lhmzj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-fa849750-1957-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 06:28:46.755: INFO: Waiting up to 5m0s for pod "pod-configmaps-fa851552-1957-11e9-af83-025056002014" in namespace "e2e-tests-configmap-lhmzj" to be "success or failure"
Jan 16 06:28:46.759: INFO: Pod "pod-configmaps-fa851552-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.22229ms
Jan 16 06:28:48.763: INFO: Pod "pod-configmaps-fa851552-1957-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007814633s
Jan 16 06:28:50.767: INFO: Pod "pod-configmaps-fa851552-1957-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011906477s
STEP: Saw pod success
Jan 16 06:28:50.767: INFO: Pod "pod-configmaps-fa851552-1957-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:28:50.772: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-configmaps-fa851552-1957-11e9-af83-025056002014 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 06:28:50.792: INFO: Waiting for pod pod-configmaps-fa851552-1957-11e9-af83-025056002014 to disappear
Jan 16 06:28:50.797: INFO: Pod pod-configmaps-fa851552-1957-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:28:50.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lhmzj" for this suite.
Jan 16 06:28:56.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:28:56.888: INFO: namespace: e2e-tests-configmap-lhmzj, resource: bindings, ignored listing per whitelist
Jan 16 06:28:56.905: INFO: namespace e2e-tests-configmap-lhmzj deletion completed in 6.103954329s

• [SLOW TEST:10.372 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:28:56.905: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-rn45g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-rn45g
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rn45g to expose endpoints map[]
Jan 16 06:28:57.127: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rn45g exposes endpoints map[] (3.433015ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-rn45g
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rn45g to expose endpoints map[pod1:[100]]
Jan 16 06:28:59.161: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rn45g exposes endpoints map[pod1:[100]] (2.02285375s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-rn45g
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rn45g to expose endpoints map[pod1:[100] pod2:[101]]
Jan 16 06:29:02.231: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rn45g exposes endpoints map[pod1:[100] pod2:[101]] (3.064826926s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-rn45g
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rn45g to expose endpoints map[pod2:[101]]
Jan 16 06:29:02.250: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rn45g exposes endpoints map[pod2:[101]] (13.599698ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-rn45g
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rn45g to expose endpoints map[]
Jan 16 06:29:02.267: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rn45g exposes endpoints map[] (9.043845ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:29:02.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rn45g" for this suite.
Jan 16 06:29:24.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:29:24.326: INFO: namespace: e2e-tests-services-rn45g, resource: bindings, ignored listing per whitelist
Jan 16 06:29:24.396: INFO: namespace e2e-tests-services-rn45g deletion completed in 22.104597019s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:27.491 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:29:24.397: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vl4nn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 16 06:29:24.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-vl4nn'
Jan 16 06:29:24.697: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 16 06:29:24.697: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan 16 06:29:24.710: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jan 16 06:29:24.713: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan 16 06:29:24.723: INFO: scanned /root for discovery docs: <nil>
Jan 16 06:29:24.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-vl4nn'
Jan 16 06:29:40.511: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 16 06:29:40.512: INFO: stdout: "Created e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925\nScaling up e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan 16 06:29:40.512: INFO: stdout: "Created e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925\nScaling up e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan 16 06:29:40.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-vl4nn'
Jan 16 06:29:40.616: INFO: stderr: ""
Jan 16 06:29:40.616: INFO: stdout: "e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925-lt8pr e2e-test-nginx-rc-kpfbt "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Jan 16 06:29:45.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-vl4nn'
Jan 16 06:29:45.736: INFO: stderr: ""
Jan 16 06:29:45.736: INFO: stdout: "e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925-lt8pr "
Jan 16 06:29:45.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925-lt8pr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vl4nn'
Jan 16 06:29:45.844: INFO: stderr: ""
Jan 16 06:29:45.844: INFO: stdout: "true"
Jan 16 06:29:45.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925-lt8pr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vl4nn'
Jan 16 06:29:45.965: INFO: stderr: ""
Jan 16 06:29:45.965: INFO: stdout: "nginx:1.14-alpine"
Jan 16 06:29:45.965: INFO: e2e-test-nginx-rc-d61fa70fcd8e60cbeea575f977a7d925-lt8pr is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Jan 16 06:29:45.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-vl4nn'
Jan 16 06:29:46.078: INFO: stderr: ""
Jan 16 06:29:46.078: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:29:46.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vl4nn" for this suite.
Jan 16 06:30:08.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:30:08.220: INFO: namespace: e2e-tests-kubectl-vl4nn, resource: bindings, ignored listing per whitelist
Jan 16 06:30:08.290: INFO: namespace e2e-tests-kubectl-vl4nn deletion completed in 22.206955199s

• [SLOW TEST:43.893 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:30:08.291: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-x79zx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 16 06:30:08.515: INFO: Waiting up to 5m0s for pod "pod-2b41bfe8-1958-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-x79zx" to be "success or failure"
Jan 16 06:30:08.518: INFO: Pod "pod-2b41bfe8-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.924831ms
Jan 16 06:30:10.522: INFO: Pod "pod-2b41bfe8-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007066822s
Jan 16 06:30:12.526: INFO: Pod "pod-2b41bfe8-1958-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011307372s
STEP: Saw pod success
Jan 16 06:30:12.526: INFO: Pod "pod-2b41bfe8-1958-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:30:12.529: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-2b41bfe8-1958-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:30:12.551: INFO: Waiting for pod pod-2b41bfe8-1958-11e9-af83-025056002014 to disappear
Jan 16 06:30:12.557: INFO: Pod pod-2b41bfe8-1958-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:30:12.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x79zx" for this suite.
Jan 16 06:30:18.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:30:18.645: INFO: namespace: e2e-tests-emptydir-x79zx, resource: bindings, ignored listing per whitelist
Jan 16 06:30:18.660: INFO: namespace e2e-tests-emptydir-x79zx deletion completed in 6.098190796s

• [SLOW TEST:10.370 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:30:18.662: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9s6z8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 16 06:30:23.387: INFO: Successfully updated pod "annotationupdate316b9939-1958-11e9-af83-025056002014"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:30:25.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9s6z8" for this suite.
Jan 16 06:30:47.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:30:47.449: INFO: namespace: e2e-tests-projected-9s6z8, resource: bindings, ignored listing per whitelist
Jan 16 06:30:47.517: INFO: namespace e2e-tests-projected-9s6z8 deletion completed in 22.101406418s

• [SLOW TEST:28.855 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:30:47.517: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-469s2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-tj6f
STEP: Creating a pod to test atomic-volume-subpath
Jan 16 06:30:47.733: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-tj6f" in namespace "e2e-tests-subpath-469s2" to be "success or failure"
Jan 16 06:30:47.746: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.710001ms
Jan 16 06:30:49.749: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016501874s
Jan 16 06:30:51.753: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Running", Reason="", readiness=false. Elapsed: 4.02050664s
Jan 16 06:30:53.757: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Running", Reason="", readiness=false. Elapsed: 6.024399261s
Jan 16 06:30:55.762: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Running", Reason="", readiness=false. Elapsed: 8.029325744s
Jan 16 06:30:57.766: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Running", Reason="", readiness=false. Elapsed: 10.033491709s
Jan 16 06:30:59.770: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Running", Reason="", readiness=false. Elapsed: 12.03705832s
Jan 16 06:31:01.774: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Running", Reason="", readiness=false. Elapsed: 14.040921374s
Jan 16 06:31:03.777: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Running", Reason="", readiness=false. Elapsed: 16.044652039s
Jan 16 06:31:05.781: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Running", Reason="", readiness=false. Elapsed: 18.048323428s
Jan 16 06:31:07.786: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Running", Reason="", readiness=false. Elapsed: 20.05277294s
Jan 16 06:31:09.789: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Running", Reason="", readiness=false. Elapsed: 22.056622851s
Jan 16 06:31:11.794: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Running", Reason="", readiness=false. Elapsed: 24.060882165s
Jan 16 06:31:13.797: INFO: Pod "pod-subpath-test-configmap-tj6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.064557853s
STEP: Saw pod success
Jan 16 06:31:13.798: INFO: Pod "pod-subpath-test-configmap-tj6f" satisfied condition "success or failure"
Jan 16 06:31:13.800: INFO: Trying to get logs from node 1f5a976a-5eac-4984-8510-5241ae82643f pod pod-subpath-test-configmap-tj6f container test-container-subpath-configmap-tj6f: <nil>
STEP: delete the pod
Jan 16 06:31:13.825: INFO: Waiting for pod pod-subpath-test-configmap-tj6f to disappear
Jan 16 06:31:13.833: INFO: Pod pod-subpath-test-configmap-tj6f no longer exists
STEP: Deleting pod pod-subpath-test-configmap-tj6f
Jan 16 06:31:13.833: INFO: Deleting pod "pod-subpath-test-configmap-tj6f" in namespace "e2e-tests-subpath-469s2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:31:13.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-469s2" for this suite.
Jan 16 06:31:19.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:31:19.878: INFO: namespace: e2e-tests-subpath-469s2, resource: bindings, ignored listing per whitelist
Jan 16 06:31:19.943: INFO: namespace e2e-tests-subpath-469s2 deletion completed in 6.102542343s

• [SLOW TEST:32.426 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:31:19.946: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-85rsj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan 16 06:31:24.164: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-55f36f4f-1958-11e9-af83-025056002014", GenerateName:"", Namespace:"e2e-tests-pods-85rsj", SelfLink:"/api/v1/namespaces/e2e-tests-pods-85rsj/pods/pod-submit-remove-55f36f4f-1958-11e9-af83-025056002014", UID:"55f48c9b-1958-11e9-ba24-0050568f491d", ResourceVersion:"16358", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683217080, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"134439678"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-sjbsr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422c8a040), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-sjbsr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421e6bd18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"d02c56a1-5f5a-4edd-b080-4296aa47afb8", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421fca240), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421e6bd50)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421e6bd70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421e6bd78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217080, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217083, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217083, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217080, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"30.0.3.3", PodIP:"40.0.5.2", StartTime:(*v1.Time)(0xc422cc6020), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc422cc6040), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://82df644a073d932682b687c4376536f3ed3e201c5451de51500631adb060388f"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:31:32.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-85rsj" for this suite.
Jan 16 06:31:38.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:31:38.287: INFO: namespace: e2e-tests-pods-85rsj, resource: bindings, ignored listing per whitelist
Jan 16 06:31:38.317: INFO: namespace e2e-tests-pods-85rsj deletion completed in 6.115477562s

• [SLOW TEST:18.371 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:31:38.322: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-9nbf8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-9nbf8
I0116 06:31:38.544457      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-9nbf8, replica count: 1
I0116 06:31:39.595032      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0116 06:31:40.595303      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0116 06:31:41.595626      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0116 06:31:42.595842      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 16 06:31:42.703: INFO: Created: latency-svc-6jsz2
Jan 16 06:31:42.726: INFO: Got endpoints: latency-svc-6jsz2 [30.544771ms]
Jan 16 06:31:42.742: INFO: Created: latency-svc-fw4tp
Jan 16 06:31:42.748: INFO: Created: latency-svc-jzhvl
Jan 16 06:31:42.751: INFO: Created: latency-svc-g8c2b
Jan 16 06:31:42.758: INFO: Got endpoints: latency-svc-fw4tp [31.67981ms]
Jan 16 06:31:42.767: INFO: Got endpoints: latency-svc-g8c2b [40.15216ms]
Jan 16 06:31:42.767: INFO: Got endpoints: latency-svc-jzhvl [40.644381ms]
Jan 16 06:31:42.774: INFO: Created: latency-svc-2xrhw
Jan 16 06:31:42.782: INFO: Created: latency-svc-t8grz
Jan 16 06:31:42.782: INFO: Created: latency-svc-vpxg7
Jan 16 06:31:42.786: INFO: Got endpoints: latency-svc-2xrhw [59.380751ms]
Jan 16 06:31:42.793: INFO: Created: latency-svc-9q4lm
Jan 16 06:31:42.797: INFO: Got endpoints: latency-svc-t8grz [70.267152ms]
Jan 16 06:31:42.798: INFO: Got endpoints: latency-svc-vpxg7 [70.871034ms]
Jan 16 06:31:42.806: INFO: Got endpoints: latency-svc-9q4lm [78.527402ms]
Jan 16 06:31:42.810: INFO: Created: latency-svc-f77gr
Jan 16 06:31:42.815: INFO: Got endpoints: latency-svc-f77gr [87.505923ms]
Jan 16 06:31:42.821: INFO: Created: latency-svc-m6jvz
Jan 16 06:31:42.826: INFO: Got endpoints: latency-svc-m6jvz [99.005975ms]
Jan 16 06:31:42.831: INFO: Created: latency-svc-fbq4x
Jan 16 06:31:42.835: INFO: Got endpoints: latency-svc-fbq4x [107.594124ms]
Jan 16 06:31:42.845: INFO: Created: latency-svc-6l88x
Jan 16 06:31:42.848: INFO: Got endpoints: latency-svc-6l88x [120.629779ms]
Jan 16 06:31:42.861: INFO: Created: latency-svc-j6nb4
Jan 16 06:31:42.872: INFO: Got endpoints: latency-svc-j6nb4 [143.98046ms]
Jan 16 06:31:42.874: INFO: Created: latency-svc-s5bn6
Jan 16 06:31:42.885: INFO: Got endpoints: latency-svc-s5bn6 [157.695907ms]
Jan 16 06:31:42.888: INFO: Created: latency-svc-nmzcz
Jan 16 06:31:42.893: INFO: Got endpoints: latency-svc-nmzcz [165.205312ms]
Jan 16 06:31:42.916: INFO: Created: latency-svc-smtcj
Jan 16 06:31:42.917: INFO: Created: latency-svc-ppzzt
Jan 16 06:31:42.917: INFO: Created: latency-svc-vhz7b
Jan 16 06:31:42.923: INFO: Got endpoints: latency-svc-smtcj [195.563268ms]
Jan 16 06:31:42.924: INFO: Created: latency-svc-bjvdf
Jan 16 06:31:42.938: INFO: Got endpoints: latency-svc-bjvdf [170.283187ms]
Jan 16 06:31:42.938: INFO: Got endpoints: latency-svc-vhz7b [170.981476ms]
Jan 16 06:31:42.938: INFO: Got endpoints: latency-svc-ppzzt [180.060692ms]
Jan 16 06:31:42.952: INFO: Created: latency-svc-wrdvj
Jan 16 06:31:42.955: INFO: Created: latency-svc-lq2bw
Jan 16 06:31:42.963: INFO: Got endpoints: latency-svc-lq2bw [25.498767ms]
Jan 16 06:31:42.965: INFO: Got endpoints: latency-svc-wrdvj [178.966476ms]
Jan 16 06:31:42.972: INFO: Created: latency-svc-2qwwn
Jan 16 06:31:42.988: INFO: Created: latency-svc-9mnkf
Jan 16 06:31:42.989: INFO: Got endpoints: latency-svc-2qwwn [50.407395ms]
Jan 16 06:31:42.997: INFO: Created: latency-svc-589wb
Jan 16 06:31:42.998: INFO: Got endpoints: latency-svc-589wb [200.149687ms]
Jan 16 06:31:43.020: INFO: Created: latency-svc-g6wjz
Jan 16 06:31:43.020: INFO: Got endpoints: latency-svc-9mnkf [214.391262ms]
Jan 16 06:31:43.024: INFO: Created: latency-svc-gs9gm
Jan 16 06:31:43.033: INFO: Created: latency-svc-xz6wp
Jan 16 06:31:43.035: INFO: Got endpoints: latency-svc-g6wjz [220.205311ms]
Jan 16 06:31:43.040: INFO: Got endpoints: latency-svc-xz6wp [204.500894ms]
Jan 16 06:31:43.040: INFO: Got endpoints: latency-svc-gs9gm [213.490715ms]
Jan 16 06:31:43.045: INFO: Created: latency-svc-nxs6h
Jan 16 06:31:43.047: INFO: Got endpoints: latency-svc-nxs6h [198.908107ms]
Jan 16 06:31:43.057: INFO: Created: latency-svc-v4zkl
Jan 16 06:31:43.059: INFO: Got endpoints: latency-svc-v4zkl [187.601922ms]
Jan 16 06:31:43.062: INFO: Created: latency-svc-bwd67
Jan 16 06:31:43.075: INFO: Got endpoints: latency-svc-bwd67 [189.379819ms]
Jan 16 06:31:43.077: INFO: Created: latency-svc-tbx62
Jan 16 06:31:43.087: INFO: Got endpoints: latency-svc-tbx62 [194.270165ms]
Jan 16 06:31:43.090: INFO: Created: latency-svc-kkp9q
Jan 16 06:31:43.096: INFO: Got endpoints: latency-svc-kkp9q [172.88951ms]
Jan 16 06:31:43.104: INFO: Created: latency-svc-rg98g
Jan 16 06:31:43.108: INFO: Created: latency-svc-gs78n
Jan 16 06:31:43.111: INFO: Created: latency-svc-f9p4f
Jan 16 06:31:43.115: INFO: Got endpoints: latency-svc-rg98g [317.33898ms]
Jan 16 06:31:43.115: INFO: Got endpoints: latency-svc-f9p4f [151.506867ms]
Jan 16 06:31:43.125: INFO: Got endpoints: latency-svc-gs78n [186.941201ms]
Jan 16 06:31:43.129: INFO: Created: latency-svc-bqdwb
Jan 16 06:31:43.137: INFO: Got endpoints: latency-svc-bqdwb [171.45375ms]
Jan 16 06:31:43.144: INFO: Created: latency-svc-7qv7v
Jan 16 06:31:43.144: INFO: Got endpoints: latency-svc-7qv7v [155.183825ms]
Jan 16 06:31:43.148: INFO: Created: latency-svc-g45qm
Jan 16 06:31:43.157: INFO: Created: latency-svc-ll2sq
Jan 16 06:31:43.158: INFO: Got endpoints: latency-svc-g45qm [159.440189ms]
Jan 16 06:31:43.171: INFO: Created: latency-svc-b994g
Jan 16 06:31:43.173: INFO: Got endpoints: latency-svc-ll2sq [153.111093ms]
Jan 16 06:31:43.181: INFO: Created: latency-svc-zw4n7
Jan 16 06:31:43.184: INFO: Created: latency-svc-vx6gp
Jan 16 06:31:43.201: INFO: Created: latency-svc-gqk7p
Jan 16 06:31:43.219: INFO: Got endpoints: latency-svc-b994g [184.189671ms]
Jan 16 06:31:43.220: INFO: Created: latency-svc-m9xgw
Jan 16 06:31:43.220: INFO: Created: latency-svc-c8lrw
Jan 16 06:31:43.236: INFO: Created: latency-svc-rh8pp
Jan 16 06:31:43.245: INFO: Created: latency-svc-hr7gt
Jan 16 06:31:43.250: INFO: Created: latency-svc-tsscb
Jan 16 06:31:43.250: INFO: Created: latency-svc-c6fxt
Jan 16 06:31:43.250: INFO: Created: latency-svc-kl6bf
Jan 16 06:31:43.259: INFO: Created: latency-svc-8mg9d
Jan 16 06:31:43.262: INFO: Got endpoints: latency-svc-zw4n7 [222.295985ms]
Jan 16 06:31:43.267: INFO: Created: latency-svc-t9vvd
Jan 16 06:31:43.278: INFO: Created: latency-svc-rxt8g
Jan 16 06:31:43.294: INFO: Created: latency-svc-mhmz4
Jan 16 06:31:43.305: INFO: Created: latency-svc-qnhqb
Jan 16 06:31:43.311: INFO: Got endpoints: latency-svc-vx6gp [270.578794ms]
Jan 16 06:31:43.325: INFO: Created: latency-svc-h8gvr
Jan 16 06:31:43.325: INFO: Created: latency-svc-vjvqs
Jan 16 06:31:43.364: INFO: Got endpoints: latency-svc-gqk7p [316.787417ms]
Jan 16 06:31:43.375: INFO: Created: latency-svc-zszhg
Jan 16 06:31:43.408: INFO: Got endpoints: latency-svc-m9xgw [349.005961ms]
Jan 16 06:31:43.433: INFO: Created: latency-svc-pjhqt
Jan 16 06:31:43.459: INFO: Got endpoints: latency-svc-c8lrw [384.510501ms]
Jan 16 06:31:43.465: INFO: Created: latency-svc-qv7z7
Jan 16 06:31:43.508: INFO: Got endpoints: latency-svc-rh8pp [420.133819ms]
Jan 16 06:31:43.521: INFO: Created: latency-svc-2dv8f
Jan 16 06:31:43.559: INFO: Got endpoints: latency-svc-hr7gt [462.926577ms]
Jan 16 06:31:43.565: INFO: Created: latency-svc-7cth4
Jan 16 06:31:43.609: INFO: Got endpoints: latency-svc-kl6bf [493.707648ms]
Jan 16 06:31:43.622: INFO: Created: latency-svc-zxjxm
Jan 16 06:31:43.659: INFO: Got endpoints: latency-svc-c6fxt [544.464054ms]
Jan 16 06:31:43.669: INFO: Created: latency-svc-qrvvm
Jan 16 06:31:43.711: INFO: Got endpoints: latency-svc-tsscb [585.838196ms]
Jan 16 06:31:43.719: INFO: Created: latency-svc-nrkmj
Jan 16 06:31:43.759: INFO: Got endpoints: latency-svc-8mg9d [621.625608ms]
Jan 16 06:31:43.765: INFO: Created: latency-svc-9wp9t
Jan 16 06:31:43.809: INFO: Got endpoints: latency-svc-t9vvd [664.495191ms]
Jan 16 06:31:43.818: INFO: Created: latency-svc-2tdnd
Jan 16 06:31:43.858: INFO: Got endpoints: latency-svc-rxt8g [700.836736ms]
Jan 16 06:31:43.866: INFO: Created: latency-svc-zkv6l
Jan 16 06:31:43.910: INFO: Got endpoints: latency-svc-mhmz4 [736.66082ms]
Jan 16 06:31:43.917: INFO: Created: latency-svc-xxvtr
Jan 16 06:31:43.960: INFO: Got endpoints: latency-svc-qnhqb [740.172854ms]
Jan 16 06:31:43.968: INFO: Created: latency-svc-rbtl9
Jan 16 06:31:44.009: INFO: Got endpoints: latency-svc-vjvqs [746.63969ms]
Jan 16 06:31:44.018: INFO: Created: latency-svc-hbplx
Jan 16 06:31:44.060: INFO: Got endpoints: latency-svc-h8gvr [749.060817ms]
Jan 16 06:31:44.072: INFO: Created: latency-svc-tg6gh
Jan 16 06:31:44.113: INFO: Got endpoints: latency-svc-zszhg [749.216493ms]
Jan 16 06:31:44.128: INFO: Created: latency-svc-gdkzs
Jan 16 06:31:44.161: INFO: Got endpoints: latency-svc-pjhqt [752.789122ms]
Jan 16 06:31:44.173: INFO: Created: latency-svc-v89dn
Jan 16 06:31:44.210: INFO: Got endpoints: latency-svc-qv7z7 [750.50845ms]
Jan 16 06:31:44.217: INFO: Created: latency-svc-pfn9q
Jan 16 06:31:44.260: INFO: Got endpoints: latency-svc-2dv8f [752.64421ms]
Jan 16 06:31:44.268: INFO: Created: latency-svc-hxr5l
Jan 16 06:31:44.307: INFO: Got endpoints: latency-svc-7cth4 [747.914887ms]
Jan 16 06:31:44.316: INFO: Created: latency-svc-hc47w
Jan 16 06:31:44.360: INFO: Got endpoints: latency-svc-zxjxm [751.307012ms]
Jan 16 06:31:44.369: INFO: Created: latency-svc-xswwq
Jan 16 06:31:44.409: INFO: Got endpoints: latency-svc-qrvvm [749.107225ms]
Jan 16 06:31:44.418: INFO: Created: latency-svc-9fgkk
Jan 16 06:31:44.463: INFO: Got endpoints: latency-svc-nrkmj [752.236569ms]
Jan 16 06:31:44.471: INFO: Created: latency-svc-vvqls
Jan 16 06:31:44.512: INFO: Got endpoints: latency-svc-9wp9t [753.306722ms]
Jan 16 06:31:44.521: INFO: Created: latency-svc-474md
Jan 16 06:31:44.560: INFO: Got endpoints: latency-svc-2tdnd [749.862432ms]
Jan 16 06:31:44.567: INFO: Created: latency-svc-sf89z
Jan 16 06:31:44.609: INFO: Got endpoints: latency-svc-zkv6l [750.644538ms]
Jan 16 06:31:44.627: INFO: Created: latency-svc-gb84z
Jan 16 06:31:44.660: INFO: Got endpoints: latency-svc-xxvtr [749.512517ms]
Jan 16 06:31:44.668: INFO: Created: latency-svc-pz4kg
Jan 16 06:31:44.708: INFO: Got endpoints: latency-svc-rbtl9 [746.782665ms]
Jan 16 06:31:44.718: INFO: Created: latency-svc-hd879
Jan 16 06:31:44.761: INFO: Got endpoints: latency-svc-hbplx [751.511359ms]
Jan 16 06:31:44.770: INFO: Created: latency-svc-ltk8p
Jan 16 06:31:44.811: INFO: Got endpoints: latency-svc-tg6gh [751.124113ms]
Jan 16 06:31:44.824: INFO: Created: latency-svc-bq92f
Jan 16 06:31:44.859: INFO: Got endpoints: latency-svc-gdkzs [745.266827ms]
Jan 16 06:31:44.867: INFO: Created: latency-svc-bt9hr
Jan 16 06:31:44.908: INFO: Got endpoints: latency-svc-v89dn [746.750068ms]
Jan 16 06:31:44.916: INFO: Created: latency-svc-xkhbb
Jan 16 06:31:44.959: INFO: Got endpoints: latency-svc-pfn9q [748.519549ms]
Jan 16 06:31:44.967: INFO: Created: latency-svc-lxrql
Jan 16 06:31:45.013: INFO: Got endpoints: latency-svc-hxr5l [753.168949ms]
Jan 16 06:31:45.029: INFO: Created: latency-svc-jhrt6
Jan 16 06:31:45.073: INFO: Got endpoints: latency-svc-hc47w [765.955744ms]
Jan 16 06:31:45.079: INFO: Created: latency-svc-5gnb6
Jan 16 06:31:45.112: INFO: Got endpoints: latency-svc-xswwq [752.012934ms]
Jan 16 06:31:45.124: INFO: Created: latency-svc-ddxjm
Jan 16 06:31:45.159: INFO: Got endpoints: latency-svc-9fgkk [749.6388ms]
Jan 16 06:31:45.168: INFO: Created: latency-svc-d652r
Jan 16 06:31:45.208: INFO: Got endpoints: latency-svc-vvqls [744.239631ms]
Jan 16 06:31:45.221: INFO: Created: latency-svc-5tmqb
Jan 16 06:31:45.260: INFO: Got endpoints: latency-svc-474md [747.946809ms]
Jan 16 06:31:45.270: INFO: Created: latency-svc-hktcb
Jan 16 06:31:45.315: INFO: Got endpoints: latency-svc-sf89z [754.942491ms]
Jan 16 06:31:45.327: INFO: Created: latency-svc-c2drw
Jan 16 06:31:45.360: INFO: Got endpoints: latency-svc-gb84z [750.415601ms]
Jan 16 06:31:45.369: INFO: Created: latency-svc-tf998
Jan 16 06:31:45.411: INFO: Got endpoints: latency-svc-pz4kg [750.810432ms]
Jan 16 06:31:45.418: INFO: Created: latency-svc-l6wfp
Jan 16 06:31:45.470: INFO: Got endpoints: latency-svc-hd879 [761.311954ms]
Jan 16 06:31:45.479: INFO: Created: latency-svc-79t4j
Jan 16 06:31:45.510: INFO: Got endpoints: latency-svc-ltk8p [748.791097ms]
Jan 16 06:31:45.520: INFO: Created: latency-svc-kl2fd
Jan 16 06:31:45.562: INFO: Got endpoints: latency-svc-bq92f [750.706483ms]
Jan 16 06:31:45.570: INFO: Created: latency-svc-cbglk
Jan 16 06:31:45.612: INFO: Got endpoints: latency-svc-bt9hr [753.141558ms]
Jan 16 06:31:45.626: INFO: Created: latency-svc-wtjsv
Jan 16 06:31:45.661: INFO: Got endpoints: latency-svc-xkhbb [752.227654ms]
Jan 16 06:31:45.672: INFO: Created: latency-svc-8jdfp
Jan 16 06:31:45.708: INFO: Got endpoints: latency-svc-lxrql [748.738099ms]
Jan 16 06:31:45.716: INFO: Created: latency-svc-wvwbz
Jan 16 06:31:45.759: INFO: Got endpoints: latency-svc-jhrt6 [745.663429ms]
Jan 16 06:31:45.770: INFO: Created: latency-svc-sr8rq
Jan 16 06:31:45.808: INFO: Got endpoints: latency-svc-5gnb6 [735.218366ms]
Jan 16 06:31:45.822: INFO: Created: latency-svc-s5ghf
Jan 16 06:31:45.863: INFO: Got endpoints: latency-svc-ddxjm [750.508152ms]
Jan 16 06:31:45.869: INFO: Created: latency-svc-8jlxw
Jan 16 06:31:45.911: INFO: Got endpoints: latency-svc-d652r [752.185578ms]
Jan 16 06:31:45.917: INFO: Created: latency-svc-jn4lk
Jan 16 06:31:45.965: INFO: Got endpoints: latency-svc-5tmqb [756.863992ms]
Jan 16 06:31:45.970: INFO: Created: latency-svc-wz5cb
Jan 16 06:31:46.008: INFO: Got endpoints: latency-svc-hktcb [748.115514ms]
Jan 16 06:31:46.016: INFO: Created: latency-svc-5zw5p
Jan 16 06:31:46.060: INFO: Got endpoints: latency-svc-c2drw [742.456846ms]
Jan 16 06:31:46.074: INFO: Created: latency-svc-qk87j
Jan 16 06:31:46.114: INFO: Got endpoints: latency-svc-tf998 [753.652435ms]
Jan 16 06:31:46.126: INFO: Created: latency-svc-2jwr2
Jan 16 06:31:46.160: INFO: Got endpoints: latency-svc-l6wfp [748.467953ms]
Jan 16 06:31:46.174: INFO: Created: latency-svc-zwjgd
Jan 16 06:31:46.208: INFO: Got endpoints: latency-svc-79t4j [738.711733ms]
Jan 16 06:31:46.221: INFO: Created: latency-svc-g5mkh
Jan 16 06:31:46.259: INFO: Got endpoints: latency-svc-kl2fd [748.744264ms]
Jan 16 06:31:46.266: INFO: Created: latency-svc-s8t27
Jan 16 06:31:46.310: INFO: Got endpoints: latency-svc-cbglk [748.154687ms]
Jan 16 06:31:46.317: INFO: Created: latency-svc-v82mk
Jan 16 06:31:46.359: INFO: Got endpoints: latency-svc-wtjsv [747.617327ms]
Jan 16 06:31:46.374: INFO: Created: latency-svc-jwqzk
Jan 16 06:31:46.409: INFO: Got endpoints: latency-svc-8jdfp [748.531914ms]
Jan 16 06:31:46.429: INFO: Created: latency-svc-pg8vq
Jan 16 06:31:46.461: INFO: Got endpoints: latency-svc-wvwbz [752.875857ms]
Jan 16 06:31:46.469: INFO: Created: latency-svc-vxbdt
Jan 16 06:31:46.507: INFO: Got endpoints: latency-svc-sr8rq [748.197542ms]
Jan 16 06:31:46.520: INFO: Created: latency-svc-9kp2k
Jan 16 06:31:46.561: INFO: Got endpoints: latency-svc-s5ghf [752.513701ms]
Jan 16 06:31:46.569: INFO: Created: latency-svc-h2l6q
Jan 16 06:31:46.609: INFO: Got endpoints: latency-svc-8jlxw [745.76558ms]
Jan 16 06:31:46.618: INFO: Created: latency-svc-mp685
Jan 16 06:31:46.664: INFO: Got endpoints: latency-svc-jn4lk [752.419483ms]
Jan 16 06:31:46.674: INFO: Created: latency-svc-wfhrp
Jan 16 06:31:46.712: INFO: Got endpoints: latency-svc-wz5cb [747.150144ms]
Jan 16 06:31:46.718: INFO: Created: latency-svc-lrzwd
Jan 16 06:31:46.761: INFO: Got endpoints: latency-svc-5zw5p [752.288354ms]
Jan 16 06:31:46.768: INFO: Created: latency-svc-86qtw
Jan 16 06:31:46.812: INFO: Got endpoints: latency-svc-qk87j [751.913993ms]
Jan 16 06:31:46.827: INFO: Created: latency-svc-s6tn5
Jan 16 06:31:46.864: INFO: Got endpoints: latency-svc-2jwr2 [750.373449ms]
Jan 16 06:31:46.878: INFO: Created: latency-svc-hvvjr
Jan 16 06:31:46.908: INFO: Got endpoints: latency-svc-zwjgd [748.104957ms]
Jan 16 06:31:46.916: INFO: Created: latency-svc-5g6d8
Jan 16 06:31:46.958: INFO: Got endpoints: latency-svc-g5mkh [749.899045ms]
Jan 16 06:31:46.967: INFO: Created: latency-svc-9gl2w
Jan 16 06:31:47.009: INFO: Got endpoints: latency-svc-s8t27 [750.592024ms]
Jan 16 06:31:47.020: INFO: Created: latency-svc-7bffg
Jan 16 06:31:47.061: INFO: Got endpoints: latency-svc-v82mk [751.38982ms]
Jan 16 06:31:47.070: INFO: Created: latency-svc-rnnfn
Jan 16 06:31:47.113: INFO: Got endpoints: latency-svc-jwqzk [753.562521ms]
Jan 16 06:31:47.120: INFO: Created: latency-svc-8qkwz
Jan 16 06:31:47.159: INFO: Got endpoints: latency-svc-pg8vq [750.199891ms]
Jan 16 06:31:47.173: INFO: Created: latency-svc-xsn52
Jan 16 06:31:47.211: INFO: Got endpoints: latency-svc-vxbdt [749.971514ms]
Jan 16 06:31:47.227: INFO: Created: latency-svc-d2k8k
Jan 16 06:31:47.259: INFO: Got endpoints: latency-svc-9kp2k [751.389597ms]
Jan 16 06:31:47.275: INFO: Created: latency-svc-qbc67
Jan 16 06:31:47.307: INFO: Got endpoints: latency-svc-h2l6q [746.146097ms]
Jan 16 06:31:47.317: INFO: Created: latency-svc-nnbfk
Jan 16 06:31:47.359: INFO: Got endpoints: latency-svc-mp685 [750.599036ms]
Jan 16 06:31:47.369: INFO: Created: latency-svc-n7lfx
Jan 16 06:31:47.410: INFO: Got endpoints: latency-svc-wfhrp [746.364092ms]
Jan 16 06:31:47.418: INFO: Created: latency-svc-48h2m
Jan 16 06:31:47.460: INFO: Got endpoints: latency-svc-lrzwd [747.807841ms]
Jan 16 06:31:47.468: INFO: Created: latency-svc-grkwv
Jan 16 06:31:47.511: INFO: Got endpoints: latency-svc-86qtw [750.923034ms]
Jan 16 06:31:47.518: INFO: Created: latency-svc-vdbtw
Jan 16 06:31:47.559: INFO: Got endpoints: latency-svc-s6tn5 [747.308062ms]
Jan 16 06:31:47.568: INFO: Created: latency-svc-sntgc
Jan 16 06:31:47.609: INFO: Got endpoints: latency-svc-hvvjr [744.530828ms]
Jan 16 06:31:47.619: INFO: Created: latency-svc-2l477
Jan 16 06:31:47.661: INFO: Got endpoints: latency-svc-5g6d8 [752.962886ms]
Jan 16 06:31:47.669: INFO: Created: latency-svc-mz7vf
Jan 16 06:31:47.708: INFO: Got endpoints: latency-svc-9gl2w [749.229315ms]
Jan 16 06:31:47.722: INFO: Created: latency-svc-wkc52
Jan 16 06:31:47.760: INFO: Got endpoints: latency-svc-7bffg [750.764901ms]
Jan 16 06:31:47.767: INFO: Created: latency-svc-b7ssg
Jan 16 06:31:47.810: INFO: Got endpoints: latency-svc-rnnfn [748.890982ms]
Jan 16 06:31:47.819: INFO: Created: latency-svc-d8brq
Jan 16 06:31:47.859: INFO: Got endpoints: latency-svc-8qkwz [745.606474ms]
Jan 16 06:31:47.877: INFO: Created: latency-svc-96ffp
Jan 16 06:31:47.911: INFO: Got endpoints: latency-svc-xsn52 [750.952799ms]
Jan 16 06:31:47.920: INFO: Created: latency-svc-q768d
Jan 16 06:31:47.959: INFO: Got endpoints: latency-svc-d2k8k [747.725614ms]
Jan 16 06:31:47.967: INFO: Created: latency-svc-dl49q
Jan 16 06:31:48.008: INFO: Got endpoints: latency-svc-qbc67 [749.21588ms]
Jan 16 06:31:48.020: INFO: Created: latency-svc-6bv9n
Jan 16 06:31:48.061: INFO: Got endpoints: latency-svc-nnbfk [753.516143ms]
Jan 16 06:31:48.069: INFO: Created: latency-svc-9nmmd
Jan 16 06:31:48.109: INFO: Got endpoints: latency-svc-n7lfx [749.121073ms]
Jan 16 06:31:48.115: INFO: Created: latency-svc-t47kc
Jan 16 06:31:48.160: INFO: Got endpoints: latency-svc-48h2m [749.505647ms]
Jan 16 06:31:48.167: INFO: Created: latency-svc-2nczn
Jan 16 06:31:48.209: INFO: Got endpoints: latency-svc-grkwv [749.12393ms]
Jan 16 06:31:48.221: INFO: Created: latency-svc-g26lp
Jan 16 06:31:48.260: INFO: Got endpoints: latency-svc-vdbtw [748.565313ms]
Jan 16 06:31:48.274: INFO: Created: latency-svc-x6vzh
Jan 16 06:31:48.309: INFO: Got endpoints: latency-svc-sntgc [750.245185ms]
Jan 16 06:31:48.322: INFO: Created: latency-svc-wh8kt
Jan 16 06:31:48.358: INFO: Got endpoints: latency-svc-2l477 [749.571122ms]
Jan 16 06:31:48.373: INFO: Created: latency-svc-kc8nm
Jan 16 06:31:48.412: INFO: Got endpoints: latency-svc-mz7vf [750.775768ms]
Jan 16 06:31:48.441: INFO: Created: latency-svc-tbxv9
Jan 16 06:31:48.460: INFO: Got endpoints: latency-svc-wkc52 [752.184259ms]
Jan 16 06:31:48.466: INFO: Created: latency-svc-9pjt7
Jan 16 06:31:48.509: INFO: Got endpoints: latency-svc-b7ssg [749.101994ms]
Jan 16 06:31:48.515: INFO: Created: latency-svc-6fxj6
Jan 16 06:31:48.560: INFO: Got endpoints: latency-svc-d8brq [749.761787ms]
Jan 16 06:31:48.567: INFO: Created: latency-svc-r4p7c
Jan 16 06:31:48.609: INFO: Got endpoints: latency-svc-96ffp [749.918712ms]
Jan 16 06:31:48.616: INFO: Created: latency-svc-hpvkr
Jan 16 06:31:48.660: INFO: Got endpoints: latency-svc-q768d [749.225105ms]
Jan 16 06:31:48.675: INFO: Created: latency-svc-cfx6z
Jan 16 06:31:48.710: INFO: Got endpoints: latency-svc-dl49q [751.112314ms]
Jan 16 06:31:48.727: INFO: Created: latency-svc-hnjk8
Jan 16 06:31:48.761: INFO: Got endpoints: latency-svc-6bv9n [752.95159ms]
Jan 16 06:31:48.768: INFO: Created: latency-svc-qnw6g
Jan 16 06:31:48.811: INFO: Got endpoints: latency-svc-9nmmd [750.199208ms]
Jan 16 06:31:48.823: INFO: Created: latency-svc-nmc84
Jan 16 06:31:48.860: INFO: Got endpoints: latency-svc-t47kc [751.02568ms]
Jan 16 06:31:48.866: INFO: Created: latency-svc-kchx2
Jan 16 06:31:48.908: INFO: Got endpoints: latency-svc-2nczn [748.437428ms]
Jan 16 06:31:48.916: INFO: Created: latency-svc-tcrbw
Jan 16 06:31:48.962: INFO: Got endpoints: latency-svc-g26lp [753.34185ms]
Jan 16 06:31:48.970: INFO: Created: latency-svc-zz9sw
Jan 16 06:31:49.012: INFO: Got endpoints: latency-svc-x6vzh [751.662962ms]
Jan 16 06:31:49.022: INFO: Created: latency-svc-gqrjx
Jan 16 06:31:49.060: INFO: Got endpoints: latency-svc-wh8kt [750.068489ms]
Jan 16 06:31:49.074: INFO: Created: latency-svc-mdnzb
Jan 16 06:31:49.109: INFO: Got endpoints: latency-svc-kc8nm [750.45274ms]
Jan 16 06:31:49.118: INFO: Created: latency-svc-j8r6w
Jan 16 06:31:49.159: INFO: Got endpoints: latency-svc-tbxv9 [747.511549ms]
Jan 16 06:31:49.172: INFO: Created: latency-svc-l4k8c
Jan 16 06:31:49.210: INFO: Got endpoints: latency-svc-9pjt7 [749.834281ms]
Jan 16 06:31:49.223: INFO: Created: latency-svc-qlg7x
Jan 16 06:31:49.262: INFO: Got endpoints: latency-svc-6fxj6 [752.177548ms]
Jan 16 06:31:49.270: INFO: Created: latency-svc-4sfqb
Jan 16 06:31:49.309: INFO: Got endpoints: latency-svc-r4p7c [749.432165ms]
Jan 16 06:31:49.321: INFO: Created: latency-svc-t72sr
Jan 16 06:31:49.359: INFO: Got endpoints: latency-svc-hpvkr [750.254663ms]
Jan 16 06:31:49.370: INFO: Created: latency-svc-rww7m
Jan 16 06:31:49.411: INFO: Got endpoints: latency-svc-cfx6z [751.053912ms]
Jan 16 06:31:49.422: INFO: Created: latency-svc-zvvnf
Jan 16 06:31:49.462: INFO: Got endpoints: latency-svc-hnjk8 [751.808538ms]
Jan 16 06:31:49.471: INFO: Created: latency-svc-shc96
Jan 16 06:31:49.507: INFO: Got endpoints: latency-svc-qnw6g [745.995261ms]
Jan 16 06:31:49.520: INFO: Created: latency-svc-dcqt2
Jan 16 06:31:49.559: INFO: Got endpoints: latency-svc-nmc84 [747.472533ms]
Jan 16 06:31:49.566: INFO: Created: latency-svc-qbqqb
Jan 16 06:31:49.608: INFO: Got endpoints: latency-svc-kchx2 [748.595626ms]
Jan 16 06:31:49.619: INFO: Created: latency-svc-kf9p7
Jan 16 06:31:49.662: INFO: Got endpoints: latency-svc-tcrbw [753.228809ms]
Jan 16 06:31:49.670: INFO: Created: latency-svc-jmnqj
Jan 16 06:31:49.712: INFO: Got endpoints: latency-svc-zz9sw [749.306785ms]
Jan 16 06:31:49.728: INFO: Created: latency-svc-cqzxx
Jan 16 06:31:49.759: INFO: Got endpoints: latency-svc-gqrjx [747.114572ms]
Jan 16 06:31:49.769: INFO: Created: latency-svc-bllvm
Jan 16 06:31:49.810: INFO: Got endpoints: latency-svc-mdnzb [750.482734ms]
Jan 16 06:31:49.826: INFO: Created: latency-svc-9l9rk
Jan 16 06:31:49.861: INFO: Got endpoints: latency-svc-j8r6w [751.940339ms]
Jan 16 06:31:49.867: INFO: Created: latency-svc-2nhz6
Jan 16 06:31:49.908: INFO: Got endpoints: latency-svc-l4k8c [748.690807ms]
Jan 16 06:31:49.920: INFO: Created: latency-svc-88ltj
Jan 16 06:31:49.958: INFO: Got endpoints: latency-svc-qlg7x [747.875983ms]
Jan 16 06:31:49.967: INFO: Created: latency-svc-tnpj4
Jan 16 06:31:50.011: INFO: Got endpoints: latency-svc-4sfqb [749.054228ms]
Jan 16 06:31:50.024: INFO: Created: latency-svc-k2lgl
Jan 16 06:31:50.060: INFO: Got endpoints: latency-svc-t72sr [750.392698ms]
Jan 16 06:31:50.069: INFO: Created: latency-svc-vr6nq
Jan 16 06:31:50.109: INFO: Got endpoints: latency-svc-rww7m [749.436092ms]
Jan 16 06:31:50.118: INFO: Created: latency-svc-4rfv8
Jan 16 06:31:50.160: INFO: Got endpoints: latency-svc-zvvnf [749.304203ms]
Jan 16 06:31:50.171: INFO: Created: latency-svc-br5gv
Jan 16 06:31:50.210: INFO: Got endpoints: latency-svc-shc96 [747.755329ms]
Jan 16 06:31:50.216: INFO: Created: latency-svc-k9wcj
Jan 16 06:31:50.260: INFO: Got endpoints: latency-svc-dcqt2 [752.506896ms]
Jan 16 06:31:50.271: INFO: Created: latency-svc-b46s2
Jan 16 06:31:50.309: INFO: Got endpoints: latency-svc-qbqqb [750.354755ms]
Jan 16 06:31:50.318: INFO: Created: latency-svc-bmxdw
Jan 16 06:31:50.362: INFO: Got endpoints: latency-svc-kf9p7 [753.537514ms]
Jan 16 06:31:50.373: INFO: Created: latency-svc-7kkv2
Jan 16 06:31:50.408: INFO: Got endpoints: latency-svc-jmnqj [746.854857ms]
Jan 16 06:31:50.426: INFO: Created: latency-svc-lbsct
Jan 16 06:31:50.461: INFO: Got endpoints: latency-svc-cqzxx [749.625218ms]
Jan 16 06:31:50.476: INFO: Created: latency-svc-4s67g
Jan 16 06:31:50.511: INFO: Got endpoints: latency-svc-bllvm [752.211194ms]
Jan 16 06:31:50.525: INFO: Created: latency-svc-72wvc
Jan 16 06:31:50.559: INFO: Got endpoints: latency-svc-9l9rk [749.162967ms]
Jan 16 06:31:50.610: INFO: Got endpoints: latency-svc-2nhz6 [749.009352ms]
Jan 16 06:31:50.662: INFO: Got endpoints: latency-svc-88ltj [753.726215ms]
Jan 16 06:31:50.710: INFO: Got endpoints: latency-svc-tnpj4 [751.64907ms]
Jan 16 06:31:50.761: INFO: Got endpoints: latency-svc-k2lgl [750.660397ms]
Jan 16 06:31:50.812: INFO: Got endpoints: latency-svc-vr6nq [751.738607ms]
Jan 16 06:31:50.858: INFO: Got endpoints: latency-svc-4rfv8 [749.541376ms]
Jan 16 06:31:50.911: INFO: Got endpoints: latency-svc-br5gv [750.344818ms]
Jan 16 06:31:50.968: INFO: Got endpoints: latency-svc-k9wcj [758.142517ms]
Jan 16 06:31:51.009: INFO: Got endpoints: latency-svc-b46s2 [749.409098ms]
Jan 16 06:31:51.070: INFO: Got endpoints: latency-svc-bmxdw [760.476593ms]
Jan 16 06:31:51.110: INFO: Got endpoints: latency-svc-7kkv2 [748.119436ms]
Jan 16 06:31:51.160: INFO: Got endpoints: latency-svc-lbsct [751.296666ms]
Jan 16 06:31:51.209: INFO: Got endpoints: latency-svc-4s67g [747.682887ms]
Jan 16 06:31:51.259: INFO: Got endpoints: latency-svc-72wvc [747.490585ms]
Jan 16 06:31:51.259: INFO: Latencies: [25.498767ms 31.67981ms 40.15216ms 40.644381ms 50.407395ms 59.380751ms 70.267152ms 70.871034ms 78.527402ms 87.505923ms 99.005975ms 107.594124ms 120.629779ms 143.98046ms 151.506867ms 153.111093ms 155.183825ms 157.695907ms 159.440189ms 165.205312ms 170.283187ms 170.981476ms 171.45375ms 172.88951ms 178.966476ms 180.060692ms 184.189671ms 186.941201ms 187.601922ms 189.379819ms 194.270165ms 195.563268ms 198.908107ms 200.149687ms 204.500894ms 213.490715ms 214.391262ms 220.205311ms 222.295985ms 270.578794ms 316.787417ms 317.33898ms 349.005961ms 384.510501ms 420.133819ms 462.926577ms 493.707648ms 544.464054ms 585.838196ms 621.625608ms 664.495191ms 700.836736ms 735.218366ms 736.66082ms 738.711733ms 740.172854ms 742.456846ms 744.239631ms 744.530828ms 745.266827ms 745.606474ms 745.663429ms 745.76558ms 745.995261ms 746.146097ms 746.364092ms 746.63969ms 746.750068ms 746.782665ms 746.854857ms 747.114572ms 747.150144ms 747.308062ms 747.472533ms 747.490585ms 747.511549ms 747.617327ms 747.682887ms 747.725614ms 747.755329ms 747.807841ms 747.875983ms 747.914887ms 747.946809ms 748.104957ms 748.115514ms 748.119436ms 748.154687ms 748.197542ms 748.437428ms 748.467953ms 748.519549ms 748.531914ms 748.565313ms 748.595626ms 748.690807ms 748.738099ms 748.744264ms 748.791097ms 748.890982ms 749.009352ms 749.054228ms 749.060817ms 749.101994ms 749.107225ms 749.121073ms 749.12393ms 749.162967ms 749.21588ms 749.216493ms 749.225105ms 749.229315ms 749.304203ms 749.306785ms 749.409098ms 749.432165ms 749.436092ms 749.505647ms 749.512517ms 749.541376ms 749.571122ms 749.625218ms 749.6388ms 749.761787ms 749.834281ms 749.862432ms 749.899045ms 749.918712ms 749.971514ms 750.068489ms 750.199208ms 750.199891ms 750.245185ms 750.254663ms 750.344818ms 750.354755ms 750.373449ms 750.392698ms 750.415601ms 750.45274ms 750.482734ms 750.508152ms 750.50845ms 750.592024ms 750.599036ms 750.644538ms 750.660397ms 750.706483ms 750.764901ms 750.775768ms 750.810432ms 750.923034ms 750.952799ms 751.02568ms 751.053912ms 751.112314ms 751.124113ms 751.296666ms 751.307012ms 751.389597ms 751.38982ms 751.511359ms 751.64907ms 751.662962ms 751.738607ms 751.808538ms 751.913993ms 751.940339ms 752.012934ms 752.177548ms 752.184259ms 752.185578ms 752.211194ms 752.227654ms 752.236569ms 752.288354ms 752.419483ms 752.506896ms 752.513701ms 752.64421ms 752.789122ms 752.875857ms 752.95159ms 752.962886ms 753.141558ms 753.168949ms 753.228809ms 753.306722ms 753.34185ms 753.516143ms 753.537514ms 753.562521ms 753.652435ms 753.726215ms 754.942491ms 756.863992ms 758.142517ms 760.476593ms 761.311954ms 765.955744ms]
Jan 16 06:31:51.259: INFO: 50 %ile: 749.009352ms
Jan 16 06:31:51.259: INFO: 90 %ile: 752.789122ms
Jan 16 06:31:51.259: INFO: 99 %ile: 761.311954ms
Jan 16 06:31:51.259: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:31:51.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-9nbf8" for this suite.
Jan 16 06:32:03.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:32:03.308: INFO: namespace: e2e-tests-svc-latency-9nbf8, resource: bindings, ignored listing per whitelist
Jan 16 06:32:03.403: INFO: namespace e2e-tests-svc-latency-9nbf8 deletion completed in 12.135819135s

• [SLOW TEST:25.082 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:32:03.405: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-xg5c8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6fde5c8f-1958-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 06:32:03.640: INFO: Waiting up to 5m0s for pod "pod-secrets-6fdefe36-1958-11e9-af83-025056002014" in namespace "e2e-tests-secrets-xg5c8" to be "success or failure"
Jan 16 06:32:03.657: INFO: Pod "pod-secrets-6fdefe36-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 17.471013ms
Jan 16 06:32:05.660: INFO: Pod "pod-secrets-6fdefe36-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020391456s
Jan 16 06:32:07.664: INFO: Pod "pod-secrets-6fdefe36-1958-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02404015s
STEP: Saw pod success
Jan 16 06:32:07.664: INFO: Pod "pod-secrets-6fdefe36-1958-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:32:07.667: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-secrets-6fdefe36-1958-11e9-af83-025056002014 container secret-volume-test: <nil>
STEP: delete the pod
Jan 16 06:32:07.698: INFO: Waiting for pod pod-secrets-6fdefe36-1958-11e9-af83-025056002014 to disappear
Jan 16 06:32:07.700: INFO: Pod pod-secrets-6fdefe36-1958-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:32:07.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xg5c8" for this suite.
Jan 16 06:32:13.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:32:13.770: INFO: namespace: e2e-tests-secrets-xg5c8, resource: bindings, ignored listing per whitelist
Jan 16 06:32:13.813: INFO: namespace e2e-tests-secrets-xg5c8 deletion completed in 6.107198483s

• [SLOW TEST:10.408 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:32:13.814: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5lmv6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 16 06:32:14.020: INFO: Waiting up to 5m0s for pod "pod-7610778d-1958-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-5lmv6" to be "success or failure"
Jan 16 06:32:14.037: INFO: Pod "pod-7610778d-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 17.147924ms
Jan 16 06:32:16.042: INFO: Pod "pod-7610778d-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021237517s
Jan 16 06:32:18.047: INFO: Pod "pod-7610778d-1958-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026263619s
STEP: Saw pod success
Jan 16 06:32:18.047: INFO: Pod "pod-7610778d-1958-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:32:18.049: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-7610778d-1958-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:32:18.071: INFO: Waiting for pod pod-7610778d-1958-11e9-af83-025056002014 to disappear
Jan 16 06:32:18.075: INFO: Pod pod-7610778d-1958-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:32:18.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5lmv6" for this suite.
Jan 16 06:32:24.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:32:24.130: INFO: namespace: e2e-tests-emptydir-5lmv6, resource: bindings, ignored listing per whitelist
Jan 16 06:32:24.176: INFO: namespace e2e-tests-emptydir-5lmv6 deletion completed in 6.095427864s

• [SLOW TEST:10.362 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:32:24.179: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-86vv2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan 16 06:32:24.363: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan 16 06:32:24.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:32:37.397: INFO: stderr: ""
Jan 16 06:32:37.397: INFO: stdout: "service/redis-slave created\n"
Jan 16 06:32:37.398: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan 16 06:32:37.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:32:37.669: INFO: stderr: ""
Jan 16 06:32:37.669: INFO: stdout: "service/redis-master created\n"
Jan 16 06:32:37.669: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 16 06:32:37.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:32:37.902: INFO: stderr: ""
Jan 16 06:32:37.902: INFO: stdout: "service/frontend created\n"
Jan 16 06:32:37.903: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan 16 06:32:37.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:32:38.134: INFO: stderr: ""
Jan 16 06:32:38.134: INFO: stdout: "deployment.extensions/frontend created\n"
Jan 16 06:32:38.134: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 16 06:32:38.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:32:38.344: INFO: stderr: ""
Jan 16 06:32:38.344: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan 16 06:32:38.344: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan 16 06:32:38.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:32:38.578: INFO: stderr: ""
Jan 16 06:32:38.578: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan 16 06:32:38.578: INFO: Waiting for all frontend pods to be Running.
Jan 16 06:33:08.629: INFO: Waiting for frontend to serve content.
Jan 16 06:33:08.655: INFO: Trying to add a new entry to the guestbook.
Jan 16 06:33:08.675: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jan 16 06:33:08.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:33:08.833: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 16 06:33:08.833: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan 16 06:33:08.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:33:08.973: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 16 06:33:08.973: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 16 06:33:08.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:33:09.094: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 16 06:33:09.094: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 16 06:33:09.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:33:09.220: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 16 06:33:09.220: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 16 06:33:09.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:33:09.324: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 16 06:33:09.324: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 16 06:33:09.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-86vv2'
Jan 16 06:33:09.445: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 16 06:33:09.445: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:33:09.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-86vv2" for this suite.
Jan 16 06:33:57.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:33:57.510: INFO: namespace: e2e-tests-kubectl-86vv2, resource: bindings, ignored listing per whitelist
Jan 16 06:33:57.547: INFO: namespace e2e-tests-kubectl-86vv2 deletion completed in 48.097351065s

• [SLOW TEST:93.369 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:33:57.547: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-99hb2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:33:57.737: INFO: Creating deployment "nginx-deployment"
Jan 16 06:33:57.747: INFO: Waiting for observed generation 1
Jan 16 06:34:13.792: INFO: Waiting for all required pods to come up
Jan 16 06:34:13.835: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan 16 06:34:19.869: INFO: Waiting for deployment "nginx-deployment" to complete
Jan 16 06:34:19.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:10, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"nginx-deployment-7f9675fb8b\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:34:21.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:10, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"nginx-deployment-7f9675fb8b\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:34:23.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:10, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"nginx-deployment-7f9675fb8b\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:34:25.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:10, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"nginx-deployment-7f9675fb8b\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:34:27.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:10, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"nginx-deployment-7f9675fb8b\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:34:29.880: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:10, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"nginx-deployment-7f9675fb8b\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:34:31.885: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:10, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"nginx-deployment-7f9675fb8b\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217237, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:34:33.880: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan 16 06:34:33.890: INFO: Updating deployment nginx-deployment
Jan 16 06:34:33.890: INFO: Waiting for observed generation 2
Jan 16 06:34:38.378: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 16 06:34:38.408: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 16 06:34:38.440: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 16 06:34:38.460: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 16 06:34:38.460: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 16 06:34:38.463: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 16 06:34:38.469: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan 16 06:34:38.469: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan 16 06:34:38.476: INFO: Updating deployment nginx-deployment
Jan 16 06:34:38.476: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan 16 06:34:38.487: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 16 06:34:38.498: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 16 06:34:38.530: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-99hb2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-99hb2/deployments/nginx-deployment,UID:b3e3dffd-1958-11e9-ba24-0050568f491d,ResourceVersion:18320,Generation:3,CreationTimestamp:2019-01-16 06:33:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-01-16 06:34:34 +0000 UTC 2019-01-16 06:33:57 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2019-01-16 06:34:38 +0000 UTC 2019-01-16 06:34:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan 16 06:34:38.572: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-99hb2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-99hb2/replicasets/nginx-deployment-7dc8f79789,UID:c9704569-1958-11e9-ba24-0050568f491d,ResourceVersion:18314,Generation:3,CreationTimestamp:2019-01-16 06:34:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b3e3dffd-1958-11e9-ba24-0050568f491d 0xc421b332f7 0xc421b332f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 16 06:34:38.572: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan 16 06:34:38.573: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-99hb2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-99hb2/replicasets/nginx-deployment-7f9675fb8b,UID:b3e6453c-1958-11e9-ba24-0050568f491d,ResourceVersion:18313,Generation:3,CreationTimestamp:2019-01-16 06:33:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b3e3dffd-1958-11e9-ba24-0050568f491d 0xc421b333b7 0xc421b333b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan 16 06:34:38.629: INFO: Pod "nginx-deployment-7dc8f79789-4t47r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-4t47r,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-4t47r,UID:cc34577a-1958-11e9-ba24-0050568f491d,ResourceVersion:18342,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc421221aa7 0xc421221aa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:91937149-2f02-4975-a6bd-87cb9213a67c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421221b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421221b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.629: INFO: Pod "nginx-deployment-7dc8f79789-5jlsk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-5jlsk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-5jlsk,UID:cc2f8e18-1958-11e9-ba24-0050568f491d,ResourceVersion:18325,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc421221ba0 0xc421221ba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421221f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421221f40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.629: INFO: Pod "nginx-deployment-7dc8f79789-6k7pj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-6k7pj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-6k7pj,UID:c971cdfe-1958-11e9-ba24-0050568f491d,ResourceVersion:18275,Generation:0,CreationTimestamp:2019-01-16 06:34:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc421221fb0 0xc421221fb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c0230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c02b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:,StartTime:2019-01-16 06:34:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.630: INFO: Pod "nginx-deployment-7dc8f79789-blfs9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-blfs9,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-blfs9,UID:cc3409f7-1958-11e9-ba24-0050568f491d,ResourceVersion:18340,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc4218c0370 0xc4218c0371}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:1f5a976a-5eac-4984-8510-5241ae82643f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c05d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c05f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.630: INFO: Pod "nginx-deployment-7dc8f79789-dg5s6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dg5s6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-dg5s6,UID:c975cda6-1958-11e9-ba24-0050568f491d,ResourceVersion:18285,Generation:0,CreationTimestamp:2019-01-16 06:34:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc4218c0660 0xc4218c0661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:91937149-2f02-4975-a6bd-87cb9213a67c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c0710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c0740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:,StartTime:2019-01-16 06:34:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.630: INFO: Pod "nginx-deployment-7dc8f79789-jnsbs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-jnsbs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-jnsbs,UID:cc344c85-1958-11e9-ba24-0050568f491d,ResourceVersion:18341,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc4218c0830 0xc4218c0831}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c08a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c08c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.630: INFO: Pod "nginx-deployment-7dc8f79789-mmhj7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mmhj7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-mmhj7,UID:cc34b172-1958-11e9-ba24-0050568f491d,ResourceVersion:18344,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc4218c09b0 0xc4218c09b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:1f5a976a-5eac-4984-8510-5241ae82643f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c0a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c0a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.630: INFO: Pod "nginx-deployment-7dc8f79789-nl9tp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nl9tp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-nl9tp,UID:cc3bb3ba-1958-11e9-ba24-0050568f491d,ResourceVersion:18352,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc4218c0ac0 0xc4218c0ac1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c0b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c0b80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.630: INFO: Pod "nginx-deployment-7dc8f79789-q8vd8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-q8vd8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-q8vd8,UID:cc2e205d-1958-11e9-ba24-0050568f491d,ResourceVersion:18343,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc4218c0c17 0xc4218c0c18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:1f5a976a-5eac-4984-8510-5241ae82643f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c0c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c0d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:,StartTime:2019-01-16 06:34:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.630: INFO: Pod "nginx-deployment-7dc8f79789-qzgj7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qzgj7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-qzgj7,UID:c9753de6-1958-11e9-ba24-0050568f491d,ResourceVersion:18281,Generation:0,CreationTimestamp:2019-01-16 06:34:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc4218c0de0 0xc4218c0de1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:1f5a976a-5eac-4984-8510-5241ae82643f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c0f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c0f90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:33 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:,StartTime:2019-01-16 06:34:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.630: INFO: Pod "nginx-deployment-7dc8f79789-spgwt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-spgwt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-spgwt,UID:c985d2d8-1958-11e9-ba24-0050568f491d,ResourceVersion:18301,Generation:0,CreationTimestamp:2019-01-16 06:34:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc4218c1070 0xc4218c1071}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:91937149-2f02-4975-a6bd-87cb9213a67c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c1200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c1220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:34 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:,StartTime:2019-01-16 06:34:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.631: INFO: Pod "nginx-deployment-7dc8f79789-vnjb6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vnjb6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-vnjb6,UID:cc309afe-1958-11e9-ba24-0050568f491d,ResourceVersion:18336,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc4218c1310 0xc4218c1311}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:91937149-2f02-4975-a6bd-87cb9213a67c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c1460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c1490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.631: INFO: Pod "nginx-deployment-7dc8f79789-vpfq2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vpfq2,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7dc8f79789-vpfq2,UID:c9847b56-1958-11e9-ba24-0050568f491d,ResourceVersion:18302,Generation:0,CreationTimestamp:2019-01-16 06:34:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c9704569-1958-11e9-ba24-0050568f491d 0xc4218c15d0 0xc4218c15d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c1650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c16e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:34 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:,StartTime:2019-01-16 06:34:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.631: INFO: Pod "nginx-deployment-7f9675fb8b-2jz28" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2jz28,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-2jz28,UID:b3efb3c5-1958-11e9-ba24-0050568f491d,ResourceVersion:18210,Generation:0,CreationTimestamp:2019-01-16 06:33:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc4218c1850 0xc4218c1851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:1f5a976a-5eac-4984-8510-5241ae82643f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218c18c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218c1a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:40.0.11.5,StartTime:2019-01-16 06:33:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-16 06:34:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://befc8fe2d901b1df507d1a9f40523c8505af0e359d2dbcadd303e86651bf1eb1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.631: INFO: Pod "nginx-deployment-7f9675fb8b-42jnv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-42jnv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-42jnv,UID:b3eb368c-1958-11e9-ba24-0050568f491d,ResourceVersion:18202,Generation:0,CreationTimestamp:2019-01-16 06:33:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc4218c1b20 0xc4218c1b21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:1f5a976a-5eac-4984-8510-5241ae82643f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c047c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c047e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:40.0.11.3,StartTime:2019-01-16 06:33:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-16 06:34:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://9d814a139cb427b071ec3f93774baf1a2b5854f474c5c843ea481c3514faca33}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.631: INFO: Pod "nginx-deployment-7f9675fb8b-4cb6f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4cb6f,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-4cb6f,UID:cc3b5086-1958-11e9-ba24-0050568f491d,ResourceVersion:18349,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc421c04ad0 0xc421c04ad1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c04c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c04c60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.631: INFO: Pod "nginx-deployment-7f9675fb8b-5s8nk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5s8nk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-5s8nk,UID:b3efa917-1958-11e9-ba24-0050568f491d,ResourceVersion:18235,Generation:0,CreationTimestamp:2019-01-16 06:33:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc421c04d27 0xc421c04d28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:91937149-2f02-4975-a6bd-87cb9213a67c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c04e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c04e30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:40.0.11.8,StartTime:2019-01-16 06:33:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-16 06:34:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://374f1d3c5853e0d96a3398e43c516325ce5dcbba54377d8b84962ccdb4d79044}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.631: INFO: Pod "nginx-deployment-7f9675fb8b-6r2lr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6r2lr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-6r2lr,UID:cc2cea97-1958-11e9-ba24-0050568f491d,ResourceVersion:18347,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc421c05590 0xc421c05591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c055f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c05620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:,StartTime:2019-01-16 06:34:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.631: INFO: Pod "nginx-deployment-7f9675fb8b-6sng4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6sng4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-6sng4,UID:cc3b1936-1958-11e9-ba24-0050568f491d,ResourceVersion:18348,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc421c056e0 0xc421c056e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4221762c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4221762e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.631: INFO: Pod "nginx-deployment-7f9675fb8b-6st5s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6st5s,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-6st5s,UID:cc327eba-1958-11e9-ba24-0050568f491d,ResourceVersion:18338,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc422176337 0xc422176338}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4221763a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422176520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.632: INFO: Pod "nginx-deployment-7f9675fb8b-9dhl5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9dhl5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-9dhl5,UID:b3fc96f0-1958-11e9-ba24-0050568f491d,ResourceVersion:18232,Generation:0,CreationTimestamp:2019-01-16 06:33:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc422176600 0xc422176601}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:1f5a976a-5eac-4984-8510-5241ae82643f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422176660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422176680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:40.0.11.9,StartTime:2019-01-16 06:34:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-16 06:34:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://0338b6bfe2c84abcbddf0d297c2ea41afbbeb077e9a6fcfe490fef618d16d384}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.632: INFO: Pod "nginx-deployment-7f9675fb8b-bksc4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bksc4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-bksc4,UID:b3eb116f-1958-11e9-ba24-0050568f491d,ResourceVersion:18230,Generation:0,CreationTimestamp:2019-01-16 06:33:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc422176a60 0xc422176a61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:91937149-2f02-4975-a6bd-87cb9213a67c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422176ad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422176af0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:40.0.11.4,StartTime:2019-01-16 06:33:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-16 06:34:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://11d3d39a2b34666f77b3bbe8368790d1a98abc420392feb646796a0580c97593}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.633: INFO: Pod "nginx-deployment-7f9675fb8b-f2bn9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-f2bn9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-f2bn9,UID:b3ef9728-1958-11e9-ba24-0050568f491d,ResourceVersion:18211,Generation:0,CreationTimestamp:2019-01-16 06:33:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc422176d70 0xc422176d71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422176dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422176df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.11.6,StartTime:2019-01-16 06:33:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-16 06:34:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://0a3f25ae3f20c15387a79f9f9885c471840c752e71f02c318e21d8453bd5c599}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.633: INFO: Pod "nginx-deployment-7f9675fb8b-gxcfp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gxcfp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-gxcfp,UID:cc31aa74-1958-11e9-ba24-0050568f491d,ResourceVersion:18335,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc422176f20 0xc422176f21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:1f5a976a-5eac-4984-8510-5241ae82643f,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422176f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422176fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.633: INFO: Pod "nginx-deployment-7f9675fb8b-k7gt4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-k7gt4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-k7gt4,UID:b3e9c9fb-1958-11e9-ba24-0050568f491d,ResourceVersion:18204,Generation:0,CreationTimestamp:2019-01-16 06:33:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc422177020 0xc422177021}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4221770c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4221770e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.11.2,StartTime:2019-01-16 06:33:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-16 06:34:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://03c495a72af28c3a86eecbe8e30e7f3bb0b61bf9455fa52c812ecde31d55676e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.633: INFO: Pod "nginx-deployment-7f9675fb8b-nt78t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nt78t,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-nt78t,UID:b3fcb715-1958-11e9-ba24-0050568f491d,ResourceVersion:18231,Generation:0,CreationTimestamp:2019-01-16 06:33:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc4221771c0 0xc4221771c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:91937149-2f02-4975-a6bd-87cb9213a67c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422177260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422177280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:34:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:33:57 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:40.0.11.10,StartTime:2019-01-16 06:34:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-16 06:34:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://6fdd0847a8f942f35cfb96b358867a554abfafc1b55007325cb1e42838bca9c9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.634: INFO: Pod "nginx-deployment-7f9675fb8b-zpk9m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zpk9m,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-zpk9m,UID:cc3b7509-1958-11e9-ba24-0050568f491d,ResourceVersion:18350,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc422177340 0xc422177341}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422177420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422177440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 16 06:34:38.634: INFO: Pod "nginx-deployment-7f9675fb8b-zzm6m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zzm6m,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-99hb2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-99hb2/pods/nginx-deployment-7f9675fb8b-zzm6m,UID:cc3b8482-1958-11e9-ba24-0050568f491d,ResourceVersion:18351,Generation:0,CreationTimestamp:2019-01-16 06:34:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b3e6453c-1958-11e9-ba24-0050568f491d 0xc422177497 0xc422177498}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vjr66 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vjr66,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vjr66 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422177500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422177530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:34:38.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-99hb2" for this suite.
Jan 16 06:34:46.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:34:46.722: INFO: namespace: e2e-tests-deployment-99hb2, resource: bindings, ignored listing per whitelist
Jan 16 06:34:46.805: INFO: namespace e2e-tests-deployment-99hb2 deletion completed in 8.15215299s

• [SLOW TEST:49.258 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:34:46.807: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-qbn98
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-d1458887-1958-11e9-af83-025056002014
STEP: Creating secret with name s-test-opt-upd-d14588c3-1958-11e9-af83-025056002014
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-d1458887-1958-11e9-af83-025056002014
STEP: Updating secret s-test-opt-upd-d14588c3-1958-11e9-af83-025056002014
STEP: Creating secret with name s-test-opt-create-d14588d5-1958-11e9-af83-025056002014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:34:55.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qbn98" for this suite.
Jan 16 06:35:17.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:35:17.248: INFO: namespace: e2e-tests-secrets-qbn98, resource: bindings, ignored listing per whitelist
Jan 16 06:35:17.304: INFO: namespace e2e-tests-secrets-qbn98 deletion completed in 22.108147809s

• [SLOW TEST:30.498 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:35:17.307: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5jbf9
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan 16 06:35:17.510: INFO: Waiting up to 5m0s for pod "pod-e36eeb0c-1958-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-5jbf9" to be "success or failure"
Jan 16 06:35:17.519: INFO: Pod "pod-e36eeb0c-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 9.151522ms
Jan 16 06:35:19.523: INFO: Pod "pod-e36eeb0c-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013354536s
Jan 16 06:35:21.527: INFO: Pod "pod-e36eeb0c-1958-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017381503s
STEP: Saw pod success
Jan 16 06:35:21.527: INFO: Pod "pod-e36eeb0c-1958-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:35:21.530: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-e36eeb0c-1958-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:35:21.552: INFO: Waiting for pod pod-e36eeb0c-1958-11e9-af83-025056002014 to disappear
Jan 16 06:35:21.558: INFO: Pod pod-e36eeb0c-1958-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:35:21.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5jbf9" for this suite.
Jan 16 06:35:27.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:35:27.629: INFO: namespace: e2e-tests-emptydir-5jbf9, resource: bindings, ignored listing per whitelist
Jan 16 06:35:27.666: INFO: namespace e2e-tests-emptydir-5jbf9 deletion completed in 6.102541994s

• [SLOW TEST:10.359 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:35:27.666: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-x29jf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 16 06:35:27.864: INFO: Waiting up to 5m0s for pod "pod-e99a9dca-1958-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-x29jf" to be "success or failure"
Jan 16 06:35:27.882: INFO: Pod "pod-e99a9dca-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 18.089774ms
Jan 16 06:35:29.885: INFO: Pod "pod-e99a9dca-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021525155s
Jan 16 06:35:31.889: INFO: Pod "pod-e99a9dca-1958-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025257151s
STEP: Saw pod success
Jan 16 06:35:31.889: INFO: Pod "pod-e99a9dca-1958-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:35:31.892: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-e99a9dca-1958-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:35:31.915: INFO: Waiting for pod pod-e99a9dca-1958-11e9-af83-025056002014 to disappear
Jan 16 06:35:31.921: INFO: Pod pod-e99a9dca-1958-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:35:31.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x29jf" for this suite.
Jan 16 06:35:37.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:35:37.978: INFO: namespace: e2e-tests-emptydir-x29jf, resource: bindings, ignored listing per whitelist
Jan 16 06:35:38.050: INFO: namespace e2e-tests-emptydir-x29jf deletion completed in 6.123463995s

• [SLOW TEST:10.385 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:35:38.056: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-46v9l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:35:38.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-46v9l" for this suite.
Jan 16 06:36:00.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:36:00.352: INFO: namespace: e2e-tests-pods-46v9l, resource: bindings, ignored listing per whitelist
Jan 16 06:36:00.421: INFO: namespace e2e-tests-pods-46v9l deletion completed in 22.14304548s

• [SLOW TEST:22.366 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:36:00.421: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xc62q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 06:36:00.625: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd21b392-1958-11e9-af83-025056002014" in namespace "e2e-tests-projected-xc62q" to be "success or failure"
Jan 16 06:36:00.636: INFO: Pod "downwardapi-volume-fd21b392-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 11.154982ms
Jan 16 06:36:02.640: INFO: Pod "downwardapi-volume-fd21b392-1958-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015364404s
Jan 16 06:36:04.645: INFO: Pod "downwardapi-volume-fd21b392-1958-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020241768s
STEP: Saw pod success
Jan 16 06:36:04.645: INFO: Pod "downwardapi-volume-fd21b392-1958-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:36:04.649: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-fd21b392-1958-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 06:36:04.671: INFO: Waiting for pod downwardapi-volume-fd21b392-1958-11e9-af83-025056002014 to disappear
Jan 16 06:36:04.676: INFO: Pod downwardapi-volume-fd21b392-1958-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:36:04.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xc62q" for this suite.
Jan 16 06:36:10.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:36:10.729: INFO: namespace: e2e-tests-projected-xc62q, resource: bindings, ignored listing per whitelist
Jan 16 06:36:10.793: INFO: namespace e2e-tests-projected-xc62q deletion completed in 6.11320141s

• [SLOW TEST:10.373 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:36:10.796: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-7x429
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan 16 06:36:11.499: INFO: Waiting up to 5m0s for pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-h84rv" in namespace "e2e-tests-svcaccounts-7x429" to be "success or failure"
Jan 16 06:36:11.509: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-h84rv": Phase="Pending", Reason="", readiness=false. Elapsed: 10.344475ms
Jan 16 06:36:13.513: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-h84rv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014410621s
Jan 16 06:36:15.519: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-h84rv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020182534s
STEP: Saw pod success
Jan 16 06:36:15.519: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-h84rv" satisfied condition "success or failure"
Jan 16 06:36:15.522: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-service-account-039cff43-1959-11e9-af83-025056002014-h84rv container token-test: <nil>
STEP: delete the pod
Jan 16 06:36:15.542: INFO: Waiting for pod pod-service-account-039cff43-1959-11e9-af83-025056002014-h84rv to disappear
Jan 16 06:36:15.546: INFO: Pod pod-service-account-039cff43-1959-11e9-af83-025056002014-h84rv no longer exists
STEP: Creating a pod to test consume service account root CA
Jan 16 06:36:15.553: INFO: Waiting up to 5m0s for pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-qh8p8" in namespace "e2e-tests-svcaccounts-7x429" to be "success or failure"
Jan 16 06:36:15.565: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-qh8p8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.056331ms
Jan 16 06:36:17.570: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-qh8p8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017005003s
Jan 16 06:36:19.574: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-qh8p8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020983797s
STEP: Saw pod success
Jan 16 06:36:19.574: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-qh8p8" satisfied condition "success or failure"
Jan 16 06:36:19.577: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-service-account-039cff43-1959-11e9-af83-025056002014-qh8p8 container root-ca-test: <nil>
STEP: delete the pod
Jan 16 06:36:19.598: INFO: Waiting for pod pod-service-account-039cff43-1959-11e9-af83-025056002014-qh8p8 to disappear
Jan 16 06:36:19.602: INFO: Pod pod-service-account-039cff43-1959-11e9-af83-025056002014-qh8p8 no longer exists
STEP: Creating a pod to test consume service account namespace
Jan 16 06:36:19.607: INFO: Waiting up to 5m0s for pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-hv8bf" in namespace "e2e-tests-svcaccounts-7x429" to be "success or failure"
Jan 16 06:36:19.609: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-hv8bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054176ms
Jan 16 06:36:21.612: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-hv8bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005310185s
Jan 16 06:36:23.616: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-hv8bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008744964s
STEP: Saw pod success
Jan 16 06:36:23.616: INFO: Pod "pod-service-account-039cff43-1959-11e9-af83-025056002014-hv8bf" satisfied condition "success or failure"
Jan 16 06:36:23.619: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-service-account-039cff43-1959-11e9-af83-025056002014-hv8bf container namespace-test: <nil>
STEP: delete the pod
Jan 16 06:36:23.644: INFO: Waiting for pod pod-service-account-039cff43-1959-11e9-af83-025056002014-hv8bf to disappear
Jan 16 06:36:23.662: INFO: Pod pod-service-account-039cff43-1959-11e9-af83-025056002014-hv8bf no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:36:23.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-7x429" for this suite.
Jan 16 06:36:29.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:36:29.700: INFO: namespace: e2e-tests-svcaccounts-7x429, resource: bindings, ignored listing per whitelist
Jan 16 06:36:29.764: INFO: namespace e2e-tests-svcaccounts-7x429 deletion completed in 6.098191709s

• [SLOW TEST:18.969 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:36:29.767: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-x94c4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 06:36:29.963: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e9dff3f-1959-11e9-af83-025056002014" in namespace "e2e-tests-projected-x94c4" to be "success or failure"
Jan 16 06:36:29.972: INFO: Pod "downwardapi-volume-0e9dff3f-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.94139ms
Jan 16 06:36:31.976: INFO: Pod "downwardapi-volume-0e9dff3f-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010749926s
Jan 16 06:36:33.979: INFO: Pod "downwardapi-volume-0e9dff3f-1959-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013856689s
STEP: Saw pod success
Jan 16 06:36:33.979: INFO: Pod "downwardapi-volume-0e9dff3f-1959-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:36:33.982: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-0e9dff3f-1959-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 06:36:34.032: INFO: Waiting for pod downwardapi-volume-0e9dff3f-1959-11e9-af83-025056002014 to disappear
Jan 16 06:36:34.039: INFO: Pod downwardapi-volume-0e9dff3f-1959-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:36:34.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x94c4" for this suite.
Jan 16 06:36:40.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:36:40.103: INFO: namespace: e2e-tests-projected-x94c4, resource: bindings, ignored listing per whitelist
Jan 16 06:36:40.148: INFO: namespace e2e-tests-projected-x94c4 deletion completed in 6.104786362s

• [SLOW TEST:10.382 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:36:40.156: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-v2vbv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:36:40.359: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Jan 16 06:36:40.365: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-v2vbv/daemonsets","resourceVersion":"19027"},"items":null}

Jan 16 06:36:40.368: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-v2vbv/pods","resourceVersion":"19027"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:36:40.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-v2vbv" for this suite.
Jan 16 06:36:46.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:36:46.482: INFO: namespace: e2e-tests-daemonsets-v2vbv, resource: bindings, ignored listing per whitelist
Jan 16 06:36:46.495: INFO: namespace e2e-tests-daemonsets-v2vbv deletion completed in 6.113457068s

S [SKIPPING] [6.339 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan 16 06:36:40.359: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:36:46.498: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tm9mr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 16 06:36:46.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-tm9mr'
Jan 16 06:36:46.940: INFO: stderr: ""
Jan 16 06:36:46.940: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 16 06:36:47.945: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:36:47.945: INFO: Found 0 / 1
Jan 16 06:36:48.943: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:36:48.943: INFO: Found 0 / 1
Jan 16 06:36:49.943: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:36:49.943: INFO: Found 0 / 1
Jan 16 06:36:50.943: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:36:50.943: INFO: Found 1 / 1
Jan 16 06:36:50.943: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan 16 06:36:50.946: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:36:50.946: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 16 06:36:50.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 patch pod redis-master-qzbqf --namespace=e2e-tests-kubectl-tm9mr -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 16 06:36:51.090: INFO: stderr: ""
Jan 16 06:36:51.090: INFO: stdout: "pod/redis-master-qzbqf patched\n"
STEP: checking annotations
Jan 16 06:36:51.096: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:36:51.096: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:36:51.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tm9mr" for this suite.
Jan 16 06:37:13.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:37:13.210: INFO: namespace: e2e-tests-kubectl-tm9mr, resource: bindings, ignored listing per whitelist
Jan 16 06:37:13.213: INFO: namespace e2e-tests-kubectl-tm9mr deletion completed in 22.112278069s

• [SLOW TEST:26.716 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:37:13.216: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-rpxt7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-rpxt7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rpxt7 to expose endpoints map[]
Jan 16 06:37:13.486: INFO: Get endpoints failed (4.892798ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan 16 06:37:14.490: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rpxt7 exposes endpoints map[] (1.009464718s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-rpxt7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rpxt7 to expose endpoints map[pod1:[80]]
Jan 16 06:37:17.542: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rpxt7 exposes endpoints map[pod1:[80]] (3.043185161s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-rpxt7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rpxt7 to expose endpoints map[pod1:[80] pod2:[80]]
Jan 16 06:37:20.593: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rpxt7 exposes endpoints map[pod1:[80] pod2:[80]] (3.044947428s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-rpxt7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rpxt7 to expose endpoints map[pod2:[80]]
Jan 16 06:37:20.616: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rpxt7 exposes endpoints map[pod2:[80]] (16.858293ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-rpxt7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rpxt7 to expose endpoints map[]
Jan 16 06:37:20.632: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rpxt7 exposes endpoints map[] (6.630144ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:37:20.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rpxt7" for this suite.
Jan 16 06:37:26.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:37:26.757: INFO: namespace: e2e-tests-services-rpxt7, resource: bindings, ignored listing per whitelist
Jan 16 06:37:26.825: INFO: namespace e2e-tests-services-rpxt7 deletion completed in 6.100933857s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:13.610 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:37:26.826: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-7w6cc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-30a1de85-1959-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 06:37:27.036: INFO: Waiting up to 5m0s for pod "pod-configmaps-30a262ce-1959-11e9-af83-025056002014" in namespace "e2e-tests-configmap-7w6cc" to be "success or failure"
Jan 16 06:37:27.045: INFO: Pod "pod-configmaps-30a262ce-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 9.529251ms
Jan 16 06:37:29.051: INFO: Pod "pod-configmaps-30a262ce-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015285642s
Jan 16 06:37:31.055: INFO: Pod "pod-configmaps-30a262ce-1959-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018917297s
STEP: Saw pod success
Jan 16 06:37:31.055: INFO: Pod "pod-configmaps-30a262ce-1959-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:37:31.057: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-configmaps-30a262ce-1959-11e9-af83-025056002014 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 06:37:31.079: INFO: Waiting for pod pod-configmaps-30a262ce-1959-11e9-af83-025056002014 to disappear
Jan 16 06:37:31.090: INFO: Pod pod-configmaps-30a262ce-1959-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:37:31.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7w6cc" for this suite.
Jan 16 06:37:37.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:37:37.158: INFO: namespace: e2e-tests-configmap-7w6cc, resource: bindings, ignored listing per whitelist
Jan 16 06:37:37.214: INFO: namespace e2e-tests-configmap-7w6cc deletion completed in 6.111427168s

• [SLOW TEST:10.388 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:37:37.217: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-rlqjz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-4rndn
STEP: Creating secret with name secret-test-36d2c099-1959-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 06:37:37.564: INFO: Waiting up to 5m0s for pod "pod-secrets-36e8e4d7-1959-11e9-af83-025056002014" in namespace "e2e-tests-secrets-rlqjz" to be "success or failure"
Jan 16 06:37:37.569: INFO: Pod "pod-secrets-36e8e4d7-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 5.167082ms
Jan 16 06:37:39.573: INFO: Pod "pod-secrets-36e8e4d7-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00862428s
Jan 16 06:37:41.577: INFO: Pod "pod-secrets-36e8e4d7-1959-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012539624s
STEP: Saw pod success
Jan 16 06:37:41.577: INFO: Pod "pod-secrets-36e8e4d7-1959-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:37:41.580: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-secrets-36e8e4d7-1959-11e9-af83-025056002014 container secret-volume-test: <nil>
STEP: delete the pod
Jan 16 06:37:41.613: INFO: Waiting for pod pod-secrets-36e8e4d7-1959-11e9-af83-025056002014 to disappear
Jan 16 06:37:41.616: INFO: Pod pod-secrets-36e8e4d7-1959-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:37:41.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rlqjz" for this suite.
Jan 16 06:37:47.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:37:47.662: INFO: namespace: e2e-tests-secrets-rlqjz, resource: bindings, ignored listing per whitelist
Jan 16 06:37:47.713: INFO: namespace e2e-tests-secrets-rlqjz deletion completed in 6.092891885s
STEP: Destroying namespace "e2e-tests-secret-namespace-4rndn" for this suite.
Jan 16 06:37:53.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:37:53.769: INFO: namespace: e2e-tests-secret-namespace-4rndn, resource: bindings, ignored listing per whitelist
Jan 16 06:37:53.821: INFO: namespace e2e-tests-secret-namespace-4rndn deletion completed in 6.10795009s

• [SLOW TEST:16.605 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:37:53.824: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-r45tx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan 16 06:37:54.107: INFO: Waiting up to 5m0s for pod "var-expansion-40c3472f-1959-11e9-af83-025056002014" in namespace "e2e-tests-var-expansion-r45tx" to be "success or failure"
Jan 16 06:37:54.119: INFO: Pod "var-expansion-40c3472f-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 11.610154ms
Jan 16 06:37:56.122: INFO: Pod "var-expansion-40c3472f-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01457848s
Jan 16 06:37:58.126: INFO: Pod "var-expansion-40c3472f-1959-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018334786s
STEP: Saw pod success
Jan 16 06:37:58.126: INFO: Pod "var-expansion-40c3472f-1959-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:37:58.128: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod var-expansion-40c3472f-1959-11e9-af83-025056002014 container dapi-container: <nil>
STEP: delete the pod
Jan 16 06:37:58.147: INFO: Waiting for pod var-expansion-40c3472f-1959-11e9-af83-025056002014 to disappear
Jan 16 06:37:58.152: INFO: Pod var-expansion-40c3472f-1959-11e9-af83-025056002014 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:37:58.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-r45tx" for this suite.
Jan 16 06:38:04.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:38:04.198: INFO: namespace: e2e-tests-var-expansion-r45tx, resource: bindings, ignored listing per whitelist
Jan 16 06:38:04.290: INFO: namespace e2e-tests-var-expansion-r45tx deletion completed in 6.13492145s

• [SLOW TEST:10.466 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:38:04.290: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-hdmjw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hdmjw
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 16 06:38:04.483: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 16 06:38:30.606: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.5.5:8080/dial?request=hostName&protocol=udp&host=40.0.5.2&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-hdmjw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:38:30.607: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:38:30.711: INFO: Waiting for endpoints: map[]
Jan 16 06:38:30.716: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.5.5:8080/dial?request=hostName&protocol=udp&host=40.0.5.3&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-hdmjw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:38:30.716: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:38:30.828: INFO: Waiting for endpoints: map[]
Jan 16 06:38:30.831: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.5.5:8080/dial?request=hostName&protocol=udp&host=40.0.5.4&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-hdmjw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:38:30.832: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:38:30.918: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:38:30.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hdmjw" for this suite.
Jan 16 06:38:52.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:38:53.015: INFO: namespace: e2e-tests-pod-network-test-hdmjw, resource: bindings, ignored listing per whitelist
Jan 16 06:38:53.025: INFO: namespace e2e-tests-pod-network-test-hdmjw deletion completed in 22.102263403s

• [SLOW TEST:48.735 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:38:53.026: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7n2mn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 16 06:38:53.236: INFO: Waiting up to 5m0s for pod "downward-api-6404404e-1959-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-7n2mn" to be "success or failure"
Jan 16 06:38:53.241: INFO: Pod "downward-api-6404404e-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.645336ms
Jan 16 06:38:55.244: INFO: Pod "downward-api-6404404e-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007663789s
Jan 16 06:38:57.248: INFO: Pod "downward-api-6404404e-1959-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011966117s
STEP: Saw pod success
Jan 16 06:38:57.248: INFO: Pod "downward-api-6404404e-1959-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:38:57.251: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downward-api-6404404e-1959-11e9-af83-025056002014 container dapi-container: <nil>
STEP: delete the pod
Jan 16 06:38:57.269: INFO: Waiting for pod downward-api-6404404e-1959-11e9-af83-025056002014 to disappear
Jan 16 06:38:57.277: INFO: Pod downward-api-6404404e-1959-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:38:57.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7n2mn" for this suite.
Jan 16 06:39:03.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:39:03.341: INFO: namespace: e2e-tests-downward-api-7n2mn, resource: bindings, ignored listing per whitelist
Jan 16 06:39:03.397: INFO: namespace e2e-tests-downward-api-7n2mn deletion completed in 6.115533618s

• [SLOW TEST:10.371 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:39:03.398: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-r6l2t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 06:39:03.601: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a31b8e5-1959-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-r6l2t" to be "success or failure"
Jan 16 06:39:03.606: INFO: Pod "downwardapi-volume-6a31b8e5-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.07623ms
Jan 16 06:39:05.613: INFO: Pod "downwardapi-volume-6a31b8e5-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01143922s
Jan 16 06:39:07.616: INFO: Pod "downwardapi-volume-6a31b8e5-1959-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014891294s
STEP: Saw pod success
Jan 16 06:39:07.616: INFO: Pod "downwardapi-volume-6a31b8e5-1959-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:39:07.619: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-6a31b8e5-1959-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 06:39:07.649: INFO: Waiting for pod downwardapi-volume-6a31b8e5-1959-11e9-af83-025056002014 to disappear
Jan 16 06:39:07.656: INFO: Pod downwardapi-volume-6a31b8e5-1959-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:39:07.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r6l2t" for this suite.
Jan 16 06:39:13.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:39:13.743: INFO: namespace: e2e-tests-downward-api-r6l2t, resource: bindings, ignored listing per whitelist
Jan 16 06:39:13.752: INFO: namespace e2e-tests-downward-api-r6l2t deletion completed in 6.091818248s

• [SLOW TEST:10.354 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:39:13.753: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-kdq54
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:39:13.943: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 16 06:39:18.947: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 16 06:39:18.947: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 16 06:39:20.951: INFO: Creating deployment "test-rollover-deployment"
Jan 16 06:39:20.959: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 16 06:39:22.964: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 16 06:39:22.970: INFO: Ensure that both replica sets have 1 created replica
Jan 16 06:39:22.975: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 16 06:39:22.982: INFO: Updating deployment test-rollover-deployment
Jan 16 06:39:22.982: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 16 06:39:24.988: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 16 06:39:24.995: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 16 06:39:25.001: INFO: all replica sets need to contain the pod-template-hash label
Jan 16 06:39:25.001: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217563, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:39:27.007: INFO: all replica sets need to contain the pod-template-hash label
Jan 16 06:39:27.008: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217565, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:39:29.008: INFO: all replica sets need to contain the pod-template-hash label
Jan 16 06:39:29.008: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217565, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:39:31.014: INFO: all replica sets need to contain the pod-template-hash label
Jan 16 06:39:31.014: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217565, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:39:33.008: INFO: all replica sets need to contain the pod-template-hash label
Jan 16 06:39:33.008: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217565, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:39:35.008: INFO: all replica sets need to contain the pod-template-hash label
Jan 16 06:39:35.009: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217565, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683217560, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 16 06:39:37.007: INFO: 
Jan 16 06:39:37.007: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 16 06:39:37.014: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-kdq54,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kdq54/deployments/test-rollover-deployment,UID:748a7600-1959-11e9-ba24-0050568f491d,ResourceVersion:19682,Generation:2,CreationTimestamp:2019-01-16 06:39:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-16 06:39:20 +0000 UTC 2019-01-16 06:39:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-16 06:39:36 +0000 UTC 2019-01-16 06:39:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 16 06:39:37.017: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-kdq54,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kdq54/replicasets/test-rollover-deployment-5b76ff8c4,UID:75c04c36-1959-11e9-ba24-0050568f491d,ResourceVersion:19673,Generation:2,CreationTimestamp:2019-01-16 06:39:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 748a7600-1959-11e9-ba24-0050568f491d 0xc42196fac7 0xc42196fac8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 16 06:39:37.017: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 16 06:39:37.018: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-kdq54,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kdq54/replicasets/test-rollover-controller,UID:705bc7bd-1959-11e9-ba24-0050568f491d,ResourceVersion:19681,Generation:2,CreationTimestamp:2019-01-16 06:39:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 748a7600-1959-11e9-ba24-0050568f491d 0xc42196f61e 0xc42196f61f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 16 06:39:37.018: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-kdq54,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kdq54/replicasets/test-rollover-deployment-6975f4fb87,UID:748d607a-1959-11e9-ba24-0050568f491d,ResourceVersion:19640,Generation:2,CreationTimestamp:2019-01-16 06:39:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 748a7600-1959-11e9-ba24-0050568f491d 0xc42196fdd7 0xc42196fdd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 16 06:39:37.020: INFO: Pod "test-rollover-deployment-5b76ff8c4-v7whk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-v7whk,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-kdq54,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kdq54/pods/test-rollover-deployment-5b76ff8c4-v7whk,UID:75c7c9da-1959-11e9-ba24-0050568f491d,ResourceVersion:19656,Generation:0,CreationTimestamp:2019-01-16 06:39:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 75c04c36-1959-11e9-ba24-0050568f491d 0xc4215a6190 0xc4215a6191}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dnprv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dnprv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-dnprv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215a6760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215a6780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:39:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:39:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:39:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:39:23 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.11.4,StartTime:2019-01-16 06:39:23 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-16 06:39:25 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1dd4cba4c34cb65355c3d234f56e7bac91faaad44c0f7f55d46ab7a5fc4b61a0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:39:37.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-kdq54" for this suite.
Jan 16 06:39:43.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:39:43.090: INFO: namespace: e2e-tests-deployment-kdq54, resource: bindings, ignored listing per whitelist
Jan 16 06:39:43.129: INFO: namespace e2e-tests-deployment-kdq54 deletion completed in 6.104249268s

• [SLOW TEST:29.376 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:39:43.132: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-zl9f9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-zl9f9/configmap-test-81e062a2-1959-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 06:39:43.337: INFO: Waiting up to 5m0s for pod "pod-configmaps-81e0eaeb-1959-11e9-af83-025056002014" in namespace "e2e-tests-configmap-zl9f9" to be "success or failure"
Jan 16 06:39:43.344: INFO: Pod "pod-configmaps-81e0eaeb-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 7.072983ms
Jan 16 06:39:45.349: INFO: Pod "pod-configmaps-81e0eaeb-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011122482s
Jan 16 06:39:47.354: INFO: Pod "pod-configmaps-81e0eaeb-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016360728s
Jan 16 06:39:49.358: INFO: Pod "pod-configmaps-81e0eaeb-1959-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020573533s
STEP: Saw pod success
Jan 16 06:39:49.358: INFO: Pod "pod-configmaps-81e0eaeb-1959-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:39:49.361: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-configmaps-81e0eaeb-1959-11e9-af83-025056002014 container env-test: <nil>
STEP: delete the pod
Jan 16 06:39:49.395: INFO: Waiting for pod pod-configmaps-81e0eaeb-1959-11e9-af83-025056002014 to disappear
Jan 16 06:39:49.399: INFO: Pod pod-configmaps-81e0eaeb-1959-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:39:49.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zl9f9" for this suite.
Jan 16 06:39:55.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:39:55.497: INFO: namespace: e2e-tests-configmap-zl9f9, resource: bindings, ignored listing per whitelist
Jan 16 06:39:55.515: INFO: namespace e2e-tests-configmap-zl9f9 deletion completed in 6.112572327s

• [SLOW TEST:12.383 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:39:55.518: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-n6mt2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan 16 06:39:55.721: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-014349168 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:39:55.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n6mt2" for this suite.
Jan 16 06:40:01.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:40:01.889: INFO: namespace: e2e-tests-kubectl-n6mt2, resource: bindings, ignored listing per whitelist
Jan 16 06:40:01.977: INFO: namespace e2e-tests-kubectl-n6mt2 deletion completed in 6.143855538s

• [SLOW TEST:6.460 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:40:01.980: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-t4zbl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan 16 06:40:02.210: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-a,UID:8d215bb6-1959-11e9-ba24-0050568f491d,ResourceVersion:19797,Generation:0,CreationTimestamp:2019-01-16 06:40:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 16 06:40:02.210: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-a,UID:8d215bb6-1959-11e9-ba24-0050568f491d,ResourceVersion:19797,Generation:0,CreationTimestamp:2019-01-16 06:40:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 16 06:40:12.218: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-a,UID:8d215bb6-1959-11e9-ba24-0050568f491d,ResourceVersion:19812,Generation:0,CreationTimestamp:2019-01-16 06:40:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 16 06:40:12.218: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-a,UID:8d215bb6-1959-11e9-ba24-0050568f491d,ResourceVersion:19812,Generation:0,CreationTimestamp:2019-01-16 06:40:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 16 06:40:22.228: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-a,UID:8d215bb6-1959-11e9-ba24-0050568f491d,ResourceVersion:19827,Generation:0,CreationTimestamp:2019-01-16 06:40:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 16 06:40:22.228: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-a,UID:8d215bb6-1959-11e9-ba24-0050568f491d,ResourceVersion:19827,Generation:0,CreationTimestamp:2019-01-16 06:40:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 16 06:40:32.236: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-a,UID:8d215bb6-1959-11e9-ba24-0050568f491d,ResourceVersion:19842,Generation:0,CreationTimestamp:2019-01-16 06:40:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 16 06:40:32.236: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-a,UID:8d215bb6-1959-11e9-ba24-0050568f491d,ResourceVersion:19842,Generation:0,CreationTimestamp:2019-01-16 06:40:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 16 06:40:42.244: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-b,UID:a4fd9ec2-1959-11e9-ba24-0050568f491d,ResourceVersion:19857,Generation:0,CreationTimestamp:2019-01-16 06:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 16 06:40:42.244: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-b,UID:a4fd9ec2-1959-11e9-ba24-0050568f491d,ResourceVersion:19857,Generation:0,CreationTimestamp:2019-01-16 06:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 16 06:40:52.251: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-b,UID:a4fd9ec2-1959-11e9-ba24-0050568f491d,ResourceVersion:19872,Generation:0,CreationTimestamp:2019-01-16 06:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 16 06:40:52.251: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t4zbl,SelfLink:/api/v1/namespaces/e2e-tests-watch-t4zbl/configmaps/e2e-watch-test-configmap-b,UID:a4fd9ec2-1959-11e9-ba24-0050568f491d,ResourceVersion:19872,Generation:0,CreationTimestamp:2019-01-16 06:40:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:41:02.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-t4zbl" for this suite.
Jan 16 06:41:08.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:41:08.344: INFO: namespace: e2e-tests-watch-t4zbl, resource: bindings, ignored listing per whitelist
Jan 16 06:41:08.351: INFO: namespace e2e-tests-watch-t4zbl deletion completed in 6.094388866s

• [SLOW TEST:66.371 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:41:08.352: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-x75xj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:41:08.551: INFO: (0) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.886336ms)
Jan 16 06:41:08.555: INFO: (1) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.363364ms)
Jan 16 06:41:08.559: INFO: (2) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.833233ms)
Jan 16 06:41:08.564: INFO: (3) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.678278ms)
Jan 16 06:41:08.570: INFO: (4) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.189674ms)
Jan 16 06:41:08.575: INFO: (5) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.979003ms)
Jan 16 06:41:08.579: INFO: (6) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.308747ms)
Jan 16 06:41:08.583: INFO: (7) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.457231ms)
Jan 16 06:41:08.588: INFO: (8) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.815672ms)
Jan 16 06:41:08.593: INFO: (9) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.315808ms)
Jan 16 06:41:08.597: INFO: (10) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.420343ms)
Jan 16 06:41:08.601: INFO: (11) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.963095ms)
Jan 16 06:41:08.611: INFO: (12) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.832944ms)
Jan 16 06:41:08.615: INFO: (13) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.192295ms)
Jan 16 06:41:08.620: INFO: (14) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.175546ms)
Jan 16 06:41:08.629: INFO: (15) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.833316ms)
Jan 16 06:41:08.632: INFO: (16) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.484976ms)
Jan 16 06:41:08.635: INFO: (17) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.167164ms)
Jan 16 06:41:08.639: INFO: (18) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.542449ms)
Jan 16 06:41:08.643: INFO: (19) /api/v1/nodes/1f5a976a-5eac-4984-8510-5241ae82643f/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.550089ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:41:08.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-x75xj" for this suite.
Jan 16 06:41:14.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:41:14.672: INFO: namespace: e2e-tests-proxy-x75xj, resource: bindings, ignored listing per whitelist
Jan 16 06:41:14.752: INFO: namespace e2e-tests-proxy-x75xj deletion completed in 6.104621091s

• [SLOW TEST:6.400 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:41:14.752: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-cjhsz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 16 06:41:23.012: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:23.017: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:25.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:25.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:27.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:27.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:29.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:29.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:31.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:31.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:33.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:33.021: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:35.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:35.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:37.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:37.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:39.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:39.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:41.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:41.021: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:43.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:43.023: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:45.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:45.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:47.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:47.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:49.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:49.023: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:51.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:51.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 16 06:41:53.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 16 06:41:53.022: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:41:53.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-cjhsz" for this suite.
Jan 16 06:42:15.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:42:15.070: INFO: namespace: e2e-tests-container-lifecycle-hook-cjhsz, resource: bindings, ignored listing per whitelist
Jan 16 06:42:15.140: INFO: namespace e2e-tests-container-lifecycle-hook-cjhsz deletion completed in 22.104847242s

• [SLOW TEST:60.389 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:42:15.145: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-rf59d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rf59d
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 16 06:42:15.344: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 16 06:42:41.464: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 40.0.11.2 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rf59d PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:42:41.464: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:42:42.546: INFO: Found all expected endpoints: [netserver-0]
Jan 16 06:42:42.552: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 40.0.11.3 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rf59d PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:42:42.552: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:42:43.638: INFO: Found all expected endpoints: [netserver-1]
Jan 16 06:42:43.641: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 40.0.11.4 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rf59d PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:42:43.641: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:42:44.727: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:42:44.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rf59d" for this suite.
Jan 16 06:43:06.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:43:06.774: INFO: namespace: e2e-tests-pod-network-test-rf59d, resource: bindings, ignored listing per whitelist
Jan 16 06:43:06.839: INFO: namespace e2e-tests-pod-network-test-rf59d deletion completed in 22.107182152s

• [SLOW TEST:51.695 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:43:06.840: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zqt7r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 06:43:07.032: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb4a6aa4-1959-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-zqt7r" to be "success or failure"
Jan 16 06:43:07.036: INFO: Pod "downwardapi-volume-fb4a6aa4-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 3.925903ms
Jan 16 06:43:09.043: INFO: Pod "downwardapi-volume-fb4a6aa4-1959-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010683033s
Jan 16 06:43:11.052: INFO: Pod "downwardapi-volume-fb4a6aa4-1959-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020057636s
STEP: Saw pod success
Jan 16 06:43:11.052: INFO: Pod "downwardapi-volume-fb4a6aa4-1959-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:43:11.057: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-fb4a6aa4-1959-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 06:43:11.102: INFO: Waiting for pod downwardapi-volume-fb4a6aa4-1959-11e9-af83-025056002014 to disappear
Jan 16 06:43:11.110: INFO: Pod downwardapi-volume-fb4a6aa4-1959-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:43:11.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zqt7r" for this suite.
Jan 16 06:43:17.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:43:17.209: INFO: namespace: e2e-tests-downward-api-zqt7r, resource: bindings, ignored listing per whitelist
Jan 16 06:43:17.211: INFO: namespace e2e-tests-downward-api-zqt7r deletion completed in 6.0978024s

• [SLOW TEST:10.371 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:43:17.212: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-pnfqx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-pnfqx
Jan 16 06:43:21.411: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-pnfqx
STEP: checking the pod's current state and verifying that restartCount is present
Jan 16 06:43:21.414: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:47:21.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pnfqx" for this suite.
Jan 16 06:47:27.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:47:27.950: INFO: namespace: e2e-tests-container-probe-pnfqx, resource: bindings, ignored listing per whitelist
Jan 16 06:47:27.998: INFO: namespace e2e-tests-container-probe-pnfqx deletion completed in 6.103989204s

• [SLOW TEST:250.786 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:47:27.998: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-62q7m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-96f75f15-195a-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 06:47:28.217: INFO: Waiting up to 5m0s for pod "pod-configmaps-96f80669-195a-11e9-af83-025056002014" in namespace "e2e-tests-configmap-62q7m" to be "success or failure"
Jan 16 06:47:28.231: INFO: Pod "pod-configmaps-96f80669-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 13.746391ms
Jan 16 06:47:30.239: INFO: Pod "pod-configmaps-96f80669-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021158772s
Jan 16 06:47:32.243: INFO: Pod "pod-configmaps-96f80669-195a-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025486488s
STEP: Saw pod success
Jan 16 06:47:32.243: INFO: Pod "pod-configmaps-96f80669-195a-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:47:32.246: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-configmaps-96f80669-195a-11e9-af83-025056002014 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 06:47:32.278: INFO: Waiting for pod pod-configmaps-96f80669-195a-11e9-af83-025056002014 to disappear
Jan 16 06:47:32.280: INFO: Pod pod-configmaps-96f80669-195a-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:47:32.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-62q7m" for this suite.
Jan 16 06:47:38.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:47:38.364: INFO: namespace: e2e-tests-configmap-62q7m, resource: bindings, ignored listing per whitelist
Jan 16 06:47:38.374: INFO: namespace e2e-tests-configmap-62q7m deletion completed in 6.089549351s

• [SLOW TEST:10.376 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:47:38.381: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-5bg9j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-9d2421c8-195a-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 06:47:38.578: INFO: Waiting up to 5m0s for pod "pod-configmaps-9d24d862-195a-11e9-af83-025056002014" in namespace "e2e-tests-configmap-5bg9j" to be "success or failure"
Jan 16 06:47:38.585: INFO: Pod "pod-configmaps-9d24d862-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.626772ms
Jan 16 06:47:40.589: INFO: Pod "pod-configmaps-9d24d862-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010564475s
Jan 16 06:47:42.593: INFO: Pod "pod-configmaps-9d24d862-195a-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014246329s
STEP: Saw pod success
Jan 16 06:47:42.593: INFO: Pod "pod-configmaps-9d24d862-195a-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:47:42.596: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-configmaps-9d24d862-195a-11e9-af83-025056002014 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 06:47:42.614: INFO: Waiting for pod pod-configmaps-9d24d862-195a-11e9-af83-025056002014 to disappear
Jan 16 06:47:42.621: INFO: Pod pod-configmaps-9d24d862-195a-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:47:42.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5bg9j" for this suite.
Jan 16 06:47:50.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:47:50.654: INFO: namespace: e2e-tests-configmap-5bg9j, resource: bindings, ignored listing per whitelist
Jan 16 06:47:50.744: INFO: namespace e2e-tests-configmap-5bg9j deletion completed in 8.119432077s

• [SLOW TEST:12.363 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:47:50.745: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2drh7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-a484cde7-195a-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 06:47:50.959: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a48596da-195a-11e9-af83-025056002014" in namespace "e2e-tests-projected-2drh7" to be "success or failure"
Jan 16 06:47:50.968: INFO: Pod "pod-projected-secrets-a48596da-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.61708ms
Jan 16 06:47:52.973: INFO: Pod "pod-projected-secrets-a48596da-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013489346s
Jan 16 06:47:54.978: INFO: Pod "pod-projected-secrets-a48596da-195a-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018582298s
STEP: Saw pod success
Jan 16 06:47:54.979: INFO: Pod "pod-projected-secrets-a48596da-195a-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:47:54.984: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-secrets-a48596da-195a-11e9-af83-025056002014 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 16 06:47:55.003: INFO: Waiting for pod pod-projected-secrets-a48596da-195a-11e9-af83-025056002014 to disappear
Jan 16 06:47:55.006: INFO: Pod pod-projected-secrets-a48596da-195a-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:47:55.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2drh7" for this suite.
Jan 16 06:48:01.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:48:01.100: INFO: namespace: e2e-tests-projected-2drh7, resource: bindings, ignored listing per whitelist
Jan 16 06:48:01.176: INFO: namespace e2e-tests-projected-2drh7 deletion completed in 6.16541012s

• [SLOW TEST:10.432 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:48:01.178: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rpmhr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 06:48:01.527: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aad2d363-195a-11e9-af83-025056002014" in namespace "e2e-tests-downward-api-rpmhr" to be "success or failure"
Jan 16 06:48:01.530: INFO: Pod "downwardapi-volume-aad2d363-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.42926ms
Jan 16 06:48:03.534: INFO: Pod "downwardapi-volume-aad2d363-195a-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006895896s
STEP: Saw pod success
Jan 16 06:48:03.535: INFO: Pod "downwardapi-volume-aad2d363-195a-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:48:03.542: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-aad2d363-195a-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 06:48:03.563: INFO: Waiting for pod downwardapi-volume-aad2d363-195a-11e9-af83-025056002014 to disappear
Jan 16 06:48:03.569: INFO: Pod downwardapi-volume-aad2d363-195a-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:48:03.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rpmhr" for this suite.
Jan 16 06:48:09.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:48:09.644: INFO: namespace: e2e-tests-downward-api-rpmhr, resource: bindings, ignored listing per whitelist
Jan 16 06:48:09.681: INFO: namespace e2e-tests-downward-api-rpmhr deletion completed in 6.107620747s

• [SLOW TEST:8.503 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:48:09.682: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-pcpfw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-afcc991c-195a-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 06:48:09.885: INFO: Waiting up to 5m0s for pod "pod-secrets-afcd6517-195a-11e9-af83-025056002014" in namespace "e2e-tests-secrets-pcpfw" to be "success or failure"
Jan 16 06:48:09.898: INFO: Pod "pod-secrets-afcd6517-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 12.041554ms
Jan 16 06:48:11.901: INFO: Pod "pod-secrets-afcd6517-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015564851s
Jan 16 06:48:13.905: INFO: Pod "pod-secrets-afcd6517-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019420214s
Jan 16 06:48:15.909: INFO: Pod "pod-secrets-afcd6517-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02323869s
Jan 16 06:48:17.913: INFO: Pod "pod-secrets-afcd6517-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.027855814s
Jan 16 06:48:19.918: INFO: Pod "pod-secrets-afcd6517-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 10.032165721s
Jan 16 06:48:21.922: INFO: Pod "pod-secrets-afcd6517-195a-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.036130408s
STEP: Saw pod success
Jan 16 06:48:21.922: INFO: Pod "pod-secrets-afcd6517-195a-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:48:21.925: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-secrets-afcd6517-195a-11e9-af83-025056002014 container secret-volume-test: <nil>
STEP: delete the pod
Jan 16 06:48:21.943: INFO: Waiting for pod pod-secrets-afcd6517-195a-11e9-af83-025056002014 to disappear
Jan 16 06:48:21.949: INFO: Pod pod-secrets-afcd6517-195a-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:48:21.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pcpfw" for this suite.
Jan 16 06:48:27.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:48:28.002: INFO: namespace: e2e-tests-secrets-pcpfw, resource: bindings, ignored listing per whitelist
Jan 16 06:48:28.056: INFO: namespace e2e-tests-secrets-pcpfw deletion completed in 6.102656452s

• [SLOW TEST:18.375 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:48:28.056: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-pq6n2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 16 06:48:30.793: INFO: Successfully updated pod "pod-update-bac01ada-195a-11e9-af83-025056002014"
STEP: verifying the updated pod is in kubernetes
Jan 16 06:48:30.805: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:48:30.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pq6n2" for this suite.
Jan 16 06:48:52.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:48:52.858: INFO: namespace: e2e-tests-pods-pq6n2, resource: bindings, ignored listing per whitelist
Jan 16 06:48:52.917: INFO: namespace e2e-tests-pods-pq6n2 deletion completed in 22.100363139s

• [SLOW TEST:24.860 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:48:52.918: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-x688t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-wplr
STEP: Creating a pod to test atomic-volume-subpath
Jan 16 06:48:53.135: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-wplr" in namespace "e2e-tests-subpath-x688t" to be "success or failure"
Jan 16 06:48:53.161: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Pending", Reason="", readiness=false. Elapsed: 25.478304ms
Jan 16 06:48:55.165: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029564072s
Jan 16 06:48:57.178: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043002685s
Jan 16 06:48:59.182: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Running", Reason="", readiness=false. Elapsed: 6.04673101s
Jan 16 06:49:01.187: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Running", Reason="", readiness=false. Elapsed: 8.051337931s
Jan 16 06:49:03.191: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Running", Reason="", readiness=false. Elapsed: 10.055708423s
Jan 16 06:49:05.196: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Running", Reason="", readiness=false. Elapsed: 12.060287868s
Jan 16 06:49:07.199: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Running", Reason="", readiness=false. Elapsed: 14.064201494s
Jan 16 06:49:09.203: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Running", Reason="", readiness=false. Elapsed: 16.067860382s
Jan 16 06:49:11.207: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Running", Reason="", readiness=false. Elapsed: 18.071899488s
Jan 16 06:49:13.211: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Running", Reason="", readiness=false. Elapsed: 20.075651751s
Jan 16 06:49:15.220: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Running", Reason="", readiness=false. Elapsed: 22.085140145s
Jan 16 06:49:17.224: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Running", Reason="", readiness=false. Elapsed: 24.088600492s
Jan 16 06:49:19.235: INFO: Pod "pod-subpath-test-projected-wplr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.099912735s
STEP: Saw pod success
Jan 16 06:49:19.235: INFO: Pod "pod-subpath-test-projected-wplr" satisfied condition "success or failure"
Jan 16 06:49:19.238: INFO: Trying to get logs from node 1f5a976a-5eac-4984-8510-5241ae82643f pod pod-subpath-test-projected-wplr container test-container-subpath-projected-wplr: <nil>
STEP: delete the pod
Jan 16 06:49:19.259: INFO: Waiting for pod pod-subpath-test-projected-wplr to disappear
Jan 16 06:49:19.266: INFO: Pod pod-subpath-test-projected-wplr no longer exists
STEP: Deleting pod pod-subpath-test-projected-wplr
Jan 16 06:49:19.266: INFO: Deleting pod "pod-subpath-test-projected-wplr" in namespace "e2e-tests-subpath-x688t"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:49:19.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-x688t" for this suite.
Jan 16 06:49:25.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:49:25.365: INFO: namespace: e2e-tests-subpath-x688t, resource: bindings, ignored listing per whitelist
Jan 16 06:49:25.378: INFO: namespace e2e-tests-subpath-x688t deletion completed in 6.103914125s

• [SLOW TEST:32.460 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:49:25.381: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-9vj5d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9vj5d
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-9vj5d
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-9vj5d
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-9vj5d
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-9vj5d
Jan 16 06:49:29.634: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9vj5d, name: ss-0, uid: df394db8-195a-11e9-ba24-0050568f491d, status phase: Pending. Waiting for statefulset controller to delete.
Jan 16 06:49:30.008: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9vj5d, name: ss-0, uid: df394db8-195a-11e9-ba24-0050568f491d, status phase: Failed. Waiting for statefulset controller to delete.
Jan 16 06:49:30.027: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9vj5d, name: ss-0, uid: df394db8-195a-11e9-ba24-0050568f491d, status phase: Failed. Waiting for statefulset controller to delete.
Jan 16 06:49:30.042: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-9vj5d
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-9vj5d
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-9vj5d and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 16 06:49:34.083: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9vj5d
Jan 16 06:49:34.085: INFO: Scaling statefulset ss to 0
Jan 16 06:49:54.104: INFO: Waiting for statefulset status.replicas updated to 0
Jan 16 06:49:54.107: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:49:54.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9vj5d" for this suite.
Jan 16 06:50:00.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:50:00.198: INFO: namespace: e2e-tests-statefulset-9vj5d, resource: bindings, ignored listing per whitelist
Jan 16 06:50:00.240: INFO: namespace e2e-tests-statefulset-9vj5d deletion completed in 6.110657102s

• [SLOW TEST:34.859 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:50:00.240: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-sjrtb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 16 06:50:00.456: INFO: Waiting up to 5m0s for pod "pod-f1b56d59-195a-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-sjrtb" to be "success or failure"
Jan 16 06:50:00.468: INFO: Pod "pod-f1b56d59-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 12.391689ms
Jan 16 06:50:02.474: INFO: Pod "pod-f1b56d59-195a-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017945057s
Jan 16 06:50:04.479: INFO: Pod "pod-f1b56d59-195a-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023442371s
STEP: Saw pod success
Jan 16 06:50:04.479: INFO: Pod "pod-f1b56d59-195a-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:50:04.483: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-f1b56d59-195a-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:50:04.523: INFO: Waiting for pod pod-f1b56d59-195a-11e9-af83-025056002014 to disappear
Jan 16 06:50:04.527: INFO: Pod pod-f1b56d59-195a-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:50:04.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sjrtb" for this suite.
Jan 16 06:50:10.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:50:10.613: INFO: namespace: e2e-tests-emptydir-sjrtb, resource: bindings, ignored listing per whitelist
Jan 16 06:50:10.631: INFO: namespace e2e-tests-emptydir-sjrtb deletion completed in 6.09886031s

• [SLOW TEST:10.391 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:50:10.631: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-pbr2k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-g5kc
STEP: Creating a pod to test atomic-volume-subpath
Jan 16 06:50:10.857: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-g5kc" in namespace "e2e-tests-subpath-pbr2k" to be "success or failure"
Jan 16 06:50:10.861: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.283752ms
Jan 16 06:50:12.890: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033314715s
Jan 16 06:50:14.894: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Running", Reason="", readiness=false. Elapsed: 4.037164888s
Jan 16 06:50:16.898: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Running", Reason="", readiness=false. Elapsed: 6.041179414s
Jan 16 06:50:18.902: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Running", Reason="", readiness=false. Elapsed: 8.044903046s
Jan 16 06:50:20.908: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Running", Reason="", readiness=false. Elapsed: 10.050785538s
Jan 16 06:50:22.911: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Running", Reason="", readiness=false. Elapsed: 12.054570924s
Jan 16 06:50:24.916: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Running", Reason="", readiness=false. Elapsed: 14.058783035s
Jan 16 06:50:26.920: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Running", Reason="", readiness=false. Elapsed: 16.062722565s
Jan 16 06:50:28.925: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Running", Reason="", readiness=false. Elapsed: 18.067901866s
Jan 16 06:50:30.927: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Running", Reason="", readiness=false. Elapsed: 20.070644287s
Jan 16 06:50:32.932: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Running", Reason="", readiness=false. Elapsed: 22.074720668s
Jan 16 06:50:34.936: INFO: Pod "pod-subpath-test-downwardapi-g5kc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.078792904s
STEP: Saw pod success
Jan 16 06:50:34.936: INFO: Pod "pod-subpath-test-downwardapi-g5kc" satisfied condition "success or failure"
Jan 16 06:50:34.938: INFO: Trying to get logs from node 1f5a976a-5eac-4984-8510-5241ae82643f pod pod-subpath-test-downwardapi-g5kc container test-container-subpath-downwardapi-g5kc: <nil>
STEP: delete the pod
Jan 16 06:50:34.961: INFO: Waiting for pod pod-subpath-test-downwardapi-g5kc to disappear
Jan 16 06:50:34.965: INFO: Pod pod-subpath-test-downwardapi-g5kc no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-g5kc
Jan 16 06:50:34.965: INFO: Deleting pod "pod-subpath-test-downwardapi-g5kc" in namespace "e2e-tests-subpath-pbr2k"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:50:34.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-pbr2k" for this suite.
Jan 16 06:50:40.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:50:41.074: INFO: namespace: e2e-tests-subpath-pbr2k, resource: bindings, ignored listing per whitelist
Jan 16 06:50:41.085: INFO: namespace e2e-tests-subpath-pbr2k deletion completed in 6.114133428s

• [SLOW TEST:30.454 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:50:41.086: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-vhbp9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan 16 06:50:47.311: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-0a0d9de3-195b-11e9-af83-025056002014,GenerateName:,Namespace:e2e-tests-events-vhbp9,SelfLink:/api/v1/namespaces/e2e-tests-events-vhbp9/pods/send-events-0a0d9de3-195b-11e9-af83-025056002014,UID:0a0e19b3-195b-11e9-ba24-0050568f491d,ResourceVersion:21336,Generation:0,CreationTimestamp:2019-01-16 06:50:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 289372494,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-p25wf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p25wf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-p25wf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:d02c56a1-5f5a-4edd-b080-4296aa47afb8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4214dd5d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4214dd5f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:50:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:50:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:50:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-16 06:50:41 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.5.2,StartTime:2019-01-16 06:50:41 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-16 06:50:47 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://a089ccb2be4fb12061df054f72fdd03103afd6b6cecdbeaa245dd84992ea0df3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan 16 06:50:49.319: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan 16 06:50:51.324: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:50:51.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-vhbp9" for this suite.
Jan 16 06:51:33.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:51:33.386: INFO: namespace: e2e-tests-events-vhbp9, resource: bindings, ignored listing per whitelist
Jan 16 06:51:33.452: INFO: namespace e2e-tests-events-vhbp9 deletion completed in 42.107053788s

• [SLOW TEST:52.366 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:51:33.455: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nzxjw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 16 06:51:33.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-nzxjw'
Jan 16 06:51:34.535: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 16 06:51:34.535: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan 16 06:51:34.557: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-xxxwl]
Jan 16 06:51:34.557: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-xxxwl" in namespace "e2e-tests-kubectl-nzxjw" to be "running and ready"
Jan 16 06:51:34.560: INFO: Pod "e2e-test-nginx-rc-xxxwl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.620131ms
Jan 16 06:51:36.563: INFO: Pod "e2e-test-nginx-rc-xxxwl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006225682s
Jan 16 06:51:38.567: INFO: Pod "e2e-test-nginx-rc-xxxwl": Phase="Running", Reason="", readiness=true. Elapsed: 4.009972387s
Jan 16 06:51:38.567: INFO: Pod "e2e-test-nginx-rc-xxxwl" satisfied condition "running and ready"
Jan 16 06:51:38.567: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-xxxwl]
Jan 16 06:51:38.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nzxjw'
Jan 16 06:51:38.701: INFO: stderr: ""
Jan 16 06:51:38.701: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Jan 16 06:51:38.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nzxjw'
Jan 16 06:51:38.813: INFO: stderr: ""
Jan 16 06:51:38.814: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:51:38.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nzxjw" for this suite.
Jan 16 06:51:44.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:51:44.883: INFO: namespace: e2e-tests-kubectl-nzxjw, resource: bindings, ignored listing per whitelist
Jan 16 06:51:44.921: INFO: namespace e2e-tests-kubectl-nzxjw deletion completed in 6.096089065s

• [SLOW TEST:11.466 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:51:44.924: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jdv4x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Jan 16 06:51:45.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-jdv4x'
Jan 16 06:51:45.355: INFO: stderr: ""
Jan 16 06:51:45.355: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan 16 06:51:46.359: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:51:46.359: INFO: Found 0 / 1
Jan 16 06:51:47.359: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:51:47.359: INFO: Found 0 / 1
Jan 16 06:51:48.362: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:51:48.362: INFO: Found 1 / 1
Jan 16 06:51:48.362: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 16 06:51:48.364: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:51:48.364: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan 16 06:51:48.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 logs redis-master-58zbz redis-master --namespace=e2e-tests-kubectl-jdv4x'
Jan 16 06:51:48.498: INFO: stderr: ""
Jan 16 06:51:48.498: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 16 Jan 06:51:47.133 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 16 Jan 06:51:47.133 # Server started, Redis version 3.2.12\n1:M 16 Jan 06:51:47.133 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 16 Jan 06:51:47.133 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan 16 06:51:48.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 log redis-master-58zbz redis-master --namespace=e2e-tests-kubectl-jdv4x --tail=1'
Jan 16 06:51:48.615: INFO: stderr: ""
Jan 16 06:51:48.615: INFO: stdout: "1:M 16 Jan 06:51:47.133 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan 16 06:51:48.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 log redis-master-58zbz redis-master --namespace=e2e-tests-kubectl-jdv4x --limit-bytes=1'
Jan 16 06:51:48.727: INFO: stderr: ""
Jan 16 06:51:48.727: INFO: stdout: " "
STEP: exposing timestamps
Jan 16 06:51:48.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 log redis-master-58zbz redis-master --namespace=e2e-tests-kubectl-jdv4x --tail=1 --timestamps'
Jan 16 06:51:48.822: INFO: stderr: ""
Jan 16 06:51:48.822: INFO: stdout: "2019-01-16T06:51:47.134199853Z 1:M 16 Jan 06:51:47.133 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan 16 06:51:51.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 log redis-master-58zbz redis-master --namespace=e2e-tests-kubectl-jdv4x --since=1s'
Jan 16 06:51:51.441: INFO: stderr: ""
Jan 16 06:51:51.441: INFO: stdout: ""
Jan 16 06:51:51.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 log redis-master-58zbz redis-master --namespace=e2e-tests-kubectl-jdv4x --since=24h'
Jan 16 06:51:51.556: INFO: stderr: ""
Jan 16 06:51:51.556: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 16 Jan 06:51:47.133 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 16 Jan 06:51:47.133 # Server started, Redis version 3.2.12\n1:M 16 Jan 06:51:47.133 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 16 Jan 06:51:47.133 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Jan 16 06:51:51.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jdv4x'
Jan 16 06:51:51.668: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 16 06:51:51.668: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan 16 06:51:51.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-jdv4x'
Jan 16 06:51:51.784: INFO: stderr: "No resources found.\n"
Jan 16 06:51:51.784: INFO: stdout: ""
Jan 16 06:51:51.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -l name=nginx --namespace=e2e-tests-kubectl-jdv4x -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 16 06:51:51.882: INFO: stderr: ""
Jan 16 06:51:51.882: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:51:51.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jdv4x" for this suite.
Jan 16 06:52:13.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:52:13.956: INFO: namespace: e2e-tests-kubectl-jdv4x, resource: bindings, ignored listing per whitelist
Jan 16 06:52:13.986: INFO: namespace e2e-tests-kubectl-jdv4x deletion completed in 22.098996281s

• [SLOW TEST:29.062 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:52:13.986: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-2lxzt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan 16 06:52:14.190: INFO: Waiting up to 5m0s for pod "client-containers-416b5426-195b-11e9-af83-025056002014" in namespace "e2e-tests-containers-2lxzt" to be "success or failure"
Jan 16 06:52:14.198: INFO: Pod "client-containers-416b5426-195b-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 7.611758ms
Jan 16 06:52:16.201: INFO: Pod "client-containers-416b5426-195b-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010598281s
Jan 16 06:52:18.207: INFO: Pod "client-containers-416b5426-195b-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016750971s
STEP: Saw pod success
Jan 16 06:52:18.207: INFO: Pod "client-containers-416b5426-195b-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:52:18.210: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod client-containers-416b5426-195b-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:52:18.229: INFO: Waiting for pod client-containers-416b5426-195b-11e9-af83-025056002014 to disappear
Jan 16 06:52:18.234: INFO: Pod client-containers-416b5426-195b-11e9-af83-025056002014 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:52:18.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2lxzt" for this suite.
Jan 16 06:52:24.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:52:24.320: INFO: namespace: e2e-tests-containers-2lxzt, resource: bindings, ignored listing per whitelist
Jan 16 06:52:24.339: INFO: namespace e2e-tests-containers-2lxzt deletion completed in 6.09993485s

• [SLOW TEST:10.353 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:52:24.341: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-76lt6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 16 06:52:24.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-76lt6'
Jan 16 06:52:24.660: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 16 06:52:24.660: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Jan 16 06:52:28.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-76lt6'
Jan 16 06:52:28.791: INFO: stderr: ""
Jan 16 06:52:28.791: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:52:28.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-76lt6" for this suite.
Jan 16 06:52:34.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:52:34.911: INFO: namespace: e2e-tests-kubectl-76lt6, resource: bindings, ignored listing per whitelist
Jan 16 06:52:34.921: INFO: namespace e2e-tests-kubectl-76lt6 deletion completed in 6.115425056s

• [SLOW TEST:10.580 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:52:34.922: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-hq4jd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan 16 06:52:35.121: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-hq4jd" to be "success or failure"
Jan 16 06:52:35.135: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 13.73206ms
Jan 16 06:52:37.140: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018687997s
Jan 16 06:52:39.144: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0225295s
STEP: Saw pod success
Jan 16 06:52:39.144: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan 16 06:52:39.146: INFO: Trying to get logs from node 1f5a976a-5eac-4984-8510-5241ae82643f pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan 16 06:52:39.171: INFO: Waiting for pod pod-host-path-test to disappear
Jan 16 06:52:39.173: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:52:39.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-hq4jd" for this suite.
Jan 16 06:52:45.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:52:45.241: INFO: namespace: e2e-tests-hostpath-hq4jd, resource: bindings, ignored listing per whitelist
Jan 16 06:52:45.295: INFO: namespace e2e-tests-hostpath-hq4jd deletion completed in 6.117645315s

• [SLOW TEST:10.373 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:52:45.295: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-rh222
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan 16 06:52:45.509: INFO: Waiting up to 5m0s for pod "var-expansion-54170f1d-195b-11e9-af83-025056002014" in namespace "e2e-tests-var-expansion-rh222" to be "success or failure"
Jan 16 06:52:45.518: INFO: Pod "var-expansion-54170f1d-195b-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.424994ms
Jan 16 06:52:47.522: INFO: Pod "var-expansion-54170f1d-195b-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012301544s
Jan 16 06:52:49.525: INFO: Pod "var-expansion-54170f1d-195b-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015647194s
STEP: Saw pod success
Jan 16 06:52:49.525: INFO: Pod "var-expansion-54170f1d-195b-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:52:49.527: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod var-expansion-54170f1d-195b-11e9-af83-025056002014 container dapi-container: <nil>
STEP: delete the pod
Jan 16 06:52:49.564: INFO: Waiting for pod var-expansion-54170f1d-195b-11e9-af83-025056002014 to disappear
Jan 16 06:52:49.567: INFO: Pod var-expansion-54170f1d-195b-11e9-af83-025056002014 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:52:49.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-rh222" for this suite.
Jan 16 06:52:55.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:52:55.681: INFO: namespace: e2e-tests-var-expansion-rh222, resource: bindings, ignored listing per whitelist
Jan 16 06:52:55.687: INFO: namespace e2e-tests-var-expansion-rh222 deletion completed in 6.112640965s

• [SLOW TEST:10.392 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:52:55.689: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-bvg7b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:52:55.893: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan 16 06:52:55.918: INFO: Number of nodes with available pods: 0
Jan 16 06:52:55.918: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:52:56.927: INFO: Number of nodes with available pods: 0
Jan 16 06:52:56.927: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:52:57.934: INFO: Number of nodes with available pods: 0
Jan 16 06:52:57.935: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:52:58.925: INFO: Number of nodes with available pods: 2
Jan 16 06:52:58.925: INFO: Node 91937149-2f02-4975-a6bd-87cb9213a67c is running more than one daemon pod
Jan 16 06:52:59.927: INFO: Number of nodes with available pods: 3
Jan 16 06:52:59.927: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan 16 06:52:59.949: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:52:59.949: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:52:59.950: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:00.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:00.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:00.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:01.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:01.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:01.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:02.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:02.958: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:02.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:03.960: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:03.960: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:03.960: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:04.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:04.958: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:04.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:05.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:05.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:05.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:06.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:06.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:06.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:07.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:07.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:07.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:08.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:08.958: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:08.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:09.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:09.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:09.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:10.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:10.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:10.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:11.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:11.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:11.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:12.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:12.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:12.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:13.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:13.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:13.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:14.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:14.958: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:14.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:15.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:15.958: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:15.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:16.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:16.958: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:16.959: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:17.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:17.958: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:17.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:18.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:18.958: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:18.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:19.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:19.958: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:19.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:20.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:20.958: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:20.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:21.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:21.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:21.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:22.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:22.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:22.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:23.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:23.958: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:23.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:24.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:24.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:24.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:25.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:25.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:25.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:26.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:26.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:26.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:27.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:27.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:27.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:28.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:28.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:28.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:29.959: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:29.959: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:29.959: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:30.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:30.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:30.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:31.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:31.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:31.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:32.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:32.957: INFO: Wrong image for pod: daemon-set-crqh2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:32.957: INFO: Pod daemon-set-crqh2 is not available
Jan 16 06:53:32.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:33.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:33.957: INFO: Pod daemon-set-76f44 is not available
Jan 16 06:53:33.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:34.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:34.957: INFO: Pod daemon-set-76f44 is not available
Jan 16 06:53:34.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:35.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:35.958: INFO: Pod daemon-set-76f44 is not available
Jan 16 06:53:35.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:36.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:36.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:37.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:37.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:38.956: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:38.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:39.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:39.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:40.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:40.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:41.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:41.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:42.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:42.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:43.959: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:43.960: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:44.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:44.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:45.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:45.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:46.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:46.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:47.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:47.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:48.956: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:48.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:49.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:49.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:50.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:50.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:51.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:51.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:52.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:52.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:53.960: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:53.960: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:54.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:54.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:55.962: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:55.962: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:56.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:56.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:57.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:57.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:58.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:58.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:59.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:53:59.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:00.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:00.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:01.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:01.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:02.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:02.958: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:03.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:03.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:04.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:04.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:05.960: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:05.961: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:06.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:06.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:07.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:07.957: INFO: Wrong image for pod: daemon-set-jr2dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:07.957: INFO: Pod daemon-set-jr2dn is not available
Jan 16 06:54:08.959: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:08.959: INFO: Pod daemon-set-rcqpl is not available
Jan 16 06:54:09.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:09.958: INFO: Pod daemon-set-rcqpl is not available
Jan 16 06:54:10.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:11.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:12.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:13.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:14.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:15.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:16.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:17.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:18.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:19.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:20.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:21.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:22.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:23.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:24.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:25.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:26.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:27.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:28.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:29.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:30.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:31.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:32.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:33.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:34.958: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:35.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:36.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:37.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:38.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:39.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:40.957: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:40.957: INFO: Pod daemon-set-2lq85 is not available
Jan 16 06:54:41.963: INFO: Wrong image for pod: daemon-set-2lq85. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 16 06:54:41.963: INFO: Pod daemon-set-2lq85 is not available
Jan 16 06:54:42.958: INFO: Pod daemon-set-jgv65 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jan 16 06:54:42.967: INFO: Number of nodes with available pods: 2
Jan 16 06:54:42.967: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:54:43.977: INFO: Number of nodes with available pods: 2
Jan 16 06:54:43.977: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:54:44.976: INFO: Number of nodes with available pods: 2
Jan 16 06:54:44.976: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:54:45.976: INFO: Number of nodes with available pods: 2
Jan 16 06:54:45.976: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:54:46.975: INFO: Number of nodes with available pods: 2
Jan 16 06:54:46.976: INFO: Node 1f5a976a-5eac-4984-8510-5241ae82643f is running more than one daemon pod
Jan 16 06:54:47.979: INFO: Number of nodes with available pods: 3
Jan 16 06:54:47.979: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-bvg7b, will wait for the garbage collector to delete the pods
Jan 16 06:54:48.055: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.294419ms
Jan 16 06:54:48.156: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.949672ms
Jan 16 06:54:57.460: INFO: Number of nodes with available pods: 0
Jan 16 06:54:57.460: INFO: Number of running nodes: 0, number of available pods: 0
Jan 16 06:54:57.462: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bvg7b/daemonsets","resourceVersion":"22017"},"items":null}

Jan 16 06:54:57.464: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bvg7b/pods","resourceVersion":"22017"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:54:57.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bvg7b" for this suite.
Jan 16 06:55:03.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:55:03.518: INFO: namespace: e2e-tests-daemonsets-bvg7b, resource: bindings, ignored listing per whitelist
Jan 16 06:55:03.592: INFO: namespace e2e-tests-daemonsets-bvg7b deletion completed in 6.113927556s

• [SLOW TEST:127.903 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:55:03.592: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wj6z7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:55:03.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 version --client'
Jan 16 06:55:03.881: INFO: stderr: ""
Jan 16 06:55:03.882: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan 16 06:55:03.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-wj6z7'
Jan 16 06:55:04.203: INFO: stderr: ""
Jan 16 06:55:04.203: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan 16 06:55:04.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-wj6z7'
Jan 16 06:55:04.423: INFO: stderr: ""
Jan 16 06:55:04.423: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 16 06:55:05.427: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:55:05.427: INFO: Found 0 / 1
Jan 16 06:55:06.428: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:55:06.428: INFO: Found 0 / 1
Jan 16 06:55:07.428: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:55:07.428: INFO: Found 1 / 1
Jan 16 06:55:07.428: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 16 06:55:07.432: INFO: Selector matched 1 pods for map[app:redis]
Jan 16 06:55:07.432: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 16 06:55:07.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 describe pod redis-master-5xq9z --namespace=e2e-tests-kubectl-wj6z7'
Jan 16 06:55:07.568: INFO: stderr: ""
Jan 16 06:55:07.568: INFO: stdout: "Name:               redis-master-5xq9z\nNamespace:          e2e-tests-kubectl-wj6z7\nPriority:           0\nPriorityClassName:  <none>\nNode:               d02c56a1-5f5a-4edd-b080-4296aa47afb8/30.0.3.3\nStart Time:         Wed, 16 Jan 2019 06:55:04 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 40.0.5.2\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://4d1ade00555df3d673e0d2809ad7d1379683d1aa144361682a95867d2d98c3e4\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 16 Jan 2019 06:55:06 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7bskz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7bskz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7bskz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                           Message\n  ----    ------     ----  ----                                           -------\n  Normal  Scheduled  3s    default-scheduler                              Successfully assigned e2e-tests-kubectl-wj6z7/redis-master-5xq9z to d02c56a1-5f5a-4edd-b080-4296aa47afb8\n  Normal  Pulled     1s    kubelet, d02c56a1-5f5a-4edd-b080-4296aa47afb8  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, d02c56a1-5f5a-4edd-b080-4296aa47afb8  Created container\n  Normal  Started    1s    kubelet, d02c56a1-5f5a-4edd-b080-4296aa47afb8  Started container\n"
Jan 16 06:55:07.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 describe rc redis-master --namespace=e2e-tests-kubectl-wj6z7'
Jan 16 06:55:07.712: INFO: stderr: ""
Jan 16 06:55:07.712: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-wj6z7\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-5xq9z\n"
Jan 16 06:55:07.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 describe service redis-master --namespace=e2e-tests-kubectl-wj6z7'
Jan 16 06:55:07.824: INFO: stderr: ""
Jan 16 06:55:07.824: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-wj6z7\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.200.82\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         40.0.5.2:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan 16 06:55:07.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 describe node 1f5a976a-5eac-4984-8510-5241ae82643f'
Jan 16 06:55:07.984: INFO: stderr: ""
Jan 16 06:55:07.984: INFO: stdout: "Name:               1f5a976a-5eac-4984-8510-5241ae82643f\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    bosh.id=112cc885-f349-4950-8d09-0fddeff53653\n                    bosh.zone=az-3\n                    failure-domain.beta.kubernetes.io/zone=az-3\n                    kubernetes.io/hostname=30.0.3.5\n                    spec.ip=30.0.3.5\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 16 Jan 2019 04:39:17 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Wed, 16 Jan 2019 06:55:05 +0000   Wed, 16 Jan 2019 04:39:17 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Wed, 16 Jan 2019 06:55:05 +0000   Wed, 16 Jan 2019 04:39:17 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 16 Jan 2019 06:55:05 +0000   Wed, 16 Jan 2019 04:39:17 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 16 Jan 2019 06:55:05 +0000   Wed, 16 Jan 2019 04:39:17 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 16 Jan 2019 06:55:05 +0000   Wed, 16 Jan 2019 04:39:27 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  30.0.3.5\n  InternalIP:  30.0.3.5\n  Hostname:    30.0.3.5\nCapacity:\n cpu:                2\n ephemeral-storage:  3030944Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8168828Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  2793317986\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8066428Ki\n pods:               110\nSystem Info:\n Machine ID:                 6db40ea29d4363ade6a737337df95111\n System UUID:                420FE92A-6750-499A-1CB9-E4A9CBE88737\n Boot ID:                    1d605aa6-8a0e-437f-b057-57575d8f7ac0\n Kernel Version:             4.15.0-42-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.12.4\n Kube-Proxy Version:         v1.12.4\nProviderID:                  vsphere://420fe92a-6750-499a-1cb9-e4a9cbe88737\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-e2e-job-b9d0f91747af40b1                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-85d823d0f35748d4-jgpvg    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kubernetes-dashboard-5f4b59b97f-ghd2b                      50m (2%)      100m (5%)   100Mi (1%)       300Mi (3%)\n  kube-system                metrics-server-555d98886f-6xwrt                            0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                wavefront-proxy-9d76d4d76-7wtjn                            0 (0%)        0 (0%)      1500M (18%)      1500M (18%)\n  pks-system                 fluent-bit-gqggz                                           0 (0%)        0 (0%)      100Mi (1%)       100Mi (1%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests          Limits\n  --------  --------          ------\n  cpu       50m (2%)          100m (5%)\n  memory    1709715200 (20%)  1919430400 (23%)\nEvents:     <none>\n"
Jan 16 06:55:07.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 describe namespace e2e-tests-kubectl-wj6z7'
Jan 16 06:55:08.105: INFO: stderr: ""
Jan 16 06:55:08.105: INFO: stdout: "Name:         e2e-tests-kubectl-wj6z7\nLabels:       e2e-framework=kubectl\n              e2e-run=8fc6ae03-194f-11e9-af83-025056002014\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:55:08.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wj6z7" for this suite.
Jan 16 06:55:30.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:55:30.184: INFO: namespace: e2e-tests-kubectl-wj6z7, resource: bindings, ignored listing per whitelist
Jan 16 06:55:30.216: INFO: namespace e2e-tests-kubectl-wj6z7 deletion completed in 22.105525942s

• [SLOW TEST:26.624 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:55:30.220: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-k5fb8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan 16 06:55:38.460: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-k5fb8 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:55:38.460: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:55:38.554: INFO: Exec stderr: ""
Jan 16 06:55:38.555: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-k5fb8 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:55:38.555: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:55:38.639: INFO: Exec stderr: ""
Jan 16 06:55:38.639: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-k5fb8 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:55:38.639: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:55:38.725: INFO: Exec stderr: ""
Jan 16 06:55:38.725: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-k5fb8 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:55:38.725: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:55:38.822: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan 16 06:55:38.822: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-k5fb8 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:55:38.822: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:55:38.906: INFO: Exec stderr: ""
Jan 16 06:55:38.906: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-k5fb8 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:55:38.906: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:55:38.986: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan 16 06:55:38.986: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-k5fb8 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:55:38.986: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:55:39.091: INFO: Exec stderr: ""
Jan 16 06:55:39.091: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-k5fb8 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:55:39.091: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:55:39.182: INFO: Exec stderr: ""
Jan 16 06:55:39.182: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-k5fb8 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:55:39.182: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:55:39.289: INFO: Exec stderr: ""
Jan 16 06:55:39.289: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-k5fb8 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:55:39.289: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:55:39.389: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:55:39.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-k5fb8" for this suite.
Jan 16 06:56:17.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:56:17.456: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-k5fb8, resource: bindings, ignored listing per whitelist
Jan 16 06:56:17.487: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-k5fb8 deletion completed in 38.092754391s

• [SLOW TEST:47.268 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:56:17.488: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-vgz8r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0116 06:56:27.718670      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 16 06:56:27.718: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:56:27.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vgz8r" for this suite.
Jan 16 06:56:33.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:56:33.775: INFO: namespace: e2e-tests-gc-vgz8r, resource: bindings, ignored listing per whitelist
Jan 16 06:56:33.827: INFO: namespace e2e-tests-gc-vgz8r deletion completed in 6.10554759s

• [SLOW TEST:16.340 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:56:33.828: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-pz5tk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 16 06:56:40.083: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:56:40.091: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:56:42.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:56:42.095: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:56:44.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:56:44.095: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:56:46.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:56:46.094: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:56:48.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:56:48.095: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:56:50.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:56:50.095: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:56:52.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:56:52.094: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:56:54.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:56:54.095: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:56:56.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:56:56.095: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:56:58.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:56:58.095: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:57:00.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:57:00.095: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:57:02.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:57:02.096: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 16 06:57:04.091: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 16 06:57:04.094: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:57:04.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-pz5tk" for this suite.
Jan 16 06:57:26.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:57:26.149: INFO: namespace: e2e-tests-container-lifecycle-hook-pz5tk, resource: bindings, ignored listing per whitelist
Jan 16 06:57:26.205: INFO: namespace e2e-tests-container-lifecycle-hook-pz5tk deletion completed in 22.10661776s

• [SLOW TEST:52.378 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:57:26.206: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-7dw5n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan 16 06:57:26.402: INFO: Waiting up to 5m0s for pod "client-containers-fb84409e-195b-11e9-af83-025056002014" in namespace "e2e-tests-containers-7dw5n" to be "success or failure"
Jan 16 06:57:26.406: INFO: Pod "client-containers-fb84409e-195b-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 3.200782ms
Jan 16 06:57:28.410: INFO: Pod "client-containers-fb84409e-195b-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007100687s
Jan 16 06:57:30.414: INFO: Pod "client-containers-fb84409e-195b-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011135416s
STEP: Saw pod success
Jan 16 06:57:30.414: INFO: Pod "client-containers-fb84409e-195b-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:57:30.416: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod client-containers-fb84409e-195b-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 06:57:30.455: INFO: Waiting for pod client-containers-fb84409e-195b-11e9-af83-025056002014 to disappear
Jan 16 06:57:30.460: INFO: Pod client-containers-fb84409e-195b-11e9-af83-025056002014 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:57:30.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7dw5n" for this suite.
Jan 16 06:57:36.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:57:36.553: INFO: namespace: e2e-tests-containers-7dw5n, resource: bindings, ignored listing per whitelist
Jan 16 06:57:36.573: INFO: namespace e2e-tests-containers-7dw5n deletion completed in 6.108194202s

• [SLOW TEST:10.367 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:57:36.574: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6lqzn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 16 06:57:39.290: INFO: Successfully updated pod "labelsupdate01b0b2ac-195c-11e9-af83-025056002014"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:57:41.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6lqzn" for this suite.
Jan 16 06:58:03.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:58:03.358: INFO: namespace: e2e-tests-projected-6lqzn, resource: bindings, ignored listing per whitelist
Jan 16 06:58:03.447: INFO: namespace e2e-tests-projected-6lqzn deletion completed in 22.118050377s

• [SLOW TEST:26.873 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:58:03.447: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-5tqbv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5tqbv A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-5tqbv;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5tqbv A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-5tqbv;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5tqbv.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-5tqbv.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5tqbv.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-5tqbv.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5tqbv.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tqbv.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5tqbv.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tqbv.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5tqbv.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-5tqbv.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5tqbv.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-5tqbv.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5tqbv.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 6.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.6_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 6.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.6_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5tqbv A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-5tqbv;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5tqbv A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-5tqbv;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5tqbv.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-5tqbv.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5tqbv.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-5tqbv.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5tqbv.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tqbv.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5tqbv.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tqbv.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5tqbv.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-5tqbv.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5tqbv.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-5tqbv.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5tqbv.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 6.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.6_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 6.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.6_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 16 06:58:31.799: INFO: DNS probes using e2e-tests-dns-5tqbv/dns-test-11bcc200-195c-11e9-af83-025056002014 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:58:31.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-5tqbv" for this suite.
Jan 16 06:58:37.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:58:37.927: INFO: namespace: e2e-tests-dns-5tqbv, resource: bindings, ignored listing per whitelist
Jan 16 06:58:37.974: INFO: namespace e2e-tests-dns-5tqbv deletion completed in 6.101388759s

• [SLOW TEST:34.527 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:58:37.975: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-hgsfb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 16 06:58:56.199: INFO: Container started at 2019-01-16 06:58:40 +0000 UTC, pod became ready at 2019-01-16 06:58:55 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:58:56.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hgsfb" for this suite.
Jan 16 06:59:18.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:59:18.282: INFO: namespace: e2e-tests-container-probe-hgsfb, resource: bindings, ignored listing per whitelist
Jan 16 06:59:18.303: INFO: namespace e2e-tests-container-probe-hgsfb deletion completed in 22.098644677s

• [SLOW TEST:40.328 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:59:18.305: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vv2cl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3e56aa54-195c-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 06:59:18.520: INFO: Waiting up to 5m0s for pod "pod-secrets-3e57975e-195c-11e9-af83-025056002014" in namespace "e2e-tests-secrets-vv2cl" to be "success or failure"
Jan 16 06:59:18.532: INFO: Pod "pod-secrets-3e57975e-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 11.332168ms
Jan 16 06:59:20.536: INFO: Pod "pod-secrets-3e57975e-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015670388s
Jan 16 06:59:22.540: INFO: Pod "pod-secrets-3e57975e-195c-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019820428s
STEP: Saw pod success
Jan 16 06:59:22.541: INFO: Pod "pod-secrets-3e57975e-195c-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 06:59:22.543: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-secrets-3e57975e-195c-11e9-af83-025056002014 container secret-volume-test: <nil>
STEP: delete the pod
Jan 16 06:59:22.578: INFO: Waiting for pod pod-secrets-3e57975e-195c-11e9-af83-025056002014 to disappear
Jan 16 06:59:22.583: INFO: Pod pod-secrets-3e57975e-195c-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:59:22.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vv2cl" for this suite.
Jan 16 06:59:28.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 06:59:28.632: INFO: namespace: e2e-tests-secrets-vv2cl, resource: bindings, ignored listing per whitelist
Jan 16 06:59:28.705: INFO: namespace e2e-tests-secrets-vv2cl deletion completed in 6.111665739s

• [SLOW TEST:10.400 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 06:59:28.707: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-77z2m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-77z2m
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 16 06:59:28.896: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 16 06:59:51.010: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://40.0.11.2:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-77z2m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:59:51.010: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:59:51.107: INFO: Found all expected endpoints: [netserver-0]
Jan 16 06:59:51.111: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://40.0.11.3:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-77z2m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:59:51.111: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:59:51.217: INFO: Found all expected endpoints: [netserver-1]
Jan 16 06:59:51.221: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://40.0.11.4:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-77z2m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 16 06:59:51.221: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
Jan 16 06:59:51.317: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 06:59:51.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-77z2m" for this suite.
Jan 16 07:00:13.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:00:13.421: INFO: namespace: e2e-tests-pod-network-test-77z2m, resource: bindings, ignored listing per whitelist
Jan 16 07:00:13.432: INFO: namespace e2e-tests-pod-network-test-77z2m deletion completed in 22.109590139s

• [SLOW TEST:44.726 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:00:13.435: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6hdck
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Jan 16 07:00:13.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 create -f - --namespace=e2e-tests-kubectl-6hdck'
Jan 16 07:00:27.551: INFO: stderr: ""
Jan 16 07:00:27.551: INFO: stdout: "pod/pause created\n"
Jan 16 07:00:27.551: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 16 07:00:27.551: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-6hdck" to be "running and ready"
Jan 16 07:00:27.562: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 11.42625ms
Jan 16 07:00:29.566: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014747281s
Jan 16 07:00:31.570: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.018599159s
Jan 16 07:00:31.570: INFO: Pod "pause" satisfied condition "running and ready"
Jan 16 07:00:31.570: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan 16 07:00:31.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-6hdck'
Jan 16 07:00:31.700: INFO: stderr: ""
Jan 16 07:00:31.700: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan 16 07:00:31.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6hdck'
Jan 16 07:00:31.820: INFO: stderr: ""
Jan 16 07:00:31.820: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan 16 07:00:31.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 label pods pause testing-label- --namespace=e2e-tests-kubectl-6hdck'
Jan 16 07:00:31.934: INFO: stderr: ""
Jan 16 07:00:31.935: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan 16 07:00:31.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6hdck'
Jan 16 07:00:32.045: INFO: stderr: ""
Jan 16 07:00:32.045: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Jan 16 07:00:32.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6hdck'
Jan 16 07:00:32.152: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 16 07:00:32.152: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 16 07:00:32.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-6hdck'
Jan 16 07:00:32.255: INFO: stderr: "No resources found.\n"
Jan 16 07:00:32.255: INFO: stdout: ""
Jan 16 07:00:32.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 get pods -l name=pause --namespace=e2e-tests-kubectl-6hdck -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 16 07:00:32.352: INFO: stderr: ""
Jan 16 07:00:32.352: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:00:32.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6hdck" for this suite.
Jan 16 07:00:38.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:00:38.385: INFO: namespace: e2e-tests-kubectl-6hdck, resource: bindings, ignored listing per whitelist
Jan 16 07:00:38.455: INFO: namespace e2e-tests-kubectl-6hdck deletion completed in 6.097524666s

• [SLOW TEST:25.022 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:00:38.460: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mbctn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-6e1bdaef-195c-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 07:00:38.660: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6e1c7311-195c-11e9-af83-025056002014" in namespace "e2e-tests-projected-mbctn" to be "success or failure"
Jan 16 07:00:38.668: INFO: Pod "pod-projected-secrets-6e1c7311-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 7.487856ms
Jan 16 07:00:40.671: INFO: Pod "pod-projected-secrets-6e1c7311-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011216097s
Jan 16 07:00:42.675: INFO: Pod "pod-projected-secrets-6e1c7311-195c-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014721242s
STEP: Saw pod success
Jan 16 07:00:42.675: INFO: Pod "pod-projected-secrets-6e1c7311-195c-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 07:00:42.677: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-projected-secrets-6e1c7311-195c-11e9-af83-025056002014 container secret-volume-test: <nil>
STEP: delete the pod
Jan 16 07:00:42.705: INFO: Waiting for pod pod-projected-secrets-6e1c7311-195c-11e9-af83-025056002014 to disappear
Jan 16 07:00:42.707: INFO: Pod pod-projected-secrets-6e1c7311-195c-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:00:42.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mbctn" for this suite.
Jan 16 07:00:48.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:00:48.793: INFO: namespace: e2e-tests-projected-mbctn, resource: bindings, ignored listing per whitelist
Jan 16 07:00:48.808: INFO: namespace e2e-tests-projected-mbctn deletion completed in 6.09645316s

• [SLOW TEST:10.349 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:00:48.809: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ftmbk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan 16 07:00:49.011: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-014349168 proxy --unix-socket=/tmp/kubectl-proxy-unix458170895/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:00:49.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ftmbk" for this suite.
Jan 16 07:00:55.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:00:55.148: INFO: namespace: e2e-tests-kubectl-ftmbk, resource: bindings, ignored listing per whitelist
Jan 16 07:00:55.187: INFO: namespace e2e-tests-kubectl-ftmbk deletion completed in 6.095366953s

• [SLOW TEST:6.378 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:00:55.200: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-9865t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 16 07:00:55.408: INFO: Waiting up to 5m0s for pod "pod-78167337-195c-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-9865t" to be "success or failure"
Jan 16 07:00:55.426: INFO: Pod "pod-78167337-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 18.340422ms
Jan 16 07:00:57.430: INFO: Pod "pod-78167337-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02229876s
Jan 16 07:00:59.434: INFO: Pod "pod-78167337-195c-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025799142s
STEP: Saw pod success
Jan 16 07:00:59.434: INFO: Pod "pod-78167337-195c-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 07:00:59.436: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-78167337-195c-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 07:00:59.463: INFO: Waiting for pod pod-78167337-195c-11e9-af83-025056002014 to disappear
Jan 16 07:00:59.466: INFO: Pod pod-78167337-195c-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:00:59.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9865t" for this suite.
Jan 16 07:01:05.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:01:05.530: INFO: namespace: e2e-tests-emptydir-9865t, resource: bindings, ignored listing per whitelist
Jan 16 07:01:05.568: INFO: namespace e2e-tests-emptydir-9865t deletion completed in 6.095966509s

• [SLOW TEST:10.378 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:01:05.570: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vdwzz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 16 07:01:05.776: INFO: Waiting up to 5m0s for pod "pod-7e451b04-195c-11e9-af83-025056002014" in namespace "e2e-tests-emptydir-vdwzz" to be "success or failure"
Jan 16 07:01:05.781: INFO: Pod "pod-7e451b04-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.877964ms
Jan 16 07:01:07.786: INFO: Pod "pod-7e451b04-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009474949s
Jan 16 07:01:09.793: INFO: Pod "pod-7e451b04-195c-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016792559s
STEP: Saw pod success
Jan 16 07:01:09.793: INFO: Pod "pod-7e451b04-195c-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 07:01:09.796: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-7e451b04-195c-11e9-af83-025056002014 container test-container: <nil>
STEP: delete the pod
Jan 16 07:01:09.830: INFO: Waiting for pod pod-7e451b04-195c-11e9-af83-025056002014 to disappear
Jan 16 07:01:09.833: INFO: Pod pod-7e451b04-195c-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:01:09.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vdwzz" for this suite.
Jan 16 07:01:15.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:01:15.877: INFO: namespace: e2e-tests-emptydir-vdwzz, resource: bindings, ignored listing per whitelist
Jan 16 07:01:15.954: INFO: namespace e2e-tests-emptydir-vdwzz deletion completed in 6.117231889s

• [SLOW TEST:10.385 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:01:15.956: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qsmrm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 16 07:01:16.175: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84772a2d-195c-11e9-af83-025056002014" in namespace "e2e-tests-projected-qsmrm" to be "success or failure"
Jan 16 07:01:16.181: INFO: Pod "downwardapi-volume-84772a2d-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.238155ms
Jan 16 07:01:18.194: INFO: Pod "downwardapi-volume-84772a2d-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019005854s
Jan 16 07:01:20.197: INFO: Pod "downwardapi-volume-84772a2d-195c-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022282255s
STEP: Saw pod success
Jan 16 07:01:20.198: INFO: Pod "downwardapi-volume-84772a2d-195c-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 07:01:20.200: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod downwardapi-volume-84772a2d-195c-11e9-af83-025056002014 container client-container: <nil>
STEP: delete the pod
Jan 16 07:01:20.228: INFO: Waiting for pod downwardapi-volume-84772a2d-195c-11e9-af83-025056002014 to disappear
Jan 16 07:01:20.231: INFO: Pod downwardapi-volume-84772a2d-195c-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:01:20.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qsmrm" for this suite.
Jan 16 07:01:26.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:01:26.328: INFO: namespace: e2e-tests-projected-qsmrm, resource: bindings, ignored listing per whitelist
Jan 16 07:01:26.385: INFO: namespace e2e-tests-projected-qsmrm deletion completed in 6.14522947s

• [SLOW TEST:10.429 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:01:26.386: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-zdn5q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:01:26.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-zdn5q" for this suite.
Jan 16 07:01:32.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:01:32.784: INFO: namespace: e2e-tests-services-zdn5q, resource: bindings, ignored listing per whitelist
Jan 16 07:01:32.811: INFO: namespace e2e-tests-services-zdn5q deletion completed in 6.095532598s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.426 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:01:32.812: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-q5z6p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan 16 07:01:33.031: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q5z6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q5z6p/configmaps/e2e-watch-test-label-changed,UID:8e82767b-195c-11e9-ba24-0050568f491d,ResourceVersion:23237,Generation:0,CreationTimestamp:2019-01-16 07:01:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 16 07:01:33.031: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q5z6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q5z6p/configmaps/e2e-watch-test-label-changed,UID:8e82767b-195c-11e9-ba24-0050568f491d,ResourceVersion:23238,Generation:0,CreationTimestamp:2019-01-16 07:01:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 16 07:01:33.031: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q5z6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q5z6p/configmaps/e2e-watch-test-label-changed,UID:8e82767b-195c-11e9-ba24-0050568f491d,ResourceVersion:23239,Generation:0,CreationTimestamp:2019-01-16 07:01:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan 16 07:01:43.055: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q5z6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q5z6p/configmaps/e2e-watch-test-label-changed,UID:8e82767b-195c-11e9-ba24-0050568f491d,ResourceVersion:23255,Generation:0,CreationTimestamp:2019-01-16 07:01:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 16 07:01:43.056: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q5z6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q5z6p/configmaps/e2e-watch-test-label-changed,UID:8e82767b-195c-11e9-ba24-0050568f491d,ResourceVersion:23256,Generation:0,CreationTimestamp:2019-01-16 07:01:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan 16 07:01:43.056: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q5z6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q5z6p/configmaps/e2e-watch-test-label-changed,UID:8e82767b-195c-11e9-ba24-0050568f491d,ResourceVersion:23257,Generation:0,CreationTimestamp:2019-01-16 07:01:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:01:43.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-q5z6p" for this suite.
Jan 16 07:01:49.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:01:49.101: INFO: namespace: e2e-tests-watch-q5z6p, resource: bindings, ignored listing per whitelist
Jan 16 07:01:49.163: INFO: namespace e2e-tests-watch-q5z6p deletion completed in 6.099313359s

• [SLOW TEST:16.352 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:01:49.166: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-jrpb8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jrpb8
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan 16 07:01:49.375: INFO: Found 0 stateful pods, waiting for 3
Jan 16 07:01:59.379: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 07:01:59.379: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 07:01:59.379: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 16 07:01:59.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-jrpb8 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 16 07:01:59.592: INFO: stderr: ""
Jan 16 07:01:59.592: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 16 07:01:59.592: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 16 07:02:09.624: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan 16 07:02:19.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-jrpb8 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 07:02:19.854: INFO: stderr: ""
Jan 16 07:02:19.854: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 16 07:02:19.854: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 16 07:02:39.873: INFO: Waiting for StatefulSet e2e-tests-statefulset-jrpb8/ss2 to complete update
STEP: Rolling back to a previous revision
Jan 16 07:02:49.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-jrpb8 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 16 07:02:50.074: INFO: stderr: ""
Jan 16 07:02:50.074: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 16 07:02:50.074: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 16 07:03:00.108: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan 16 07:03:10.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 exec --namespace=e2e-tests-statefulset-jrpb8 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 16 07:03:10.383: INFO: stderr: ""
Jan 16 07:03:10.383: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 16 07:03:10.383: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 16 07:03:20.418: INFO: Waiting for StatefulSet e2e-tests-statefulset-jrpb8/ss2 to complete update
Jan 16 07:03:20.418: INFO: Waiting for Pod e2e-tests-statefulset-jrpb8/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 16 07:03:30.424: INFO: Waiting for StatefulSet e2e-tests-statefulset-jrpb8/ss2 to complete update
Jan 16 07:03:30.424: INFO: Waiting for Pod e2e-tests-statefulset-jrpb8/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 16 07:03:40.423: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jrpb8
Jan 16 07:03:40.425: INFO: Scaling statefulset ss2 to 0
Jan 16 07:04:10.446: INFO: Waiting for statefulset status.replicas updated to 0
Jan 16 07:04:10.449: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:04:10.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jrpb8" for this suite.
Jan 16 07:04:16.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:04:16.562: INFO: namespace: e2e-tests-statefulset-jrpb8, resource: bindings, ignored listing per whitelist
Jan 16 07:04:16.594: INFO: namespace e2e-tests-statefulset-jrpb8 deletion completed in 6.12881414s

• [SLOW TEST:147.429 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:04:16.601: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-4w9mr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-4w9mr/secret-test-f020c9a7-195c-11e9-af83-025056002014
STEP: Creating a pod to test consume secrets
Jan 16 07:04:16.796: INFO: Waiting up to 5m0s for pod "pod-configmaps-f0215c58-195c-11e9-af83-025056002014" in namespace "e2e-tests-secrets-4w9mr" to be "success or failure"
Jan 16 07:04:16.807: INFO: Pod "pod-configmaps-f0215c58-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 11.48264ms
Jan 16 07:04:18.811: INFO: Pod "pod-configmaps-f0215c58-195c-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015459188s
Jan 16 07:04:20.817: INFO: Pod "pod-configmaps-f0215c58-195c-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021433773s
STEP: Saw pod success
Jan 16 07:04:20.817: INFO: Pod "pod-configmaps-f0215c58-195c-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 07:04:20.819: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-configmaps-f0215c58-195c-11e9-af83-025056002014 container env-test: <nil>
STEP: delete the pod
Jan 16 07:04:20.842: INFO: Waiting for pod pod-configmaps-f0215c58-195c-11e9-af83-025056002014 to disappear
Jan 16 07:04:20.852: INFO: Pod pod-configmaps-f0215c58-195c-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:04:20.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4w9mr" for this suite.
Jan 16 07:04:26.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:04:26.914: INFO: namespace: e2e-tests-secrets-4w9mr, resource: bindings, ignored listing per whitelist
Jan 16 07:04:26.990: INFO: namespace e2e-tests-secrets-4w9mr deletion completed in 6.128591392s

• [SLOW TEST:10.390 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:04:26.992: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-4dkwd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0116 07:04:37.303441      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 16 07:04:37.303: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:04:37.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4dkwd" for this suite.
Jan 16 07:04:43.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:04:43.380: INFO: namespace: e2e-tests-gc-4dkwd, resource: bindings, ignored listing per whitelist
Jan 16 07:04:43.419: INFO: namespace e2e-tests-gc-4dkwd deletion completed in 6.112057159s

• [SLOW TEST:16.427 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:04:43.419: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-n85cc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 16 07:04:43.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-n85cc'
Jan 16 07:04:44.549: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 16 07:04:44.549: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Jan 16 07:04:44.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-014349168 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-n85cc'
Jan 16 07:04:44.655: INFO: stderr: ""
Jan 16 07:04:44.655: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:04:44.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n85cc" for this suite.
Jan 16 07:05:06.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:05:06.825: INFO: namespace: e2e-tests-kubectl-n85cc, resource: bindings, ignored listing per whitelist
Jan 16 07:05:06.846: INFO: namespace e2e-tests-kubectl-n85cc deletion completed in 22.185139694s

• [SLOW TEST:23.427 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:05:06.847: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-r7fsg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0e1dce17-195d-11e9-af83-025056002014
STEP: Creating a pod to test consume configMaps
Jan 16 07:05:07.122: INFO: Waiting up to 5m0s for pod "pod-configmaps-0e1f7351-195d-11e9-af83-025056002014" in namespace "e2e-tests-configmap-r7fsg" to be "success or failure"
Jan 16 07:05:07.135: INFO: Pod "pod-configmaps-0e1f7351-195d-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 12.915079ms
Jan 16 07:05:09.139: INFO: Pod "pod-configmaps-0e1f7351-195d-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01715034s
Jan 16 07:05:11.143: INFO: Pod "pod-configmaps-0e1f7351-195d-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020876226s
Jan 16 07:05:13.147: INFO: Pod "pod-configmaps-0e1f7351-195d-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024801524s
Jan 16 07:05:15.150: INFO: Pod "pod-configmaps-0e1f7351-195d-11e9-af83-025056002014": Phase="Pending", Reason="", readiness=false. Elapsed: 8.028423691s
Jan 16 07:05:17.154: INFO: Pod "pod-configmaps-0e1f7351-195d-11e9-af83-025056002014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.031779852s
STEP: Saw pod success
Jan 16 07:05:17.154: INFO: Pod "pod-configmaps-0e1f7351-195d-11e9-af83-025056002014" satisfied condition "success or failure"
Jan 16 07:05:17.156: INFO: Trying to get logs from node d02c56a1-5f5a-4edd-b080-4296aa47afb8 pod pod-configmaps-0e1f7351-195d-11e9-af83-025056002014 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 16 07:05:17.182: INFO: Waiting for pod pod-configmaps-0e1f7351-195d-11e9-af83-025056002014 to disappear
Jan 16 07:05:17.185: INFO: Pod pod-configmaps-0e1f7351-195d-11e9-af83-025056002014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:05:17.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r7fsg" for this suite.
Jan 16 07:05:23.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:05:23.221: INFO: namespace: e2e-tests-configmap-r7fsg, resource: bindings, ignored listing per whitelist
Jan 16 07:05:23.290: INFO: namespace e2e-tests-configmap-r7fsg deletion completed in 6.101102606s

• [SLOW TEST:16.444 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 16 07:05:23.298: INFO: >>> kubeConfig: /tmp/kubeconfig-014349168
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-qx4sq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-qx4sq.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-qx4sq.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qx4sq.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-qx4sq.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-qx4sq.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qx4sq.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 16 07:05:41.622: INFO: DNS probes using e2e-tests-dns-qx4sq/dns-test-17e76b39-195d-11e9-af83-025056002014 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 16 07:05:41.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-qx4sq" for this suite.
Jan 16 07:05:47.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 16 07:05:47.677: INFO: namespace: e2e-tests-dns-qx4sq, resource: bindings, ignored listing per whitelist
Jan 16 07:05:47.750: INFO: namespace e2e-tests-dns-qx4sq deletion completed in 6.104471508s

• [SLOW TEST:24.452 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSJan 16 07:05:47.751: INFO: Running AfterSuite actions on all node
Jan 16 07:05:47.751: INFO: Running AfterSuite actions on node 1
Jan 16 07:05:47.751: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5835.325 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h37m16.236230804s
Test Suite Passed
