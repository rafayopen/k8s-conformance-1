Feb 22 20:55:23.447: INFO: Overriding default scale value of zero to 1
Feb 22 20:55:23.448: INFO: Overriding default milliseconds value of zero to 5000
I0222 20:55:24.577745      13 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-109334344
I0222 20:55:24.581276      13 e2e.go:304] Starting e2e run "2c332fdb-36e4-11e9-9d47-0276c9498759" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1550868923 - Will randomize all specs
Will run 188 of 1814 specs

Feb 22 20:55:25.121: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 20:55:25.124: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 22 20:55:25.164: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 22 20:55:25.212: INFO: The status of Pod rke-ingress-controller-deploy-job-lwzmk is Succeeded, skipping waiting
Feb 22 20:55:25.212: INFO: The status of Pod rke-kube-dns-addon-deploy-job-lknlp is Succeeded, skipping waiting
Feb 22 20:55:25.212: INFO: The status of Pod rke-metrics-addon-deploy-job-q9tzq is Succeeded, skipping waiting
Feb 22 20:55:25.212: INFO: The status of Pod rke-network-plugin-deploy-job-rnnp7 is Succeeded, skipping waiting
Feb 22 20:55:25.212: INFO: 6 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 22 20:55:25.212: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Feb 22 20:55:25.212: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 22 20:55:25.226: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Feb 22 20:55:25.226: INFO: e2e test version: v1.12.1
Feb 22 20:55:25.228: INFO: kube-apiserver version: v1.12.5
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 20:55:25.228: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
Feb 22 20:55:25.366: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-2d670167-36e4-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 20:55:25.424: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2d6a9a0c-36e4-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-hbgjk" to be "success or failure"
Feb 22 20:55:25.442: INFO: Pod "pod-projected-configmaps-2d6a9a0c-36e4-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 18.386763ms
Feb 22 20:55:27.450: INFO: Pod "pod-projected-configmaps-2d6a9a0c-36e4-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026030908s
Feb 22 20:55:29.455: INFO: Pod "pod-projected-configmaps-2d6a9a0c-36e4-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03152078s
STEP: Saw pod success
Feb 22 20:55:29.455: INFO: Pod "pod-projected-configmaps-2d6a9a0c-36e4-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 20:55:29.459: INFO: Trying to get logs from node conformance112-3 pod pod-projected-configmaps-2d6a9a0c-36e4-11e9-9d47-0276c9498759 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 20:55:29.508: INFO: Waiting for pod pod-projected-configmaps-2d6a9a0c-36e4-11e9-9d47-0276c9498759 to disappear
Feb 22 20:55:29.518: INFO: Pod pod-projected-configmaps-2d6a9a0c-36e4-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 20:55:29.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hbgjk" for this suite.
Feb 22 20:55:35.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 20:55:35.767: INFO: namespace: e2e-tests-projected-hbgjk, resource: bindings, ignored listing per whitelist
Feb 22 20:55:35.903: INFO: namespace e2e-tests-projected-hbgjk deletion completed in 6.377036822s

• [SLOW TEST:10.675 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 20:55:35.905: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 22 20:55:43.163: INFO: Successfully updated pod "labelsupdate33be99ca-36e4-11e9-9d47-0276c9498759"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 20:55:52.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xmzxv" for this suite.
Feb 22 20:56:14.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 20:56:14.643: INFO: namespace: e2e-tests-projected-xmzxv, resource: bindings, ignored listing per whitelist
Feb 22 20:56:14.748: INFO: namespace e2e-tests-projected-xmzxv deletion completed in 22.339784334s

• [SLOW TEST:38.844 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 20:56:14.750: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-c5rxv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 22 20:56:14.843: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 22 20:56:43.249: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.42.2.4 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-c5rxv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 20:56:43.249: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 20:56:44.497: INFO: Found all expected endpoints: [netserver-0]
Feb 22 20:56:44.505: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.42.1.5 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-c5rxv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 20:56:44.505: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 20:56:46.489: INFO: Found all expected endpoints: [netserver-1]
Feb 22 20:56:46.494: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.42.0.6 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-c5rxv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 20:56:46.494: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 20:56:47.767: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 20:56:47.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-c5rxv" for this suite.
Feb 22 20:57:11.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 20:57:11.848: INFO: namespace: e2e-tests-pod-network-test-c5rxv, resource: bindings, ignored listing per whitelist
Feb 22 20:57:11.987: INFO: namespace e2e-tests-pod-network-test-c5rxv deletion completed in 24.209609683s

• [SLOW TEST:57.237 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 20:57:11.992: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 22 20:57:12.105: INFO: Waiting up to 5m0s for pod "pod-6d0244c1-36e4-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-7bkmb" to be "success or failure"
Feb 22 20:57:12.121: INFO: Pod "pod-6d0244c1-36e4-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 16.426381ms
Feb 22 20:57:14.126: INFO: Pod "pod-6d0244c1-36e4-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020976009s
Feb 22 20:57:16.139: INFO: Pod "pod-6d0244c1-36e4-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03394971s
STEP: Saw pod success
Feb 22 20:57:16.139: INFO: Pod "pod-6d0244c1-36e4-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 20:57:16.142: INFO: Trying to get logs from node conformance112-3 pod pod-6d0244c1-36e4-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 20:57:16.195: INFO: Waiting for pod pod-6d0244c1-36e4-11e9-9d47-0276c9498759 to disappear
Feb 22 20:57:16.201: INFO: Pod pod-6d0244c1-36e4-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 20:57:16.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7bkmb" for this suite.
Feb 22 20:57:24.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 20:57:24.380: INFO: namespace: e2e-tests-emptydir-7bkmb, resource: bindings, ignored listing per whitelist
Feb 22 20:57:24.434: INFO: namespace e2e-tests-emptydir-7bkmb deletion completed in 8.228355673s

• [SLOW TEST:12.442 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 20:57:24.435: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-qvmjm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 22 20:57:24.554: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 22 20:57:48.772: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.6:8080/dial?request=hostName&protocol=http&host=10.42.1.8&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-qvmjm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 20:57:48.773: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 20:57:49.175: INFO: Waiting for endpoints: map[]
Feb 22 20:57:52.113: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.6:8080/dial?request=hostName&protocol=http&host=10.42.2.5&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-qvmjm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 20:57:52.113: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 20:57:52.331: INFO: Waiting for endpoints: map[]
Feb 22 20:57:55.132: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.6:8080/dial?request=hostName&protocol=http&host=10.42.0.7&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-qvmjm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 20:57:55.132: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 20:57:55.440: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 20:57:55.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-qvmjm" for this suite.
Feb 22 20:58:19.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 20:58:19.573: INFO: namespace: e2e-tests-pod-network-test-qvmjm, resource: bindings, ignored listing per whitelist
Feb 22 20:58:19.692: INFO: namespace e2e-tests-pod-network-test-qvmjm deletion completed in 24.229832581s

• [SLOW TEST:55.257 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 20:58:19.695: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-955e7e21-36e4-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 20:58:19.897: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9564c225-36e4-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-6vxbc" to be "success or failure"
Feb 22 20:58:19.911: INFO: Pod "pod-projected-configmaps-9564c225-36e4-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 13.736221ms
Feb 22 20:58:21.915: INFO: Pod "pod-projected-configmaps-9564c225-36e4-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018228417s
STEP: Saw pod success
Feb 22 20:58:21.915: INFO: Pod "pod-projected-configmaps-9564c225-36e4-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 20:58:21.919: INFO: Trying to get logs from node conformance112-2 pod pod-projected-configmaps-9564c225-36e4-11e9-9d47-0276c9498759 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 20:58:22.298: INFO: Waiting for pod pod-projected-configmaps-9564c225-36e4-11e9-9d47-0276c9498759 to disappear
Feb 22 20:58:22.303: INFO: Pod pod-projected-configmaps-9564c225-36e4-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 20:58:22.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6vxbc" for this suite.
Feb 22 20:58:28.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 20:58:28.402: INFO: namespace: e2e-tests-projected-6vxbc, resource: bindings, ignored listing per whitelist
Feb 22 20:58:28.525: INFO: namespace e2e-tests-projected-6vxbc deletion completed in 6.210279096s

• [SLOW TEST:8.831 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 20:58:28.527: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-46pw
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 20:58:28.656: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-46pw" in namespace "e2e-tests-subpath-jcb65" to be "success or failure"
Feb 22 20:58:28.663: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.942341ms
Feb 22 20:58:30.676: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020286656s
Feb 22 20:58:32.689: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033594293s
Feb 22 20:58:34.694: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Running", Reason="", readiness=false. Elapsed: 6.037710093s
Feb 22 20:58:36.698: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Running", Reason="", readiness=false. Elapsed: 8.042621067s
Feb 22 20:58:38.703: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Running", Reason="", readiness=false. Elapsed: 10.04760661s
Feb 22 20:58:40.719: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Running", Reason="", readiness=false. Elapsed: 12.062657049s
Feb 22 20:58:42.723: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Running", Reason="", readiness=false. Elapsed: 14.067194625s
Feb 22 20:58:44.731: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Running", Reason="", readiness=false. Elapsed: 16.07534256s
Feb 22 20:58:46.736: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Running", Reason="", readiness=false. Elapsed: 18.080364637s
Feb 22 20:58:48.742: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Running", Reason="", readiness=false. Elapsed: 20.08634122s
Feb 22 20:58:50.753: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Running", Reason="", readiness=false. Elapsed: 22.097268343s
Feb 22 20:58:52.758: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Running", Reason="", readiness=false. Elapsed: 24.102268411s
Feb 22 20:58:54.764: INFO: Pod "pod-subpath-test-configmap-46pw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.107717763s
STEP: Saw pod success
Feb 22 20:58:54.764: INFO: Pod "pod-subpath-test-configmap-46pw" satisfied condition "success or failure"
Feb 22 20:58:54.767: INFO: Trying to get logs from node conformance112-3 pod pod-subpath-test-configmap-46pw container test-container-subpath-configmap-46pw: <nil>
STEP: delete the pod
Feb 22 20:58:54.827: INFO: Waiting for pod pod-subpath-test-configmap-46pw to disappear
Feb 22 20:58:54.830: INFO: Pod pod-subpath-test-configmap-46pw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-46pw
Feb 22 20:58:54.831: INFO: Deleting pod "pod-subpath-test-configmap-46pw" in namespace "e2e-tests-subpath-jcb65"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 20:58:54.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jcb65" for this suite.
Feb 22 20:59:00.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 20:59:00.882: INFO: namespace: e2e-tests-subpath-jcb65, resource: bindings, ignored listing per whitelist
Feb 22 20:59:01.088: INFO: namespace e2e-tests-subpath-jcb65 deletion completed in 6.249432742s

• [SLOW TEST:32.561 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 20:59:01.091: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ae0ec15f-36e4-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 20:59:01.244: INFO: Waiting up to 5m0s for pod "pod-secrets-ae10db1a-36e4-11e9-9d47-0276c9498759" in namespace "e2e-tests-secrets-lmjlt" to be "success or failure"
Feb 22 20:59:01.252: INFO: Pod "pod-secrets-ae10db1a-36e4-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 7.840138ms
Feb 22 20:59:03.256: INFO: Pod "pod-secrets-ae10db1a-36e4-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012692763s
Feb 22 20:59:05.262: INFO: Pod "pod-secrets-ae10db1a-36e4-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017925758s
Feb 22 20:59:07.266: INFO: Pod "pod-secrets-ae10db1a-36e4-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02255675s
Feb 22 20:59:09.271: INFO: Pod "pod-secrets-ae10db1a-36e4-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.027036305s
STEP: Saw pod success
Feb 22 20:59:09.271: INFO: Pod "pod-secrets-ae10db1a-36e4-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 20:59:09.274: INFO: Trying to get logs from node conformance112-2 pod pod-secrets-ae10db1a-36e4-11e9-9d47-0276c9498759 container secret-env-test: <nil>
STEP: delete the pod
Feb 22 20:59:09.311: INFO: Waiting for pod pod-secrets-ae10db1a-36e4-11e9-9d47-0276c9498759 to disappear
Feb 22 20:59:09.326: INFO: Pod pod-secrets-ae10db1a-36e4-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 20:59:09.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lmjlt" for this suite.
Feb 22 20:59:15.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 20:59:15.545: INFO: namespace: e2e-tests-secrets-lmjlt, resource: bindings, ignored listing per whitelist
Feb 22 20:59:15.604: INFO: namespace e2e-tests-secrets-lmjlt deletion completed in 6.266994139s

• [SLOW TEST:14.514 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 20:59:15.607: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-b6b91c6d-36e4-11e9-9d47-0276c9498759
STEP: Creating configMap with name cm-test-opt-upd-b6b91cab-36e4-11e9-9d47-0276c9498759
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b6b91c6d-36e4-11e9-9d47-0276c9498759
STEP: Updating configmap cm-test-opt-upd-b6b91cab-36e4-11e9-9d47-0276c9498759
STEP: Creating configMap with name cm-test-opt-create-b6b91cc2-36e4-11e9-9d47-0276c9498759
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:00:29.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-97tjf" for this suite.
Feb 22 21:01:18.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:01:18.235: INFO: namespace: e2e-tests-projected-97tjf, resource: bindings, ignored listing per whitelist
Feb 22 21:01:18.336: INFO: namespace e2e-tests-projected-97tjf deletion completed in 48.550307421s

• [SLOW TEST:122.730 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:01:18.339: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:01:30.161: INFO: Waiting up to 5m0s for pod "downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-f42ql" to be "success or failure"
Feb 22 21:01:30.182: INFO: Pod "downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 20.363521ms
Feb 22 21:01:32.187: INFO: Pod "downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025594223s
Feb 22 21:01:36.829: INFO: Pod "downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 6.667644516s
Feb 22 21:01:38.834: INFO: Pod "downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 8.673039136s
Feb 22 21:01:40.839: INFO: Pod "downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 10.677645619s
Feb 22 21:01:43.136: INFO: Pod "downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 12.974807451s
Feb 22 21:01:49.281: INFO: Pod "downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 19.120098161s
Feb 22 21:01:54.123: INFO: Pod "downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.961735748s
STEP: Saw pod success
Feb 22 21:01:54.123: INFO: Pod "downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:01:54.137: INFO: Trying to get logs from node conformance112-2 pod downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 21:01:54.182: INFO: Waiting for pod downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759 to disappear
Feb 22 21:01:54.198: INFO: Pod downwardapi-volume-06b30ee3-36e5-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:01:54.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f42ql" for this suite.
Feb 22 21:04:37.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:05:30.155: INFO: namespace: e2e-tests-downward-api-f42ql, resource: bindings, ignored listing per whitelist
Feb 22 21:05:30.160: INFO: namespace e2e-tests-downward-api-f42ql deletion completed in 3m35.94171767s

• [SLOW TEST:251.822 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:05:30.162: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:05:36.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 version --client'
Feb 22 21:05:36.383: INFO: stderr: ""
Feb 22 21:05:36.383: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 22 21:05:36.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-n8lf5'
Feb 22 21:05:52.941: INFO: stderr: ""
Feb 22 21:05:52.941: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 22 21:05:52.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-n8lf5'
Feb 22 21:05:58.570: INFO: stderr: ""
Feb 22 21:05:58.570: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 22 21:06:00.050: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:06:00.050: INFO: Found 0 / 1
Feb 22 21:06:02.141: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:06:02.141: INFO: Found 0 / 1
Feb 22 21:06:04.582: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:06:04.582: INFO: Found 0 / 1
Feb 22 21:06:05.699: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:06:05.699: INFO: Found 0 / 1
Feb 22 21:06:06.575: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:06:06.575: INFO: Found 1 / 1
Feb 22 21:06:06.576: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 22 21:06:06.580: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:06:06.580: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 22 21:06:06.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 describe pod redis-master-6bsqb --namespace=e2e-tests-kubectl-n8lf5'
Feb 22 21:06:06.703: INFO: stderr: ""
Feb 22 21:06:06.703: INFO: stdout: "Name:               redis-master-6bsqb\nNamespace:          e2e-tests-kubectl-n8lf5\nPriority:           0\nPriorityClassName:  <none>\nNode:               conformance112-3/68.183.151.156\nStart Time:         Fri, 22 Feb 2019 21:05:58 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.42.1.10/32\nStatus:             Running\nIP:                 10.42.1.10\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://fbaaca63e219c48685526670ec4c7e112df6d90bf8a7bffd1383bb596669ba03\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 22 Feb 2019 21:06:05 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-hjpg5 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-hjpg5:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-hjpg5\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                       Message\n  ----    ------     ----  ----                       -------\n  Normal  Scheduled  8s    default-scheduler          Successfully assigned e2e-tests-kubectl-n8lf5/redis-master-6bsqb to conformance112-3\n  Normal  Pulling    7s    kubelet, conformance112-3  pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     2s    kubelet, conformance112-3  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, conformance112-3  Created container\n  Normal  Started    1s    kubelet, conformance112-3  Started container\n"
Feb 22 21:06:06.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 describe rc redis-master --namespace=e2e-tests-kubectl-n8lf5'
Feb 22 21:06:09.105: INFO: stderr: ""
Feb 22 21:06:09.105: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-n8lf5\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  11s   replication-controller  Created pod: redis-master-6bsqb\n"
Feb 22 21:06:09.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 describe service redis-master --namespace=e2e-tests-kubectl-n8lf5'
Feb 22 21:06:09.299: INFO: stderr: ""
Feb 22 21:06:09.299: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-n8lf5\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.43.74.255\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.42.1.10:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 22 21:06:12.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 describe node conformance112-1'
Feb 22 21:06:23.713: INFO: stderr: ""
Feb 22 21:06:23.713: INFO: stdout: "Name:               conformance112-1\nRoles:              controlplane,etcd,worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    cattle.io/creator=norman\n                    kubernetes.io/hostname=conformance112-1\n                    node-role.kubernetes.io/controlplane=true\n                    node-role.kubernetes.io/etcd=true\n                    node-role.kubernetes.io/worker=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"8e:c2:87:22:2b:7a\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 68.183.151.44\n                    node.alpha.kubernetes.io/ttl: 0\n                    rke.cattle.io/external-ip: 68.183.151.44\n                    rke.cattle.io/internal-ip: 68.183.151.44\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 22 Feb 2019 20:44:52 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Fri, 22 Feb 2019 21:06:22 +0000   Fri, 22 Feb 2019 20:44:52 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Fri, 22 Feb 2019 21:06:22 +0000   Fri, 22 Feb 2019 20:44:52 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 22 Feb 2019 21:06:22 +0000   Fri, 22 Feb 2019 20:44:52 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 22 Feb 2019 21:06:22 +0000   Fri, 22 Feb 2019 20:44:52 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 22 Feb 2019 21:06:22 +0000   Fri, 22 Feb 2019 20:45:42 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  68.183.151.44\n  Hostname:    conformance112-1\nCapacity:\n cpu:                1\n ephemeral-storage:  60795880Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3080328Ki\n pods:               110\nAllocatable:\n cpu:                1\n ephemeral-storage:  56029482916\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             2977928Ki\n pods:               110\nSystem Info:\n Machine ID:                 3e608929fbd39b959f388bf468c9f0b1\n System UUID:                572DBEF8-9788-49B7-B931-08DD675C823F\n Boot ID:                    f846be46-16e4-4afc-ac05-1b9ee70aad61\n Kernel Version:             4.4.0-142-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.2\n Kubelet Version:            v1.12.5\n Kube-Proxy Version:         v1.12.5\nPodCIDR:                     10.42.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  cattle-system              cattle-node-agent-52q4q                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  cattle-system              kube-api-auth-crl57                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-e2e-job-aabea1c863cb45f7                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-89b3526db0284161-hvxhg    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  ingress-nginx              nginx-ingress-controller-zzcwv                             0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                canal-fqx62                                                250m (25%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-dns-autoscaler-689f6f9756-f5x2h                       20m (2%)      0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                kube-dns-ddddcfcc8-9km9v                                   260m (26%)    0 (0%)      110Mi (3%)       170Mi (5%)\n  kube-system                metrics-server-5444cf6dfc-f7p26                            0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       530m (53%)  0 (0%)\n  memory    120Mi (4%)  170Mi (5%)\nEvents:\n  Type    Reason                   Age   From                          Message\n  ----    ------                   ----  ----                          -------\n  Normal  Starting                 21m   kubelet, conformance112-1     Starting kubelet.\n  Normal  NodeHasSufficientDisk    21m   kubelet, conformance112-1     Node conformance112-1 status is now: NodeHasSufficientDisk\n  Normal  NodeHasSufficientMemory  21m   kubelet, conformance112-1     Node conformance112-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    21m   kubelet, conformance112-1     Node conformance112-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     21m   kubelet, conformance112-1     Node conformance112-1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  21m   kubelet, conformance112-1     Updated Node Allocatable limit across pods\n  Normal  Starting                 21m   kube-proxy, conformance112-1  Starting kube-proxy.\n  Normal  NodeReady                20m   kubelet, conformance112-1     Node conformance112-1 status is now: NodeReady\n"
Feb 22 21:06:23.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 describe namespace e2e-tests-kubectl-n8lf5'
Feb 22 21:06:23.854: INFO: stderr: ""
Feb 22 21:06:23.854: INFO: stdout: "Name:         e2e-tests-kubectl-n8lf5\nLabels:       e2e-framework=kubectl\n              e2e-run=2c332fdb-36e4-11e9-9d47-0276c9498759\nAnnotations:  cattle.io/status:\n                {\"Conditions\":[{\"Type\":\"ResourceQuotaInit\",\"Status\":\"True\",\"Message\":\"\",\"LastUpdateTime\":\"2019-02-22T21:05:37Z\"},{\"Type\":\"InitialRolesPopu...\n              lifecycle.cattle.io/create.namespace-auth: true\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:06:23.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n8lf5" for this suite.
Feb 22 21:07:03.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:07:09.387: INFO: namespace: e2e-tests-kubectl-n8lf5, resource: bindings, ignored listing per whitelist
Feb 22 21:07:16.240: INFO: namespace e2e-tests-kubectl-n8lf5 deletion completed in 52.380741595s

• [SLOW TEST:106.078 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:07:16.241: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d52ca2eb-36e5-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 21:07:16.364: INFO: Waiting up to 5m0s for pod "pod-configmaps-d52e9747-36e5-11e9-9d47-0276c9498759" in namespace "e2e-tests-configmap-qg47b" to be "success or failure"
Feb 22 21:07:16.393: INFO: Pod "pod-configmaps-d52e9747-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 28.716773ms
Feb 22 21:07:18.453: INFO: Pod "pod-configmaps-d52e9747-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088539134s
Feb 22 21:07:22.020: INFO: Pod "pod-configmaps-d52e9747-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 5.655636625s
Feb 22 21:07:27.626: INFO: Pod "pod-configmaps-d52e9747-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 11.262284864s
Feb 22 21:07:32.671: INFO: Pod "pod-configmaps-d52e9747-36e5-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 16.306548252s
Feb 22 21:07:34.691: INFO: Pod "pod-configmaps-d52e9747-36e5-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.326533269s
STEP: Saw pod success
Feb 22 21:07:34.691: INFO: Pod "pod-configmaps-d52e9747-36e5-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:07:34.695: INFO: Trying to get logs from node conformance112-2 pod pod-configmaps-d52e9747-36e5-11e9-9d47-0276c9498759 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:07:34.745: INFO: Waiting for pod pod-configmaps-d52e9747-36e5-11e9-9d47-0276c9498759 to disappear
Feb 22 21:07:34.754: INFO: Pod pod-configmaps-d52e9747-36e5-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:07:34.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qg47b" for this suite.
Feb 22 21:08:08.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:08:08.652: INFO: namespace: e2e-tests-configmap-qg47b, resource: bindings, ignored listing per whitelist
Feb 22 21:08:08.800: INFO: namespace e2e-tests-configmap-qg47b deletion completed in 34.038458638s

• [SLOW TEST:52.559 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:08:08.802: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-hjp66
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-hjp66
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-hjp66
Feb 22 21:08:19.585: INFO: Found 0 stateful pods, waiting for 1
Feb 22 21:08:32.682: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 21:08:39.591: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 22 21:08:39.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-hjp66 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 21:08:40.229: INFO: stderr: ""
Feb 22 21:08:40.230: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 21:08:40.230: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 21:08:40.236: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 22 21:08:53.254: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 21:08:53.254: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 21:08:53.287: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999943s
Feb 22 21:08:54.471: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993639666s
Feb 22 21:08:56.032: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.809681393s
Feb 22 21:08:57.377: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.248845727s
Feb 22 21:08:59.006: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.903188349s
Feb 22 21:09:00.012: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.274853274s
Feb 22 21:09:01.863: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.268633069s
Feb 22 21:09:02.869: INFO: Verifying statefulset ss doesn't scale past 1 for another 417.830758ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-hjp66
Feb 22 21:09:08.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-hjp66 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 21:09:10.077: INFO: stderr: ""
Feb 22 21:09:10.077: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 21:09:10.077: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 21:09:10.082: INFO: Found 1 stateful pods, waiting for 3
Feb 22 21:09:22.317: INFO: Found 2 stateful pods, waiting for 3
Feb 22 21:09:30.184: INFO: Found 2 stateful pods, waiting for 3
Feb 22 21:09:40.097: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:09:40.097: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:09:40.097: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 21:09:50.932: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:09:50.932: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:09:50.933: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 22 21:09:50.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-hjp66 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 21:09:58.827: INFO: stderr: ""
Feb 22 21:09:58.827: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 21:09:58.827: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 21:09:58.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-hjp66 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 21:09:59.517: INFO: stderr: ""
Feb 22 21:09:59.517: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 21:09:59.517: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 21:09:59.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-hjp66 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 21:09:59.829: INFO: stderr: ""
Feb 22 21:09:59.829: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 21:09:59.829: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 21:09:59.829: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 21:09:59.834: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 22 21:10:11.588: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 21:10:11.588: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 21:10:11.588: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 21:10:12.775: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999257s
Feb 22 21:10:13.782: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988999151s
Feb 22 21:10:14.789: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982042929s
Feb 22 21:10:19.813: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.975521658s
Feb 22 21:10:20.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.951281406s
Feb 22 21:10:25.193: INFO: Verifying statefulset ss doesn't scale past 3 for another 945.799413ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-hjp66
Feb 22 21:10:27.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-hjp66 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 21:10:36.690: INFO: stderr: ""
Feb 22 21:10:36.690: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 21:10:36.690: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 21:10:36.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-hjp66 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 21:10:41.781: INFO: stderr: ""
Feb 22 21:10:41.781: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 21:10:41.781: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 21:10:41.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-hjp66 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 21:10:42.129: INFO: stderr: ""
Feb 22 21:10:42.129: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 21:10:42.129: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 21:10:42.129: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 22 21:14:02.328: INFO: Deleting all statefulset in ns e2e-tests-statefulset-hjp66
Feb 22 21:14:02.374: INFO: Scaling statefulset ss to 0
Feb 22 21:14:02.568: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 21:14:02.575: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:14:02.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-hjp66" for this suite.
Feb 22 21:14:20.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:14:20.833: INFO: namespace: e2e-tests-statefulset-hjp66, resource: bindings, ignored listing per whitelist
Feb 22 21:14:20.834: INFO: namespace e2e-tests-statefulset-hjp66 deletion completed in 18.210768198s

• [SLOW TEST:372.032 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:14:20.837: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-j4cqg/secret-test-db7663f4-36e6-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 21:14:36.632: INFO: Waiting up to 5m0s for pod "pod-configmaps-db95c507-36e6-11e9-9d47-0276c9498759" in namespace "e2e-tests-secrets-j4cqg" to be "success or failure"
Feb 22 21:14:36.650: INFO: Pod "pod-configmaps-db95c507-36e6-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 18.071602ms
Feb 22 21:14:41.489: INFO: Pod "pod-configmaps-db95c507-36e6-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 4.857237247s
Feb 22 21:14:47.290: INFO: Pod "pod-configmaps-db95c507-36e6-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.658386948s
STEP: Saw pod success
Feb 22 21:14:47.290: INFO: Pod "pod-configmaps-db95c507-36e6-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:14:53.062: INFO: Trying to get logs from node conformance112-3 pod pod-configmaps-db95c507-36e6-11e9-9d47-0276c9498759 container env-test: <nil>
STEP: delete the pod
Feb 22 21:14:53.120: INFO: Waiting for pod pod-configmaps-db95c507-36e6-11e9-9d47-0276c9498759 to disappear
Feb 22 21:14:53.142: INFO: Pod pod-configmaps-db95c507-36e6-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:14:53.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j4cqg" for this suite.
Feb 22 21:15:31.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:15:31.102: INFO: namespace: e2e-tests-secrets-j4cqg, resource: bindings, ignored listing per whitelist
Feb 22 21:15:31.242: INFO: namespace e2e-tests-secrets-j4cqg deletion completed in 38.094550341s

• [SLOW TEST:70.405 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:15:31.243: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-k6hvv/configmap-test-ffffdb07-36e6-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 21:15:41.377: INFO: Waiting up to 5m0s for pod "pod-configmaps-02122854-36e7-11e9-9d47-0276c9498759" in namespace "e2e-tests-configmap-k6hvv" to be "success or failure"
Feb 22 21:15:41.401: INFO: Pod "pod-configmaps-02122854-36e7-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 24.345197ms
Feb 22 21:15:49.265: INFO: Pod "pod-configmaps-02122854-36e7-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 7.887622539s
Feb 22 21:15:51.270: INFO: Pod "pod-configmaps-02122854-36e7-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 9.893376424s
Feb 22 21:16:03.988: INFO: Pod "pod-configmaps-02122854-36e7-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 22.610805375s
Feb 22 21:16:18.049: INFO: Pod "pod-configmaps-02122854-36e7-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 36.671584787s
STEP: Saw pod success
Feb 22 21:16:18.049: INFO: Pod "pod-configmaps-02122854-36e7-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:16:22.129: INFO: Trying to get logs from node conformance112-2 pod pod-configmaps-02122854-36e7-11e9-9d47-0276c9498759 container env-test: <nil>
STEP: delete the pod
Feb 22 21:16:22.235: INFO: Waiting for pod pod-configmaps-02122854-36e7-11e9-9d47-0276c9498759 to disappear
Feb 22 21:16:22.248: INFO: Pod pod-configmaps-02122854-36e7-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:16:22.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k6hvv" for this suite.
Feb 22 21:16:34.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:16:34.300: INFO: namespace: e2e-tests-configmap-k6hvv, resource: bindings, ignored listing per whitelist
Feb 22 21:16:34.441: INFO: namespace e2e-tests-configmap-k6hvv deletion completed in 12.188037459s

• [SLOW TEST:63.199 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:16:34.451: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 22 21:16:40.531: INFO: Waiting up to 5m0s for pod "downward-api-2571a35d-36e7-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-t6kkw" to be "success or failure"
Feb 22 21:16:40.543: INFO: Pod "downward-api-2571a35d-36e7-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 11.663861ms
Feb 22 21:16:42.547: INFO: Pod "downward-api-2571a35d-36e7-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016055627s
Feb 22 21:16:44.553: INFO: Pod "downward-api-2571a35d-36e7-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021160943s
Feb 22 21:16:51.453: INFO: Pod "downward-api-2571a35d-36e7-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 10.921885489s
Feb 22 21:16:57.891: INFO: Pod "downward-api-2571a35d-36e7-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 17.359937735s
STEP: Saw pod success
Feb 22 21:16:57.891: INFO: Pod "downward-api-2571a35d-36e7-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:16:57.903: INFO: Trying to get logs from node conformance112-3 pod downward-api-2571a35d-36e7-11e9-9d47-0276c9498759 container dapi-container: <nil>
STEP: delete the pod
Feb 22 21:16:57.955: INFO: Waiting for pod downward-api-2571a35d-36e7-11e9-9d47-0276c9498759 to disappear
Feb 22 21:16:57.965: INFO: Pod downward-api-2571a35d-36e7-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:16:57.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t6kkw" for this suite.
Feb 22 21:17:13.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:17:13.506: INFO: namespace: e2e-tests-downward-api-t6kkw, resource: bindings, ignored listing per whitelist
Feb 22 21:17:13.602: INFO: namespace e2e-tests-downward-api-t6kkw deletion completed in 15.632697304s

• [SLOW TEST:39.152 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:17:13.603: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 22 21:17:20.681: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-sw5xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-sw5xf/configmaps/e2e-watch-test-watch-closed,UID:3d5fcf0b-36e7-11e9-b930-96c406f7d171,ResourceVersion:4654,Generation:0,CreationTimestamp:2019-02-22 21:17:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 22 21:17:20.681: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-sw5xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-sw5xf/configmaps/e2e-watch-test-watch-closed,UID:3d5fcf0b-36e7-11e9-b930-96c406f7d171,ResourceVersion:4655,Generation:0,CreationTimestamp:2019-02-22 21:17:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 22 21:17:20.714: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-sw5xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-sw5xf/configmaps/e2e-watch-test-watch-closed,UID:3d5fcf0b-36e7-11e9-b930-96c406f7d171,ResourceVersion:4656,Generation:0,CreationTimestamp:2019-02-22 21:17:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 22 21:17:20.714: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-sw5xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-sw5xf/configmaps/e2e-watch-test-watch-closed,UID:3d5fcf0b-36e7-11e9-b930-96c406f7d171,ResourceVersion:4657,Generation:0,CreationTimestamp:2019-02-22 21:17:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:17:20.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-sw5xf" for this suite.
Feb 22 21:17:44.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:17:52.031: INFO: namespace: e2e-tests-watch-sw5xf, resource: bindings, ignored listing per whitelist
Feb 22 21:17:52.069: INFO: namespace e2e-tests-watch-sw5xf deletion completed in 31.348275395s

• [SLOW TEST:38.466 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:17:52.070: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:17:52.192: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Feb 22 21:17:52.209: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-ltp4f/daemonsets","resourceVersion":"4711"},"items":null}

Feb 22 21:17:52.216: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-ltp4f/pods","resourceVersion":"4712"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:17:52.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-ltp4f" for this suite.
Feb 22 21:18:03.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:18:04.314: INFO: namespace: e2e-tests-daemonsets-ltp4f, resource: bindings, ignored listing per whitelist
Feb 22 21:18:04.345: INFO: namespace e2e-tests-daemonsets-ltp4f deletion completed in 12.103441794s

S [SKIPPING] [12.275 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 22 21:17:52.192: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:18:04.347: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 21:18:05.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-vvrd7'
Feb 22 21:18:06.097: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 22 21:18:06.098: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Feb 22 21:18:10.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-vvrd7'
Feb 22 21:18:11.427: INFO: stderr: ""
Feb 22 21:18:11.427: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:18:11.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vvrd7" for this suite.
Feb 22 21:18:25.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:18:25.649: INFO: namespace: e2e-tests-kubectl-vvrd7, resource: bindings, ignored listing per whitelist
Feb 22 21:18:25.763: INFO: namespace e2e-tests-kubectl-vvrd7 deletion completed in 14.326122267s

• [SLOW TEST:21.416 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:18:25.764: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:18:25.855: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 22 21:18:25.877: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 22 21:18:31.646: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 22 21:18:34.780: INFO: Creating deployment "test-rolling-update-deployment"
Feb 22 21:18:34.804: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 22 21:18:34.839: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 22 21:18:43.541: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Feb 22 21:18:44.887: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 22 21:18:44.897: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467124, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:18:47.242: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467124, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:18:51.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467124, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:18:56.726: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467124, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:18:58.262: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467124, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:18:58.942: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467124, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:19:04.832: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467124, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467123, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:19:05.105: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 22 21:19:05.121: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-bwnqf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bwnqf/deployments/test-rolling-update-deployment,UID:69922113-36e7-11e9-b930-96c406f7d171,ResourceVersion:4902,Generation:1,CreationTimestamp:2019-02-22 21:18:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-22 21:18:43 +0000 UTC 2019-02-22 21:18:43 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-22 21:19:04 +0000 UTC 2019-02-22 21:18:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 22 21:19:05.128: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-bwnqf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bwnqf/replicasets/test-rolling-update-deployment-65b7695dcf,UID:6d70ce8f-36e7-11e9-9789-ee2871ff36f5,ResourceVersion:4889,Generation:1,CreationTimestamp:2019-02-22 21:18:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 69922113-36e7-11e9-b930-96c406f7d171 0xc421b42127 0xc421b42128}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 22 21:19:05.128: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 22 21:19:05.129: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-bwnqf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bwnqf/replicasets/test-rolling-update-controller,UID:643f3114-36e7-11e9-b930-96c406f7d171,ResourceVersion:4901,Generation:2,CreationTimestamp:2019-02-22 21:18:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 69922113-36e7-11e9-b930-96c406f7d171 0xc421b42077 0xc421b42078}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 21:19:05.139: INFO: Pod "test-rolling-update-deployment-65b7695dcf-hf9ck" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-hf9ck,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-bwnqf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bwnqf/pods/test-rolling-update-deployment-65b7695dcf-hf9ck,UID:6f302d2d-36e7-11e9-9789-ee2871ff36f5,ResourceVersion:4886,Generation:0,CreationTimestamp:2019-02-22 21:18:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.16/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 6d70ce8f-36e7-11e9-9789-ee2871ff36f5 0xc421b42967 0xc421b42968}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-v68bc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-v68bc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-v68bc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b429e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b42a00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:18:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:18:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:18:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:18:44 +0000 UTC  }],Message:,Reason:,HostIP:142.93.77.213,PodIP:10.42.2.16,StartTime:2019-02-22 21:18:44 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-22 21:18:57 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://cfbbce95804db3e8b11a7db28a40529d42104fc805c65ce25b7e5cbc48cce993}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:19:05.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bwnqf" for this suite.
Feb 22 21:19:24.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:19:31.921: INFO: namespace: e2e-tests-deployment-bwnqf, resource: bindings, ignored listing per whitelist
Feb 22 21:19:39.984: INFO: namespace e2e-tests-deployment-bwnqf deletion completed in 34.835319361s

• [SLOW TEST:74.219 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:19:39.984: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 22 21:20:07.572: INFO: Pod pod-hostip-915550a9-36e7-11e9-9d47-0276c9498759 has hostIP: 68.183.151.156
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:20:07.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-m2nlc" for this suite.
Feb 22 21:20:54.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:20:54.195: INFO: namespace: e2e-tests-pods-m2nlc, resource: bindings, ignored listing per whitelist
Feb 22 21:20:54.327: INFO: namespace e2e-tests-pods-m2nlc deletion completed in 44.312826379s

• [SLOW TEST:74.343 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:20:54.329: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 22 21:21:00.712: INFO: Waiting up to 5m0s for pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-2tqvh" in namespace "e2e-tests-svcaccounts-6cvlh" to be "success or failure"
Feb 22 21:21:00.725: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-2tqvh": Phase="Pending", Reason="", readiness=false. Elapsed: 13.204428ms
Feb 22 21:21:06.022: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-2tqvh": Phase="Pending", Reason="", readiness=false. Elapsed: 5.30977065s
Feb 22 21:21:08.029: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-2tqvh": Phase="Pending", Reason="", readiness=false. Elapsed: 7.317036941s
Feb 22 21:21:10.036: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-2tqvh": Phase="Pending", Reason="", readiness=false. Elapsed: 9.324101441s
Feb 22 21:21:15.070: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-2tqvh": Phase="Pending", Reason="", readiness=false. Elapsed: 14.358148317s
Feb 22 21:21:17.077: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-2tqvh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.364993391s
STEP: Saw pod success
Feb 22 21:21:17.077: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-2tqvh" satisfied condition "success or failure"
Feb 22 21:21:17.085: INFO: Trying to get logs from node conformance112-3 pod pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-2tqvh container token-test: <nil>
STEP: delete the pod
Feb 22 21:21:23.302: INFO: Waiting for pod pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-2tqvh to disappear
Feb 22 21:21:23.307: INFO: Pod pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-2tqvh no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 22 21:21:23.338: INFO: Waiting up to 5m0s for pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-cvzkh" in namespace "e2e-tests-svcaccounts-6cvlh" to be "success or failure"
Feb 22 21:21:23.361: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-cvzkh": Phase="Pending", Reason="", readiness=false. Elapsed: 23.112277ms
Feb 22 21:21:28.782: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-cvzkh": Phase="Pending", Reason="", readiness=false. Elapsed: 5.444724597s
Feb 22 21:21:31.945: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-cvzkh": Phase="Pending", Reason="", readiness=false. Elapsed: 8.607493995s
Feb 22 21:21:34.917: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-cvzkh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 11.579282375s
STEP: Saw pod success
Feb 22 21:21:34.917: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-cvzkh" satisfied condition "success or failure"
Feb 22 21:21:34.932: INFO: Trying to get logs from node conformance112-1 pod pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-cvzkh container root-ca-test: <nil>
STEP: delete the pod
Feb 22 21:21:35.640: INFO: Waiting for pod pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-cvzkh to disappear
Feb 22 21:21:35.646: INFO: Pod pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-cvzkh no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 22 21:21:35.667: INFO: Waiting up to 5m0s for pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-7btfg" in namespace "e2e-tests-svcaccounts-6cvlh" to be "success or failure"
Feb 22 21:21:35.697: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-7btfg": Phase="Pending", Reason="", readiness=false. Elapsed: 30.210673ms
Feb 22 21:21:37.704: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-7btfg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037281653s
Feb 22 21:21:39.724: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-7btfg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057271318s
Feb 22 21:21:41.829: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-7btfg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.162157523s
STEP: Saw pod success
Feb 22 21:21:41.830: INFO: Pod "pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-7btfg" satisfied condition "success or failure"
Feb 22 21:21:41.848: INFO: Trying to get logs from node conformance112-3 pod pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-7btfg container namespace-test: <nil>
STEP: delete the pod
Feb 22 21:21:42.513: INFO: Waiting for pod pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-7btfg to disappear
Feb 22 21:21:42.523: INFO: Pod pod-service-account-c0873366-36e7-11e9-9d47-0276c9498759-7btfg no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:21:42.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-6cvlh" for this suite.
Feb 22 21:22:03.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:22:03.538: INFO: namespace: e2e-tests-svcaccounts-6cvlh, resource: bindings, ignored listing per whitelist
Feb 22 21:22:03.672: INFO: namespace e2e-tests-svcaccounts-6cvlh deletion completed in 14.283171169s

• [SLOW TEST:69.343 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:22:03.676: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-e6313d21-36e7-11e9-9d47-0276c9498759
STEP: Creating secret with name s-test-opt-upd-e6314075-36e7-11e9-9d47-0276c9498759
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e6313d21-36e7-11e9-9d47-0276c9498759
STEP: Updating secret s-test-opt-upd-e6314075-36e7-11e9-9d47-0276c9498759
STEP: Creating secret with name s-test-opt-create-e63140c7-36e7-11e9-9d47-0276c9498759
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:23:41.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gnrtz" for this suite.
Feb 22 21:24:07.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:24:07.396: INFO: namespace: e2e-tests-secrets-gnrtz, resource: bindings, ignored listing per whitelist
Feb 22 21:24:11.531: INFO: namespace e2e-tests-secrets-gnrtz deletion completed in 30.264471996s

• [SLOW TEST:127.856 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:24:11.540: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-fbkq4
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 22 21:24:11.723: INFO: Found 0 stateful pods, waiting for 3
Feb 22 21:24:21.741: INFO: Found 2 stateful pods, waiting for 3
Feb 22 21:24:32.003: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:24:32.003: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:24:32.003: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 22 21:24:32.428: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 22 21:24:43.271: INFO: Updating stateful set ss2
Feb 22 21:24:43.288: INFO: Waiting for Pod e2e-tests-statefulset-fbkq4/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 22 21:24:53.749: INFO: Found 2 stateful pods, waiting for 3
Feb 22 21:25:03.762: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:25:03.762: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:25:03.762: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 21:25:13.760: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:25:13.760: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:25:13.761: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 22 21:25:13.814: INFO: Updating stateful set ss2
Feb 22 21:25:13.862: INFO: Waiting for Pod e2e-tests-statefulset-fbkq4/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 22 21:25:23.942: INFO: Updating stateful set ss2
Feb 22 21:25:23.974: INFO: Waiting for StatefulSet e2e-tests-statefulset-fbkq4/ss2 to complete update
Feb 22 21:25:23.975: INFO: Waiting for Pod e2e-tests-statefulset-fbkq4/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 22 21:25:34.004: INFO: Waiting for StatefulSet e2e-tests-statefulset-fbkq4/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 22 21:25:43.986: INFO: Deleting all statefulset in ns e2e-tests-statefulset-fbkq4
Feb 22 21:25:43.991: INFO: Scaling statefulset ss2 to 0
Feb 22 21:26:14.050: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 21:26:14.056: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:26:14.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-fbkq4" for this suite.
Feb 22 21:26:24.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:26:24.227: INFO: namespace: e2e-tests-statefulset-fbkq4, resource: bindings, ignored listing per whitelist
Feb 22 21:26:28.678: INFO: namespace e2e-tests-statefulset-fbkq4 deletion completed in 14.560153289s

• [SLOW TEST:137.139 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:26:28.680: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-843f408a-36e8-11e9-9d47-0276c9498759
STEP: Creating configMap with name cm-test-opt-upd-843f40da-36e8-11e9-9d47-0276c9498759
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-843f408a-36e8-11e9-9d47-0276c9498759
STEP: Updating configmap cm-test-opt-upd-843f40da-36e8-11e9-9d47-0276c9498759
STEP: Creating configMap with name cm-test-opt-create-843f40fc-36e8-11e9-9d47-0276c9498759
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:27:38.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h5xm8" for this suite.
Feb 22 21:28:04.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:28:04.499: INFO: namespace: e2e-tests-configmap-h5xm8, resource: bindings, ignored listing per whitelist
Feb 22 21:28:04.885: INFO: namespace e2e-tests-configmap-h5xm8 deletion completed in 26.612175317s

• [SLOW TEST:96.206 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:28:04.887: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:28:05.309: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"bd8e243d-36e8-11e9-b930-96c406f7d171", Controller:(*bool)(0xc421562432), BlockOwnerDeletion:(*bool)(0xc421562433)}}
Feb 22 21:28:05.514: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"bd82c5c5-36e8-11e9-b930-96c406f7d171", Controller:(*bool)(0xc4215627a6), BlockOwnerDeletion:(*bool)(0xc4215627a7)}}
Feb 22 21:28:05.591: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"bd860d51-36e8-11e9-b930-96c406f7d171", Controller:(*bool)(0xc421562a76), BlockOwnerDeletion:(*bool)(0xc421562a77)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:28:10.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ktzmn" for this suite.
Feb 22 21:28:22.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:28:22.551: INFO: namespace: e2e-tests-gc-ktzmn, resource: bindings, ignored listing per whitelist
Feb 22 21:28:22.665: INFO: namespace e2e-tests-gc-ktzmn deletion completed in 8.34419037s

• [SLOW TEST:17.779 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:28:22.667: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0222 21:28:53.598740      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 21:28:53.598: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:28:53.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wcxdt" for this suite.
Feb 22 21:29:01.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:29:02.123: INFO: namespace: e2e-tests-gc-wcxdt, resource: bindings, ignored listing per whitelist
Feb 22 21:29:02.200: INFO: namespace e2e-tests-gc-wcxdt deletion completed in 8.595391418s

• [SLOW TEST:39.534 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:29:02.203: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 22 21:29:07.112: INFO: Successfully updated pod "pod-update-dfb1180f-36e8-11e9-9d47-0276c9498759"
STEP: verifying the updated pod is in kubernetes
Feb 22 21:29:07.154: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:29:07.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9lq86" for this suite.
Feb 22 21:29:38.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:29:38.373: INFO: namespace: e2e-tests-pods-9lq86, resource: bindings, ignored listing per whitelist
Feb 22 21:29:38.454: INFO: namespace e2e-tests-pods-9lq86 deletion completed in 28.457321451s

• [SLOW TEST:36.251 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:29:38.455: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:29:38.668: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f53f78b3-36e8-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-9ghcb" to be "success or failure"
Feb 22 21:29:38.720: INFO: Pod "downwardapi-volume-f53f78b3-36e8-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 51.7244ms
Feb 22 21:29:40.728: INFO: Pod "downwardapi-volume-f53f78b3-36e8-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060256402s
Feb 22 21:29:42.737: INFO: Pod "downwardapi-volume-f53f78b3-36e8-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069291284s
STEP: Saw pod success
Feb 22 21:29:42.737: INFO: Pod "downwardapi-volume-f53f78b3-36e8-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:29:42.762: INFO: Trying to get logs from node conformance112-3 pod downwardapi-volume-f53f78b3-36e8-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 21:29:42.884: INFO: Waiting for pod downwardapi-volume-f53f78b3-36e8-11e9-9d47-0276c9498759 to disappear
Feb 22 21:29:42.926: INFO: Pod downwardapi-volume-f53f78b3-36e8-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:29:42.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9ghcb" for this suite.
Feb 22 21:29:48.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:29:49.303: INFO: namespace: e2e-tests-projected-9ghcb, resource: bindings, ignored listing per whitelist
Feb 22 21:29:49.513: INFO: namespace e2e-tests-projected-9ghcb deletion completed in 6.57863428s

• [SLOW TEST:11.059 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:29:49.519: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:29:49.732: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fbd5d5c0-36e8-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-fsdhk" to be "success or failure"
Feb 22 21:29:49.759: INFO: Pod "downwardapi-volume-fbd5d5c0-36e8-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 26.161745ms
Feb 22 21:29:51.766: INFO: Pod "downwardapi-volume-fbd5d5c0-36e8-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033713144s
Feb 22 21:29:53.785: INFO: Pod "downwardapi-volume-fbd5d5c0-36e8-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052625529s
STEP: Saw pod success
Feb 22 21:29:53.785: INFO: Pod "downwardapi-volume-fbd5d5c0-36e8-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:29:53.791: INFO: Trying to get logs from node conformance112-2 pod downwardapi-volume-fbd5d5c0-36e8-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 21:29:55.376: INFO: Waiting for pod downwardapi-volume-fbd5d5c0-36e8-11e9-9d47-0276c9498759 to disappear
Feb 22 21:29:55.414: INFO: Pod downwardapi-volume-fbd5d5c0-36e8-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:29:55.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fsdhk" for this suite.
Feb 22 21:30:03.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:30:03.678: INFO: namespace: e2e-tests-downward-api-fsdhk, resource: bindings, ignored listing per whitelist
Feb 22 21:30:03.858: INFO: namespace e2e-tests-downward-api-fsdhk deletion completed in 8.408045502s

• [SLOW TEST:14.340 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:30:03.861: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 22 21:30:04.276: INFO: Waiting up to 5m0s for pod "var-expansion-047f831f-36e9-11e9-9d47-0276c9498759" in namespace "e2e-tests-var-expansion-hcltm" to be "success or failure"
Feb 22 21:30:04.356: INFO: Pod "var-expansion-047f831f-36e9-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 80.049572ms
Feb 22 21:30:06.383: INFO: Pod "var-expansion-047f831f-36e9-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106717456s
Feb 22 21:30:08.392: INFO: Pod "var-expansion-047f831f-36e9-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.115403968s
STEP: Saw pod success
Feb 22 21:30:08.392: INFO: Pod "var-expansion-047f831f-36e9-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:30:08.399: INFO: Trying to get logs from node conformance112-3 pod var-expansion-047f831f-36e9-11e9-9d47-0276c9498759 container dapi-container: <nil>
STEP: delete the pod
Feb 22 21:30:08.536: INFO: Waiting for pod var-expansion-047f831f-36e9-11e9-9d47-0276c9498759 to disappear
Feb 22 21:30:08.596: INFO: Pod var-expansion-047f831f-36e9-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:30:08.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-hcltm" for this suite.
Feb 22 21:30:16.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:30:16.707: INFO: namespace: e2e-tests-var-expansion-hcltm, resource: bindings, ignored listing per whitelist
Feb 22 21:30:16.976: INFO: namespace e2e-tests-var-expansion-hcltm deletion completed in 8.369889652s

• [SLOW TEST:13.116 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:30:16.980: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:30:17.272: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 22 21:30:22.293: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 22 21:30:22.293: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 22 21:30:24.311: INFO: Creating deployment "test-rollover-deployment"
Feb 22 21:30:24.345: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 22 21:30:28.714: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 22 21:30:28.788: INFO: Ensure that both replica sets have 1 created replica
Feb 22 21:30:28.868: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 22 21:30:29.075: INFO: Updating deployment test-rollover-deployment
Feb 22 21:30:29.075: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 22 21:30:31.098: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 22 21:30:31.115: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 22 21:30:31.138: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:30:31.139: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467829, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:30:36.031: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:30:36.031: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467829, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:30:37.151: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:30:37.152: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467829, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:30:39.175: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:30:39.175: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467837, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:30:41.182: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:30:41.182: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467837, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:30:43.151: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:30:43.151: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467837, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:30:45.161: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:30:45.162: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467837, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:30:48.485: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 21:30:48.485: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467837, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686467824, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 21:30:49.262: INFO: 
Feb 22 21:30:49.263: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 22 21:30:49.302: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-l2skp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-l2skp/deployments/test-rollover-deployment,UID:107b2dbe-36e9-11e9-b930-96c406f7d171,ResourceVersion:6821,Generation:2,CreationTimestamp:2019-02-22 21:30:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-22 21:30:24 +0000 UTC 2019-02-22 21:30:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-22 21:30:48 +0000 UTC 2019-02-22 21:30:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 22 21:30:49.311: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-l2skp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-l2skp/replicasets/test-rollover-deployment-5b76ff8c4,UID:1350006c-36e9-11e9-b930-96c406f7d171,ResourceVersion:6811,Generation:2,CreationTimestamp:2019-02-22 21:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 107b2dbe-36e9-11e9-b930-96c406f7d171 0xc4213cf147 0xc4213cf148}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 22 21:30:49.311: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 22 21:30:49.312: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-l2skp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-l2skp/replicasets/test-rollover-controller,UID:0c4393ca-36e9-11e9-b930-96c406f7d171,ResourceVersion:6819,Generation:2,CreationTimestamp:2019-02-22 21:30:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 107b2dbe-36e9-11e9-b930-96c406f7d171 0xc4213cf08e 0xc4213cf08f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 21:30:49.312: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-l2skp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-l2skp/replicasets/test-rollover-deployment-6975f4fb87,UID:1086d7b7-36e9-11e9-b930-96c406f7d171,ResourceVersion:6774,Generation:2,CreationTimestamp:2019-02-22 21:30:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 107b2dbe-36e9-11e9-b930-96c406f7d171 0xc4213cf1f7 0xc4213cf1f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 21:30:49.327: INFO: Pod "test-rollover-deployment-5b76ff8c4-jlgc5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-jlgc5,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-l2skp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-l2skp/pods/test-rollover-deployment-5b76ff8c4-jlgc5,UID:136346cc-36e9-11e9-b930-96c406f7d171,ResourceVersion:6790,Generation:0,CreationTimestamp:2019-02-22 21:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.26/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 1350006c-36e9-11e9-b930-96c406f7d171 0xc4213cfcd0 0xc4213cfcd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jk848 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jk848,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-jk848 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4213cfd40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4213cfd60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:30:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:30:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:30:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:30:29 +0000 UTC  }],Message:,Reason:,HostIP:142.93.77.213,PodIP:10.42.2.26,StartTime:2019-02-22 21:30:29 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-22 21:30:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://847cf3a936b24543fda88b90cd7937cd5ce4558381ac67f2a8f66e1d904e3104}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:30:49.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-l2skp" for this suite.
Feb 22 21:30:57.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:30:57.485: INFO: namespace: e2e-tests-deployment-l2skp, resource: bindings, ignored listing per whitelist
Feb 22 21:30:57.789: INFO: namespace e2e-tests-deployment-l2skp deletion completed in 8.447523095s

• [SLOW TEST:40.810 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:30:57.792: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 22 21:30:58.230: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-8n5vx" to be "success or failure"
Feb 22 21:30:58.307: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 76.447941ms
Feb 22 21:31:00.327: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.096571273s
Feb 22 21:31:02.405: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.174862285s
STEP: Saw pod success
Feb 22 21:31:02.405: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 22 21:31:02.431: INFO: Trying to get logs from node conformance112-3 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 22 21:31:02.541: INFO: Waiting for pod pod-host-path-test to disappear
Feb 22 21:31:02.554: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:31:02.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-8n5vx" for this suite.
Feb 22 21:31:10.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:31:10.777: INFO: namespace: e2e-tests-hostpath-8n5vx, resource: bindings, ignored listing per whitelist
Feb 22 21:31:10.978: INFO: namespace e2e-tests-hostpath-8n5vx deletion completed in 8.398048672s

• [SLOW TEST:13.186 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:31:10.980: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 21:31:11.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-qb4x8'
Feb 22 21:31:11.877: INFO: stderr: ""
Feb 22 21:31:11.877: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 22 21:31:21.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-qb4x8 -o json'
Feb 22 21:31:22.485: INFO: stderr: ""
Feb 22 21:31:22.485: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.42.2.27/32\"\n        },\n        \"creationTimestamp\": \"2019-02-22T21:31:11Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-qb4x8\",\n        \"resourceVersion\": \"6954\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-qb4x8/pods/e2e-test-nginx-pod\",\n        \"uid\": \"2cc59a1b-36e9-11e9-b930-96c406f7d171\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-sd72r\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"conformance112-2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-sd72r\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-sd72r\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-22T21:31:11Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-22T21:31:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-22T21:31:15Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-22T21:31:11Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://4d51efa4da67b7fd0eebdaa5de7638c32ec86f2dfae9e626aa30f4958cc05d97\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-22T21:31:14Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"142.93.77.213\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.2.27\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-22T21:31:11Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 22 21:31:22.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 replace -f - --namespace=e2e-tests-kubectl-qb4x8'
Feb 22 21:31:22.868: INFO: stderr: ""
Feb 22 21:31:22.868: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Feb 22 21:31:22.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-qb4x8'
Feb 22 21:31:33.053: INFO: stderr: ""
Feb 22 21:31:33.053: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:31:33.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qb4x8" for this suite.
Feb 22 21:31:43.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:31:43.534: INFO: namespace: e2e-tests-kubectl-qb4x8, resource: bindings, ignored listing per whitelist
Feb 22 21:31:43.571: INFO: namespace e2e-tests-kubectl-qb4x8 deletion completed in 10.447056049s

• [SLOW TEST:32.592 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:31:43.575: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 22 21:31:43.834: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:31:54.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-jwn2f" for this suite.
Feb 22 21:32:02.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:32:02.564: INFO: namespace: e2e-tests-init-container-jwn2f, resource: bindings, ignored listing per whitelist
Feb 22 21:32:02.774: INFO: namespace e2e-tests-init-container-jwn2f deletion completed in 8.514517603s

• [SLOW TEST:19.200 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:32:02.777: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-sj92t
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-sj92t
STEP: Deleting pre-stop pod
Feb 22 21:32:21.777: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:32:26.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-sj92t" for this suite.
Feb 22 21:33:10.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:33:10.591: INFO: namespace: e2e-tests-prestop-sj92t, resource: bindings, ignored listing per whitelist
Feb 22 21:33:10.838: INFO: namespace e2e-tests-prestop-sj92t deletion completed in 44.573282793s

• [SLOW TEST:68.061 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:33:10.842: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-73e04e83-36e9-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 21:33:11.213: INFO: Waiting up to 5m0s for pod "pod-configmaps-73e4d520-36e9-11e9-9d47-0276c9498759" in namespace "e2e-tests-configmap-qqxbg" to be "success or failure"
Feb 22 21:33:11.265: INFO: Pod "pod-configmaps-73e4d520-36e9-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 52.00143ms
Feb 22 21:33:13.467: INFO: Pod "pod-configmaps-73e4d520-36e9-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.254212574s
Feb 22 21:33:19.075: INFO: Pod "pod-configmaps-73e4d520-36e9-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 7.861469816s
Feb 22 21:33:21.101: INFO: Pod "pod-configmaps-73e4d520-36e9-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.887627489s
STEP: Saw pod success
Feb 22 21:33:21.101: INFO: Pod "pod-configmaps-73e4d520-36e9-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:33:21.109: INFO: Trying to get logs from node conformance112-2 pod pod-configmaps-73e4d520-36e9-11e9-9d47-0276c9498759 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:33:22.023: INFO: Waiting for pod pod-configmaps-73e4d520-36e9-11e9-9d47-0276c9498759 to disappear
Feb 22 21:33:22.059: INFO: Pod pod-configmaps-73e4d520-36e9-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:33:22.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qqxbg" for this suite.
Feb 22 21:33:28.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:33:29.091: INFO: namespace: e2e-tests-configmap-qqxbg, resource: bindings, ignored listing per whitelist
Feb 22 21:33:29.100: INFO: namespace e2e-tests-configmap-qqxbg deletion completed in 7.001962245s

• [SLOW TEST:18.258 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:33:29.101: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:33:29.429: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 22 21:33:29.466: INFO: Number of nodes with available pods: 0
Feb 22 21:33:29.466: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 22 21:33:29.622: INFO: Number of nodes with available pods: 0
Feb 22 21:33:29.622: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:35.376: INFO: Number of nodes with available pods: 0
Feb 22 21:33:35.376: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:35.725: INFO: Number of nodes with available pods: 0
Feb 22 21:33:35.725: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:36.644: INFO: Number of nodes with available pods: 0
Feb 22 21:33:36.644: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:37.636: INFO: Number of nodes with available pods: 0
Feb 22 21:33:37.636: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:38.639: INFO: Number of nodes with available pods: 1
Feb 22 21:33:38.639: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 22 21:33:42.294: INFO: Number of nodes with available pods: 1
Feb 22 21:33:42.294: INFO: Number of running nodes: 0, number of available pods: 1
Feb 22 21:33:43.305: INFO: Number of nodes with available pods: 0
Feb 22 21:33:43.305: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 22 21:33:43.390: INFO: Number of nodes with available pods: 0
Feb 22 21:33:43.391: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:44.422: INFO: Number of nodes with available pods: 0
Feb 22 21:33:44.422: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:45.400: INFO: Number of nodes with available pods: 0
Feb 22 21:33:45.400: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:46.424: INFO: Number of nodes with available pods: 0
Feb 22 21:33:46.424: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:50.170: INFO: Number of nodes with available pods: 0
Feb 22 21:33:50.170: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:50.400: INFO: Number of nodes with available pods: 0
Feb 22 21:33:50.400: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:51.401: INFO: Number of nodes with available pods: 0
Feb 22 21:33:51.401: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:52.402: INFO: Number of nodes with available pods: 0
Feb 22 21:33:52.402: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:53.397: INFO: Number of nodes with available pods: 0
Feb 22 21:33:53.397: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:54.434: INFO: Number of nodes with available pods: 0
Feb 22 21:33:54.434: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:55.399: INFO: Number of nodes with available pods: 0
Feb 22 21:33:55.399: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:57.843: INFO: Number of nodes with available pods: 0
Feb 22 21:33:57.843: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:33:58.425: INFO: Number of nodes with available pods: 0
Feb 22 21:33:58.425: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:00.031: INFO: Number of nodes with available pods: 0
Feb 22 21:34:00.032: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:00.417: INFO: Number of nodes with available pods: 0
Feb 22 21:34:00.418: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:01.398: INFO: Number of nodes with available pods: 0
Feb 22 21:34:01.398: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:07.696: INFO: Number of nodes with available pods: 0
Feb 22 21:34:07.696: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:08.401: INFO: Number of nodes with available pods: 0
Feb 22 21:34:08.401: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:10.401: INFO: Number of nodes with available pods: 0
Feb 22 21:34:10.401: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:11.401: INFO: Number of nodes with available pods: 0
Feb 22 21:34:11.401: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:12.404: INFO: Number of nodes with available pods: 0
Feb 22 21:34:12.404: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:13.405: INFO: Number of nodes with available pods: 0
Feb 22 21:34:13.405: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:15.885: INFO: Number of nodes with available pods: 0
Feb 22 21:34:15.885: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:17.463: INFO: Number of nodes with available pods: 0
Feb 22 21:34:17.463: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:18.420: INFO: Number of nodes with available pods: 0
Feb 22 21:34:18.420: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:19.454: INFO: Number of nodes with available pods: 0
Feb 22 21:34:19.456: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:23.528: INFO: Number of nodes with available pods: 0
Feb 22 21:34:23.529: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:34:24.426: INFO: Number of nodes with available pods: 1
Feb 22 21:34:24.426: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-hxr84, will wait for the garbage collector to delete the pods
Feb 22 21:34:24.530: INFO: Deleting {extensions DaemonSet} daemon-set took: 34.724249ms
Feb 22 21:34:24.654: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 124.12837ms
Feb 22 21:35:04.392: INFO: Number of nodes with available pods: 0
Feb 22 21:35:04.392: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 21:35:04.398: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hxr84/daemonsets","resourceVersion":"7461"},"items":null}

Feb 22 21:35:04.406: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hxr84/pods","resourceVersion":"7461"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:35:04.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hxr84" for this suite.
Feb 22 21:35:14.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:35:14.717: INFO: namespace: e2e-tests-daemonsets-hxr84, resource: bindings, ignored listing per whitelist
Feb 22 21:35:14.923: INFO: namespace e2e-tests-daemonsets-hxr84 deletion completed in 10.379464482s

• [SLOW TEST:105.822 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:35:14.925: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 22 21:35:15.252: INFO: Waiting up to 5m0s for pod "pod-bddab863-36e9-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-h2hkm" to be "success or failure"
Feb 22 21:35:15.268: INFO: Pod "pod-bddab863-36e9-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 15.149756ms
Feb 22 21:35:19.110: INFO: Pod "pod-bddab863-36e9-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 3.857913846s
Feb 22 21:35:21.133: INFO: Pod "pod-bddab863-36e9-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 5.880565148s
Feb 22 21:35:23.191: INFO: Pod "pod-bddab863-36e9-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.938610968s
STEP: Saw pod success
Feb 22 21:35:23.191: INFO: Pod "pod-bddab863-36e9-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:35:23.198: INFO: Trying to get logs from node conformance112-3 pod pod-bddab863-36e9-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 21:35:23.301: INFO: Waiting for pod pod-bddab863-36e9-11e9-9d47-0276c9498759 to disappear
Feb 22 21:35:23.326: INFO: Pod pod-bddab863-36e9-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:35:23.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h2hkm" for this suite.
Feb 22 21:35:29.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:35:29.456: INFO: namespace: e2e-tests-emptydir-h2hkm, resource: bindings, ignored listing per whitelist
Feb 22 21:35:29.778: INFO: namespace e2e-tests-emptydir-h2hkm deletion completed in 6.443383725s

• [SLOW TEST:14.854 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:35:29.781: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-596h
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 21:35:30.061: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-596h" in namespace "e2e-tests-subpath-7jfkj" to be "success or failure"
Feb 22 21:35:30.101: INFO: Pod "pod-subpath-test-configmap-596h": Phase="Pending", Reason="", readiness=false. Elapsed: 39.845062ms
Feb 22 21:35:34.092: INFO: Pod "pod-subpath-test-configmap-596h": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030893895s
Feb 22 21:35:40.680: INFO: Pod "pod-subpath-test-configmap-596h": Phase="Pending", Reason="", readiness=false. Elapsed: 10.619494696s
Feb 22 21:35:42.703: INFO: Pod "pod-subpath-test-configmap-596h": Phase="Running", Reason="", readiness=false. Elapsed: 12.642141039s
Feb 22 21:35:47.495: INFO: Pod "pod-subpath-test-configmap-596h": Phase="Running", Reason="", readiness=false. Elapsed: 17.43374916s
Feb 22 21:35:49.515: INFO: Pod "pod-subpath-test-configmap-596h": Phase="Running", Reason="", readiness=false. Elapsed: 19.454228973s
Feb 22 21:35:51.522: INFO: Pod "pod-subpath-test-configmap-596h": Phase="Running", Reason="", readiness=false. Elapsed: 21.460748402s
Feb 22 21:35:53.538: INFO: Pod "pod-subpath-test-configmap-596h": Phase="Running", Reason="", readiness=false. Elapsed: 23.476769128s
Feb 22 21:35:57.265: INFO: Pod "pod-subpath-test-configmap-596h": Phase="Running", Reason="", readiness=false. Elapsed: 27.203925168s
Feb 22 21:35:59.275: INFO: Pod "pod-subpath-test-configmap-596h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 29.214355341s
STEP: Saw pod success
Feb 22 21:35:59.275: INFO: Pod "pod-subpath-test-configmap-596h" satisfied condition "success or failure"
Feb 22 21:35:59.293: INFO: Trying to get logs from node conformance112-2 pod pod-subpath-test-configmap-596h container test-container-subpath-configmap-596h: <nil>
STEP: delete the pod
Feb 22 21:35:59.478: INFO: Waiting for pod pod-subpath-test-configmap-596h to disappear
Feb 22 21:35:59.515: INFO: Pod pod-subpath-test-configmap-596h no longer exists
STEP: Deleting pod pod-subpath-test-configmap-596h
Feb 22 21:35:59.515: INFO: Deleting pod "pod-subpath-test-configmap-596h" in namespace "e2e-tests-subpath-7jfkj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:35:59.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-7jfkj" for this suite.
Feb 22 21:36:09.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:36:09.685: INFO: namespace: e2e-tests-subpath-7jfkj, resource: bindings, ignored listing per whitelist
Feb 22 21:36:10.333: INFO: namespace e2e-tests-subpath-7jfkj deletion completed in 10.77151055s

• [SLOW TEST:40.553 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:36:10.337: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:36:24.796: INFO: Waiting up to 5m0s for pod "client-envvars-e4422cd1-36e9-11e9-9d47-0276c9498759" in namespace "e2e-tests-pods-f9vzw" to be "success or failure"
Feb 22 21:36:24.856: INFO: Pod "client-envvars-e4422cd1-36e9-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 59.641163ms
Feb 22 21:36:26.871: INFO: Pod "client-envvars-e4422cd1-36e9-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074785263s
Feb 22 21:36:28.877: INFO: Pod "client-envvars-e4422cd1-36e9-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.080624612s
STEP: Saw pod success
Feb 22 21:36:28.877: INFO: Pod "client-envvars-e4422cd1-36e9-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:36:28.882: INFO: Trying to get logs from node conformance112-2 pod client-envvars-e4422cd1-36e9-11e9-9d47-0276c9498759 container env3cont: <nil>
STEP: delete the pod
Feb 22 21:36:32.477: INFO: Waiting for pod client-envvars-e4422cd1-36e9-11e9-9d47-0276c9498759 to disappear
Feb 22 21:36:32.500: INFO: Pod client-envvars-e4422cd1-36e9-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:36:32.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f9vzw" for this suite.
Feb 22 21:37:24.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:37:24.766: INFO: namespace: e2e-tests-pods-f9vzw, resource: bindings, ignored listing per whitelist
Feb 22 21:37:24.834: INFO: namespace e2e-tests-pods-f9vzw deletion completed in 52.320945274s

• [SLOW TEST:74.498 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:37:24.838: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:37:25.056: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0b3cc8b8-36ea-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-qj2tq" to be "success or failure"
Feb 22 21:37:25.084: INFO: Pod "downwardapi-volume-0b3cc8b8-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 27.381216ms
Feb 22 21:37:27.091: INFO: Pod "downwardapi-volume-0b3cc8b8-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035008185s
Feb 22 21:37:33.109: INFO: Pod "downwardapi-volume-0b3cc8b8-36ea-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.052432791s
STEP: Saw pod success
Feb 22 21:37:33.109: INFO: Pod "downwardapi-volume-0b3cc8b8-36ea-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:37:33.161: INFO: Trying to get logs from node conformance112-3 pod downwardapi-volume-0b3cc8b8-36ea-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 21:37:33.236: INFO: Waiting for pod downwardapi-volume-0b3cc8b8-36ea-11e9-9d47-0276c9498759 to disappear
Feb 22 21:37:33.244: INFO: Pod downwardapi-volume-0b3cc8b8-36ea-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:37:33.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qj2tq" for this suite.
Feb 22 21:37:45.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:37:45.488: INFO: namespace: e2e-tests-downward-api-qj2tq, resource: bindings, ignored listing per whitelist
Feb 22 21:37:45.559: INFO: namespace e2e-tests-downward-api-qj2tq deletion completed in 12.306063504s

• [SLOW TEST:20.722 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:37:45.561: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 22 21:37:45.749: INFO: Waiting up to 5m0s for pod "var-expansion-17928fb9-36ea-11e9-9d47-0276c9498759" in namespace "e2e-tests-var-expansion-mtpjz" to be "success or failure"
Feb 22 21:37:45.785: INFO: Pod "var-expansion-17928fb9-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 35.393301ms
Feb 22 21:37:47.791: INFO: Pod "var-expansion-17928fb9-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041862755s
Feb 22 21:37:49.798: INFO: Pod "var-expansion-17928fb9-36ea-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048080222s
STEP: Saw pod success
Feb 22 21:37:49.798: INFO: Pod "var-expansion-17928fb9-36ea-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:37:49.803: INFO: Trying to get logs from node conformance112-2 pod var-expansion-17928fb9-36ea-11e9-9d47-0276c9498759 container dapi-container: <nil>
STEP: delete the pod
Feb 22 21:37:49.857: INFO: Waiting for pod var-expansion-17928fb9-36ea-11e9-9d47-0276c9498759 to disappear
Feb 22 21:37:49.884: INFO: Pod var-expansion-17928fb9-36ea-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:37:49.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-mtpjz" for this suite.
Feb 22 21:37:59.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:37:59.980: INFO: namespace: e2e-tests-var-expansion-mtpjz, resource: bindings, ignored listing per whitelist
Feb 22 21:38:00.184: INFO: namespace e2e-tests-var-expansion-mtpjz deletion completed in 10.289344288s

• [SLOW TEST:14.623 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:38:00.189: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:38:00.398: INFO: Waiting up to 5m0s for pod "downwardapi-volume-204d14d7-36ea-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-zqclg" to be "success or failure"
Feb 22 21:38:00.429: INFO: Pod "downwardapi-volume-204d14d7-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 30.615217ms
Feb 22 21:38:03.788: INFO: Pod "downwardapi-volume-204d14d7-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 3.390220075s
Feb 22 21:38:05.796: INFO: Pod "downwardapi-volume-204d14d7-36ea-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 5.398411744s
STEP: Saw pod success
Feb 22 21:38:05.797: INFO: Pod "downwardapi-volume-204d14d7-36ea-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:38:05.804: INFO: Trying to get logs from node conformance112-3 pod downwardapi-volume-204d14d7-36ea-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 21:38:05.883: INFO: Waiting for pod downwardapi-volume-204d14d7-36ea-11e9-9d47-0276c9498759 to disappear
Feb 22 21:38:05.935: INFO: Pod downwardapi-volume-204d14d7-36ea-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:38:05.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zqclg" for this suite.
Feb 22 21:38:12.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:38:12.156: INFO: namespace: e2e-tests-projected-zqclg, resource: bindings, ignored listing per whitelist
Feb 22 21:38:12.482: INFO: namespace e2e-tests-projected-zqclg deletion completed in 6.530224113s

• [SLOW TEST:12.293 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:38:12.483: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-279f83eb-36ea-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 21:38:12.700: INFO: Waiting up to 5m0s for pod "pod-secrets-27a13e76-36ea-11e9-9d47-0276c9498759" in namespace "e2e-tests-secrets-hzth4" to be "success or failure"
Feb 22 21:38:12.734: INFO: Pod "pod-secrets-27a13e76-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 33.655147ms
Feb 22 21:38:14.742: INFO: Pod "pod-secrets-27a13e76-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041321916s
Feb 22 21:38:16.929: INFO: Pod "pod-secrets-27a13e76-36ea-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.228226529s
STEP: Saw pod success
Feb 22 21:38:16.929: INFO: Pod "pod-secrets-27a13e76-36ea-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:38:16.938: INFO: Trying to get logs from node conformance112-2 pod pod-secrets-27a13e76-36ea-11e9-9d47-0276c9498759 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 21:38:17.242: INFO: Waiting for pod pod-secrets-27a13e76-36ea-11e9-9d47-0276c9498759 to disappear
Feb 22 21:38:17.280: INFO: Pod pod-secrets-27a13e76-36ea-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:38:17.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hzth4" for this suite.
Feb 22 21:38:27.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:38:31.441: INFO: namespace: e2e-tests-secrets-hzth4, resource: bindings, ignored listing per whitelist
Feb 22 21:38:31.789: INFO: namespace e2e-tests-secrets-hzth4 deletion completed in 14.48779292s

• [SLOW TEST:19.306 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:38:31.791: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-klh9c
I0222 21:38:32.035536      13 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-klh9c, replica count: 1
I0222 21:38:33.086052      13 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 21:38:34.086664      13 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 22 21:38:34.225: INFO: Created: latency-svc-m8lr8
Feb 22 21:38:34.238: INFO: Got endpoints: latency-svc-m8lr8 [51.739058ms]
Feb 22 21:38:34.285: INFO: Created: latency-svc-jkbx4
Feb 22 21:38:34.298: INFO: Got endpoints: latency-svc-jkbx4 [59.02243ms]
Feb 22 21:38:34.318: INFO: Created: latency-svc-xmpvm
Feb 22 21:38:34.353: INFO: Created: latency-svc-w85w7
Feb 22 21:38:34.357: INFO: Got endpoints: latency-svc-xmpvm [117.241528ms]
Feb 22 21:38:34.368: INFO: Got endpoints: latency-svc-w85w7 [128.287775ms]
Feb 22 21:38:34.383: INFO: Created: latency-svc-c788s
Feb 22 21:38:34.405: INFO: Got endpoints: latency-svc-c788s [165.163348ms]
Feb 22 21:38:34.415: INFO: Created: latency-svc-p6v2r
Feb 22 21:38:34.443: INFO: Created: latency-svc-n9wn7
Feb 22 21:38:34.444: INFO: Got endpoints: latency-svc-p6v2r [202.925397ms]
Feb 22 21:38:34.466: INFO: Got endpoints: latency-svc-n9wn7 [226.441391ms]
Feb 22 21:38:34.653: INFO: Created: latency-svc-7qv87
Feb 22 21:38:34.692: INFO: Got endpoints: latency-svc-7qv87 [451.927495ms]
Feb 22 21:38:34.733: INFO: Created: latency-svc-6557h
Feb 22 21:38:34.844: INFO: Created: latency-svc-dtqdw
Feb 22 21:38:34.890: INFO: Created: latency-svc-v6htc
Feb 22 21:38:34.895: INFO: Got endpoints: latency-svc-dtqdw [654.632336ms]
Feb 22 21:38:34.895: INFO: Got endpoints: latency-svc-6557h [655.306229ms]
Feb 22 21:38:34.943: INFO: Got endpoints: latency-svc-v6htc [702.399714ms]
Feb 22 21:38:34.959: INFO: Created: latency-svc-6nblq
Feb 22 21:38:35.045: INFO: Got endpoints: latency-svc-6nblq [804.950569ms]
Feb 22 21:38:35.063: INFO: Created: latency-svc-d5rtb
Feb 22 21:38:35.151: INFO: Got endpoints: latency-svc-d5rtb [910.144064ms]
Feb 22 21:38:35.152: INFO: Created: latency-svc-jhndc
Feb 22 21:38:35.214: INFO: Created: latency-svc-fzjjf
Feb 22 21:38:35.214: INFO: Got endpoints: latency-svc-jhndc [973.807051ms]
Feb 22 21:38:35.235: INFO: Got endpoints: latency-svc-fzjjf [994.261519ms]
Feb 22 21:38:35.287: INFO: Created: latency-svc-x2pdj
Feb 22 21:38:35.370: INFO: Got endpoints: latency-svc-x2pdj [1.12959294s]
Feb 22 21:38:35.370: INFO: Created: latency-svc-9dfmp
Feb 22 21:38:35.427: INFO: Got endpoints: latency-svc-9dfmp [1.128906906s]
Feb 22 21:38:35.687: INFO: Created: latency-svc-frhgf
Feb 22 21:38:35.954: INFO: Got endpoints: latency-svc-frhgf [1.597123089s]
Feb 22 21:38:35.970: INFO: Created: latency-svc-2lwbt
Feb 22 21:38:36.021: INFO: Got endpoints: latency-svc-2lwbt [1.653778652s]
Feb 22 21:38:36.023: INFO: Created: latency-svc-ws86x
Feb 22 21:38:36.038: INFO: Got endpoints: latency-svc-ws86x [1.633087966s]
Feb 22 21:38:36.089: INFO: Created: latency-svc-k5srl
Feb 22 21:38:36.109: INFO: Created: latency-svc-p6b77
Feb 22 21:38:36.129: INFO: Got endpoints: latency-svc-k5srl [1.685272476s]
Feb 22 21:38:36.154: INFO: Got endpoints: latency-svc-p6b77 [132.705913ms]
Feb 22 21:38:36.156: INFO: Created: latency-svc-svtkt
Feb 22 21:38:36.188: INFO: Created: latency-svc-s254h
Feb 22 21:38:36.190: INFO: Got endpoints: latency-svc-svtkt [1.723838751s]
Feb 22 21:38:36.224: INFO: Created: latency-svc-b2l8l
Feb 22 21:38:36.227: INFO: Got endpoints: latency-svc-s254h [1.535210501s]
Feb 22 21:38:36.243: INFO: Got endpoints: latency-svc-b2l8l [1.348351417s]
Feb 22 21:38:36.269: INFO: Created: latency-svc-5zt59
Feb 22 21:38:36.292: INFO: Got endpoints: latency-svc-5zt59 [1.396253261s]
Feb 22 21:38:36.316: INFO: Created: latency-svc-47lhn
Feb 22 21:38:36.329: INFO: Got endpoints: latency-svc-47lhn [1.385971204s]
Feb 22 21:38:36.368: INFO: Created: latency-svc-vqjkv
Feb 22 21:38:36.396: INFO: Got endpoints: latency-svc-vqjkv [1.350463206s]
Feb 22 21:38:36.407: INFO: Created: latency-svc-gsx9z
Feb 22 21:38:36.421: INFO: Got endpoints: latency-svc-gsx9z [1.269932814s]
Feb 22 21:38:36.451: INFO: Created: latency-svc-82mwr
Feb 22 21:38:36.473: INFO: Got endpoints: latency-svc-82mwr [1.258771356s]
Feb 22 21:38:36.478: INFO: Created: latency-svc-wm9hm
Feb 22 21:38:36.504: INFO: Got endpoints: latency-svc-wm9hm [1.268388401s]
Feb 22 21:38:36.528: INFO: Created: latency-svc-vc4cf
Feb 22 21:38:36.549: INFO: Created: latency-svc-gwzs5
Feb 22 21:38:36.573: INFO: Got endpoints: latency-svc-vc4cf [1.203157945s]
Feb 22 21:38:36.584: INFO: Got endpoints: latency-svc-gwzs5 [1.157101764s]
Feb 22 21:38:36.647: INFO: Created: latency-svc-wssk2
Feb 22 21:38:36.652: INFO: Got endpoints: latency-svc-wssk2 [697.824317ms]
Feb 22 21:38:36.692: INFO: Created: latency-svc-n4ckw
Feb 22 21:38:36.700: INFO: Got endpoints: latency-svc-n4ckw [661.389126ms]
Feb 22 21:38:36.754: INFO: Created: latency-svc-sscnb
Feb 22 21:38:36.754: INFO: Got endpoints: latency-svc-sscnb [624.827174ms]
Feb 22 21:38:36.829: INFO: Created: latency-svc-kvknn
Feb 22 21:38:36.845: INFO: Created: latency-svc-4g7gn
Feb 22 21:38:36.853: INFO: Got endpoints: latency-svc-kvknn [698.77323ms]
Feb 22 21:38:36.865: INFO: Got endpoints: latency-svc-4g7gn [674.99574ms]
Feb 22 21:38:36.901: INFO: Created: latency-svc-sz7q7
Feb 22 21:38:36.909: INFO: Got endpoints: latency-svc-sz7q7 [681.968844ms]
Feb 22 21:38:36.942: INFO: Created: latency-svc-jzrpf
Feb 22 21:38:36.949: INFO: Got endpoints: latency-svc-jzrpf [705.255036ms]
Feb 22 21:38:36.986: INFO: Created: latency-svc-bdcd2
Feb 22 21:38:37.185: INFO: Got endpoints: latency-svc-bdcd2 [892.964774ms]
Feb 22 21:38:37.331: INFO: Created: latency-svc-t9vpc
Feb 22 21:38:37.349: INFO: Got endpoints: latency-svc-t9vpc [1.01999857s]
Feb 22 21:38:37.387: INFO: Created: latency-svc-p8dmm
Feb 22 21:38:37.393: INFO: Got endpoints: latency-svc-p8dmm [997.079215ms]
Feb 22 21:38:37.434: INFO: Created: latency-svc-wmzj2
Feb 22 21:38:37.445: INFO: Got endpoints: latency-svc-wmzj2 [1.02363899s]
Feb 22 21:38:37.462: INFO: Created: latency-svc-hbklv
Feb 22 21:38:37.509: INFO: Got endpoints: latency-svc-hbklv [1.035983085s]
Feb 22 21:38:37.539: INFO: Created: latency-svc-7zk4q
Feb 22 21:38:37.562: INFO: Got endpoints: latency-svc-7zk4q [1.058406007s]
Feb 22 21:38:37.585: INFO: Created: latency-svc-wgzr7
Feb 22 21:38:37.600: INFO: Got endpoints: latency-svc-wgzr7 [1.026926697s]
Feb 22 21:38:37.639: INFO: Created: latency-svc-qvmm5
Feb 22 21:38:37.646: INFO: Got endpoints: latency-svc-qvmm5 [1.062277783s]
Feb 22 21:38:37.676: INFO: Created: latency-svc-nvjtr
Feb 22 21:38:37.680: INFO: Got endpoints: latency-svc-nvjtr [1.027500003s]
Feb 22 21:38:37.722: INFO: Created: latency-svc-zt726
Feb 22 21:38:37.729: INFO: Got endpoints: latency-svc-zt726 [1.029315592s]
Feb 22 21:38:37.780: INFO: Created: latency-svc-ptkcr
Feb 22 21:38:37.804: INFO: Got endpoints: latency-svc-ptkcr [1.049880276s]
Feb 22 21:38:37.873: INFO: Created: latency-svc-4sltr
Feb 22 21:38:37.873: INFO: Created: latency-svc-hq54z
Feb 22 21:38:37.885: INFO: Got endpoints: latency-svc-4sltr [1.031759986s]
Feb 22 21:38:37.907: INFO: Got endpoints: latency-svc-hq54z [1.041229798s]
Feb 22 21:38:37.932: INFO: Created: latency-svc-g2s6f
Feb 22 21:38:37.973: INFO: Created: latency-svc-8cjn8
Feb 22 21:38:37.986: INFO: Got endpoints: latency-svc-g2s6f [1.076098417s]
Feb 22 21:38:37.992: INFO: Got endpoints: latency-svc-8cjn8 [1.043159882s]
Feb 22 21:38:38.016: INFO: Created: latency-svc-qz25g
Feb 22 21:38:38.036: INFO: Got endpoints: latency-svc-qz25g [851.130614ms]
Feb 22 21:38:38.055: INFO: Created: latency-svc-tqbbv
Feb 22 21:38:38.106: INFO: Created: latency-svc-stswd
Feb 22 21:38:38.117: INFO: Got endpoints: latency-svc-stswd [723.444828ms]
Feb 22 21:38:38.117: INFO: Got endpoints: latency-svc-tqbbv [768.14413ms]
Feb 22 21:38:38.143: INFO: Created: latency-svc-b6f5g
Feb 22 21:38:38.153: INFO: Got endpoints: latency-svc-b6f5g [708.220321ms]
Feb 22 21:38:38.186: INFO: Created: latency-svc-9mjbf
Feb 22 21:38:38.192: INFO: Got endpoints: latency-svc-9mjbf [682.692074ms]
Feb 22 21:38:38.225: INFO: Created: latency-svc-zgqtz
Feb 22 21:38:38.244: INFO: Got endpoints: latency-svc-zgqtz [681.56911ms]
Feb 22 21:38:38.263: INFO: Created: latency-svc-btxpm
Feb 22 21:38:38.277: INFO: Got endpoints: latency-svc-btxpm [676.66796ms]
Feb 22 21:38:38.303: INFO: Created: latency-svc-8tlmf
Feb 22 21:38:38.312: INFO: Got endpoints: latency-svc-8tlmf [665.228314ms]
Feb 22 21:38:38.336: INFO: Created: latency-svc-x54sf
Feb 22 21:38:38.356: INFO: Got endpoints: latency-svc-x54sf [676.342959ms]
Feb 22 21:38:38.391: INFO: Created: latency-svc-mw5hw
Feb 22 21:38:38.399: INFO: Got endpoints: latency-svc-mw5hw [669.624407ms]
Feb 22 21:38:38.432: INFO: Created: latency-svc-l5dc4
Feb 22 21:38:38.441: INFO: Got endpoints: latency-svc-l5dc4 [636.625862ms]
Feb 22 21:38:38.479: INFO: Created: latency-svc-2rsl7
Feb 22 21:38:38.489: INFO: Got endpoints: latency-svc-2rsl7 [603.820082ms]
Feb 22 21:38:38.532: INFO: Created: latency-svc-fqflt
Feb 22 21:38:38.549: INFO: Got endpoints: latency-svc-fqflt [642.191209ms]
Feb 22 21:38:38.565: INFO: Created: latency-svc-8ffrc
Feb 22 21:38:38.573: INFO: Got endpoints: latency-svc-8ffrc [587.680749ms]
Feb 22 21:38:38.615: INFO: Created: latency-svc-zpcpj
Feb 22 21:38:38.627: INFO: Got endpoints: latency-svc-zpcpj [634.433642ms]
Feb 22 21:38:38.676: INFO: Created: latency-svc-68kxj
Feb 22 21:38:38.726: INFO: Created: latency-svc-86bd5
Feb 22 21:38:38.732: INFO: Got endpoints: latency-svc-68kxj [695.857476ms]
Feb 22 21:38:38.765: INFO: Got endpoints: latency-svc-86bd5 [648.451571ms]
Feb 22 21:38:38.790: INFO: Created: latency-svc-z59pq
Feb 22 21:38:38.819: INFO: Got endpoints: latency-svc-z59pq [701.387296ms]
Feb 22 21:38:38.833: INFO: Created: latency-svc-qtrmv
Feb 22 21:38:38.850: INFO: Got endpoints: latency-svc-qtrmv [696.599885ms]
Feb 22 21:38:38.884: INFO: Created: latency-svc-fjns8
Feb 22 21:38:38.905: INFO: Got endpoints: latency-svc-fjns8 [712.728416ms]
Feb 22 21:38:38.950: INFO: Created: latency-svc-j5xpg
Feb 22 21:38:38.956: INFO: Got endpoints: latency-svc-j5xpg [712.19759ms]
Feb 22 21:38:39.000: INFO: Created: latency-svc-dw966
Feb 22 21:38:39.019: INFO: Got endpoints: latency-svc-dw966 [742.512943ms]
Feb 22 21:38:39.043: INFO: Created: latency-svc-fpm2w
Feb 22 21:38:39.067: INFO: Got endpoints: latency-svc-fpm2w [754.642848ms]
Feb 22 21:38:39.078: INFO: Created: latency-svc-8zzvm
Feb 22 21:38:39.095: INFO: Got endpoints: latency-svc-8zzvm [738.390032ms]
Feb 22 21:38:39.118: INFO: Created: latency-svc-d666r
Feb 22 21:38:39.136: INFO: Got endpoints: latency-svc-d666r [737.670178ms]
Feb 22 21:38:39.152: INFO: Created: latency-svc-zmq2f
Feb 22 21:38:39.167: INFO: Got endpoints: latency-svc-zmq2f [726.561463ms]
Feb 22 21:38:39.182: INFO: Created: latency-svc-45qfm
Feb 22 21:38:39.204: INFO: Got endpoints: latency-svc-45qfm [714.920688ms]
Feb 22 21:38:39.238: INFO: Created: latency-svc-dszpn
Feb 22 21:38:39.243: INFO: Got endpoints: latency-svc-dszpn [693.963713ms]
Feb 22 21:38:40.475: INFO: Created: latency-svc-qpnvf
Feb 22 21:38:40.491: INFO: Got endpoints: latency-svc-qpnvf [1.917210436s]
Feb 22 21:38:40.534: INFO: Created: latency-svc-lhw2n
Feb 22 21:38:40.549: INFO: Got endpoints: latency-svc-lhw2n [1.921907904s]
Feb 22 21:38:40.569: INFO: Created: latency-svc-tkgl7
Feb 22 21:38:40.584: INFO: Got endpoints: latency-svc-tkgl7 [1.851624419s]
Feb 22 21:38:40.626: INFO: Created: latency-svc-jkbjs
Feb 22 21:38:40.631: INFO: Got endpoints: latency-svc-jkbjs [1.86567705s]
Feb 22 21:38:40.662: INFO: Created: latency-svc-mwf7p
Feb 22 21:38:40.672: INFO: Got endpoints: latency-svc-mwf7p [1.853349689s]
Feb 22 21:38:40.706: INFO: Created: latency-svc-xlgvt
Feb 22 21:38:40.713: INFO: Got endpoints: latency-svc-xlgvt [1.863111469s]
Feb 22 21:38:40.735: INFO: Created: latency-svc-h45fx
Feb 22 21:38:40.752: INFO: Got endpoints: latency-svc-h45fx [1.847147701s]
Feb 22 21:38:40.779: INFO: Created: latency-svc-ff7gc
Feb 22 21:38:40.790: INFO: Got endpoints: latency-svc-ff7gc [1.834168071s]
Feb 22 21:38:40.814: INFO: Created: latency-svc-8wpdg
Feb 22 21:38:40.832: INFO: Got endpoints: latency-svc-8wpdg [1.812306048s]
Feb 22 21:38:40.864: INFO: Created: latency-svc-5tl64
Feb 22 21:38:40.887: INFO: Created: latency-svc-w48lt
Feb 22 21:38:40.896: INFO: Got endpoints: latency-svc-5tl64 [1.829451358s]
Feb 22 21:38:40.910: INFO: Got endpoints: latency-svc-w48lt [1.815710698s]
Feb 22 21:38:40.958: INFO: Created: latency-svc-2b4w8
Feb 22 21:38:40.976: INFO: Got endpoints: latency-svc-2b4w8 [1.839403679s]
Feb 22 21:38:40.995: INFO: Created: latency-svc-6bctd
Feb 22 21:38:41.043: INFO: Got endpoints: latency-svc-6bctd [1.875679427s]
Feb 22 21:38:41.051: INFO: Created: latency-svc-r2zvv
Feb 22 21:38:41.069: INFO: Got endpoints: latency-svc-r2zvv [1.864805776s]
Feb 22 21:38:41.098: INFO: Created: latency-svc-q4ssr
Feb 22 21:38:41.102: INFO: Got endpoints: latency-svc-q4ssr [1.858461599s]
Feb 22 21:38:41.143: INFO: Created: latency-svc-4dvvw
Feb 22 21:38:41.149: INFO: Got endpoints: latency-svc-4dvvw [658.141674ms]
Feb 22 21:38:41.177: INFO: Created: latency-svc-z9fhb
Feb 22 21:38:41.185: INFO: Got endpoints: latency-svc-z9fhb [636.35895ms]
Feb 22 21:38:41.217: INFO: Created: latency-svc-8mjdm
Feb 22 21:38:41.227: INFO: Got endpoints: latency-svc-8mjdm [643.169058ms]
Feb 22 21:38:41.247: INFO: Created: latency-svc-ps4zg
Feb 22 21:38:41.404: INFO: Got endpoints: latency-svc-ps4zg [773.019688ms]
Feb 22 21:38:41.433: INFO: Created: latency-svc-vl584
Feb 22 21:38:41.450: INFO: Got endpoints: latency-svc-vl584 [777.515207ms]
Feb 22 21:38:41.489: INFO: Created: latency-svc-8wd89
Feb 22 21:38:41.500: INFO: Got endpoints: latency-svc-8wd89 [787.349194ms]
Feb 22 21:38:41.536: INFO: Created: latency-svc-4r2bm
Feb 22 21:38:41.554: INFO: Got endpoints: latency-svc-4r2bm [801.42845ms]
Feb 22 21:38:41.595: INFO: Created: latency-svc-ljrkn
Feb 22 21:38:41.624: INFO: Got endpoints: latency-svc-ljrkn [833.457906ms]
Feb 22 21:38:41.663: INFO: Created: latency-svc-7fvnv
Feb 22 21:38:41.676: INFO: Got endpoints: latency-svc-7fvnv [844.373561ms]
Feb 22 21:38:41.704: INFO: Created: latency-svc-zv4nw
Feb 22 21:38:41.718: INFO: Got endpoints: latency-svc-zv4nw [821.53762ms]
Feb 22 21:38:41.754: INFO: Created: latency-svc-c7dpc
Feb 22 21:38:41.768: INFO: Got endpoints: latency-svc-c7dpc [857.18915ms]
Feb 22 21:38:41.804: INFO: Created: latency-svc-tdkdj
Feb 22 21:38:41.818: INFO: Got endpoints: latency-svc-tdkdj [842.157352ms]
Feb 22 21:38:41.840: INFO: Created: latency-svc-5cd4w
Feb 22 21:38:41.884: INFO: Got endpoints: latency-svc-5cd4w [840.790174ms]
Feb 22 21:38:41.904: INFO: Created: latency-svc-hf66q
Feb 22 21:38:41.962: INFO: Got endpoints: latency-svc-hf66q [893.031834ms]
Feb 22 21:38:41.985: INFO: Created: latency-svc-p98mt
Feb 22 21:38:42.009: INFO: Got endpoints: latency-svc-p98mt [907.608105ms]
Feb 22 21:38:42.035: INFO: Created: latency-svc-f9sjg
Feb 22 21:38:42.048: INFO: Got endpoints: latency-svc-f9sjg [899.514891ms]
Feb 22 21:38:42.073: INFO: Created: latency-svc-j7c97
Feb 22 21:38:42.088: INFO: Got endpoints: latency-svc-j7c97 [902.320729ms]
Feb 22 21:38:42.108: INFO: Created: latency-svc-8vgxz
Feb 22 21:38:42.126: INFO: Got endpoints: latency-svc-8vgxz [899.346702ms]
Feb 22 21:38:42.142: INFO: Created: latency-svc-szlwk
Feb 22 21:38:42.162: INFO: Got endpoints: latency-svc-szlwk [758.057607ms]
Feb 22 21:38:42.183: INFO: Created: latency-svc-p5xp9
Feb 22 21:38:42.202: INFO: Got endpoints: latency-svc-p5xp9 [752.020516ms]
Feb 22 21:38:42.226: INFO: Created: latency-svc-tx5vh
Feb 22 21:38:42.262: INFO: Got endpoints: latency-svc-tx5vh [761.195048ms]
Feb 22 21:38:42.267: INFO: Created: latency-svc-tqstb
Feb 22 21:38:42.280: INFO: Got endpoints: latency-svc-tqstb [655.61997ms]
Feb 22 21:38:42.317: INFO: Created: latency-svc-j98qh
Feb 22 21:38:42.359: INFO: Created: latency-svc-n7nbp
Feb 22 21:38:42.377: INFO: Got endpoints: latency-svc-j98qh [822.974417ms]
Feb 22 21:38:42.395: INFO: Got endpoints: latency-svc-n7nbp [719.031528ms]
Feb 22 21:38:42.409: INFO: Created: latency-svc-xmhlk
Feb 22 21:38:42.429: INFO: Got endpoints: latency-svc-xmhlk [710.993329ms]
Feb 22 21:38:42.447: INFO: Created: latency-svc-cjmx7
Feb 22 21:38:42.479: INFO: Created: latency-svc-6kvth
Feb 22 21:38:42.494: INFO: Got endpoints: latency-svc-cjmx7 [726.395321ms]
Feb 22 21:38:42.534: INFO: Created: latency-svc-ffd8v
Feb 22 21:38:42.539: INFO: Got endpoints: latency-svc-6kvth [720.455222ms]
Feb 22 21:38:42.556: INFO: Got endpoints: latency-svc-ffd8v [671.447921ms]
Feb 22 21:38:42.668: INFO: Created: latency-svc-9vgtp
Feb 22 21:38:42.701: INFO: Created: latency-svc-t5np2
Feb 22 21:38:42.750: INFO: Got endpoints: latency-svc-9vgtp [787.827839ms]
Feb 22 21:38:42.754: INFO: Got endpoints: latency-svc-t5np2 [744.971748ms]
Feb 22 21:38:42.831: INFO: Created: latency-svc-4p8bp
Feb 22 21:38:42.859: INFO: Got endpoints: latency-svc-4p8bp [810.47153ms]
Feb 22 21:38:42.880: INFO: Created: latency-svc-lgn2q
Feb 22 21:38:42.924: INFO: Got endpoints: latency-svc-lgn2q [836.00354ms]
Feb 22 21:38:42.924: INFO: Created: latency-svc-r2q4h
Feb 22 21:38:42.949: INFO: Created: latency-svc-zrvf8
Feb 22 21:38:42.959: INFO: Got endpoints: latency-svc-r2q4h [832.579326ms]
Feb 22 21:38:43.007: INFO: Got endpoints: latency-svc-zrvf8 [844.965222ms]
Feb 22 21:38:43.049: INFO: Created: latency-svc-4rphd
Feb 22 21:38:43.080: INFO: Got endpoints: latency-svc-4rphd [877.52721ms]
Feb 22 21:38:43.118: INFO: Created: latency-svc-pnxcl
Feb 22 21:38:43.119: INFO: Got endpoints: latency-svc-pnxcl [857.004047ms]
Feb 22 21:38:43.130: INFO: Created: latency-svc-qmf2b
Feb 22 21:38:43.140: INFO: Got endpoints: latency-svc-qmf2b [859.949538ms]
Feb 22 21:38:43.168: INFO: Created: latency-svc-7f965
Feb 22 21:38:43.183: INFO: Got endpoints: latency-svc-7f965 [806.234146ms]
Feb 22 21:38:43.197: INFO: Created: latency-svc-t5mvb
Feb 22 21:38:43.233: INFO: Got endpoints: latency-svc-t5mvb [837.25593ms]
Feb 22 21:38:43.250: INFO: Created: latency-svc-f7rtv
Feb 22 21:38:43.271: INFO: Got endpoints: latency-svc-f7rtv [841.689064ms]
Feb 22 21:38:43.293: INFO: Created: latency-svc-9lgms
Feb 22 21:38:43.310: INFO: Got endpoints: latency-svc-9lgms [815.783026ms]
Feb 22 21:38:43.333: INFO: Created: latency-svc-8rlz4
Feb 22 21:38:43.353: INFO: Got endpoints: latency-svc-8rlz4 [813.84149ms]
Feb 22 21:38:43.375: INFO: Created: latency-svc-f24hm
Feb 22 21:38:43.375: INFO: Got endpoints: latency-svc-f24hm [819.654802ms]
Feb 22 21:38:43.407: INFO: Created: latency-svc-lv4qp
Feb 22 21:38:43.421: INFO: Got endpoints: latency-svc-lv4qp [670.356932ms]
Feb 22 21:38:43.438: INFO: Created: latency-svc-4gvp4
Feb 22 21:38:43.454: INFO: Got endpoints: latency-svc-4gvp4 [698.928032ms]
Feb 22 21:38:43.474: INFO: Created: latency-svc-k54lv
Feb 22 21:38:43.508: INFO: Created: latency-svc-hrf6v
Feb 22 21:38:43.525: INFO: Got endpoints: latency-svc-k54lv [665.680445ms]
Feb 22 21:38:43.536: INFO: Got endpoints: latency-svc-hrf6v [612.718089ms]
Feb 22 21:38:43.562: INFO: Created: latency-svc-l79nz
Feb 22 21:38:43.575: INFO: Got endpoints: latency-svc-l79nz [616.000643ms]
Feb 22 21:38:43.599: INFO: Created: latency-svc-24qgr
Feb 22 21:38:43.623: INFO: Got endpoints: latency-svc-24qgr [615.525502ms]
Feb 22 21:38:43.633: INFO: Created: latency-svc-k67l8
Feb 22 21:38:43.652: INFO: Got endpoints: latency-svc-k67l8 [571.829139ms]
Feb 22 21:38:43.676: INFO: Created: latency-svc-77tk6
Feb 22 21:38:43.693: INFO: Got endpoints: latency-svc-77tk6 [574.148367ms]
Feb 22 21:38:43.718: INFO: Created: latency-svc-kj95l
Feb 22 21:38:43.734: INFO: Got endpoints: latency-svc-kj95l [594.466936ms]
Feb 22 21:38:43.762: INFO: Created: latency-svc-52bch
Feb 22 21:38:43.772: INFO: Got endpoints: latency-svc-52bch [588.290513ms]
Feb 22 21:38:43.794: INFO: Created: latency-svc-q4g8c
Feb 22 21:38:43.807: INFO: Got endpoints: latency-svc-q4g8c [574.590548ms]
Feb 22 21:38:43.840: INFO: Created: latency-svc-4lbfp
Feb 22 21:38:43.848: INFO: Got endpoints: latency-svc-4lbfp [576.951942ms]
Feb 22 21:38:43.889: INFO: Created: latency-svc-n8nxv
Feb 22 21:38:43.908: INFO: Got endpoints: latency-svc-n8nxv [597.731081ms]
Feb 22 21:38:43.994: INFO: Created: latency-svc-29k87
Feb 22 21:38:44.019: INFO: Created: latency-svc-r646l
Feb 22 21:38:44.024: INFO: Got endpoints: latency-svc-29k87 [670.673343ms]
Feb 22 21:38:44.044: INFO: Got endpoints: latency-svc-r646l [668.528151ms]
Feb 22 21:38:44.101: INFO: Created: latency-svc-s2d2v
Feb 22 21:38:44.113: INFO: Got endpoints: latency-svc-s2d2v [691.734082ms]
Feb 22 21:38:44.136: INFO: Created: latency-svc-fkdzm
Feb 22 21:38:44.152: INFO: Got endpoints: latency-svc-fkdzm [698.150249ms]
Feb 22 21:38:44.181: INFO: Created: latency-svc-99j5x
Feb 22 21:38:44.181: INFO: Got endpoints: latency-svc-99j5x [655.481922ms]
Feb 22 21:38:44.212: INFO: Created: latency-svc-fvq76
Feb 22 21:38:44.228: INFO: Got endpoints: latency-svc-fvq76 [691.237864ms]
Feb 22 21:38:44.250: INFO: Created: latency-svc-9vxlw
Feb 22 21:38:44.288: INFO: Created: latency-svc-rmjq4
Feb 22 21:38:44.331: INFO: Created: latency-svc-hhxms
Feb 22 21:38:44.345: INFO: Got endpoints: latency-svc-9vxlw [770.212492ms]
Feb 22 21:38:44.363: INFO: Got endpoints: latency-svc-hhxms [711.210283ms]
Feb 22 21:38:44.380: INFO: Got endpoints: latency-svc-rmjq4 [757.070678ms]
Feb 22 21:38:44.391: INFO: Created: latency-svc-v49mj
Feb 22 21:38:44.404: INFO: Got endpoints: latency-svc-v49mj [711.1699ms]
Feb 22 21:38:44.423: INFO: Created: latency-svc-kpkt9
Feb 22 21:38:44.441: INFO: Got endpoints: latency-svc-kpkt9 [707.129129ms]
Feb 22 21:38:44.487: INFO: Created: latency-svc-97qhn
Feb 22 21:38:44.487: INFO: Got endpoints: latency-svc-97qhn [715.187281ms]
Feb 22 21:38:44.495: INFO: Created: latency-svc-4x5hz
Feb 22 21:38:44.528: INFO: Got endpoints: latency-svc-4x5hz [720.580741ms]
Feb 22 21:38:44.560: INFO: Created: latency-svc-g8mpl
Feb 22 21:38:48.151: INFO: Got endpoints: latency-svc-g8mpl [4.303470747s]
Feb 22 21:38:48.172: INFO: Created: latency-svc-p5sqr
Feb 22 21:38:48.427: INFO: Got endpoints: latency-svc-p5sqr [4.518814353s]
Feb 22 21:38:48.506: INFO: Created: latency-svc-dwckz
Feb 22 21:38:48.547: INFO: Got endpoints: latency-svc-dwckz [4.52313244s]
Feb 22 21:38:48.609: INFO: Created: latency-svc-pl5hp
Feb 22 21:38:48.609: INFO: Got endpoints: latency-svc-pl5hp [4.564803565s]
Feb 22 21:38:48.664: INFO: Created: latency-svc-lchvw
Feb 22 21:38:48.720: INFO: Got endpoints: latency-svc-lchvw [4.606971973s]
Feb 22 21:38:48.766: INFO: Created: latency-svc-jqll4
Feb 22 21:38:48.798: INFO: Got endpoints: latency-svc-jqll4 [4.646264519s]
Feb 22 21:38:48.817: INFO: Created: latency-svc-gph5h
Feb 22 21:38:48.857: INFO: Got endpoints: latency-svc-gph5h [4.676025875s]
Feb 22 21:38:48.877: INFO: Created: latency-svc-pm65v
Feb 22 21:38:48.914: INFO: Got endpoints: latency-svc-pm65v [4.686242341s]
Feb 22 21:38:48.928: INFO: Created: latency-svc-xlsbj
Feb 22 21:38:48.965: INFO: Created: latency-svc-nlnq4
Feb 22 21:38:48.965: INFO: Got endpoints: latency-svc-xlsbj [4.619833084s]
Feb 22 21:38:48.997: INFO: Got endpoints: latency-svc-nlnq4 [4.633593954s]
Feb 22 21:38:49.064: INFO: Created: latency-svc-tnx9k
Feb 22 21:38:49.095: INFO: Created: latency-svc-w47hm
Feb 22 21:38:49.095: INFO: Got endpoints: latency-svc-tnx9k [4.714809853s]
Feb 22 21:38:49.104: INFO: Got endpoints: latency-svc-w47hm [4.699806228s]
Feb 22 21:38:49.134: INFO: Created: latency-svc-k5trt
Feb 22 21:38:49.148: INFO: Got endpoints: latency-svc-k5trt [4.706009377s]
Feb 22 21:38:49.180: INFO: Created: latency-svc-9x5vh
Feb 22 21:38:49.188: INFO: Got endpoints: latency-svc-9x5vh [4.700665994s]
Feb 22 21:38:49.221: INFO: Created: latency-svc-kckdw
Feb 22 21:38:49.228: INFO: Got endpoints: latency-svc-kckdw [4.69923111s]
Feb 22 21:38:49.264: INFO: Created: latency-svc-ph69w
Feb 22 21:38:49.272: INFO: Got endpoints: latency-svc-ph69w [1.120083263s]
Feb 22 21:38:49.300: INFO: Created: latency-svc-rqh5n
Feb 22 21:38:49.318: INFO: Got endpoints: latency-svc-rqh5n [890.543976ms]
Feb 22 21:38:49.346: INFO: Created: latency-svc-79lnx
Feb 22 21:38:49.356: INFO: Got endpoints: latency-svc-79lnx [808.887171ms]
Feb 22 21:38:49.392: INFO: Created: latency-svc-qcgrj
Feb 22 21:38:49.395: INFO: Got endpoints: latency-svc-qcgrj [785.728096ms]
Feb 22 21:38:49.432: INFO: Created: latency-svc-wq6sx
Feb 22 21:38:49.439: INFO: Got endpoints: latency-svc-wq6sx [719.627936ms]
Feb 22 21:38:49.469: INFO: Created: latency-svc-lm6lt
Feb 22 21:38:49.475: INFO: Got endpoints: latency-svc-lm6lt [677.123086ms]
Feb 22 21:38:49.503: INFO: Created: latency-svc-lg4zq
Feb 22 21:38:49.510: INFO: Got endpoints: latency-svc-lg4zq [652.828709ms]
Feb 22 21:38:49.535: INFO: Created: latency-svc-w5gd9
Feb 22 21:38:49.543: INFO: Got endpoints: latency-svc-w5gd9 [628.27057ms]
Feb 22 21:38:49.573: INFO: Created: latency-svc-fjr6j
Feb 22 21:38:49.589: INFO: Got endpoints: latency-svc-fjr6j [623.385907ms]
Feb 22 21:38:49.630: INFO: Created: latency-svc-r5xp8
Feb 22 21:38:49.635: INFO: Got endpoints: latency-svc-r5xp8 [638.882839ms]
Feb 22 21:38:49.670: INFO: Created: latency-svc-jmzqh
Feb 22 21:38:49.677: INFO: Got endpoints: latency-svc-jmzqh [581.422352ms]
Feb 22 21:38:49.695: INFO: Created: latency-svc-qp8s7
Feb 22 21:38:49.718: INFO: Got endpoints: latency-svc-qp8s7 [613.287328ms]
Feb 22 21:38:49.732: INFO: Created: latency-svc-hrrnb
Feb 22 21:38:49.741: INFO: Got endpoints: latency-svc-hrrnb [592.917555ms]
Feb 22 21:38:49.763: INFO: Created: latency-svc-2rhrp
Feb 22 21:38:49.779: INFO: Got endpoints: latency-svc-2rhrp [591.640915ms]
Feb 22 21:38:49.803: INFO: Created: latency-svc-s466h
Feb 22 21:38:49.809: INFO: Got endpoints: latency-svc-s466h [581.092965ms]
Feb 22 21:38:49.839: INFO: Created: latency-svc-7xfcj
Feb 22 21:38:49.855: INFO: Got endpoints: latency-svc-7xfcj [583.46457ms]
Feb 22 21:38:49.876: INFO: Created: latency-svc-bz7tg
Feb 22 21:38:49.902: INFO: Created: latency-svc-t8tqh
Feb 22 21:38:49.915: INFO: Got endpoints: latency-svc-bz7tg [596.670211ms]
Feb 22 21:38:49.934: INFO: Got endpoints: latency-svc-t8tqh [578.004988ms]
Feb 22 21:38:49.952: INFO: Created: latency-svc-zf8jw
Feb 22 21:38:49.960: INFO: Got endpoints: latency-svc-zf8jw [565.152617ms]
Feb 22 21:38:49.960: INFO: Latencies: [59.02243ms 117.241528ms 128.287775ms 132.705913ms 165.163348ms 202.925397ms 226.441391ms 451.927495ms 565.152617ms 571.829139ms 574.148367ms 574.590548ms 576.951942ms 578.004988ms 581.092965ms 581.422352ms 583.46457ms 587.680749ms 588.290513ms 591.640915ms 592.917555ms 594.466936ms 596.670211ms 597.731081ms 603.820082ms 612.718089ms 613.287328ms 615.525502ms 616.000643ms 623.385907ms 624.827174ms 628.27057ms 634.433642ms 636.35895ms 636.625862ms 638.882839ms 642.191209ms 643.169058ms 648.451571ms 652.828709ms 654.632336ms 655.306229ms 655.481922ms 655.61997ms 658.141674ms 661.389126ms 665.228314ms 665.680445ms 668.528151ms 669.624407ms 670.356932ms 670.673343ms 671.447921ms 674.99574ms 676.342959ms 676.66796ms 677.123086ms 681.56911ms 681.968844ms 682.692074ms 691.237864ms 691.734082ms 693.963713ms 695.857476ms 696.599885ms 697.824317ms 698.150249ms 698.77323ms 698.928032ms 701.387296ms 702.399714ms 705.255036ms 707.129129ms 708.220321ms 710.993329ms 711.1699ms 711.210283ms 712.19759ms 712.728416ms 714.920688ms 715.187281ms 719.031528ms 719.627936ms 720.455222ms 720.580741ms 723.444828ms 726.395321ms 726.561463ms 737.670178ms 738.390032ms 742.512943ms 744.971748ms 752.020516ms 754.642848ms 757.070678ms 758.057607ms 761.195048ms 768.14413ms 770.212492ms 773.019688ms 777.515207ms 785.728096ms 787.349194ms 787.827839ms 801.42845ms 804.950569ms 806.234146ms 808.887171ms 810.47153ms 813.84149ms 815.783026ms 819.654802ms 821.53762ms 822.974417ms 832.579326ms 833.457906ms 836.00354ms 837.25593ms 840.790174ms 841.689064ms 842.157352ms 844.373561ms 844.965222ms 851.130614ms 857.004047ms 857.18915ms 859.949538ms 877.52721ms 890.543976ms 892.964774ms 893.031834ms 899.346702ms 899.514891ms 902.320729ms 907.608105ms 910.144064ms 973.807051ms 994.261519ms 997.079215ms 1.01999857s 1.02363899s 1.026926697s 1.027500003s 1.029315592s 1.031759986s 1.035983085s 1.041229798s 1.043159882s 1.049880276s 1.058406007s 1.062277783s 1.076098417s 1.120083263s 1.128906906s 1.12959294s 1.157101764s 1.203157945s 1.258771356s 1.268388401s 1.269932814s 1.348351417s 1.350463206s 1.385971204s 1.396253261s 1.535210501s 1.597123089s 1.633087966s 1.653778652s 1.685272476s 1.723838751s 1.812306048s 1.815710698s 1.829451358s 1.834168071s 1.839403679s 1.847147701s 1.851624419s 1.853349689s 1.858461599s 1.863111469s 1.864805776s 1.86567705s 1.875679427s 1.917210436s 1.921907904s 4.303470747s 4.518814353s 4.52313244s 4.564803565s 4.606971973s 4.619833084s 4.633593954s 4.646264519s 4.676025875s 4.686242341s 4.69923111s 4.699806228s 4.700665994s 4.706009377s 4.714809853s]
Feb 22 21:38:49.961: INFO: 50 %ile: 777.515207ms
Feb 22 21:38:49.961: INFO: 90 %ile: 1.864805776s
Feb 22 21:38:49.961: INFO: 99 %ile: 4.706009377s
Feb 22 21:38:49.961: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:38:49.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-klh9c" for this suite.
Feb 22 21:39:18.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:39:18.051: INFO: namespace: e2e-tests-svc-latency-klh9c, resource: bindings, ignored listing per whitelist
Feb 22 21:39:18.284: INFO: namespace e2e-tests-svc-latency-klh9c deletion completed in 28.316692436s

• [SLOW TEST:46.493 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:39:18.286: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-rjl9l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rjl9l to expose endpoints map[]
Feb 22 21:39:18.568: INFO: Get endpoints failed (43.240675ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 22 21:39:19.573: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rjl9l exposes endpoints map[] (1.048125237s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-rjl9l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rjl9l to expose endpoints map[pod1:[100]]
Feb 22 21:39:23.719: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rjl9l exposes endpoints map[pod1:[100]] (4.1185498s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-rjl9l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rjl9l to expose endpoints map[pod1:[100] pod2:[101]]
Feb 22 21:39:26.911: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rjl9l exposes endpoints map[pod1:[100] pod2:[101]] (3.161386501s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-rjl9l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rjl9l to expose endpoints map[pod2:[101]]
Feb 22 21:39:27.101: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rjl9l exposes endpoints map[pod2:[101]] (163.263329ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-rjl9l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rjl9l to expose endpoints map[]
Feb 22 21:39:28.464: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rjl9l exposes endpoints map[] (1.214462878s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:39:28.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rjl9l" for this suite.
Feb 22 21:39:39.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:39:39.498: INFO: namespace: e2e-tests-services-rjl9l, resource: bindings, ignored listing per whitelist
Feb 22 21:39:39.562: INFO: namespace e2e-tests-services-rjl9l deletion completed in 10.529773297s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:21.276 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:39:39.565: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 22 21:39:39.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 cluster-info'
Feb 22 21:39:39.953: INFO: stderr: ""
Feb 22 21:39:39.953: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:39:39.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hdbxz" for this suite.
Feb 22 21:39:45.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:39:46.207: INFO: namespace: e2e-tests-kubectl-hdbxz, resource: bindings, ignored listing per whitelist
Feb 22 21:39:46.345: INFO: namespace e2e-tests-kubectl-hdbxz deletion completed in 6.378115366s

• [SLOW TEST:6.781 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:39:46.347: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-2lh5n.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-2lh5n.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-2lh5n.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-2lh5n.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-2lh5n.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-2lh5n.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 21:40:18.789: INFO: DNS probes using e2e-tests-dns-2lh5n/dns-test-5f949b30-36ea-11e9-9d47-0276c9498759 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:40:18.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-2lh5n" for this suite.
Feb 22 21:40:27.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:40:27.272: INFO: namespace: e2e-tests-dns-2lh5n, resource: bindings, ignored listing per whitelist
Feb 22 21:40:27.367: INFO: namespace e2e-tests-dns-2lh5n deletion completed in 8.426938198s

• [SLOW TEST:41.020 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:40:27.368: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-780e474b-36ea-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 21:40:27.684: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-780fad9c-36ea-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-vx48z" to be "success or failure"
Feb 22 21:40:27.746: INFO: Pod "pod-projected-configmaps-780fad9c-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 61.829518ms
Feb 22 21:40:29.785: INFO: Pod "pod-projected-configmaps-780fad9c-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100693431s
Feb 22 21:40:31.794: INFO: Pod "pod-projected-configmaps-780fad9c-36ea-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109182025s
STEP: Saw pod success
Feb 22 21:40:31.794: INFO: Pod "pod-projected-configmaps-780fad9c-36ea-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:40:31.804: INFO: Trying to get logs from node conformance112-3 pod pod-projected-configmaps-780fad9c-36ea-11e9-9d47-0276c9498759 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:40:31.914: INFO: Waiting for pod pod-projected-configmaps-780fad9c-36ea-11e9-9d47-0276c9498759 to disappear
Feb 22 21:40:31.924: INFO: Pod pod-projected-configmaps-780fad9c-36ea-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:40:31.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vx48z" for this suite.
Feb 22 21:40:40.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:40:40.111: INFO: namespace: e2e-tests-projected-vx48z, resource: bindings, ignored listing per whitelist
Feb 22 21:40:40.361: INFO: namespace e2e-tests-projected-vx48z deletion completed in 8.411290233s

• [SLOW TEST:12.993 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:40:40.365: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-7l2px/configmap-test-7fc8808f-36ea-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 21:40:40.627: INFO: Waiting up to 5m0s for pod "pod-configmaps-7fcd45a8-36ea-11e9-9d47-0276c9498759" in namespace "e2e-tests-configmap-7l2px" to be "success or failure"
Feb 22 21:40:40.664: INFO: Pod "pod-configmaps-7fcd45a8-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 36.763646ms
Feb 22 21:40:42.670: INFO: Pod "pod-configmaps-7fcd45a8-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042847034s
Feb 22 21:40:44.678: INFO: Pod "pod-configmaps-7fcd45a8-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051331036s
Feb 22 21:40:46.685: INFO: Pod "pod-configmaps-7fcd45a8-36ea-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.057665178s
STEP: Saw pod success
Feb 22 21:40:46.685: INFO: Pod "pod-configmaps-7fcd45a8-36ea-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:40:46.691: INFO: Trying to get logs from node conformance112-2 pod pod-configmaps-7fcd45a8-36ea-11e9-9d47-0276c9498759 container env-test: <nil>
STEP: delete the pod
Feb 22 21:40:46.902: INFO: Waiting for pod pod-configmaps-7fcd45a8-36ea-11e9-9d47-0276c9498759 to disappear
Feb 22 21:40:46.919: INFO: Pod pod-configmaps-7fcd45a8-36ea-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:40:46.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7l2px" for this suite.
Feb 22 21:40:54.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:40:55.421: INFO: namespace: e2e-tests-configmap-7l2px, resource: bindings, ignored listing per whitelist
Feb 22 21:40:55.421: INFO: namespace e2e-tests-configmap-7l2px deletion completed in 8.495587753s

• [SLOW TEST:15.057 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:40:55.424: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-88bfe1e9-36ea-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 21:40:55.669: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-88c2be08-36ea-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-zt4ww" to be "success or failure"
Feb 22 21:40:55.696: INFO: Pod "pod-projected-configmaps-88c2be08-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 26.871597ms
Feb 22 21:40:58.125: INFO: Pod "pod-projected-configmaps-88c2be08-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.455314328s
Feb 22 21:41:00.131: INFO: Pod "pod-projected-configmaps-88c2be08-36ea-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.461558654s
STEP: Saw pod success
Feb 22 21:41:00.131: INFO: Pod "pod-projected-configmaps-88c2be08-36ea-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:41:00.136: INFO: Trying to get logs from node conformance112-3 pod pod-projected-configmaps-88c2be08-36ea-11e9-9d47-0276c9498759 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 21:41:00.186: INFO: Waiting for pod pod-projected-configmaps-88c2be08-36ea-11e9-9d47-0276c9498759 to disappear
Feb 22 21:41:00.195: INFO: Pod pod-projected-configmaps-88c2be08-36ea-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:41:00.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zt4ww" for this suite.
Feb 22 21:41:06.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:41:06.513: INFO: namespace: e2e-tests-projected-zt4ww, resource: bindings, ignored listing per whitelist
Feb 22 21:41:06.523: INFO: namespace e2e-tests-projected-zt4ww deletion completed in 6.297491535s

• [SLOW TEST:11.100 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:41:06.530: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 22 21:41:06.689: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-109334344 proxy --unix-socket=/tmp/kubectl-proxy-unix322151943/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:41:06.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2k58x" for this suite.
Feb 22 21:41:16.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:41:16.890: INFO: namespace: e2e-tests-kubectl-2k58x, resource: bindings, ignored listing per whitelist
Feb 22 21:41:17.195: INFO: namespace e2e-tests-kubectl-2k58x deletion completed in 10.376131014s

• [SLOW TEST:10.665 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:41:17.199: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:41:17.415: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95baab6f-36ea-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-ktxjt" to be "success or failure"
Feb 22 21:41:17.454: INFO: Pod "downwardapi-volume-95baab6f-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 38.612462ms
Feb 22 21:41:19.460: INFO: Pod "downwardapi-volume-95baab6f-36ea-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044878255s
Feb 22 21:41:21.473: INFO: Pod "downwardapi-volume-95baab6f-36ea-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057604485s
STEP: Saw pod success
Feb 22 21:41:21.473: INFO: Pod "downwardapi-volume-95baab6f-36ea-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:41:21.486: INFO: Trying to get logs from node conformance112-2 pod downwardapi-volume-95baab6f-36ea-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 21:41:22.897: INFO: Waiting for pod downwardapi-volume-95baab6f-36ea-11e9-9d47-0276c9498759 to disappear
Feb 22 21:41:22.951: INFO: Pod downwardapi-volume-95baab6f-36ea-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:41:22.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ktxjt" for this suite.
Feb 22 21:41:33.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:41:33.212: INFO: namespace: e2e-tests-projected-ktxjt, resource: bindings, ignored listing per whitelist
Feb 22 21:41:33.260: INFO: namespace e2e-tests-projected-ktxjt deletion completed in 10.301460347s

• [SLOW TEST:16.062 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:41:33.265: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 22 21:41:33.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:34.106: INFO: stderr: ""
Feb 22 21:41:34.106: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 21:41:34.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:34.316: INFO: stderr: ""
Feb 22 21:41:34.316: INFO: stdout: "update-demo-nautilus-7gqch update-demo-nautilus-hk8bx "
Feb 22 21:41:34.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-7gqch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:34.513: INFO: stderr: ""
Feb 22 21:41:34.513: INFO: stdout: ""
Feb 22 21:41:34.513: INFO: update-demo-nautilus-7gqch is created but not running
Feb 22 21:41:39.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:39.645: INFO: stderr: ""
Feb 22 21:41:39.645: INFO: stdout: "update-demo-nautilus-7gqch update-demo-nautilus-hk8bx "
Feb 22 21:41:39.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-7gqch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:39.803: INFO: stderr: ""
Feb 22 21:41:39.803: INFO: stdout: "true"
Feb 22 21:41:39.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-7gqch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:39.940: INFO: stderr: ""
Feb 22 21:41:39.940: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:41:39.940: INFO: validating pod update-demo-nautilus-7gqch
Feb 22 21:41:39.953: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:41:39.953: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:41:39.953: INFO: update-demo-nautilus-7gqch is verified up and running
Feb 22 21:41:39.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-hk8bx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:40.132: INFO: stderr: ""
Feb 22 21:41:40.132: INFO: stdout: "true"
Feb 22 21:41:40.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-hk8bx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:40.292: INFO: stderr: ""
Feb 22 21:41:40.292: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:41:40.292: INFO: validating pod update-demo-nautilus-hk8bx
Feb 22 21:41:40.301: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:41:40.301: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:41:40.301: INFO: update-demo-nautilus-hk8bx is verified up and running
STEP: scaling down the replication controller
Feb 22 21:41:40.304: INFO: scanned /root for discovery docs: <nil>
Feb 22 21:41:40.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:41.591: INFO: stderr: ""
Feb 22 21:41:41.591: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 21:41:41.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:41.769: INFO: stderr: ""
Feb 22 21:41:41.769: INFO: stdout: "update-demo-nautilus-7gqch update-demo-nautilus-hk8bx "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 22 21:41:46.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:46.956: INFO: stderr: ""
Feb 22 21:41:46.956: INFO: stdout: "update-demo-nautilus-7gqch update-demo-nautilus-hk8bx "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 22 21:41:51.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:52.123: INFO: stderr: ""
Feb 22 21:41:52.123: INFO: stdout: "update-demo-nautilus-7gqch update-demo-nautilus-hk8bx "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 22 21:41:57.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:57.305: INFO: stderr: ""
Feb 22 21:41:57.305: INFO: stdout: "update-demo-nautilus-7gqch "
Feb 22 21:41:57.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-7gqch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:41:57.484: INFO: stderr: ""
Feb 22 21:41:57.484: INFO: stdout: "true"
Feb 22 21:41:57.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-7gqch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:42:02.242: INFO: stderr: ""
Feb 22 21:42:02.242: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:42:02.242: INFO: validating pod update-demo-nautilus-7gqch
Feb 22 21:42:02.260: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:42:02.260: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:42:02.260: INFO: update-demo-nautilus-7gqch is verified up and running
STEP: scaling up the replication controller
Feb 22 21:42:02.263: INFO: scanned /root for discovery docs: <nil>
Feb 22 21:42:02.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:42:03.628: INFO: stderr: ""
Feb 22 21:42:03.628: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 21:42:03.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:42:03.782: INFO: stderr: ""
Feb 22 21:42:03.782: INFO: stdout: "update-demo-nautilus-2zlts update-demo-nautilus-7gqch "
Feb 22 21:42:03.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-2zlts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:42:03.912: INFO: stderr: ""
Feb 22 21:42:03.912: INFO: stdout: ""
Feb 22 21:42:03.912: INFO: update-demo-nautilus-2zlts is created but not running
Feb 22 21:42:08.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:42:09.049: INFO: stderr: ""
Feb 22 21:42:09.049: INFO: stdout: "update-demo-nautilus-2zlts update-demo-nautilus-7gqch "
Feb 22 21:42:09.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-2zlts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:42:09.191: INFO: stderr: ""
Feb 22 21:42:09.191: INFO: stdout: "true"
Feb 22 21:42:09.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-2zlts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:42:09.326: INFO: stderr: ""
Feb 22 21:42:09.326: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:42:09.326: INFO: validating pod update-demo-nautilus-2zlts
Feb 22 21:42:09.347: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:42:09.347: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:42:09.347: INFO: update-demo-nautilus-2zlts is verified up and running
Feb 22 21:42:09.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-7gqch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:42:09.507: INFO: stderr: ""
Feb 22 21:42:09.507: INFO: stdout: "true"
Feb 22 21:42:09.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-7gqch -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:42:09.645: INFO: stderr: ""
Feb 22 21:42:09.646: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 21:42:09.646: INFO: validating pod update-demo-nautilus-7gqch
Feb 22 21:42:09.652: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 21:42:09.652: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 21:42:09.652: INFO: update-demo-nautilus-7gqch is verified up and running
STEP: using delete to clean up resources
Feb 22 21:42:09.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:42:09.836: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 21:42:09.836: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 22 21:42:09.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-kn6pk'
Feb 22 21:42:10.010: INFO: stderr: "No resources found.\n"
Feb 22 21:42:10.010: INFO: stdout: ""
Feb 22 21:42:10.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -l name=update-demo --namespace=e2e-tests-kubectl-kn6pk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 21:42:10.154: INFO: stderr: ""
Feb 22 21:42:10.154: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:42:10.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kn6pk" for this suite.
Feb 22 21:42:38.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:42:38.382: INFO: namespace: e2e-tests-kubectl-kn6pk, resource: bindings, ignored listing per whitelist
Feb 22 21:42:38.524: INFO: namespace e2e-tests-kubectl-kn6pk deletion completed in 28.363789755s

• [SLOW TEST:65.260 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:42:38.525: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-c62ca537-36ea-11e9-9d47-0276c9498759
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-c62ca537-36ea-11e9-9d47-0276c9498759
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:42:42.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k2f4r" for this suite.
Feb 22 21:43:06.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:43:07.099: INFO: namespace: e2e-tests-configmap-k2f4r, resource: bindings, ignored listing per whitelist
Feb 22 21:43:07.168: INFO: namespace e2e-tests-configmap-k2f4r deletion completed in 24.342611202s

• [SLOW TEST:28.644 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:43:07.172: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 22 21:43:07.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-sg5qk'
Feb 22 21:43:07.710: INFO: stderr: ""
Feb 22 21:43:07.710: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 22 21:43:08.717: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:43:08.717: INFO: Found 0 / 1
Feb 22 21:43:09.717: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:43:09.717: INFO: Found 1 / 1
Feb 22 21:43:09.717: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 22 21:43:09.723: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:43:09.723: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 22 21:43:09.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 patch pod redis-master-65nrm --namespace=e2e-tests-kubectl-sg5qk -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 22 21:43:09.926: INFO: stderr: ""
Feb 22 21:43:09.926: INFO: stdout: "pod/redis-master-65nrm patched\n"
STEP: checking annotations
Feb 22 21:43:09.934: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:43:09.934: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:43:09.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sg5qk" for this suite.
Feb 22 21:43:35.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:43:36.412: INFO: namespace: e2e-tests-kubectl-sg5qk, resource: bindings, ignored listing per whitelist
Feb 22 21:43:36.413: INFO: namespace e2e-tests-kubectl-sg5qk deletion completed in 26.467835675s

• [SLOW TEST:29.241 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:43:36.413: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:43:36.617: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 22 21:43:36.660: INFO: Number of nodes with available pods: 0
Feb 22 21:43:36.660: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:43:37.708: INFO: Number of nodes with available pods: 0
Feb 22 21:43:37.709: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:43:38.702: INFO: Number of nodes with available pods: 0
Feb 22 21:43:38.703: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 21:43:39.711: INFO: Number of nodes with available pods: 2
Feb 22 21:43:39.711: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 21:43:40.688: INFO: Number of nodes with available pods: 2
Feb 22 21:43:40.689: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 21:43:41.682: INFO: Number of nodes with available pods: 3
Feb 22 21:43:41.683: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 22 21:43:41.827: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:41.827: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:41.827: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:42.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:42.850: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:42.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:43.860: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:43.860: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:43.860: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:44.853: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:44.853: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:44.853: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:46.221: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:46.221: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:46.221: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:48.888: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:48.888: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:48.888: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:49.851: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:49.851: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:49.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:50.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:50.850: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:50.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:51.852: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:51.852: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:51.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:52.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:52.850: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:52.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:53.851: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:53.851: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:53.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:54.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:54.850: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:54.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:55.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:55.850: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:55.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:56.849: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:56.849: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:56.849: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:57.849: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:57.849: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:57.849: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:58.851: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:58.852: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:58.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:59.866: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:59.866: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:43:59.866: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:00.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:00.850: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:00.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:01.852: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:01.852: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:01.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:02.851: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:02.851: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:02.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:03.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:03.851: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:03.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:04.851: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:04.851: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:04.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:07.857: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:07.857: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:07.857: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:12.409: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:12.409: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:12.409: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:12.865: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:12.865: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:12.865: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:13.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:13.850: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:13.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:14.853: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:14.853: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:14.853: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:15.885: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:15.885: INFO: Wrong image for pod: daemon-set-t9g4t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:15.885: INFO: Pod daemon-set-t9g4t is not available
Feb 22 21:44:15.885: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:16.852: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:16.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:16.852: INFO: Pod daemon-set-x5255 is not available
Feb 22 21:44:17.899: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:17.899: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:17.900: INFO: Pod daemon-set-x5255 is not available
Feb 22 21:44:18.854: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:18.854: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:18.854: INFO: Pod daemon-set-x5255 is not available
Feb 22 21:44:20.147: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:20.147: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:20.947: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:20.947: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:21.865: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:21.865: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:26.436: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:26.436: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:26.870: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:26.870: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:27.878: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:27.879: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:28.916: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:28.917: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:29.912: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:29.912: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:33.454: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:33.454: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:33.928: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:33.928: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:34.849: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:34.849: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:35.854: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:35.854: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:36.876: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:36.876: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:37.849: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:37.849: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:38.851: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:38.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:40.430: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:40.430: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:40.856: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:40.857: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:42.250: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:42.250: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:42.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:42.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:43.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:43.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:48.192: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:48.192: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:48.854: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:48.855: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:49.852: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:49.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:50.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:50.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:51.851: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:51.851: INFO: Pod daemon-set-h2g4l is not available
Feb 22 21:44:51.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:52.855: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:52.855: INFO: Pod daemon-set-h2g4l is not available
Feb 22 21:44:52.855: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:53.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:53.850: INFO: Pod daemon-set-h2g4l is not available
Feb 22 21:44:53.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:54.851: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:54.852: INFO: Pod daemon-set-h2g4l is not available
Feb 22 21:44:54.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:55.851: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:55.851: INFO: Pod daemon-set-h2g4l is not available
Feb 22 21:44:55.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:57.089: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:57.090: INFO: Pod daemon-set-h2g4l is not available
Feb 22 21:44:57.090: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:57.852: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:57.852: INFO: Pod daemon-set-h2g4l is not available
Feb 22 21:44:57.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:58.928: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:58.928: INFO: Pod daemon-set-h2g4l is not available
Feb 22 21:44:58.928: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:59.850: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:44:59.850: INFO: Pod daemon-set-h2g4l is not available
Feb 22 21:44:59.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:00.854: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:00.854: INFO: Pod daemon-set-h2g4l is not available
Feb 22 21:45:00.854: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:01.853: INFO: Wrong image for pod: daemon-set-h2g4l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:01.853: INFO: Pod daemon-set-h2g4l is not available
Feb 22 21:45:01.853: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:02.851: INFO: Pod daemon-set-bdnlv is not available
Feb 22 21:45:02.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:03.850: INFO: Pod daemon-set-bdnlv is not available
Feb 22 21:45:03.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:04.849: INFO: Pod daemon-set-bdnlv is not available
Feb 22 21:45:04.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:05.852: INFO: Pod daemon-set-bdnlv is not available
Feb 22 21:45:05.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:06.856: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:07.849: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:08.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:09.859: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:10.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:11.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:12.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:13.856: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:14.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:15.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:16.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:17.865: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:18.853: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:19.859: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:20.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:23.877: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:24.866: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:25.854: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:26.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:27.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:28.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:29.849: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:30.861: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:31.852: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:32.851: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:33.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:38.140: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:38.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:39.850: INFO: Wrong image for pod: daemon-set-v7sx5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 22 21:45:39.850: INFO: Pod daemon-set-v7sx5 is not available
Feb 22 21:45:40.856: INFO: Pod daemon-set-bvkwr is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 22 21:45:40.938: INFO: Number of nodes with available pods: 2
Feb 22 21:45:40.938: INFO: Node conformance112-3 is running more than one daemon pod
Feb 22 21:45:41.967: INFO: Number of nodes with available pods: 2
Feb 22 21:45:41.967: INFO: Node conformance112-3 is running more than one daemon pod
Feb 22 21:45:44.781: INFO: Number of nodes with available pods: 3
Feb 22 21:45:44.781: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-849jf, will wait for the garbage collector to delete the pods
Feb 22 21:45:44.982: INFO: Deleting {extensions DaemonSet} daemon-set took: 61.650277ms
Feb 22 21:45:45.182: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.504987ms
Feb 22 21:45:53.434: INFO: Number of nodes with available pods: 0
Feb 22 21:45:53.435: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 21:45:53.467: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-849jf/daemonsets","resourceVersion":"10552"},"items":null}

Feb 22 21:45:53.475: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-849jf/pods","resourceVersion":"10552"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:45:53.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-849jf" for this suite.
Feb 22 21:46:01.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:46:01.835: INFO: namespace: e2e-tests-daemonsets-849jf, resource: bindings, ignored listing per whitelist
Feb 22 21:46:01.986: INFO: namespace e2e-tests-daemonsets-849jf deletion completed in 8.457417287s

• [SLOW TEST:145.574 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:46:01.990: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-92gfx A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-92gfx;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-92gfx A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-92gfx;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-92gfx.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-92gfx.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-92gfx.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-92gfx.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-92gfx.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-92gfx.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-92gfx.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-92gfx.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-92gfx.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-92gfx.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-92gfx.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-92gfx.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-92gfx.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 175.186.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.186.175_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 175.186.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.186.175_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-92gfx A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-92gfx;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-92gfx A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-92gfx;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-92gfx.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-92gfx.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-92gfx.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-92gfx.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-92gfx.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-92gfx.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-92gfx.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-92gfx.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-92gfx.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-92gfx.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-92gfx.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-92gfx.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-92gfx.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 175.186.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.186.175_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 175.186.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.186.175_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 21:46:26.904: INFO: DNS probes using e2e-tests-dns-92gfx/dns-test-3f8e0f9f-36eb-11e9-9d47-0276c9498759 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:46:27.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-92gfx" for this suite.
Feb 22 21:46:35.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:46:35.427: INFO: namespace: e2e-tests-dns-92gfx, resource: bindings, ignored listing per whitelist
Feb 22 21:46:35.492: INFO: namespace e2e-tests-dns-92gfx deletion completed in 8.318545998s

• [SLOW TEST:33.502 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:46:35.494: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-fl49
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 21:46:35.714: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-fl49" in namespace "e2e-tests-subpath-m6jnv" to be "success or failure"
Feb 22 21:46:35.739: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Pending", Reason="", readiness=false. Elapsed: 25.115436ms
Feb 22 21:46:38.359: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.644912416s
Feb 22 21:46:40.375: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Running", Reason="", readiness=false. Elapsed: 4.660566039s
Feb 22 21:46:42.738: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Running", Reason="", readiness=false. Elapsed: 7.024358121s
Feb 22 21:46:44.747: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Running", Reason="", readiness=false. Elapsed: 9.033445191s
Feb 22 21:46:46.753: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Running", Reason="", readiness=false. Elapsed: 11.039259922s
Feb 22 21:46:48.813: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Running", Reason="", readiness=false. Elapsed: 13.098781576s
Feb 22 21:46:50.829: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Running", Reason="", readiness=false. Elapsed: 15.114635584s
Feb 22 21:46:52.840: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Running", Reason="", readiness=false. Elapsed: 17.126321382s
Feb 22 21:46:54.852: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Running", Reason="", readiness=false. Elapsed: 19.137728792s
Feb 22 21:46:56.869: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Running", Reason="", readiness=false. Elapsed: 21.154626604s
Feb 22 21:46:58.941: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Running", Reason="", readiness=false. Elapsed: 23.227415029s
Feb 22 21:47:00.948: INFO: Pod "pod-subpath-test-projected-fl49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 25.234368217s
STEP: Saw pod success
Feb 22 21:47:00.948: INFO: Pod "pod-subpath-test-projected-fl49" satisfied condition "success or failure"
Feb 22 21:47:00.961: INFO: Trying to get logs from node conformance112-3 pod pod-subpath-test-projected-fl49 container test-container-subpath-projected-fl49: <nil>
STEP: delete the pod
Feb 22 21:47:01.074: INFO: Waiting for pod pod-subpath-test-projected-fl49 to disappear
Feb 22 21:47:01.104: INFO: Pod pod-subpath-test-projected-fl49 no longer exists
STEP: Deleting pod pod-subpath-test-projected-fl49
Feb 22 21:47:01.105: INFO: Deleting pod "pod-subpath-test-projected-fl49" in namespace "e2e-tests-subpath-m6jnv"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:47:01.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-m6jnv" for this suite.
Feb 22 21:47:07.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:47:07.649: INFO: namespace: e2e-tests-subpath-m6jnv, resource: bindings, ignored listing per whitelist
Feb 22 21:47:07.772: INFO: namespace e2e-tests-subpath-m6jnv deletion completed in 6.649981949s

• [SLOW TEST:32.279 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:47:07.776: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-dbdfs
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 22 21:47:07.959: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 22 21:47:34.347: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.42.0.18:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dbdfs PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:47:34.347: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 21:47:34.675: INFO: Found all expected endpoints: [netserver-0]
Feb 22 21:47:34.680: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.42.1.41:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dbdfs PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:47:34.680: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 21:47:35.090: INFO: Found all expected endpoints: [netserver-1]
Feb 22 21:47:35.096: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.42.2.44:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dbdfs PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:47:35.097: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 21:47:35.454: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:47:35.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-dbdfs" for this suite.
Feb 22 21:48:03.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:48:04.018: INFO: namespace: e2e-tests-pod-network-test-dbdfs, resource: bindings, ignored listing per whitelist
Feb 22 21:48:04.147: INFO: namespace e2e-tests-pod-network-test-dbdfs deletion completed in 28.685878795s

• [SLOW TEST:56.371 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:48:04.147: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 22 21:48:06.867: INFO: Successfully updated pod "pod-update-activedeadlineseconds-883fcc7f-36eb-11e9-9d47-0276c9498759"
Feb 22 21:48:06.868: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-883fcc7f-36eb-11e9-9d47-0276c9498759" in namespace "e2e-tests-pods-jmg9l" to be "terminated due to deadline exceeded"
Feb 22 21:48:06.873: INFO: Pod "pod-update-activedeadlineseconds-883fcc7f-36eb-11e9-9d47-0276c9498759": Phase="Running", Reason="", readiness=true. Elapsed: 5.357451ms
Feb 22 21:48:08.880: INFO: Pod "pod-update-activedeadlineseconds-883fcc7f-36eb-11e9-9d47-0276c9498759": Phase="Running", Reason="", readiness=true. Elapsed: 2.011468223s
Feb 22 21:48:10.885: INFO: Pod "pod-update-activedeadlineseconds-883fcc7f-36eb-11e9-9d47-0276c9498759": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.016947997s
Feb 22 21:48:10.885: INFO: Pod "pod-update-activedeadlineseconds-883fcc7f-36eb-11e9-9d47-0276c9498759" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:48:10.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jmg9l" for this suite.
Feb 22 21:48:16.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:48:17.032: INFO: namespace: e2e-tests-pods-jmg9l, resource: bindings, ignored listing per whitelist
Feb 22 21:48:17.244: INFO: namespace e2e-tests-pods-jmg9l deletion completed in 6.350761916s

• [SLOW TEST:13.097 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:48:17.247: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Feb 22 21:48:23.783: INFO: 0 pods remaining
Feb 22 21:48:23.783: INFO: 0 pods has nil DeletionTimestamp
Feb 22 21:48:23.783: INFO: 
STEP: Gathering metrics
W0222 21:48:24.510197      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 21:48:24.510: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:48:24.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8qvln" for this suite.
Feb 22 21:48:35.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:48:35.579: INFO: namespace: e2e-tests-gc-8qvln, resource: bindings, ignored listing per whitelist
Feb 22 21:48:35.778: INFO: namespace e2e-tests-gc-8qvln deletion completed in 11.264392384s

• [SLOW TEST:18.532 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:48:35.779: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 22 21:48:44.000: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 21:48:44.013: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 21:48:46.013: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 21:48:46.019: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 21:48:48.014: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 21:48:48.028: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 21:48:50.014: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 21:48:50.020: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 21:48:52.013: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 21:48:52.018: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 21:48:54.013: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 21:48:54.019: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:48:54.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-x6hcd" for this suite.
Feb 22 21:49:16.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:49:16.256: INFO: namespace: e2e-tests-container-lifecycle-hook-x6hcd, resource: bindings, ignored listing per whitelist
Feb 22 21:49:16.276: INFO: namespace e2e-tests-container-lifecycle-hook-x6hcd deletion completed in 22.23859971s

• [SLOW TEST:40.498 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:49:16.281: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 22 21:49:18.459: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-b33ecceb-36eb-11e9-9d47-0276c9498759,GenerateName:,Namespace:e2e-tests-events-sx257,SelfLink:/api/v1/namespaces/e2e-tests-events-sx257/pods/send-events-b33ecceb-36eb-11e9-9d47-0276c9498759,UID:b34215e6-36eb-11e9-b930-96c406f7d171,ResourceVersion:11452,Generation:0,CreationTimestamp:2019-02-22 21:49:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 396265603,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.46/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6gpjr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6gpjr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-6gpjr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121e420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121e440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:49:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:49:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:49:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 21:49:16 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:10.42.1.46,StartTime:2019-02-22 21:49:16 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-22 21:49:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://e25df44b0f1382f4604df5f68a9c8440d6df05fdf3eb286bb7373a3aa9ed929a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 22 21:49:20.475: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 22 21:49:22.480: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:49:22.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-sx257" for this suite.
Feb 22 21:50:02.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:50:02.648: INFO: namespace: e2e-tests-events-sx257, resource: bindings, ignored listing per whitelist
Feb 22 21:50:02.868: INFO: namespace e2e-tests-events-sx257 deletion completed in 40.364165248s

• [SLOW TEST:46.587 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:50:02.871: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:50:03.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-mxbln" for this suite.
Feb 22 21:50:09.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:50:09.152: INFO: namespace: e2e-tests-services-mxbln, resource: bindings, ignored listing per whitelist
Feb 22 21:50:09.269: INFO: namespace e2e-tests-services-mxbln deletion completed in 6.18597306s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.399 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:50:09.271: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 21:50:45.543: INFO: Container started at 2019-02-22 21:50:11 +0000 UTC, pod became ready at 2019-02-22 21:50:43 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:50:45.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cg6vq" for this suite.
Feb 22 21:51:07.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:51:07.701: INFO: namespace: e2e-tests-container-probe-cg6vq, resource: bindings, ignored listing per whitelist
Feb 22 21:51:07.740: INFO: namespace e2e-tests-container-probe-cg6vq deletion completed in 22.189741305s

• [SLOW TEST:58.469 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:51:07.743: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Feb 22 21:51:07.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-vhg7v'
Feb 22 21:51:08.077: INFO: stderr: ""
Feb 22 21:51:08.077: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 22 21:51:09.086: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:51:09.086: INFO: Found 0 / 1
Feb 22 21:51:10.082: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:51:10.083: INFO: Found 1 / 1
Feb 22 21:51:10.083: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 22 21:51:10.088: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 21:51:10.089: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 22 21:51:10.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 logs redis-master-qgdml redis-master --namespace=e2e-tests-kubectl-vhg7v'
Feb 22 21:51:10.209: INFO: stderr: ""
Feb 22 21:51:10.209: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Feb 21:51:09.314 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Feb 21:51:09.314 # Server started, Redis version 3.2.12\n1:M 22 Feb 21:51:09.314 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Feb 21:51:09.314 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 22 21:51:10.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 log redis-master-qgdml redis-master --namespace=e2e-tests-kubectl-vhg7v --tail=1'
Feb 22 21:51:10.315: INFO: stderr: ""
Feb 22 21:51:10.315: INFO: stdout: "1:M 22 Feb 21:51:09.314 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 22 21:51:10.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 log redis-master-qgdml redis-master --namespace=e2e-tests-kubectl-vhg7v --limit-bytes=1'
Feb 22 21:51:10.440: INFO: stderr: ""
Feb 22 21:51:10.440: INFO: stdout: " "
STEP: exposing timestamps
Feb 22 21:51:10.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 log redis-master-qgdml redis-master --namespace=e2e-tests-kubectl-vhg7v --tail=1 --timestamps'
Feb 22 21:51:10.560: INFO: stderr: ""
Feb 22 21:51:10.560: INFO: stdout: "2019-02-22T21:51:09.315281843Z 1:M 22 Feb 21:51:09.314 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 22 21:51:13.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 log redis-master-qgdml redis-master --namespace=e2e-tests-kubectl-vhg7v --since=1s'
Feb 22 21:51:13.177: INFO: stderr: ""
Feb 22 21:51:13.177: INFO: stdout: ""
Feb 22 21:51:13.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 log redis-master-qgdml redis-master --namespace=e2e-tests-kubectl-vhg7v --since=24h'
Feb 22 21:51:13.278: INFO: stderr: ""
Feb 22 21:51:13.278: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Feb 21:51:09.314 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Feb 21:51:09.314 # Server started, Redis version 3.2.12\n1:M 22 Feb 21:51:09.314 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Feb 21:51:09.314 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Feb 22 21:51:13.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vhg7v'
Feb 22 21:51:13.384: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 21:51:13.384: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 22 21:51:13.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-vhg7v'
Feb 22 21:51:13.489: INFO: stderr: "No resources found.\n"
Feb 22 21:51:13.489: INFO: stdout: ""
Feb 22 21:51:13.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -l name=nginx --namespace=e2e-tests-kubectl-vhg7v -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 21:51:13.594: INFO: stderr: ""
Feb 22 21:51:13.594: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:51:13.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vhg7v" for this suite.
Feb 22 21:51:37.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:51:37.660: INFO: namespace: e2e-tests-kubectl-vhg7v, resource: bindings, ignored listing per whitelist
Feb 22 21:51:37.740: INFO: namespace e2e-tests-kubectl-vhg7v deletion completed in 24.140965895s

• [SLOW TEST:29.997 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:51:37.744: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 22 21:51:41.616: INFO: Waiting up to 5m0s for pod "pod-09cb0426-36ec-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-z2t7s" to be "success or failure"
Feb 22 21:51:41.637: INFO: Pod "pod-09cb0426-36ec-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 20.74817ms
Feb 22 21:51:43.642: INFO: Pod "pod-09cb0426-36ec-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025956365s
Feb 22 21:51:45.650: INFO: Pod "pod-09cb0426-36ec-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033821901s
STEP: Saw pod success
Feb 22 21:51:45.650: INFO: Pod "pod-09cb0426-36ec-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:51:45.656: INFO: Trying to get logs from node conformance112-2 pod pod-09cb0426-36ec-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 21:51:45.721: INFO: Waiting for pod pod-09cb0426-36ec-11e9-9d47-0276c9498759 to disappear
Feb 22 21:51:45.735: INFO: Pod pod-09cb0426-36ec-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:51:45.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z2t7s" for this suite.
Feb 22 21:51:51.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:51:51.894: INFO: namespace: e2e-tests-emptydir-z2t7s, resource: bindings, ignored listing per whitelist
Feb 22 21:51:51.916: INFO: namespace e2e-tests-emptydir-z2t7s deletion completed in 6.162326375s

• [SLOW TEST:14.173 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:51:51.921: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:51:52.020: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ffdd38c-36ec-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-9jq6t" to be "success or failure"
Feb 22 21:51:52.031: INFO: Pod "downwardapi-volume-0ffdd38c-36ec-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 10.917673ms
Feb 22 21:51:54.038: INFO: Pod "downwardapi-volume-0ffdd38c-36ec-11e9-9d47-0276c9498759": Phase="Running", Reason="", readiness=true. Elapsed: 2.01763876s
Feb 22 21:51:58.187: INFO: Pod "downwardapi-volume-0ffdd38c-36ec-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.166343021s
STEP: Saw pod success
Feb 22 21:51:58.187: INFO: Pod "downwardapi-volume-0ffdd38c-36ec-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:51:58.194: INFO: Trying to get logs from node conformance112-3 pod downwardapi-volume-0ffdd38c-36ec-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 21:51:58.293: INFO: Waiting for pod downwardapi-volume-0ffdd38c-36ec-11e9-9d47-0276c9498759 to disappear
Feb 22 21:51:58.303: INFO: Pod downwardapi-volume-0ffdd38c-36ec-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:51:58.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9jq6t" for this suite.
Feb 22 21:52:04.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:52:04.452: INFO: namespace: e2e-tests-downward-api-9jq6t, resource: bindings, ignored listing per whitelist
Feb 22 21:52:04.464: INFO: namespace e2e-tests-downward-api-9jq6t deletion completed in 6.149653992s

• [SLOW TEST:12.543 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:52:04.465: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-kncj6
Feb 22 21:52:08.613: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-kncj6
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 21:52:08.620: INFO: Initial restart count of pod liveness-exec is 0
Feb 22 21:53:00.733: INFO: Restart count of pod e2e-tests-container-probe-kncj6/liveness-exec is now 1 (52.113188308s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:53:00.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kncj6" for this suite.
Feb 22 21:53:06.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:53:07.027: INFO: namespace: e2e-tests-container-probe-kncj6, resource: bindings, ignored listing per whitelist
Feb 22 21:53:07.065: INFO: namespace e2e-tests-container-probe-kncj6 deletion completed in 6.254905377s

• [SLOW TEST:62.601 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:53:07.067: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 22 21:53:07.177: INFO: Waiting up to 5m0s for pod "pod-3cca0f10-36ec-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-rqnfh" to be "success or failure"
Feb 22 21:53:07.190: INFO: Pod "pod-3cca0f10-36ec-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 13.371419ms
Feb 22 21:53:09.196: INFO: Pod "pod-3cca0f10-36ec-11e9-9d47-0276c9498759": Phase="Running", Reason="", readiness=true. Elapsed: 2.019275267s
Feb 22 21:53:11.203: INFO: Pod "pod-3cca0f10-36ec-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026236689s
STEP: Saw pod success
Feb 22 21:53:11.203: INFO: Pod "pod-3cca0f10-36ec-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:53:11.207: INFO: Trying to get logs from node conformance112-3 pod pod-3cca0f10-36ec-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 21:53:11.268: INFO: Waiting for pod pod-3cca0f10-36ec-11e9-9d47-0276c9498759 to disappear
Feb 22 21:53:11.273: INFO: Pod pod-3cca0f10-36ec-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:53:11.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rqnfh" for this suite.
Feb 22 21:53:17.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:53:17.381: INFO: namespace: e2e-tests-emptydir-rqnfh, resource: bindings, ignored listing per whitelist
Feb 22 21:53:17.458: INFO: namespace e2e-tests-emptydir-rqnfh deletion completed in 6.178514487s

• [SLOW TEST:10.392 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:53:17.460: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:53:17.575: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42fb9d09-36ec-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-5sksr" to be "success or failure"
Feb 22 21:53:17.589: INFO: Pod "downwardapi-volume-42fb9d09-36ec-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 12.957953ms
Feb 22 21:53:19.593: INFO: Pod "downwardapi-volume-42fb9d09-36ec-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017801607s
STEP: Saw pod success
Feb 22 21:53:19.594: INFO: Pod "downwardapi-volume-42fb9d09-36ec-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:53:19.597: INFO: Trying to get logs from node conformance112-2 pod downwardapi-volume-42fb9d09-36ec-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 21:53:19.644: INFO: Waiting for pod downwardapi-volume-42fb9d09-36ec-11e9-9d47-0276c9498759 to disappear
Feb 22 21:53:19.653: INFO: Pod downwardapi-volume-42fb9d09-36ec-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:53:19.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5sksr" for this suite.
Feb 22 21:53:25.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:53:25.860: INFO: namespace: e2e-tests-projected-5sksr, resource: bindings, ignored listing per whitelist
Feb 22 21:53:25.871: INFO: namespace e2e-tests-projected-5sksr deletion completed in 6.212521658s

• [SLOW TEST:8.411 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:53:25.873: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0222 21:54:06.071394      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 21:54:06.071: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:54:06.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qkkg8" for this suite.
Feb 22 21:54:14.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:54:14.219: INFO: namespace: e2e-tests-gc-qkkg8, resource: bindings, ignored listing per whitelist
Feb 22 21:54:14.226: INFO: namespace e2e-tests-gc-qkkg8 deletion completed in 8.147933654s

• [SLOW TEST:48.354 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:54:14.228: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-sh6s9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 22 21:54:14.314: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 22 21:54:38.587: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.55:8080/dial?request=hostName&protocol=udp&host=10.42.1.54&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-sh6s9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:54:38.587: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 21:54:38.806: INFO: Waiting for endpoints: map[]
Feb 22 21:54:38.821: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.55:8080/dial?request=hostName&protocol=udp&host=10.42.0.25&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-sh6s9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:54:38.822: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 21:54:39.133: INFO: Waiting for endpoints: map[]
Feb 22 21:54:39.138: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.55:8080/dial?request=hostName&protocol=udp&host=10.42.2.59&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-sh6s9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 21:54:39.138: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 21:54:39.416: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:54:39.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-sh6s9" for this suite.
Feb 22 21:55:03.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:55:03.637: INFO: namespace: e2e-tests-pod-network-test-sh6s9, resource: bindings, ignored listing per whitelist
Feb 22 21:55:03.643: INFO: namespace e2e-tests-pod-network-test-sh6s9 deletion completed in 24.2207936s

• [SLOW TEST:49.415 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:55:03.646: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 22 21:55:03.729: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 22 21:55:03.738: INFO: Waiting for terminating namespaces to be deleted...
Feb 22 21:55:03.742: INFO: 
Logging pods the kubelet thinks is on node conformance112-1 before test
Feb 22 21:55:03.750: INFO: canal-fqx62 from kube-system started at 2019-02-22 20:45:17 +0000 UTC (3 container statuses recorded)
Feb 22 21:55:03.750: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:55:03.750: INFO: 	Container install-cni ready: true, restart count 0
Feb 22 21:55:03.751: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:55:03.751: INFO: metrics-server-5444cf6dfc-f7p26 from kube-system started at 2019-02-22 20:45:43 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.751: INFO: 	Container metrics-server ready: true, restart count 0
Feb 22 21:55:03.751: INFO: kube-dns-ddddcfcc8-9km9v from kube-system started at 2019-02-22 20:45:43 +0000 UTC (3 container statuses recorded)
Feb 22 21:55:03.751: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 22 21:55:03.751: INFO: 	Container kubedns ready: true, restart count 0
Feb 22 21:55:03.751: INFO: 	Container sidecar ready: true, restart count 0
Feb 22 21:55:03.751: INFO: kube-api-auth-crl57 from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.751: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:55:03.751: INFO: kube-dns-autoscaler-689f6f9756-f5x2h from kube-system started at 2019-02-22 20:45:43 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.751: INFO: 	Container autoscaler ready: true, restart count 0
Feb 22 21:55:03.751: INFO: nginx-ingress-controller-zzcwv from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.751: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:55:03.751: INFO: cattle-node-agent-52q4q from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.751: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:55:03.751: INFO: sonobuoy-e2e-job-aabea1c863cb45f7 from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 21:55:03.751: INFO: 	Container e2e ready: true, restart count 0
Feb 22 21:55:03.752: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:55:03.752: INFO: sonobuoy-systemd-logs-daemon-set-89b3526db0284161-hvxhg from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 21:55:03.752: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:55:03.752: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:55:03.752: INFO: 
Logging pods the kubelet thinks is on node conformance112-2 before test
Feb 22 21:55:03.762: INFO: kube-api-auth-vwg8z from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.762: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:55:03.763: INFO: rke-network-plugin-deploy-job-rnnp7 from kube-system started at 2019-02-22 20:45:14 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.763: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Feb 22 21:55:03.763: INFO: cattle-cluster-agent-5987cffc6d-mwd5w from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.763: INFO: 	Container cluster-register ready: true, restart count 0
Feb 22 21:55:03.763: INFO: rke-metrics-addon-deploy-job-q9tzq from kube-system started at 2019-02-22 20:45:25 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.763: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Feb 22 21:55:03.763: INFO: cattle-node-agent-dh5xl from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.763: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:55:03.763: INFO: sonobuoy-systemd-logs-daemon-set-89b3526db0284161-dll9w from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 21:55:03.763: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:55:03.763: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:55:03.763: INFO: rke-kube-dns-addon-deploy-job-lknlp from kube-system started at 2019-02-22 20:45:19 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.763: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Feb 22 21:55:03.763: INFO: nginx-ingress-controller-x4x5r from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.764: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:55:03.764: INFO: canal-ljdg7 from kube-system started at 2019-02-22 20:45:17 +0000 UTC (3 container statuses recorded)
Feb 22 21:55:03.764: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:55:03.764: INFO: 	Container install-cni ready: true, restart count 0
Feb 22 21:55:03.764: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:55:03.764: INFO: rke-ingress-controller-deploy-job-lwzmk from kube-system started at 2019-02-22 20:45:37 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.764: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Feb 22 21:55:03.764: INFO: 
Logging pods the kubelet thinks is on node conformance112-3 before test
Feb 22 21:55:03.773: INFO: cattle-node-agent-2v5w2 from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.773: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:55:03.773: INFO: kube-api-auth-l24hc from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.773: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:55:03.773: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-22 20:54:55 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.773: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 22 21:55:03.773: INFO: sonobuoy-systemd-logs-daemon-set-89b3526db0284161-dwzls from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 21:55:03.773: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 22 21:55:03.773: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:55:03.773: INFO: canal-jrkm8 from kube-system started at 2019-02-22 20:45:17 +0000 UTC (3 container statuses recorded)
Feb 22 21:55:03.773: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:55:03.773: INFO: 	Container install-cni ready: true, restart count 0
Feb 22 21:55:03.773: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:55:03.774: INFO: nginx-ingress-controller-hklzw from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.774: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:55:03.774: INFO: default-http-backend-5bdd9fdd69-crj4m from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 21:55:03.774: INFO: 	Container default-http-backend ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1585ce5349638c12], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:55:04.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-qc7mh" for this suite.
Feb 22 21:55:10.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:55:10.889: INFO: namespace: e2e-tests-sched-pred-qc7mh, resource: bindings, ignored listing per whitelist
Feb 22 21:55:11.017: INFO: namespace e2e-tests-sched-pred-qc7mh deletion completed in 6.199820355s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.371 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:55:11.019: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-l5tdq
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 22 21:55:11.158: INFO: Found 0 stateful pods, waiting for 3
Feb 22 21:55:21.175: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:55:21.175: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:55:21.175: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 21:55:21.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-l5tdq ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 21:55:21.522: INFO: stderr: ""
Feb 22 21:55:21.522: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 21:55:21.522: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 22 21:55:31.583: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 22 21:55:41.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-l5tdq ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 21:55:41.958: INFO: stderr: ""
Feb 22 21:55:41.958: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 21:55:41.958: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 21:56:01.992: INFO: Waiting for StatefulSet e2e-tests-statefulset-l5tdq/ss2 to complete update
Feb 22 21:56:01.992: INFO: Waiting for Pod e2e-tests-statefulset-l5tdq/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb 22 21:56:12.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-l5tdq ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 21:56:12.334: INFO: stderr: ""
Feb 22 21:56:12.334: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 21:56:12.334: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 21:56:22.388: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 22 21:56:32.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-l5tdq ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 21:56:32.779: INFO: stderr: ""
Feb 22 21:56:32.779: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 21:56:32.779: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 21:56:32.946: INFO: Waiting for StatefulSet e2e-tests-statefulset-l5tdq/ss2 to complete update
Feb 22 21:56:32.946: INFO: Waiting for Pod e2e-tests-statefulset-l5tdq/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 22 21:56:32.947: INFO: Waiting for Pod e2e-tests-statefulset-l5tdq/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 22 21:56:32.947: INFO: Waiting for Pod e2e-tests-statefulset-l5tdq/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 22 21:56:42.975: INFO: Waiting for StatefulSet e2e-tests-statefulset-l5tdq/ss2 to complete update
Feb 22 21:56:42.975: INFO: Waiting for Pod e2e-tests-statefulset-l5tdq/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 22 21:56:52.962: INFO: Waiting for StatefulSet e2e-tests-statefulset-l5tdq/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 22 21:57:02.960: INFO: Deleting all statefulset in ns e2e-tests-statefulset-l5tdq
Feb 22 21:57:02.963: INFO: Scaling statefulset ss2 to 0
Feb 22 21:57:13.008: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 21:57:13.012: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:57:13.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-l5tdq" for this suite.
Feb 22 21:57:19.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:57:19.112: INFO: namespace: e2e-tests-statefulset-l5tdq, resource: bindings, ignored listing per whitelist
Feb 22 21:57:19.235: INFO: namespace e2e-tests-statefulset-l5tdq deletion completed in 6.17741837s

• [SLOW TEST:128.216 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:57:19.238: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 22 21:57:23.925: INFO: Successfully updated pod "annotationupdated319d59d-36ec-11e9-9d47-0276c9498759"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:57:25.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rhj46" for this suite.
Feb 22 21:57:49.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:57:50.096: INFO: namespace: e2e-tests-downward-api-rhj46, resource: bindings, ignored listing per whitelist
Feb 22 21:57:50.171: INFO: namespace e2e-tests-downward-api-rhj46 deletion completed in 24.214578411s

• [SLOW TEST:30.934 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:57:50.178: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:57:50.286: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e589eece-36ec-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-cp7lm" to be "success or failure"
Feb 22 21:57:50.301: INFO: Pod "downwardapi-volume-e589eece-36ec-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 15.303635ms
Feb 22 21:57:52.307: INFO: Pod "downwardapi-volume-e589eece-36ec-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021011506s
STEP: Saw pod success
Feb 22 21:57:52.307: INFO: Pod "downwardapi-volume-e589eece-36ec-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:57:52.313: INFO: Trying to get logs from node conformance112-3 pod downwardapi-volume-e589eece-36ec-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 21:57:52.365: INFO: Waiting for pod downwardapi-volume-e589eece-36ec-11e9-9d47-0276c9498759 to disappear
Feb 22 21:57:52.370: INFO: Pod downwardapi-volume-e589eece-36ec-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:57:52.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cp7lm" for this suite.
Feb 22 21:57:58.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:57:58.573: INFO: namespace: e2e-tests-downward-api-cp7lm, resource: bindings, ignored listing per whitelist
Feb 22 21:57:58.589: INFO: namespace e2e-tests-downward-api-cp7lm deletion completed in 6.211337439s

• [SLOW TEST:8.411 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:57:58.591: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 22 21:57:58.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 --namespace=e2e-tests-kubectl-d9q6g run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 22 21:58:01.880: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 22 21:58:01.880: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:58:03.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d9q6g" for this suite.
Feb 22 21:58:09.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:58:09.929: INFO: namespace: e2e-tests-kubectl-d9q6g, resource: bindings, ignored listing per whitelist
Feb 22 21:58:10.115: INFO: namespace e2e-tests-kubectl-d9q6g deletion completed in 6.217338597s

• [SLOW TEST:11.524 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:58:10.119: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 22 21:58:10.223: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 22 21:58:10.234: INFO: Waiting for terminating namespaces to be deleted...
Feb 22 21:58:10.237: INFO: 
Logging pods the kubelet thinks is on node conformance112-1 before test
Feb 22 21:58:10.245: INFO: cattle-node-agent-52q4q from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.246: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:58:10.246: INFO: sonobuoy-e2e-job-aabea1c863cb45f7 from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 21:58:10.246: INFO: 	Container e2e ready: true, restart count 0
Feb 22 21:58:10.246: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 21:58:10.246: INFO: sonobuoy-systemd-logs-daemon-set-89b3526db0284161-hvxhg from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 21:58:10.246: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 22 21:58:10.246: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 22 21:58:10.246: INFO: kube-dns-autoscaler-689f6f9756-f5x2h from kube-system started at 2019-02-22 20:45:43 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.246: INFO: 	Container autoscaler ready: true, restart count 0
Feb 22 21:58:10.246: INFO: nginx-ingress-controller-zzcwv from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.246: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:58:10.246: INFO: kube-dns-ddddcfcc8-9km9v from kube-system started at 2019-02-22 20:45:43 +0000 UTC (3 container statuses recorded)
Feb 22 21:58:10.247: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 22 21:58:10.247: INFO: 	Container kubedns ready: true, restart count 0
Feb 22 21:58:10.247: INFO: 	Container sidecar ready: true, restart count 0
Feb 22 21:58:10.247: INFO: kube-api-auth-crl57 from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.247: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:58:10.247: INFO: canal-fqx62 from kube-system started at 2019-02-22 20:45:17 +0000 UTC (3 container statuses recorded)
Feb 22 21:58:10.247: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:58:10.247: INFO: 	Container install-cni ready: true, restart count 0
Feb 22 21:58:10.247: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:58:10.247: INFO: metrics-server-5444cf6dfc-f7p26 from kube-system started at 2019-02-22 20:45:43 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.247: INFO: 	Container metrics-server ready: true, restart count 0
Feb 22 21:58:10.247: INFO: 
Logging pods the kubelet thinks is on node conformance112-2 before test
Feb 22 21:58:10.261: INFO: cattle-cluster-agent-5987cffc6d-mwd5w from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.262: INFO: 	Container cluster-register ready: true, restart count 0
Feb 22 21:58:10.262: INFO: kube-api-auth-vwg8z from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.263: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:58:10.263: INFO: rke-network-plugin-deploy-job-rnnp7 from kube-system started at 2019-02-22 20:45:14 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.264: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Feb 22 21:58:10.264: INFO: cattle-node-agent-dh5xl from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.264: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:58:10.264: INFO: rke-metrics-addon-deploy-job-q9tzq from kube-system started at 2019-02-22 20:45:25 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.264: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Feb 22 21:58:10.264: INFO: nginx-ingress-controller-x4x5r from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.264: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 21:58:10.264: INFO: sonobuoy-systemd-logs-daemon-set-89b3526db0284161-dll9w from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 21:58:10.264: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 22 21:58:10.264: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 22 21:58:10.264: INFO: rke-kube-dns-addon-deploy-job-lknlp from kube-system started at 2019-02-22 20:45:19 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.264: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Feb 22 21:58:10.265: INFO: rke-ingress-controller-deploy-job-lwzmk from kube-system started at 2019-02-22 20:45:37 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.265: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Feb 22 21:58:10.265: INFO: canal-ljdg7 from kube-system started at 2019-02-22 20:45:17 +0000 UTC (3 container statuses recorded)
Feb 22 21:58:10.265: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:58:10.265: INFO: 	Container install-cni ready: true, restart count 0
Feb 22 21:58:10.265: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:58:10.265: INFO: 
Logging pods the kubelet thinks is on node conformance112-3 before test
Feb 22 21:58:10.273: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-22 20:54:55 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.273: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 22 21:58:10.273: INFO: sonobuoy-systemd-logs-daemon-set-89b3526db0284161-dwzls from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 21:58:10.273: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 22 21:58:10.273: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 22 21:58:10.273: INFO: cattle-node-agent-2v5w2 from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.273: INFO: 	Container agent ready: true, restart count 0
Feb 22 21:58:10.274: INFO: kube-api-auth-l24hc from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.274: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 21:58:10.274: INFO: default-http-backend-5bdd9fdd69-crj4m from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.274: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 22 21:58:10.274: INFO: canal-jrkm8 from kube-system started at 2019-02-22 20:45:17 +0000 UTC (3 container statuses recorded)
Feb 22 21:58:10.274: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 21:58:10.274: INFO: 	Container install-cni ready: true, restart count 0
Feb 22 21:58:10.274: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 21:58:10.274: INFO: nginx-ingress-controller-hklzw from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 21:58:10.274: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f3e77cd8-36ec-11e9-9d47-0276c9498759 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f3e77cd8-36ec-11e9-9d47-0276c9498759 off the node conformance112-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f3e77cd8-36ec-11e9-9d47-0276c9498759
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:58:18.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-v2k9f" for this suite.
Feb 22 21:58:34.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:58:34.561: INFO: namespace: e2e-tests-sched-pred-v2k9f, resource: bindings, ignored listing per whitelist
Feb 22 21:58:34.689: INFO: namespace e2e-tests-sched-pred-v2k9f deletion completed in 16.177585717s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:24.571 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:58:34.691: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 21:58:34.792: INFO: Waiting up to 5m0s for pod "downwardapi-volume-001090cc-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-4lj7l" to be "success or failure"
Feb 22 21:58:34.803: INFO: Pod "downwardapi-volume-001090cc-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 10.980434ms
Feb 22 21:58:36.808: INFO: Pod "downwardapi-volume-001090cc-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016776453s
Feb 22 21:58:38.820: INFO: Pod "downwardapi-volume-001090cc-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027844435s
STEP: Saw pod success
Feb 22 21:58:38.820: INFO: Pod "downwardapi-volume-001090cc-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:58:38.823: INFO: Trying to get logs from node conformance112-2 pod downwardapi-volume-001090cc-36ed-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 21:58:38.888: INFO: Waiting for pod downwardapi-volume-001090cc-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 21:58:38.899: INFO: Pod downwardapi-volume-001090cc-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:58:38.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4lj7l" for this suite.
Feb 22 21:58:44.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:58:44.962: INFO: namespace: e2e-tests-projected-4lj7l, resource: bindings, ignored listing per whitelist
Feb 22 21:58:45.165: INFO: namespace e2e-tests-projected-4lj7l deletion completed in 6.24601623s

• [SLOW TEST:10.474 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:58:45.170: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0651221e-36ed-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 21:58:45.480: INFO: Waiting up to 5m0s for pod "pod-secrets-0657211a-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-secrets-2fnsb" to be "success or failure"
Feb 22 21:58:45.499: INFO: Pod "pod-secrets-0657211a-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 17.638796ms
Feb 22 21:58:47.504: INFO: Pod "pod-secrets-0657211a-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023342744s
STEP: Saw pod success
Feb 22 21:58:47.505: INFO: Pod "pod-secrets-0657211a-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 21:58:47.510: INFO: Trying to get logs from node conformance112-3 pod pod-secrets-0657211a-36ed-11e9-9d47-0276c9498759 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 21:58:47.566: INFO: Waiting for pod pod-secrets-0657211a-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 21:58:47.579: INFO: Pod pod-secrets-0657211a-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:58:47.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2fnsb" for this suite.
Feb 22 21:58:53.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:58:53.645: INFO: namespace: e2e-tests-secrets-2fnsb, resource: bindings, ignored listing per whitelist
Feb 22 21:58:53.778: INFO: namespace e2e-tests-secrets-2fnsb deletion completed in 6.190412709s

• [SLOW TEST:8.609 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:58:53.780: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 21:58:55.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-qgvtc'
Feb 22 21:58:55.679: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 22 21:58:55.679: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 22 21:58:55.730: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-w9t48]
Feb 22 21:58:55.730: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-w9t48" in namespace "e2e-tests-kubectl-qgvtc" to be "running and ready"
Feb 22 21:58:55.758: INFO: Pod "e2e-test-nginx-rc-w9t48": Phase="Pending", Reason="", readiness=false. Elapsed: 27.734669ms
Feb 22 21:58:57.764: INFO: Pod "e2e-test-nginx-rc-w9t48": Phase="Running", Reason="", readiness=true. Elapsed: 2.033237891s
Feb 22 21:58:57.764: INFO: Pod "e2e-test-nginx-rc-w9t48" satisfied condition "running and ready"
Feb 22 21:58:57.764: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-w9t48]
Feb 22 21:58:57.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qgvtc'
Feb 22 21:58:57.893: INFO: stderr: ""
Feb 22 21:58:57.893: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Feb 22 21:58:57.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qgvtc'
Feb 22 21:58:58.052: INFO: stderr: ""
Feb 22 21:58:58.052: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:58:58.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qgvtc" for this suite.
Feb 22 21:59:04.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:59:04.176: INFO: namespace: e2e-tests-kubectl-qgvtc, resource: bindings, ignored listing per whitelist
Feb 22 21:59:04.246: INFO: namespace e2e-tests-kubectl-qgvtc deletion completed in 6.179059999s

• [SLOW TEST:10.466 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:59:04.252: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 22 21:59:04.352: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:59:08.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-vx5dm" for this suite.
Feb 22 21:59:34.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:59:34.684: INFO: namespace: e2e-tests-init-container-vx5dm, resource: bindings, ignored listing per whitelist
Feb 22 21:59:34.754: INFO: namespace e2e-tests-init-container-vx5dm deletion completed in 26.200688883s

• [SLOW TEST:30.503 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:59:34.756: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:59:41.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-zqzbh" for this suite.
Feb 22 21:59:47.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:59:47.086: INFO: namespace: e2e-tests-namespaces-zqzbh, resource: bindings, ignored listing per whitelist
Feb 22 21:59:47.233: INFO: namespace e2e-tests-namespaces-zqzbh deletion completed in 6.189252324s
STEP: Destroying namespace "e2e-tests-nsdeletetest-kfjdt" for this suite.
Feb 22 21:59:47.236: INFO: Namespace e2e-tests-nsdeletetest-kfjdt was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-rkbm4" for this suite.
Feb 22 21:59:53.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:59:53.365: INFO: namespace: e2e-tests-nsdeletetest-rkbm4, resource: bindings, ignored listing per whitelist
Feb 22 21:59:53.447: INFO: namespace e2e-tests-nsdeletetest-rkbm4 deletion completed in 6.2101682s

• [SLOW TEST:18.691 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:59:53.449: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 22 21:59:53.546: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-109334344 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 21:59:53.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rbbjz" for this suite.
Feb 22 21:59:59.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 21:59:59.698: INFO: namespace: e2e-tests-kubectl-rbbjz, resource: bindings, ignored listing per whitelist
Feb 22 21:59:59.879: INFO: namespace e2e-tests-kubectl-rbbjz deletion completed in 6.229519228s

• [SLOW TEST:6.431 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 21:59:59.882: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:00:00.058: INFO: Waiting up to 5m0s for pod "downwardapi-volume-32e2692e-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-jsqkb" to be "success or failure"
Feb 22 22:00:00.086: INFO: Pod "downwardapi-volume-32e2692e-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 28.322555ms
Feb 22 22:00:02.113: INFO: Pod "downwardapi-volume-32e2692e-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.05505765s
STEP: Saw pod success
Feb 22 22:00:02.113: INFO: Pod "downwardapi-volume-32e2692e-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:00:02.174: INFO: Trying to get logs from node conformance112-2 pod downwardapi-volume-32e2692e-36ed-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 22:00:02.384: INFO: Waiting for pod downwardapi-volume-32e2692e-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 22:00:02.440: INFO: Pod downwardapi-volume-32e2692e-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:00:02.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jsqkb" for this suite.
Feb 22 22:00:08.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:00:08.963: INFO: namespace: e2e-tests-projected-jsqkb, resource: bindings, ignored listing per whitelist
Feb 22 22:00:09.094: INFO: namespace e2e-tests-projected-jsqkb deletion completed in 6.498307311s

• [SLOW TEST:9.213 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:00:09.098: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:00:09.204: INFO: Creating deployment "nginx-deployment"
Feb 22 22:00:09.213: INFO: Waiting for observed generation 1
Feb 22 22:00:11.252: INFO: Waiting for all required pods to come up
Feb 22 22:00:11.268: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 22 22:00:15.349: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 22 22:00:15.356: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 22 22:00:15.371: INFO: Updating deployment nginx-deployment
Feb 22 22:00:15.371: INFO: Waiting for observed generation 2
Feb 22 22:00:17.411: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 22 22:00:17.424: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 22 22:00:17.438: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 22 22:00:17.467: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 22 22:00:17.468: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 22 22:00:17.475: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 22 22:00:17.495: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 22 22:00:17.495: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 22 22:00:17.527: INFO: Updating deployment nginx-deployment
Feb 22 22:00:17.527: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 22 22:00:17.600: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 22 22:00:19.847: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 22 22:00:19.948: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-52cch,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-52cch/deployments/nginx-deployment,UID:385a9d63-36ed-11e9-b930-96c406f7d171,ResourceVersion:14242,Generation:3,CreationTimestamp:2019-02-22 22:00:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-02-22 22:00:17 +0000 UTC 2019-02-22 22:00:17 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-22 22:00:18 +0000 UTC 2019-02-22 22:00:09 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 22 22:00:19.990: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-52cch,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-52cch/replicasets/nginx-deployment-7dc8f79789,UID:3c07b737-36ed-11e9-b930-96c406f7d171,ResourceVersion:14239,Generation:3,CreationTimestamp:2019-02-22 22:00:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 385a9d63-36ed-11e9-b930-96c406f7d171 0xc421a9dad7 0xc421a9dad8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 22:00:19.990: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 22 22:00:19.990: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-52cch,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-52cch/replicasets/nginx-deployment-7f9675fb8b,UID:385e6b4f-36ed-11e9-b930-96c406f7d171,ResourceVersion:14227,Generation:3,CreationTimestamp:2019-02-22 22:00:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 385a9d63-36ed-11e9-b930-96c406f7d171 0xc421a9db97 0xc421a9db98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 22 22:00:21.001: INFO: Pod "nginx-deployment-7dc8f79789-2ldzp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2ldzp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-2ldzp,UID:3dc9f07d-36ed-11e9-b930-96c406f7d171,ResourceVersion:14234,Generation:0,CreationTimestamp:2019-02-22 22:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229da627 0xc4229da628}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229da710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229da730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.44,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.001: INFO: Pod "nginx-deployment-7dc8f79789-5szjm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-5szjm,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-5szjm,UID:3d68d365-36ed-11e9-b930-96c406f7d171,ResourceVersion:14276,Generation:0,CreationTimestamp:2019-02-22 22:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.69/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229da810 0xc4229da811}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229dab40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229dab60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:17 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:,StartTime:2019-02-22 22:00:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.001: INFO: Pod "nginx-deployment-7dc8f79789-7dj28" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7dj28,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-7dj28,UID:3c0b540e-36ed-11e9-b930-96c406f7d171,ResourceVersion:14106,Generation:0,CreationTimestamp:2019-02-22 22:00:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229dade0 0xc4229dade1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229dae60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229dae80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC  }],Message:,Reason:,HostIP:142.93.77.213,PodIP:,StartTime:2019-02-22 22:00:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.002: INFO: Pod "nginx-deployment-7dc8f79789-7stnf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7stnf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-7stnf,UID:3deebc57-36ed-11e9-b930-96c406f7d171,ResourceVersion:14226,Generation:0,CreationTimestamp:2019-02-22 22:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229daff0 0xc4229daff1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229db070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229db090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.002: INFO: Pod "nginx-deployment-7dc8f79789-8r4jw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-8r4jw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-8r4jw,UID:3dc91a02-36ed-11e9-b930-96c406f7d171,ResourceVersion:14225,Generation:0,CreationTimestamp:2019-02-22 22:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229db100 0xc4229db101}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229db1d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229db1f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.002: INFO: Pod "nginx-deployment-7dc8f79789-dmrz2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dmrz2,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-dmrz2,UID:3c0fdee1-36ed-11e9-b930-96c406f7d171,ResourceVersion:14252,Generation:0,CreationTimestamp:2019-02-22 22:00:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.68/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229db2c0 0xc4229db2c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229db340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229db360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:10.42.1.68,StartTime:2019-02-22 22:00:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.002: INFO: Pod "nginx-deployment-7dc8f79789-mfzb5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mfzb5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-mfzb5,UID:3c6ee647-36ed-11e9-b930-96c406f7d171,ResourceVersion:14181,Generation:0,CreationTimestamp:2019-02-22 22:00:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.33/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229db460 0xc4229db461}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229db4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229db510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:16 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.44,PodIP:10.42.0.33,StartTime:2019-02-22 22:00:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.002: INFO: Pod "nginx-deployment-7dc8f79789-n622j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-n622j,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-n622j,UID:3dbc8d45-36ed-11e9-b930-96c406f7d171,ResourceVersion:14211,Generation:0,CreationTimestamp:2019-02-22 22:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229db5f0 0xc4229db5f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229db670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229db690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.002: INFO: Pod "nginx-deployment-7dc8f79789-snrk8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-snrk8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-snrk8,UID:3dc9921a-36ed-11e9-b930-96c406f7d171,ResourceVersion:14224,Generation:0,CreationTimestamp:2019-02-22 22:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229db750 0xc4229db751}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229db7d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229db7f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.002: INFO: Pod "nginx-deployment-7dc8f79789-tp4mh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-tp4mh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-tp4mh,UID:3d8d50c0-36ed-11e9-b930-96c406f7d171,ResourceVersion:14198,Generation:0,CreationTimestamp:2019-02-22 22:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229db860 0xc4229db861}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229db8e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229db900}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.44,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.002: INFO: Pod "nginx-deployment-7dc8f79789-vwfc8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vwfc8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-vwfc8,UID:3c11b3d2-36ed-11e9-b930-96c406f7d171,ResourceVersion:14178,Generation:0,CreationTimestamp:2019-02-22 22:00:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.32/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229db9d0 0xc4229db9d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229dba50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229dba70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:15 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.44,PodIP:10.42.0.32,StartTime:2019-02-22 22:00:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.003: INFO: Pod "nginx-deployment-7dc8f79789-wj7cv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-wj7cv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-wj7cv,UID:3c63966a-36ed-11e9-b930-96c406f7d171,ResourceVersion:14130,Generation:0,CreationTimestamp:2019-02-22 22:00:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229dbb50 0xc4229dbb51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229dbbd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229dbbf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:16 +0000 UTC  }],Message:,Reason:,HostIP:142.93.77.213,PodIP:,StartTime:2019-02-22 22:00:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.003: INFO: Pod "nginx-deployment-7dc8f79789-z4gq8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-z4gq8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7dc8f79789-z4gq8,UID:3d8461db-36ed-11e9-b930-96c406f7d171,ResourceVersion:14278,Generation:0,CreationTimestamp:2019-02-22 22:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3c07b737-36ed-11e9-b930-96c406f7d171 0xc4229dbcb0 0xc4229dbcb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229dbd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229dbd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:142.93.77.213,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.003: INFO: Pod "nginx-deployment-7f9675fb8b-24dbp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-24dbp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-24dbp,UID:3dca4b80-36ed-11e9-b930-96c406f7d171,ResourceVersion:14259,Generation:0,CreationTimestamp:2019-02-22 22:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc4229dbe10 0xc4229dbe11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229dbe80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4229dbea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.44,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.003: INFO: Pod "nginx-deployment-7f9675fb8b-59clf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-59clf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-59clf,UID:387c2f69-36ed-11e9-b930-96c406f7d171,ResourceVersion:14046,Generation:0,CreationTimestamp:2019-02-22 22:00:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.29/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc4229dbf67 0xc4229dbf68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4229dbff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a86010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.44,PodIP:10.42.0.29,StartTime:2019-02-22 22:00:09 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:00:11 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://ba59a458f75cd985fe58a97f1e7e4ca80e26673fc7cea9959faaeacfb090b1cf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.003: INFO: Pod "nginx-deployment-7f9675fb8b-66dlg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-66dlg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-66dlg,UID:3d58c52e-36ed-11e9-b930-96c406f7d171,ResourceVersion:14204,Generation:0,CreationTimestamp:2019-02-22 22:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a860d0 0xc422a860d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a86150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a861d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:17 +0000 UTC  }],Message:,Reason:,HostIP:142.93.77.213,PodIP:,StartTime:2019-02-22 22:00:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.003: INFO: Pod "nginx-deployment-7f9675fb8b-679sx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-679sx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-679sx,UID:3d644f8b-36ed-11e9-b930-96c406f7d171,ResourceVersion:14231,Generation:0,CreationTimestamp:2019-02-22 22:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a86287 0xc422a86288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a86340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a86360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:17 +0000 UTC  }],Message:,Reason:,HostIP:142.93.77.213,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.003: INFO: Pod "nginx-deployment-7f9675fb8b-82lvx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-82lvx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-82lvx,UID:3dca6309-36ed-11e9-b930-96c406f7d171,ResourceVersion:14229,Generation:0,CreationTimestamp:2019-02-22 22:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a86417 0xc422a86418}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a864d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a864f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.003: INFO: Pod "nginx-deployment-7f9675fb8b-d8rbv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-d8rbv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-d8rbv,UID:3d90cd9e-36ed-11e9-b930-96c406f7d171,ResourceVersion:14193,Generation:0,CreationTimestamp:2019-02-22 22:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a865a7 0xc422a865a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a86660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a86680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.44,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.004: INFO: Pod "nginx-deployment-7f9675fb8b-ds7gw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ds7gw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-ds7gw,UID:3881a3b4-36ed-11e9-b930-96c406f7d171,ResourceVersion:14068,Generation:0,CreationTimestamp:2019-02-22 22:00:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.67/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a86747 0xc422a86748}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a86800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a86820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:10.42.1.67,StartTime:2019-02-22 22:00:09 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:00:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://de53f76de60fe160af87f1d79fcd5c112f1232acae7efd3c6b386c8cf476f32d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.004: INFO: Pod "nginx-deployment-7f9675fb8b-gd6jk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gd6jk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-gd6jk,UID:387a5827-36ed-11e9-b930-96c406f7d171,ResourceVersion:14052,Generation:0,CreationTimestamp:2019-02-22 22:00:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.64/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a868f0 0xc422a868f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a869e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a86a00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:10.42.1.64,StartTime:2019-02-22 22:00:09 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:00:11 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://20be648ba5100a85fae1749b468a877a1b770c9c363e1d05ef34736472eb60cd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.004: INFO: Pod "nginx-deployment-7f9675fb8b-j4xxq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-j4xxq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-j4xxq,UID:3dca57a9-36ed-11e9-b930-96c406f7d171,ResourceVersion:14214,Generation:0,CreationTimestamp:2019-02-22 22:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a86ac0 0xc422a86ac1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a86ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a86bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.004: INFO: Pod "nginx-deployment-7f9675fb8b-jmgft" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jmgft,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-jmgft,UID:38810850-36ed-11e9-b930-96c406f7d171,ResourceVersion:14040,Generation:0,CreationTimestamp:2019-02-22 22:00:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.65/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a86c40 0xc422a86c41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a86d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a86d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:10.42.1.65,StartTime:2019-02-22 22:00:09 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:00:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://5d83ea598f1722b476f63c4261a9e0e72ff379ed6d79c85c086add48db7c8d8a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.004: INFO: Pod "nginx-deployment-7f9675fb8b-k62gb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-k62gb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-k62gb,UID:3d8fabbb-36ed-11e9-b930-96c406f7d171,ResourceVersion:14206,Generation:0,CreationTimestamp:2019-02-22 22:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a86e00 0xc422a86e01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a86e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a86e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.004: INFO: Pod "nginx-deployment-7f9675fb8b-l6wjx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-l6wjx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-l6wjx,UID:3dca3907-36ed-11e9-b930-96c406f7d171,ResourceVersion:14219,Generation:0,CreationTimestamp:2019-02-22 22:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a86fd7 0xc422a86fd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a87050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a87070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.004: INFO: Pod "nginx-deployment-7f9675fb8b-lr9nf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lr9nf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-lr9nf,UID:3dc43d28-36ed-11e9-b930-96c406f7d171,ResourceVersion:14210,Generation:0,CreationTimestamp:2019-02-22 22:00:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a871a0 0xc422a871a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a87210} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a87230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.44,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.004: INFO: Pod "nginx-deployment-7f9675fb8b-m2fkr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-m2fkr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-m2fkr,UID:388cfb24-36ed-11e9-b930-96c406f7d171,ResourceVersion:14074,Generation:0,CreationTimestamp:2019-02-22 22:00:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.69/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a87367 0xc422a87368}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a873e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a87400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  }],Message:,Reason:,HostIP:142.93.77.213,PodIP:10.42.2.69,StartTime:2019-02-22 22:00:09 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:00:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://0248e819e854a811fc8ad5e166cf1c397760fd90d5240123a2e86e4b85928962}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.004: INFO: Pod "nginx-deployment-7f9675fb8b-nh8gg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nh8gg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-nh8gg,UID:3d6719a8-36ed-11e9-b930-96c406f7d171,ResourceVersion:14274,Generation:0,CreationTimestamp:2019-02-22 22:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a87540 0xc422a87541}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a875b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a875d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:17 +0000 UTC  }],Message:,Reason:,HostIP:142.93.77.213,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.006: INFO: Pod "nginx-deployment-7f9675fb8b-nrq4k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nrq4k,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-nrq4k,UID:388e6ba5-36ed-11e9-b930-96c406f7d171,ResourceVersion:14065,Generation:0,CreationTimestamp:2019-02-22 22:00:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.30/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a87757 0xc422a87758}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a877d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a877f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.44,PodIP:10.42.0.30,StartTime:2019-02-22 22:00:09 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:00:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://8e5c5f7faafd426af1126d302ec9a38b4665bc8c3f0058785d27cc5c39cedcc1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.006: INFO: Pod "nginx-deployment-7f9675fb8b-rtgwm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rtgwm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-rtgwm,UID:3d8ec6bb-36ed-11e9-b930-96c406f7d171,ResourceVersion:14192,Generation:0,CreationTimestamp:2019-02-22 22:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a879f0 0xc422a879f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a87a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a87a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.007: INFO: Pod "nginx-deployment-7f9675fb8b-s4bj4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-s4bj4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-s4bj4,UID:38816398-36ed-11e9-b930-96c406f7d171,ResourceVersion:14062,Generation:0,CreationTimestamp:2019-02-22 22:00:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.31/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a87c40 0xc422a87c41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a87cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a87cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.44,PodIP:10.42.0.31,StartTime:2019-02-22 22:00:09 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:00:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://ac04cfe62afbe0dfe488294405809ff4d04890cbca0df2131a61229f57306a2d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.007: INFO: Pod "nginx-deployment-7f9675fb8b-vjtm9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vjtm9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-vjtm9,UID:3d8dccd2-36ed-11e9-b930-96c406f7d171,ResourceVersion:14203,Generation:0,CreationTimestamp:2019-02-22 22:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a87e10 0xc422a87e11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a87e80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a87ea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:18 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.44,PodIP:,StartTime:2019-02-22 22:00:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:21.013: INFO: Pod "nginx-deployment-7f9675fb8b-xgd8d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xgd8d,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-52cch,SelfLink:/api/v1/namespaces/e2e-tests-deployment-52cch/pods/nginx-deployment-7f9675fb8b-xgd8d,UID:388e7b9a-36ed-11e9-b930-96c406f7d171,ResourceVersion:14071,Generation:0,CreationTimestamp:2019-02-22 22:00:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.66/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 385e6b4f-36ed-11e9-b930-96c406f7d171 0xc422a2e037 0xc422a2e038}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qmgq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qmgq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-7qmgq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a2e0b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a2e0e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:09 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:10.42.1.66,StartTime:2019-02-22 22:00:09 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:00:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://cba21871fa473038529b75e9ffc51ef006e08a34e543aeceeccc76e44449cb4b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:00:21.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-52cch" for this suite.
Feb 22 22:00:35.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:00:36.824: INFO: namespace: e2e-tests-deployment-52cch, resource: bindings, ignored listing per whitelist
Feb 22 22:00:36.854: INFO: namespace e2e-tests-deployment-52cch deletion completed in 15.738118344s

• [SLOW TEST:27.756 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:00:36.855: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:00:37.684: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 22 22:00:43.695: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 22 22:00:43.756: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-gzwtv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gzwtv/deployments/test-cleanup-deployment,UID:4ceb1326-36ed-11e9-b930-96c406f7d171,ResourceVersion:14588,Generation:1,CreationTimestamp:2019-02-22 22:00:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 22 22:00:43.771: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-gzwtv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gzwtv/replicasets/test-cleanup-deployment-755f6b95cc,UID:4cf30104-36ed-11e9-b930-96c406f7d171,ResourceVersion:14591,Generation:1,CreationTimestamp:2019-02-22 22:00:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 4ceb1326-36ed-11e9-b930-96c406f7d171 0xc4222f8977 0xc4222f8978}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 22:00:43.771: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb 22 22:00:43.771: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-gzwtv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gzwtv/replicasets/test-cleanup-controller,UID:4929b402-36ed-11e9-b930-96c406f7d171,ResourceVersion:14590,Generation:1,CreationTimestamp:2019-02-22 22:00:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 4ceb1326-36ed-11e9-b930-96c406f7d171 0xc4222f88a7 0xc4222f88a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 22 22:00:43.822: INFO: Pod "test-cleanup-controller-zxmjr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-zxmjr,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-gzwtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gzwtv/pods/test-cleanup-controller-zxmjr,UID:4940d499-36ed-11e9-b930-96c406f7d171,ResourceVersion:14585,Generation:0,CreationTimestamp:2019-02-22 22:00:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.75/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 4929b402-36ed-11e9-b930-96c406f7d171 0xc4222f9677 0xc4222f9678}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbdm2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbdm2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbdm2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4222f96f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4222f9710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:00:37 +0000 UTC  }],Message:,Reason:,HostIP:142.93.77.213,PodIP:10.42.2.75,StartTime:2019-02-22 22:00:37 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-22 22:00:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://5b37eacf76e37c4dd8151e167d6d8c08cd3c9e2443c765535bd60cca90c656c2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 22 22:00:43.822: INFO: Pod "test-cleanup-deployment-755f6b95cc-npbrz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-npbrz,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-gzwtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gzwtv/pods/test-cleanup-deployment-755f6b95cc-npbrz,UID:4cf54781-36ed-11e9-b930-96c406f7d171,ResourceVersion:14592,Generation:0,CreationTimestamp:2019-02-22 22:00:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc 4cf30104-36ed-11e9-b930-96c406f7d171 0xc4222f97e7 0xc4222f97e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbdm2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbdm2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-gbdm2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4222f9850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4222f9870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:00:43.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gzwtv" for this suite.
Feb 22 22:00:49.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:00:50.011: INFO: namespace: e2e-tests-deployment-gzwtv, resource: bindings, ignored listing per whitelist
Feb 22 22:00:50.145: INFO: namespace e2e-tests-deployment-gzwtv deletion completed in 6.273503218s

• [SLOW TEST:13.290 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:00:50.148: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:00:50.325: INFO: Waiting up to 5m0s for pod "downwardapi-volume-50d13aa0-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-tw44w" to be "success or failure"
Feb 22 22:00:50.364: INFO: Pod "downwardapi-volume-50d13aa0-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 38.424202ms
Feb 22 22:00:52.375: INFO: Pod "downwardapi-volume-50d13aa0-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049701677s
Feb 22 22:00:54.381: INFO: Pod "downwardapi-volume-50d13aa0-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055291224s
STEP: Saw pod success
Feb 22 22:00:54.381: INFO: Pod "downwardapi-volume-50d13aa0-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:00:54.386: INFO: Trying to get logs from node conformance112-2 pod downwardapi-volume-50d13aa0-36ed-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 22:00:54.444: INFO: Waiting for pod downwardapi-volume-50d13aa0-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 22:00:54.467: INFO: Pod downwardapi-volume-50d13aa0-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:00:54.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tw44w" for this suite.
Feb 22 22:01:00.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:01:00.587: INFO: namespace: e2e-tests-downward-api-tw44w, resource: bindings, ignored listing per whitelist
Feb 22 22:01:00.724: INFO: namespace e2e-tests-downward-api-tw44w deletion completed in 6.222355446s

• [SLOW TEST:10.576 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:01:00.727: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:01:00.888: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:01:02.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-k5k9h" for this suite.
Feb 22 22:01:08.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:01:08.195: INFO: namespace: e2e-tests-custom-resource-definition-k5k9h, resource: bindings, ignored listing per whitelist
Feb 22 22:01:08.240: INFO: namespace e2e-tests-custom-resource-definition-k5k9h deletion completed in 6.217377334s

• [SLOW TEST:7.514 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:01:08.247: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 22 22:01:08.372: INFO: Waiting up to 5m0s for pod "downward-api-5b9b856f-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-cv8jl" to be "success or failure"
Feb 22 22:01:08.383: INFO: Pod "downward-api-5b9b856f-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 10.859124ms
Feb 22 22:01:10.398: INFO: Pod "downward-api-5b9b856f-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026200625s
Feb 22 22:01:12.405: INFO: Pod "downward-api-5b9b856f-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033015779s
STEP: Saw pod success
Feb 22 22:01:12.405: INFO: Pod "downward-api-5b9b856f-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:01:12.411: INFO: Trying to get logs from node conformance112-3 pod downward-api-5b9b856f-36ed-11e9-9d47-0276c9498759 container dapi-container: <nil>
STEP: delete the pod
Feb 22 22:01:12.485: INFO: Waiting for pod downward-api-5b9b856f-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 22:01:12.501: INFO: Pod downward-api-5b9b856f-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:01:12.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cv8jl" for this suite.
Feb 22 22:01:18.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:01:18.792: INFO: namespace: e2e-tests-downward-api-cv8jl, resource: bindings, ignored listing per whitelist
Feb 22 22:01:18.825: INFO: namespace e2e-tests-downward-api-cv8jl deletion completed in 6.316814391s

• [SLOW TEST:10.579 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:01:18.832: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-6225d620-36ed-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 22:01:19.407: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-622be9d1-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-vgldj" to be "success or failure"
Feb 22 22:01:19.433: INFO: Pod "pod-projected-secrets-622be9d1-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 26.352962ms
Feb 22 22:01:21.447: INFO: Pod "pod-projected-secrets-622be9d1-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040543198s
Feb 22 22:01:23.597: INFO: Pod "pod-projected-secrets-622be9d1-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.189862908s
STEP: Saw pod success
Feb 22 22:01:23.597: INFO: Pod "pod-projected-secrets-622be9d1-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:01:23.628: INFO: Trying to get logs from node conformance112-2 pod pod-projected-secrets-622be9d1-36ed-11e9-9d47-0276c9498759 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:01:23.672: INFO: Waiting for pod pod-projected-secrets-622be9d1-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 22:01:23.696: INFO: Pod pod-projected-secrets-622be9d1-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:01:23.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vgldj" for this suite.
Feb 22 22:01:31.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:01:32.075: INFO: namespace: e2e-tests-projected-vgldj, resource: bindings, ignored listing per whitelist
Feb 22 22:01:32.133: INFO: namespace e2e-tests-projected-vgldj deletion completed in 8.431383098s

• [SLOW TEST:13.302 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:01:32.135: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:01:32.258: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69d6e19d-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-5p46m" to be "success or failure"
Feb 22 22:01:32.290: INFO: Pod "downwardapi-volume-69d6e19d-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 31.718115ms
Feb 22 22:01:34.660: INFO: Pod "downwardapi-volume-69d6e19d-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.402472003s
STEP: Saw pod success
Feb 22 22:01:34.660: INFO: Pod "downwardapi-volume-69d6e19d-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:01:34.673: INFO: Trying to get logs from node conformance112-3 pod downwardapi-volume-69d6e19d-36ed-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 22:01:35.190: INFO: Waiting for pod downwardapi-volume-69d6e19d-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 22:01:35.204: INFO: Pod downwardapi-volume-69d6e19d-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:01:35.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5p46m" for this suite.
Feb 22 22:01:41.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:01:41.356: INFO: namespace: e2e-tests-projected-5p46m, resource: bindings, ignored listing per whitelist
Feb 22 22:01:41.395: INFO: namespace e2e-tests-projected-5p46m deletion completed in 6.183161341s

• [SLOW TEST:9.261 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:01:41.400: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-6f5a8dfd-36ed-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 22:01:41.514: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6f5bc430-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-9tbks" to be "success or failure"
Feb 22 22:01:41.524: INFO: Pod "pod-projected-secrets-6f5bc430-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 9.56307ms
Feb 22 22:01:43.540: INFO: Pod "pod-projected-secrets-6f5bc430-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025704325s
STEP: Saw pod success
Feb 22 22:01:43.540: INFO: Pod "pod-projected-secrets-6f5bc430-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:01:43.544: INFO: Trying to get logs from node conformance112-2 pod pod-projected-secrets-6f5bc430-36ed-11e9-9d47-0276c9498759 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:01:43.602: INFO: Waiting for pod pod-projected-secrets-6f5bc430-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 22:01:43.637: INFO: Pod pod-projected-secrets-6f5bc430-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:01:43.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9tbks" for this suite.
Feb 22 22:01:49.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:01:49.754: INFO: namespace: e2e-tests-projected-9tbks, resource: bindings, ignored listing per whitelist
Feb 22 22:01:49.872: INFO: namespace e2e-tests-projected-9tbks deletion completed in 6.218751251s

• [SLOW TEST:8.473 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:01:49.876: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-746c15b8-36ed-11e9-9d47-0276c9498759
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:01:55.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gs8w8" for this suite.
Feb 22 22:02:17.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:02:18.018: INFO: namespace: e2e-tests-configmap-gs8w8, resource: bindings, ignored listing per whitelist
Feb 22 22:02:18.038: INFO: namespace e2e-tests-configmap-gs8w8 deletion completed in 22.236400171s

• [SLOW TEST:28.162 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:02:18.039: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-8536f6c8-36ed-11e9-9d47-0276c9498759
Feb 22 22:02:18.195: INFO: Pod name my-hostname-basic-8536f6c8-36ed-11e9-9d47-0276c9498759: Found 0 pods out of 1
Feb 22 22:02:23.199: INFO: Pod name my-hostname-basic-8536f6c8-36ed-11e9-9d47-0276c9498759: Found 1 pods out of 1
Feb 22 22:02:23.200: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8536f6c8-36ed-11e9-9d47-0276c9498759" are running
Feb 22 22:02:23.203: INFO: Pod "my-hostname-basic-8536f6c8-36ed-11e9-9d47-0276c9498759-g4m2s" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:02:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:02:20 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:02:20 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:02:18 +0000 UTC Reason: Message:}])
Feb 22 22:02:23.203: INFO: Trying to dial the pod
Feb 22 22:02:28.278: INFO: Controller my-hostname-basic-8536f6c8-36ed-11e9-9d47-0276c9498759: Got expected result from replica 1 [my-hostname-basic-8536f6c8-36ed-11e9-9d47-0276c9498759-g4m2s]: "my-hostname-basic-8536f6c8-36ed-11e9-9d47-0276c9498759-g4m2s", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:02:28.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-qk2md" for this suite.
Feb 22 22:02:34.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:02:34.414: INFO: namespace: e2e-tests-replication-controller-qk2md, resource: bindings, ignored listing per whitelist
Feb 22 22:02:34.448: INFO: namespace e2e-tests-replication-controller-qk2md deletion completed in 6.166341301s

• [SLOW TEST:16.409 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:02:34.449: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 22 22:02:40.619: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:02:40.633: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:02:42.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:02:42.638: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:02:44.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:02:44.639: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:02:46.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:02:46.639: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:02:48.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:02:48.646: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:02:50.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:02:50.638: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:02:52.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:02:52.639: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:02:54.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:02:54.640: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:02:56.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:02:56.639: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:02:58.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:02:58.639: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:03:00.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:03:00.645: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:03:02.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:03:02.638: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 22:03:04.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 22:03:04.638: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:03:04.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-dr9m6" for this suite.
Feb 22 22:03:26.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:03:26.766: INFO: namespace: e2e-tests-container-lifecycle-hook-dr9m6, resource: bindings, ignored listing per whitelist
Feb 22 22:03:26.826: INFO: namespace e2e-tests-container-lifecycle-hook-dr9m6 deletion completed in 22.169840727s

• [SLOW TEST:52.378 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:03:26.831: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 22 22:03:26.935: INFO: Waiting up to 5m0s for pod "client-containers-ae31f020-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-containers-h9x4g" to be "success or failure"
Feb 22 22:03:26.956: INFO: Pod "client-containers-ae31f020-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 21.210132ms
Feb 22 22:03:28.961: INFO: Pod "client-containers-ae31f020-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026302782s
Feb 22 22:03:30.967: INFO: Pod "client-containers-ae31f020-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03252568s
STEP: Saw pod success
Feb 22 22:03:30.967: INFO: Pod "client-containers-ae31f020-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:03:30.972: INFO: Trying to get logs from node conformance112-3 pod client-containers-ae31f020-36ed-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:03:31.047: INFO: Waiting for pod client-containers-ae31f020-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 22:03:31.069: INFO: Pod client-containers-ae31f020-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:03:31.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-h9x4g" for this suite.
Feb 22 22:03:45.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:03:45.311: INFO: namespace: e2e-tests-containers-h9x4g, resource: bindings, ignored listing per whitelist
Feb 22 22:03:45.349: INFO: namespace e2e-tests-containers-h9x4g deletion completed in 14.272477467s

• [SLOW TEST:18.519 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:03:45.351: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-xrcc5 in namespace e2e-tests-proxy-b45ld
I0222 22:03:45.479349      13 runners.go:180] Created replication controller with name: proxy-service-xrcc5, namespace: e2e-tests-proxy-b45ld, replica count: 1
I0222 22:03:46.529836      13 runners.go:180] proxy-service-xrcc5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 22:03:47.530070      13 runners.go:180] proxy-service-xrcc5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 22:03:48.530359      13 runners.go:180] proxy-service-xrcc5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 22:03:49.530561      13 runners.go:180] proxy-service-xrcc5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0222 22:03:50.530754      13 runners.go:180] proxy-service-xrcc5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0222 22:03:51.531309      13 runners.go:180] proxy-service-xrcc5 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 22 22:03:51.542: INFO: setup took 6.103372479s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 22 22:03:51.609: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 63.838898ms)
Feb 22 22:03:51.609: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 64.344604ms)
Feb 22 22:03:51.609: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 60.365583ms)
Feb 22 22:03:51.609: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 60.658537ms)
Feb 22 22:03:51.609: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 61.076249ms)
Feb 22 22:03:51.616: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 67.000026ms)
Feb 22 22:03:51.622: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 72.763004ms)
Feb 22 22:03:51.622: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 73.011534ms)
Feb 22 22:03:51.622: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 73.866874ms)
Feb 22 22:03:51.623: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 73.80159ms)
Feb 22 22:03:51.623: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 74.029857ms)
Feb 22 22:03:51.623: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 74.415102ms)
Feb 22 22:03:51.629: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 80.335099ms)
Feb 22 22:03:51.629: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 85.335336ms)
Feb 22 22:03:51.630: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 80.861413ms)
Feb 22 22:03:51.630: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 81.531136ms)
Feb 22 22:03:51.651: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 19.072603ms)
Feb 22 22:03:51.651: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 20.206619ms)
Feb 22 22:03:51.651: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 19.913777ms)
Feb 22 22:03:51.652: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 20.98828ms)
Feb 22 22:03:51.652: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 20.583492ms)
Feb 22 22:03:51.654: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 24.136994ms)
Feb 22 22:03:51.654: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 23.129799ms)
Feb 22 22:03:51.655: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 23.310995ms)
Feb 22 22:03:51.655: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 23.925818ms)
Feb 22 22:03:51.656: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 25.172435ms)
Feb 22 22:03:51.656: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 25.049357ms)
Feb 22 22:03:51.656: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 24.626981ms)
Feb 22 22:03:51.657: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 25.440556ms)
Feb 22 22:03:51.657: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 26.166703ms)
Feb 22 22:03:51.658: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 26.659133ms)
Feb 22 22:03:51.658: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 26.80933ms)
Feb 22 22:03:51.681: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 22.844142ms)
Feb 22 22:03:51.682: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 23.326084ms)
Feb 22 22:03:51.682: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 23.74831ms)
Feb 22 22:03:51.683: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 24.190375ms)
Feb 22 22:03:51.683: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 24.65056ms)
Feb 22 22:03:51.685: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 26.517579ms)
Feb 22 22:03:51.685: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 26.301159ms)
Feb 22 22:03:51.685: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 26.574092ms)
Feb 22 22:03:51.686: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 27.076748ms)
Feb 22 22:03:51.686: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 27.340037ms)
Feb 22 22:03:51.686: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 27.527658ms)
Feb 22 22:03:51.687: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 28.20772ms)
Feb 22 22:03:51.687: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 28.54676ms)
Feb 22 22:03:51.687: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 28.391969ms)
Feb 22 22:03:51.687: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 28.886239ms)
Feb 22 22:03:51.687: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 28.684216ms)
Feb 22 22:03:51.726: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 38.185128ms)
Feb 22 22:03:51.726: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 38.600131ms)
Feb 22 22:03:51.726: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 38.886006ms)
Feb 22 22:03:51.726: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 39.041232ms)
Feb 22 22:03:51.729: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 41.211213ms)
Feb 22 22:03:51.734: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 45.911223ms)
Feb 22 22:03:51.735: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 47.026935ms)
Feb 22 22:03:51.736: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 48.71326ms)
Feb 22 22:03:51.737: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 49.645658ms)
Feb 22 22:03:51.738: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 49.899029ms)
Feb 22 22:03:51.739: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 50.823058ms)
Feb 22 22:03:51.739: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 51.559178ms)
Feb 22 22:03:51.740: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 52.098759ms)
Feb 22 22:03:51.740: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 52.396178ms)
Feb 22 22:03:51.741: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 52.758462ms)
Feb 22 22:03:51.741: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 53.306476ms)
Feb 22 22:03:51.764: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 21.13619ms)
Feb 22 22:03:51.768: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 25.397169ms)
Feb 22 22:03:51.768: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 26.553886ms)
Feb 22 22:03:51.769: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 25.998601ms)
Feb 22 22:03:51.773: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 28.883714ms)
Feb 22 22:03:51.776: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 29.230205ms)
Feb 22 22:03:51.776: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 30.873561ms)
Feb 22 22:03:51.776: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 29.265299ms)
Feb 22 22:03:51.776: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 32.540655ms)
Feb 22 22:03:51.778: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 31.562479ms)
Feb 22 22:03:51.778: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 30.8974ms)
Feb 22 22:03:51.778: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 33.613376ms)
Feb 22 22:03:51.778: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 32.593457ms)
Feb 22 22:03:51.779: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 32.684784ms)
Feb 22 22:03:51.779: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 34.262226ms)
Feb 22 22:03:51.779: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 32.093282ms)
Feb 22 22:03:51.822: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 43.433611ms)
Feb 22 22:03:51.822: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 43.801331ms)
Feb 22 22:03:51.824: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 44.48997ms)
Feb 22 22:03:51.824: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 44.622118ms)
Feb 22 22:03:51.825: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 45.93627ms)
Feb 22 22:03:51.826: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 46.855638ms)
Feb 22 22:03:51.826: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 46.487941ms)
Feb 22 22:03:51.826: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 46.879098ms)
Feb 22 22:03:51.826: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 47.252425ms)
Feb 22 22:03:51.827: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 48.194419ms)
Feb 22 22:03:51.827: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 48.206324ms)
Feb 22 22:03:51.828: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 48.537715ms)
Feb 22 22:03:51.828: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 48.758289ms)
Feb 22 22:03:51.828: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 49.050014ms)
Feb 22 22:03:51.828: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 49.300105ms)
Feb 22 22:03:51.828: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 48.779123ms)
Feb 22 22:03:51.852: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 23.043593ms)
Feb 22 22:03:51.853: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 23.786408ms)
Feb 22 22:03:51.856: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 26.553074ms)
Feb 22 22:03:51.857: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 27.871433ms)
Feb 22 22:03:51.858: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 28.946791ms)
Feb 22 22:03:51.858: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 29.237482ms)
Feb 22 22:03:51.858: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 29.369883ms)
Feb 22 22:03:51.858: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 29.44953ms)
Feb 22 22:03:51.859: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 29.649863ms)
Feb 22 22:03:51.859: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 29.28447ms)
Feb 22 22:03:51.859: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 29.884551ms)
Feb 22 22:03:51.859: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 29.113899ms)
Feb 22 22:03:51.859: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 29.846425ms)
Feb 22 22:03:51.859: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 29.717841ms)
Feb 22 22:03:51.859: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 29.514816ms)
Feb 22 22:03:51.859: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 30.065253ms)
Feb 22 22:03:51.891: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 28.204374ms)
Feb 22 22:03:51.892: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 29.180881ms)
Feb 22 22:03:51.892: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 29.899987ms)
Feb 22 22:03:51.892: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 29.723923ms)
Feb 22 22:03:51.892: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 30.757667ms)
Feb 22 22:03:51.895: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 32.139021ms)
Feb 22 22:03:51.895: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 33.941377ms)
Feb 22 22:03:51.896: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 34.242118ms)
Feb 22 22:03:51.896: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 32.779543ms)
Feb 22 22:03:51.896: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 32.663287ms)
Feb 22 22:03:51.896: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 34.41016ms)
Feb 22 22:03:51.896: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 34.342305ms)
Feb 22 22:03:51.897: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 33.416746ms)
Feb 22 22:03:51.897: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 34.755754ms)
Feb 22 22:03:51.897: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 33.73977ms)
Feb 22 22:03:51.897: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 34.981279ms)
Feb 22 22:03:51.934: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 33.191392ms)
Feb 22 22:03:51.934: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 33.94395ms)
Feb 22 22:03:51.937: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 36.076274ms)
Feb 22 22:03:51.938: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 36.719105ms)
Feb 22 22:03:51.940: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 38.515053ms)
Feb 22 22:03:51.940: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 39.17686ms)
Feb 22 22:03:51.941: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 39.727418ms)
Feb 22 22:03:51.941: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 40.314191ms)
Feb 22 22:03:51.941: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 40.054849ms)
Feb 22 22:03:51.941: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 40.833921ms)
Feb 22 22:03:51.942: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 40.359804ms)
Feb 22 22:03:51.942: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 41.277261ms)
Feb 22 22:03:51.942: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 41.400009ms)
Feb 22 22:03:51.942: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 41.854786ms)
Feb 22 22:03:51.943: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 41.784417ms)
Feb 22 22:03:51.943: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 41.69219ms)
Feb 22 22:03:51.971: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 28.110189ms)
Feb 22 22:03:51.974: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 30.405362ms)
Feb 22 22:03:51.982: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 37.351844ms)
Feb 22 22:03:51.983: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 37.95735ms)
Feb 22 22:03:51.983: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 38.928392ms)
Feb 22 22:03:51.984: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 39.829108ms)
Feb 22 22:03:51.985: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 41.315609ms)
Feb 22 22:03:51.986: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 41.390836ms)
Feb 22 22:03:51.986: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 42.286579ms)
Feb 22 22:03:51.987: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 42.543666ms)
Feb 22 22:03:51.988: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 43.535976ms)
Feb 22 22:03:51.988: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 44.451888ms)
Feb 22 22:03:51.989: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 44.245842ms)
Feb 22 22:03:51.989: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 44.197712ms)
Feb 22 22:03:51.989: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 44.713914ms)
Feb 22 22:03:51.990: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 45.328234ms)
Feb 22 22:03:52.022: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 31.152025ms)
Feb 22 22:03:52.024: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 33.350607ms)
Feb 22 22:03:52.025: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 33.595812ms)
Feb 22 22:03:52.025: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 34.105165ms)
Feb 22 22:03:52.025: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 34.497392ms)
Feb 22 22:03:52.025: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 35.509553ms)
Feb 22 22:03:52.028: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 37.843959ms)
Feb 22 22:03:52.029: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 37.520938ms)
Feb 22 22:03:52.029: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 37.937875ms)
Feb 22 22:03:52.029: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 38.234102ms)
Feb 22 22:03:52.030: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 39.334173ms)
Feb 22 22:03:52.030: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 39.136693ms)
Feb 22 22:03:52.031: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 40.624787ms)
Feb 22 22:03:52.031: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 39.843455ms)
Feb 22 22:03:52.031: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 40.430876ms)
Feb 22 22:03:52.031: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 40.117689ms)
Feb 22 22:03:52.053: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 21.462781ms)
Feb 22 22:03:52.054: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 21.771745ms)
Feb 22 22:03:52.060: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 26.770511ms)
Feb 22 22:03:52.061: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 28.064028ms)
Feb 22 22:03:52.061: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 28.427021ms)
Feb 22 22:03:52.061: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 29.227869ms)
Feb 22 22:03:52.063: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 31.273454ms)
Feb 22 22:03:52.063: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 30.535322ms)
Feb 22 22:03:52.063: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 31.075008ms)
Feb 22 22:03:52.063: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 31.492702ms)
Feb 22 22:03:52.063: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 30.957797ms)
Feb 22 22:03:52.064: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 31.672505ms)
Feb 22 22:03:52.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 31.621378ms)
Feb 22 22:03:52.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 32.395965ms)
Feb 22 22:03:52.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 32.651361ms)
Feb 22 22:03:52.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 32.436529ms)
Feb 22 22:03:52.093: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 27.07286ms)
Feb 22 22:03:52.094: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 27.929943ms)
Feb 22 22:03:52.094: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 28.234879ms)
Feb 22 22:03:52.094: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 28.569029ms)
Feb 22 22:03:52.094: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 28.710078ms)
Feb 22 22:03:52.094: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 29.028505ms)
Feb 22 22:03:52.095: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 29.038276ms)
Feb 22 22:03:52.095: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 29.401474ms)
Feb 22 22:03:52.095: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 29.756262ms)
Feb 22 22:03:52.096: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 30.42204ms)
Feb 22 22:03:52.096: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 30.460242ms)
Feb 22 22:03:52.096: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 30.498718ms)
Feb 22 22:03:52.096: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 30.647182ms)
Feb 22 22:03:52.097: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 30.597276ms)
Feb 22 22:03:52.097: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 31.212551ms)
Feb 22 22:03:52.097: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 30.862646ms)
Feb 22 22:03:52.126: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 28.714391ms)
Feb 22 22:03:52.127: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 28.3857ms)
Feb 22 22:03:52.130: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 31.923925ms)
Feb 22 22:03:52.132: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 33.482285ms)
Feb 22 22:03:52.132: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 33.961078ms)
Feb 22 22:03:52.132: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 34.25609ms)
Feb 22 22:03:52.132: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 33.752849ms)
Feb 22 22:03:52.132: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 34.551673ms)
Feb 22 22:03:52.132: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 34.428189ms)
Feb 22 22:03:52.132: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 34.76818ms)
Feb 22 22:03:52.132: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 35.216038ms)
Feb 22 22:03:52.132: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 33.724141ms)
Feb 22 22:03:52.133: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 34.885463ms)
Feb 22 22:03:52.133: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 36.04888ms)
Feb 22 22:03:52.133: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 35.244409ms)
Feb 22 22:03:52.133: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 35.981883ms)
Feb 22 22:03:52.156: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 20.034601ms)
Feb 22 22:03:52.157: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 22.188428ms)
Feb 22 22:03:52.157: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 21.166814ms)
Feb 22 22:03:52.159: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 22.33938ms)
Feb 22 22:03:52.159: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 23.907131ms)
Feb 22 22:03:52.159: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 23.098941ms)
Feb 22 22:03:52.159: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 23.515343ms)
Feb 22 22:03:52.160: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 24.380191ms)
Feb 22 22:03:52.160: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 25.070269ms)
Feb 22 22:03:52.160: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 24.829695ms)
Feb 22 22:03:52.161: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 24.857781ms)
Feb 22 22:03:52.161: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 25.212312ms)
Feb 22 22:03:52.161: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 26.022331ms)
Feb 22 22:03:52.162: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 25.254395ms)
Feb 22 22:03:52.162: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 25.906516ms)
Feb 22 22:03:52.162: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 26.519474ms)
Feb 22 22:03:52.186: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 23.348121ms)
Feb 22 22:03:52.187: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 24.044504ms)
Feb 22 22:03:52.188: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 25.378756ms)
Feb 22 22:03:52.188: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 26.109676ms)
Feb 22 22:03:52.189: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 26.480408ms)
Feb 22 22:03:52.189: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 27.096018ms)
Feb 22 22:03:52.191: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 28.929111ms)
Feb 22 22:03:52.192: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 28.988793ms)
Feb 22 22:03:52.192: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 29.268038ms)
Feb 22 22:03:52.193: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 29.740764ms)
Feb 22 22:03:52.193: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 30.232694ms)
Feb 22 22:03:52.193: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 31.019029ms)
Feb 22 22:03:52.193: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 30.81979ms)
Feb 22 22:03:52.194: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 31.19377ms)
Feb 22 22:03:52.194: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 31.287759ms)
Feb 22 22:03:52.194: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 30.999227ms)
Feb 22 22:03:52.220: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 24.726959ms)
Feb 22 22:03:52.220: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 24.995141ms)
Feb 22 22:03:52.220: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 25.943295ms)
Feb 22 22:03:52.221: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 26.335253ms)
Feb 22 22:03:52.221: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 26.725382ms)
Feb 22 22:03:52.222: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 28.183135ms)
Feb 22 22:03:52.222: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 27.81943ms)
Feb 22 22:03:52.222: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 27.703681ms)
Feb 22 22:03:52.222: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 28.02018ms)
Feb 22 22:03:52.223: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 27.655165ms)
Feb 22 22:03:52.223: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 27.564105ms)
Feb 22 22:03:52.223: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 27.568601ms)
Feb 22 22:03:52.224: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 28.668836ms)
Feb 22 22:03:52.224: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 28.607891ms)
Feb 22 22:03:52.224: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 29.171338ms)
Feb 22 22:03:52.224: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 28.770869ms)
Feb 22 22:03:52.249: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 24.142492ms)
Feb 22 22:03:52.250: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 24.766768ms)
Feb 22 22:03:52.251: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 26.067839ms)
Feb 22 22:03:52.251: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 26.5219ms)
Feb 22 22:03:52.251: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 26.667387ms)
Feb 22 22:03:52.251: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 26.467058ms)
Feb 22 22:03:52.253: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 28.315521ms)
Feb 22 22:03:52.253: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 28.203936ms)
Feb 22 22:03:52.253: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 28.90908ms)
Feb 22 22:03:52.253: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 28.072039ms)
Feb 22 22:03:52.254: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 28.334938ms)
Feb 22 22:03:52.255: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 29.164991ms)
Feb 22 22:03:52.255: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 29.581326ms)
Feb 22 22:03:52.255: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 30.059638ms)
Feb 22 22:03:52.255: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 30.334507ms)
Feb 22 22:03:52.255: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 30.194876ms)
Feb 22 22:03:52.281: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 24.575678ms)
Feb 22 22:03:52.282: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 26.039893ms)
Feb 22 22:03:52.282: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 26.531534ms)
Feb 22 22:03:52.283: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 27.016776ms)
Feb 22 22:03:52.283: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 27.415148ms)
Feb 22 22:03:52.284: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 28.019227ms)
Feb 22 22:03:52.284: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 27.592271ms)
Feb 22 22:03:52.285: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 29.604119ms)
Feb 22 22:03:52.285: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 29.336226ms)
Feb 22 22:03:52.285: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 29.788164ms)
Feb 22 22:03:52.286: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 29.863782ms)
Feb 22 22:03:52.286: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 30.081758ms)
Feb 22 22:03:52.287: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 30.557212ms)
Feb 22 22:03:52.287: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 30.716195ms)
Feb 22 22:03:52.287: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 31.516407ms)
Feb 22 22:03:52.287: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 31.142176ms)
Feb 22 22:03:52.333: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g/proxy/rewriteme"... (200; 44.279587ms)
Feb 22 22:03:52.333: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:460/proxy/: tls baz (200; 44.612442ms)
Feb 22 22:03:52.334: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:443/proxy/... (200; 46.142443ms)
Feb 22 22:03:52.339: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:1080/proxy/... (200; 50.666188ms)
Feb 22 22:03:52.340: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 50.658551ms)
Feb 22 22:03:52.341: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/http:proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 52.215036ms)
Feb 22 22:03:52.341: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:162/proxy/: bar (200; 52.024144ms)
Feb 22 22:03:52.342: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname1/proxy/: tls baz (200; 52.194851ms)
Feb 22 22:03:52.344: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:160/proxy/: foo (200; 55.173715ms)
Feb 22 22:03:52.344: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-b45ld/pods/proxy-service-xrcc5-kp58g:1080/proxy/rewri... (200; 55.338971ms)
Feb 22 22:03:52.344: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname2/proxy/: bar (200; 56.358851ms)
Feb 22 22:03:52.344: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/https:proxy-service-xrcc5:tlsportname2/proxy/: tls qux (200; 56.257028ms)
Feb 22 22:03:52.344: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/pods/https:proxy-service-xrcc5-kp58g:462/proxy/: tls qux (200; 55.231091ms)
Feb 22 22:03:52.344: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/proxy-service-xrcc5:portname1/proxy/: foo (200; 55.63792ms)
Feb 22 22:03:52.344: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname2/proxy/: bar (200; 55.179379ms)
Feb 22 22:03:52.344: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-b45ld/services/http:proxy-service-xrcc5:portname1/proxy/: foo (200; 56.681495ms)
STEP: deleting { ReplicationController} proxy-service-xrcc5 in namespace e2e-tests-proxy-b45ld, will wait for the garbage collector to delete the pods
Feb 22 22:03:52.419: INFO: Deleting { ReplicationController} proxy-service-xrcc5 took: 20.220193ms
Feb 22 22:03:52.519: INFO: Terminating { ReplicationController} proxy-service-xrcc5 pods took: 100.263376ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:03:55.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-b45ld" for this suite.
Feb 22 22:04:04.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:04:04.252: INFO: namespace: e2e-tests-proxy-b45ld, resource: bindings, ignored listing per whitelist
Feb 22 22:04:04.281: INFO: namespace e2e-tests-proxy-b45ld deletion completed in 6.211095739s

• [SLOW TEST:18.930 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:04:04.286: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-c4869c80-36ed-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 22:04:04.408: INFO: Waiting up to 5m0s for pod "pod-secrets-c487c939-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-secrets-2mhc8" to be "success or failure"
Feb 22 22:04:04.420: INFO: Pod "pod-secrets-c487c939-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 11.964492ms
Feb 22 22:04:06.425: INFO: Pod "pod-secrets-c487c939-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016575362s
STEP: Saw pod success
Feb 22 22:04:06.425: INFO: Pod "pod-secrets-c487c939-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:04:06.429: INFO: Trying to get logs from node conformance112-3 pod pod-secrets-c487c939-36ed-11e9-9d47-0276c9498759 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:04:06.472: INFO: Waiting for pod pod-secrets-c487c939-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 22:04:06.482: INFO: Pod pod-secrets-c487c939-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:04:06.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2mhc8" for this suite.
Feb 22 22:04:16.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:04:16.591: INFO: namespace: e2e-tests-secrets-2mhc8, resource: bindings, ignored listing per whitelist
Feb 22 22:04:16.712: INFO: namespace e2e-tests-secrets-2mhc8 deletion completed in 10.22169231s

• [SLOW TEST:12.427 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:04:16.715: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:04:17.953: INFO: Creating deployment "test-recreate-deployment"
Feb 22 22:04:17.967: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 22 22:04:17.981: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb 22 22:04:20.009: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 22 22:04:20.013: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 22 22:04:20.026: INFO: Updating deployment test-recreate-deployment
Feb 22 22:04:20.026: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 22 22:04:20.337: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-h7wm9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h7wm9/deployments/test-recreate-deployment,UID:cc9ecab7-36ed-11e9-b930-96c406f7d171,ResourceVersion:15463,Generation:2,CreationTimestamp:2019-02-22 22:04:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-22 22:04:20 +0000 UTC 2019-02-22 22:04:20 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-22 22:04:20 +0000 UTC 2019-02-22 22:04:18 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 22 22:04:20.343: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-h7wm9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h7wm9/replicasets/test-recreate-deployment-7cf749666b,UID:cdf0641c-36ed-11e9-b930-96c406f7d171,ResourceVersion:15459,Generation:1,CreationTimestamp:2019-02-22 22:04:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment cc9ecab7-36ed-11e9-b930-96c406f7d171 0xc422b26527 0xc422b26528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 22:04:20.344: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 22 22:04:20.344: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-h7wm9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h7wm9/replicasets/test-recreate-deployment-79f694ff59,UID:cca2fd57-36ed-11e9-b930-96c406f7d171,ResourceVersion:15451,Generation:2,CreationTimestamp:2019-02-22 22:04:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment cc9ecab7-36ed-11e9-b930-96c406f7d171 0xc422b263f7 0xc422b263f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 22 22:04:20.354: INFO: Pod "test-recreate-deployment-7cf749666b-pwn5b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-pwn5b,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-h7wm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7wm9/pods/test-recreate-deployment-7cf749666b-pwn5b,UID:cdf2c59f-36ed-11e9-b930-96c406f7d171,ResourceVersion:15460,Generation:0,CreationTimestamp:2019-02-22 22:04:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b cdf0641c-36ed-11e9-b930-96c406f7d171 0xc422b26d17 0xc422b26d18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jfjq8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jfjq8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jfjq8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance112-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422b26d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422b26db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:04:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:04:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:04:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:04:20 +0000 UTC  }],Message:,Reason:,HostIP:68.183.151.156,PodIP:,StartTime:2019-02-22 22:04:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:04:20.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-h7wm9" for this suite.
Feb 22 22:04:32.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:04:32.909: INFO: namespace: e2e-tests-deployment-h7wm9, resource: bindings, ignored listing per whitelist
Feb 22 22:04:33.099: INFO: namespace e2e-tests-deployment-h7wm9 deletion completed in 11.53372261s

• [SLOW TEST:16.385 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:04:33.101: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-d5c3f0d4-36ed-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 22:04:33.331: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d5c52a1f-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-q7vs9" to be "success or failure"
Feb 22 22:04:33.354: INFO: Pod "pod-projected-secrets-d5c52a1f-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 22.693329ms
Feb 22 22:04:35.362: INFO: Pod "pod-projected-secrets-d5c52a1f-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029994057s
Feb 22 22:04:39.626: INFO: Pod "pod-projected-secrets-d5c52a1f-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 6.294710976s
Feb 22 22:04:41.633: INFO: Pod "pod-projected-secrets-d5c52a1f-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.301264758s
STEP: Saw pod success
Feb 22 22:04:41.633: INFO: Pod "pod-projected-secrets-d5c52a1f-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:04:41.638: INFO: Trying to get logs from node conformance112-2 pod pod-projected-secrets-d5c52a1f-36ed-11e9-9d47-0276c9498759 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:04:41.732: INFO: Waiting for pod pod-projected-secrets-d5c52a1f-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 22:04:41.749: INFO: Pod pod-projected-secrets-d5c52a1f-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:04:41.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q7vs9" for this suite.
Feb 22 22:04:47.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:04:52.177: INFO: namespace: e2e-tests-projected-q7vs9, resource: bindings, ignored listing per whitelist
Feb 22 22:04:52.215: INFO: namespace e2e-tests-projected-q7vs9 deletion completed in 10.455010815s

• [SLOW TEST:19.114 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:04:52.222: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 22 22:04:52.333: INFO: Waiting up to 5m0s for pod "downward-api-e1195eb7-36ed-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-2lvn2" to be "success or failure"
Feb 22 22:04:52.339: INFO: Pod "downward-api-e1195eb7-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 5.993179ms
Feb 22 22:04:54.354: INFO: Pod "downward-api-e1195eb7-36ed-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02014269s
Feb 22 22:04:56.359: INFO: Pod "downward-api-e1195eb7-36ed-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025099096s
STEP: Saw pod success
Feb 22 22:04:56.359: INFO: Pod "downward-api-e1195eb7-36ed-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:04:56.363: INFO: Trying to get logs from node conformance112-3 pod downward-api-e1195eb7-36ed-11e9-9d47-0276c9498759 container dapi-container: <nil>
STEP: delete the pod
Feb 22 22:04:56.417: INFO: Waiting for pod downward-api-e1195eb7-36ed-11e9-9d47-0276c9498759 to disappear
Feb 22 22:04:56.422: INFO: Pod downward-api-e1195eb7-36ed-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:04:56.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2lvn2" for this suite.
Feb 22 22:05:04.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:05:04.580: INFO: namespace: e2e-tests-downward-api-2lvn2, resource: bindings, ignored listing per whitelist
Feb 22 22:05:04.630: INFO: namespace e2e-tests-downward-api-2lvn2 deletion completed in 8.202521348s

• [SLOW TEST:12.409 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:05:04.631: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 22 22:05:06.019: INFO: Number of nodes with available pods: 0
Feb 22 22:05:06.020: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 22:05:07.030: INFO: Number of nodes with available pods: 0
Feb 22 22:05:07.030: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 22:05:08.037: INFO: Number of nodes with available pods: 3
Feb 22 22:05:08.037: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 22 22:05:08.100: INFO: Number of nodes with available pods: 2
Feb 22 22:05:08.100: INFO: Node conformance112-3 is running more than one daemon pod
Feb 22 22:05:09.112: INFO: Number of nodes with available pods: 2
Feb 22 22:05:09.112: INFO: Node conformance112-3 is running more than one daemon pod
Feb 22 22:05:10.112: INFO: Number of nodes with available pods: 2
Feb 22 22:05:10.112: INFO: Node conformance112-3 is running more than one daemon pod
Feb 22 22:05:11.125: INFO: Number of nodes with available pods: 3
Feb 22 22:05:11.125: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-vqscx, will wait for the garbage collector to delete the pods
Feb 22 22:05:11.213: INFO: Deleting {extensions DaemonSet} daemon-set took: 19.716944ms
Feb 22 22:05:11.314: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.368892ms
Feb 22 22:05:52.628: INFO: Number of nodes with available pods: 0
Feb 22 22:05:52.628: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 22:05:52.631: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vqscx/daemonsets","resourceVersion":"15787"},"items":null}

Feb 22 22:05:52.635: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vqscx/pods","resourceVersion":"15787"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:05:52.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-vqscx" for this suite.
Feb 22 22:05:58.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:05:58.874: INFO: namespace: e2e-tests-daemonsets-vqscx, resource: bindings, ignored listing per whitelist
Feb 22 22:05:58.889: INFO: namespace e2e-tests-daemonsets-vqscx deletion completed in 6.218617796s

• [SLOW TEST:54.259 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:05:58.895: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 22 22:05:59.046: INFO: PodSpec: initContainers in spec.initContainers
Feb 22 22:06:47.571: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-08df275e-36ee-11e9-9d47-0276c9498759", GenerateName:"", Namespace:"e2e-tests-init-container-4p8p2", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-4p8p2/pods/pod-init-08df275e-36ee-11e9-9d47-0276c9498759", UID:"08e11122-36ee-11e9-b930-96c406f7d171", ResourceVersion:"15949", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686469959, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"46953071"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.2.85/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-s6bhd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420f2fe00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s6bhd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s6bhd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s6bhd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4214f2a38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance112-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc422643980), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4214f2d90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4214f2db0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4214f2db8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469959, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469959, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469959, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686469959, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"142.93.77.213", PodIP:"10.42.2.85", StartTime:(*v1.Time)(0xc42184adc0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420a0ed90)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420a0efc0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://af4c6e871bb2573db770d5949f127f295eff757e6b35ed6e73040e83a7bba613"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc42184ae00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc42184ade0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:06:47.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4p8p2" for this suite.
Feb 22 22:07:09.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:07:09.752: INFO: namespace: e2e-tests-init-container-4p8p2, resource: bindings, ignored listing per whitelist
Feb 22 22:07:09.834: INFO: namespace e2e-tests-init-container-4p8p2 deletion completed in 22.206739171s

• [SLOW TEST:70.939 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:07:09.834: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 22 22:07:09.952: INFO: Waiting up to 5m0s for pod "client-containers-331f740f-36ee-11e9-9d47-0276c9498759" in namespace "e2e-tests-containers-gd44h" to be "success or failure"
Feb 22 22:07:09.959: INFO: Pod "client-containers-331f740f-36ee-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 6.735716ms
Feb 22 22:07:11.964: INFO: Pod "client-containers-331f740f-36ee-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011505727s
STEP: Saw pod success
Feb 22 22:07:11.964: INFO: Pod "client-containers-331f740f-36ee-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:07:11.967: INFO: Trying to get logs from node conformance112-3 pod client-containers-331f740f-36ee-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:07:12.038: INFO: Waiting for pod client-containers-331f740f-36ee-11e9-9d47-0276c9498759 to disappear
Feb 22 22:07:12.045: INFO: Pod client-containers-331f740f-36ee-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:07:12.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gd44h" for this suite.
Feb 22 22:07:18.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:07:18.185: INFO: namespace: e2e-tests-containers-gd44h, resource: bindings, ignored listing per whitelist
Feb 22 22:07:18.228: INFO: namespace e2e-tests-containers-gd44h deletion completed in 6.177854469s

• [SLOW TEST:8.394 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:07:18.231: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-38239b16-36ee-11e9-9d47-0276c9498759
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-38239b16-36ee-11e9-9d47-0276c9498759
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:07:22.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sz2fr" for this suite.
Feb 22 22:07:44.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:07:44.573: INFO: namespace: e2e-tests-projected-sz2fr, resource: bindings, ignored listing per whitelist
Feb 22 22:07:44.634: INFO: namespace e2e-tests-projected-sz2fr deletion completed in 22.17631888s

• [SLOW TEST:26.404 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:07:44.644: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:07:44.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kz6lx" for this suite.
Feb 22 22:08:06.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:08:06.854: INFO: namespace: e2e-tests-pods-kz6lx, resource: bindings, ignored listing per whitelist
Feb 22 22:08:06.960: INFO: namespace e2e-tests-pods-kz6lx deletion completed in 22.180247389s

• [SLOW TEST:22.317 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:08:06.961: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 22 22:08:07.116: INFO: Number of nodes with available pods: 0
Feb 22 22:08:07.116: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 22:08:08.132: INFO: Number of nodes with available pods: 0
Feb 22 22:08:08.132: INFO: Node conformance112-1 is running more than one daemon pod
Feb 22 22:08:09.131: INFO: Number of nodes with available pods: 2
Feb 22 22:08:09.132: INFO: Node conformance112-3 is running more than one daemon pod
Feb 22 22:08:10.130: INFO: Number of nodes with available pods: 3
Feb 22 22:08:10.130: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 22 22:08:10.173: INFO: Number of nodes with available pods: 2
Feb 22 22:08:10.174: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:11.189: INFO: Number of nodes with available pods: 2
Feb 22 22:08:11.190: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:12.188: INFO: Number of nodes with available pods: 2
Feb 22 22:08:12.188: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:13.188: INFO: Number of nodes with available pods: 2
Feb 22 22:08:13.189: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:14.185: INFO: Number of nodes with available pods: 2
Feb 22 22:08:14.185: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:15.192: INFO: Number of nodes with available pods: 2
Feb 22 22:08:15.193: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:16.189: INFO: Number of nodes with available pods: 2
Feb 22 22:08:16.189: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:17.187: INFO: Number of nodes with available pods: 2
Feb 22 22:08:17.187: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:18.186: INFO: Number of nodes with available pods: 2
Feb 22 22:08:18.186: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:19.201: INFO: Number of nodes with available pods: 2
Feb 22 22:08:19.201: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:20.183: INFO: Number of nodes with available pods: 2
Feb 22 22:08:20.184: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:21.184: INFO: Number of nodes with available pods: 2
Feb 22 22:08:21.184: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:22.186: INFO: Number of nodes with available pods: 2
Feb 22 22:08:22.186: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:23.187: INFO: Number of nodes with available pods: 2
Feb 22 22:08:23.188: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:24.182: INFO: Number of nodes with available pods: 2
Feb 22 22:08:24.182: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:25.184: INFO: Number of nodes with available pods: 2
Feb 22 22:08:25.185: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:26.196: INFO: Number of nodes with available pods: 2
Feb 22 22:08:26.197: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:27.185: INFO: Number of nodes with available pods: 2
Feb 22 22:08:27.185: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:28.206: INFO: Number of nodes with available pods: 2
Feb 22 22:08:28.206: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:29.187: INFO: Number of nodes with available pods: 2
Feb 22 22:08:29.187: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:30.188: INFO: Number of nodes with available pods: 2
Feb 22 22:08:30.188: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:31.186: INFO: Number of nodes with available pods: 2
Feb 22 22:08:31.186: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:32.189: INFO: Number of nodes with available pods: 2
Feb 22 22:08:32.189: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:33.187: INFO: Number of nodes with available pods: 2
Feb 22 22:08:33.187: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:34.187: INFO: Number of nodes with available pods: 2
Feb 22 22:08:34.187: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:35.186: INFO: Number of nodes with available pods: 2
Feb 22 22:08:35.186: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:36.187: INFO: Number of nodes with available pods: 2
Feb 22 22:08:36.187: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:37.196: INFO: Number of nodes with available pods: 2
Feb 22 22:08:37.197: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:38.186: INFO: Number of nodes with available pods: 2
Feb 22 22:08:38.186: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:39.188: INFO: Number of nodes with available pods: 2
Feb 22 22:08:39.188: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:40.185: INFO: Number of nodes with available pods: 2
Feb 22 22:08:40.186: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:41.192: INFO: Number of nodes with available pods: 2
Feb 22 22:08:41.193: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:42.186: INFO: Number of nodes with available pods: 2
Feb 22 22:08:42.186: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:43.188: INFO: Number of nodes with available pods: 2
Feb 22 22:08:43.188: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:44.190: INFO: Number of nodes with available pods: 2
Feb 22 22:08:44.190: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:45.185: INFO: Number of nodes with available pods: 2
Feb 22 22:08:45.186: INFO: Node conformance112-2 is running more than one daemon pod
Feb 22 22:08:46.185: INFO: Number of nodes with available pods: 3
Feb 22 22:08:46.186: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-25s4h, will wait for the garbage collector to delete the pods
Feb 22 22:08:46.264: INFO: Deleting {extensions DaemonSet} daemon-set took: 16.807414ms
Feb 22 22:08:46.364: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.263954ms
Feb 22 22:09:23.077: INFO: Number of nodes with available pods: 0
Feb 22 22:09:23.077: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 22:09:23.080: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-25s4h/daemonsets","resourceVersion":"16395"},"items":null}

Feb 22 22:09:23.084: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-25s4h/pods","resourceVersion":"16395"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:09:23.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-25s4h" for this suite.
Feb 22 22:09:33.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:09:33.188: INFO: namespace: e2e-tests-daemonsets-25s4h, resource: bindings, ignored listing per whitelist
Feb 22 22:09:33.335: INFO: namespace e2e-tests-daemonsets-25s4h deletion completed in 10.214295999s

• [SLOW TEST:86.375 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:09:33.343: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:10:33.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-z8qrk" for this suite.
Feb 22 22:10:57.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:10:57.699: INFO: namespace: e2e-tests-container-probe-z8qrk, resource: bindings, ignored listing per whitelist
Feb 22 22:10:57.709: INFO: namespace e2e-tests-container-probe-z8qrk deletion completed in 24.209937546s

• [SLOW TEST:84.366 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:10:57.712: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 22 22:10:57.882: INFO: Waiting up to 5m0s for pod "downward-api-bafa4734-36ee-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-k9j7p" to be "success or failure"
Feb 22 22:10:57.895: INFO: Pod "downward-api-bafa4734-36ee-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 13.105009ms
Feb 22 22:10:59.909: INFO: Pod "downward-api-bafa4734-36ee-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026822732s
STEP: Saw pod success
Feb 22 22:10:59.909: INFO: Pod "downward-api-bafa4734-36ee-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:10:59.912: INFO: Trying to get logs from node conformance112-3 pod downward-api-bafa4734-36ee-11e9-9d47-0276c9498759 container dapi-container: <nil>
STEP: delete the pod
Feb 22 22:10:59.971: INFO: Waiting for pod downward-api-bafa4734-36ee-11e9-9d47-0276c9498759 to disappear
Feb 22 22:10:59.980: INFO: Pod downward-api-bafa4734-36ee-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:10:59.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k9j7p" for this suite.
Feb 22 22:11:06.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:11:06.146: INFO: namespace: e2e-tests-downward-api-k9j7p, resource: bindings, ignored listing per whitelist
Feb 22 22:11:06.224: INFO: namespace e2e-tests-downward-api-k9j7p deletion completed in 6.238596278s

• [SLOW TEST:8.513 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:11:06.235: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-cdcgn
Feb 22 22:11:10.408: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-cdcgn
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 22:11:10.413: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:15:11.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cdcgn" for this suite.
Feb 22 22:15:18.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:15:18.916: INFO: namespace: e2e-tests-container-probe-cdcgn, resource: bindings, ignored listing per whitelist
Feb 22 22:15:19.079: INFO: namespace e2e-tests-container-probe-cdcgn deletion completed in 7.624137938s

• [SLOW TEST:252.845 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:15:19.084: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 22 22:15:19.276: INFO: Waiting up to 5m0s for pod "downward-api-56c88d2e-36ef-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-dzg8n" to be "success or failure"
Feb 22 22:15:19.301: INFO: Pod "downward-api-56c88d2e-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 25.122065ms
Feb 22 22:15:21.329: INFO: Pod "downward-api-56c88d2e-36ef-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052839781s
STEP: Saw pod success
Feb 22 22:15:21.329: INFO: Pod "downward-api-56c88d2e-36ef-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:15:21.334: INFO: Trying to get logs from node conformance112-3 pod downward-api-56c88d2e-36ef-11e9-9d47-0276c9498759 container dapi-container: <nil>
STEP: delete the pod
Feb 22 22:15:21.466: INFO: Waiting for pod downward-api-56c88d2e-36ef-11e9-9d47-0276c9498759 to disappear
Feb 22 22:15:21.478: INFO: Pod downward-api-56c88d2e-36ef-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:15:21.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dzg8n" for this suite.
Feb 22 22:15:27.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:15:27.668: INFO: namespace: e2e-tests-downward-api-dzg8n, resource: bindings, ignored listing per whitelist
Feb 22 22:15:27.689: INFO: namespace e2e-tests-downward-api-dzg8n deletion completed in 6.201341852s

• [SLOW TEST:8.606 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:15:27.694: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:15:27.790: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5bdc1c50-36ef-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-2k8tt" to be "success or failure"
Feb 22 22:15:27.830: INFO: Pod "downwardapi-volume-5bdc1c50-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 39.697762ms
Feb 22 22:15:29.843: INFO: Pod "downwardapi-volume-5bdc1c50-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052996259s
Feb 22 22:15:31.847: INFO: Pod "downwardapi-volume-5bdc1c50-36ef-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057398503s
STEP: Saw pod success
Feb 22 22:15:31.847: INFO: Pod "downwardapi-volume-5bdc1c50-36ef-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:15:31.852: INFO: Trying to get logs from node conformance112-2 pod downwardapi-volume-5bdc1c50-36ef-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 22:15:31.904: INFO: Waiting for pod downwardapi-volume-5bdc1c50-36ef-11e9-9d47-0276c9498759 to disappear
Feb 22 22:15:31.931: INFO: Pod downwardapi-volume-5bdc1c50-36ef-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:15:31.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2k8tt" for this suite.
Feb 22 22:15:39.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:15:40.075: INFO: namespace: e2e-tests-downward-api-2k8tt, resource: bindings, ignored listing per whitelist
Feb 22 22:15:40.134: INFO: namespace e2e-tests-downward-api-2k8tt deletion completed in 8.194602056s

• [SLOW TEST:12.441 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:15:40.138: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0222 22:15:50.524348      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 22:15:50.524: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:15:50.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ldzhk" for this suite.
Feb 22 22:15:58.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:15:58.718: INFO: namespace: e2e-tests-gc-ldzhk, resource: bindings, ignored listing per whitelist
Feb 22 22:15:58.738: INFO: namespace e2e-tests-gc-ldzhk deletion completed in 8.207123075s

• [SLOW TEST:18.601 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:15:58.741: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 22 22:15:58.860: INFO: Waiting up to 5m0s for pod "pod-6e6149f7-36ef-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-pfq4x" to be "success or failure"
Feb 22 22:15:58.879: INFO: Pod "pod-6e6149f7-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 18.636495ms
Feb 22 22:16:00.893: INFO: Pod "pod-6e6149f7-36ef-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032802083s
STEP: Saw pod success
Feb 22 22:16:00.893: INFO: Pod "pod-6e6149f7-36ef-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:16:00.897: INFO: Trying to get logs from node conformance112-3 pod pod-6e6149f7-36ef-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:16:01.010: INFO: Waiting for pod pod-6e6149f7-36ef-11e9-9d47-0276c9498759 to disappear
Feb 22 22:16:01.033: INFO: Pod pod-6e6149f7-36ef-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:16:01.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pfq4x" for this suite.
Feb 22 22:16:09.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:16:09.258: INFO: namespace: e2e-tests-emptydir-pfq4x, resource: bindings, ignored listing per whitelist
Feb 22 22:16:09.288: INFO: namespace e2e-tests-emptydir-pfq4x deletion completed in 8.246456627s

• [SLOW TEST:10.547 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:16:09.289: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-74abd8a7-36ef-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 22:16:09.511: INFO: Waiting up to 5m0s for pod "pod-secrets-74b7a97f-36ef-11e9-9d47-0276c9498759" in namespace "e2e-tests-secrets-96k5m" to be "success or failure"
Feb 22 22:16:09.551: INFO: Pod "pod-secrets-74b7a97f-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 40.099326ms
Feb 22 22:16:11.567: INFO: Pod "pod-secrets-74b7a97f-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055764523s
Feb 22 22:16:13.578: INFO: Pod "pod-secrets-74b7a97f-36ef-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067070913s
STEP: Saw pod success
Feb 22 22:16:13.578: INFO: Pod "pod-secrets-74b7a97f-36ef-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:16:13.584: INFO: Trying to get logs from node conformance112-2 pod pod-secrets-74b7a97f-36ef-11e9-9d47-0276c9498759 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:16:13.646: INFO: Waiting for pod pod-secrets-74b7a97f-36ef-11e9-9d47-0276c9498759 to disappear
Feb 22 22:16:13.677: INFO: Pod pod-secrets-74b7a97f-36ef-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:16:13.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-96k5m" for this suite.
Feb 22 22:16:21.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:16:21.880: INFO: namespace: e2e-tests-secrets-96k5m, resource: bindings, ignored listing per whitelist
Feb 22 22:16:21.971: INFO: namespace e2e-tests-secrets-96k5m deletion completed in 8.288188053s
STEP: Destroying namespace "e2e-tests-secret-namespace-88gnq" for this suite.
Feb 22 22:16:27.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:16:28.171: INFO: namespace: e2e-tests-secret-namespace-88gnq, resource: bindings, ignored listing per whitelist
Feb 22 22:16:28.355: INFO: namespace e2e-tests-secret-namespace-88gnq deletion completed in 6.38323149s

• [SLOW TEST:19.066 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:16:28.357: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 22 22:16:31.069: INFO: Successfully updated pod "labelsupdate800a003c-36ef-11e9-9d47-0276c9498759"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:16:33.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jgnmw" for this suite.
Feb 22 22:16:55.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:16:55.206: INFO: namespace: e2e-tests-downward-api-jgnmw, resource: bindings, ignored listing per whitelist
Feb 22 22:16:55.364: INFO: namespace e2e-tests-downward-api-jgnmw deletion completed in 22.234932488s

• [SLOW TEST:27.007 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:16:55.364: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-90216d59-36ef-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 22:16:55.490: INFO: Waiting up to 5m0s for pod "pod-secrets-90228289-36ef-11e9-9d47-0276c9498759" in namespace "e2e-tests-secrets-jdj7f" to be "success or failure"
Feb 22 22:16:55.519: INFO: Pod "pod-secrets-90228289-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 29.410945ms
Feb 22 22:16:57.525: INFO: Pod "pod-secrets-90228289-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035307076s
Feb 22 22:16:59.531: INFO: Pod "pod-secrets-90228289-36ef-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041047344s
STEP: Saw pod success
Feb 22 22:16:59.531: INFO: Pod "pod-secrets-90228289-36ef-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:16:59.536: INFO: Trying to get logs from node conformance112-2 pod pod-secrets-90228289-36ef-11e9-9d47-0276c9498759 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:16:59.604: INFO: Waiting for pod pod-secrets-90228289-36ef-11e9-9d47-0276c9498759 to disappear
Feb 22 22:16:59.626: INFO: Pod pod-secrets-90228289-36ef-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:16:59.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jdj7f" for this suite.
Feb 22 22:17:05.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:17:05.772: INFO: namespace: e2e-tests-secrets-jdj7f, resource: bindings, ignored listing per whitelist
Feb 22 22:17:05.854: INFO: namespace e2e-tests-secrets-jdj7f deletion completed in 6.218575861s

• [SLOW TEST:10.490 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:17:05.857: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:17:05.964: INFO: Waiting up to 5m0s for pod "downwardapi-volume-965f27d4-36ef-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-np96s" to be "success or failure"
Feb 22 22:17:05.986: INFO: Pod "downwardapi-volume-965f27d4-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 22.340926ms
Feb 22 22:17:07.993: INFO: Pod "downwardapi-volume-965f27d4-36ef-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028964597s
STEP: Saw pod success
Feb 22 22:17:07.994: INFO: Pod "downwardapi-volume-965f27d4-36ef-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:17:08.001: INFO: Trying to get logs from node conformance112-3 pod downwardapi-volume-965f27d4-36ef-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 22:17:08.062: INFO: Waiting for pod downwardapi-volume-965f27d4-36ef-11e9-9d47-0276c9498759 to disappear
Feb 22 22:17:08.074: INFO: Pod downwardapi-volume-965f27d4-36ef-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:17:08.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-np96s" for this suite.
Feb 22 22:17:14.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:17:14.639: INFO: namespace: e2e-tests-projected-np96s, resource: bindings, ignored listing per whitelist
Feb 22 22:17:14.746: INFO: namespace e2e-tests-projected-np96s deletion completed in 6.662561792s

• [SLOW TEST:8.890 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:17:14.749: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 22 22:17:14.885: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-lv8zk,SelfLink:/api/v1/namespaces/e2e-tests-watch-lv8zk/configmaps/e2e-watch-test-resource-version,UID:9bae623f-36ef-11e9-b930-96c406f7d171,ResourceVersion:17760,Generation:0,CreationTimestamp:2019-02-22 22:17:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 22 22:17:14.885: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-lv8zk,SelfLink:/api/v1/namespaces/e2e-tests-watch-lv8zk/configmaps/e2e-watch-test-resource-version,UID:9bae623f-36ef-11e9-b930-96c406f7d171,ResourceVersion:17761,Generation:0,CreationTimestamp:2019-02-22 22:17:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:17:14.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-lv8zk" for this suite.
Feb 22 22:17:20.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:17:21.043: INFO: namespace: e2e-tests-watch-lv8zk, resource: bindings, ignored listing per whitelist
Feb 22 22:17:21.137: INFO: namespace e2e-tests-watch-lv8zk deletion completed in 6.244829927s

• [SLOW TEST:6.389 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:17:21.150: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-9f7cd28d-36ef-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 22:17:21.261: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f7dd44d-36ef-11e9-9d47-0276c9498759" in namespace "e2e-tests-configmap-wcp7j" to be "success or failure"
Feb 22 22:17:21.276: INFO: Pod "pod-configmaps-9f7dd44d-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 15.574992ms
Feb 22 22:17:23.281: INFO: Pod "pod-configmaps-9f7dd44d-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020706381s
Feb 22 22:17:25.286: INFO: Pod "pod-configmaps-9f7dd44d-36ef-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025642161s
STEP: Saw pod success
Feb 22 22:17:25.286: INFO: Pod "pod-configmaps-9f7dd44d-36ef-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:17:25.290: INFO: Trying to get logs from node conformance112-2 pod pod-configmaps-9f7dd44d-36ef-11e9-9d47-0276c9498759 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:17:25.383: INFO: Waiting for pod pod-configmaps-9f7dd44d-36ef-11e9-9d47-0276c9498759 to disappear
Feb 22 22:17:25.394: INFO: Pod pod-configmaps-9f7dd44d-36ef-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:17:25.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wcp7j" for this suite.
Feb 22 22:17:33.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:17:33.598: INFO: namespace: e2e-tests-configmap-wcp7j, resource: bindings, ignored listing per whitelist
Feb 22 22:17:33.696: INFO: namespace e2e-tests-configmap-wcp7j deletion completed in 8.270568805s

• [SLOW TEST:12.547 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:17:33.699: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-a6ff0b2a-36ef-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 22:17:33.860: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a7009b9b-36ef-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-sd44d" to be "success or failure"
Feb 22 22:17:33.875: INFO: Pod "pod-projected-secrets-a7009b9b-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 14.387954ms
Feb 22 22:17:35.879: INFO: Pod "pod-projected-secrets-a7009b9b-36ef-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018752762s
Feb 22 22:17:37.904: INFO: Pod "pod-projected-secrets-a7009b9b-36ef-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043473643s
STEP: Saw pod success
Feb 22 22:17:37.904: INFO: Pod "pod-projected-secrets-a7009b9b-36ef-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:17:37.912: INFO: Trying to get logs from node conformance112-3 pod pod-projected-secrets-a7009b9b-36ef-11e9-9d47-0276c9498759 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:17:37.967: INFO: Waiting for pod pod-projected-secrets-a7009b9b-36ef-11e9-9d47-0276c9498759 to disappear
Feb 22 22:17:37.971: INFO: Pod pod-projected-secrets-a7009b9b-36ef-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:17:37.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sd44d" for this suite.
Feb 22 22:17:43.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:17:44.087: INFO: namespace: e2e-tests-projected-sd44d, resource: bindings, ignored listing per whitelist
Feb 22 22:17:44.222: INFO: namespace e2e-tests-projected-sd44d deletion completed in 6.245702008s

• [SLOW TEST:10.523 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:17:44.222: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 22 22:17:46.431: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-ad430bf7-36ef-11e9-9d47-0276c9498759", GenerateName:"", Namespace:"e2e-tests-pods-p2kjn", SelfLink:"/api/v1/namespaces/e2e-tests-pods-p2kjn/pods/pod-submit-remove-ad430bf7-36ef-11e9-9d47-0276c9498759", UID:"ad46ee9a-36ef-11e9-b930-96c406f7d171", ResourceVersion:"17904", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686470664, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"344684180"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.2.98/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-vk4th", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4239a47c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vk4th", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4239ac4b8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance112-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc422987260), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4239ac500)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4239ac520)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4239ac528), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686470664, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686470666, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686470666, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686470664, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"142.93.77.213", PodIP:"10.42.2.98", StartTime:(*v1.Time)(0xc4239aa660), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4239aa680), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://cdd787576cea20dc06db58a858ed6fa17daa3b19cb17c5eaa9ed578dfb786b88"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:17:53.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-p2kjn" for this suite.
Feb 22 22:17:59.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:17:59.258: INFO: namespace: e2e-tests-pods-p2kjn, resource: bindings, ignored listing per whitelist
Feb 22 22:17:59.265: INFO: namespace e2e-tests-pods-p2kjn deletion completed in 6.198607277s

• [SLOW TEST:15.043 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:17:59.265: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 22 22:18:03.452: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:18:27.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-khdhm" for this suite.
Feb 22 22:18:33.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:18:33.584: INFO: namespace: e2e-tests-namespaces-khdhm, resource: bindings, ignored listing per whitelist
Feb 22 22:18:33.688: INFO: namespace e2e-tests-namespaces-khdhm deletion completed in 6.178585408s
STEP: Destroying namespace "e2e-tests-nsdeletetest-xs6c6" for this suite.
Feb 22 22:18:33.692: INFO: Namespace e2e-tests-nsdeletetest-xs6c6 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-2bsqr" for this suite.
Feb 22 22:18:39.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:18:39.848: INFO: namespace: e2e-tests-nsdeletetest-2bsqr, resource: bindings, ignored listing per whitelist
Feb 22 22:18:39.895: INFO: namespace e2e-tests-nsdeletetest-2bsqr deletion completed in 6.202042305s

• [SLOW TEST:40.630 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:18:39.899: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 22 22:18:40.546: INFO: created pod pod-service-account-defaultsa
Feb 22 22:18:40.546: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 22 22:18:40.582: INFO: created pod pod-service-account-mountsa
Feb 22 22:18:40.582: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 22 22:18:40.640: INFO: created pod pod-service-account-nomountsa
Feb 22 22:18:40.640: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 22 22:18:40.685: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 22 22:18:40.685: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 22 22:18:40.725: INFO: created pod pod-service-account-mountsa-mountspec
Feb 22 22:18:40.725: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 22 22:18:40.767: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 22 22:18:40.767: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 22 22:18:40.823: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 22 22:18:40.823: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 22 22:18:40.893: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 22 22:18:40.893: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 22 22:18:40.949: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 22 22:18:40.949: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:18:40.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-5k2pw" for this suite.
Feb 22 22:18:51.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:18:51.371: INFO: namespace: e2e-tests-svcaccounts-5k2pw, resource: bindings, ignored listing per whitelist
Feb 22 22:18:51.517: INFO: namespace e2e-tests-svcaccounts-5k2pw deletion completed in 10.333131734s

• [SLOW TEST:11.618 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:18:51.520: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jfzgc
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-jfzgc
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-jfzgc
Feb 22 22:18:51.666: INFO: Found 0 stateful pods, waiting for 1
Feb 22 22:19:01.685: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 22 22:19:01.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-jfzgc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 22:19:02.131: INFO: stderr: ""
Feb 22 22:19:02.131: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 22:19:02.132: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 22:19:02.136: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 22 22:19:12.153: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 22:19:12.153: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 22:19:12.203: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 22:19:12.203: INFO: ss-0  conformance112-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  }]
Feb 22 22:19:12.203: INFO: ss-1                    Pending         []
Feb 22 22:19:12.203: INFO: 
Feb 22 22:19:12.203: INFO: StatefulSet ss has not reached scale 3, at 2
Feb 22 22:19:13.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.974442788s
Feb 22 22:19:14.219: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.965779477s
Feb 22 22:19:15.225: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.958919224s
Feb 22 22:19:16.232: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.952468045s
Feb 22 22:19:17.240: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.945466817s
Feb 22 22:19:18.247: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.93768783s
Feb 22 22:19:19.253: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.931106418s
Feb 22 22:19:20.260: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.924526454s
Feb 22 22:19:21.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 918.213067ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-jfzgc
Feb 22 22:19:22.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-jfzgc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:19:22.681: INFO: stderr: ""
Feb 22 22:19:22.681: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 22:19:22.681: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 22:19:22.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-jfzgc ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:19:23.015: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 22 22:19:23.015: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 22:19:23.015: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 22:19:23.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-jfzgc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 22 22:19:23.336: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 22 22:19:23.336: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 22 22:19:23.336: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 22 22:19:23.341: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 22:19:23.341: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 22:19:23.341: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 22 22:19:23.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-jfzgc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 22:19:23.866: INFO: stderr: ""
Feb 22 22:19:23.866: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 22:19:23.866: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 22:19:23.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-jfzgc ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 22:19:24.191: INFO: stderr: ""
Feb 22 22:19:24.191: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 22:19:24.191: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 22:19:24.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 exec --namespace=e2e-tests-statefulset-jfzgc ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 22 22:19:24.576: INFO: stderr: ""
Feb 22 22:19:24.576: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 22 22:19:24.576: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 22 22:19:24.576: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 22:19:24.580: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 22 22:19:34.603: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 22:19:34.604: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 22:19:34.604: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 22:19:34.630: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 22:19:34.631: INFO: ss-0  conformance112-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  }]
Feb 22 22:19:34.631: INFO: ss-1  conformance112-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  }]
Feb 22 22:19:34.632: INFO: ss-2  conformance112-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  }]
Feb 22 22:19:34.632: INFO: 
Feb 22 22:19:34.632: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 22:19:35.640: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 22:19:35.640: INFO: ss-0  conformance112-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  }]
Feb 22 22:19:35.640: INFO: ss-1  conformance112-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  }]
Feb 22 22:19:35.640: INFO: ss-2  conformance112-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  }]
Feb 22 22:19:35.640: INFO: 
Feb 22 22:19:35.640: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 22:19:36.646: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 22:19:36.646: INFO: ss-0  conformance112-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  }]
Feb 22 22:19:36.646: INFO: ss-1  conformance112-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  }]
Feb 22 22:19:36.646: INFO: ss-2  conformance112-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  }]
Feb 22 22:19:36.646: INFO: 
Feb 22 22:19:36.646: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 22:19:37.652: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 22:19:37.652: INFO: ss-0  conformance112-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  }]
Feb 22 22:19:37.652: INFO: ss-2  conformance112-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  }]
Feb 22 22:19:37.653: INFO: 
Feb 22 22:19:37.653: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 22 22:19:38.659: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 22:19:38.659: INFO: ss-0  conformance112-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  }]
Feb 22 22:19:38.659: INFO: ss-2  conformance112-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  }]
Feb 22 22:19:38.660: INFO: 
Feb 22 22:19:38.660: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 22 22:19:39.667: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 22:19:39.668: INFO: ss-0  conformance112-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  }]
Feb 22 22:19:39.668: INFO: ss-2  conformance112-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  }]
Feb 22 22:19:39.668: INFO: 
Feb 22 22:19:39.668: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 22 22:19:40.675: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 22:19:40.675: INFO: ss-0  conformance112-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  }]
Feb 22 22:19:40.675: INFO: ss-2  conformance112-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  }]
Feb 22 22:19:40.676: INFO: 
Feb 22 22:19:40.676: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 22 22:19:41.681: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 22:19:41.681: INFO: ss-0  conformance112-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  }]
Feb 22 22:19:41.682: INFO: ss-2  conformance112-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:12 +0000 UTC  }]
Feb 22 22:19:41.682: INFO: 
Feb 22 22:19:41.682: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 22 22:19:42.688: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Feb 22 22:19:42.688: INFO: ss-0  conformance112-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:19:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-22 22:18:51 +0000 UTC  }]
Feb 22 22:19:42.688: INFO: 
Feb 22 22:19:42.688: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 22 22:19:43.694: INFO: Verifying statefulset ss doesn't scale past 0 for another 933.45302ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-jfzgc
Feb 22 22:19:44.708: INFO: Scaling statefulset ss to 0
Feb 22 22:19:44.726: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 22 22:19:44.736: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jfzgc
Feb 22 22:19:44.742: INFO: Scaling statefulset ss to 0
Feb 22 22:19:44.762: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 22:19:44.767: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:19:44.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jfzgc" for this suite.
Feb 22 22:19:50.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:19:50.854: INFO: namespace: e2e-tests-statefulset-jfzgc, resource: bindings, ignored listing per whitelist
Feb 22 22:19:51.078: INFO: namespace e2e-tests-statefulset-jfzgc deletion completed in 6.271262006s

• [SLOW TEST:59.559 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:19:51.081: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 22 22:19:59.430: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:19:59.448: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 22:20:01.448: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:20:01.456: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 22:20:03.448: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 22:20:03.454: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:20:03.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4ck8t" for this suite.
Feb 22 22:20:27.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:20:27.728: INFO: namespace: e2e-tests-container-lifecycle-hook-4ck8t, resource: bindings, ignored listing per whitelist
Feb 22 22:20:27.770: INFO: namespace e2e-tests-container-lifecycle-hook-4ck8t deletion completed in 24.298390414s

• [SLOW TEST:36.689 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:20:27.773: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-ssj2m
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ssj2m to expose endpoints map[]
Feb 22 22:20:28.028: INFO: Get endpoints failed (56.574827ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 22 22:20:29.035: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ssj2m exposes endpoints map[] (1.0633544s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-ssj2m
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ssj2m to expose endpoints map[pod1:[80]]
Feb 22 22:20:31.100: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ssj2m exposes endpoints map[pod1:[80]] (2.04681299s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-ssj2m
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ssj2m to expose endpoints map[pod1:[80] pod2:[80]]
Feb 22 22:20:34.405: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ssj2m exposes endpoints map[pod1:[80] pod2:[80]] (3.291847413s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-ssj2m
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ssj2m to expose endpoints map[pod2:[80]]
Feb 22 22:20:34.464: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ssj2m exposes endpoints map[pod2:[80]] (26.901985ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-ssj2m
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ssj2m to expose endpoints map[]
Feb 22 22:20:35.519: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ssj2m exposes endpoints map[] (1.019158813s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:20:35.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-ssj2m" for this suite.
Feb 22 22:20:41.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:20:41.773: INFO: namespace: e2e-tests-services-ssj2m, resource: bindings, ignored listing per whitelist
Feb 22 22:20:41.860: INFO: namespace e2e-tests-services-ssj2m deletion completed in 6.240793519s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:14.088 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:20:41.865: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-lsf2
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 22:20:42.007: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-lsf2" in namespace "e2e-tests-subpath-rrql8" to be "success or failure"
Feb 22 22:20:42.034: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.029243ms
Feb 22 22:20:44.040: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032865187s
Feb 22 22:20:46.047: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Running", Reason="", readiness=false. Elapsed: 4.039029862s
Feb 22 22:20:48.059: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Running", Reason="", readiness=false. Elapsed: 6.051607798s
Feb 22 22:20:50.065: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Running", Reason="", readiness=false. Elapsed: 8.057386654s
Feb 22 22:20:52.071: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Running", Reason="", readiness=false. Elapsed: 10.063096504s
Feb 22 22:20:54.078: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Running", Reason="", readiness=false. Elapsed: 12.070654196s
Feb 22 22:20:56.084: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Running", Reason="", readiness=false. Elapsed: 14.076029519s
Feb 22 22:20:58.096: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Running", Reason="", readiness=false. Elapsed: 16.088428443s
Feb 22 22:21:00.101: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Running", Reason="", readiness=false. Elapsed: 18.093842261s
Feb 22 22:21:02.108: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Running", Reason="", readiness=false. Elapsed: 20.100453835s
Feb 22 22:21:04.113: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Running", Reason="", readiness=false. Elapsed: 22.105443807s
Feb 22 22:21:06.119: INFO: Pod "pod-subpath-test-downwardapi-lsf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.111345073s
STEP: Saw pod success
Feb 22 22:21:06.119: INFO: Pod "pod-subpath-test-downwardapi-lsf2" satisfied condition "success or failure"
Feb 22 22:21:06.124: INFO: Trying to get logs from node conformance112-3 pod pod-subpath-test-downwardapi-lsf2 container test-container-subpath-downwardapi-lsf2: <nil>
STEP: delete the pod
Feb 22 22:21:06.191: INFO: Waiting for pod pod-subpath-test-downwardapi-lsf2 to disappear
Feb 22 22:21:06.227: INFO: Pod pod-subpath-test-downwardapi-lsf2 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-lsf2
Feb 22 22:21:06.227: INFO: Deleting pod "pod-subpath-test-downwardapi-lsf2" in namespace "e2e-tests-subpath-rrql8"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:21:06.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rrql8" for this suite.
Feb 22 22:21:12.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:21:12.460: INFO: namespace: e2e-tests-subpath-rrql8, resource: bindings, ignored listing per whitelist
Feb 22 22:21:12.509: INFO: namespace e2e-tests-subpath-rrql8 deletion completed in 6.268190817s

• [SLOW TEST:30.644 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:21:12.512: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:21:12.670: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2968f346-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-2df4k" to be "success or failure"
Feb 22 22:21:12.698: INFO: Pod "downwardapi-volume-2968f346-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 27.88936ms
Feb 22 22:21:14.704: INFO: Pod "downwardapi-volume-2968f346-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034140777s
Feb 22 22:21:16.710: INFO: Pod "downwardapi-volume-2968f346-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040353696s
STEP: Saw pod success
Feb 22 22:21:16.710: INFO: Pod "downwardapi-volume-2968f346-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:21:16.715: INFO: Trying to get logs from node conformance112-2 pod downwardapi-volume-2968f346-36f0-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 22:21:16.776: INFO: Waiting for pod downwardapi-volume-2968f346-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:21:16.790: INFO: Pod downwardapi-volume-2968f346-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:21:16.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2df4k" for this suite.
Feb 22 22:21:22.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:21:22.918: INFO: namespace: e2e-tests-downward-api-2df4k, resource: bindings, ignored listing per whitelist
Feb 22 22:21:23.023: INFO: namespace e2e-tests-downward-api-2df4k deletion completed in 6.222336901s

• [SLOW TEST:10.511 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:21:23.027: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 22 22:21:23.157: INFO: Waiting up to 5m0s for pod "pod-2fac0b27-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-2sfl7" to be "success or failure"
Feb 22 22:21:23.175: INFO: Pod "pod-2fac0b27-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 17.791447ms
Feb 22 22:21:25.180: INFO: Pod "pod-2fac0b27-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022720449s
STEP: Saw pod success
Feb 22 22:21:25.180: INFO: Pod "pod-2fac0b27-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:21:25.185: INFO: Trying to get logs from node conformance112-3 pod pod-2fac0b27-36f0-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:21:25.241: INFO: Waiting for pod pod-2fac0b27-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:21:25.253: INFO: Pod pod-2fac0b27-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:21:25.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2sfl7" for this suite.
Feb 22 22:21:31.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:21:31.382: INFO: namespace: e2e-tests-emptydir-2sfl7, resource: bindings, ignored listing per whitelist
Feb 22 22:21:31.521: INFO: namespace e2e-tests-emptydir-2sfl7 deletion completed in 6.231673324s

• [SLOW TEST:8.494 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:21:31.522: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 22 22:21:31.693: INFO: Waiting up to 5m0s for pod "client-containers-34c3b2c2-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-containers-nm69n" to be "success or failure"
Feb 22 22:21:31.730: INFO: Pod "client-containers-34c3b2c2-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 37.519794ms
Feb 22 22:21:33.736: INFO: Pod "client-containers-34c3b2c2-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043197464s
Feb 22 22:21:35.742: INFO: Pod "client-containers-34c3b2c2-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049481728s
STEP: Saw pod success
Feb 22 22:21:35.742: INFO: Pod "client-containers-34c3b2c2-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:21:35.748: INFO: Trying to get logs from node conformance112-2 pod client-containers-34c3b2c2-36f0-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:21:35.800: INFO: Waiting for pod client-containers-34c3b2c2-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:21:35.827: INFO: Pod client-containers-34c3b2c2-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:21:35.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nm69n" for this suite.
Feb 22 22:21:41.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:21:41.883: INFO: namespace: e2e-tests-containers-nm69n, resource: bindings, ignored listing per whitelist
Feb 22 22:21:42.024: INFO: namespace e2e-tests-containers-nm69n deletion completed in 6.188683419s

• [SLOW TEST:10.503 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:21:42.028: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb 22 22:21:42.129: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 22 22:21:42.137: INFO: Waiting for terminating namespaces to be deleted...
Feb 22 22:21:42.141: INFO: 
Logging pods the kubelet thinks is on node conformance112-1 before test
Feb 22 22:21:42.148: INFO: canal-fqx62 from kube-system started at 2019-02-22 20:45:17 +0000 UTC (3 container statuses recorded)
Feb 22 22:21:42.148: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 22:21:42.148: INFO: 	Container install-cni ready: true, restart count 0
Feb 22 22:21:42.148: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 22:21:42.148: INFO: metrics-server-5444cf6dfc-f7p26 from kube-system started at 2019-02-22 20:45:43 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.148: INFO: 	Container metrics-server ready: true, restart count 0
Feb 22 22:21:42.148: INFO: kube-dns-ddddcfcc8-9km9v from kube-system started at 2019-02-22 20:45:43 +0000 UTC (3 container statuses recorded)
Feb 22 22:21:42.148: INFO: 	Container dnsmasq ready: true, restart count 0
Feb 22 22:21:42.149: INFO: 	Container kubedns ready: true, restart count 0
Feb 22 22:21:42.149: INFO: 	Container sidecar ready: true, restart count 0
Feb 22 22:21:42.149: INFO: nginx-ingress-controller-zzcwv from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.149: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 22:21:42.149: INFO: sonobuoy-systemd-logs-daemon-set-89b3526db0284161-hvxhg from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 22:21:42.149: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 22 22:21:42.149: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 22 22:21:42.149: INFO: kube-api-auth-crl57 from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.149: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 22:21:42.149: INFO: kube-dns-autoscaler-689f6f9756-f5x2h from kube-system started at 2019-02-22 20:45:43 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.149: INFO: 	Container autoscaler ready: true, restart count 0
Feb 22 22:21:42.149: INFO: cattle-node-agent-52q4q from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.149: INFO: 	Container agent ready: true, restart count 0
Feb 22 22:21:42.150: INFO: sonobuoy-e2e-job-aabea1c863cb45f7 from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 22:21:42.150: INFO: 	Container e2e ready: true, restart count 0
Feb 22 22:21:42.150: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 22 22:21:42.150: INFO: 
Logging pods the kubelet thinks is on node conformance112-2 before test
Feb 22 22:21:42.160: INFO: rke-network-plugin-deploy-job-rnnp7 from kube-system started at 2019-02-22 20:45:14 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.160: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Feb 22 22:21:42.161: INFO: cattle-cluster-agent-5987cffc6d-mwd5w from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.161: INFO: 	Container cluster-register ready: true, restart count 0
Feb 22 22:21:42.161: INFO: kube-api-auth-vwg8z from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.161: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 22:21:42.161: INFO: rke-metrics-addon-deploy-job-q9tzq from kube-system started at 2019-02-22 20:45:25 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.161: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Feb 22 22:21:42.161: INFO: cattle-node-agent-dh5xl from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.161: INFO: 	Container agent ready: true, restart count 0
Feb 22 22:21:42.161: INFO: rke-kube-dns-addon-deploy-job-lknlp from kube-system started at 2019-02-22 20:45:19 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.161: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Feb 22 22:21:42.162: INFO: nginx-ingress-controller-x4x5r from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.162: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 22 22:21:42.162: INFO: sonobuoy-systemd-logs-daemon-set-89b3526db0284161-dll9w from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 22:21:42.162: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 22 22:21:42.162: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 22 22:21:42.162: INFO: canal-ljdg7 from kube-system started at 2019-02-22 20:45:17 +0000 UTC (3 container statuses recorded)
Feb 22 22:21:42.162: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 22:21:42.162: INFO: 	Container install-cni ready: true, restart count 0
Feb 22 22:21:42.163: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 22:21:42.163: INFO: rke-ingress-controller-deploy-job-lwzmk from kube-system started at 2019-02-22 20:45:37 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.163: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Feb 22 22:21:42.163: INFO: 
Logging pods the kubelet thinks is on node conformance112-3 before test
Feb 22 22:21:42.181: INFO: kube-api-auth-l24hc from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.182: INFO: 	Container kube-api-auth ready: true, restart count 0
Feb 22 22:21:42.182: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-22 20:54:55 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.182: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 22 22:21:42.182: INFO: default-http-backend-5bdd9fdd69-crj4m from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.182: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 22 22:21:42.182: INFO: cattle-node-agent-2v5w2 from cattle-system started at 2019-02-22 20:46:07 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.183: INFO: 	Container agent ready: true, restart count 0
Feb 22 22:21:42.183: INFO: sonobuoy-systemd-logs-daemon-set-89b3526db0284161-dwzls from heptio-sonobuoy started at 2019-02-22 20:54:59 +0000 UTC (2 container statuses recorded)
Feb 22 22:21:42.183: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 22 22:21:42.183: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 22 22:21:42.183: INFO: canal-jrkm8 from kube-system started at 2019-02-22 20:45:17 +0000 UTC (3 container statuses recorded)
Feb 22 22:21:42.183: INFO: 	Container calico-node ready: true, restart count 0
Feb 22 22:21:42.183: INFO: 	Container install-cni ready: true, restart count 0
Feb 22 22:21:42.184: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 22 22:21:42.185: INFO: nginx-ingress-controller-hklzw from ingress-nginx started at 2019-02-22 20:45:46 +0000 UTC (1 container statuses recorded)
Feb 22 22:21:42.186: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node conformance112-1
STEP: verifying the node has the label node conformance112-2
STEP: verifying the node has the label node conformance112-3
Feb 22 22:21:42.316: INFO: Pod cattle-cluster-agent-5987cffc6d-mwd5w requesting resource cpu=0m on Node conformance112-2
Feb 22 22:21:42.316: INFO: Pod cattle-node-agent-2v5w2 requesting resource cpu=0m on Node conformance112-3
Feb 22 22:21:42.316: INFO: Pod cattle-node-agent-52q4q requesting resource cpu=0m on Node conformance112-1
Feb 22 22:21:42.316: INFO: Pod cattle-node-agent-dh5xl requesting resource cpu=0m on Node conformance112-2
Feb 22 22:21:42.316: INFO: Pod kube-api-auth-crl57 requesting resource cpu=0m on Node conformance112-1
Feb 22 22:21:42.316: INFO: Pod kube-api-auth-l24hc requesting resource cpu=0m on Node conformance112-3
Feb 22 22:21:42.316: INFO: Pod kube-api-auth-vwg8z requesting resource cpu=0m on Node conformance112-2
Feb 22 22:21:42.316: INFO: Pod sonobuoy requesting resource cpu=0m on Node conformance112-3
Feb 22 22:21:42.316: INFO: Pod sonobuoy-e2e-job-aabea1c863cb45f7 requesting resource cpu=0m on Node conformance112-1
Feb 22 22:21:42.316: INFO: Pod sonobuoy-systemd-logs-daemon-set-89b3526db0284161-dll9w requesting resource cpu=0m on Node conformance112-2
Feb 22 22:21:42.317: INFO: Pod sonobuoy-systemd-logs-daemon-set-89b3526db0284161-dwzls requesting resource cpu=0m on Node conformance112-3
Feb 22 22:21:42.317: INFO: Pod sonobuoy-systemd-logs-daemon-set-89b3526db0284161-hvxhg requesting resource cpu=0m on Node conformance112-1
Feb 22 22:21:42.317: INFO: Pod default-http-backend-5bdd9fdd69-crj4m requesting resource cpu=10m on Node conformance112-3
Feb 22 22:21:42.317: INFO: Pod nginx-ingress-controller-hklzw requesting resource cpu=0m on Node conformance112-3
Feb 22 22:21:42.317: INFO: Pod nginx-ingress-controller-x4x5r requesting resource cpu=0m on Node conformance112-2
Feb 22 22:21:42.317: INFO: Pod nginx-ingress-controller-zzcwv requesting resource cpu=0m on Node conformance112-1
Feb 22 22:21:42.317: INFO: Pod canal-fqx62 requesting resource cpu=250m on Node conformance112-1
Feb 22 22:21:42.317: INFO: Pod canal-jrkm8 requesting resource cpu=250m on Node conformance112-3
Feb 22 22:21:42.317: INFO: Pod canal-ljdg7 requesting resource cpu=250m on Node conformance112-2
Feb 22 22:21:42.317: INFO: Pod kube-dns-autoscaler-689f6f9756-f5x2h requesting resource cpu=20m on Node conformance112-1
Feb 22 22:21:42.317: INFO: Pod kube-dns-ddddcfcc8-9km9v requesting resource cpu=260m on Node conformance112-1
Feb 22 22:21:42.317: INFO: Pod metrics-server-5444cf6dfc-f7p26 requesting resource cpu=0m on Node conformance112-1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b1ae5ff-36f0-11e9-9d47-0276c9498759.1585cfc77b1cd3bd], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-bgk4c/filler-pod-3b1ae5ff-36f0-11e9-9d47-0276c9498759 to conformance112-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b1ae5ff-36f0-11e9-9d47-0276c9498759.1585cfc7b60fde98], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b1ae5ff-36f0-11e9-9d47-0276c9498759.1585cfc7d91af04b], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b1ae5ff-36f0-11e9-9d47-0276c9498759.1585cfc7dc91dc6b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b1ae5ff-36f0-11e9-9d47-0276c9498759.1585cfc7eb9e58f9], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b206c7d-36f0-11e9-9d47-0276c9498759.1585cfc77e288427], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-bgk4c/filler-pod-3b206c7d-36f0-11e9-9d47-0276c9498759 to conformance112-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b206c7d-36f0-11e9-9d47-0276c9498759.1585cfc7ce2f5743], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b206c7d-36f0-11e9-9d47-0276c9498759.1585cfc7d1588941], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b206c7d-36f0-11e9-9d47-0276c9498759.1585cfc7e21fe7da], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b23c2a5-36f0-11e9-9d47-0276c9498759.1585cfc77df65e86], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-bgk4c/filler-pod-3b23c2a5-36f0-11e9-9d47-0276c9498759 to conformance112-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b23c2a5-36f0-11e9-9d47-0276c9498759.1585cfc7b9ba4d6f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b23c2a5-36f0-11e9-9d47-0276c9498759.1585cfc7bc365158], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3b23c2a5-36f0-11e9-9d47-0276c9498759.1585cfc7c95e3815], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1585cfc871195cd3], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node conformance112-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node conformance112-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node conformance112-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:21:47.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-bgk4c" for this suite.
Feb 22 22:21:55.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:21:55.770: INFO: namespace: e2e-tests-sched-pred-bgk4c, resource: bindings, ignored listing per whitelist
Feb 22 22:21:55.801: INFO: namespace e2e-tests-sched-pred-bgk4c deletion completed in 8.181153522s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:13.774 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:21:55.807: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-43355776-36f0-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 22:21:55.941: INFO: Waiting up to 5m0s for pod "pod-secrets-4336c2db-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-secrets-vcdp5" to be "success or failure"
Feb 22 22:21:55.963: INFO: Pod "pod-secrets-4336c2db-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 21.738235ms
Feb 22 22:21:57.969: INFO: Pod "pod-secrets-4336c2db-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027154575s
STEP: Saw pod success
Feb 22 22:21:57.969: INFO: Pod "pod-secrets-4336c2db-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:21:57.974: INFO: Trying to get logs from node conformance112-3 pod pod-secrets-4336c2db-36f0-11e9-9d47-0276c9498759 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:21:58.769: INFO: Waiting for pod pod-secrets-4336c2db-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:21:58.779: INFO: Pod pod-secrets-4336c2db-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:21:58.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vcdp5" for this suite.
Feb 22 22:22:04.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:22:04.859: INFO: namespace: e2e-tests-secrets-vcdp5, resource: bindings, ignored listing per whitelist
Feb 22 22:22:04.954: INFO: namespace e2e-tests-secrets-vcdp5 deletion completed in 6.169916282s

• [SLOW TEST:9.148 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:22:04.958: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-48a913d8-36f0-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 22:22:05.082: INFO: Waiting up to 5m0s for pod "pod-configmaps-48aa4168-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-configmap-dxd44" to be "success or failure"
Feb 22 22:22:05.111: INFO: Pod "pod-configmaps-48aa4168-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 28.462467ms
Feb 22 22:22:07.116: INFO: Pod "pod-configmaps-48aa4168-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03355993s
Feb 22 22:22:09.123: INFO: Pod "pod-configmaps-48aa4168-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040416765s
STEP: Saw pod success
Feb 22 22:22:09.123: INFO: Pod "pod-configmaps-48aa4168-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:22:09.127: INFO: Trying to get logs from node conformance112-2 pod pod-configmaps-48aa4168-36f0-11e9-9d47-0276c9498759 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:22:09.202: INFO: Waiting for pod pod-configmaps-48aa4168-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:22:09.210: INFO: Pod pod-configmaps-48aa4168-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:22:09.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dxd44" for this suite.
Feb 22 22:22:19.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:22:19.389: INFO: namespace: e2e-tests-configmap-dxd44, resource: bindings, ignored listing per whitelist
Feb 22 22:22:19.400: INFO: namespace e2e-tests-configmap-dxd44 deletion completed in 10.18406743s

• [SLOW TEST:14.443 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:22:19.409: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-51448771-36f0-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 22:22:19.524: INFO: Waiting up to 5m0s for pod "pod-secrets-5145df83-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-secrets-6phpw" to be "success or failure"
Feb 22 22:22:19.546: INFO: Pod "pod-secrets-5145df83-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 21.783117ms
Feb 22 22:22:21.551: INFO: Pod "pod-secrets-5145df83-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027066742s
STEP: Saw pod success
Feb 22 22:22:21.551: INFO: Pod "pod-secrets-5145df83-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:22:21.556: INFO: Trying to get logs from node conformance112-3 pod pod-secrets-5145df83-36f0-11e9-9d47-0276c9498759 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:22:21.627: INFO: Waiting for pod pod-secrets-5145df83-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:22:21.642: INFO: Pod pod-secrets-5145df83-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:22:21.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6phpw" for this suite.
Feb 22 22:22:27.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:22:27.703: INFO: namespace: e2e-tests-secrets-6phpw, resource: bindings, ignored listing per whitelist
Feb 22 22:22:27.850: INFO: namespace e2e-tests-secrets-6phpw deletion completed in 6.201228235s

• [SLOW TEST:8.443 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:22:27.855: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 22 22:22:28.010: INFO: Waiting up to 5m0s for pod "pod-5654b0b9-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-jzlmv" to be "success or failure"
Feb 22 22:22:28.074: INFO: Pod "pod-5654b0b9-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 63.756838ms
Feb 22 22:22:30.080: INFO: Pod "pod-5654b0b9-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.069179099s
STEP: Saw pod success
Feb 22 22:22:30.080: INFO: Pod "pod-5654b0b9-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:22:30.084: INFO: Trying to get logs from node conformance112-2 pod pod-5654b0b9-36f0-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:22:30.228: INFO: Waiting for pod pod-5654b0b9-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:22:30.243: INFO: Pod pod-5654b0b9-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:22:30.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jzlmv" for this suite.
Feb 22 22:22:42.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:22:42.376: INFO: namespace: e2e-tests-emptydir-jzlmv, resource: bindings, ignored listing per whitelist
Feb 22 22:22:42.455: INFO: namespace e2e-tests-emptydir-jzlmv deletion completed in 12.202981276s

• [SLOW TEST:14.601 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:22:42.455: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-42gbn
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-42gbn
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-42gbn
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-42gbn
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-42gbn
Feb 22 22:22:46.670: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-42gbn, name: ss-0, uid: 60411a09-36f0-11e9-b930-96c406f7d171, status phase: Pending. Waiting for statefulset controller to delete.
Feb 22 22:22:47.484: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-42gbn, name: ss-0, uid: 60411a09-36f0-11e9-b930-96c406f7d171, status phase: Failed. Waiting for statefulset controller to delete.
Feb 22 22:22:47.508: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-42gbn, name: ss-0, uid: 60411a09-36f0-11e9-b930-96c406f7d171, status phase: Failed. Waiting for statefulset controller to delete.
Feb 22 22:22:47.514: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-42gbn
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-42gbn
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-42gbn and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 22 22:22:51.596: INFO: Deleting all statefulset in ns e2e-tests-statefulset-42gbn
Feb 22 22:22:51.601: INFO: Scaling statefulset ss to 0
Feb 22 22:23:11.630: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 22:23:11.635: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:23:11.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-42gbn" for this suite.
Feb 22 22:23:18.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:23:20.953: INFO: namespace: e2e-tests-statefulset-42gbn, resource: bindings, ignored listing per whitelist
Feb 22 22:23:21.132: INFO: namespace e2e-tests-statefulset-42gbn deletion completed in 8.978264405s

• [SLOW TEST:38.677 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:23:21.135: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 22 22:23:21.245: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:23:25.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-pbs2s" for this suite.
Feb 22 22:23:31.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:23:31.516: INFO: namespace: e2e-tests-init-container-pbs2s, resource: bindings, ignored listing per whitelist
Feb 22 22:23:31.664: INFO: namespace e2e-tests-init-container-pbs2s deletion completed in 6.249379476s

• [SLOW TEST:10.530 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:23:31.664: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-7c577748-36f0-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 22:23:31.807: INFO: Waiting up to 5m0s for pod "pod-configmaps-7c58b65f-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-configmap-jdq8j" to be "success or failure"
Feb 22 22:23:31.827: INFO: Pod "pod-configmaps-7c58b65f-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 19.555698ms
Feb 22 22:23:33.837: INFO: Pod "pod-configmaps-7c58b65f-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029444123s
Feb 22 22:23:35.856: INFO: Pod "pod-configmaps-7c58b65f-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048848673s
STEP: Saw pod success
Feb 22 22:23:35.856: INFO: Pod "pod-configmaps-7c58b65f-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:23:35.862: INFO: Trying to get logs from node conformance112-2 pod pod-configmaps-7c58b65f-36f0-11e9-9d47-0276c9498759 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:23:35.907: INFO: Waiting for pod pod-configmaps-7c58b65f-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:23:35.935: INFO: Pod pod-configmaps-7c58b65f-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:23:35.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jdq8j" for this suite.
Feb 22 22:23:43.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:23:44.049: INFO: namespace: e2e-tests-configmap-jdq8j, resource: bindings, ignored listing per whitelist
Feb 22 22:23:44.176: INFO: namespace e2e-tests-configmap-jdq8j deletion completed in 8.230622218s

• [SLOW TEST:12.513 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:23:44.183: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 22 22:23:44.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 api-versions'
Feb 22 22:23:44.382: INFO: stderr: ""
Feb 22 22:23:44.382: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncluster.cattle.io/v3\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nmonitoring.coreos.com/v1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:23:44.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bqbfx" for this suite.
Feb 22 22:23:52.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:23:52.458: INFO: namespace: e2e-tests-kubectl-bqbfx, resource: bindings, ignored listing per whitelist
Feb 22 22:23:52.619: INFO: namespace e2e-tests-kubectl-bqbfx deletion completed in 8.231391482s

• [SLOW TEST:8.436 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:23:52.622: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:23:55.439: INFO: (0) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 10.740457ms)
Feb 22 22:23:55.452: INFO: (1) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 13.46741ms)
Feb 22 22:23:55.457: INFO: (2) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.809824ms)
Feb 22 22:23:55.462: INFO: (3) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.856017ms)
Feb 22 22:23:55.473: INFO: (4) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 11.152244ms)
Feb 22 22:23:55.487: INFO: (5) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 13.791508ms)
Feb 22 22:23:55.496: INFO: (6) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.827636ms)
Feb 22 22:23:55.503: INFO: (7) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.504799ms)
Feb 22 22:23:55.511: INFO: (8) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.649176ms)
Feb 22 22:23:55.516: INFO: (9) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.35711ms)
Feb 22 22:23:55.523: INFO: (10) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.527416ms)
Feb 22 22:23:55.528: INFO: (11) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.583492ms)
Feb 22 22:23:55.533: INFO: (12) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.951827ms)
Feb 22 22:23:55.539: INFO: (13) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.494551ms)
Feb 22 22:23:55.544: INFO: (14) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.800604ms)
Feb 22 22:23:55.549: INFO: (15) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.953786ms)
Feb 22 22:23:55.554: INFO: (16) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.895695ms)
Feb 22 22:23:55.558: INFO: (17) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.695342ms)
Feb 22 22:23:55.563: INFO: (18) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.692171ms)
Feb 22 22:23:55.568: INFO: (19) /api/v1/nodes/conformance112-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.764296ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:23:55.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9qxxg" for this suite.
Feb 22 22:24:01.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:24:01.748: INFO: namespace: e2e-tests-proxy-9qxxg, resource: bindings, ignored listing per whitelist
Feb 22 22:24:01.876: INFO: namespace e2e-tests-proxy-9qxxg deletion completed in 6.302780636s

• [SLOW TEST:9.254 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:24:01.877: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:24:02.121: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e67be16-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-tzs4g" to be "success or failure"
Feb 22 22:24:02.144: INFO: Pod "downwardapi-volume-8e67be16-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 23.298621ms
Feb 22 22:24:04.148: INFO: Pod "downwardapi-volume-8e67be16-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027468682s
STEP: Saw pod success
Feb 22 22:24:04.148: INFO: Pod "downwardapi-volume-8e67be16-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:24:04.155: INFO: Trying to get logs from node conformance112-3 pod downwardapi-volume-8e67be16-36f0-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 22:24:04.200: INFO: Waiting for pod downwardapi-volume-8e67be16-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:24:04.205: INFO: Pod downwardapi-volume-8e67be16-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:24:04.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tzs4g" for this suite.
Feb 22 22:24:10.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:24:10.366: INFO: namespace: e2e-tests-projected-tzs4g, resource: bindings, ignored listing per whitelist
Feb 22 22:24:10.378: INFO: namespace e2e-tests-projected-tzs4g deletion completed in 6.168266418s

• [SLOW TEST:8.502 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:24:10.381: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-zpdp
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 22:24:10.502: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-zpdp" in namespace "e2e-tests-subpath-dz5kn" to be "success or failure"
Feb 22 22:24:10.540: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Pending", Reason="", readiness=false. Elapsed: 38.242112ms
Feb 22 22:24:12.546: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044145919s
Feb 22 22:24:14.554: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Running", Reason="", readiness=false. Elapsed: 4.051499036s
Feb 22 22:24:16.560: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Running", Reason="", readiness=false. Elapsed: 6.057853327s
Feb 22 22:24:18.577: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Running", Reason="", readiness=false. Elapsed: 8.075100073s
Feb 22 22:24:20.584: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Running", Reason="", readiness=false. Elapsed: 10.081731624s
Feb 22 22:24:22.591: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Running", Reason="", readiness=false. Elapsed: 12.088713355s
Feb 22 22:24:24.597: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Running", Reason="", readiness=false. Elapsed: 14.094806159s
Feb 22 22:24:26.604: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Running", Reason="", readiness=false. Elapsed: 16.101393649s
Feb 22 22:24:28.889: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Running", Reason="", readiness=false. Elapsed: 18.386699026s
Feb 22 22:24:30.957: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Running", Reason="", readiness=false. Elapsed: 20.455051465s
Feb 22 22:24:33.245: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Running", Reason="", readiness=false. Elapsed: 22.74254816s
Feb 22 22:24:35.251: INFO: Pod "pod-subpath-test-secret-zpdp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.749264614s
STEP: Saw pod success
Feb 22 22:24:35.252: INFO: Pod "pod-subpath-test-secret-zpdp" satisfied condition "success or failure"
Feb 22 22:24:35.257: INFO: Trying to get logs from node conformance112-2 pod pod-subpath-test-secret-zpdp container test-container-subpath-secret-zpdp: <nil>
STEP: delete the pod
Feb 22 22:24:35.346: INFO: Waiting for pod pod-subpath-test-secret-zpdp to disappear
Feb 22 22:24:35.355: INFO: Pod pod-subpath-test-secret-zpdp no longer exists
STEP: Deleting pod pod-subpath-test-secret-zpdp
Feb 22 22:24:35.355: INFO: Deleting pod "pod-subpath-test-secret-zpdp" in namespace "e2e-tests-subpath-dz5kn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:24:35.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dz5kn" for this suite.
Feb 22 22:24:41.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:24:41.458: INFO: namespace: e2e-tests-subpath-dz5kn, resource: bindings, ignored listing per whitelist
Feb 22 22:24:46.090: INFO: namespace e2e-tests-subpath-dz5kn deletion completed in 10.720394069s

• [SLOW TEST:35.710 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:24:46.093: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 22 22:24:46.299: INFO: Waiting up to 5m0s for pod "pod-a8bfa1ef-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-2k8z7" to be "success or failure"
Feb 22 22:24:46.324: INFO: Pod "pod-a8bfa1ef-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 24.837981ms
Feb 22 22:24:48.329: INFO: Pod "pod-a8bfa1ef-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030247467s
STEP: Saw pod success
Feb 22 22:24:48.330: INFO: Pod "pod-a8bfa1ef-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:24:48.334: INFO: Trying to get logs from node conformance112-3 pod pod-a8bfa1ef-36f0-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:24:51.289: INFO: Waiting for pod pod-a8bfa1ef-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:24:51.315: INFO: Pod pod-a8bfa1ef-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:24:51.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2k8z7" for this suite.
Feb 22 22:24:57.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:24:57.365: INFO: namespace: e2e-tests-emptydir-2k8z7, resource: bindings, ignored listing per whitelist
Feb 22 22:24:57.519: INFO: namespace e2e-tests-emptydir-2k8z7 deletion completed in 6.197380953s

• [SLOW TEST:11.427 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:24:57.526: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-af87697a-36f0-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 22:24:57.693: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-af88d919-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-r4xgw" to be "success or failure"
Feb 22 22:24:57.716: INFO: Pod "pod-projected-secrets-af88d919-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 22.313358ms
Feb 22 22:24:59.721: INFO: Pod "pod-projected-secrets-af88d919-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027651574s
Feb 22 22:25:01.757: INFO: Pod "pod-projected-secrets-af88d919-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063411689s
STEP: Saw pod success
Feb 22 22:25:01.757: INFO: Pod "pod-projected-secrets-af88d919-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:25:01.763: INFO: Trying to get logs from node conformance112-2 pod pod-projected-secrets-af88d919-36f0-11e9-9d47-0276c9498759 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:25:07.843: INFO: Waiting for pod pod-projected-secrets-af88d919-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:25:07.849: INFO: Pod pod-projected-secrets-af88d919-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:25:07.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r4xgw" for this suite.
Feb 22 22:25:13.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:25:13.979: INFO: namespace: e2e-tests-projected-r4xgw, resource: bindings, ignored listing per whitelist
Feb 22 22:25:14.048: INFO: namespace e2e-tests-projected-r4xgw deletion completed in 6.19495598s

• [SLOW TEST:16.523 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:25:14.051: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 22 22:25:14.161: INFO: Waiting up to 5m0s for pod "var-expansion-b95d2c1c-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-var-expansion-z2msh" to be "success or failure"
Feb 22 22:25:14.190: INFO: Pod "var-expansion-b95d2c1c-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 28.75055ms
Feb 22 22:25:16.196: INFO: Pod "var-expansion-b95d2c1c-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034595959s
Feb 22 22:25:18.201: INFO: Pod "var-expansion-b95d2c1c-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039342613s
STEP: Saw pod success
Feb 22 22:25:18.201: INFO: Pod "var-expansion-b95d2c1c-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:25:18.205: INFO: Trying to get logs from node conformance112-3 pod var-expansion-b95d2c1c-36f0-11e9-9d47-0276c9498759 container dapi-container: <nil>
STEP: delete the pod
Feb 22 22:25:18.260: INFO: Waiting for pod var-expansion-b95d2c1c-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:25:18.265: INFO: Pod var-expansion-b95d2c1c-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:25:18.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-z2msh" for this suite.
Feb 22 22:25:24.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:25:24.466: INFO: namespace: e2e-tests-var-expansion-z2msh, resource: bindings, ignored listing per whitelist
Feb 22 22:25:24.478: INFO: namespace e2e-tests-var-expansion-z2msh deletion completed in 6.207233453s

• [SLOW TEST:10.428 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:25:24.481: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:25:24.592: INFO: (0) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.515372ms)
Feb 22 22:25:24.597: INFO: (1) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.21793ms)
Feb 22 22:25:24.603: INFO: (2) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.292791ms)
Feb 22 22:25:24.607: INFO: (3) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.411523ms)
Feb 22 22:25:24.621: INFO: (4) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 13.827978ms)
Feb 22 22:25:24.626: INFO: (5) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.257606ms)
Feb 22 22:25:24.633: INFO: (6) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.172971ms)
Feb 22 22:25:24.638: INFO: (7) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.627092ms)
Feb 22 22:25:24.644: INFO: (8) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.406719ms)
Feb 22 22:25:24.650: INFO: (9) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.787114ms)
Feb 22 22:25:24.655: INFO: (10) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.115741ms)
Feb 22 22:25:24.660: INFO: (11) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.950121ms)
Feb 22 22:25:24.666: INFO: (12) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.560749ms)
Feb 22 22:25:24.671: INFO: (13) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.138661ms)
Feb 22 22:25:24.676: INFO: (14) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.194747ms)
Feb 22 22:25:24.682: INFO: (15) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.945027ms)
Feb 22 22:25:24.690: INFO: (16) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.232286ms)
Feb 22 22:25:24.698: INFO: (17) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.489835ms)
Feb 22 22:25:24.708: INFO: (18) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 9.377756ms)
Feb 22 22:25:24.713: INFO: (19) /api/v1/nodes/conformance112-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.768875ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:25:24.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-r2rgl" for this suite.
Feb 22 22:25:30.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:25:31.012: INFO: namespace: e2e-tests-proxy-r2rgl, resource: bindings, ignored listing per whitelist
Feb 22 22:25:31.033: INFO: namespace e2e-tests-proxy-r2rgl deletion completed in 6.314165587s

• [SLOW TEST:6.553 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:25:31.039: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c38a8877-36f0-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 22:25:31.254: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c38c8c41-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-96q85" to be "success or failure"
Feb 22 22:25:31.280: INFO: Pod "pod-projected-configmaps-c38c8c41-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 25.664011ms
Feb 22 22:25:33.291: INFO: Pod "pod-projected-configmaps-c38c8c41-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037106853s
STEP: Saw pod success
Feb 22 22:25:33.291: INFO: Pod "pod-projected-configmaps-c38c8c41-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:25:33.296: INFO: Trying to get logs from node conformance112-2 pod pod-projected-configmaps-c38c8c41-36f0-11e9-9d47-0276c9498759 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:25:33.341: INFO: Waiting for pod pod-projected-configmaps-c38c8c41-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:25:33.351: INFO: Pod pod-projected-configmaps-c38c8c41-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:25:33.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-96q85" for this suite.
Feb 22 22:25:39.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:25:39.554: INFO: namespace: e2e-tests-projected-96q85, resource: bindings, ignored listing per whitelist
Feb 22 22:25:39.595: INFO: namespace e2e-tests-projected-96q85 deletion completed in 6.23670859s

• [SLOW TEST:8.557 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:25:39.596: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 22 22:25:39.724: INFO: Waiting up to 5m0s for pod "pod-c89a328f-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-l5gm7" to be "success or failure"
Feb 22 22:25:39.749: INFO: Pod "pod-c89a328f-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 25.103326ms
Feb 22 22:25:41.755: INFO: Pod "pod-c89a328f-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030584829s
Feb 22 22:25:43.767: INFO: Pod "pod-c89a328f-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042572865s
STEP: Saw pod success
Feb 22 22:25:43.767: INFO: Pod "pod-c89a328f-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:25:43.771: INFO: Trying to get logs from node conformance112-3 pod pod-c89a328f-36f0-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:25:43.857: INFO: Waiting for pod pod-c89a328f-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:25:43.864: INFO: Pod pod-c89a328f-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:25:43.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l5gm7" for this suite.
Feb 22 22:25:49.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:25:50.025: INFO: namespace: e2e-tests-emptydir-l5gm7, resource: bindings, ignored listing per whitelist
Feb 22 22:25:50.083: INFO: namespace e2e-tests-emptydir-l5gm7 deletion completed in 6.212363311s

• [SLOW TEST:10.487 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:25:50.085: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-ced9fb32-36f0-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume secrets
Feb 22 22:25:50.217: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cedb34b1-36f0-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-thdcn" to be "success or failure"
Feb 22 22:25:50.236: INFO: Pod "pod-projected-secrets-cedb34b1-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 18.489034ms
Feb 22 22:25:52.244: INFO: Pod "pod-projected-secrets-cedb34b1-36f0-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026441365s
Feb 22 22:25:54.258: INFO: Pod "pod-projected-secrets-cedb34b1-36f0-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040351839s
STEP: Saw pod success
Feb 22 22:25:54.258: INFO: Pod "pod-projected-secrets-cedb34b1-36f0-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:25:54.262: INFO: Trying to get logs from node conformance112-2 pod pod-projected-secrets-cedb34b1-36f0-11e9-9d47-0276c9498759 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 22:25:54.323: INFO: Waiting for pod pod-projected-secrets-cedb34b1-36f0-11e9-9d47-0276c9498759 to disappear
Feb 22 22:25:54.331: INFO: Pod pod-projected-secrets-cedb34b1-36f0-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:25:54.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-thdcn" for this suite.
Feb 22 22:26:00.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:26:00.468: INFO: namespace: e2e-tests-projected-thdcn, resource: bindings, ignored listing per whitelist
Feb 22 22:26:00.557: INFO: namespace e2e-tests-projected-thdcn deletion completed in 6.220353404s

• [SLOW TEST:10.472 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:26:00.558: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-hdtnc
Feb 22 22:26:02.721: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-hdtnc
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 22:26:02.726: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:30:03.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hdtnc" for this suite.
Feb 22 22:30:09.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:30:09.720: INFO: namespace: e2e-tests-container-probe-hdtnc, resource: bindings, ignored listing per whitelist
Feb 22 22:30:09.897: INFO: namespace e2e-tests-container-probe-hdtnc deletion completed in 6.220448919s

• [SLOW TEST:249.339 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:30:09.899: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0222 22:30:11.221790      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 22:30:11.221: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:30:11.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k85vf" for this suite.
Feb 22 22:30:17.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:30:17.408: INFO: namespace: e2e-tests-gc-k85vf, resource: bindings, ignored listing per whitelist
Feb 22 22:30:17.462: INFO: namespace e2e-tests-gc-k85vf deletion completed in 6.235162444s

• [SLOW TEST:7.563 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:30:17.464: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 22 22:30:25.715: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:25.732: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:27.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:27.744: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:29.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:29.760: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:31.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:31.754: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:33.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:33.740: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:35.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:36.793: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:37.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:37.742: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:39.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:39.739: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:41.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:41.748: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:43.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:43.740: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:45.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:45.739: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:47.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:47.747: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:49.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:49.738: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:51.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:51.740: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 22:30:53.733: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 22:30:53.749: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:30:53.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-2qntq" for this suite.
Feb 22 22:31:17.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:31:17.881: INFO: namespace: e2e-tests-container-lifecycle-hook-2qntq, resource: bindings, ignored listing per whitelist
Feb 22 22:31:18.018: INFO: namespace e2e-tests-container-lifecycle-hook-2qntq deletion completed in 24.262347889s

• [SLOW TEST:60.554 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:31:18.019: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:31:18.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 version'
Feb 22 22:31:18.281: INFO: stderr: ""
Feb 22 22:31:18.281: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.5\", GitCommit:\"51dd616cdd25d6ee22c83a858773b607328a18ec\", GitTreeState:\"clean\", BuildDate:\"2019-01-16T18:14:49Z\", GoVersion:\"go1.10.7\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:31:18.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5hv67" for this suite.
Feb 22 22:31:24.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:31:24.416: INFO: namespace: e2e-tests-kubectl-5hv67, resource: bindings, ignored listing per whitelist
Feb 22 22:31:24.513: INFO: namespace e2e-tests-kubectl-5hv67 deletion completed in 6.221216024s

• [SLOW TEST:6.495 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:31:24.522: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 22 22:31:24.632: INFO: Creating ReplicaSet my-hostname-basic-9630fb7d-36f1-11e9-9d47-0276c9498759
Feb 22 22:31:24.653: INFO: Pod name my-hostname-basic-9630fb7d-36f1-11e9-9d47-0276c9498759: Found 0 pods out of 1
Feb 22 22:31:29.664: INFO: Pod name my-hostname-basic-9630fb7d-36f1-11e9-9d47-0276c9498759: Found 1 pods out of 1
Feb 22 22:31:29.664: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-9630fb7d-36f1-11e9-9d47-0276c9498759" is running
Feb 22 22:31:29.673: INFO: Pod "my-hostname-basic-9630fb7d-36f1-11e9-9d47-0276c9498759-8rrrz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:31:24 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:31:26 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:31:26 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-22 22:31:24 +0000 UTC Reason: Message:}])
Feb 22 22:31:29.673: INFO: Trying to dial the pod
Feb 22 22:31:34.692: INFO: Controller my-hostname-basic-9630fb7d-36f1-11e9-9d47-0276c9498759: Got expected result from replica 1 [my-hostname-basic-9630fb7d-36f1-11e9-9d47-0276c9498759-8rrrz]: "my-hostname-basic-9630fb7d-36f1-11e9-9d47-0276c9498759-8rrrz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:31:34.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-fg88n" for this suite.
Feb 22 22:31:40.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:31:40.798: INFO: namespace: e2e-tests-replicaset-fg88n, resource: bindings, ignored listing per whitelist
Feb 22 22:31:40.909: INFO: namespace e2e-tests-replicaset-fg88n deletion completed in 6.206173009s

• [SLOW TEST:16.388 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:31:40.912: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 22 22:31:41.076: INFO: Waiting up to 5m0s for pod "pod-9ffc653f-36f1-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-rwjzd" to be "success or failure"
Feb 22 22:31:41.095: INFO: Pod "pod-9ffc653f-36f1-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 18.713363ms
Feb 22 22:31:43.101: INFO: Pod "pod-9ffc653f-36f1-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025207374s
Feb 22 22:31:45.108: INFO: Pod "pod-9ffc653f-36f1-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031597031s
STEP: Saw pod success
Feb 22 22:31:45.108: INFO: Pod "pod-9ffc653f-36f1-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:31:45.112: INFO: Trying to get logs from node conformance112-3 pod pod-9ffc653f-36f1-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:31:45.150: INFO: Waiting for pod pod-9ffc653f-36f1-11e9-9d47-0276c9498759 to disappear
Feb 22 22:31:45.159: INFO: Pod pod-9ffc653f-36f1-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:31:45.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rwjzd" for this suite.
Feb 22 22:31:51.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:31:51.216: INFO: namespace: e2e-tests-emptydir-rwjzd, resource: bindings, ignored listing per whitelist
Feb 22 22:31:51.366: INFO: namespace e2e-tests-emptydir-rwjzd deletion completed in 6.201006169s

• [SLOW TEST:10.455 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:31:51.373: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 22 22:31:51.473: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a62e71ad-36f1-11e9-9d47-0276c9498759" in namespace "e2e-tests-downward-api-nqnvt" to be "success or failure"
Feb 22 22:31:51.495: INFO: Pod "downwardapi-volume-a62e71ad-36f1-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 22.015182ms
Feb 22 22:31:53.500: INFO: Pod "downwardapi-volume-a62e71ad-36f1-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026960412s
STEP: Saw pod success
Feb 22 22:31:53.501: INFO: Pod "downwardapi-volume-a62e71ad-36f1-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:31:53.506: INFO: Trying to get logs from node conformance112-2 pod downwardapi-volume-a62e71ad-36f1-11e9-9d47-0276c9498759 container client-container: <nil>
STEP: delete the pod
Feb 22 22:31:53.573: INFO: Waiting for pod downwardapi-volume-a62e71ad-36f1-11e9-9d47-0276c9498759 to disappear
Feb 22 22:31:53.593: INFO: Pod downwardapi-volume-a62e71ad-36f1-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:31:53.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nqnvt" for this suite.
Feb 22 22:31:59.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:31:59.670: INFO: namespace: e2e-tests-downward-api-nqnvt, resource: bindings, ignored listing per whitelist
Feb 22 22:31:59.809: INFO: namespace e2e-tests-downward-api-nqnvt deletion completed in 6.209330875s

• [SLOW TEST:8.437 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:31:59.812: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ab35c750-36f1-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 22:31:59.919: INFO: Waiting up to 5m0s for pod "pod-configmaps-ab371549-36f1-11e9-9d47-0276c9498759" in namespace "e2e-tests-configmap-c5gqp" to be "success or failure"
Feb 22 22:31:59.934: INFO: Pod "pod-configmaps-ab371549-36f1-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 15.403362ms
Feb 22 22:32:01.959: INFO: Pod "pod-configmaps-ab371549-36f1-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039649367s
STEP: Saw pod success
Feb 22 22:32:01.959: INFO: Pod "pod-configmaps-ab371549-36f1-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:32:01.968: INFO: Trying to get logs from node conformance112-3 pod pod-configmaps-ab371549-36f1-11e9-9d47-0276c9498759 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:32:02.057: INFO: Waiting for pod pod-configmaps-ab371549-36f1-11e9-9d47-0276c9498759 to disappear
Feb 22 22:32:02.062: INFO: Pod pod-configmaps-ab371549-36f1-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:32:02.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-c5gqp" for this suite.
Feb 22 22:32:08.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:32:08.289: INFO: namespace: e2e-tests-configmap-c5gqp, resource: bindings, ignored listing per whitelist
Feb 22 22:32:08.313: INFO: namespace e2e-tests-configmap-c5gqp deletion completed in 6.243653237s

• [SLOW TEST:8.501 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:32:08.315: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-cdsvs
Feb 22 22:32:12.485: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-cdsvs
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 22:32:12.490: INFO: Initial restart count of pod liveness-http is 0
Feb 22 22:32:26.555: INFO: Restart count of pod e2e-tests-container-probe-cdsvs/liveness-http is now 1 (14.065153007s elapsed)
Feb 22 22:32:46.638: INFO: Restart count of pod e2e-tests-container-probe-cdsvs/liveness-http is now 2 (34.147730068s elapsed)
Feb 22 22:33:06.712: INFO: Restart count of pod e2e-tests-container-probe-cdsvs/liveness-http is now 3 (54.222312165s elapsed)
Feb 22 22:33:26.779: INFO: Restart count of pod e2e-tests-container-probe-cdsvs/liveness-http is now 4 (1m14.288577929s elapsed)
Feb 22 22:34:37.558: INFO: Restart count of pod e2e-tests-container-probe-cdsvs/liveness-http is now 5 (2m25.068179134s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:34:37.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cdsvs" for this suite.
Feb 22 22:34:43.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:34:43.966: INFO: namespace: e2e-tests-container-probe-cdsvs, resource: bindings, ignored listing per whitelist
Feb 22 22:34:43.996: INFO: namespace e2e-tests-container-probe-cdsvs deletion completed in 6.318343947s

• [SLOW TEST:155.682 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:34:44.001: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 22 22:34:44.149: INFO: Waiting up to 5m0s for pod "pod-0d19d867-36f2-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-jc8mn" to be "success or failure"
Feb 22 22:34:44.175: INFO: Pod "pod-0d19d867-36f2-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 26.053609ms
Feb 22 22:34:48.975: INFO: Pod "pod-0d19d867-36f2-11e9-9d47-0276c9498759": Phase="Running", Reason="", readiness=true. Elapsed: 4.826328211s
Feb 22 22:34:50.982: INFO: Pod "pod-0d19d867-36f2-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.833637495s
STEP: Saw pod success
Feb 22 22:34:50.982: INFO: Pod "pod-0d19d867-36f2-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:34:50.991: INFO: Trying to get logs from node conformance112-3 pod pod-0d19d867-36f2-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:34:51.811: INFO: Waiting for pod pod-0d19d867-36f2-11e9-9d47-0276c9498759 to disappear
Feb 22 22:34:51.816: INFO: Pod pod-0d19d867-36f2-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:34:51.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jc8mn" for this suite.
Feb 22 22:34:57.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:34:57.949: INFO: namespace: e2e-tests-emptydir-jc8mn, resource: bindings, ignored listing per whitelist
Feb 22 22:34:58.090: INFO: namespace e2e-tests-emptydir-jc8mn deletion completed in 6.266698968s

• [SLOW TEST:14.089 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:34:58.092: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-157eb954-36f2-11e9-9d47-0276c9498759
STEP: Creating secret with name secret-projected-all-test-volume-157eb945-36f2-11e9-9d47-0276c9498759
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 22 22:34:58.323: INFO: Waiting up to 5m0s for pod "projected-volume-157eb916-36f2-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-s7kzj" to be "success or failure"
Feb 22 22:34:58.336: INFO: Pod "projected-volume-157eb916-36f2-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 13.293932ms
Feb 22 22:35:01.202: INFO: Pod "projected-volume-157eb916-36f2-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.87917443s
Feb 22 22:35:03.207: INFO: Pod "projected-volume-157eb916-36f2-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.884273348s
STEP: Saw pod success
Feb 22 22:35:03.207: INFO: Pod "projected-volume-157eb916-36f2-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:35:03.212: INFO: Trying to get logs from node conformance112-2 pod projected-volume-157eb916-36f2-11e9-9d47-0276c9498759 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 22 22:35:03.269: INFO: Waiting for pod projected-volume-157eb916-36f2-11e9-9d47-0276c9498759 to disappear
Feb 22 22:35:03.276: INFO: Pod projected-volume-157eb916-36f2-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:35:03.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s7kzj" for this suite.
Feb 22 22:35:09.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:35:09.471: INFO: namespace: e2e-tests-projected-s7kzj, resource: bindings, ignored listing per whitelist
Feb 22 22:35:09.561: INFO: namespace e2e-tests-projected-s7kzj deletion completed in 6.276803705s

• [SLOW TEST:11.469 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:35:09.562: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 22 22:35:09.736: INFO: Waiting up to 5m0s for pod "pod-1c58b10b-36f2-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-wfqgh" to be "success or failure"
Feb 22 22:35:09.772: INFO: Pod "pod-1c58b10b-36f2-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 35.995395ms
Feb 22 22:35:11.780: INFO: Pod "pod-1c58b10b-36f2-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043960774s
Feb 22 22:35:13.787: INFO: Pod "pod-1c58b10b-36f2-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050787459s
STEP: Saw pod success
Feb 22 22:35:13.787: INFO: Pod "pod-1c58b10b-36f2-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:35:13.792: INFO: Trying to get logs from node conformance112-2 pod pod-1c58b10b-36f2-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:35:13.854: INFO: Waiting for pod pod-1c58b10b-36f2-11e9-9d47-0276c9498759 to disappear
Feb 22 22:35:13.878: INFO: Pod pod-1c58b10b-36f2-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:35:13.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wfqgh" for this suite.
Feb 22 22:35:22.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:35:22.889: INFO: namespace: e2e-tests-emptydir-wfqgh, resource: bindings, ignored listing per whitelist
Feb 22 22:35:23.046: INFO: namespace e2e-tests-emptydir-wfqgh deletion completed in 9.15296482s

• [SLOW TEST:13.485 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:35:23.050: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0222 22:35:33.347821      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 22 22:35:33.347: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:35:33.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ph9dk" for this suite.
Feb 22 22:35:39.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:35:39.486: INFO: namespace: e2e-tests-gc-ph9dk, resource: bindings, ignored listing per whitelist
Feb 22 22:35:39.653: INFO: namespace e2e-tests-gc-ph9dk deletion completed in 6.298764224s

• [SLOW TEST:16.603 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:35:39.655: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 22:35:39.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jmnln'
Feb 22 22:35:40.444: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 22 22:35:40.444: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Feb 22 22:35:42.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-jmnln'
Feb 22 22:35:42.677: INFO: stderr: ""
Feb 22 22:35:42.677: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:35:42.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jmnln" for this suite.
Feb 22 22:36:06.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:36:06.885: INFO: namespace: e2e-tests-kubectl-jmnln, resource: bindings, ignored listing per whitelist
Feb 22 22:36:07.039: INFO: namespace e2e-tests-kubectl-jmnln deletion completed in 24.336173645s

• [SLOW TEST:27.384 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:36:07.042: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 22 22:36:07.153: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 22 22:36:07.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:07.447: INFO: stderr: ""
Feb 22 22:36:07.447: INFO: stdout: "service/redis-slave created\n"
Feb 22 22:36:07.447: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 22 22:36:07.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:07.769: INFO: stderr: ""
Feb 22 22:36:07.769: INFO: stdout: "service/redis-master created\n"
Feb 22 22:36:07.769: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 22 22:36:07.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:08.051: INFO: stderr: ""
Feb 22 22:36:08.051: INFO: stdout: "service/frontend created\n"
Feb 22 22:36:08.051: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 22 22:36:08.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:08.287: INFO: stderr: ""
Feb 22 22:36:08.287: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 22 22:36:08.287: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 22 22:36:08.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:08.641: INFO: stderr: ""
Feb 22 22:36:08.641: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 22 22:36:08.641: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 22 22:36:08.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:09.238: INFO: stderr: ""
Feb 22 22:36:09.238: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 22 22:36:09.238: INFO: Waiting for all frontend pods to be Running.
Feb 22 22:36:34.289: INFO: Waiting for frontend to serve content.
Feb 22 22:36:34.339: INFO: Trying to add a new entry to the guestbook.
Feb 22 22:36:34.361: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 22 22:36:34.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:34.603: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:36:34.603: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 22:36:34.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:34.869: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:36:34.869: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 22:36:34.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:35.326: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:36:35.327: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 22:36:35.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:35.517: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:36:35.517: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 22:36:35.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:35.737: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:36:35.737: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 22:36:35.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rrk6j'
Feb 22 22:36:36.012: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:36:36.012: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:36:36.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rrk6j" for this suite.
Feb 22 22:37:16.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:37:16.327: INFO: namespace: e2e-tests-kubectl-rrk6j, resource: bindings, ignored listing per whitelist
Feb 22 22:37:16.386: INFO: namespace e2e-tests-kubectl-rrk6j deletion completed in 40.347761727s

• [SLOW TEST:69.345 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:37:16.389: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 22 22:37:16.551: INFO: namespace e2e-tests-kubectl-bppvv
Feb 22 22:37:16.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-bppvv'
Feb 22 22:37:16.806: INFO: stderr: ""
Feb 22 22:37:16.806: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 22 22:37:17.812: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 22:37:17.812: INFO: Found 0 / 1
Feb 22 22:37:18.812: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 22:37:18.812: INFO: Found 1 / 1
Feb 22 22:37:18.812: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 22 22:37:18.819: INFO: Selector matched 1 pods for map[app:redis]
Feb 22 22:37:18.819: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 22 22:37:18.819: INFO: wait on redis-master startup in e2e-tests-kubectl-bppvv 
Feb 22 22:37:18.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 logs redis-master-grrw8 redis-master --namespace=e2e-tests-kubectl-bppvv'
Feb 22 22:37:18.953: INFO: stderr: ""
Feb 22 22:37:18.953: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Feb 22:37:18.448 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Feb 22:37:18.448 # Server started, Redis version 3.2.12\n1:M 22 Feb 22:37:18.448 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Feb 22:37:18.448 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 22 22:37:18.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-bppvv'
Feb 22 22:37:19.134: INFO: stderr: ""
Feb 22 22:37:19.134: INFO: stdout: "service/rm2 exposed\n"
Feb 22 22:37:19.146: INFO: Service rm2 in namespace e2e-tests-kubectl-bppvv found.
STEP: exposing service
Feb 22 22:37:21.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-bppvv'
Feb 22 22:37:21.353: INFO: stderr: ""
Feb 22 22:37:21.353: INFO: stdout: "service/rm3 exposed\n"
Feb 22 22:37:21.358: INFO: Service rm3 in namespace e2e-tests-kubectl-bppvv found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:37:23.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bppvv" for this suite.
Feb 22 22:37:47.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:37:47.453: INFO: namespace: e2e-tests-kubectl-bppvv, resource: bindings, ignored listing per whitelist
Feb 22 22:37:47.609: INFO: namespace e2e-tests-kubectl-bppvv deletion completed in 24.229382957s

• [SLOW TEST:31.220 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:37:47.613: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-b9vnn
Feb 22 22:37:51.794: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-b9vnn
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 22:37:51.799: INFO: Initial restart count of pod liveness-http is 0
Feb 22 22:38:15.963: INFO: Restart count of pod e2e-tests-container-probe-b9vnn/liveness-http is now 1 (24.164227369s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:38:16.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-b9vnn" for this suite.
Feb 22 22:38:22.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:38:22.278: INFO: namespace: e2e-tests-container-probe-b9vnn, resource: bindings, ignored listing per whitelist
Feb 22 22:38:22.310: INFO: namespace e2e-tests-container-probe-b9vnn deletion completed in 6.278252629s

• [SLOW TEST:34.697 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:38:22.310: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 22 22:38:22.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-nvhfb'
Feb 22 22:38:22.655: INFO: stderr: ""
Feb 22 22:38:22.655: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 22:38:22.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nvhfb'
Feb 22 22:38:22.813: INFO: stderr: ""
Feb 22 22:38:22.813: INFO: stdout: "update-demo-nautilus-mbj8j update-demo-nautilus-tbfzx "
Feb 22 22:38:22.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-mbj8j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvhfb'
Feb 22 22:38:22.935: INFO: stderr: ""
Feb 22 22:38:22.935: INFO: stdout: ""
Feb 22 22:38:22.935: INFO: update-demo-nautilus-mbj8j is created but not running
Feb 22 22:38:27.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nvhfb'
Feb 22 22:38:28.109: INFO: stderr: ""
Feb 22 22:38:28.109: INFO: stdout: "update-demo-nautilus-mbj8j update-demo-nautilus-tbfzx "
Feb 22 22:38:28.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-mbj8j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvhfb'
Feb 22 22:38:28.302: INFO: stderr: ""
Feb 22 22:38:28.302: INFO: stdout: "true"
Feb 22 22:38:28.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-mbj8j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvhfb'
Feb 22 22:38:28.484: INFO: stderr: ""
Feb 22 22:38:28.484: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 22:38:28.484: INFO: validating pod update-demo-nautilus-mbj8j
Feb 22 22:38:28.497: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 22:38:28.497: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 22:38:28.497: INFO: update-demo-nautilus-mbj8j is verified up and running
Feb 22 22:38:28.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-tbfzx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvhfb'
Feb 22 22:38:28.622: INFO: stderr: ""
Feb 22 22:38:28.622: INFO: stdout: "true"
Feb 22 22:38:28.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-tbfzx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nvhfb'
Feb 22 22:38:28.741: INFO: stderr: ""
Feb 22 22:38:28.741: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 22:38:28.741: INFO: validating pod update-demo-nautilus-tbfzx
Feb 22 22:38:28.748: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 22:38:28.748: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 22:38:28.748: INFO: update-demo-nautilus-tbfzx is verified up and running
STEP: using delete to clean up resources
Feb 22 22:38:28.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nvhfb'
Feb 22 22:38:28.880: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:38:28.880: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 22 22:38:28.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-nvhfb'
Feb 22 22:38:29.021: INFO: stderr: "No resources found.\n"
Feb 22 22:38:29.021: INFO: stdout: ""
Feb 22 22:38:29.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -l name=update-demo --namespace=e2e-tests-kubectl-nvhfb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 22:38:29.144: INFO: stderr: ""
Feb 22 22:38:29.144: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:38:29.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nvhfb" for this suite.
Feb 22 22:38:53.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:38:53.424: INFO: namespace: e2e-tests-kubectl-nvhfb, resource: bindings, ignored listing per whitelist
Feb 22 22:38:53.462: INFO: namespace e2e-tests-kubectl-nvhfb deletion completed in 24.298363s

• [SLOW TEST:31.152 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:38:53.464: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 22:38:53.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-z2x5m'
Feb 22 22:38:53.745: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 22 22:38:53.745: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 22 22:38:53.758: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb 22 22:38:53.782: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 22 22:38:53.853: INFO: scanned /root for discovery docs: <nil>
Feb 22 22:38:53.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-z2x5m'
Feb 22 22:39:09.965: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 22 22:39:09.965: INFO: stdout: "Created e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6\nScaling up e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 22 22:39:09.965: INFO: stdout: "Created e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6\nScaling up e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 22 22:39:09.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-z2x5m'
Feb 22 22:39:10.104: INFO: stderr: ""
Feb 22 22:39:10.104: INFO: stdout: "e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6-646ww "
Feb 22 22:39:10.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6-646ww -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z2x5m'
Feb 22 22:39:10.209: INFO: stderr: ""
Feb 22 22:39:10.209: INFO: stdout: "true"
Feb 22 22:39:10.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6-646ww -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-z2x5m'
Feb 22 22:39:10.308: INFO: stderr: ""
Feb 22 22:39:10.308: INFO: stdout: "nginx:1.14-alpine"
Feb 22 22:39:10.308: INFO: e2e-test-nginx-rc-e0959599a19c1bfd37e39ff0b893f6a6-646ww is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Feb 22 22:39:10.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-z2x5m'
Feb 22 22:39:10.442: INFO: stderr: ""
Feb 22 22:39:10.442: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:39:10.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z2x5m" for this suite.
Feb 22 22:39:34.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:39:34.616: INFO: namespace: e2e-tests-kubectl-z2x5m, resource: bindings, ignored listing per whitelist
Feb 22 22:39:34.806: INFO: namespace e2e-tests-kubectl-z2x5m deletion completed in 24.351507109s

• [SLOW TEST:41.343 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:39:34.809: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 22 22:39:34.967: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-a,UID:ba738e6b-36f2-11e9-b930-96c406f7d171,ResourceVersion:22508,Generation:0,CreationTimestamp:2019-02-22 22:39:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 22 22:39:34.968: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-a,UID:ba738e6b-36f2-11e9-b930-96c406f7d171,ResourceVersion:22508,Generation:0,CreationTimestamp:2019-02-22 22:39:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 22 22:39:45.001: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-a,UID:ba738e6b-36f2-11e9-b930-96c406f7d171,ResourceVersion:22531,Generation:0,CreationTimestamp:2019-02-22 22:39:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 22 22:39:45.001: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-a,UID:ba738e6b-36f2-11e9-b930-96c406f7d171,ResourceVersion:22531,Generation:0,CreationTimestamp:2019-02-22 22:39:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 22 22:39:55.031: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-a,UID:ba738e6b-36f2-11e9-b930-96c406f7d171,ResourceVersion:22549,Generation:0,CreationTimestamp:2019-02-22 22:39:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 22 22:39:55.032: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-a,UID:ba738e6b-36f2-11e9-b930-96c406f7d171,ResourceVersion:22549,Generation:0,CreationTimestamp:2019-02-22 22:39:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 22 22:40:05.071: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-a,UID:ba738e6b-36f2-11e9-b930-96c406f7d171,ResourceVersion:22567,Generation:0,CreationTimestamp:2019-02-22 22:39:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 22 22:40:05.072: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-a,UID:ba738e6b-36f2-11e9-b930-96c406f7d171,ResourceVersion:22567,Generation:0,CreationTimestamp:2019-02-22 22:39:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 22 22:40:15.094: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-b,UID:d25dd064-36f2-11e9-b930-96c406f7d171,ResourceVersion:22586,Generation:0,CreationTimestamp:2019-02-22 22:40:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 22 22:40:15.094: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-b,UID:d25dd064-36f2-11e9-b930-96c406f7d171,ResourceVersion:22586,Generation:0,CreationTimestamp:2019-02-22 22:40:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 22 22:40:25.123: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-b,UID:d25dd064-36f2-11e9-b930-96c406f7d171,ResourceVersion:22604,Generation:0,CreationTimestamp:2019-02-22 22:40:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 22 22:40:25.123: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5n84w,SelfLink:/api/v1/namespaces/e2e-tests-watch-5n84w/configmaps/e2e-watch-test-configmap-b,UID:d25dd064-36f2-11e9-b930-96c406f7d171,ResourceVersion:22604,Generation:0,CreationTimestamp:2019-02-22 22:40:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:40:35.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5n84w" for this suite.
Feb 22 22:40:41.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:40:41.343: INFO: namespace: e2e-tests-watch-5n84w, resource: bindings, ignored listing per whitelist
Feb 22 22:40:41.569: INFO: namespace e2e-tests-watch-5n84w deletion completed in 6.429771544s

• [SLOW TEST:66.761 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:40:41.573: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-e245a1e5-36f2-11e9-9d47-0276c9498759
STEP: Creating secret with name s-test-opt-upd-e245a2bc-36f2-11e9-9d47-0276c9498759
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e245a1e5-36f2-11e9-9d47-0276c9498759
STEP: Updating secret s-test-opt-upd-e245a2bc-36f2-11e9-9d47-0276c9498759
STEP: Creating secret with name s-test-opt-create-e245a2e6-36f2-11e9-9d47-0276c9498759
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:42:13.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qcfth" for this suite.
Feb 22 22:42:37.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:42:37.248: INFO: namespace: e2e-tests-projected-qcfth, resource: bindings, ignored listing per whitelist
Feb 22 22:42:37.343: INFO: namespace e2e-tests-projected-qcfth deletion completed in 24.274764191s

• [SLOW TEST:115.771 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:42:37.346: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 22:42:37.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-9wl2k'
Feb 22 22:42:37.694: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb 22 22:42:37.694: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Feb 22 22:42:37.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-9wl2k'
Feb 22 22:42:37.855: INFO: stderr: ""
Feb 22 22:42:37.855: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:42:37.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9wl2k" for this suite.
Feb 22 22:42:43.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:42:44.014: INFO: namespace: e2e-tests-kubectl-9wl2k, resource: bindings, ignored listing per whitelist
Feb 22 22:42:44.149: INFO: namespace e2e-tests-kubectl-9wl2k deletion completed in 6.284274251s

• [SLOW TEST:6.804 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:42:44.153: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 22 22:42:44.360: INFO: Waiting up to 5m0s for pod "pod-2b54b805-36f3-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-hbwfv" to be "success or failure"
Feb 22 22:42:44.402: INFO: Pod "pod-2b54b805-36f3-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 41.403297ms
Feb 22 22:42:46.409: INFO: Pod "pod-2b54b805-36f3-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048994913s
Feb 22 22:42:48.416: INFO: Pod "pod-2b54b805-36f3-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055511658s
STEP: Saw pod success
Feb 22 22:42:48.416: INFO: Pod "pod-2b54b805-36f3-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:42:48.421: INFO: Trying to get logs from node conformance112-2 pod pod-2b54b805-36f3-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:42:48.485: INFO: Waiting for pod pod-2b54b805-36f3-11e9-9d47-0276c9498759 to disappear
Feb 22 22:42:48.518: INFO: Pod pod-2b54b805-36f3-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:42:48.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hbwfv" for this suite.
Feb 22 22:42:54.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:42:54.596: INFO: namespace: e2e-tests-emptydir-hbwfv, resource: bindings, ignored listing per whitelist
Feb 22 22:42:54.753: INFO: namespace e2e-tests-emptydir-hbwfv deletion completed in 6.226933186s

• [SLOW TEST:10.600 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:42:54.756: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 22 22:42:54.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:42:55.208: INFO: stderr: ""
Feb 22 22:42:55.209: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 22:42:55.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:42:55.440: INFO: stderr: ""
Feb 22 22:42:55.440: INFO: stdout: "update-demo-nautilus-cf4r4 update-demo-nautilus-knvpq "
Feb 22 22:42:55.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-cf4r4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:42:55.593: INFO: stderr: ""
Feb 22 22:42:55.593: INFO: stdout: ""
Feb 22 22:42:55.593: INFO: update-demo-nautilus-cf4r4 is created but not running
Feb 22 22:43:00.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:43:00.723: INFO: stderr: ""
Feb 22 22:43:00.723: INFO: stdout: "update-demo-nautilus-cf4r4 update-demo-nautilus-knvpq "
Feb 22 22:43:00.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-cf4r4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:43:00.848: INFO: stderr: ""
Feb 22 22:43:00.848: INFO: stdout: "true"
Feb 22 22:43:00.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-cf4r4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:43:01.008: INFO: stderr: ""
Feb 22 22:43:01.008: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 22:43:01.008: INFO: validating pod update-demo-nautilus-cf4r4
Feb 22 22:43:01.026: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 22:43:01.026: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 22:43:01.026: INFO: update-demo-nautilus-cf4r4 is verified up and running
Feb 22 22:43:01.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-knvpq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:43:01.180: INFO: stderr: ""
Feb 22 22:43:01.180: INFO: stdout: "true"
Feb 22 22:43:01.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-nautilus-knvpq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:43:01.322: INFO: stderr: ""
Feb 22 22:43:01.322: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 22:43:01.322: INFO: validating pod update-demo-nautilus-knvpq
Feb 22 22:43:01.349: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 22:43:01.349: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 22:43:01.349: INFO: update-demo-nautilus-knvpq is verified up and running
STEP: rolling-update to new replication controller
Feb 22 22:43:01.353: INFO: scanned /root for discovery docs: <nil>
Feb 22 22:43:01.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:43:24.317: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 22 22:43:24.317: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 22:43:24.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:43:24.477: INFO: stderr: ""
Feb 22 22:43:24.477: INFO: stdout: "update-demo-kitten-f6gqn update-demo-kitten-h7c9q "
Feb 22 22:43:24.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-kitten-f6gqn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:43:24.612: INFO: stderr: ""
Feb 22 22:43:24.612: INFO: stdout: "true"
Feb 22 22:43:24.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-kitten-f6gqn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:43:24.747: INFO: stderr: ""
Feb 22 22:43:24.747: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 22 22:43:24.747: INFO: validating pod update-demo-kitten-f6gqn
Feb 22 22:43:24.764: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 22 22:43:24.764: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 22 22:43:24.764: INFO: update-demo-kitten-f6gqn is verified up and running
Feb 22 22:43:24.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-kitten-h7c9q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:43:24.904: INFO: stderr: ""
Feb 22 22:43:24.904: INFO: stdout: "true"
Feb 22 22:43:24.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods update-demo-kitten-h7c9q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zqxdr'
Feb 22 22:43:25.022: INFO: stderr: ""
Feb 22 22:43:25.022: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 22 22:43:25.022: INFO: validating pod update-demo-kitten-h7c9q
Feb 22 22:43:25.037: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 22 22:43:25.037: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 22 22:43:25.037: INFO: update-demo-kitten-h7c9q is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:43:25.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zqxdr" for this suite.
Feb 22 22:43:49.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:43:49.181: INFO: namespace: e2e-tests-kubectl-zqxdr, resource: bindings, ignored listing per whitelist
Feb 22 22:43:49.407: INFO: namespace e2e-tests-kubectl-zqxdr deletion completed in 24.362532098s

• [SLOW TEST:54.651 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:43:49.407: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 22 22:43:49.584: INFO: Waiting up to 5m0s for pod "client-containers-52326076-36f3-11e9-9d47-0276c9498759" in namespace "e2e-tests-containers-5x5q9" to be "success or failure"
Feb 22 22:43:49.598: INFO: Pod "client-containers-52326076-36f3-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 12.520795ms
Feb 22 22:43:51.604: INFO: Pod "client-containers-52326076-36f3-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019172241s
Feb 22 22:43:53.610: INFO: Pod "client-containers-52326076-36f3-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025084882s
STEP: Saw pod success
Feb 22 22:43:53.610: INFO: Pod "client-containers-52326076-36f3-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:43:53.616: INFO: Trying to get logs from node conformance112-3 pod client-containers-52326076-36f3-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:43:53.690: INFO: Waiting for pod client-containers-52326076-36f3-11e9-9d47-0276c9498759 to disappear
Feb 22 22:43:53.697: INFO: Pod client-containers-52326076-36f3-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:43:53.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-5x5q9" for this suite.
Feb 22 22:43:59.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:43:59.800: INFO: namespace: e2e-tests-containers-5x5q9, resource: bindings, ignored listing per whitelist
Feb 22 22:43:59.937: INFO: namespace e2e-tests-containers-5x5q9 deletion completed in 6.230192932s

• [SLOW TEST:10.530 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:43:59.938: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 22 22:44:04.644: INFO: Successfully updated pod "annotationupdate58741581-36f3-11e9-9d47-0276c9498759"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:44:06.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h482h" for this suite.
Feb 22 22:44:36.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:44:36.919: INFO: namespace: e2e-tests-projected-h482h, resource: bindings, ignored listing per whitelist
Feb 22 22:44:36.992: INFO: namespace e2e-tests-projected-h482h deletion completed in 30.283294203s

• [SLOW TEST:37.054 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:44:36.995: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Feb 22 22:44:37.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 create -f - --namespace=e2e-tests-kubectl-wrl7v'
Feb 22 22:44:37.514: INFO: stderr: ""
Feb 22 22:44:37.514: INFO: stdout: "pod/pause created\n"
Feb 22 22:44:37.514: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 22 22:44:37.514: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-wrl7v" to be "running and ready"
Feb 22 22:44:37.527: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.40715ms
Feb 22 22:44:39.533: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.019564773s
Feb 22 22:44:39.533: INFO: Pod "pause" satisfied condition "running and ready"
Feb 22 22:44:39.533: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 22 22:44:39.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-wrl7v'
Feb 22 22:44:39.680: INFO: stderr: ""
Feb 22 22:44:39.680: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 22 22:44:39.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pod pause -L testing-label --namespace=e2e-tests-kubectl-wrl7v'
Feb 22 22:44:39.811: INFO: stderr: ""
Feb 22 22:44:39.811: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 22 22:44:39.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 label pods pause testing-label- --namespace=e2e-tests-kubectl-wrl7v'
Feb 22 22:44:39.965: INFO: stderr: ""
Feb 22 22:44:39.965: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 22 22:44:39.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pod pause -L testing-label --namespace=e2e-tests-kubectl-wrl7v'
Feb 22 22:44:40.077: INFO: stderr: ""
Feb 22 22:44:40.077: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Feb 22 22:44:40.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wrl7v'
Feb 22 22:44:40.204: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 22:44:40.204: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 22 22:44:40.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-wrl7v'
Feb 22 22:44:40.343: INFO: stderr: "No resources found.\n"
Feb 22 22:44:40.343: INFO: stdout: ""
Feb 22 22:44:40.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 get pods -l name=pause --namespace=e2e-tests-kubectl-wrl7v -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 22:44:40.496: INFO: stderr: ""
Feb 22 22:44:40.497: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:44:40.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wrl7v" for this suite.
Feb 22 22:44:48.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:44:48.656: INFO: namespace: e2e-tests-kubectl-wrl7v, resource: bindings, ignored listing per whitelist
Feb 22 22:44:48.807: INFO: namespace e2e-tests-kubectl-wrl7v deletion completed in 8.302910455s

• [SLOW TEST:11.813 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:44:48.810: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-75964a14-36f3-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 22:44:48.974: INFO: Waiting up to 5m0s for pod "pod-configmaps-7597b595-36f3-11e9-9d47-0276c9498759" in namespace "e2e-tests-configmap-sl6ps" to be "success or failure"
Feb 22 22:44:49.011: INFO: Pod "pod-configmaps-7597b595-36f3-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 37.001436ms
Feb 22 22:44:51.037: INFO: Pod "pod-configmaps-7597b595-36f3-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062794933s
Feb 22 22:44:53.069: INFO: Pod "pod-configmaps-7597b595-36f3-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.094473131s
STEP: Saw pod success
Feb 22 22:44:53.069: INFO: Pod "pod-configmaps-7597b595-36f3-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:44:53.085: INFO: Trying to get logs from node conformance112-2 pod pod-configmaps-7597b595-36f3-11e9-9d47-0276c9498759 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:44:53.320: INFO: Waiting for pod pod-configmaps-7597b595-36f3-11e9-9d47-0276c9498759 to disappear
Feb 22 22:44:53.371: INFO: Pod pod-configmaps-7597b595-36f3-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:44:53.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sl6ps" for this suite.
Feb 22 22:44:59.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:44:59.485: INFO: namespace: e2e-tests-configmap-sl6ps, resource: bindings, ignored listing per whitelist
Feb 22 22:44:59.727: INFO: namespace e2e-tests-configmap-sl6ps deletion completed in 6.334466078s

• [SLOW TEST:10.918 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:44:59.732: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 22 22:44:59.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-f84cf'
Feb 22 22:45:00.031: INFO: stderr: ""
Feb 22 22:45:00.031: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Feb 22 22:45:00.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-109334344 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-f84cf'
Feb 22 22:45:02.561: INFO: stderr: ""
Feb 22 22:45:02.561: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:45:02.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f84cf" for this suite.
Feb 22 22:45:08.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:45:08.866: INFO: namespace: e2e-tests-kubectl-f84cf, resource: bindings, ignored listing per whitelist
Feb 22 22:45:08.957: INFO: namespace e2e-tests-kubectl-f84cf deletion completed in 6.37252668s

• [SLOW TEST:9.226 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:45:08.959: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 22 22:45:09.265: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fq6ql,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq6ql/configmaps/e2e-watch-test-label-changed,UID:81a6910f-36f3-11e9-b930-96c406f7d171,ResourceVersion:23510,Generation:0,CreationTimestamp:2019-02-22 22:45:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 22 22:45:09.265: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fq6ql,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq6ql/configmaps/e2e-watch-test-label-changed,UID:81a6910f-36f3-11e9-b930-96c406f7d171,ResourceVersion:23512,Generation:0,CreationTimestamp:2019-02-22 22:45:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 22 22:45:09.266: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fq6ql,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq6ql/configmaps/e2e-watch-test-label-changed,UID:81a6910f-36f3-11e9-b930-96c406f7d171,ResourceVersion:23513,Generation:0,CreationTimestamp:2019-02-22 22:45:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 22 22:45:19.387: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fq6ql,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq6ql/configmaps/e2e-watch-test-label-changed,UID:81a6910f-36f3-11e9-b930-96c406f7d171,ResourceVersion:23536,Generation:0,CreationTimestamp:2019-02-22 22:45:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 22 22:45:19.388: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fq6ql,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq6ql/configmaps/e2e-watch-test-label-changed,UID:81a6910f-36f3-11e9-b930-96c406f7d171,ResourceVersion:23537,Generation:0,CreationTimestamp:2019-02-22 22:45:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 22 22:45:19.388: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fq6ql,SelfLink:/api/v1/namespaces/e2e-tests-watch-fq6ql/configmaps/e2e-watch-test-label-changed,UID:81a6910f-36f3-11e9-b930-96c406f7d171,ResourceVersion:23538,Generation:0,CreationTimestamp:2019-02-22 22:45:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:45:19.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fq6ql" for this suite.
Feb 22 22:45:25.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:45:25.533: INFO: namespace: e2e-tests-watch-fq6ql, resource: bindings, ignored listing per whitelist
Feb 22 22:45:25.714: INFO: namespace e2e-tests-watch-fq6ql deletion completed in 6.314161023s

• [SLOW TEST:16.756 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:45:25.720: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-8b9c0e4a-36f3-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 22:45:25.924: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8b9e9f3f-36f3-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-plvkj" to be "success or failure"
Feb 22 22:45:26.001: INFO: Pod "pod-projected-configmaps-8b9e9f3f-36f3-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 77.402125ms
Feb 22 22:45:28.008: INFO: Pod "pod-projected-configmaps-8b9e9f3f-36f3-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08397241s
Feb 22 22:45:30.025: INFO: Pod "pod-projected-configmaps-8b9e9f3f-36f3-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.101198237s
STEP: Saw pod success
Feb 22 22:45:30.025: INFO: Pod "pod-projected-configmaps-8b9e9f3f-36f3-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:45:30.031: INFO: Trying to get logs from node conformance112-2 pod pod-projected-configmaps-8b9e9f3f-36f3-11e9-9d47-0276c9498759 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:45:30.141: INFO: Waiting for pod pod-projected-configmaps-8b9e9f3f-36f3-11e9-9d47-0276c9498759 to disappear
Feb 22 22:45:30.167: INFO: Pod pod-projected-configmaps-8b9e9f3f-36f3-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:45:30.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-plvkj" for this suite.
Feb 22 22:45:36.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:45:36.468: INFO: namespace: e2e-tests-projected-plvkj, resource: bindings, ignored listing per whitelist
Feb 22 22:45:36.633: INFO: namespace e2e-tests-projected-plvkj deletion completed in 6.446902205s

• [SLOW TEST:10.914 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:45:36.633: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 22 22:45:45.007: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbct2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 22:45:45.007: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 22:45:45.231: INFO: Exec stderr: ""
Feb 22 22:45:45.231: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbct2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 22:45:45.231: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 22:45:45.477: INFO: Exec stderr: ""
Feb 22 22:45:45.477: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbct2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 22:45:45.478: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 22:45:45.743: INFO: Exec stderr: ""
Feb 22 22:45:45.743: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbct2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 22:45:45.743: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 22:45:45.979: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 22 22:45:45.980: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbct2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 22:45:45.980: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 22:45:46.255: INFO: Exec stderr: ""
Feb 22 22:45:46.255: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbct2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 22:45:46.255: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 22:45:46.503: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 22 22:45:46.503: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbct2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 22:45:46.503: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 22:45:46.898: INFO: Exec stderr: ""
Feb 22 22:45:46.899: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbct2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 22:45:46.900: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 22:45:47.482: INFO: Exec stderr: ""
Feb 22 22:45:47.482: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbct2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 22:45:47.482: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 22:45:47.946: INFO: Exec stderr: ""
Feb 22 22:45:47.946: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbct2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 22:45:47.946: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
Feb 22 22:45:48.365: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:45:48.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-rbct2" for this suite.
Feb 22 22:46:34.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:46:34.677: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-rbct2, resource: bindings, ignored listing per whitelist
Feb 22 22:46:34.763: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-rbct2 deletion completed in 46.391323467s

• [SLOW TEST:58.131 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:46:34.775: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 22 22:46:35.058: INFO: Waiting up to 5m0s for pod "pod-b4d111b5-36f3-11e9-9d47-0276c9498759" in namespace "e2e-tests-emptydir-zbmd2" to be "success or failure"
Feb 22 22:46:35.079: INFO: Pod "pod-b4d111b5-36f3-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 20.542142ms
Feb 22 22:46:37.085: INFO: Pod "pod-b4d111b5-36f3-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026503332s
STEP: Saw pod success
Feb 22 22:46:37.085: INFO: Pod "pod-b4d111b5-36f3-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:46:37.090: INFO: Trying to get logs from node conformance112-3 pod pod-b4d111b5-36f3-11e9-9d47-0276c9498759 container test-container: <nil>
STEP: delete the pod
Feb 22 22:46:37.171: INFO: Waiting for pod pod-b4d111b5-36f3-11e9-9d47-0276c9498759 to disappear
Feb 22 22:46:37.178: INFO: Pod pod-b4d111b5-36f3-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:46:37.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zbmd2" for this suite.
Feb 22 22:46:43.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:46:43.339: INFO: namespace: e2e-tests-emptydir-zbmd2, resource: bindings, ignored listing per whitelist
Feb 22 22:46:43.559: INFO: namespace e2e-tests-emptydir-zbmd2 deletion completed in 6.365892519s

• [SLOW TEST:8.785 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb 22 22:46:43.561: INFO: >>> kubeConfig: /tmp/kubeconfig-109334344
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-ba01c95f-36f3-11e9-9d47-0276c9498759
STEP: Creating a pod to test consume configMaps
Feb 22 22:46:43.757: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ba03b312-36f3-11e9-9d47-0276c9498759" in namespace "e2e-tests-projected-nprqp" to be "success or failure"
Feb 22 22:46:43.808: INFO: Pod "pod-projected-configmaps-ba03b312-36f3-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 50.864841ms
Feb 22 22:46:45.820: INFO: Pod "pod-projected-configmaps-ba03b312-36f3-11e9-9d47-0276c9498759": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062137092s
Feb 22 22:46:47.826: INFO: Pod "pod-projected-configmaps-ba03b312-36f3-11e9-9d47-0276c9498759": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069078854s
STEP: Saw pod success
Feb 22 22:46:47.827: INFO: Pod "pod-projected-configmaps-ba03b312-36f3-11e9-9d47-0276c9498759" satisfied condition "success or failure"
Feb 22 22:46:47.832: INFO: Trying to get logs from node conformance112-2 pod pod-projected-configmaps-ba03b312-36f3-11e9-9d47-0276c9498759 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 22:46:47.893: INFO: Waiting for pod pod-projected-configmaps-ba03b312-36f3-11e9-9d47-0276c9498759 to disappear
Feb 22 22:46:47.926: INFO: Pod pod-projected-configmaps-ba03b312-36f3-11e9-9d47-0276c9498759 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb 22 22:46:47.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nprqp" for this suite.
Feb 22 22:46:53.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 22 22:46:54.231: INFO: namespace: e2e-tests-projected-nprqp, resource: bindings, ignored listing per whitelist
Feb 22 22:46:54.317: INFO: namespace e2e-tests-projected-nprqp deletion completed in 6.380767917s

• [SLOW TEST:10.757 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
Feb 22 22:46:54.319: INFO: Running AfterSuite actions on all node
Feb 22 22:46:54.319: INFO: Running AfterSuite actions on node 1
Feb 22 22:46:54.319: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 6689.199 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h51m31.148082048s
Test Suite Passed
