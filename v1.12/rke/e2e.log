Mar 22 23:55:52.579: INFO: Overriding default scale value of zero to 1
Mar 22 23:55:52.579: INFO: Overriding default milliseconds value of zero to 5000
I0322 23:55:53.020064      17 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-648197830
I0322 23:55:53.020236      17 e2e.go:304] Starting e2e run "06727a6a-4cfe-11e9-96f5-ea7d86f92d02" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1553298952 - Will randomize all specs
Will run 188 of 1814 specs

Mar 22 23:55:53.176: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 22 23:55:53.178: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 22 23:55:53.188: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 22 23:55:53.214: INFO: The status of Pod rke-ingress-controller-deploy-job-p2bnl is Succeeded, skipping waiting
Mar 22 23:55:53.214: INFO: The status of Pod rke-kube-dns-addon-deploy-job-ll858 is Succeeded, skipping waiting
Mar 22 23:55:53.214: INFO: The status of Pod rke-metrics-addon-deploy-job-lvhn9 is Succeeded, skipping waiting
Mar 22 23:55:53.214: INFO: The status of Pod rke-network-plugin-deploy-job-g47g4 is Succeeded, skipping waiting
Mar 22 23:55:53.214: INFO: 6 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 22 23:55:53.214: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Mar 22 23:55:53.214: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 22 23:55:53.227: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Mar 22 23:55:53.227: INFO: e2e test version: v1.12.1
Mar 22 23:55:53.229: INFO: kube-apiserver version: v1.12.6
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:55:53.229: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
Mar 22 23:55:53.296: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-06eb6ec3-4cfe-11e9-96f5-ea7d86f92d02
STEP: Creating secret with name s-test-opt-upd-06eb6f07-4cfe-11e9-96f5-ea7d86f92d02
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-06eb6ec3-4cfe-11e9-96f5-ea7d86f92d02
STEP: Updating secret s-test-opt-upd-06eb6f07-4cfe-11e9-96f5-ea7d86f92d02
STEP: Creating secret with name s-test-opt-create-06eb6f28-4cfe-11e9-96f5-ea7d86f92d02
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 22 23:56:01.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mvw56" for this suite.
Mar 22 23:56:23.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 22 23:56:23.473: INFO: namespace: e2e-tests-projected-mvw56, resource: bindings, ignored listing per whitelist
Mar 22 23:56:23.481: INFO: namespace e2e-tests-projected-mvw56 deletion completed in 22.085911969s

• [SLOW TEST:30.252 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:56:23.481: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 22 23:56:28.054: INFO: Successfully updated pod "pod-update-18f0b880-4cfe-11e9-96f5-ea7d86f92d02"
STEP: verifying the updated pod is in kubernetes
Mar 22 23:56:28.058: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 22 23:56:28.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-djbr7" for this suite.
Mar 22 23:56:50.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 22 23:56:50.104: INFO: namespace: e2e-tests-pods-djbr7, resource: bindings, ignored listing per whitelist
Mar 22 23:56:50.143: INFO: namespace e2e-tests-pods-djbr7 deletion completed in 22.082326981s

• [SLOW TEST:26.662 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:56:50.143: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-28d4e315-4cfe-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 22 23:56:50.202: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-28d54301-4cfe-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-22zds" to be "success or failure"
Mar 22 23:56:50.205: INFO: Pod "pod-projected-configmaps-28d54301-4cfe-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.700267ms
Mar 22 23:56:52.207: INFO: Pod "pod-projected-configmaps-28d54301-4cfe-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005490972s
STEP: Saw pod success
Mar 22 23:56:52.207: INFO: Pod "pod-projected-configmaps-28d54301-4cfe-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 22 23:56:52.209: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-28d54301-4cfe-11e9-96f5-ea7d86f92d02 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 22 23:56:52.227: INFO: Waiting for pod pod-projected-configmaps-28d54301-4cfe-11e9-96f5-ea7d86f92d02 to disappear
Mar 22 23:56:52.229: INFO: Pod pod-projected-configmaps-28d54301-4cfe-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 22 23:56:52.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-22zds" for this suite.
Mar 22 23:56:58.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 22 23:56:58.305: INFO: namespace: e2e-tests-projected-22zds, resource: bindings, ignored listing per whitelist
Mar 22 23:56:58.321: INFO: namespace e2e-tests-projected-22zds deletion completed in 6.089413372s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:56:58.321: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar 22 23:56:58.378: INFO: Waiting up to 5m0s for pod "pod-2db49fdd-4cfe-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-n8xnk" to be "success or failure"
Mar 22 23:56:58.381: INFO: Pod "pod-2db49fdd-4cfe-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.583897ms
Mar 22 23:57:00.384: INFO: Pod "pod-2db49fdd-4cfe-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00569739s
STEP: Saw pod success
Mar 22 23:57:00.384: INFO: Pod "pod-2db49fdd-4cfe-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 22 23:57:00.386: INFO: Trying to get logs from node node-2 pod pod-2db49fdd-4cfe-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 22 23:57:00.400: INFO: Waiting for pod pod-2db49fdd-4cfe-11e9-96f5-ea7d86f92d02 to disappear
Mar 22 23:57:00.403: INFO: Pod pod-2db49fdd-4cfe-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 22 23:57:00.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n8xnk" for this suite.
Mar 22 23:57:06.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 22 23:57:06.516: INFO: namespace: e2e-tests-emptydir-n8xnk, resource: bindings, ignored listing per whitelist
Mar 22 23:57:06.525: INFO: namespace e2e-tests-emptydir-n8xnk deletion completed in 6.119717183s

• [SLOW TEST:8.205 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:57:06.526: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 22 23:57:06.585: INFO: Waiting up to 5m0s for pod "downward-api-3299149d-4cfe-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-dqszc" to be "success or failure"
Mar 22 23:57:06.588: INFO: Pod "downward-api-3299149d-4cfe-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.816189ms
Mar 22 23:57:08.591: INFO: Pod "downward-api-3299149d-4cfe-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005765256s
Mar 22 23:57:10.595: INFO: Pod "downward-api-3299149d-4cfe-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009854255s
STEP: Saw pod success
Mar 22 23:57:10.595: INFO: Pod "downward-api-3299149d-4cfe-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 22 23:57:10.597: INFO: Trying to get logs from node node-2 pod downward-api-3299149d-4cfe-11e9-96f5-ea7d86f92d02 container dapi-container: <nil>
STEP: delete the pod
Mar 22 23:57:10.613: INFO: Waiting for pod downward-api-3299149d-4cfe-11e9-96f5-ea7d86f92d02 to disappear
Mar 22 23:57:10.615: INFO: Pod downward-api-3299149d-4cfe-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 22 23:57:10.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dqszc" for this suite.
Mar 22 23:57:16.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 22 23:57:16.671: INFO: namespace: e2e-tests-downward-api-dqszc, resource: bindings, ignored listing per whitelist
Mar 22 23:57:16.700: INFO: namespace e2e-tests-downward-api-dqszc deletion completed in 6.081293765s

• [SLOW TEST:10.174 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:57:16.700: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar 22 23:57:16.758: INFO: Waiting up to 5m0s for pod "client-containers-38a930d0-4cfe-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-containers-s8w9k" to be "success or failure"
Mar 22 23:57:16.762: INFO: Pod "client-containers-38a930d0-4cfe-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.247696ms
Mar 22 23:57:18.765: INFO: Pod "client-containers-38a930d0-4cfe-11e9-96f5-ea7d86f92d02": Phase="Running", Reason="", readiness=true. Elapsed: 2.007271542s
Mar 22 23:57:20.768: INFO: Pod "client-containers-38a930d0-4cfe-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010258814s
STEP: Saw pod success
Mar 22 23:57:20.768: INFO: Pod "client-containers-38a930d0-4cfe-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 22 23:57:20.770: INFO: Trying to get logs from node node-2 pod client-containers-38a930d0-4cfe-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 22 23:57:20.787: INFO: Waiting for pod client-containers-38a930d0-4cfe-11e9-96f5-ea7d86f92d02 to disappear
Mar 22 23:57:20.792: INFO: Pod client-containers-38a930d0-4cfe-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 22 23:57:20.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-s8w9k" for this suite.
Mar 22 23:57:26.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 22 23:57:26.862: INFO: namespace: e2e-tests-containers-s8w9k, resource: bindings, ignored listing per whitelist
Mar 22 23:57:26.884: INFO: namespace e2e-tests-containers-s8w9k deletion completed in 6.088060372s

• [SLOW TEST:10.184 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:57:26.884: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3ebb7850-4cfe-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 22 23:57:26.946: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3ebbe06a-4cfe-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-k4459" to be "success or failure"
Mar 22 23:57:26.949: INFO: Pod "pod-projected-configmaps-3ebbe06a-4cfe-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.879785ms
Mar 22 23:57:28.952: INFO: Pod "pod-projected-configmaps-3ebbe06a-4cfe-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005806064s
STEP: Saw pod success
Mar 22 23:57:28.952: INFO: Pod "pod-projected-configmaps-3ebbe06a-4cfe-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 22 23:57:28.954: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-3ebbe06a-4cfe-11e9-96f5-ea7d86f92d02 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 22 23:57:28.969: INFO: Waiting for pod pod-projected-configmaps-3ebbe06a-4cfe-11e9-96f5-ea7d86f92d02 to disappear
Mar 22 23:57:28.971: INFO: Pod pod-projected-configmaps-3ebbe06a-4cfe-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 22 23:57:28.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k4459" for this suite.
Mar 22 23:57:34.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 22 23:57:35.004: INFO: namespace: e2e-tests-projected-k4459, resource: bindings, ignored listing per whitelist
Mar 22 23:57:35.058: INFO: namespace e2e-tests-projected-k4459 deletion completed in 6.08379508s

• [SLOW TEST:8.174 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:57:35.058: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 22 23:57:35.133: INFO: Number of nodes with available pods: 0
Mar 22 23:57:35.133: INFO: Node node-1 is running more than one daemon pod
Mar 22 23:57:36.139: INFO: Number of nodes with available pods: 0
Mar 22 23:57:36.139: INFO: Node node-1 is running more than one daemon pod
Mar 22 23:57:37.144: INFO: Number of nodes with available pods: 1
Mar 22 23:57:37.144: INFO: Node node-1 is running more than one daemon pod
Mar 22 23:57:38.139: INFO: Number of nodes with available pods: 3
Mar 22 23:57:38.139: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar 22 23:57:38.157: INFO: Number of nodes with available pods: 2
Mar 22 23:57:38.157: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:39.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:39.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:40.164: INFO: Number of nodes with available pods: 2
Mar 22 23:57:40.164: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:41.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:41.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:42.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:42.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:43.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:43.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:44.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:44.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:45.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:45.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:46.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:46.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:47.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:47.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:48.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:48.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:49.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:49.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:50.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:50.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:51.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:51.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:52.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:52.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:53.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:53.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:54.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:54.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:55.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:55.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:56.167: INFO: Number of nodes with available pods: 2
Mar 22 23:57:56.168: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:57.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:57.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:58.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:58.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:57:59.163: INFO: Number of nodes with available pods: 2
Mar 22 23:57:59.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:00.163: INFO: Number of nodes with available pods: 2
Mar 22 23:58:00.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:01.164: INFO: Number of nodes with available pods: 2
Mar 22 23:58:01.164: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:02.164: INFO: Number of nodes with available pods: 2
Mar 22 23:58:02.164: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:03.163: INFO: Number of nodes with available pods: 2
Mar 22 23:58:03.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:04.163: INFO: Number of nodes with available pods: 2
Mar 22 23:58:04.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:05.163: INFO: Number of nodes with available pods: 2
Mar 22 23:58:05.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:06.164: INFO: Number of nodes with available pods: 2
Mar 22 23:58:06.164: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:07.164: INFO: Number of nodes with available pods: 2
Mar 22 23:58:07.164: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:08.163: INFO: Number of nodes with available pods: 2
Mar 22 23:58:08.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:09.163: INFO: Number of nodes with available pods: 2
Mar 22 23:58:09.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:10.163: INFO: Number of nodes with available pods: 2
Mar 22 23:58:10.163: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:11.165: INFO: Number of nodes with available pods: 2
Mar 22 23:58:11.165: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:12.164: INFO: Number of nodes with available pods: 2
Mar 22 23:58:12.164: INFO: Node node-3 is running more than one daemon pod
Mar 22 23:58:13.163: INFO: Number of nodes with available pods: 3
Mar 22 23:58:13.163: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-4s5xv, will wait for the garbage collector to delete the pods
Mar 22 23:58:13.223: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.46925ms
Mar 22 23:58:13.324: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.213528ms
Mar 22 23:58:57.227: INFO: Number of nodes with available pods: 0
Mar 22 23:58:57.227: INFO: Number of running nodes: 0, number of available pods: 0
Mar 22 23:58:57.230: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4s5xv/daemonsets","resourceVersion":"1569"},"items":null}

Mar 22 23:58:57.232: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4s5xv/pods","resourceVersion":"1569"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 22 23:58:57.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4s5xv" for this suite.
Mar 22 23:59:03.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 22 23:59:03.296: INFO: namespace: e2e-tests-daemonsets-4s5xv, resource: bindings, ignored listing per whitelist
Mar 22 23:59:03.334: INFO: namespace e2e-tests-daemonsets-4s5xv deletion completed in 6.090246236s

• [SLOW TEST:88.277 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:59:03.335: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 22 23:59:03.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-vzbqc'
Mar 22 23:59:03.670: INFO: stderr: ""
Mar 22 23:59:03.670: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Mar 22 23:59:03.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-vzbqc'
Mar 22 23:59:07.150: INFO: stderr: ""
Mar 22 23:59:07.150: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 22 23:59:07.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vzbqc" for this suite.
Mar 22 23:59:13.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 22 23:59:13.186: INFO: namespace: e2e-tests-kubectl-vzbqc, resource: bindings, ignored listing per whitelist
Mar 22 23:59:13.244: INFO: namespace e2e-tests-kubectl-vzbqc deletion completed in 6.088713651s

• [SLOW TEST:9.909 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:59:13.244: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-d95lr.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-d95lr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-d95lr.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-d95lr.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-d95lr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-d95lr.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 22 23:59:35.368: INFO: DNS probes using e2e-tests-dns-d95lr/dns-test-7e20379a-4cfe-11e9-96f5-ea7d86f92d02 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 22 23:59:35.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-d95lr" for this suite.
Mar 22 23:59:41.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 22 23:59:41.411: INFO: namespace: e2e-tests-dns-d95lr, resource: bindings, ignored listing per whitelist
Mar 22 23:59:41.466: INFO: namespace e2e-tests-dns-d95lr deletion completed in 6.085060924s

• [SLOW TEST:28.222 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:59:41.466: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-8ef32389-4cfe-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 22 23:59:41.528: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8ef37cea-4cfe-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-d9474" to be "success or failure"
Mar 22 23:59:41.531: INFO: Pod "pod-projected-configmaps-8ef37cea-4cfe-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.314739ms
Mar 22 23:59:43.534: INFO: Pod "pod-projected-configmaps-8ef37cea-4cfe-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006308079s
STEP: Saw pod success
Mar 22 23:59:43.534: INFO: Pod "pod-projected-configmaps-8ef37cea-4cfe-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 22 23:59:43.536: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-8ef37cea-4cfe-11e9-96f5-ea7d86f92d02 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 22 23:59:43.551: INFO: Waiting for pod pod-projected-configmaps-8ef37cea-4cfe-11e9-96f5-ea7d86f92d02 to disappear
Mar 22 23:59:43.554: INFO: Pod pod-projected-configmaps-8ef37cea-4cfe-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 22 23:59:43.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d9474" for this suite.
Mar 22 23:59:49.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 22 23:59:49.582: INFO: namespace: e2e-tests-projected-d9474, resource: bindings, ignored listing per whitelist
Mar 22 23:59:49.646: INFO: namespace e2e-tests-projected-d9474 deletion completed in 6.089574326s

• [SLOW TEST:8.180 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 22 23:59:49.647: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 22 23:59:57.725: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 22 23:59:57.728: INFO: Pod pod-with-prestop-http-hook still exists
Mar 22 23:59:59.728: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 22 23:59:59.733: INFO: Pod pod-with-prestop-http-hook still exists
Mar 23 00:00:01.728: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 23 00:00:01.732: INFO: Pod pod-with-prestop-http-hook still exists
Mar 23 00:00:03.728: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 23 00:00:03.731: INFO: Pod pod-with-prestop-http-hook still exists
Mar 23 00:00:05.728: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 23 00:00:05.731: INFO: Pod pod-with-prestop-http-hook still exists
Mar 23 00:00:07.728: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 23 00:00:07.731: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:00:07.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-p9jt5" for this suite.
Mar 23 00:00:29.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:00:29.795: INFO: namespace: e2e-tests-container-lifecycle-hook-p9jt5, resource: bindings, ignored listing per whitelist
Mar 23 00:00:29.827: INFO: namespace e2e-tests-container-lifecycle-hook-p9jt5 deletion completed in 22.085176712s

• [SLOW TEST:40.181 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:00:29.827: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 23 00:00:35.909: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 23 00:00:35.913: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 23 00:00:37.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 23 00:00:37.916: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 23 00:00:39.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 23 00:00:39.917: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 23 00:00:41.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 23 00:00:41.917: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 23 00:00:43.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 23 00:00:43.917: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 23 00:00:45.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 23 00:00:45.916: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 23 00:00:47.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 23 00:00:47.916: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 23 00:00:49.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 23 00:00:49.916: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 23 00:00:51.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 23 00:00:51.916: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 23 00:00:53.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 23 00:00:53.916: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:00:53.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-spln5" for this suite.
Mar 23 00:01:15.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:01:15.958: INFO: namespace: e2e-tests-container-lifecycle-hook-spln5, resource: bindings, ignored listing per whitelist
Mar 23 00:01:16.009: INFO: namespace e2e-tests-container-lifecycle-hook-spln5 deletion completed in 22.082248372s

• [SLOW TEST:46.182 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:01:16.009: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0323 00:01:46.588401      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 23 00:01:46.588: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:01:46.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fc29s" for this suite.
Mar 23 00:01:52.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:01:52.625: INFO: namespace: e2e-tests-gc-fc29s, resource: bindings, ignored listing per whitelist
Mar 23 00:01:52.677: INFO: namespace e2e-tests-gc-fc29s deletion completed in 6.086030153s

• [SLOW TEST:36.668 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:01:52.677: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 00:01:52.732: INFO: Creating ReplicaSet my-hostname-basic-dd28600b-4cfe-11e9-96f5-ea7d86f92d02
Mar 23 00:01:52.738: INFO: Pod name my-hostname-basic-dd28600b-4cfe-11e9-96f5-ea7d86f92d02: Found 0 pods out of 1
Mar 23 00:01:57.741: INFO: Pod name my-hostname-basic-dd28600b-4cfe-11e9-96f5-ea7d86f92d02: Found 1 pods out of 1
Mar 23 00:01:57.741: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-dd28600b-4cfe-11e9-96f5-ea7d86f92d02" is running
Mar 23 00:01:57.743: INFO: Pod "my-hostname-basic-dd28600b-4cfe-11e9-96f5-ea7d86f92d02-2vt5n" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-23 00:01:52 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-23 00:01:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-23 00:01:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-23 00:01:52 +0000 UTC Reason: Message:}])
Mar 23 00:01:57.743: INFO: Trying to dial the pod
Mar 23 00:02:02.752: INFO: Controller my-hostname-basic-dd28600b-4cfe-11e9-96f5-ea7d86f92d02: Got expected result from replica 1 [my-hostname-basic-dd28600b-4cfe-11e9-96f5-ea7d86f92d02-2vt5n]: "my-hostname-basic-dd28600b-4cfe-11e9-96f5-ea7d86f92d02-2vt5n", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:02:02.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-mzbz9" for this suite.
Mar 23 00:02:08.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:02:08.825: INFO: namespace: e2e-tests-replicaset-mzbz9, resource: bindings, ignored listing per whitelist
Mar 23 00:02:08.840: INFO: namespace e2e-tests-replicaset-mzbz9 deletion completed in 6.084706227s

• [SLOW TEST:16.162 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:02:08.840: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 23 00:02:08.901: INFO: Waiting up to 5m0s for pod "pod-e6cab1e9-4cfe-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-7jnbh" to be "success or failure"
Mar 23 00:02:08.905: INFO: Pod "pod-e6cab1e9-4cfe-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.744589ms
Mar 23 00:02:10.907: INFO: Pod "pod-e6cab1e9-4cfe-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006536285s
Mar 23 00:02:12.910: INFO: Pod "pod-e6cab1e9-4cfe-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009334849s
STEP: Saw pod success
Mar 23 00:02:12.910: INFO: Pod "pod-e6cab1e9-4cfe-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:02:12.912: INFO: Trying to get logs from node node-2 pod pod-e6cab1e9-4cfe-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 00:02:12.928: INFO: Waiting for pod pod-e6cab1e9-4cfe-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:02:12.930: INFO: Pod pod-e6cab1e9-4cfe-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:02:12.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7jnbh" for this suite.
Mar 23 00:02:18.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:02:18.972: INFO: namespace: e2e-tests-emptydir-7jnbh, resource: bindings, ignored listing per whitelist
Mar 23 00:02:19.017: INFO: namespace e2e-tests-emptydir-7jnbh deletion completed in 6.084821493s

• [SLOW TEST:10.177 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:02:19.017: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-ecdc34c2-4cfe-11e9-96f5-ea7d86f92d02
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:02:25.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rvr9h" for this suite.
Mar 23 00:02:47.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:02:47.149: INFO: namespace: e2e-tests-configmap-rvr9h, resource: bindings, ignored listing per whitelist
Mar 23 00:02:47.199: INFO: namespace e2e-tests-configmap-rvr9h deletion completed in 22.081451402s

• [SLOW TEST:28.182 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:02:47.199: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lh7pf
Mar 23 00:02:51.259: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lh7pf
STEP: checking the pod's current state and verifying that restartCount is present
Mar 23 00:02:51.261: INFO: Initial restart count of pod liveness-http is 0
Mar 23 00:03:15.297: INFO: Restart count of pod e2e-tests-container-probe-lh7pf/liveness-http is now 1 (24.03599678s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:03:15.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lh7pf" for this suite.
Mar 23 00:03:21.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:03:21.353: INFO: namespace: e2e-tests-container-probe-lh7pf, resource: bindings, ignored listing per whitelist
Mar 23 00:03:21.395: INFO: namespace e2e-tests-container-probe-lh7pf deletion completed in 6.082406788s

• [SLOW TEST:34.196 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:03:21.395: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 23 00:03:21.453: INFO: Waiting up to 5m0s for pod "pod-1209270f-4cff-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-5xtdt" to be "success or failure"
Mar 23 00:03:21.457: INFO: Pod "pod-1209270f-4cff-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.770328ms
Mar 23 00:03:23.460: INFO: Pod "pod-1209270f-4cff-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006610699s
STEP: Saw pod success
Mar 23 00:03:23.460: INFO: Pod "pod-1209270f-4cff-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:03:23.462: INFO: Trying to get logs from node node-2 pod pod-1209270f-4cff-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 00:03:23.476: INFO: Waiting for pod pod-1209270f-4cff-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:03:23.478: INFO: Pod pod-1209270f-4cff-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:03:23.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5xtdt" for this suite.
Mar 23 00:03:29.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:03:29.533: INFO: namespace: e2e-tests-emptydir-5xtdt, resource: bindings, ignored listing per whitelist
Mar 23 00:03:29.574: INFO: namespace e2e-tests-emptydir-5xtdt deletion completed in 6.09235085s

• [SLOW TEST:8.179 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:03:29.574: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-bscqf/configmap-test-16e9611a-4cff-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 00:03:29.635: INFO: Waiting up to 5m0s for pod "pod-configmaps-16e9cfd6-4cff-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-configmap-bscqf" to be "success or failure"
Mar 23 00:03:29.637: INFO: Pod "pod-configmaps-16e9cfd6-4cff-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.50393ms
Mar 23 00:03:31.640: INFO: Pod "pod-configmaps-16e9cfd6-4cff-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005085508s
STEP: Saw pod success
Mar 23 00:03:31.640: INFO: Pod "pod-configmaps-16e9cfd6-4cff-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:03:31.642: INFO: Trying to get logs from node node-2 pod pod-configmaps-16e9cfd6-4cff-11e9-96f5-ea7d86f92d02 container env-test: <nil>
STEP: delete the pod
Mar 23 00:03:31.655: INFO: Waiting for pod pod-configmaps-16e9cfd6-4cff-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:03:31.657: INFO: Pod pod-configmaps-16e9cfd6-4cff-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:03:31.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bscqf" for this suite.
Mar 23 00:03:37.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:03:37.697: INFO: namespace: e2e-tests-configmap-bscqf, resource: bindings, ignored listing per whitelist
Mar 23 00:03:37.750: INFO: namespace e2e-tests-configmap-bscqf deletion completed in 6.089571682s

• [SLOW TEST:8.176 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:03:37.750: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bx6fd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 23 00:03:37.805: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 23 00:03:57.874: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.8:8080/dial?request=hostName&protocol=udp&host=10.42.1.7&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-bx6fd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:03:57.874: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:03:57.938: INFO: Waiting for endpoints: map[]
Mar 23 00:03:57.941: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.8:8080/dial?request=hostName&protocol=udp&host=10.42.0.7&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-bx6fd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:03:57.941: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:03:58.004: INFO: Waiting for endpoints: map[]
Mar 23 00:03:58.007: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.8:8080/dial?request=hostName&protocol=udp&host=10.42.2.23&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-bx6fd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:03:58.007: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:03:58.108: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:03:58.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bx6fd" for this suite.
Mar 23 00:04:20.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:04:20.147: INFO: namespace: e2e-tests-pod-network-test-bx6fd, resource: bindings, ignored listing per whitelist
Mar 23 00:04:20.195: INFO: namespace e2e-tests-pod-network-test-bx6fd deletion completed in 22.082620632s

• [SLOW TEST:42.444 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:04:20.195: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 23 00:04:20.253: INFO: Waiting up to 5m0s for pod "pod-35155b51-4cff-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-rnddz" to be "success or failure"
Mar 23 00:04:20.257: INFO: Pod "pod-35155b51-4cff-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.950481ms
Mar 23 00:04:22.260: INFO: Pod "pod-35155b51-4cff-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007124133s
STEP: Saw pod success
Mar 23 00:04:22.260: INFO: Pod "pod-35155b51-4cff-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:04:22.262: INFO: Trying to get logs from node node-2 pod pod-35155b51-4cff-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 00:04:22.278: INFO: Waiting for pod pod-35155b51-4cff-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:04:22.280: INFO: Pod pod-35155b51-4cff-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:04:22.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rnddz" for this suite.
Mar 23 00:04:28.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:04:28.359: INFO: namespace: e2e-tests-emptydir-rnddz, resource: bindings, ignored listing per whitelist
Mar 23 00:04:28.364: INFO: namespace e2e-tests-emptydir-rnddz deletion completed in 6.080682607s

• [SLOW TEST:8.169 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:04:28.364: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0323 00:04:34.485764      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 23 00:04:34.485: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:04:34.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rr5z4" for this suite.
Mar 23 00:04:40.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:04:40.556: INFO: namespace: e2e-tests-gc-rr5z4, resource: bindings, ignored listing per whitelist
Mar 23 00:04:40.568: INFO: namespace e2e-tests-gc-rr5z4 deletion completed in 6.079572726s

• [SLOW TEST:12.204 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:04:40.568: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 23 00:04:44.654: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-srb8j PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:04:44.654: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:04:44.721: INFO: Exec stderr: ""
Mar 23 00:04:44.721: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-srb8j PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:04:44.721: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:04:44.786: INFO: Exec stderr: ""
Mar 23 00:04:44.786: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-srb8j PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:04:44.786: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:04:44.855: INFO: Exec stderr: ""
Mar 23 00:04:44.855: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-srb8j PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:04:44.855: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:04:44.927: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 23 00:04:44.927: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-srb8j PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:04:44.927: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:04:44.991: INFO: Exec stderr: ""
Mar 23 00:04:44.991: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-srb8j PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:04:44.991: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:04:45.056: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 23 00:04:45.056: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-srb8j PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:04:45.056: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:04:45.120: INFO: Exec stderr: ""
Mar 23 00:04:45.120: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-srb8j PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:04:45.120: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:04:45.185: INFO: Exec stderr: ""
Mar 23 00:04:45.185: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-srb8j PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:04:45.185: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:04:45.249: INFO: Exec stderr: ""
Mar 23 00:04:45.249: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-srb8j PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:04:45.249: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:04:45.314: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:04:45.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-srb8j" for this suite.
Mar 23 00:05:29.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:05:29.370: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-srb8j, resource: bindings, ignored listing per whitelist
Mar 23 00:05:29.405: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-srb8j deletion completed in 44.087973588s

• [SLOW TEST:48.837 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:05:29.405: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:05:29.470: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5e566855-4cff-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-5zmrt" to be "success or failure"
Mar 23 00:05:29.473: INFO: Pod "downwardapi-volume-5e566855-4cff-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.902214ms
Mar 23 00:05:31.476: INFO: Pod "downwardapi-volume-5e566855-4cff-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005971151s
STEP: Saw pod success
Mar 23 00:05:31.476: INFO: Pod "downwardapi-volume-5e566855-4cff-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:05:31.478: INFO: Trying to get logs from node node-2 pod downwardapi-volume-5e566855-4cff-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:05:31.496: INFO: Waiting for pod downwardapi-volume-5e566855-4cff-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:05:31.499: INFO: Pod downwardapi-volume-5e566855-4cff-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:05:31.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5zmrt" for this suite.
Mar 23 00:05:37.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:05:37.582: INFO: namespace: e2e-tests-downward-api-5zmrt, resource: bindings, ignored listing per whitelist
Mar 23 00:05:37.588: INFO: namespace e2e-tests-downward-api-5zmrt deletion completed in 6.085442217s

• [SLOW TEST:8.182 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:05:37.588: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 23 00:05:41.682: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:05:41.684: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:05:43.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:05:43.687: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:05:45.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:05:45.687: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:05:47.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:05:47.687: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:05:49.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:05:49.687: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:05:51.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:05:51.687: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:05:53.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:05:53.687: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:05:55.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:05:55.687: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:05:57.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:05:57.687: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:05:59.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:05:59.687: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:06:01.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:06:01.692: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:06:03.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:06:03.687: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:06:05.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:06:05.687: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 23 00:06:07.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 23 00:06:07.687: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:06:07.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gdcb5" for this suite.
Mar 23 00:06:29.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:06:29.854: INFO: namespace: e2e-tests-container-lifecycle-hook-gdcb5, resource: bindings, ignored listing per whitelist
Mar 23 00:06:30.141: INFO: namespace e2e-tests-container-lifecycle-hook-gdcb5 deletion completed in 22.450357827s

• [SLOW TEST:52.553 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:06:30.141: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar 23 00:06:30.505: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-648197830 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:06:30.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sw22p" for this suite.
Mar 23 00:06:36.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:06:36.662: INFO: namespace: e2e-tests-kubectl-sw22p, resource: bindings, ignored listing per whitelist
Mar 23 00:06:36.686: INFO: namespace e2e-tests-kubectl-sw22p deletion completed in 6.098293867s

• [SLOW TEST:6.545 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:06:36.686: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 23 00:06:36.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-2hqpv'
Mar 23 00:06:36.821: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 23 00:06:36.821: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Mar 23 00:06:40.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-2hqpv'
Mar 23 00:06:40.920: INFO: stderr: ""
Mar 23 00:06:40.920: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:06:40.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2hqpv" for this suite.
Mar 23 00:07:02.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:07:02.994: INFO: namespace: e2e-tests-kubectl-2hqpv, resource: bindings, ignored listing per whitelist
Mar 23 00:07:03.018: INFO: namespace e2e-tests-kubectl-2hqpv deletion completed in 22.093603097s

• [SLOW TEST:26.332 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:07:03.018: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Mar 23 00:07:03.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-4k29z'
Mar 23 00:07:03.314: INFO: stderr: ""
Mar 23 00:07:03.314: INFO: stdout: "pod/pause created\n"
Mar 23 00:07:03.314: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 23 00:07:03.314: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-4k29z" to be "running and ready"
Mar 23 00:07:03.318: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.992077ms
Mar 23 00:07:05.321: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.006994896s
Mar 23 00:07:05.321: INFO: Pod "pause" satisfied condition "running and ready"
Mar 23 00:07:05.321: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar 23 00:07:05.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-4k29z'
Mar 23 00:07:05.420: INFO: stderr: ""
Mar 23 00:07:05.420: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar 23 00:07:05.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pod pause -L testing-label --namespace=e2e-tests-kubectl-4k29z'
Mar 23 00:07:05.505: INFO: stderr: ""
Mar 23 00:07:05.505: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar 23 00:07:05.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 label pods pause testing-label- --namespace=e2e-tests-kubectl-4k29z'
Mar 23 00:07:05.593: INFO: stderr: ""
Mar 23 00:07:05.593: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar 23 00:07:05.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pod pause -L testing-label --namespace=e2e-tests-kubectl-4k29z'
Mar 23 00:07:05.674: INFO: stderr: ""
Mar 23 00:07:05.674: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Mar 23 00:07:05.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4k29z'
Mar 23 00:07:05.763: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 23 00:07:05.763: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 23 00:07:05.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-4k29z'
Mar 23 00:07:05.848: INFO: stderr: "No resources found.\n"
Mar 23 00:07:05.848: INFO: stdout: ""
Mar 23 00:07:05.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -l name=pause --namespace=e2e-tests-kubectl-4k29z -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 23 00:07:05.928: INFO: stderr: ""
Mar 23 00:07:05.928: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:07:05.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4k29z" for this suite.
Mar 23 00:07:11.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:07:11.965: INFO: namespace: e2e-tests-kubectl-4k29z, resource: bindings, ignored listing per whitelist
Mar 23 00:07:12.018: INFO: namespace e2e-tests-kubectl-4k29z deletion completed in 6.086283091s

• [SLOW TEST:8.999 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:07:12.018: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8d7l2
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar 23 00:07:12.085: INFO: Found 0 stateful pods, waiting for 3
Mar 23 00:07:22.090: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 23 00:07:22.090: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 23 00:07:22.090: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 23 00:07:22.113: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar 23 00:07:32.140: INFO: Updating stateful set ss2
Mar 23 00:07:32.146: INFO: Waiting for Pod e2e-tests-statefulset-8d7l2/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar 23 00:07:42.189: INFO: Found 1 stateful pods, waiting for 3
Mar 23 00:07:52.201: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 23 00:07:52.201: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 23 00:07:52.201: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar 23 00:07:52.227: INFO: Updating stateful set ss2
Mar 23 00:07:52.235: INFO: Waiting for Pod e2e-tests-statefulset-8d7l2/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 23 00:08:02.257: INFO: Updating stateful set ss2
Mar 23 00:08:02.264: INFO: Waiting for StatefulSet e2e-tests-statefulset-8d7l2/ss2 to complete update
Mar 23 00:08:02.264: INFO: Waiting for Pod e2e-tests-statefulset-8d7l2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 23 00:08:12.269: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8d7l2
Mar 23 00:08:12.271: INFO: Scaling statefulset ss2 to 0
Mar 23 00:08:22.282: INFO: Waiting for statefulset status.replicas updated to 0
Mar 23 00:08:22.285: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:08:22.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8d7l2" for this suite.
Mar 23 00:08:28.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:08:28.326: INFO: namespace: e2e-tests-statefulset-8d7l2, resource: bindings, ignored listing per whitelist
Mar 23 00:08:28.389: INFO: namespace e2e-tests-statefulset-8d7l2 deletion completed in 6.087763022s

• [SLOW TEST:76.371 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:08:28.389: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:08:28.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mgslt" for this suite.
Mar 23 00:08:50.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:08:50.474: INFO: namespace: e2e-tests-pods-mgslt, resource: bindings, ignored listing per whitelist
Mar 23 00:08:50.535: INFO: namespace e2e-tests-pods-mgslt deletion completed in 22.080814943s

• [SLOW TEST:22.146 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:08:50.535: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 23 00:08:50.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-mv86z'
Mar 23 00:08:50.671: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 23 00:08:50.671: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Mar 23 00:08:50.677: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Mar 23 00:08:50.683: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar 23 00:08:50.687: INFO: scanned /root for discovery docs: <nil>
Mar 23 00:08:50.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-mv86z'
Mar 23 00:09:06.436: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 23 00:09:06.436: INFO: stdout: "Created e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef\nScaling up e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar 23 00:09:06.436: INFO: stdout: "Created e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef\nScaling up e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar 23 00:09:06.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-mv86z'
Mar 23 00:09:06.691: INFO: stderr: ""
Mar 23 00:09:06.691: INFO: stdout: "e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef-f85wj "
Mar 23 00:09:06.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef-f85wj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mv86z'
Mar 23 00:09:06.770: INFO: stderr: ""
Mar 23 00:09:06.770: INFO: stdout: "true"
Mar 23 00:09:06.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef-f85wj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mv86z'
Mar 23 00:09:06.851: INFO: stderr: ""
Mar 23 00:09:06.851: INFO: stdout: "nginx:1.14-alpine"
Mar 23 00:09:06.851: INFO: e2e-test-nginx-rc-33940cac16d8f64b68aa359ab913f5ef-f85wj is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Mar 23 00:09:06.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-mv86z'
Mar 23 00:09:06.939: INFO: stderr: ""
Mar 23 00:09:06.939: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:09:06.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mv86z" for this suite.
Mar 23 00:09:12.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:09:12.987: INFO: namespace: e2e-tests-kubectl-mv86z, resource: bindings, ignored listing per whitelist
Mar 23 00:09:13.031: INFO: namespace e2e-tests-kubectl-mv86z deletion completed in 6.086895473s

• [SLOW TEST:22.495 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:09:13.031: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-dzlgd/secret-test-e3a08c7c-4cff-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 00:09:13.090: INFO: Waiting up to 5m0s for pod "pod-configmaps-e3a10219-4cff-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-secrets-dzlgd" to be "success or failure"
Mar 23 00:09:13.093: INFO: Pod "pod-configmaps-e3a10219-4cff-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.604651ms
Mar 23 00:09:15.096: INFO: Pod "pod-configmaps-e3a10219-4cff-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006339436s
STEP: Saw pod success
Mar 23 00:09:15.096: INFO: Pod "pod-configmaps-e3a10219-4cff-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:09:15.098: INFO: Trying to get logs from node node-2 pod pod-configmaps-e3a10219-4cff-11e9-96f5-ea7d86f92d02 container env-test: <nil>
STEP: delete the pod
Mar 23 00:09:15.116: INFO: Waiting for pod pod-configmaps-e3a10219-4cff-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:09:15.117: INFO: Pod pod-configmaps-e3a10219-4cff-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:09:15.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dzlgd" for this suite.
Mar 23 00:09:21.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:09:21.203: INFO: namespace: e2e-tests-secrets-dzlgd, resource: bindings, ignored listing per whitelist
Mar 23 00:09:21.204: INFO: namespace e2e-tests-secrets-dzlgd deletion completed in 6.083917724s

• [SLOW TEST:8.173 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:09:21.205: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-e8801ed1-4cff-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 00:09:21.267: INFO: Waiting up to 5m0s for pod "pod-configmaps-e88088b8-4cff-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-configmap-j4d6p" to be "success or failure"
Mar 23 00:09:21.270: INFO: Pod "pod-configmaps-e88088b8-4cff-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.994832ms
Mar 23 00:09:23.273: INFO: Pod "pod-configmaps-e88088b8-4cff-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005870454s
STEP: Saw pod success
Mar 23 00:09:23.273: INFO: Pod "pod-configmaps-e88088b8-4cff-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:09:23.275: INFO: Trying to get logs from node node-2 pod pod-configmaps-e88088b8-4cff-11e9-96f5-ea7d86f92d02 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 23 00:09:23.288: INFO: Waiting for pod pod-configmaps-e88088b8-4cff-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:09:23.290: INFO: Pod pod-configmaps-e88088b8-4cff-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:09:23.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-j4d6p" for this suite.
Mar 23 00:09:29.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:09:29.362: INFO: namespace: e2e-tests-configmap-j4d6p, resource: bindings, ignored listing per whitelist
Mar 23 00:09:29.380: INFO: namespace e2e-tests-configmap-j4d6p deletion completed in 6.086634948s

• [SLOW TEST:8.176 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:09:29.380: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:09:29.439: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ed5faf25-4cff-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-mg9qk" to be "success or failure"
Mar 23 00:09:29.442: INFO: Pod "downwardapi-volume-ed5faf25-4cff-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.605787ms
Mar 23 00:09:31.445: INFO: Pod "downwardapi-volume-ed5faf25-4cff-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005541536s
STEP: Saw pod success
Mar 23 00:09:31.445: INFO: Pod "downwardapi-volume-ed5faf25-4cff-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:09:31.447: INFO: Trying to get logs from node node-2 pod downwardapi-volume-ed5faf25-4cff-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:09:31.462: INFO: Waiting for pod downwardapi-volume-ed5faf25-4cff-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:09:31.464: INFO: Pod downwardapi-volume-ed5faf25-4cff-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:09:31.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mg9qk" for this suite.
Mar 23 00:09:37.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:09:37.549: INFO: namespace: e2e-tests-downward-api-mg9qk, resource: bindings, ignored listing per whitelist
Mar 23 00:09:37.554: INFO: namespace e2e-tests-downward-api-mg9qk deletion completed in 6.086657211s

• [SLOW TEST:8.174 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:09:37.554: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 00:10:03.616: INFO: Container started at 2019-03-23 00:09:38 +0000 UTC, pod became ready at 2019-03-23 00:10:02 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:10:03.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-blvwd" for this suite.
Mar 23 00:10:25.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:10:25.686: INFO: namespace: e2e-tests-container-probe-blvwd, resource: bindings, ignored listing per whitelist
Mar 23 00:10:25.724: INFO: namespace e2e-tests-container-probe-blvwd deletion completed in 22.104542523s

• [SLOW TEST:48.170 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:10:25.724: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ppr7f
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 23 00:10:25.781: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 23 00:10:51.850: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.45:8080/dial?request=hostName&protocol=http&host=10.42.2.44&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ppr7f PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:10:51.850: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:10:51.914: INFO: Waiting for endpoints: map[]
Mar 23 00:10:51.916: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.45:8080/dial?request=hostName&protocol=http&host=10.42.1.15&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ppr7f PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:10:51.916: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:10:51.979: INFO: Waiting for endpoints: map[]
Mar 23 00:10:51.981: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.2.45:8080/dial?request=hostName&protocol=http&host=10.42.0.14&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ppr7f PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:10:51.981: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:10:52.047: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:10:52.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ppr7f" for this suite.
Mar 23 00:11:14.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:11:14.125: INFO: namespace: e2e-tests-pod-network-test-ppr7f, resource: bindings, ignored listing per whitelist
Mar 23 00:11:14.140: INFO: namespace e2e-tests-pod-network-test-ppr7f deletion completed in 22.088380619s

• [SLOW TEST:48.416 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:11:14.141: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 23 00:11:14.195: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 23 00:11:14.201: INFO: Waiting for terminating namespaces to be deleted...
Mar 23 00:11:14.203: INFO: 
Logging pods the kubelet thinks is on node node-1 before test
Mar 23 00:11:14.217: INFO: kube-dns-5c9cfc6cb9-c6f5q from kube-system started at 2019-03-22 23:54:02 +0000 UTC (3 container statuses recorded)
Mar 23 00:11:14.217: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 23 00:11:14.217: INFO: 	Container kubedns ready: true, restart count 0
Mar 23 00:11:14.217: INFO: 	Container sidecar ready: true, restart count 0
Mar 23 00:11:14.217: INFO: canal-xxshj from kube-system started at 2019-03-22 23:53:45 +0000 UTC (3 container statuses recorded)
Mar 23 00:11:14.217: INFO: 	Container calico-node ready: true, restart count 0
Mar 23 00:11:14.217: INFO: 	Container install-cni ready: true, restart count 0
Mar 23 00:11:14.217: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 23 00:11:14.217: INFO: rke-metrics-addon-deploy-job-lvhn9 from kube-system started at 2019-03-22 23:53:56 +0000 UTC (1 container statuses recorded)
Mar 23 00:11:14.217: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 23 00:11:14.217: INFO: metrics-server-844bd95c7b-2nnxc from kube-system started at 2019-03-22 23:54:02 +0000 UTC (1 container statuses recorded)
Mar 23 00:11:14.217: INFO: 	Container metrics-server ready: true, restart count 0
Mar 23 00:11:14.217: INFO: rke-ingress-controller-deploy-job-p2bnl from kube-system started at 2019-03-22 23:54:03 +0000 UTC (1 container statuses recorded)
Mar 23 00:11:14.217: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 23 00:11:14.217: INFO: nginx-ingress-controller-q69fx from ingress-nginx started at 2019-03-22 23:54:04 +0000 UTC (1 container statuses recorded)
Mar 23 00:11:14.217: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 23 00:11:14.217: INFO: default-http-backend-54bff6fc5d-2c5b4 from ingress-nginx started at 2019-03-22 23:54:04 +0000 UTC (1 container statuses recorded)
Mar 23 00:11:14.217: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 23 00:11:14.217: INFO: rke-network-plugin-deploy-job-g47g4 from kube-system started at 2019-03-22 23:53:42 +0000 UTC (1 container statuses recorded)
Mar 23 00:11:14.217: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 23 00:11:14.217: INFO: rke-kube-dns-addon-deploy-job-ll858 from kube-system started at 2019-03-22 23:53:49 +0000 UTC (1 container statuses recorded)
Mar 23 00:11:14.217: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Mar 23 00:11:14.217: INFO: kube-dns-autoscaler-59cc69d67f-gczdw from kube-system started at 2019-03-22 23:54:02 +0000 UTC (1 container statuses recorded)
Mar 23 00:11:14.217: INFO: 	Container autoscaler ready: true, restart count 0
Mar 23 00:11:14.217: INFO: sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-swz92 from heptio-sonobuoy started at 2019-03-22 23:55:25 +0000 UTC (2 container statuses recorded)
Mar 23 00:11:14.217: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 23 00:11:14.217: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:11:14.217: INFO: 
Logging pods the kubelet thinks is on node node-2 before test
Mar 23 00:11:14.224: INFO: canal-vqzvc from kube-system started at 2019-03-22 23:53:45 +0000 UTC (3 container statuses recorded)
Mar 23 00:11:14.224: INFO: 	Container calico-node ready: true, restart count 0
Mar 23 00:11:14.224: INFO: 	Container install-cni ready: true, restart count 0
Mar 23 00:11:14.224: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 23 00:11:14.224: INFO: nginx-ingress-controller-qvs56 from ingress-nginx started at 2019-03-22 23:54:07 +0000 UTC (1 container statuses recorded)
Mar 23 00:11:14.224: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 23 00:11:14.224: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-22 23:55:22 +0000 UTC (1 container statuses recorded)
Mar 23 00:11:14.224: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 23 00:11:14.224: INFO: sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-d7tzm from heptio-sonobuoy started at 2019-03-22 23:55:25 +0000 UTC (2 container statuses recorded)
Mar 23 00:11:14.224: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 23 00:11:14.224: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:11:14.224: INFO: 
Logging pods the kubelet thinks is on node node-3 before test
Mar 23 00:11:14.230: INFO: sonobuoy-e2e-job-08fc2d888de548b8 from heptio-sonobuoy started at 2019-03-22 23:55:24 +0000 UTC (2 container statuses recorded)
Mar 23 00:11:14.230: INFO: 	Container e2e ready: true, restart count 0
Mar 23 00:11:14.230: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:11:14.230: INFO: sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-zn4k6 from heptio-sonobuoy started at 2019-03-22 23:55:25 +0000 UTC (2 container statuses recorded)
Mar 23 00:11:14.230: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 23 00:11:14.230: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:11:14.230: INFO: canal-5gdw5 from kube-system started at 2019-03-22 23:53:45 +0000 UTC (3 container statuses recorded)
Mar 23 00:11:14.230: INFO: 	Container calico-node ready: true, restart count 0
Mar 23 00:11:14.230: INFO: 	Container install-cni ready: true, restart count 0
Mar 23 00:11:14.230: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 23 00:11:14.230: INFO: nginx-ingress-controller-lf7sv from ingress-nginx started at 2019-03-22 23:54:07 +0000 UTC (1 container statuses recorded)
Mar 23 00:11:14.230: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node node-1
STEP: verifying the node has the label node node-2
STEP: verifying the node has the label node node-3
Mar 23 00:11:14.268: INFO: Pod sonobuoy requesting resource cpu=0m on Node node-2
Mar 23 00:11:14.268: INFO: Pod sonobuoy-e2e-job-08fc2d888de548b8 requesting resource cpu=0m on Node node-3
Mar 23 00:11:14.268: INFO: Pod sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-d7tzm requesting resource cpu=0m on Node node-2
Mar 23 00:11:14.268: INFO: Pod sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-swz92 requesting resource cpu=0m on Node node-1
Mar 23 00:11:14.268: INFO: Pod sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-zn4k6 requesting resource cpu=0m on Node node-3
Mar 23 00:11:14.268: INFO: Pod default-http-backend-54bff6fc5d-2c5b4 requesting resource cpu=10m on Node node-1
Mar 23 00:11:14.268: INFO: Pod nginx-ingress-controller-lf7sv requesting resource cpu=0m on Node node-3
Mar 23 00:11:14.268: INFO: Pod nginx-ingress-controller-q69fx requesting resource cpu=0m on Node node-1
Mar 23 00:11:14.268: INFO: Pod nginx-ingress-controller-qvs56 requesting resource cpu=0m on Node node-2
Mar 23 00:11:14.268: INFO: Pod canal-5gdw5 requesting resource cpu=250m on Node node-3
Mar 23 00:11:14.268: INFO: Pod canal-vqzvc requesting resource cpu=250m on Node node-2
Mar 23 00:11:14.268: INFO: Pod canal-xxshj requesting resource cpu=250m on Node node-1
Mar 23 00:11:14.268: INFO: Pod kube-dns-5c9cfc6cb9-c6f5q requesting resource cpu=260m on Node node-1
Mar 23 00:11:14.268: INFO: Pod kube-dns-autoscaler-59cc69d67f-gczdw requesting resource cpu=20m on Node node-1
Mar 23 00:11:14.268: INFO: Pod metrics-server-844bd95c7b-2nnxc requesting resource cpu=0m on Node node-1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdbfab6-4d00-11e9-96f5-ea7d86f92d02.158e6e0183ad747b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-rd5js/filler-pod-2bdbfab6-4d00-11e9-96f5-ea7d86f92d02 to node-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdbfab6-4d00-11e9-96f5-ea7d86f92d02.158e6e01b0814671], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdbfab6-4d00-11e9-96f5-ea7d86f92d02.158e6e01d0cba911], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdbfab6-4d00-11e9-96f5-ea7d86f92d02.158e6e01d3893e8e], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdbfab6-4d00-11e9-96f5-ea7d86f92d02.158e6e01ded929a7], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdca9c5-4d00-11e9-96f5-ea7d86f92d02.158e6e018422a716], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-rd5js/filler-pod-2bdca9c5-4d00-11e9-96f5-ea7d86f92d02 to node-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdca9c5-4d00-11e9-96f5-ea7d86f92d02.158e6e01ae12db0c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdca9c5-4d00-11e9-96f5-ea7d86f92d02.158e6e01b1321270], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdca9c5-4d00-11e9-96f5-ea7d86f92d02.158e6e01b6fbd2f8], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdddb93-4d00-11e9-96f5-ea7d86f92d02.158e6e0184cdb9d7], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-rd5js/filler-pod-2bdddb93-4d00-11e9-96f5-ea7d86f92d02 to node-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdddb93-4d00-11e9-96f5-ea7d86f92d02.158e6e01b13ec44b], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdddb93-4d00-11e9-96f5-ea7d86f92d02.158e6e01d13bd39e], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdddb93-4d00-11e9-96f5-ea7d86f92d02.158e6e01d457598b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bdddb93-4d00-11e9-96f5-ea7d86f92d02.158e6e01d9fa264d], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158e6e01fcef86e6], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node node-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node node-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:11:17.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-rd5js" for this suite.
Mar 23 00:11:23.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:11:23.385: INFO: namespace: e2e-tests-sched-pred-rd5js, resource: bindings, ignored listing per whitelist
Mar 23 00:11:23.445: INFO: namespace e2e-tests-sched-pred-rd5js deletion completed in 6.081602792s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:9.305 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:11:23.445: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 23 00:11:26.039: INFO: Successfully updated pod "labelsupdate315dba75-4d00-11e9-96f5-ea7d86f92d02"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:11:30.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-85q78" for this suite.
Mar 23 00:11:52.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:11:52.104: INFO: namespace: e2e-tests-downward-api-85q78, resource: bindings, ignored listing per whitelist
Mar 23 00:11:52.150: INFO: namespace e2e-tests-downward-api-85q78 deletion completed in 22.084759563s

• [SLOW TEST:28.704 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:11:52.150: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-4278ff34-4d00-11e9-96f5-ea7d86f92d02
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-4278ff34-4d00-11e9-96f5-ea7d86f92d02
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:12:58.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p7gft" for this suite.
Mar 23 00:13:20.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:13:20.520: INFO: namespace: e2e-tests-configmap-p7gft, resource: bindings, ignored listing per whitelist
Mar 23 00:13:20.560: INFO: namespace e2e-tests-configmap-p7gft deletion completed in 22.08235169s

• [SLOW TEST:88.410 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:13:20.560: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 00:13:20.613: INFO: Creating deployment "test-recreate-deployment"
Mar 23 00:13:20.616: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 23 00:13:20.622: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Mar 23 00:13:22.627: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 23 00:13:22.629: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 23 00:13:22.634: INFO: Updating deployment test-recreate-deployment
Mar 23 00:13:22.634: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 23 00:13:22.699: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-tpq6n,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tpq6n/deployments/test-recreate-deployment,UID:7729d7b8-4d00-11e9-9a5c-0646f33e71ba,ResourceVersion:4654,Generation:2,CreationTimestamp:2019-03-23 00:13:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-23 00:13:22 +0000 UTC 2019-03-23 00:13:22 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-23 00:13:22 +0000 UTC 2019-03-23 00:13:20 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar 23 00:13:22.702: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-tpq6n,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tpq6n/replicasets/test-recreate-deployment-7cf749666b,UID:7862f81a-4d00-11e9-9a5c-0646f33e71ba,ResourceVersion:4651,Generation:1,CreationTimestamp:2019-03-23 00:13:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 7729d7b8-4d00-11e9-9a5c-0646f33e71ba 0xc42195ffd7 0xc42195ffd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 23 00:13:22.702: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 23 00:13:22.702: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-tpq6n,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tpq6n/replicasets/test-recreate-deployment-79f694ff59,UID:772adb9c-4d00-11e9-9a5c-0646f33e71ba,ResourceVersion:4642,Generation:2,CreationTimestamp:2019-03-23 00:13:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 7729d7b8-4d00-11e9-9a5c-0646f33e71ba 0xc42195fe97 0xc42195fe98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 23 00:13:22.705: INFO: Pod "test-recreate-deployment-7cf749666b-f595d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-f595d,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-tpq6n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tpq6n/pods/test-recreate-deployment-7cf749666b-f595d,UID:78638d18-4d00-11e9-9a5c-0646f33e71ba,ResourceVersion:4653,Generation:0,CreationTimestamp:2019-03-23 00:13:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 7862f81a-4d00-11e9-9a5c-0646f33e71ba 0xc4208c91e7 0xc4208c91e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bdztf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bdztf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bdztf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4208c9300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4208c9320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:13:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:13:22 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:,StartTime:2019-03-23 00:13:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:13:22.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-tpq6n" for this suite.
Mar 23 00:13:28.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:13:28.796: INFO: namespace: e2e-tests-deployment-tpq6n, resource: bindings, ignored listing per whitelist
Mar 23 00:13:28.800: INFO: namespace e2e-tests-deployment-tpq6n deletion completed in 6.092202028s

• [SLOW TEST:8.241 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:13:28.801: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-7c13fc48-4d00-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 00:13:28.860: INFO: Waiting up to 5m0s for pod "pod-secrets-7c1457ab-4d00-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-secrets-t6wcq" to be "success or failure"
Mar 23 00:13:28.864: INFO: Pod "pod-secrets-7c1457ab-4d00-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.086927ms
Mar 23 00:13:30.867: INFO: Pod "pod-secrets-7c1457ab-4d00-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006898961s
STEP: Saw pod success
Mar 23 00:13:30.867: INFO: Pod "pod-secrets-7c1457ab-4d00-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:13:30.869: INFO: Trying to get logs from node node-2 pod pod-secrets-7c1457ab-4d00-11e9-96f5-ea7d86f92d02 container secret-volume-test: <nil>
STEP: delete the pod
Mar 23 00:13:30.889: INFO: Waiting for pod pod-secrets-7c1457ab-4d00-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:13:30.891: INFO: Pod pod-secrets-7c1457ab-4d00-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:13:30.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t6wcq" for this suite.
Mar 23 00:13:36.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:13:36.926: INFO: namespace: e2e-tests-secrets-t6wcq, resource: bindings, ignored listing per whitelist
Mar 23 00:13:36.978: INFO: namespace e2e-tests-secrets-t6wcq deletion completed in 6.083272902s

• [SLOW TEST:8.177 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:13:36.978: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 23 00:13:37.034: INFO: Waiting up to 5m0s for pod "pod-80f3b460-4d00-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-hd24q" to be "success or failure"
Mar 23 00:13:37.036: INFO: Pod "pod-80f3b460-4d00-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.094429ms
Mar 23 00:13:39.039: INFO: Pod "pod-80f3b460-4d00-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00510163s
STEP: Saw pod success
Mar 23 00:13:39.039: INFO: Pod "pod-80f3b460-4d00-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:13:39.041: INFO: Trying to get logs from node node-2 pod pod-80f3b460-4d00-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 00:13:39.056: INFO: Waiting for pod pod-80f3b460-4d00-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:13:39.059: INFO: Pod pod-80f3b460-4d00-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:13:39.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hd24q" for this suite.
Mar 23 00:13:45.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:13:45.144: INFO: namespace: e2e-tests-emptydir-hd24q, resource: bindings, ignored listing per whitelist
Mar 23 00:13:45.151: INFO: namespace e2e-tests-emptydir-hd24q deletion completed in 6.088676991s

• [SLOW TEST:8.173 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:13:45.151: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-85d328c1-4d00-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 00:13:45.213: INFO: Waiting up to 5m0s for pod "pod-configmaps-85d393d8-4d00-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-configmap-lkcxz" to be "success or failure"
Mar 23 00:13:45.216: INFO: Pod "pod-configmaps-85d393d8-4d00-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.87747ms
Mar 23 00:13:47.219: INFO: Pod "pod-configmaps-85d393d8-4d00-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005895087s
STEP: Saw pod success
Mar 23 00:13:47.219: INFO: Pod "pod-configmaps-85d393d8-4d00-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:13:47.221: INFO: Trying to get logs from node node-2 pod pod-configmaps-85d393d8-4d00-11e9-96f5-ea7d86f92d02 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 23 00:13:47.236: INFO: Waiting for pod pod-configmaps-85d393d8-4d00-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:13:47.238: INFO: Pod pod-configmaps-85d393d8-4d00-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:13:47.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lkcxz" for this suite.
Mar 23 00:13:53.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:13:53.269: INFO: namespace: e2e-tests-configmap-lkcxz, resource: bindings, ignored listing per whitelist
Mar 23 00:13:53.327: INFO: namespace e2e-tests-configmap-lkcxz deletion completed in 6.08602008s

• [SLOW TEST:8.177 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:13:53.328: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8ab2a329-4d00-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 00:13:53.406: INFO: Waiting up to 5m0s for pod "pod-secrets-8ab5d3f5-4d00-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-secrets-8wh55" to be "success or failure"
Mar 23 00:13:53.411: INFO: Pod "pod-secrets-8ab5d3f5-4d00-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.966881ms
Mar 23 00:13:55.417: INFO: Pod "pod-secrets-8ab5d3f5-4d00-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010544738s
STEP: Saw pod success
Mar 23 00:13:55.417: INFO: Pod "pod-secrets-8ab5d3f5-4d00-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:13:55.419: INFO: Trying to get logs from node node-2 pod pod-secrets-8ab5d3f5-4d00-11e9-96f5-ea7d86f92d02 container secret-volume-test: <nil>
STEP: delete the pod
Mar 23 00:13:55.433: INFO: Waiting for pod pod-secrets-8ab5d3f5-4d00-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:13:55.435: INFO: Pod pod-secrets-8ab5d3f5-4d00-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:13:55.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8wh55" for this suite.
Mar 23 00:14:01.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:14:01.461: INFO: namespace: e2e-tests-secrets-8wh55, resource: bindings, ignored listing per whitelist
Mar 23 00:14:01.529: INFO: namespace e2e-tests-secrets-8wh55 deletion completed in 6.090902599s
STEP: Destroying namespace "e2e-tests-secret-namespace-6mgsw" for this suite.
Mar 23 00:14:07.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:14:07.590: INFO: namespace: e2e-tests-secret-namespace-6mgsw, resource: bindings, ignored listing per whitelist
Mar 23 00:14:07.626: INFO: namespace e2e-tests-secret-namespace-6mgsw deletion completed in 6.096884531s

• [SLOW TEST:14.298 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:14:07.626: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0323 00:14:17.702620      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 23 00:14:17.702: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:14:17.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ssqhq" for this suite.
Mar 23 00:14:23.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:14:23.725: INFO: namespace: e2e-tests-gc-ssqhq, resource: bindings, ignored listing per whitelist
Mar 23 00:14:23.789: INFO: namespace e2e-tests-gc-ssqhq deletion completed in 6.084048689s

• [SLOW TEST:16.163 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:14:23.791: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 23 00:14:23.865: INFO: Waiting up to 5m0s for pod "pod-9cdd758e-4d00-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-j5fbq" to be "success or failure"
Mar 23 00:14:23.869: INFO: Pod "pod-9cdd758e-4d00-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.826072ms
Mar 23 00:14:25.872: INFO: Pod "pod-9cdd758e-4d00-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006935031s
STEP: Saw pod success
Mar 23 00:14:25.872: INFO: Pod "pod-9cdd758e-4d00-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:14:25.874: INFO: Trying to get logs from node node-2 pod pod-9cdd758e-4d00-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 00:14:25.889: INFO: Waiting for pod pod-9cdd758e-4d00-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:14:25.891: INFO: Pod pod-9cdd758e-4d00-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:14:25.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j5fbq" for this suite.
Mar 23 00:14:31.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:14:31.941: INFO: namespace: e2e-tests-emptydir-j5fbq, resource: bindings, ignored listing per whitelist
Mar 23 00:14:31.977: INFO: namespace e2e-tests-emptydir-j5fbq deletion completed in 6.083349634s

• [SLOW TEST:8.186 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:14:31.977: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-lg9td
Mar 23 00:14:34.038: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-lg9td
STEP: checking the pod's current state and verifying that restartCount is present
Mar 23 00:14:34.040: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:18:34.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lg9td" for this suite.
Mar 23 00:18:40.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:18:40.458: INFO: namespace: e2e-tests-container-probe-lg9td, resource: bindings, ignored listing per whitelist
Mar 23 00:18:40.502: INFO: namespace e2e-tests-container-probe-lg9td deletion completed in 6.087023535s

• [SLOW TEST:248.524 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:18:40.502: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 23 00:18:40.562: INFO: Waiting up to 5m0s for pod "downward-api-35de565e-4d01-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-2kxjr" to be "success or failure"
Mar 23 00:18:40.564: INFO: Pod "downward-api-35de565e-4d01-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 1.806056ms
Mar 23 00:18:42.567: INFO: Pod "downward-api-35de565e-4d01-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004785637s
STEP: Saw pod success
Mar 23 00:18:42.567: INFO: Pod "downward-api-35de565e-4d01-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:18:42.570: INFO: Trying to get logs from node node-2 pod downward-api-35de565e-4d01-11e9-96f5-ea7d86f92d02 container dapi-container: <nil>
STEP: delete the pod
Mar 23 00:18:42.585: INFO: Waiting for pod downward-api-35de565e-4d01-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:18:42.587: INFO: Pod downward-api-35de565e-4d01-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:18:42.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2kxjr" for this suite.
Mar 23 00:18:48.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:18:48.665: INFO: namespace: e2e-tests-downward-api-2kxjr, resource: bindings, ignored listing per whitelist
Mar 23 00:18:48.675: INFO: namespace e2e-tests-downward-api-2kxjr deletion completed in 6.084610496s

• [SLOW TEST:8.173 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:18:48.675: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-t9csd
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-t9csd
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-t9csd
Mar 23 00:18:48.741: INFO: Found 0 stateful pods, waiting for 1
Mar 23 00:18:58.744: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 23 00:18:58.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-t9csd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 23 00:18:58.886: INFO: stderr: ""
Mar 23 00:18:58.886: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 23 00:18:58.886: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 23 00:18:58.889: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 23 00:19:08.892: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 23 00:19:08.892: INFO: Waiting for statefulset status.replicas updated to 0
Mar 23 00:19:08.902: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999029s
Mar 23 00:19:09.905: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997586973s
Mar 23 00:19:10.909: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994427276s
Mar 23 00:19:11.912: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.991320611s
Mar 23 00:19:12.915: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988228611s
Mar 23 00:19:13.918: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.985005734s
Mar 23 00:19:14.921: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.98218702s
Mar 23 00:19:15.924: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.979038532s
Mar 23 00:19:16.928: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.975795207s
Mar 23 00:19:17.931: INFO: Verifying statefulset ss doesn't scale past 1 for another 972.063586ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-t9csd
Mar 23 00:19:18.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-t9csd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:19:19.078: INFO: stderr: ""
Mar 23 00:19:19.078: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 23 00:19:19.078: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 23 00:19:19.081: INFO: Found 1 stateful pods, waiting for 3
Mar 23 00:19:29.083: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 23 00:19:29.084: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 23 00:19:29.084: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar 23 00:19:29.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-t9csd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 23 00:19:29.235: INFO: stderr: ""
Mar 23 00:19:29.235: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 23 00:19:29.235: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 23 00:19:29.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-t9csd ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 23 00:19:29.375: INFO: stderr: ""
Mar 23 00:19:29.375: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 23 00:19:29.375: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 23 00:19:29.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-t9csd ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 23 00:19:29.519: INFO: stderr: ""
Mar 23 00:19:29.519: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 23 00:19:29.519: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 23 00:19:29.519: INFO: Waiting for statefulset status.replicas updated to 0
Mar 23 00:19:29.521: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 23 00:19:39.527: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 23 00:19:39.527: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 23 00:19:39.527: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 23 00:19:39.536: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999116s
Mar 23 00:19:40.539: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996556567s
Mar 23 00:19:41.542: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993126838s
Mar 23 00:19:42.546: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989730126s
Mar 23 00:19:43.549: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986308389s
Mar 23 00:19:44.552: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983014993s
Mar 23 00:19:45.556: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.979650763s
Mar 23 00:19:46.559: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.976475565s
Mar 23 00:19:47.562: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.973217023s
Mar 23 00:19:48.565: INFO: Verifying statefulset ss doesn't scale past 3 for another 969.883363ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-t9csd
Mar 23 00:19:49.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-t9csd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:19:49.717: INFO: stderr: ""
Mar 23 00:19:49.717: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 23 00:19:49.717: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 23 00:19:49.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-t9csd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:19:49.873: INFO: stderr: ""
Mar 23 00:19:49.873: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 23 00:19:49.873: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 23 00:19:49.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-t9csd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:19:50.010: INFO: stderr: ""
Mar 23 00:19:50.010: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 23 00:19:50.010: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 23 00:19:50.010: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 23 00:20:00.021: INFO: Deleting all statefulset in ns e2e-tests-statefulset-t9csd
Mar 23 00:20:00.025: INFO: Scaling statefulset ss to 0
Mar 23 00:20:00.033: INFO: Waiting for statefulset status.replicas updated to 0
Mar 23 00:20:00.035: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:20:00.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-t9csd" for this suite.
Mar 23 00:20:06.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:20:06.095: INFO: namespace: e2e-tests-statefulset-t9csd, resource: bindings, ignored listing per whitelist
Mar 23 00:20:06.137: INFO: namespace e2e-tests-statefulset-t9csd deletion completed in 6.087493122s

• [SLOW TEST:77.462 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:20:06.137: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-gz84c
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 23 00:20:06.200: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 23 00:20:24.267: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.42.1.19 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gz84c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:20:24.267: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:20:25.335: INFO: Found all expected endpoints: [netserver-0]
Mar 23 00:20:25.338: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.42.2.60 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gz84c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:20:25.338: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:20:26.407: INFO: Found all expected endpoints: [netserver-1]
Mar 23 00:20:26.409: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.42.0.17 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gz84c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:20:26.409: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:20:27.478: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:20:27.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-gz84c" for this suite.
Mar 23 00:20:49.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:20:49.543: INFO: namespace: e2e-tests-pod-network-test-gz84c, resource: bindings, ignored listing per whitelist
Mar 23 00:20:49.563: INFO: namespace e2e-tests-pod-network-test-gz84c deletion completed in 22.081320251s

• [SLOW TEST:43.426 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:20:49.563: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:20:49.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-mddgf" for this suite.
Mar 23 00:20:55.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:20:55.694: INFO: namespace: e2e-tests-services-mddgf, resource: bindings, ignored listing per whitelist
Mar 23 00:20:55.707: INFO: namespace e2e-tests-services-mddgf deletion completed in 6.081803727s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.144 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:20:55.707: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-k849
STEP: Creating a pod to test atomic-volume-subpath
Mar 23 00:20:55.822: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-k849" in namespace "e2e-tests-subpath-5gzgh" to be "success or failure"
Mar 23 00:20:55.824: INFO: Pod "pod-subpath-test-projected-k849": Phase="Pending", Reason="", readiness=false. Elapsed: 1.958813ms
Mar 23 00:20:57.827: INFO: Pod "pod-subpath-test-projected-k849": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005001687s
Mar 23 00:20:59.830: INFO: Pod "pod-subpath-test-projected-k849": Phase="Running", Reason="", readiness=false. Elapsed: 4.007964268s
Mar 23 00:21:01.833: INFO: Pod "pod-subpath-test-projected-k849": Phase="Running", Reason="", readiness=false. Elapsed: 6.011363976s
Mar 23 00:21:03.836: INFO: Pod "pod-subpath-test-projected-k849": Phase="Running", Reason="", readiness=false. Elapsed: 8.014442536s
Mar 23 00:21:05.839: INFO: Pod "pod-subpath-test-projected-k849": Phase="Running", Reason="", readiness=false. Elapsed: 10.01748242s
Mar 23 00:21:07.842: INFO: Pod "pod-subpath-test-projected-k849": Phase="Running", Reason="", readiness=false. Elapsed: 12.020574213s
Mar 23 00:21:09.846: INFO: Pod "pod-subpath-test-projected-k849": Phase="Running", Reason="", readiness=false. Elapsed: 14.024063512s
Mar 23 00:21:11.849: INFO: Pod "pod-subpath-test-projected-k849": Phase="Running", Reason="", readiness=false. Elapsed: 16.027067629s
Mar 23 00:21:13.852: INFO: Pod "pod-subpath-test-projected-k849": Phase="Running", Reason="", readiness=false. Elapsed: 18.030227324s
Mar 23 00:21:15.855: INFO: Pod "pod-subpath-test-projected-k849": Phase="Running", Reason="", readiness=false. Elapsed: 20.033333487s
Mar 23 00:21:17.858: INFO: Pod "pod-subpath-test-projected-k849": Phase="Running", Reason="", readiness=false. Elapsed: 22.036398269s
Mar 23 00:21:19.862: INFO: Pod "pod-subpath-test-projected-k849": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.039619008s
STEP: Saw pod success
Mar 23 00:21:19.862: INFO: Pod "pod-subpath-test-projected-k849" satisfied condition "success or failure"
Mar 23 00:21:19.864: INFO: Trying to get logs from node node-2 pod pod-subpath-test-projected-k849 container test-container-subpath-projected-k849: <nil>
STEP: delete the pod
Mar 23 00:21:19.893: INFO: Waiting for pod pod-subpath-test-projected-k849 to disappear
Mar 23 00:21:19.895: INFO: Pod pod-subpath-test-projected-k849 no longer exists
STEP: Deleting pod pod-subpath-test-projected-k849
Mar 23 00:21:19.895: INFO: Deleting pod "pod-subpath-test-projected-k849" in namespace "e2e-tests-subpath-5gzgh"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:21:19.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5gzgh" for this suite.
Mar 23 00:21:25.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:21:25.947: INFO: namespace: e2e-tests-subpath-5gzgh, resource: bindings, ignored listing per whitelist
Mar 23 00:21:26.000: INFO: namespace e2e-tests-subpath-5gzgh deletion completed in 6.099599558s

• [SLOW TEST:30.293 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:21:26.001: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 23 00:21:26.064: INFO: Waiting up to 5m0s for pod "downward-api-9883cbe9-4d01-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-dv7v4" to be "success or failure"
Mar 23 00:21:26.066: INFO: Pod "downward-api-9883cbe9-4d01-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.557954ms
Mar 23 00:21:28.069: INFO: Pod "downward-api-9883cbe9-4d01-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0056108s
STEP: Saw pod success
Mar 23 00:21:28.069: INFO: Pod "downward-api-9883cbe9-4d01-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:21:28.071: INFO: Trying to get logs from node node-2 pod downward-api-9883cbe9-4d01-11e9-96f5-ea7d86f92d02 container dapi-container: <nil>
STEP: delete the pod
Mar 23 00:21:28.086: INFO: Waiting for pod downward-api-9883cbe9-4d01-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:21:28.088: INFO: Pod downward-api-9883cbe9-4d01-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:21:28.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dv7v4" for this suite.
Mar 23 00:21:34.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:21:34.132: INFO: namespace: e2e-tests-downward-api-dv7v4, resource: bindings, ignored listing per whitelist
Mar 23 00:21:34.174: INFO: namespace e2e-tests-downward-api-dv7v4 deletion completed in 6.083477122s

• [SLOW TEST:8.174 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:21:34.175: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-9d62fae2-4d01-11e9-96f5-ea7d86f92d02
Mar 23 00:21:34.237: INFO: Pod name my-hostname-basic-9d62fae2-4d01-11e9-96f5-ea7d86f92d02: Found 0 pods out of 1
Mar 23 00:21:39.241: INFO: Pod name my-hostname-basic-9d62fae2-4d01-11e9-96f5-ea7d86f92d02: Found 1 pods out of 1
Mar 23 00:21:39.241: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9d62fae2-4d01-11e9-96f5-ea7d86f92d02" are running
Mar 23 00:21:39.243: INFO: Pod "my-hostname-basic-9d62fae2-4d01-11e9-96f5-ea7d86f92d02-knz5j" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-23 00:21:34 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-23 00:21:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-23 00:21:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-23 00:21:34 +0000 UTC Reason: Message:}])
Mar 23 00:21:39.243: INFO: Trying to dial the pod
Mar 23 00:21:44.251: INFO: Controller my-hostname-basic-9d62fae2-4d01-11e9-96f5-ea7d86f92d02: Got expected result from replica 1 [my-hostname-basic-9d62fae2-4d01-11e9-96f5-ea7d86f92d02-knz5j]: "my-hostname-basic-9d62fae2-4d01-11e9-96f5-ea7d86f92d02-knz5j", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:21:44.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-zg26n" for this suite.
Mar 23 00:21:50.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:21:50.285: INFO: namespace: e2e-tests-replication-controller-zg26n, resource: bindings, ignored listing per whitelist
Mar 23 00:21:50.339: INFO: namespace e2e-tests-replication-controller-zg26n deletion completed in 6.084470925s

• [SLOW TEST:16.164 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:21:50.339: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar 23 00:21:50.409: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qh5lq,SelfLink:/api/v1/namespaces/e2e-tests-watch-qh5lq/configmaps/e2e-watch-test-label-changed,UID:a7046f31-4d01-11e9-9a5c-0646f33e71ba,ResourceVersion:6104,Generation:0,CreationTimestamp:2019-03-23 00:21:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 23 00:21:50.409: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qh5lq,SelfLink:/api/v1/namespaces/e2e-tests-watch-qh5lq/configmaps/e2e-watch-test-label-changed,UID:a7046f31-4d01-11e9-9a5c-0646f33e71ba,ResourceVersion:6105,Generation:0,CreationTimestamp:2019-03-23 00:21:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 23 00:21:50.409: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qh5lq,SelfLink:/api/v1/namespaces/e2e-tests-watch-qh5lq/configmaps/e2e-watch-test-label-changed,UID:a7046f31-4d01-11e9-9a5c-0646f33e71ba,ResourceVersion:6106,Generation:0,CreationTimestamp:2019-03-23 00:21:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar 23 00:22:00.429: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qh5lq,SelfLink:/api/v1/namespaces/e2e-tests-watch-qh5lq/configmaps/e2e-watch-test-label-changed,UID:a7046f31-4d01-11e9-9a5c-0646f33e71ba,ResourceVersion:6123,Generation:0,CreationTimestamp:2019-03-23 00:21:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 23 00:22:00.429: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qh5lq,SelfLink:/api/v1/namespaces/e2e-tests-watch-qh5lq/configmaps/e2e-watch-test-label-changed,UID:a7046f31-4d01-11e9-9a5c-0646f33e71ba,ResourceVersion:6124,Generation:0,CreationTimestamp:2019-03-23 00:21:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 23 00:22:00.429: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qh5lq,SelfLink:/api/v1/namespaces/e2e-tests-watch-qh5lq/configmaps/e2e-watch-test-label-changed,UID:a7046f31-4d01-11e9-9a5c-0646f33e71ba,ResourceVersion:6125,Generation:0,CreationTimestamp:2019-03-23 00:21:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:22:00.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qh5lq" for this suite.
Mar 23 00:22:06.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:22:06.484: INFO: namespace: e2e-tests-watch-qh5lq, resource: bindings, ignored listing per whitelist
Mar 23 00:22:06.521: INFO: namespace e2e-tests-watch-qh5lq deletion completed in 6.087933797s

• [SLOW TEST:16.181 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:22:06.521: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar 23 00:22:08.598: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-b0ab59dc-4d01-11e9-96f5-ea7d86f92d02,GenerateName:,Namespace:e2e-tests-events-gxlfr,SelfLink:/api/v1/namespaces/e2e-tests-events-gxlfr/pods/send-events-b0ab59dc-4d01-11e9-96f5-ea7d86f92d02,UID:b0aa8145-4d01-11e9-9a5c-0646f33e71ba,ResourceVersion:6156,Generation:0,CreationTimestamp:2019-03-23 00:22:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 583655870,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.65/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-r8shd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r8shd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-r8shd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422284880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4222848a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:22:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:22:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:22:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:22:06 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:10.42.2.65,StartTime:2019-03-23 00:22:06 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-23 00:22:07 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://59ad53021708ce4370f7b30ab92a3b5a4e111234168c315633b92e42fbf0e205}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar 23 00:22:10.601: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar 23 00:22:12.604: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:22:12.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-gxlfr" for this suite.
Mar 23 00:22:50.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:22:50.696: INFO: namespace: e2e-tests-events-gxlfr, resource: bindings, ignored listing per whitelist
Mar 23 00:22:50.700: INFO: namespace e2e-tests-events-gxlfr deletion completed in 38.084907119s

• [SLOW TEST:44.179 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:22:50.700: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gjxjw A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-gjxjw;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gjxjw A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-gjxjw;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gjxjw.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-gjxjw.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gjxjw.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-gjxjw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gjxjw.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gjxjw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gjxjw.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gjxjw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gjxjw.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-gjxjw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gjxjw.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-gjxjw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gjxjw.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 124.142.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.142.124_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 124.142.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.142.124_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gjxjw A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-gjxjw;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gjxjw A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-gjxjw;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gjxjw.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-gjxjw.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gjxjw.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-gjxjw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gjxjw.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-gjxjw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gjxjw.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gjxjw.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gjxjw.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-gjxjw.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gjxjw.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-gjxjw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gjxjw.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 124.142.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.142.124_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 124.142.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.142.124_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 23 00:23:02.864: INFO: DNS probes using e2e-tests-dns-gjxjw/dns-test-cb00e2e3-4d01-11e9-96f5-ea7d86f92d02 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:23:02.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-gjxjw" for this suite.
Mar 23 00:23:08.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:23:08.999: INFO: namespace: e2e-tests-dns-gjxjw, resource: bindings, ignored listing per whitelist
Mar 23 00:23:09.005: INFO: namespace e2e-tests-dns-gjxjw deletion completed in 6.090921345s

• [SLOW TEST:18.305 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:23:09.005: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-2grn9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-2grn9 to expose endpoints map[]
Mar 23 00:23:09.075: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-2grn9 exposes endpoints map[] (4.085298ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-2grn9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-2grn9 to expose endpoints map[pod1:[80]]
Mar 23 00:23:11.099: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-2grn9 exposes endpoints map[pod1:[80]] (2.018289786s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-2grn9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-2grn9 to expose endpoints map[pod1:[80] pod2:[80]]
Mar 23 00:23:13.128: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-2grn9 exposes endpoints map[pod1:[80] pod2:[80]] (2.024574546s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-2grn9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-2grn9 to expose endpoints map[pod2:[80]]
Mar 23 00:23:14.142: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-2grn9 exposes endpoints map[pod2:[80]] (1.009923924s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-2grn9
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-2grn9 to expose endpoints map[]
Mar 23 00:23:14.155: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-2grn9 exposes endpoints map[] (7.808922ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:23:14.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-2grn9" for this suite.
Mar 23 00:23:36.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:23:36.225: INFO: namespace: e2e-tests-services-2grn9, resource: bindings, ignored listing per whitelist
Mar 23 00:23:36.266: INFO: namespace e2e-tests-services-2grn9 deletion completed in 22.090457904s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:27.260 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:23:36.266: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 23 00:23:36.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-kpmrh'
Mar 23 00:23:36.671: INFO: stderr: ""
Mar 23 00:23:36.671: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 23 00:23:37.674: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 00:23:37.674: INFO: Found 0 / 1
Mar 23 00:23:38.674: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 00:23:38.674: INFO: Found 1 / 1
Mar 23 00:23:38.674: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar 23 00:23:38.676: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 00:23:38.676: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 23 00:23:38.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 patch pod redis-master-v2nck --namespace=e2e-tests-kubectl-kpmrh -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 23 00:23:38.760: INFO: stderr: ""
Mar 23 00:23:38.760: INFO: stdout: "pod/redis-master-v2nck patched\n"
STEP: checking annotations
Mar 23 00:23:38.762: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 00:23:38.762: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:23:38.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kpmrh" for this suite.
Mar 23 00:24:00.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:24:00.788: INFO: namespace: e2e-tests-kubectl-kpmrh, resource: bindings, ignored listing per whitelist
Mar 23 00:24:00.851: INFO: namespace e2e-tests-kubectl-kpmrh deletion completed in 22.085902964s

• [SLOW TEST:24.586 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:24:00.852: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Mar 23 00:24:02.979: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:24:27.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-fqkbf" for this suite.
Mar 23 00:24:33.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:24:33.035: INFO: namespace: e2e-tests-namespaces-fqkbf, resource: bindings, ignored listing per whitelist
Mar 23 00:24:33.098: INFO: namespace e2e-tests-namespaces-fqkbf deletion completed in 6.083945304s
STEP: Destroying namespace "e2e-tests-nsdeletetest-sdzcz" for this suite.
Mar 23 00:24:33.100: INFO: Namespace e2e-tests-nsdeletetest-sdzcz was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-jhdjj" for this suite.
Mar 23 00:24:39.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:24:39.181: INFO: namespace: e2e-tests-nsdeletetest-jhdjj, resource: bindings, ignored listing per whitelist
Mar 23 00:24:39.181: INFO: namespace e2e-tests-nsdeletetest-jhdjj deletion completed in 6.080881401s

• [SLOW TEST:38.330 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:24:39.181: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 23 00:24:43.267: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 23 00:24:43.271: INFO: Pod pod-with-poststart-http-hook still exists
Mar 23 00:24:45.272: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 23 00:24:45.274: INFO: Pod pod-with-poststart-http-hook still exists
Mar 23 00:24:47.272: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 23 00:24:47.275: INFO: Pod pod-with-poststart-http-hook still exists
Mar 23 00:24:49.272: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 23 00:24:49.275: INFO: Pod pod-with-poststart-http-hook still exists
Mar 23 00:24:51.272: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 23 00:24:51.275: INFO: Pod pod-with-poststart-http-hook still exists
Mar 23 00:24:53.272: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 23 00:24:53.274: INFO: Pod pod-with-poststart-http-hook still exists
Mar 23 00:24:55.272: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 23 00:24:55.274: INFO: Pod pod-with-poststart-http-hook still exists
Mar 23 00:24:57.272: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 23 00:24:57.274: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:24:57.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-qshpp" for this suite.
Mar 23 00:25:19.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:25:19.307: INFO: namespace: e2e-tests-container-lifecycle-hook-qshpp, resource: bindings, ignored listing per whitelist
Mar 23 00:25:19.359: INFO: namespace e2e-tests-container-lifecycle-hook-qshpp deletion completed in 22.081630458s

• [SLOW TEST:40.178 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:25:19.360: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0323 00:25:29.467373      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 23 00:25:29.467: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:25:29.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8wpqq" for this suite.
Mar 23 00:25:35.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:25:35.502: INFO: namespace: e2e-tests-gc-8wpqq, resource: bindings, ignored listing per whitelist
Mar 23 00:25:35.558: INFO: namespace e2e-tests-gc-8wpqq deletion completed in 6.088307125s

• [SLOW TEST:16.198 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:25:35.558: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-9dg2
STEP: Creating a pod to test atomic-volume-subpath
Mar 23 00:25:35.630: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9dg2" in namespace "e2e-tests-subpath-ztndg" to be "success or failure"
Mar 23 00:25:35.632: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.71478ms
Mar 23 00:25:37.636: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006073196s
Mar 23 00:25:39.639: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Running", Reason="", readiness=false. Elapsed: 4.009132864s
Mar 23 00:25:41.642: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Running", Reason="", readiness=false. Elapsed: 6.01206905s
Mar 23 00:25:43.645: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Running", Reason="", readiness=false. Elapsed: 8.015300112s
Mar 23 00:25:45.648: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Running", Reason="", readiness=false. Elapsed: 10.018312203s
Mar 23 00:25:47.651: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Running", Reason="", readiness=false. Elapsed: 12.021181005s
Mar 23 00:25:49.654: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Running", Reason="", readiness=false. Elapsed: 14.024359037s
Mar 23 00:25:51.657: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Running", Reason="", readiness=false. Elapsed: 16.026899142s
Mar 23 00:25:53.660: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Running", Reason="", readiness=false. Elapsed: 18.029949284s
Mar 23 00:25:55.663: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Running", Reason="", readiness=false. Elapsed: 20.032942986s
Mar 23 00:25:57.666: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Running", Reason="", readiness=false. Elapsed: 22.035956254s
Mar 23 00:25:59.669: INFO: Pod "pod-subpath-test-configmap-9dg2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.039034706s
STEP: Saw pod success
Mar 23 00:25:59.669: INFO: Pod "pod-subpath-test-configmap-9dg2" satisfied condition "success or failure"
Mar 23 00:25:59.671: INFO: Trying to get logs from node node-2 pod pod-subpath-test-configmap-9dg2 container test-container-subpath-configmap-9dg2: <nil>
STEP: delete the pod
Mar 23 00:25:59.697: INFO: Waiting for pod pod-subpath-test-configmap-9dg2 to disappear
Mar 23 00:25:59.700: INFO: Pod pod-subpath-test-configmap-9dg2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9dg2
Mar 23 00:25:59.700: INFO: Deleting pod "pod-subpath-test-configmap-9dg2" in namespace "e2e-tests-subpath-ztndg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:25:59.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ztndg" for this suite.
Mar 23 00:26:05.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:26:05.749: INFO: namespace: e2e-tests-subpath-ztndg, resource: bindings, ignored listing per whitelist
Mar 23 00:26:05.794: INFO: namespace e2e-tests-subpath-ztndg deletion completed in 6.089580256s

• [SLOW TEST:30.236 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:26:05.795: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-74pmq in namespace e2e-tests-proxy-kg4xt
I0323 00:26:05.862919      17 runners.go:180] Created replication controller with name: proxy-service-74pmq, namespace: e2e-tests-proxy-kg4xt, replica count: 1
I0323 00:26:06.914325      17 runners.go:180] proxy-service-74pmq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0323 00:26:07.914548      17 runners.go:180] proxy-service-74pmq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0323 00:26:08.914775      17 runners.go:180] proxy-service-74pmq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0323 00:26:09.914995      17 runners.go:180] proxy-service-74pmq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0323 00:26:10.915246      17 runners.go:180] proxy-service-74pmq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0323 00:26:11.915452      17 runners.go:180] proxy-service-74pmq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0323 00:26:12.915683      17 runners.go:180] proxy-service-74pmq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0323 00:26:13.915922      17 runners.go:180] proxy-service-74pmq Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 23 00:26:13.918: INFO: setup took 8.068236209s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar 23 00:26:13.931: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 12.886538ms)
Mar 23 00:26:13.931: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 13.382239ms)
Mar 23 00:26:13.932: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 13.235597ms)
Mar 23 00:26:13.932: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 13.189535ms)
Mar 23 00:26:13.932: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 13.421867ms)
Mar 23 00:26:13.932: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 13.761176ms)
Mar 23 00:26:13.933: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 15.141311ms)
Mar 23 00:26:13.935: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 16.508905ms)
Mar 23 00:26:13.935: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 16.64865ms)
Mar 23 00:26:13.936: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 18.2875ms)
Mar 23 00:26:13.937: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 18.985545ms)
Mar 23 00:26:13.938: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 20.197791ms)
Mar 23 00:26:13.939: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 20.527971ms)
Mar 23 00:26:13.939: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 21.224839ms)
Mar 23 00:26:13.940: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 21.501112ms)
Mar 23 00:26:13.943: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 24.545845ms)
Mar 23 00:26:13.948: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 5.400889ms)
Mar 23 00:26:13.949: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 5.802393ms)
Mar 23 00:26:13.949: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 5.909575ms)
Mar 23 00:26:13.949: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 5.787701ms)
Mar 23 00:26:13.949: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 5.986105ms)
Mar 23 00:26:13.950: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 6.822979ms)
Mar 23 00:26:13.953: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 9.586275ms)
Mar 23 00:26:13.953: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 9.6346ms)
Mar 23 00:26:13.953: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 10.508749ms)
Mar 23 00:26:13.954: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 10.618888ms)
Mar 23 00:26:13.954: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 10.914257ms)
Mar 23 00:26:13.954: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 10.807815ms)
Mar 23 00:26:13.954: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 11.397593ms)
Mar 23 00:26:13.954: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 11.066303ms)
Mar 23 00:26:13.955: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 11.396034ms)
Mar 23 00:26:13.956: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 12.44212ms)
Mar 23 00:26:13.963: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 6.661946ms)
Mar 23 00:26:13.963: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 6.989234ms)
Mar 23 00:26:13.963: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 7.149785ms)
Mar 23 00:26:13.963: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 7.04984ms)
Mar 23 00:26:13.964: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 7.342015ms)
Mar 23 00:26:13.964: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 8.163121ms)
Mar 23 00:26:13.964: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 7.965441ms)
Mar 23 00:26:13.964: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 8.125559ms)
Mar 23 00:26:13.965: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 8.713035ms)
Mar 23 00:26:13.965: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 8.66999ms)
Mar 23 00:26:13.965: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 8.751373ms)
Mar 23 00:26:13.967: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 10.00615ms)
Mar 23 00:26:13.967: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 10.273455ms)
Mar 23 00:26:13.967: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 10.500164ms)
Mar 23 00:26:13.968: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 12.227096ms)
Mar 23 00:26:13.968: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 11.977759ms)
Mar 23 00:26:13.975: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 6.402762ms)
Mar 23 00:26:13.975: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 5.818167ms)
Mar 23 00:26:13.975: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 6.495801ms)
Mar 23 00:26:13.977: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 7.566906ms)
Mar 23 00:26:13.977: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 7.717997ms)
Mar 23 00:26:13.977: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 8.247415ms)
Mar 23 00:26:13.978: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 8.639162ms)
Mar 23 00:26:13.978: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 9.627332ms)
Mar 23 00:26:13.979: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 9.113187ms)
Mar 23 00:26:13.979: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 9.667796ms)
Mar 23 00:26:13.979: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 10.201116ms)
Mar 23 00:26:13.979: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 10.471117ms)
Mar 23 00:26:13.979: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 10.068298ms)
Mar 23 00:26:13.979: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 10.027791ms)
Mar 23 00:26:13.979: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 10.114843ms)
Mar 23 00:26:13.979: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 10.699666ms)
Mar 23 00:26:13.983: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 3.552788ms)
Mar 23 00:26:13.983: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 3.890861ms)
Mar 23 00:26:13.984: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 3.937543ms)
Mar 23 00:26:13.984: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 4.4945ms)
Mar 23 00:26:13.987: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 7.417241ms)
Mar 23 00:26:13.988: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 8.092312ms)
Mar 23 00:26:13.988: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 8.550996ms)
Mar 23 00:26:13.989: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 8.997938ms)
Mar 23 00:26:13.989: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 9.580444ms)
Mar 23 00:26:13.990: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 9.530848ms)
Mar 23 00:26:13.990: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 9.803096ms)
Mar 23 00:26:13.990: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 10.51684ms)
Mar 23 00:26:13.992: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 11.935311ms)
Mar 23 00:26:13.992: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 11.759934ms)
Mar 23 00:26:13.992: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 12.124767ms)
Mar 23 00:26:13.992: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 12.077383ms)
Mar 23 00:26:13.996: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 4.197492ms)
Mar 23 00:26:13.996: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 4.231321ms)
Mar 23 00:26:13.997: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 4.56435ms)
Mar 23 00:26:13.997: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 4.842887ms)
Mar 23 00:26:13.998: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 5.987332ms)
Mar 23 00:26:13.999: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 6.095824ms)
Mar 23 00:26:14.001: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 8.4769ms)
Mar 23 00:26:14.002: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 9.821867ms)
Mar 23 00:26:14.002: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 9.36974ms)
Mar 23 00:26:14.002: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 9.676889ms)
Mar 23 00:26:14.002: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 9.720773ms)
Mar 23 00:26:14.003: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 10.180428ms)
Mar 23 00:26:14.003: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 10.583404ms)
Mar 23 00:26:14.003: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 10.814822ms)
Mar 23 00:26:14.004: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 11.01547ms)
Mar 23 00:26:14.004: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 11.755138ms)
Mar 23 00:26:14.008: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 3.71224ms)
Mar 23 00:26:14.010: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 5.680763ms)
Mar 23 00:26:14.010: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 5.761682ms)
Mar 23 00:26:14.011: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 6.271765ms)
Mar 23 00:26:14.011: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 5.973723ms)
Mar 23 00:26:14.014: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 9.510692ms)
Mar 23 00:26:14.015: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 9.969545ms)
Mar 23 00:26:14.015: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 10.094682ms)
Mar 23 00:26:14.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 10.670237ms)
Mar 23 00:26:14.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 11.263677ms)
Mar 23 00:26:14.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 11.327293ms)
Mar 23 00:26:14.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 11.014647ms)
Mar 23 00:26:14.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 11.183178ms)
Mar 23 00:26:14.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 11.422754ms)
Mar 23 00:26:14.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 11.324626ms)
Mar 23 00:26:14.017: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 11.676484ms)
Mar 23 00:26:14.025: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 8.10043ms)
Mar 23 00:26:14.025: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 8.759343ms)
Mar 23 00:26:14.026: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 8.216426ms)
Mar 23 00:26:14.026: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 8.313195ms)
Mar 23 00:26:14.026: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 8.663404ms)
Mar 23 00:26:14.026: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 8.641242ms)
Mar 23 00:26:14.026: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 8.773314ms)
Mar 23 00:26:14.026: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 8.649497ms)
Mar 23 00:26:14.026: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 8.44424ms)
Mar 23 00:26:14.026: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 8.61333ms)
Mar 23 00:26:14.028: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 11.208465ms)
Mar 23 00:26:14.029: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 11.888967ms)
Mar 23 00:26:14.029: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 12.351998ms)
Mar 23 00:26:14.030: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 12.858268ms)
Mar 23 00:26:14.030: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 12.719613ms)
Mar 23 00:26:14.030: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 13.306388ms)
Mar 23 00:26:14.035: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 4.474258ms)
Mar 23 00:26:14.035: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 4.934552ms)
Mar 23 00:26:14.037: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 6.733515ms)
Mar 23 00:26:14.037: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 7.152337ms)
Mar 23 00:26:14.038: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 7.486297ms)
Mar 23 00:26:14.038: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 7.65496ms)
Mar 23 00:26:14.042: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 12.117749ms)
Mar 23 00:26:14.043: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 12.302639ms)
Mar 23 00:26:14.043: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 12.415494ms)
Mar 23 00:26:14.043: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 12.374106ms)
Mar 23 00:26:14.043: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 12.688721ms)
Mar 23 00:26:14.043: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 12.790099ms)
Mar 23 00:26:14.043: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 13.312363ms)
Mar 23 00:26:14.043: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 13.038252ms)
Mar 23 00:26:14.044: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 13.457551ms)
Mar 23 00:26:14.044: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 13.341215ms)
Mar 23 00:26:14.053: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 9.115407ms)
Mar 23 00:26:14.054: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 9.504593ms)
Mar 23 00:26:14.054: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 9.176596ms)
Mar 23 00:26:14.054: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 9.247898ms)
Mar 23 00:26:14.054: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 9.764094ms)
Mar 23 00:26:14.054: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 9.172434ms)
Mar 23 00:26:14.054: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 9.988345ms)
Mar 23 00:26:14.054: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 10.260199ms)
Mar 23 00:26:14.054: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 10.002728ms)
Mar 23 00:26:14.054: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 10.144028ms)
Mar 23 00:26:14.054: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 9.863698ms)
Mar 23 00:26:14.054: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 10.17034ms)
Mar 23 00:26:14.055: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 10.805619ms)
Mar 23 00:26:14.055: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 10.060828ms)
Mar 23 00:26:14.055: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 10.112429ms)
Mar 23 00:26:14.055: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 10.809095ms)
Mar 23 00:26:14.062: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 7.185429ms)
Mar 23 00:26:14.062: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 7.276178ms)
Mar 23 00:26:14.063: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 7.562567ms)
Mar 23 00:26:14.063: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 7.434486ms)
Mar 23 00:26:14.063: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 7.477605ms)
Mar 23 00:26:14.063: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 7.681063ms)
Mar 23 00:26:14.063: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 7.700513ms)
Mar 23 00:26:14.063: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 7.75798ms)
Mar 23 00:26:14.063: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 7.867133ms)
Mar 23 00:26:14.063: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 7.796392ms)
Mar 23 00:26:14.065: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 9.772508ms)
Mar 23 00:26:14.065: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 10.107975ms)
Mar 23 00:26:14.066: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 10.388993ms)
Mar 23 00:26:14.066: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 10.686452ms)
Mar 23 00:26:14.066: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 10.256093ms)
Mar 23 00:26:14.066: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 11.281405ms)
Mar 23 00:26:14.076: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 8.970441ms)
Mar 23 00:26:14.076: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 8.98748ms)
Mar 23 00:26:14.076: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 9.31653ms)
Mar 23 00:26:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 9.848282ms)
Mar 23 00:26:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 9.41156ms)
Mar 23 00:26:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 10.316378ms)
Mar 23 00:26:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 10.24501ms)
Mar 23 00:26:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 9.867048ms)
Mar 23 00:26:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 10.148029ms)
Mar 23 00:26:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 9.517924ms)
Mar 23 00:26:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 10.195528ms)
Mar 23 00:26:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 10.810425ms)
Mar 23 00:26:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 10.431888ms)
Mar 23 00:26:14.078: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 10.32581ms)
Mar 23 00:26:14.078: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 10.816435ms)
Mar 23 00:26:14.078: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 10.197997ms)
Mar 23 00:26:14.082: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 4.645519ms)
Mar 23 00:26:14.083: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 5.206461ms)
Mar 23 00:26:14.084: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 5.817728ms)
Mar 23 00:26:14.085: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 6.824774ms)
Mar 23 00:26:14.086: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 7.287283ms)
Mar 23 00:26:14.086: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 8.027553ms)
Mar 23 00:26:14.087: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 8.90065ms)
Mar 23 00:26:14.087: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 8.889137ms)
Mar 23 00:26:14.087: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 9.130409ms)
Mar 23 00:26:14.087: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 9.42865ms)
Mar 23 00:26:14.088: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 9.430588ms)
Mar 23 00:26:14.088: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 9.150529ms)
Mar 23 00:26:14.088: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 9.399463ms)
Mar 23 00:26:14.088: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 9.660581ms)
Mar 23 00:26:14.089: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 10.574015ms)
Mar 23 00:26:14.090: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 11.572473ms)
Mar 23 00:26:14.098: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 8.101939ms)
Mar 23 00:26:14.100: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 9.901753ms)
Mar 23 00:26:14.100: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 10.031548ms)
Mar 23 00:26:14.100: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 9.628996ms)
Mar 23 00:26:14.100: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 9.938604ms)
Mar 23 00:26:14.100: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 9.821141ms)
Mar 23 00:26:14.101: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 9.982738ms)
Mar 23 00:26:14.101: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 10.663641ms)
Mar 23 00:26:14.101: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 10.397561ms)
Mar 23 00:26:14.101: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 10.941893ms)
Mar 23 00:26:14.101: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 10.861317ms)
Mar 23 00:26:14.101: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 11.268271ms)
Mar 23 00:26:14.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 10.743856ms)
Mar 23 00:26:14.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 11.312055ms)
Mar 23 00:26:14.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 10.987443ms)
Mar 23 00:26:14.102: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 11.310992ms)
Mar 23 00:26:14.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 5.157616ms)
Mar 23 00:26:14.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 5.13353ms)
Mar 23 00:26:14.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 5.386621ms)
Mar 23 00:26:14.108: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 5.982538ms)
Mar 23 00:26:14.108: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 5.876584ms)
Mar 23 00:26:14.108: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 5.755778ms)
Mar 23 00:26:14.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 8.423216ms)
Mar 23 00:26:14.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 8.605773ms)
Mar 23 00:26:14.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 9.286629ms)
Mar 23 00:26:14.112: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 9.515699ms)
Mar 23 00:26:14.113: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 10.605988ms)
Mar 23 00:26:14.113: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 11.021443ms)
Mar 23 00:26:14.114: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 11.417234ms)
Mar 23 00:26:14.114: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 11.206119ms)
Mar 23 00:26:14.114: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 11.573426ms)
Mar 23 00:26:14.114: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 11.665823ms)
Mar 23 00:26:14.119: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 5.199509ms)
Mar 23 00:26:14.120: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 5.222068ms)
Mar 23 00:26:14.120: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 5.295232ms)
Mar 23 00:26:14.120: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 6.244094ms)
Mar 23 00:26:14.121: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 6.103132ms)
Mar 23 00:26:14.121: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 6.737632ms)
Mar 23 00:26:14.121: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 7.007839ms)
Mar 23 00:26:14.122: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 7.578153ms)
Mar 23 00:26:14.122: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 7.602346ms)
Mar 23 00:26:14.122: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 7.835197ms)
Mar 23 00:26:14.123: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 8.293767ms)
Mar 23 00:26:14.125: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 10.424343ms)
Mar 23 00:26:14.125: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 11.12454ms)
Mar 23 00:26:14.126: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 11.964635ms)
Mar 23 00:26:14.126: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 12.035762ms)
Mar 23 00:26:14.127: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 12.585916ms)
Mar 23 00:26:14.132: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 5.317165ms)
Mar 23 00:26:14.135: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 7.696492ms)
Mar 23 00:26:14.135: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 8.398433ms)
Mar 23 00:26:14.135: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 8.494136ms)
Mar 23 00:26:14.136: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 8.063971ms)
Mar 23 00:26:14.136: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 7.825894ms)
Mar 23 00:26:14.136: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 8.062558ms)
Mar 23 00:26:14.136: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 8.268958ms)
Mar 23 00:26:14.136: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 8.600595ms)
Mar 23 00:26:14.136: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 8.003989ms)
Mar 23 00:26:14.137: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 9.269629ms)
Mar 23 00:26:14.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 11.646658ms)
Mar 23 00:26:14.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 12.010218ms)
Mar 23 00:26:14.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 12.449241ms)
Mar 23 00:26:14.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 12.636113ms)
Mar 23 00:26:14.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 12.521544ms)
Mar 23 00:26:14.146: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 6.05216ms)
Mar 23 00:26:14.146: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 6.588525ms)
Mar 23 00:26:14.147: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 6.520901ms)
Mar 23 00:26:14.147: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 7.14604ms)
Mar 23 00:26:14.148: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 8.189218ms)
Mar 23 00:26:14.148: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 8.007174ms)
Mar 23 00:26:14.149: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 8.333976ms)
Mar 23 00:26:14.149: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 8.47008ms)
Mar 23 00:26:14.149: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 8.371377ms)
Mar 23 00:26:14.150: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 8.751376ms)
Mar 23 00:26:14.150: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 9.106554ms)
Mar 23 00:26:14.152: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 11.359834ms)
Mar 23 00:26:14.152: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 11.673526ms)
Mar 23 00:26:14.152: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 11.781369ms)
Mar 23 00:26:14.152: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 11.956657ms)
Mar 23 00:26:14.152: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 12.001876ms)
Mar 23 00:26:14.157: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 4.801183ms)
Mar 23 00:26:14.158: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 4.87101ms)
Mar 23 00:26:14.158: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 4.959639ms)
Mar 23 00:26:14.158: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 5.111361ms)
Mar 23 00:26:14.161: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 8.568514ms)
Mar 23 00:26:14.162: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 8.675502ms)
Mar 23 00:26:14.162: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 9.543607ms)
Mar 23 00:26:14.162: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 9.503734ms)
Mar 23 00:26:14.163: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 9.543508ms)
Mar 23 00:26:14.163: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 9.80124ms)
Mar 23 00:26:14.163: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 10.942492ms)
Mar 23 00:26:14.164: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 10.759438ms)
Mar 23 00:26:14.164: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 11.574978ms)
Mar 23 00:26:14.164: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 11.470697ms)
Mar 23 00:26:14.165: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 12.01965ms)
Mar 23 00:26:14.165: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 12.498088ms)
Mar 23 00:26:14.170: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:443/proxy/... (200; 5.156536ms)
Mar 23 00:26:14.176: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:1080/proxy/... (200; 10.210201ms)
Mar 23 00:26:14.177: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:1080/proxy/rewri... (200; 10.797952ms)
Mar 23 00:26:14.177: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l/proxy/rewriteme"... (200; 11.626655ms)
Mar 23 00:26:14.177: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname1/proxy/: foo (200; 11.479343ms)
Mar 23 00:26:14.177: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 11.165397ms)
Mar 23 00:26:14.177: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/proxy-service-74pmq:portname2/proxy/: bar (200; 11.135534ms)
Mar 23 00:26:14.178: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname1/proxy/: tls baz (200; 11.688688ms)
Mar 23 00:26:14.178: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/https:proxy-service-74pmq:tlsportname2/proxy/: tls qux (200; 12.36726ms)
Mar 23 00:26:14.178: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:460/proxy/: tls baz (200; 11.867187ms)
Mar 23 00:26:14.178: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/http:proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 12.380911ms)
Mar 23 00:26:14.178: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/https:proxy-service-74pmq-4pb6l:462/proxy/: tls qux (200; 12.336507ms)
Mar 23 00:26:14.178: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname2/proxy/: bar (200; 12.235373ms)
Mar 23 00:26:14.178: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:160/proxy/: foo (200; 11.91689ms)
Mar 23 00:26:14.178: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/services/http:proxy-service-74pmq:portname1/proxy/: foo (200; 12.586394ms)
Mar 23 00:26:14.178: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-kg4xt/pods/proxy-service-74pmq-4pb6l:162/proxy/: bar (200; 12.095499ms)
STEP: deleting { ReplicationController} proxy-service-74pmq in namespace e2e-tests-proxy-kg4xt, will wait for the garbage collector to delete the pods
Mar 23 00:26:14.244: INFO: Deleting { ReplicationController} proxy-service-74pmq took: 12.919602ms
Mar 23 00:26:14.344: INFO: Terminating { ReplicationController} proxy-service-74pmq pods took: 100.225502ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:26:15.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-kg4xt" for this suite.
Mar 23 00:26:21.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:26:21.851: INFO: namespace: e2e-tests-proxy-kg4xt, resource: bindings, ignored listing per whitelist
Mar 23 00:26:21.853: INFO: namespace e2e-tests-proxy-kg4xt deletion completed in 6.10563831s

• [SLOW TEST:16.059 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:26:21.854: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:26:21.915: INFO: Waiting up to 5m0s for pod "downwardapi-volume-48dab44b-4d02-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-t4mgz" to be "success or failure"
Mar 23 00:26:21.918: INFO: Pod "downwardapi-volume-48dab44b-4d02-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.49882ms
Mar 23 00:26:23.921: INFO: Pod "downwardapi-volume-48dab44b-4d02-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006536671s
STEP: Saw pod success
Mar 23 00:26:23.921: INFO: Pod "downwardapi-volume-48dab44b-4d02-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:26:23.924: INFO: Trying to get logs from node node-2 pod downwardapi-volume-48dab44b-4d02-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:26:23.939: INFO: Waiting for pod downwardapi-volume-48dab44b-4d02-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:26:23.941: INFO: Pod downwardapi-volume-48dab44b-4d02-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:26:23.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t4mgz" for this suite.
Mar 23 00:26:29.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:26:29.998: INFO: namespace: e2e-tests-projected-t4mgz, resource: bindings, ignored listing per whitelist
Mar 23 00:26:30.024: INFO: namespace e2e-tests-projected-t4mgz deletion completed in 6.080092737s

• [SLOW TEST:8.171 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:26:30.025: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar 23 00:26:32.087: INFO: Pod pod-hostip-4db8c030-4d02-11e9-96f5-ea7d86f92d02 has hostIP: 172.31.45.82
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:26:32.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wmtph" for this suite.
Mar 23 00:26:54.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:26:54.158: INFO: namespace: e2e-tests-pods-wmtph, resource: bindings, ignored listing per whitelist
Mar 23 00:26:54.186: INFO: namespace e2e-tests-pods-wmtph deletion completed in 22.095229834s

• [SLOW TEST:24.161 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:26:54.186: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:27:00.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-bt96t" for this suite.
Mar 23 00:27:06.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:27:06.375: INFO: namespace: e2e-tests-namespaces-bt96t, resource: bindings, ignored listing per whitelist
Mar 23 00:27:06.389: INFO: namespace e2e-tests-namespaces-bt96t deletion completed in 6.088168395s
STEP: Destroying namespace "e2e-tests-nsdeletetest-pnbp4" for this suite.
Mar 23 00:27:06.391: INFO: Namespace e2e-tests-nsdeletetest-pnbp4 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-g5pnn" for this suite.
Mar 23 00:27:12.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:27:12.430: INFO: namespace: e2e-tests-nsdeletetest-g5pnn, resource: bindings, ignored listing per whitelist
Mar 23 00:27:12.480: INFO: namespace e2e-tests-nsdeletetest-g5pnn deletion completed in 6.089106382s

• [SLOW TEST:18.294 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:27:12.480: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 00:27:12.536: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:27:13.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-n5mtd" for this suite.
Mar 23 00:27:19.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:27:19.641: INFO: namespace: e2e-tests-custom-resource-definition-n5mtd, resource: bindings, ignored listing per whitelist
Mar 23 00:27:19.703: INFO: namespace e2e-tests-custom-resource-definition-n5mtd deletion completed in 6.094719572s

• [SLOW TEST:7.222 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:27:19.703: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 00:27:19.769: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"6b558262-4d02-11e9-9a5c-0646f33e71ba", Controller:(*bool)(0xc421d25cc6), BlockOwnerDeletion:(*bool)(0xc421d25cc7)}}
Mar 23 00:27:19.776: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6b54799f-4d02-11e9-9a5c-0646f33e71ba", Controller:(*bool)(0xc421d25ea6), BlockOwnerDeletion:(*bool)(0xc421d25ea7)}}
Mar 23 00:27:19.781: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"6b54f216-4d02-11e9-9a5c-0646f33e71ba", Controller:(*bool)(0xc4221f0c0a), BlockOwnerDeletion:(*bool)(0xc4221f0c0b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:27:24.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vjrhm" for this suite.
Mar 23 00:27:30.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:27:30.826: INFO: namespace: e2e-tests-gc-vjrhm, resource: bindings, ignored listing per whitelist
Mar 23 00:27:30.876: INFO: namespace e2e-tests-gc-vjrhm deletion completed in 6.081810349s

• [SLOW TEST:11.173 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:27:30.876: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 23 00:27:30.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-ppvx9'
Mar 23 00:27:31.015: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 23 00:27:31.015: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar 23 00:27:31.023: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-cxn4q]
Mar 23 00:27:31.023: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-cxn4q" in namespace "e2e-tests-kubectl-ppvx9" to be "running and ready"
Mar 23 00:27:31.026: INFO: Pod "e2e-test-nginx-rc-cxn4q": Phase="Pending", Reason="", readiness=false. Elapsed: 3.532095ms
Mar 23 00:27:33.029: INFO: Pod "e2e-test-nginx-rc-cxn4q": Phase="Running", Reason="", readiness=true. Elapsed: 2.006630956s
Mar 23 00:27:33.029: INFO: Pod "e2e-test-nginx-rc-cxn4q" satisfied condition "running and ready"
Mar 23 00:27:33.029: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-cxn4q]
Mar 23 00:27:33.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ppvx9'
Mar 23 00:27:33.125: INFO: stderr: ""
Mar 23 00:27:33.125: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Mar 23 00:27:33.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ppvx9'
Mar 23 00:27:33.217: INFO: stderr: ""
Mar 23 00:27:33.217: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:27:33.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ppvx9" for this suite.
Mar 23 00:27:55.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:27:55.282: INFO: namespace: e2e-tests-kubectl-ppvx9, resource: bindings, ignored listing per whitelist
Mar 23 00:27:55.308: INFO: namespace e2e-tests-kubectl-ppvx9 deletion completed in 22.086970773s

• [SLOW TEST:24.432 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:27:55.309: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 00:27:55.373: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Mar 23 00:27:55.377: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-sn6pb/daemonsets","resourceVersion":"7457"},"items":null}

Mar 23 00:27:55.379: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-sn6pb/pods","resourceVersion":"7457"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:27:55.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-sn6pb" for this suite.
Mar 23 00:28:01.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:28:01.474: INFO: namespace: e2e-tests-daemonsets-sn6pb, resource: bindings, ignored listing per whitelist
Mar 23 00:28:01.663: INFO: namespace e2e-tests-daemonsets-sn6pb deletion completed in 6.272792677s

S [SKIPPING] [6.355 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar 23 00:27:55.373: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:28:01.664: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-c5f4j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-c5f4j to expose endpoints map[]
Mar 23 00:28:01.735: INFO: Get endpoints failed (3.045053ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar 23 00:28:02.738: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-c5f4j exposes endpoints map[] (1.005876492s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-c5f4j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-c5f4j to expose endpoints map[pod1:[100]]
Mar 23 00:28:04.762: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-c5f4j exposes endpoints map[pod1:[100]] (2.017518405s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-c5f4j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-c5f4j to expose endpoints map[pod1:[100] pod2:[101]]
Mar 23 00:28:05.782: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-c5f4j exposes endpoints map[pod2:[101] pod1:[100]] (1.017047645s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-c5f4j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-c5f4j to expose endpoints map[pod2:[101]]
Mar 23 00:28:05.796: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-c5f4j exposes endpoints map[pod2:[101]] (7.596988ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-c5f4j
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-c5f4j to expose endpoints map[]
Mar 23 00:28:05.805: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-c5f4j exposes endpoints map[] (4.121207ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:28:05.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-c5f4j" for this suite.
Mar 23 00:28:23.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:28:23.896: INFO: namespace: e2e-tests-services-c5f4j, resource: bindings, ignored listing per whitelist
Mar 23 00:28:23.926: INFO: namespace e2e-tests-services-c5f4j deletion completed in 18.10185287s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:22.262 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:28:23.926: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 23 00:28:23.978: INFO: namespace e2e-tests-kubectl-s542n
Mar 23 00:28:23.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-s542n'
Mar 23 00:28:24.174: INFO: stderr: ""
Mar 23 00:28:24.174: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 23 00:28:25.177: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 00:28:25.177: INFO: Found 0 / 1
Mar 23 00:28:26.177: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 00:28:26.177: INFO: Found 1 / 1
Mar 23 00:28:26.177: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 23 00:28:26.180: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 00:28:26.180: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 23 00:28:26.180: INFO: wait on redis-master startup in e2e-tests-kubectl-s542n 
Mar 23 00:28:26.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 logs redis-master-v78gn redis-master --namespace=e2e-tests-kubectl-s542n'
Mar 23 00:28:26.268: INFO: stderr: ""
Mar 23 00:28:26.268: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 23 Mar 00:28:24.981 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 23 Mar 00:28:24.981 # Server started, Redis version 3.2.12\n1:M 23 Mar 00:28:24.981 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 23 Mar 00:28:24.981 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar 23 00:28:26.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-s542n'
Mar 23 00:28:26.365: INFO: stderr: ""
Mar 23 00:28:26.365: INFO: stdout: "service/rm2 exposed\n"
Mar 23 00:28:26.369: INFO: Service rm2 in namespace e2e-tests-kubectl-s542n found.
STEP: exposing service
Mar 23 00:28:28.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-s542n'
Mar 23 00:28:28.463: INFO: stderr: ""
Mar 23 00:28:28.463: INFO: stdout: "service/rm3 exposed\n"
Mar 23 00:28:28.467: INFO: Service rm3 in namespace e2e-tests-kubectl-s542n found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:28:30.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s542n" for this suite.
Mar 23 00:28:52.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:28:52.530: INFO: namespace: e2e-tests-kubectl-s542n, resource: bindings, ignored listing per whitelist
Mar 23 00:28:52.560: INFO: namespace e2e-tests-kubectl-s542n deletion completed in 22.084002131s

• [SLOW TEST:28.634 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:28:52.560: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:28:52.617: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2ae7720-4d02-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-d79w6" to be "success or failure"
Mar 23 00:28:52.619: INFO: Pod "downwardapi-volume-a2ae7720-4d02-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.729592ms
Mar 23 00:28:54.622: INFO: Pod "downwardapi-volume-a2ae7720-4d02-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005645389s
STEP: Saw pod success
Mar 23 00:28:54.622: INFO: Pod "downwardapi-volume-a2ae7720-4d02-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:28:54.624: INFO: Trying to get logs from node node-2 pod downwardapi-volume-a2ae7720-4d02-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:28:54.640: INFO: Waiting for pod downwardapi-volume-a2ae7720-4d02-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:28:54.642: INFO: Pod downwardapi-volume-a2ae7720-4d02-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:28:54.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d79w6" for this suite.
Mar 23 00:29:00.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:29:00.684: INFO: namespace: e2e-tests-downward-api-d79w6, resource: bindings, ignored listing per whitelist
Mar 23 00:29:00.725: INFO: namespace e2e-tests-downward-api-d79w6 deletion completed in 6.080213789s

• [SLOW TEST:8.165 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:29:00.725: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:29:00.791: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a78da9de-4d02-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-tpn8g" to be "success or failure"
Mar 23 00:29:00.797: INFO: Pod "downwardapi-volume-a78da9de-4d02-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 6.109594ms
Mar 23 00:29:02.800: INFO: Pod "downwardapi-volume-a78da9de-4d02-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009003653s
STEP: Saw pod success
Mar 23 00:29:02.800: INFO: Pod "downwardapi-volume-a78da9de-4d02-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:29:02.802: INFO: Trying to get logs from node node-2 pod downwardapi-volume-a78da9de-4d02-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:29:02.820: INFO: Waiting for pod downwardapi-volume-a78da9de-4d02-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:29:02.822: INFO: Pod downwardapi-volume-a78da9de-4d02-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:29:02.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tpn8g" for this suite.
Mar 23 00:29:08.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:29:08.897: INFO: namespace: e2e-tests-downward-api-tpn8g, resource: bindings, ignored listing per whitelist
Mar 23 00:29:08.907: INFO: namespace e2e-tests-downward-api-tpn8g deletion completed in 6.081380817s

• [SLOW TEST:8.182 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:29:08.907: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar 23 00:29:09.471: INFO: Waiting up to 5m0s for pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p922v" in namespace "e2e-tests-svcaccounts-lmzks" to be "success or failure"
Mar 23 00:29:09.476: INFO: Pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p922v": Phase="Pending", Reason="", readiness=false. Elapsed: 5.386096ms
Mar 23 00:29:11.480: INFO: Pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p922v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008549976s
STEP: Saw pod success
Mar 23 00:29:11.480: INFO: Pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p922v" satisfied condition "success or failure"
Mar 23 00:29:11.482: INFO: Trying to get logs from node node-2 pod pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p922v container token-test: <nil>
STEP: delete the pod
Mar 23 00:29:11.499: INFO: Waiting for pod pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p922v to disappear
Mar 23 00:29:11.501: INFO: Pod pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p922v no longer exists
STEP: Creating a pod to test consume service account root CA
Mar 23 00:29:11.504: INFO: Waiting up to 5m0s for pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-x9swj" in namespace "e2e-tests-svcaccounts-lmzks" to be "success or failure"
Mar 23 00:29:11.506: INFO: Pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-x9swj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.170011ms
Mar 23 00:29:13.509: INFO: Pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-x9swj": Phase="Running", Reason="", readiness=false. Elapsed: 2.00507972s
Mar 23 00:29:15.514: INFO: Pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-x9swj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009658229s
STEP: Saw pod success
Mar 23 00:29:15.514: INFO: Pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-x9swj" satisfied condition "success or failure"
Mar 23 00:29:15.516: INFO: Trying to get logs from node node-2 pod pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-x9swj container root-ca-test: <nil>
STEP: delete the pod
Mar 23 00:29:15.534: INFO: Waiting for pod pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-x9swj to disappear
Mar 23 00:29:15.536: INFO: Pod pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-x9swj no longer exists
STEP: Creating a pod to test consume service account namespace
Mar 23 00:29:15.540: INFO: Waiting up to 5m0s for pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p9pjh" in namespace "e2e-tests-svcaccounts-lmzks" to be "success or failure"
Mar 23 00:29:15.543: INFO: Pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p9pjh": Phase="Pending", Reason="", readiness=false. Elapsed: 3.127379ms
Mar 23 00:29:17.546: INFO: Pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p9pjh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006135438s
STEP: Saw pod success
Mar 23 00:29:17.546: INFO: Pod "pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p9pjh" satisfied condition "success or failure"
Mar 23 00:29:17.549: INFO: Trying to get logs from node node-2 pod pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p9pjh container namespace-test: <nil>
STEP: delete the pod
Mar 23 00:29:17.565: INFO: Waiting for pod pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p9pjh to disappear
Mar 23 00:29:17.567: INFO: Pod pod-service-account-acb9f441-4d02-11e9-96f5-ea7d86f92d02-p9pjh no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:29:17.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-lmzks" for this suite.
Mar 23 00:29:23.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:29:23.631: INFO: namespace: e2e-tests-svcaccounts-lmzks, resource: bindings, ignored listing per whitelist
Mar 23 00:29:23.657: INFO: namespace e2e-tests-svcaccounts-lmzks deletion completed in 6.086860277s

• [SLOW TEST:14.750 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:29:23.658: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:29:23.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b5377003-4d02-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-x7d2q" to be "success or failure"
Mar 23 00:29:23.718: INFO: Pod "downwardapi-volume-b5377003-4d02-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.413795ms
Mar 23 00:29:25.721: INFO: Pod "downwardapi-volume-b5377003-4d02-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006238831s
STEP: Saw pod success
Mar 23 00:29:25.721: INFO: Pod "downwardapi-volume-b5377003-4d02-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:29:25.723: INFO: Trying to get logs from node node-2 pod downwardapi-volume-b5377003-4d02-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:29:25.939: INFO: Waiting for pod downwardapi-volume-b5377003-4d02-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:29:25.941: INFO: Pod downwardapi-volume-b5377003-4d02-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:29:25.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x7d2q" for this suite.
Mar 23 00:29:31.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:29:31.959: INFO: namespace: e2e-tests-downward-api-x7d2q, resource: bindings, ignored listing per whitelist
Mar 23 00:29:32.028: INFO: namespace e2e-tests-downward-api-x7d2q deletion completed in 6.083926881s

• [SLOW TEST:8.370 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:29:32.028: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-2vbs8
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 23 00:29:32.129: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 23 00:29:54.210: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.42.1.28:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-2vbs8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:29:54.210: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:29:54.279: INFO: Found all expected endpoints: [netserver-0]
Mar 23 00:29:54.282: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.42.0.21:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-2vbs8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:29:54.282: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:29:54.348: INFO: Found all expected endpoints: [netserver-1]
Mar 23 00:29:54.350: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.42.2.88:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-2vbs8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 23 00:29:54.350: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
Mar 23 00:29:54.415: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:29:54.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-2vbs8" for this suite.
Mar 23 00:30:16.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:30:16.444: INFO: namespace: e2e-tests-pod-network-test-2vbs8, resource: bindings, ignored listing per whitelist
Mar 23 00:30:16.499: INFO: namespace e2e-tests-pod-network-test-2vbs8 deletion completed in 22.080152838s

• [SLOW TEST:44.471 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:30:16.499: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 23 00:30:16.556: INFO: Waiting up to 5m0s for pod "pod-d4b6a198-4d02-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-68hlm" to be "success or failure"
Mar 23 00:30:16.559: INFO: Pod "pod-d4b6a198-4d02-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.171533ms
Mar 23 00:30:18.562: INFO: Pod "pod-d4b6a198-4d02-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006359438s
STEP: Saw pod success
Mar 23 00:30:18.562: INFO: Pod "pod-d4b6a198-4d02-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:30:18.564: INFO: Trying to get logs from node node-2 pod pod-d4b6a198-4d02-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 00:30:18.579: INFO: Waiting for pod pod-d4b6a198-4d02-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:30:18.581: INFO: Pod pod-d4b6a198-4d02-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:30:18.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-68hlm" for this suite.
Mar 23 00:30:24.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:30:24.655: INFO: namespace: e2e-tests-emptydir-68hlm, resource: bindings, ignored listing per whitelist
Mar 23 00:30:24.672: INFO: namespace e2e-tests-emptydir-68hlm deletion completed in 6.087585272s

• [SLOW TEST:8.173 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:30:24.672: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar 23 00:30:24.746: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-ckcfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-ckcfp/configmaps/e2e-watch-test-resource-version,UID:d995779e-4d02-11e9-9a5c-0646f33e71ba,ResourceVersion:8086,Generation:0,CreationTimestamp:2019-03-23 00:30:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 23 00:30:24.746: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-ckcfp,SelfLink:/api/v1/namespaces/e2e-tests-watch-ckcfp/configmaps/e2e-watch-test-resource-version,UID:d995779e-4d02-11e9-9a5c-0646f33e71ba,ResourceVersion:8087,Generation:0,CreationTimestamp:2019-03-23 00:30:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:30:24.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ckcfp" for this suite.
Mar 23 00:30:30.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:30:30.768: INFO: namespace: e2e-tests-watch-ckcfp, resource: bindings, ignored listing per whitelist
Mar 23 00:30:30.834: INFO: namespace e2e-tests-watch-ckcfp deletion completed in 6.083137927s

• [SLOW TEST:6.161 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:30:30.834: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:30:30.892: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd42120c-4d02-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-6l857" to be "success or failure"
Mar 23 00:30:30.895: INFO: Pod "downwardapi-volume-dd42120c-4d02-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058476ms
Mar 23 00:30:32.898: INFO: Pod "downwardapi-volume-dd42120c-4d02-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005015434s
STEP: Saw pod success
Mar 23 00:30:32.898: INFO: Pod "downwardapi-volume-dd42120c-4d02-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:30:32.900: INFO: Trying to get logs from node node-2 pod downwardapi-volume-dd42120c-4d02-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:30:32.916: INFO: Waiting for pod downwardapi-volume-dd42120c-4d02-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:30:32.918: INFO: Pod downwardapi-volume-dd42120c-4d02-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:30:32.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6l857" for this suite.
Mar 23 00:30:38.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:30:38.974: INFO: namespace: e2e-tests-projected-6l857, resource: bindings, ignored listing per whitelist
Mar 23 00:30:39.009: INFO: namespace e2e-tests-projected-6l857 deletion completed in 6.08701233s

• [SLOW TEST:8.175 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:30:39.009: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e22133ee-4d02-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 00:30:39.069: INFO: Waiting up to 5m0s for pod "pod-secrets-e2219858-4d02-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-secrets-gnjxr" to be "success or failure"
Mar 23 00:30:39.074: INFO: Pod "pod-secrets-e2219858-4d02-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.591254ms
Mar 23 00:30:41.077: INFO: Pod "pod-secrets-e2219858-4d02-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007567357s
STEP: Saw pod success
Mar 23 00:30:41.077: INFO: Pod "pod-secrets-e2219858-4d02-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:30:41.079: INFO: Trying to get logs from node node-2 pod pod-secrets-e2219858-4d02-11e9-96f5-ea7d86f92d02 container secret-volume-test: <nil>
STEP: delete the pod
Mar 23 00:30:41.094: INFO: Waiting for pod pod-secrets-e2219858-4d02-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:30:41.096: INFO: Pod pod-secrets-e2219858-4d02-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:30:41.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gnjxr" for this suite.
Mar 23 00:30:47.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:30:47.180: INFO: namespace: e2e-tests-secrets-gnjxr, resource: bindings, ignored listing per whitelist
Mar 23 00:30:47.200: INFO: namespace e2e-tests-secrets-gnjxr deletion completed in 6.101435423s

• [SLOW TEST:8.192 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:30:47.201: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e703ada6-4d02-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 00:30:47.263: INFO: Waiting up to 5m0s for pod "pod-secrets-e7042068-4d02-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-secrets-f7z4n" to be "success or failure"
Mar 23 00:30:47.267: INFO: Pod "pod-secrets-e7042068-4d02-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.165949ms
Mar 23 00:30:49.270: INFO: Pod "pod-secrets-e7042068-4d02-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007095546s
STEP: Saw pod success
Mar 23 00:30:49.270: INFO: Pod "pod-secrets-e7042068-4d02-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:30:49.272: INFO: Trying to get logs from node node-2 pod pod-secrets-e7042068-4d02-11e9-96f5-ea7d86f92d02 container secret-env-test: <nil>
STEP: delete the pod
Mar 23 00:30:49.286: INFO: Waiting for pod pod-secrets-e7042068-4d02-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:30:49.288: INFO: Pod pod-secrets-e7042068-4d02-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:30:49.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-f7z4n" for this suite.
Mar 23 00:30:55.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:30:55.330: INFO: namespace: e2e-tests-secrets-f7z4n, resource: bindings, ignored listing per whitelist
Mar 23 00:30:55.384: INFO: namespace e2e-tests-secrets-f7z4n deletion completed in 6.092927338s

• [SLOW TEST:8.184 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:30:55.384: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 00:30:55.443: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar 23 00:30:55.452: INFO: Number of nodes with available pods: 0
Mar 23 00:30:55.452: INFO: Node node-1 is running more than one daemon pod
Mar 23 00:30:56.458: INFO: Number of nodes with available pods: 3
Mar 23 00:30:56.458: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar 23 00:30:56.478: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:30:56.478: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:30:56.478: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:30:57.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:30:57.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:30:57.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:30:58.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:30:58.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:30:58.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:30:59.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:30:59.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:30:59.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:00.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:00.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:00.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:01.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:01.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:01.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:02.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:02.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:02.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:03.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:03.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:03.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:04.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:04.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:04.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:05.488: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:05.488: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:05.488: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:06.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:06.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:06.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:07.498: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:07.498: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:07.498: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:08.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:08.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:08.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:09.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:09.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:09.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:10.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:10.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:10.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:11.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:11.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:11.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:12.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:12.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:12.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:13.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:13.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:13.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:14.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:14.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:14.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:15.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:15.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:15.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:16.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:16.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:16.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:17.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:17.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:17.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:18.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:18.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:18.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:19.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:19.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:19.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:20.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:20.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:20.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:21.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:21.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:21.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:22.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:22.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:22.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:23.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:23.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:23.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:24.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:24.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:24.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:25.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:25.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:25.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:26.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:26.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:26.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:27.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:27.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:27.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:28.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:28.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:28.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:29.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:29.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:29.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:30.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:30.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:30.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:30.487: INFO: Pod daemon-set-fv5vb is not available
Mar 23 00:31:31.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:31.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:31.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:31.487: INFO: Pod daemon-set-fv5vb is not available
Mar 23 00:31:32.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:32.488: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:32.488: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:32.488: INFO: Pod daemon-set-fv5vb is not available
Mar 23 00:31:33.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:33.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:33.487: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:33.487: INFO: Pod daemon-set-fv5vb is not available
Mar 23 00:31:34.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:34.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:34.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:34.486: INFO: Pod daemon-set-fv5vb is not available
Mar 23 00:31:35.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:35.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:35.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:35.486: INFO: Pod daemon-set-fv5vb is not available
Mar 23 00:31:36.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:36.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:36.486: INFO: Wrong image for pod: daemon-set-fv5vb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:36.486: INFO: Pod daemon-set-fv5vb is not available
Mar 23 00:31:37.488: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:37.488: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:37.488: INFO: Pod daemon-set-gznw4 is not available
Mar 23 00:31:38.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:38.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:38.486: INFO: Pod daemon-set-gznw4 is not available
Mar 23 00:31:39.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:39.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:39.486: INFO: Pod daemon-set-gznw4 is not available
Mar 23 00:31:40.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:40.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:41.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:41.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:42.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:42.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:43.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:43.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:44.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:44.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:45.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:45.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:46.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:46.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:47.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:47.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:48.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:48.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:49.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:49.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:50.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:50.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:51.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:51.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:52.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:52.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:53.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:53.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:54.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:54.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:55.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:55.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:56.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:56.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:57.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:57.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:58.493: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:58.493: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:59.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:31:59.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:00.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:00.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:01.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:01.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:02.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:02.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:03.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:03.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:04.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:04.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:05.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:05.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:06.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:06.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:07.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:07.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:08.486: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:08.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:09.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:09.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:10.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:10.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:11.487: INFO: Wrong image for pod: daemon-set-b8rjd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:11.487: INFO: Pod daemon-set-b8rjd is not available
Mar 23 00:32:11.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:12.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:12.487: INFO: Pod daemon-set-gc57d is not available
Mar 23 00:32:13.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:13.487: INFO: Pod daemon-set-gc57d is not available
Mar 23 00:32:14.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:14.487: INFO: Pod daemon-set-gc57d is not available
Mar 23 00:32:15.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:16.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:17.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:18.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:19.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:20.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:21.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:22.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:23.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:24.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:25.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:26.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:27.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:28.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:29.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:30.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:31.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:32.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:33.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:34.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:35.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:36.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:37.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:38.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:39.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:40.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:41.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:42.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:43.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:44.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:45.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:46.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:46.487: INFO: Pod daemon-set-bmbdd is not available
Mar 23 00:32:47.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:47.486: INFO: Pod daemon-set-bmbdd is not available
Mar 23 00:32:48.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:48.487: INFO: Pod daemon-set-bmbdd is not available
Mar 23 00:32:49.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:49.486: INFO: Pod daemon-set-bmbdd is not available
Mar 23 00:32:50.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:50.487: INFO: Pod daemon-set-bmbdd is not available
Mar 23 00:32:51.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:51.486: INFO: Pod daemon-set-bmbdd is not available
Mar 23 00:32:52.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:52.487: INFO: Pod daemon-set-bmbdd is not available
Mar 23 00:32:53.487: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:53.487: INFO: Pod daemon-set-bmbdd is not available
Mar 23 00:32:54.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:54.486: INFO: Pod daemon-set-bmbdd is not available
Mar 23 00:32:55.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:55.486: INFO: Pod daemon-set-bmbdd is not available
Mar 23 00:32:56.486: INFO: Wrong image for pod: daemon-set-bmbdd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 23 00:32:56.486: INFO: Pod daemon-set-bmbdd is not available
Mar 23 00:32:57.497: INFO: Pod daemon-set-hhxpt is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar 23 00:32:57.505: INFO: Number of nodes with available pods: 2
Mar 23 00:32:57.505: INFO: Node node-2 is running more than one daemon pod
Mar 23 00:32:58.512: INFO: Number of nodes with available pods: 2
Mar 23 00:32:58.512: INFO: Node node-2 is running more than one daemon pod
Mar 23 00:32:59.512: INFO: Number of nodes with available pods: 3
Mar 23 00:32:59.512: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-8v9ws, will wait for the garbage collector to delete the pods
Mar 23 00:32:59.587: INFO: Deleting {extensions DaemonSet} daemon-set took: 10.712295ms
Mar 23 00:32:59.687: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.23546ms
Mar 23 00:33:11.690: INFO: Number of nodes with available pods: 0
Mar 23 00:33:11.690: INFO: Number of running nodes: 0, number of available pods: 0
Mar 23 00:33:11.693: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8v9ws/daemonsets","resourceVersion":"8547"},"items":null}

Mar 23 00:33:11.695: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8v9ws/pods","resourceVersion":"8547"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:33:11.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8v9ws" for this suite.
Mar 23 00:33:17.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:33:17.762: INFO: namespace: e2e-tests-daemonsets-8v9ws, resource: bindings, ignored listing per whitelist
Mar 23 00:33:17.801: INFO: namespace e2e-tests-daemonsets-8v9ws deletion completed in 6.091975414s

• [SLOW TEST:142.416 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:33:17.801: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-40ca23ab-4d03-11e9-96f5-ea7d86f92d02
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-40ca23ab-4d03-11e9-96f5-ea7d86f92d02
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:33:21.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4qd4g" for this suite.
Mar 23 00:33:43.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:33:43.961: INFO: namespace: e2e-tests-projected-4qd4g, resource: bindings, ignored listing per whitelist
Mar 23 00:33:43.995: INFO: namespace e2e-tests-projected-4qd4g deletion completed in 22.08178858s

• [SLOW TEST:26.195 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:33:43.995: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar 23 00:33:44.056: INFO: Waiting up to 5m0s for pod "var-expansion-50645e96-4d03-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-var-expansion-mgwlf" to be "success or failure"
Mar 23 00:33:44.059: INFO: Pod "var-expansion-50645e96-4d03-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.66407ms
Mar 23 00:33:46.062: INFO: Pod "var-expansion-50645e96-4d03-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00558618s
STEP: Saw pod success
Mar 23 00:33:46.062: INFO: Pod "var-expansion-50645e96-4d03-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:33:46.064: INFO: Trying to get logs from node node-2 pod var-expansion-50645e96-4d03-11e9-96f5-ea7d86f92d02 container dapi-container: <nil>
STEP: delete the pod
Mar 23 00:33:46.080: INFO: Waiting for pod var-expansion-50645e96-4d03-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:33:46.082: INFO: Pod var-expansion-50645e96-4d03-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:33:46.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-mgwlf" for this suite.
Mar 23 00:33:52.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:33:52.103: INFO: namespace: e2e-tests-var-expansion-mgwlf, resource: bindings, ignored listing per whitelist
Mar 23 00:33:52.167: INFO: namespace e2e-tests-var-expansion-mgwlf deletion completed in 6.082339299s

• [SLOW TEST:8.171 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:33:52.167: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-rmjk
STEP: Creating a pod to test atomic-volume-subpath
Mar 23 00:33:52.227: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rmjk" in namespace "e2e-tests-subpath-hzb4r" to be "success or failure"
Mar 23 00:33:52.231: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.395319ms
Mar 23 00:33:54.234: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Running", Reason="", readiness=false. Elapsed: 2.006132734s
Mar 23 00:33:56.237: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Running", Reason="", readiness=false. Elapsed: 4.009420154s
Mar 23 00:33:58.240: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Running", Reason="", readiness=false. Elapsed: 6.012540174s
Mar 23 00:34:00.243: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Running", Reason="", readiness=false. Elapsed: 8.015530058s
Mar 23 00:34:02.246: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Running", Reason="", readiness=false. Elapsed: 10.018549725s
Mar 23 00:34:04.249: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Running", Reason="", readiness=false. Elapsed: 12.021922705s
Mar 23 00:34:06.290: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Running", Reason="", readiness=false. Elapsed: 14.062754132s
Mar 23 00:34:08.294: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Running", Reason="", readiness=false. Elapsed: 16.066398295s
Mar 23 00:34:10.297: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Running", Reason="", readiness=false. Elapsed: 18.069325707s
Mar 23 00:34:12.300: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Running", Reason="", readiness=false. Elapsed: 20.072401973s
Mar 23 00:34:14.303: INFO: Pod "pod-subpath-test-configmap-rmjk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.075339346s
STEP: Saw pod success
Mar 23 00:34:14.303: INFO: Pod "pod-subpath-test-configmap-rmjk" satisfied condition "success or failure"
Mar 23 00:34:14.305: INFO: Trying to get logs from node node-3 pod pod-subpath-test-configmap-rmjk container test-container-subpath-configmap-rmjk: <nil>
STEP: delete the pod
Mar 23 00:34:14.321: INFO: Waiting for pod pod-subpath-test-configmap-rmjk to disappear
Mar 23 00:34:14.324: INFO: Pod pod-subpath-test-configmap-rmjk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rmjk
Mar 23 00:34:14.324: INFO: Deleting pod "pod-subpath-test-configmap-rmjk" in namespace "e2e-tests-subpath-hzb4r"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:34:14.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hzb4r" for this suite.
Mar 23 00:34:20.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:34:20.412: INFO: namespace: e2e-tests-subpath-hzb4r, resource: bindings, ignored listing per whitelist
Mar 23 00:34:20.416: INFO: namespace e2e-tests-subpath-hzb4r deletion completed in 6.084902036s

• [SLOW TEST:28.248 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:34:20.416: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 23 00:34:20.468: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:34:24.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-ps77t" for this suite.
Mar 23 00:34:46.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:34:46.308: INFO: namespace: e2e-tests-init-container-ps77t, resource: bindings, ignored listing per whitelist
Mar 23 00:34:46.314: INFO: namespace e2e-tests-init-container-ps77t deletion completed in 22.081544781s

• [SLOW TEST:25.898 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:34:46.314: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 00:34:46.373: INFO: (0) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.528626ms)
Mar 23 00:34:46.376: INFO: (1) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.563061ms)
Mar 23 00:34:46.378: INFO: (2) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.532815ms)
Mar 23 00:34:46.381: INFO: (3) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.555871ms)
Mar 23 00:34:46.383: INFO: (4) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.49189ms)
Mar 23 00:34:46.386: INFO: (5) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.434013ms)
Mar 23 00:34:46.388: INFO: (6) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.384999ms)
Mar 23 00:34:46.391: INFO: (7) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.478647ms)
Mar 23 00:34:46.393: INFO: (8) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.517338ms)
Mar 23 00:34:46.396: INFO: (9) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.427234ms)
Mar 23 00:34:46.398: INFO: (10) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.532708ms)
Mar 23 00:34:46.401: INFO: (11) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.385643ms)
Mar 23 00:34:46.403: INFO: (12) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.511451ms)
Mar 23 00:34:46.407: INFO: (13) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.762163ms)
Mar 23 00:34:46.409: INFO: (14) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.445007ms)
Mar 23 00:34:46.412: INFO: (15) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.580934ms)
Mar 23 00:34:46.415: INFO: (16) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.520967ms)
Mar 23 00:34:46.417: INFO: (17) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.485802ms)
Mar 23 00:34:46.420: INFO: (18) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.407769ms)
Mar 23 00:34:46.422: INFO: (19) /api/v1/nodes/node-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.497086ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:34:46.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-6527x" for this suite.
Mar 23 00:34:52.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:34:52.506: INFO: namespace: e2e-tests-proxy-6527x, resource: bindings, ignored listing per whitelist
Mar 23 00:34:52.512: INFO: namespace e2e-tests-proxy-6527x deletion completed in 6.08641176s

• [SLOW TEST:6.198 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:34:52.512: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:35:52.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gvpvx" for this suite.
Mar 23 00:36:14.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:36:14.601: INFO: namespace: e2e-tests-container-probe-gvpvx, resource: bindings, ignored listing per whitelist
Mar 23 00:36:14.665: INFO: namespace e2e-tests-container-probe-gvpvx deletion completed in 22.083701879s

• [SLOW TEST:82.154 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:36:14.666: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-aa3301f5-4d03-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 00:36:14.729: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aa337314-4d03-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-525rp" to be "success or failure"
Mar 23 00:36:14.732: INFO: Pod "pod-projected-secrets-aa337314-4d03-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.853214ms
Mar 23 00:36:16.735: INFO: Pod "pod-projected-secrets-aa337314-4d03-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005842337s
STEP: Saw pod success
Mar 23 00:36:16.735: INFO: Pod "pod-projected-secrets-aa337314-4d03-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:36:16.737: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-aa337314-4d03-11e9-96f5-ea7d86f92d02 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 23 00:36:16.752: INFO: Waiting for pod pod-projected-secrets-aa337314-4d03-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:36:16.754: INFO: Pod pod-projected-secrets-aa337314-4d03-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:36:16.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-525rp" for this suite.
Mar 23 00:36:22.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:36:22.791: INFO: namespace: e2e-tests-projected-525rp, resource: bindings, ignored listing per whitelist
Mar 23 00:36:22.843: INFO: namespace e2e-tests-projected-525rp deletion completed in 6.085974814s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:36:22.843: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-af122b4d-4d03-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 00:36:22.902: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-af128a03-4d03-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-4j4kv" to be "success or failure"
Mar 23 00:36:22.906: INFO: Pod "pod-projected-configmaps-af128a03-4d03-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.742114ms
Mar 23 00:36:24.909: INFO: Pod "pod-projected-configmaps-af128a03-4d03-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007827716s
STEP: Saw pod success
Mar 23 00:36:24.910: INFO: Pod "pod-projected-configmaps-af128a03-4d03-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:36:24.912: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-af128a03-4d03-11e9-96f5-ea7d86f92d02 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 23 00:36:24.927: INFO: Waiting for pod pod-projected-configmaps-af128a03-4d03-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:36:24.929: INFO: Pod pod-projected-configmaps-af128a03-4d03-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:36:24.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4j4kv" for this suite.
Mar 23 00:36:30.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:36:30.971: INFO: namespace: e2e-tests-projected-4j4kv, resource: bindings, ignored listing per whitelist
Mar 23 00:36:31.024: INFO: namespace e2e-tests-projected-4j4kv deletion completed in 6.09104434s

• [SLOW TEST:8.181 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:36:31.024: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b3f3325d-4d03-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 00:36:31.092: INFO: Waiting up to 5m0s for pod "pod-secrets-b3f3a04c-4d03-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-secrets-wv8cg" to be "success or failure"
Mar 23 00:36:31.096: INFO: Pod "pod-secrets-b3f3a04c-4d03-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.748111ms
Mar 23 00:36:33.098: INFO: Pod "pod-secrets-b3f3a04c-4d03-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006560598s
STEP: Saw pod success
Mar 23 00:36:33.098: INFO: Pod "pod-secrets-b3f3a04c-4d03-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:36:33.100: INFO: Trying to get logs from node node-2 pod pod-secrets-b3f3a04c-4d03-11e9-96f5-ea7d86f92d02 container secret-volume-test: <nil>
STEP: delete the pod
Mar 23 00:36:33.115: INFO: Waiting for pod pod-secrets-b3f3a04c-4d03-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:36:33.118: INFO: Pod pod-secrets-b3f3a04c-4d03-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:36:33.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wv8cg" for this suite.
Mar 23 00:36:39.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:36:39.178: INFO: namespace: e2e-tests-secrets-wv8cg, resource: bindings, ignored listing per whitelist
Mar 23 00:36:39.203: INFO: namespace e2e-tests-secrets-wv8cg deletion completed in 6.082148989s

• [SLOW TEST:8.179 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:36:39.203: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar 23 00:36:39.262: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-fqs8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fqs8t/configmaps/e2e-watch-test-watch-closed,UID:b8d1256f-4d03-11e9-9a5c-0646f33e71ba,ResourceVersion:9183,Generation:0,CreationTimestamp:2019-03-23 00:36:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 23 00:36:39.262: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-fqs8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fqs8t/configmaps/e2e-watch-test-watch-closed,UID:b8d1256f-4d03-11e9-9a5c-0646f33e71ba,ResourceVersion:9184,Generation:0,CreationTimestamp:2019-03-23 00:36:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 23 00:36:39.272: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-fqs8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fqs8t/configmaps/e2e-watch-test-watch-closed,UID:b8d1256f-4d03-11e9-9a5c-0646f33e71ba,ResourceVersion:9185,Generation:0,CreationTimestamp:2019-03-23 00:36:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 23 00:36:39.272: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-fqs8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-fqs8t/configmaps/e2e-watch-test-watch-closed,UID:b8d1256f-4d03-11e9-9a5c-0646f33e71ba,ResourceVersion:9186,Generation:0,CreationTimestamp:2019-03-23 00:36:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:36:39.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fqs8t" for this suite.
Mar 23 00:36:45.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:36:45.295: INFO: namespace: e2e-tests-watch-fqs8t, resource: bindings, ignored listing per whitelist
Mar 23 00:36:45.357: INFO: namespace e2e-tests-watch-fqs8t deletion completed in 6.082068743s

• [SLOW TEST:6.154 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:36:45.357: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0323 00:37:25.636292      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 23 00:37:25.636: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:37:25.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2ldq7" for this suite.
Mar 23 00:37:31.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:37:31.682: INFO: namespace: e2e-tests-gc-2ldq7, resource: bindings, ignored listing per whitelist
Mar 23 00:37:31.741: INFO: namespace e2e-tests-gc-2ldq7 deletion completed in 6.10228669s

• [SLOW TEST:46.384 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:37:31.741: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 23 00:37:31.804: INFO: Waiting up to 5m0s for pod "pod-d8241ac3-4d03-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-t84c9" to be "success or failure"
Mar 23 00:37:31.807: INFO: Pod "pod-d8241ac3-4d03-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.518875ms
Mar 23 00:37:33.810: INFO: Pod "pod-d8241ac3-4d03-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006547738s
Mar 23 00:37:35.814: INFO: Pod "pod-d8241ac3-4d03-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010366217s
STEP: Saw pod success
Mar 23 00:37:35.814: INFO: Pod "pod-d8241ac3-4d03-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:37:35.816: INFO: Trying to get logs from node node-2 pod pod-d8241ac3-4d03-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 00:37:35.833: INFO: Waiting for pod pod-d8241ac3-4d03-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:37:35.835: INFO: Pod pod-d8241ac3-4d03-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:37:35.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t84c9" for this suite.
Mar 23 00:37:41.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:37:41.893: INFO: namespace: e2e-tests-emptydir-t84c9, resource: bindings, ignored listing per whitelist
Mar 23 00:37:41.933: INFO: namespace e2e-tests-emptydir-t84c9 deletion completed in 6.095081437s

• [SLOW TEST:10.192 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:37:41.934: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-de376c86-4d03-11e9-96f5-ea7d86f92d02
STEP: Creating secret with name s-test-opt-upd-de376cd3-4d03-11e9-96f5-ea7d86f92d02
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-de376c86-4d03-11e9-96f5-ea7d86f92d02
STEP: Updating secret s-test-opt-upd-de376cd3-4d03-11e9-96f5-ea7d86f92d02
STEP: Creating secret with name s-test-opt-create-de376cf8-4d03-11e9-96f5-ea7d86f92d02
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:37:46.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-spwcn" for this suite.
Mar 23 00:38:08.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:38:08.112: INFO: namespace: e2e-tests-secrets-spwcn, resource: bindings, ignored listing per whitelist
Mar 23 00:38:08.152: INFO: namespace e2e-tests-secrets-spwcn deletion completed in 22.080774158s

• [SLOW TEST:26.218 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:38:08.152: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 00:38:08.211: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 23 00:38:13.214: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 23 00:38:13.214: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 23 00:38:13.230: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-skxgz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-skxgz/deployments/test-cleanup-deployment,UID:f0d2bfd4-4d03-11e9-9a5c-0646f33e71ba,ResourceVersion:9635,Generation:1,CreationTimestamp:2019-03-23 00:38:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar 23 00:38:13.233: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-skxgz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-skxgz/replicasets/test-cleanup-deployment-755f6b95cc,UID:f0d4a156-4d03-11e9-9a5c-0646f33e71ba,ResourceVersion:9637,Generation:1,CreationTimestamp:2019-03-23 00:38:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment f0d2bfd4-4d03-11e9-9a5c-0646f33e71ba 0xc420b238c7 0xc420b238c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 23 00:38:13.233: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar 23 00:38:13.233: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-skxgz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-skxgz/replicasets/test-cleanup-controller,UID:edd5fb43-4d03-11e9-9a5c-0646f33e71ba,ResourceVersion:9636,Generation:1,CreationTimestamp:2019-03-23 00:38:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment f0d2bfd4-4d03-11e9-9a5c-0646f33e71ba 0xc420b2366f 0xc420b23680}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 23 00:38:13.240: INFO: Pod "test-cleanup-controller-hfwwd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-hfwwd,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-skxgz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-skxgz/pods/test-cleanup-controller-hfwwd,UID:edd75341-4d03-11e9-9a5c-0646f33e71ba,ResourceVersion:9628,Generation:0,CreationTimestamp:2019-03-23 00:38:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.108/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller edd5fb43-4d03-11e9-9a5c-0646f33e71ba 0xc420c8b04f 0xc420c8b100}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6d889 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6d889,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6d889 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c8b170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c8b190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:38:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:38:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:38:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:38:08 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:10.42.2.108,StartTime:2019-03-23 00:38:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-23 00:38:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://89776b281cef87620803a249f31b29501b4196fa5cec951a504e22db20a5162f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 00:38:13.240: INFO: Pod "test-cleanup-deployment-755f6b95cc-xxdf6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-xxdf6,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-skxgz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-skxgz/pods/test-cleanup-deployment-755f6b95cc-xxdf6,UID:f0d51e8b-4d03-11e9-9a5c-0646f33e71ba,ResourceVersion:9638,Generation:0,CreationTimestamp:2019-03-23 00:38:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc f0d4a156-4d03-11e9-9a5c-0646f33e71ba 0xc420c8b2b7 0xc420c8b2b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6d889 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6d889,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-6d889 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c8b340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c8b370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:38:13.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-skxgz" for this suite.
Mar 23 00:38:19.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:38:19.312: INFO: namespace: e2e-tests-deployment-skxgz, resource: bindings, ignored listing per whitelist
Mar 23 00:38:19.338: INFO: namespace e2e-tests-deployment-skxgz deletion completed in 6.087999226s

• [SLOW TEST:11.186 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:38:19.339: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:38:19.396: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f48233bc-4d03-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-88tbq" to be "success or failure"
Mar 23 00:38:19.401: INFO: Pod "downwardapi-volume-f48233bc-4d03-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 5.071145ms
Mar 23 00:38:21.404: INFO: Pod "downwardapi-volume-f48233bc-4d03-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008099715s
STEP: Saw pod success
Mar 23 00:38:21.404: INFO: Pod "downwardapi-volume-f48233bc-4d03-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:38:21.407: INFO: Trying to get logs from node node-2 pod downwardapi-volume-f48233bc-4d03-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:38:21.423: INFO: Waiting for pod downwardapi-volume-f48233bc-4d03-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:38:21.425: INFO: Pod downwardapi-volume-f48233bc-4d03-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:38:21.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-88tbq" for this suite.
Mar 23 00:38:27.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:38:27.460: INFO: namespace: e2e-tests-downward-api-88tbq, resource: bindings, ignored listing per whitelist
Mar 23 00:38:27.518: INFO: namespace e2e-tests-downward-api-88tbq deletion completed in 6.089877888s

• [SLOW TEST:8.179 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:38:27.518: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f9620abc-4d03-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 00:38:27.578: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f9627050-4d03-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-cxpxg" to be "success or failure"
Mar 23 00:38:27.583: INFO: Pod "pod-projected-secrets-f9627050-4d03-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.395588ms
Mar 23 00:38:29.586: INFO: Pod "pod-projected-secrets-f9627050-4d03-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007811426s
STEP: Saw pod success
Mar 23 00:38:29.586: INFO: Pod "pod-projected-secrets-f9627050-4d03-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:38:29.588: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-f9627050-4d03-11e9-96f5-ea7d86f92d02 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 23 00:38:29.602: INFO: Waiting for pod pod-projected-secrets-f9627050-4d03-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:38:29.605: INFO: Pod pod-projected-secrets-f9627050-4d03-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:38:29.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cxpxg" for this suite.
Mar 23 00:38:35.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:38:35.628: INFO: namespace: e2e-tests-projected-cxpxg, resource: bindings, ignored listing per whitelist
Mar 23 00:38:35.693: INFO: namespace e2e-tests-projected-cxpxg deletion completed in 6.085253587s

• [SLOW TEST:8.176 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:38:35.694: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mz2km
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-mz2km
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-mz2km
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-mz2km
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-mz2km
Mar 23 00:38:39.783: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-mz2km, name: ss-0, uid: 00896805-4d04-11e9-9a5c-0646f33e71ba, status phase: Pending. Waiting for statefulset controller to delete.
Mar 23 00:38:40.171: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-mz2km, name: ss-0, uid: 00896805-4d04-11e9-9a5c-0646f33e71ba, status phase: Failed. Waiting for statefulset controller to delete.
Mar 23 00:38:40.176: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-mz2km, name: ss-0, uid: 00896805-4d04-11e9-9a5c-0646f33e71ba, status phase: Failed. Waiting for statefulset controller to delete.
Mar 23 00:38:40.179: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-mz2km
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-mz2km
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-mz2km and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 23 00:38:44.214: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mz2km
Mar 23 00:38:44.216: INFO: Scaling statefulset ss to 0
Mar 23 00:38:54.227: INFO: Waiting for statefulset status.replicas updated to 0
Mar 23 00:38:54.229: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:38:54.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mz2km" for this suite.
Mar 23 00:39:00.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:39:00.301: INFO: namespace: e2e-tests-statefulset-mz2km, resource: bindings, ignored listing per whitelist
Mar 23 00:39:00.329: INFO: namespace e2e-tests-statefulset-mz2km deletion completed in 6.085387639s

• [SLOW TEST:24.635 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:39:00.329: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 23 00:39:00.382: INFO: PodSpec: initContainers in spec.initContainers
Mar 23 00:39:42.155: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-0cf0ba69-4d04-11e9-96f5-ea7d86f92d02", GenerateName:"", Namespace:"e2e-tests-init-container-jvknd", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-jvknd/pods/pod-init-0cf0ba69-4d04-11e9-96f5-ea7d86f92d02", UID:"0cefb181-4d04-11e9-9a5c-0646f33e71ba", ResourceVersion:"10037", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688898340, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"382173072"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.2.112/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-jnf8n", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4221be480), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jnf8n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jnf8n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jnf8n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421e28fc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4219848a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421e291b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421e291d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421e291d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688898340, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688898340, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688898340, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688898340, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.45.82", PodIP:"10.42.2.112", StartTime:(*v1.Time)(0xc4220b09a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421fe9880)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421fe98f0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://d69994c3ba416f2e12a4b92d9a165a477e821902dfa63346f6929fce9ccc3b73"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4220b09e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4220b09c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:39:42.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-jvknd" for this suite.
Mar 23 00:40:04.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:40:04.211: INFO: namespace: e2e-tests-init-container-jvknd, resource: bindings, ignored listing per whitelist
Mar 23 00:40:04.264: INFO: namespace e2e-tests-init-container-jvknd deletion completed in 22.105135135s

• [SLOW TEST:63.935 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:40:04.264: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:40:04.338: INFO: Waiting up to 5m0s for pod "downwardapi-volume-330e82b4-4d04-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-vxql6" to be "success or failure"
Mar 23 00:40:04.345: INFO: Pod "downwardapi-volume-330e82b4-4d04-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 7.28856ms
Mar 23 00:40:06.348: INFO: Pod "downwardapi-volume-330e82b4-4d04-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010311294s
STEP: Saw pod success
Mar 23 00:40:06.348: INFO: Pod "downwardapi-volume-330e82b4-4d04-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:40:06.350: INFO: Trying to get logs from node node-2 pod downwardapi-volume-330e82b4-4d04-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:40:06.371: INFO: Waiting for pod downwardapi-volume-330e82b4-4d04-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:40:06.381: INFO: Pod downwardapi-volume-330e82b4-4d04-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:40:06.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vxql6" for this suite.
Mar 23 00:40:12.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:40:12.540: INFO: namespace: e2e-tests-projected-vxql6, resource: bindings, ignored listing per whitelist
Mar 23 00:40:12.586: INFO: namespace e2e-tests-projected-vxql6 deletion completed in 6.201300649s

• [SLOW TEST:8.322 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:40:12.586: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9k4bm
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-9k4bm
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-9k4bm
Mar 23 00:40:12.732: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Mar 23 00:40:22.735: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 23 00:40:22.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 23 00:40:22.886: INFO: stderr: ""
Mar 23 00:40:22.886: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 23 00:40:22.886: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 23 00:40:22.889: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 23 00:40:32.892: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 23 00:40:32.892: INFO: Waiting for statefulset status.replicas updated to 0
Mar 23 00:40:32.905: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 23 00:40:32.905: INFO: ss-0  node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:12 +0000 UTC  }]
Mar 23 00:40:32.905: INFO: ss-1          Pending         []
Mar 23 00:40:32.905: INFO: 
Mar 23 00:40:32.905: INFO: StatefulSet ss has not reached scale 3, at 2
Mar 23 00:40:33.909: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994718844s
Mar 23 00:40:34.914: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99120482s
Mar 23 00:40:35.919: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986001083s
Mar 23 00:40:36.926: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981030337s
Mar 23 00:40:37.929: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974412433s
Mar 23 00:40:38.932: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971237581s
Mar 23 00:40:39.935: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96793592s
Mar 23 00:40:40.939: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.964585839s
Mar 23 00:40:41.942: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.163236ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-9k4bm
Mar 23 00:40:42.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:40:43.088: INFO: stderr: ""
Mar 23 00:40:43.088: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 23 00:40:43.088: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 23 00:40:43.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:40:43.229: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 23 00:40:43.229: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 23 00:40:43.229: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 23 00:40:43.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:40:43.371: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 23 00:40:43.371: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 23 00:40:43.371: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 23 00:40:43.375: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 23 00:40:43.375: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 23 00:40:43.375: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar 23 00:40:43.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 23 00:40:43.523: INFO: stderr: ""
Mar 23 00:40:43.523: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 23 00:40:43.523: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 23 00:40:43.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 23 00:40:43.663: INFO: stderr: ""
Mar 23 00:40:43.663: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 23 00:40:43.663: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 23 00:40:43.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 23 00:40:43.819: INFO: stderr: ""
Mar 23 00:40:43.819: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 23 00:40:43.819: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 23 00:40:43.819: INFO: Waiting for statefulset status.replicas updated to 0
Mar 23 00:40:43.821: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 23 00:40:53.827: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 23 00:40:53.827: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 23 00:40:53.827: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 23 00:40:53.836: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 23 00:40:53.836: INFO: ss-0  node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:12 +0000 UTC  }]
Mar 23 00:40:53.837: INFO: ss-1  node-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:40:53.837: INFO: ss-2  node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:40:53.837: INFO: 
Mar 23 00:40:53.837: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 23 00:40:54.840: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 23 00:40:54.841: INFO: ss-0  node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:12 +0000 UTC  }]
Mar 23 00:40:54.841: INFO: ss-1  node-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:40:54.841: INFO: ss-2  node-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:40:54.841: INFO: 
Mar 23 00:40:54.841: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 23 00:40:55.844: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 23 00:40:55.844: INFO: ss-1  node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:40:55.844: INFO: ss-2  node-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:40:55.844: INFO: 
Mar 23 00:40:55.844: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 23 00:40:56.847: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 23 00:40:56.847: INFO: ss-1  node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:40:56.847: INFO: 
Mar 23 00:40:56.847: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 23 00:40:57.850: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 23 00:40:57.850: INFO: ss-1  node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:40:57.850: INFO: 
Mar 23 00:40:57.850: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 23 00:40:58.854: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 23 00:40:58.854: INFO: ss-1  node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:40:58.854: INFO: 
Mar 23 00:40:58.854: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 23 00:40:59.857: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 23 00:40:59.857: INFO: ss-1  node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:40:59.857: INFO: 
Mar 23 00:40:59.857: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 23 00:41:00.861: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 23 00:41:00.861: INFO: ss-1  node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:41:00.861: INFO: 
Mar 23 00:41:00.862: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 23 00:41:01.871: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 23 00:41:01.871: INFO: ss-1  node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:41:01.871: INFO: 
Mar 23 00:41:01.871: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 23 00:41:02.874: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 23 00:41:02.874: INFO: ss-1  node-3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 00:40:32 +0000 UTC  }]
Mar 23 00:41:02.874: INFO: 
Mar 23 00:41:02.874: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-9k4bm
Mar 23 00:41:03.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:41:03.994: INFO: rc: 1
Mar 23 00:41:03.994: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc421ceec30 exit status 1 <nil> <nil> true [0xc42000f6a8 0xc42000f790 0xc420eb62e0] [0xc42000f6a8 0xc42000f790 0xc420eb62e0] [0xc42000f750 0xc420eb61f0] [0x8fd520 0x8fd520] 0xc421a98b40 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Mar 23 00:41:13.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:41:14.067: INFO: rc: 1
Mar 23 00:41:14.067: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421cef3b0 exit status 1 <nil> <nil> true [0xc420eb6300 0xc420eb6698 0xc420eb68c0] [0xc420eb6300 0xc420eb6698 0xc420eb68c0] [0xc420eb6510 0xc420eb6848] [0x8fd520 0x8fd520] 0xc421428cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:41:24.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:41:24.139: INFO: rc: 1
Mar 23 00:41:24.139: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421cefad0 exit status 1 <nil> <nil> true [0xc420eb6948 0xc420eb6a08 0xc420eb6b50] [0xc420eb6948 0xc420eb6a08 0xc420eb6b50] [0xc420eb69d0 0xc420eb6b48] [0x8fd520 0x8fd520] 0xc4213041e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:41:34.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:41:34.211: INFO: rc: 1
Mar 23 00:41:34.211: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4217627e0 exit status 1 <nil> <nil> true [0xc4200ca248 0xc4200ca2a8 0xc4200ca2e8] [0xc4200ca248 0xc4200ca2a8 0xc4200ca2e8] [0xc4200ca278 0xc4200ca2d8] [0x8fd520 0x8fd520] 0xc4216ea060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:41:44.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:41:44.283: INFO: rc: 1
Mar 23 00:41:44.283: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421608030 exit status 1 <nil> <nil> true [0xc420eb6d00 0xc420eb7170 0xc420eb7330] [0xc420eb6d00 0xc420eb7170 0xc420eb7330] [0xc420eb7050 0xc420eb72b8] [0x8fd520 0x8fd520] 0xc420d2be00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:41:54.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:41:54.355: INFO: rc: 1
Mar 23 00:41:54.355: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421608840 exit status 1 <nil> <nil> true [0xc420eb73b0 0xc420eb7640 0xc420eb77e0] [0xc420eb73b0 0xc420eb7640 0xc420eb77e0] [0xc420eb7528 0xc420eb76d0] [0x8fd520 0x8fd520] 0xc4215f3b60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:42:04.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:42:04.434: INFO: rc: 1
Mar 23 00:42:04.434: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421608cf0 exit status 1 <nil> <nil> true [0xc420eb7820 0xc420eb7b50 0xc420eb7c90] [0xc420eb7820 0xc420eb7b50 0xc420eb7c90] [0xc420eb7a80 0xc420eb7b90] [0x8fd520 0x8fd520] 0xc4208c44e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:42:14.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:42:14.505: INFO: rc: 1
Mar 23 00:42:14.505: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421609110 exit status 1 <nil> <nil> true [0xc420eb7cf0 0xc420eb7d50 0xc420eb7e20] [0xc420eb7cf0 0xc420eb7d50 0xc420eb7e20] [0xc420eb7d28 0xc420eb7e08] [0x8fd520 0x8fd520] 0xc4208c5440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:42:24.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:42:24.576: INFO: rc: 1
Mar 23 00:42:24.576: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421762bd0 exit status 1 <nil> <nil> true [0xc4200ca840 0xc4200cbf40 0xc4200cbf88] [0xc4200ca840 0xc4200cbf40 0xc4200cbf88] [0xc4200cbf30 0xc4200cbf78] [0x8fd520 0x8fd520] 0xc421b208a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:42:34.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:42:34.646: INFO: rc: 1
Mar 23 00:42:34.646: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4216095f0 exit status 1 <nil> <nil> true [0xc420eb7e60 0xc420eb7ec8 0xc420eb7f28] [0xc420eb7e60 0xc420eb7ec8 0xc420eb7f28] [0xc420eb7eb0 0xc420eb7ef0] [0x8fd520 0x8fd520] 0xc421c6e0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:42:44.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:42:44.718: INFO: rc: 1
Mar 23 00:42:44.718: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421762ff0 exit status 1 <nil> <nil> true [0xc4200cbf90 0xc4200cbfb8 0xc4200cbfe0] [0xc4200cbf90 0xc4200cbfb8 0xc4200cbfe0] [0xc4200cbfa8 0xc4200cbfd8] [0x8fd520 0x8fd520] 0xc421b20f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:42:54.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:42:54.791: INFO: rc: 1
Mar 23 00:42:54.791: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4217633b0 exit status 1 <nil> <nil> true [0xc4232da000 0xc4232da018 0xc4232da030] [0xc4232da000 0xc4232da018 0xc4232da030] [0xc4232da010 0xc4232da028] [0x8fd520 0x8fd520] 0xc421b21740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:43:04.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:43:04.865: INFO: rc: 1
Mar 23 00:43:04.865: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421cee450 exit status 1 <nil> <nil> true [0xc42000e080 0xc42000e238 0xc42000e4a0] [0xc42000e080 0xc42000e238 0xc42000e4a0] [0xc42000e198 0xc42000e450] [0x8fd520 0x8fd520] 0xc421b6daa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:43:14.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:43:14.937: INFO: rc: 1
Mar 23 00:43:14.937: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421ceea80 exit status 1 <nil> <nil> true [0xc42000e4f0 0xc42000f6e8 0xc4200ca138] [0xc42000e4f0 0xc42000f6e8 0xc4200ca138] [0xc42000f6a8 0xc42000f790] [0x8fd520 0x8fd520] 0xc4208c5320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:43:24.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:43:25.012: INFO: rc: 1
Mar 23 00:43:25.012: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421ceeea0 exit status 1 <nil> <nil> true [0xc4200ca158 0xc4200ca218 0xc4200ca278] [0xc4200ca158 0xc4200ca218 0xc4200ca278] [0xc4200ca208 0xc4200ca268] [0x8fd520 0x8fd520] 0xc421677680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:43:35.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:43:35.083: INFO: rc: 1
Mar 23 00:43:35.083: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4216088a0 exit status 1 <nil> <nil> true [0xc420eb6098 0xc420eb6300 0xc420eb6698] [0xc420eb6098 0xc420eb6300 0xc420eb6698] [0xc420eb62e0 0xc420eb6510] [0x8fd520 0x8fd520] 0xc42070e900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:43:45.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:43:45.160: INFO: rc: 1
Mar 23 00:43:45.161: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421cef650 exit status 1 <nil> <nil> true [0xc4200ca2a8 0xc4200ca2e8 0xc4200cbf30] [0xc4200ca2a8 0xc4200ca2e8 0xc4200cbf30] [0xc4200ca2d8 0xc4200cbf08] [0x8fd520 0x8fd520] 0xc4215f3b60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:43:55.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:43:55.236: INFO: rc: 1
Mar 23 00:43:55.236: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421cefe30 exit status 1 <nil> <nil> true [0xc4200cbf40 0xc4200cbf88 0xc4200cbfa8] [0xc4200cbf40 0xc4200cbf88 0xc4200cbfa8] [0xc4200cbf78 0xc4200cbfa0] [0x8fd520 0x8fd520] 0xc420d64780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:44:05.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:44:05.309: INFO: rc: 1
Mar 23 00:44:05.309: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421608d80 exit status 1 <nil> <nil> true [0xc420eb66f0 0xc420eb6948 0xc420eb6a08] [0xc420eb66f0 0xc420eb6948 0xc420eb6a08] [0xc420eb68c0 0xc420eb69d0] [0x8fd520 0x8fd520] 0xc42140f440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:44:15.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:44:15.383: INFO: rc: 1
Mar 23 00:44:15.383: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4216091d0 exit status 1 <nil> <nil> true [0xc420eb6a78 0xc420eb6d00 0xc420eb7170] [0xc420eb6a78 0xc420eb6d00 0xc420eb7170] [0xc420eb6b50 0xc420eb7050] [0x8fd520 0x8fd520] 0xc421a98b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:44:25.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:44:25.454: INFO: rc: 1
Mar 23 00:44:25.454: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421762300 exit status 1 <nil> <nil> true [0xc4200cbfb8 0xc4200cbfe0 0xc4232da010] [0xc4200cbfb8 0xc4200cbfe0 0xc4232da010] [0xc4200cbfd8 0xc4232da008] [0x8fd520 0x8fd520] 0xc421690960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:44:35.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:44:35.526: INFO: rc: 1
Mar 23 00:44:35.526: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421609680 exit status 1 <nil> <nil> true [0xc420eb7288 0xc420eb73b0 0xc420eb7640] [0xc420eb7288 0xc420eb73b0 0xc420eb7640] [0xc420eb7330 0xc420eb7528] [0x8fd520 0x8fd520] 0xc421be2360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:44:45.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:44:45.600: INFO: rc: 1
Mar 23 00:44:45.600: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421762720 exit status 1 <nil> <nil> true [0xc4232da018 0xc4232da030 0xc4232da048] [0xc4232da018 0xc4232da030 0xc4232da048] [0xc4232da028 0xc4232da040] [0x8fd520 0x8fd520] 0xc4216918c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:44:55.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:44:55.671: INFO: rc: 1
Mar 23 00:44:55.671: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421609ad0 exit status 1 <nil> <nil> true [0xc420eb7688 0xc420eb7820 0xc420eb7b50] [0xc420eb7688 0xc420eb7820 0xc420eb7b50] [0xc420eb77e0 0xc420eb7a80] [0x8fd520 0x8fd520] 0xc421b20540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:45:05.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:45:05.755: INFO: rc: 1
Mar 23 00:45:05.755: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421609fb0 exit status 1 <nil> <nil> true [0xc420eb7b90 0xc420eb7d00 0xc420eb7de8] [0xc420eb7b90 0xc420eb7d00 0xc420eb7de8] [0xc420eb7cf0 0xc420eb7d50] [0x8fd520 0x8fd520] 0xc421b20ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:45:15.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:45:15.831: INFO: rc: 1
Mar 23 00:45:15.831: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421cee480 exit status 1 <nil> <nil> true [0xc4200ca138 0xc4200ca208 0xc4200ca268] [0xc4200ca138 0xc4200ca208 0xc4200ca268] [0xc4200ca1b8 0xc4200ca248] [0x8fd520 0x8fd520] 0xc421be29c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:45:25.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:45:26.265: INFO: rc: 1
Mar 23 00:45:26.265: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4216087b0 exit status 1 <nil> <nil> true [0xc42000e010 0xc42000e198 0xc42000e450] [0xc42000e010 0xc42000e198 0xc42000e450] [0xc42000e108 0xc42000e270] [0x8fd520 0x8fd520] 0xc421690960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:45:36.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:45:36.337: INFO: rc: 1
Mar 23 00:45:36.338: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421608cf0 exit status 1 <nil> <nil> true [0xc42000e4a0 0xc42000f6a8 0xc42000f790] [0xc42000e4a0 0xc42000f6a8 0xc42000f790] [0xc42000f5a0 0xc42000f750] [0x8fd520 0x8fd520] 0xc4216918c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:45:46.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:45:46.412: INFO: rc: 1
Mar 23 00:45:46.412: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421609170 exit status 1 <nil> <nil> true [0xc4232da000 0xc4232da018 0xc4232da030] [0xc4232da000 0xc4232da018 0xc4232da030] [0xc4232da010 0xc4232da028] [0x8fd520 0x8fd520] 0xc421a99560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:45:56.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:45:56.484: INFO: rc: 1
Mar 23 00:45:56.484: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421ceeae0 exit status 1 <nil> <nil> true [0xc4200ca278 0xc4200ca2d8 0xc4200cbf08] [0xc4200ca278 0xc4200ca2d8 0xc4200cbf08] [0xc4200ca2b8 0xc4200ca840] [0x8fd520 0x8fd520] 0xc42140e0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 23 00:46:06.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-9k4bm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 00:46:06.562: INFO: rc: 1
Mar 23 00:46:06.562: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Mar 23 00:46:06.562: INFO: Scaling statefulset ss to 0
Mar 23 00:46:06.569: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 23 00:46:06.571: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9k4bm
Mar 23 00:46:06.573: INFO: Scaling statefulset ss to 0
Mar 23 00:46:06.581: INFO: Waiting for statefulset status.replicas updated to 0
Mar 23 00:46:06.583: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:46:06.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9k4bm" for this suite.
Mar 23 00:46:12.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:46:12.617: INFO: namespace: e2e-tests-statefulset-9k4bm, resource: bindings, ignored listing per whitelist
Mar 23 00:46:12.685: INFO: namespace e2e-tests-statefulset-9k4bm deletion completed in 6.086713962s

• [SLOW TEST:360.099 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:46:12.686: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 23 00:46:12.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-gkdcx'
Mar 23 00:46:13.117: INFO: stderr: ""
Mar 23 00:46:13.117: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 23 00:46:13.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gkdcx'
Mar 23 00:46:13.210: INFO: stderr: ""
Mar 23 00:46:13.210: INFO: stdout: "update-demo-nautilus-qds9t update-demo-nautilus-w25f9 "
Mar 23 00:46:13.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-qds9t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkdcx'
Mar 23 00:46:13.289: INFO: stderr: ""
Mar 23 00:46:13.289: INFO: stdout: ""
Mar 23 00:46:13.289: INFO: update-demo-nautilus-qds9t is created but not running
Mar 23 00:46:18.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gkdcx'
Mar 23 00:46:18.370: INFO: stderr: ""
Mar 23 00:46:18.370: INFO: stdout: "update-demo-nautilus-qds9t update-demo-nautilus-w25f9 "
Mar 23 00:46:18.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-qds9t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkdcx'
Mar 23 00:46:18.448: INFO: stderr: ""
Mar 23 00:46:18.448: INFO: stdout: "true"
Mar 23 00:46:18.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-qds9t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkdcx'
Mar 23 00:46:18.526: INFO: stderr: ""
Mar 23 00:46:18.526: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 23 00:46:18.526: INFO: validating pod update-demo-nautilus-qds9t
Mar 23 00:46:18.530: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 23 00:46:18.530: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 23 00:46:18.530: INFO: update-demo-nautilus-qds9t is verified up and running
Mar 23 00:46:18.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-w25f9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkdcx'
Mar 23 00:46:18.610: INFO: stderr: ""
Mar 23 00:46:18.610: INFO: stdout: "true"
Mar 23 00:46:18.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-w25f9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkdcx'
Mar 23 00:46:18.687: INFO: stderr: ""
Mar 23 00:46:18.687: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 23 00:46:18.687: INFO: validating pod update-demo-nautilus-w25f9
Mar 23 00:46:18.691: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 23 00:46:18.691: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 23 00:46:18.691: INFO: update-demo-nautilus-w25f9 is verified up and running
STEP: using delete to clean up resources
Mar 23 00:46:18.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gkdcx'
Mar 23 00:46:18.769: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 23 00:46:18.769: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 23 00:46:18.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-gkdcx'
Mar 23 00:46:18.880: INFO: stderr: "No resources found.\n"
Mar 23 00:46:18.880: INFO: stdout: ""
Mar 23 00:46:18.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -l name=update-demo --namespace=e2e-tests-kubectl-gkdcx -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 23 00:46:18.998: INFO: stderr: ""
Mar 23 00:46:18.998: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:46:18.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gkdcx" for this suite.
Mar 23 00:46:41.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:46:41.068: INFO: namespace: e2e-tests-kubectl-gkdcx, resource: bindings, ignored listing per whitelist
Mar 23 00:46:41.087: INFO: namespace e2e-tests-kubectl-gkdcx deletion completed in 22.084980354s

• [SLOW TEST:28.401 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:46:41.087: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 23 00:46:41.138: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 23 00:46:41.144: INFO: Waiting for terminating namespaces to be deleted...
Mar 23 00:46:41.146: INFO: 
Logging pods the kubelet thinks is on node node-1 before test
Mar 23 00:46:41.152: INFO: nginx-ingress-controller-q69fx from ingress-nginx started at 2019-03-22 23:54:04 +0000 UTC (1 container statuses recorded)
Mar 23 00:46:41.152: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 23 00:46:41.152: INFO: default-http-backend-54bff6fc5d-2c5b4 from ingress-nginx started at 2019-03-22 23:54:04 +0000 UTC (1 container statuses recorded)
Mar 23 00:46:41.152: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 23 00:46:41.152: INFO: metrics-server-844bd95c7b-2nnxc from kube-system started at 2019-03-22 23:54:02 +0000 UTC (1 container statuses recorded)
Mar 23 00:46:41.152: INFO: 	Container metrics-server ready: true, restart count 0
Mar 23 00:46:41.152: INFO: rke-ingress-controller-deploy-job-p2bnl from kube-system started at 2019-03-22 23:54:03 +0000 UTC (1 container statuses recorded)
Mar 23 00:46:41.152: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 23 00:46:41.152: INFO: kube-dns-autoscaler-59cc69d67f-gczdw from kube-system started at 2019-03-22 23:54:02 +0000 UTC (1 container statuses recorded)
Mar 23 00:46:41.152: INFO: 	Container autoscaler ready: true, restart count 0
Mar 23 00:46:41.152: INFO: sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-swz92 from heptio-sonobuoy started at 2019-03-22 23:55:25 +0000 UTC (2 container statuses recorded)
Mar 23 00:46:41.152: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 23 00:46:41.152: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:46:41.152: INFO: rke-network-plugin-deploy-job-g47g4 from kube-system started at 2019-03-22 23:53:42 +0000 UTC (1 container statuses recorded)
Mar 23 00:46:41.152: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 23 00:46:41.152: INFO: rke-kube-dns-addon-deploy-job-ll858 from kube-system started at 2019-03-22 23:53:49 +0000 UTC (1 container statuses recorded)
Mar 23 00:46:41.152: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Mar 23 00:46:41.152: INFO: kube-dns-5c9cfc6cb9-c6f5q from kube-system started at 2019-03-22 23:54:02 +0000 UTC (3 container statuses recorded)
Mar 23 00:46:41.152: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 23 00:46:41.152: INFO: 	Container kubedns ready: true, restart count 0
Mar 23 00:46:41.152: INFO: 	Container sidecar ready: true, restart count 0
Mar 23 00:46:41.152: INFO: canal-xxshj from kube-system started at 2019-03-22 23:53:45 +0000 UTC (3 container statuses recorded)
Mar 23 00:46:41.152: INFO: 	Container calico-node ready: true, restart count 0
Mar 23 00:46:41.152: INFO: 	Container install-cni ready: true, restart count 0
Mar 23 00:46:41.152: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 23 00:46:41.152: INFO: rke-metrics-addon-deploy-job-lvhn9 from kube-system started at 2019-03-22 23:53:56 +0000 UTC (1 container statuses recorded)
Mar 23 00:46:41.152: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 23 00:46:41.152: INFO: 
Logging pods the kubelet thinks is on node node-2 before test
Mar 23 00:46:41.157: INFO: nginx-ingress-controller-qvs56 from ingress-nginx started at 2019-03-22 23:54:07 +0000 UTC (1 container statuses recorded)
Mar 23 00:46:41.157: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 23 00:46:41.157: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-22 23:55:22 +0000 UTC (1 container statuses recorded)
Mar 23 00:46:41.157: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 23 00:46:41.157: INFO: sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-d7tzm from heptio-sonobuoy started at 2019-03-22 23:55:25 +0000 UTC (2 container statuses recorded)
Mar 23 00:46:41.157: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 23 00:46:41.157: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:46:41.157: INFO: canal-vqzvc from kube-system started at 2019-03-22 23:53:45 +0000 UTC (3 container statuses recorded)
Mar 23 00:46:41.157: INFO: 	Container calico-node ready: true, restart count 0
Mar 23 00:46:41.157: INFO: 	Container install-cni ready: true, restart count 0
Mar 23 00:46:41.157: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 23 00:46:41.157: INFO: 
Logging pods the kubelet thinks is on node node-3 before test
Mar 23 00:46:41.161: INFO: sonobuoy-e2e-job-08fc2d888de548b8 from heptio-sonobuoy started at 2019-03-22 23:55:24 +0000 UTC (2 container statuses recorded)
Mar 23 00:46:41.161: INFO: 	Container e2e ready: true, restart count 0
Mar 23 00:46:41.161: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:46:41.161: INFO: sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-zn4k6 from heptio-sonobuoy started at 2019-03-22 23:55:25 +0000 UTC (2 container statuses recorded)
Mar 23 00:46:41.161: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 23 00:46:41.161: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:46:41.161: INFO: canal-5gdw5 from kube-system started at 2019-03-22 23:53:45 +0000 UTC (3 container statuses recorded)
Mar 23 00:46:41.161: INFO: 	Container calico-node ready: true, restart count 0
Mar 23 00:46:41.161: INFO: 	Container install-cni ready: true, restart count 0
Mar 23 00:46:41.161: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 23 00:46:41.161: INFO: nginx-ingress-controller-lf7sv from ingress-nginx started at 2019-03-22 23:54:07 +0000 UTC (1 container statuses recorded)
Mar 23 00:46:41.161: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158e6ff0b838be13], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:46:42.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-bjz6b" for this suite.
Mar 23 00:46:48.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:46:48.210: INFO: namespace: e2e-tests-sched-pred-bjz6b, resource: bindings, ignored listing per whitelist
Mar 23 00:46:48.262: INFO: namespace e2e-tests-sched-pred-bjz6b deletion completed in 6.079465704s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.175 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:46:48.262: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-c5wxk
Mar 23 00:46:50.320: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-c5wxk
STEP: checking the pod's current state and verifying that restartCount is present
Mar 23 00:46:50.322: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:50:50.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-c5wxk" for this suite.
Mar 23 00:50:56.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:50:56.779: INFO: namespace: e2e-tests-container-probe-c5wxk, resource: bindings, ignored listing per whitelist
Mar 23 00:50:56.781: INFO: namespace e2e-tests-container-probe-c5wxk deletion completed in 6.085210192s

• [SLOW TEST:248.519 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:50:56.781: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:50:56.875: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b7ff374d-4d05-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-b9smn" to be "success or failure"
Mar 23 00:50:56.878: INFO: Pod "downwardapi-volume-b7ff374d-4d05-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.196546ms
Mar 23 00:50:58.881: INFO: Pod "downwardapi-volume-b7ff374d-4d05-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006172289s
STEP: Saw pod success
Mar 23 00:50:58.881: INFO: Pod "downwardapi-volume-b7ff374d-4d05-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:50:58.883: INFO: Trying to get logs from node node-2 pod downwardapi-volume-b7ff374d-4d05-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:50:58.897: INFO: Waiting for pod downwardapi-volume-b7ff374d-4d05-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:50:58.900: INFO: Pod downwardapi-volume-b7ff374d-4d05-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:50:58.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b9smn" for this suite.
Mar 23 00:51:04.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:51:04.942: INFO: namespace: e2e-tests-projected-b9smn, resource: bindings, ignored listing per whitelist
Mar 23 00:51:04.990: INFO: namespace e2e-tests-projected-b9smn deletion completed in 6.08677192s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:51:04.990: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 23 00:51:05.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-679th'
Mar 23 00:51:05.193: INFO: stderr: ""
Mar 23 00:51:05.193: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar 23 00:51:10.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-679th -o json'
Mar 23 00:51:10.324: INFO: stderr: ""
Mar 23 00:51:10.324: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.42.2.118/32\"\n        },\n        \"creationTimestamp\": \"2019-03-23T00:51:05Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-679th\",\n        \"resourceVersion\": \"11445\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-679th/pods/e2e-test-nginx-pod\",\n        \"uid\": \"bcf2821c-4d05-11e9-9a5c-0646f33e71ba\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-2v4vn\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"node-2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-2v4vn\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-2v4vn\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-23T00:51:05Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-23T00:51:06Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-23T00:51:06Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-23T00:51:05Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://dc2352d4c542f86bb4267ff290683e3ca4659ac03d4efb164911545f00a2676f\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-23T00:51:05Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.45.82\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.2.118\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-23T00:51:05Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar 23 00:51:10.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 replace -f - --namespace=e2e-tests-kubectl-679th'
Mar 23 00:51:10.588: INFO: stderr: ""
Mar 23 00:51:10.588: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Mar 23 00:51:10.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-679th'
Mar 23 00:51:17.159: INFO: stderr: ""
Mar 23 00:51:17.159: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:51:17.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-679th" for this suite.
Mar 23 00:51:23.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:51:23.222: INFO: namespace: e2e-tests-kubectl-679th, resource: bindings, ignored listing per whitelist
Mar 23 00:51:23.256: INFO: namespace e2e-tests-kubectl-679th deletion completed in 6.092849101s

• [SLOW TEST:18.266 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:51:23.256: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:51:23.315: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c7c2a626-4d05-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-ddvxt" to be "success or failure"
Mar 23 00:51:23.318: INFO: Pod "downwardapi-volume-c7c2a626-4d05-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.399622ms
Mar 23 00:51:25.321: INFO: Pod "downwardapi-volume-c7c2a626-4d05-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006127577s
STEP: Saw pod success
Mar 23 00:51:25.321: INFO: Pod "downwardapi-volume-c7c2a626-4d05-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:51:25.323: INFO: Trying to get logs from node node-2 pod downwardapi-volume-c7c2a626-4d05-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:51:25.337: INFO: Waiting for pod downwardapi-volume-c7c2a626-4d05-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:51:25.340: INFO: Pod downwardapi-volume-c7c2a626-4d05-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:51:25.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ddvxt" for this suite.
Mar 23 00:51:31.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:51:31.367: INFO: namespace: e2e-tests-projected-ddvxt, resource: bindings, ignored listing per whitelist
Mar 23 00:51:31.427: INFO: namespace e2e-tests-projected-ddvxt deletion completed in 6.084457309s

• [SLOW TEST:8.171 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:51:31.428: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar 23 00:51:31.481: INFO: Waiting up to 5m0s for pod "client-containers-cca0c4cc-4d05-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-containers-n68rj" to be "success or failure"
Mar 23 00:51:31.484: INFO: Pod "client-containers-cca0c4cc-4d05-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.172043ms
Mar 23 00:51:33.487: INFO: Pod "client-containers-cca0c4cc-4d05-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006091321s
STEP: Saw pod success
Mar 23 00:51:33.487: INFO: Pod "client-containers-cca0c4cc-4d05-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:51:33.489: INFO: Trying to get logs from node node-2 pod client-containers-cca0c4cc-4d05-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 00:51:33.504: INFO: Waiting for pod client-containers-cca0c4cc-4d05-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:51:33.506: INFO: Pod client-containers-cca0c4cc-4d05-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:51:33.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-n68rj" for this suite.
Mar 23 00:51:39.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:51:39.525: INFO: namespace: e2e-tests-containers-n68rj, resource: bindings, ignored listing per whitelist
Mar 23 00:51:39.602: INFO: namespace e2e-tests-containers-n68rj deletion completed in 6.092949814s

• [SLOW TEST:8.175 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:51:39.602: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 23 00:51:39.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-wpfxk'
Mar 23 00:51:39.740: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 23 00:51:39.740: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Mar 23 00:51:41.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-wpfxk'
Mar 23 00:51:41.830: INFO: stderr: ""
Mar 23 00:51:41.830: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:51:41.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wpfxk" for this suite.
Mar 23 00:52:03.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:52:03.916: INFO: namespace: e2e-tests-kubectl-wpfxk, resource: bindings, ignored listing per whitelist
Mar 23 00:52:03.924: INFO: namespace e2e-tests-kubectl-wpfxk deletion completed in 22.089407829s

• [SLOW TEST:24.321 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:52:03.924: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-e0006b98-4d05-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 00:52:03.987: INFO: Waiting up to 5m0s for pod "pod-configmaps-e000d3ba-4d05-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-configmap-pdksp" to be "success or failure"
Mar 23 00:52:03.993: INFO: Pod "pod-configmaps-e000d3ba-4d05-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 5.476449ms
Mar 23 00:52:05.996: INFO: Pod "pod-configmaps-e000d3ba-4d05-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008366506s
STEP: Saw pod success
Mar 23 00:52:05.996: INFO: Pod "pod-configmaps-e000d3ba-4d05-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:52:05.998: INFO: Trying to get logs from node node-2 pod pod-configmaps-e000d3ba-4d05-11e9-96f5-ea7d86f92d02 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 23 00:52:06.011: INFO: Waiting for pod pod-configmaps-e000d3ba-4d05-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:52:06.013: INFO: Pod pod-configmaps-e000d3ba-4d05-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:52:06.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pdksp" for this suite.
Mar 23 00:52:12.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:52:12.077: INFO: namespace: e2e-tests-configmap-pdksp, resource: bindings, ignored listing per whitelist
Mar 23 00:52:12.109: INFO: namespace e2e-tests-configmap-pdksp deletion completed in 6.09345585s

• [SLOW TEST:8.186 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:52:12.110: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 00:52:12.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 version --client'
Mar 23 00:52:12.274: INFO: stderr: ""
Mar 23 00:52:12.274: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar 23 00:52:12.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-td8tt'
Mar 23 00:52:12.432: INFO: stderr: ""
Mar 23 00:52:12.432: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar 23 00:52:12.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-td8tt'
Mar 23 00:52:12.587: INFO: stderr: ""
Mar 23 00:52:12.587: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 23 00:52:13.592: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 00:52:13.592: INFO: Found 0 / 1
Mar 23 00:52:14.590: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 00:52:14.590: INFO: Found 1 / 1
Mar 23 00:52:14.590: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 23 00:52:14.593: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 00:52:14.593: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 23 00:52:14.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 describe pod redis-master-j4x79 --namespace=e2e-tests-kubectl-td8tt'
Mar 23 00:52:14.685: INFO: stderr: ""
Mar 23 00:52:14.685: INFO: stdout: "Name:               redis-master-j4x79\nNamespace:          e2e-tests-kubectl-td8tt\nPriority:           0\nPriorityClassName:  <none>\nNode:               node-2/172.31.45.82\nStart Time:         Sat, 23 Mar 2019 00:52:12 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.42.2.123/32\nStatus:             Running\nIP:                 10.42.2.123\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://8d70b9b030122113f6bb05bcf6f09245155104b39c3f4776d721068d6a867a5a\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 23 Mar 2019 00:52:13 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-jfpvb (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-jfpvb:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-jfpvb\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned e2e-tests-kubectl-td8tt/redis-master-j4x79 to node-2\n  Normal  Pulled     1s    kubelet, node-2    Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, node-2    Created container\n  Normal  Started    1s    kubelet, node-2    Started container\n"
Mar 23 00:52:14.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 describe rc redis-master --namespace=e2e-tests-kubectl-td8tt'
Mar 23 00:52:14.786: INFO: stderr: ""
Mar 23 00:52:14.786: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-td8tt\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-j4x79\n"
Mar 23 00:52:14.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 describe service redis-master --namespace=e2e-tests-kubectl-td8tt'
Mar 23 00:52:14.876: INFO: stderr: ""
Mar 23 00:52:14.876: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-td8tt\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.43.190.235\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.42.2.123:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 23 00:52:14.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 describe node node-1'
Mar 23 00:52:14.985: INFO: stderr: ""
Mar 23 00:52:14.985: INFO: stdout: "Name:               node-1\nRoles:              controlplane,etcd,worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=node-1\n                    node-role.kubernetes.io/controlplane=true\n                    node-role.kubernetes.io/etcd=true\n                    node-role.kubernetes.io/worker=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"be:ec:ec:5f:1d:52\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.31.37.195\n                    node.alpha.kubernetes.io/ttl: 0\n                    rke.cattle.io/external-ip: 54.202.12.207\n                    rke.cattle.io/internal-ip: 54.202.12.207\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 22 Mar 2019 23:53:21 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Sat, 23 Mar 2019 00:52:09 +0000   Fri, 22 Mar 2019 23:53:21 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Sat, 23 Mar 2019 00:52:09 +0000   Fri, 22 Mar 2019 23:53:21 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 23 Mar 2019 00:52:09 +0000   Fri, 22 Mar 2019 23:53:21 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 23 Mar 2019 00:52:09 +0000   Fri, 22 Mar 2019 23:53:21 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 23 Mar 2019 00:52:09 +0000   Fri, 22 Mar 2019 23:54:01 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.31.37.195\n  Hostname:    node-1\nCapacity:\n cpu:                2\n ephemeral-storage:  8065444Ki\n hugepages-2Mi:      0\n memory:             4045052Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  7433113179\n hugepages-2Mi:      0\n memory:             3942652Ki\n pods:               110\nSystem Info:\n Machine ID:                 3e608929fbd39b959f388bf468c9f0b1\n System UUID:                EC26E044-C132-ABAF-C5AB-AA5261917386\n Boot ID:                    52490f17-ed4e-46cc-b6d7-562e3ca6d98b\n Kernel Version:             4.4.0-1067-aws\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.12.6\n Kube-Proxy Version:         v1.12.6\nPodCIDR:                     10.42.0.0/24\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-swz92    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  ingress-nginx              default-http-backend-54bff6fc5d-2c5b4                      10m (0%)      10m (0%)    20Mi (0%)        20Mi (0%)\n  ingress-nginx              nginx-ingress-controller-q69fx                             0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                canal-xxshj                                                250m (12%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-dns-5c9cfc6cb9-c6f5q                                  260m (13%)    0 (0%)      110Mi (2%)       170Mi (4%)\n  kube-system                kube-dns-autoscaler-59cc69d67f-gczdw                       20m (1%)      0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                metrics-server-844bd95c7b-2nnxc                            0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       540m (27%)  10m (0%)\n  memory    140Mi (3%)  190Mi (4%)\nEvents:\n  Type    Reason                   Age                From                Message\n  ----    ------                   ----               ----                -------\n  Normal  Starting                 58m                kubelet, node-1     Starting kubelet.\n  Normal  NodeHasSufficientDisk    58m (x2 over 58m)  kubelet, node-1     Node node-1 status is now: NodeHasSufficientDisk\n  Normal  NodeHasSufficientMemory  58m (x2 over 58m)  kubelet, node-1     Node node-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    58m (x2 over 58m)  kubelet, node-1     Node node-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     58m (x2 over 58m)  kubelet, node-1     Node node-1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  58m                kubelet, node-1     Updated Node Allocatable limit across pods\n  Normal  Starting                 58m                kube-proxy, node-1  Starting kube-proxy.\n  Normal  NodeReady                58m                kubelet, node-1     Node node-1 status is now: NodeReady\n"
Mar 23 00:52:14.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 describe namespace e2e-tests-kubectl-td8tt'
Mar 23 00:52:15.073: INFO: stderr: ""
Mar 23 00:52:15.073: INFO: stdout: "Name:         e2e-tests-kubectl-td8tt\nLabels:       e2e-framework=kubectl\n              e2e-run=06727a6a-4cfe-11e9-96f5-ea7d86f92d02\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:52:15.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-td8tt" for this suite.
Mar 23 00:52:37.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:52:37.103: INFO: namespace: e2e-tests-kubectl-td8tt, resource: bindings, ignored listing per whitelist
Mar 23 00:52:37.163: INFO: namespace e2e-tests-kubectl-td8tt deletion completed in 22.086925145s

• [SLOW TEST:25.053 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:52:37.163: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0323 00:52:38.254758      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 23 00:52:38.254: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:52:38.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rt2cp" for this suite.
Mar 23 00:52:44.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:52:44.328: INFO: namespace: e2e-tests-gc-rt2cp, resource: bindings, ignored listing per whitelist
Mar 23 00:52:44.358: INFO: namespace e2e-tests-gc-rt2cp deletion completed in 6.093178123s

• [SLOW TEST:7.195 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:52:44.358: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 23 00:52:44.445: INFO: Number of nodes with available pods: 0
Mar 23 00:52:44.445: INFO: Node node-1 is running more than one daemon pod
Mar 23 00:52:45.452: INFO: Number of nodes with available pods: 1
Mar 23 00:52:45.452: INFO: Node node-1 is running more than one daemon pod
Mar 23 00:52:46.452: INFO: Number of nodes with available pods: 3
Mar 23 00:52:46.452: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 23 00:52:46.474: INFO: Number of nodes with available pods: 2
Mar 23 00:52:46.474: INFO: Node node-1 is running more than one daemon pod
Mar 23 00:52:47.481: INFO: Number of nodes with available pods: 2
Mar 23 00:52:47.481: INFO: Node node-1 is running more than one daemon pod
Mar 23 00:52:48.481: INFO: Number of nodes with available pods: 3
Mar 23 00:52:48.481: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-ll75p, will wait for the garbage collector to delete the pods
Mar 23 00:52:48.545: INFO: Deleting {extensions DaemonSet} daemon-set took: 8.043808ms
Mar 23 00:52:48.646: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.217752ms
Mar 23 00:53:31.648: INFO: Number of nodes with available pods: 0
Mar 23 00:53:31.648: INFO: Number of running nodes: 0, number of available pods: 0
Mar 23 00:53:31.650: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-ll75p/daemonsets","resourceVersion":"11969"},"items":null}

Mar 23 00:53:31.652: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-ll75p/pods","resourceVersion":"11969"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:53:31.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-ll75p" for this suite.
Mar 23 00:53:37.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:53:37.704: INFO: namespace: e2e-tests-daemonsets-ll75p, resource: bindings, ignored listing per whitelist
Mar 23 00:53:37.749: INFO: namespace e2e-tests-daemonsets-ll75p deletion completed in 6.083586263s

• [SLOW TEST:53.391 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:53:37.749: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-lwhx
STEP: Creating a pod to test atomic-volume-subpath
Mar 23 00:53:37.813: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-lwhx" in namespace "e2e-tests-subpath-7scv2" to be "success or failure"
Mar 23 00:53:37.816: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Pending", Reason="", readiness=false. Elapsed: 3.567286ms
Mar 23 00:53:39.820: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007535892s
Mar 23 00:53:41.823: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Running", Reason="", readiness=false. Elapsed: 4.010517456s
Mar 23 00:53:43.826: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Running", Reason="", readiness=false. Elapsed: 6.013538935s
Mar 23 00:53:45.829: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Running", Reason="", readiness=false. Elapsed: 8.016570924s
Mar 23 00:53:47.832: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Running", Reason="", readiness=false. Elapsed: 10.019576061s
Mar 23 00:53:49.835: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Running", Reason="", readiness=false. Elapsed: 12.022427515s
Mar 23 00:53:51.838: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Running", Reason="", readiness=false. Elapsed: 14.025389556s
Mar 23 00:53:53.841: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Running", Reason="", readiness=false. Elapsed: 16.02829751s
Mar 23 00:53:55.844: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Running", Reason="", readiness=false. Elapsed: 18.031114395s
Mar 23 00:53:57.847: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Running", Reason="", readiness=false. Elapsed: 20.033969465s
Mar 23 00:53:59.850: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Running", Reason="", readiness=false. Elapsed: 22.03693706s
Mar 23 00:54:01.853: INFO: Pod "pod-subpath-test-secret-lwhx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.04021652s
STEP: Saw pod success
Mar 23 00:54:01.853: INFO: Pod "pod-subpath-test-secret-lwhx" satisfied condition "success or failure"
Mar 23 00:54:01.855: INFO: Trying to get logs from node node-2 pod pod-subpath-test-secret-lwhx container test-container-subpath-secret-lwhx: <nil>
STEP: delete the pod
Mar 23 00:54:01.871: INFO: Waiting for pod pod-subpath-test-secret-lwhx to disappear
Mar 23 00:54:01.873: INFO: Pod pod-subpath-test-secret-lwhx no longer exists
STEP: Deleting pod pod-subpath-test-secret-lwhx
Mar 23 00:54:01.873: INFO: Deleting pod "pod-subpath-test-secret-lwhx" in namespace "e2e-tests-subpath-7scv2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:54:01.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-7scv2" for this suite.
Mar 23 00:54:07.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:54:07.911: INFO: namespace: e2e-tests-subpath-7scv2, resource: bindings, ignored listing per whitelist
Mar 23 00:54:07.963: INFO: namespace e2e-tests-subpath-7scv2 deletion completed in 6.084479789s

• [SLOW TEST:30.214 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:54:07.963: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 23 00:54:08.021: INFO: Waiting up to 5m0s for pod "downward-api-29eed298-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-whstc" to be "success or failure"
Mar 23 00:54:08.024: INFO: Pod "downward-api-29eed298-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.198163ms
Mar 23 00:54:10.027: INFO: Pod "downward-api-29eed298-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006139413s
STEP: Saw pod success
Mar 23 00:54:10.027: INFO: Pod "downward-api-29eed298-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:54:10.029: INFO: Trying to get logs from node node-2 pod downward-api-29eed298-4d06-11e9-96f5-ea7d86f92d02 container dapi-container: <nil>
STEP: delete the pod
Mar 23 00:54:10.044: INFO: Waiting for pod downward-api-29eed298-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:54:10.046: INFO: Pod downward-api-29eed298-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:54:10.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-whstc" for this suite.
Mar 23 00:54:16.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:54:16.119: INFO: namespace: e2e-tests-downward-api-whstc, resource: bindings, ignored listing per whitelist
Mar 23 00:54:16.134: INFO: namespace e2e-tests-downward-api-whstc deletion completed in 6.084173964s

• [SLOW TEST:8.170 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:54:16.134: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-2ed4f37b-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 00:54:16.244: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ed55a84-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-configmap-pnq48" to be "success or failure"
Mar 23 00:54:16.249: INFO: Pod "pod-configmaps-2ed55a84-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.796309ms
Mar 23 00:54:18.252: INFO: Pod "pod-configmaps-2ed55a84-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007553393s
STEP: Saw pod success
Mar 23 00:54:18.252: INFO: Pod "pod-configmaps-2ed55a84-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:54:18.254: INFO: Trying to get logs from node node-2 pod pod-configmaps-2ed55a84-4d06-11e9-96f5-ea7d86f92d02 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 23 00:54:18.271: INFO: Waiting for pod pod-configmaps-2ed55a84-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:54:18.277: INFO: Pod pod-configmaps-2ed55a84-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:54:18.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pnq48" for this suite.
Mar 23 00:54:24.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:54:24.309: INFO: namespace: e2e-tests-configmap-pnq48, resource: bindings, ignored listing per whitelist
Mar 23 00:54:24.364: INFO: namespace e2e-tests-configmap-pnq48 deletion completed in 6.084258375s

• [SLOW TEST:8.231 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:54:24.365: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 23 00:54:24.421: INFO: Waiting up to 5m0s for pod "pod-33b54c6b-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-pwdsz" to be "success or failure"
Mar 23 00:54:24.426: INFO: Pod "pod-33b54c6b-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.374577ms
Mar 23 00:54:26.429: INFO: Pod "pod-33b54c6b-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007335052s
STEP: Saw pod success
Mar 23 00:54:26.429: INFO: Pod "pod-33b54c6b-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:54:26.431: INFO: Trying to get logs from node node-2 pod pod-33b54c6b-4d06-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 00:54:26.445: INFO: Waiting for pod pod-33b54c6b-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:54:26.448: INFO: Pod pod-33b54c6b-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:54:26.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pwdsz" for this suite.
Mar 23 00:54:32.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:54:32.498: INFO: namespace: e2e-tests-emptydir-pwdsz, resource: bindings, ignored listing per whitelist
Mar 23 00:54:32.536: INFO: namespace e2e-tests-emptydir-pwdsz deletion completed in 6.084089765s

• [SLOW TEST:8.171 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:54:32.536: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-389bdb28-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 00:54:32.648: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-389c547f-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-xls6d" to be "success or failure"
Mar 23 00:54:32.653: INFO: Pod "pod-projected-secrets-389c547f-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.76526ms
Mar 23 00:54:34.655: INFO: Pod "pod-projected-secrets-389c547f-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007642604s
STEP: Saw pod success
Mar 23 00:54:34.655: INFO: Pod "pod-projected-secrets-389c547f-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:54:34.658: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-389c547f-4d06-11e9-96f5-ea7d86f92d02 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 23 00:54:34.671: INFO: Waiting for pod pod-projected-secrets-389c547f-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:54:34.674: INFO: Pod pod-projected-secrets-389c547f-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:54:34.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xls6d" for this suite.
Mar 23 00:54:40.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:54:40.752: INFO: namespace: e2e-tests-projected-xls6d, resource: bindings, ignored listing per whitelist
Mar 23 00:54:40.763: INFO: namespace e2e-tests-projected-xls6d deletion completed in 6.085857286s

• [SLOW TEST:8.227 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:54:40.763: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:54:40.827: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d7c92a8-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-26hn4" to be "success or failure"
Mar 23 00:54:40.830: INFO: Pod "downwardapi-volume-3d7c92a8-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.091597ms
Mar 23 00:54:42.833: INFO: Pod "downwardapi-volume-3d7c92a8-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005766315s
STEP: Saw pod success
Mar 23 00:54:42.833: INFO: Pod "downwardapi-volume-3d7c92a8-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:54:42.835: INFO: Trying to get logs from node node-2 pod downwardapi-volume-3d7c92a8-4d06-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:54:42.849: INFO: Waiting for pod downwardapi-volume-3d7c92a8-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:54:42.851: INFO: Pod downwardapi-volume-3d7c92a8-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:54:42.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-26hn4" for this suite.
Mar 23 00:54:48.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:54:48.918: INFO: namespace: e2e-tests-projected-26hn4, resource: bindings, ignored listing per whitelist
Mar 23 00:54:48.940: INFO: namespace e2e-tests-projected-26hn4 deletion completed in 6.085353852s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:54:48.940: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar 23 00:54:49.000: INFO: Waiting up to 5m0s for pod "pod-425bc19e-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-982xb" to be "success or failure"
Mar 23 00:54:49.005: INFO: Pod "pod-425bc19e-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 5.145214ms
Mar 23 00:54:51.008: INFO: Pod "pod-425bc19e-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008257989s
STEP: Saw pod success
Mar 23 00:54:51.008: INFO: Pod "pod-425bc19e-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:54:51.011: INFO: Trying to get logs from node node-2 pod pod-425bc19e-4d06-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 00:54:51.026: INFO: Waiting for pod pod-425bc19e-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:54:51.028: INFO: Pod pod-425bc19e-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:54:51.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-982xb" for this suite.
Mar 23 00:54:57.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:54:57.087: INFO: namespace: e2e-tests-emptydir-982xb, resource: bindings, ignored listing per whitelist
Mar 23 00:54:57.116: INFO: namespace e2e-tests-emptydir-982xb deletion completed in 6.085021862s

• [SLOW TEST:8.176 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:54:57.116: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar 23 00:54:57.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 api-versions'
Mar 23 00:54:57.252: INFO: stderr: ""
Mar 23 00:54:57.252: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:54:57.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9cfwv" for this suite.
Mar 23 00:55:03.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:55:03.292: INFO: namespace: e2e-tests-kubectl-9cfwv, resource: bindings, ignored listing per whitelist
Mar 23 00:55:03.371: INFO: namespace e2e-tests-kubectl-9cfwv deletion completed in 6.11538457s

• [SLOW TEST:6.255 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:55:03.372: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 00:55:03.442: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4af72801-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-njdr9" to be "success or failure"
Mar 23 00:55:03.445: INFO: Pod "downwardapi-volume-4af72801-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.258335ms
Mar 23 00:55:05.449: INFO: Pod "downwardapi-volume-4af72801-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006575253s
STEP: Saw pod success
Mar 23 00:55:05.449: INFO: Pod "downwardapi-volume-4af72801-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:55:05.451: INFO: Trying to get logs from node node-2 pod downwardapi-volume-4af72801-4d06-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 00:55:05.465: INFO: Waiting for pod downwardapi-volume-4af72801-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:55:05.468: INFO: Pod downwardapi-volume-4af72801-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:55:05.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-njdr9" for this suite.
Mar 23 00:55:11.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:55:11.553: INFO: namespace: e2e-tests-downward-api-njdr9, resource: bindings, ignored listing per whitelist
Mar 23 00:55:11.566: INFO: namespace e2e-tests-downward-api-njdr9 deletion completed in 6.093755287s

• [SLOW TEST:8.194 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:55:11.566: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 23 00:55:11.624: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 23 00:55:11.630: INFO: Waiting for terminating namespaces to be deleted...
Mar 23 00:55:11.633: INFO: 
Logging pods the kubelet thinks is on node node-1 before test
Mar 23 00:55:11.639: INFO: default-http-backend-54bff6fc5d-2c5b4 from ingress-nginx started at 2019-03-22 23:54:04 +0000 UTC (1 container statuses recorded)
Mar 23 00:55:11.639: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 23 00:55:11.639: INFO: metrics-server-844bd95c7b-2nnxc from kube-system started at 2019-03-22 23:54:02 +0000 UTC (1 container statuses recorded)
Mar 23 00:55:11.639: INFO: 	Container metrics-server ready: true, restart count 0
Mar 23 00:55:11.639: INFO: rke-ingress-controller-deploy-job-p2bnl from kube-system started at 2019-03-22 23:54:03 +0000 UTC (1 container statuses recorded)
Mar 23 00:55:11.639: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 23 00:55:11.639: INFO: nginx-ingress-controller-q69fx from ingress-nginx started at 2019-03-22 23:54:04 +0000 UTC (1 container statuses recorded)
Mar 23 00:55:11.639: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 23 00:55:11.639: INFO: sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-swz92 from heptio-sonobuoy started at 2019-03-22 23:55:25 +0000 UTC (2 container statuses recorded)
Mar 23 00:55:11.639: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 23 00:55:11.639: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:55:11.639: INFO: rke-network-plugin-deploy-job-g47g4 from kube-system started at 2019-03-22 23:53:42 +0000 UTC (1 container statuses recorded)
Mar 23 00:55:11.639: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 23 00:55:11.639: INFO: rke-kube-dns-addon-deploy-job-ll858 from kube-system started at 2019-03-22 23:53:49 +0000 UTC (1 container statuses recorded)
Mar 23 00:55:11.639: INFO: 	Container rke-kube-dns-addon-pod ready: false, restart count 0
Mar 23 00:55:11.639: INFO: kube-dns-autoscaler-59cc69d67f-gczdw from kube-system started at 2019-03-22 23:54:02 +0000 UTC (1 container statuses recorded)
Mar 23 00:55:11.639: INFO: 	Container autoscaler ready: true, restart count 0
Mar 23 00:55:11.639: INFO: kube-dns-5c9cfc6cb9-c6f5q from kube-system started at 2019-03-22 23:54:02 +0000 UTC (3 container statuses recorded)
Mar 23 00:55:11.639: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 23 00:55:11.639: INFO: 	Container kubedns ready: true, restart count 0
Mar 23 00:55:11.639: INFO: 	Container sidecar ready: true, restart count 0
Mar 23 00:55:11.639: INFO: canal-xxshj from kube-system started at 2019-03-22 23:53:45 +0000 UTC (3 container statuses recorded)
Mar 23 00:55:11.639: INFO: 	Container calico-node ready: true, restart count 0
Mar 23 00:55:11.639: INFO: 	Container install-cni ready: true, restart count 0
Mar 23 00:55:11.639: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 23 00:55:11.639: INFO: rke-metrics-addon-deploy-job-lvhn9 from kube-system started at 2019-03-22 23:53:56 +0000 UTC (1 container statuses recorded)
Mar 23 00:55:11.639: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 23 00:55:11.639: INFO: 
Logging pods the kubelet thinks is on node node-2 before test
Mar 23 00:55:11.644: INFO: canal-vqzvc from kube-system started at 2019-03-22 23:53:45 +0000 UTC (3 container statuses recorded)
Mar 23 00:55:11.644: INFO: 	Container calico-node ready: true, restart count 0
Mar 23 00:55:11.644: INFO: 	Container install-cni ready: true, restart count 0
Mar 23 00:55:11.644: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 23 00:55:11.644: INFO: nginx-ingress-controller-qvs56 from ingress-nginx started at 2019-03-22 23:54:07 +0000 UTC (1 container statuses recorded)
Mar 23 00:55:11.644: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 23 00:55:11.644: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-22 23:55:22 +0000 UTC (1 container statuses recorded)
Mar 23 00:55:11.644: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 23 00:55:11.644: INFO: sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-d7tzm from heptio-sonobuoy started at 2019-03-22 23:55:25 +0000 UTC (2 container statuses recorded)
Mar 23 00:55:11.644: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 23 00:55:11.644: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:55:11.644: INFO: 
Logging pods the kubelet thinks is on node node-3 before test
Mar 23 00:55:11.648: INFO: sonobuoy-e2e-job-08fc2d888de548b8 from heptio-sonobuoy started at 2019-03-22 23:55:24 +0000 UTC (2 container statuses recorded)
Mar 23 00:55:11.648: INFO: 	Container e2e ready: true, restart count 0
Mar 23 00:55:11.648: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:55:11.648: INFO: sonobuoy-systemd-logs-daemon-set-a625e05720d24c5b-zn4k6 from heptio-sonobuoy started at 2019-03-22 23:55:25 +0000 UTC (2 container statuses recorded)
Mar 23 00:55:11.648: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 23 00:55:11.649: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 23 00:55:11.649: INFO: canal-5gdw5 from kube-system started at 2019-03-22 23:53:45 +0000 UTC (3 container statuses recorded)
Mar 23 00:55:11.649: INFO: 	Container calico-node ready: true, restart count 0
Mar 23 00:55:11.649: INFO: 	Container install-cni ready: true, restart count 0
Mar 23 00:55:11.649: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 23 00:55:11.649: INFO: nginx-ingress-controller-lf7sv from ingress-nginx started at 2019-03-22 23:54:07 +0000 UTC (1 container statuses recorded)
Mar 23 00:55:11.649: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-511063b9-4d06-11e9-96f5-ea7d86f92d02 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-511063b9-4d06-11e9-96f5-ea7d86f92d02 off the node node-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-511063b9-4d06-11e9-96f5-ea7d86f92d02
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:55:15.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-bmbbf" for this suite.
Mar 23 00:55:27.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:55:27.791: INFO: namespace: e2e-tests-sched-pred-bmbbf, resource: bindings, ignored listing per whitelist
Mar 23 00:55:27.793: INFO: namespace e2e-tests-sched-pred-bmbbf deletion completed in 12.0843288s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:16.227 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:55:27.793: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-5984874b-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating configMap with name cm-test-opt-upd-59848789-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5984874b-4d06-11e9-96f5-ea7d86f92d02
STEP: Updating configmap cm-test-opt-upd-59848789-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating configMap with name cm-test-opt-create-598487a2-4d06-11e9-96f5-ea7d86f92d02
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:55:31.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zlsj2" for this suite.
Mar 23 00:55:53.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:55:53.955: INFO: namespace: e2e-tests-configmap-zlsj2, resource: bindings, ignored listing per whitelist
Mar 23 00:55:54.013: INFO: namespace e2e-tests-configmap-zlsj2 deletion completed in 22.088106521s

• [SLOW TEST:26.220 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:55:54.013: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-692642b6-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 00:55:54.084: INFO: Waiting up to 5m0s for pod "pod-configmaps-6926b076-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-configmap-hs8vl" to be "success or failure"
Mar 23 00:55:54.090: INFO: Pod "pod-configmaps-6926b076-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 5.368553ms
Mar 23 00:55:56.092: INFO: Pod "pod-configmaps-6926b076-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008283259s
STEP: Saw pod success
Mar 23 00:55:56.093: INFO: Pod "pod-configmaps-6926b076-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:55:56.095: INFO: Trying to get logs from node node-2 pod pod-configmaps-6926b076-4d06-11e9-96f5-ea7d86f92d02 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 23 00:55:56.110: INFO: Waiting for pod pod-configmaps-6926b076-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:55:56.112: INFO: Pod pod-configmaps-6926b076-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:55:56.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hs8vl" for this suite.
Mar 23 00:56:02.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:56:02.208: INFO: namespace: e2e-tests-configmap-hs8vl, resource: bindings, ignored listing per whitelist
Mar 23 00:56:02.212: INFO: namespace e2e-tests-configmap-hs8vl deletion completed in 6.09645592s

• [SLOW TEST:8.199 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:56:02.213: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 23 00:56:02.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-n9bw8'
Mar 23 00:56:02.355: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 23 00:56:02.355: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Mar 23 00:56:02.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-n9bw8'
Mar 23 00:56:02.447: INFO: stderr: ""
Mar 23 00:56:02.447: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:56:02.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n9bw8" for this suite.
Mar 23 00:56:08.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:56:08.498: INFO: namespace: e2e-tests-kubectl-n9bw8, resource: bindings, ignored listing per whitelist
Mar 23 00:56:08.535: INFO: namespace e2e-tests-kubectl-n9bw8 deletion completed in 6.081770378s

• [SLOW TEST:6.322 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:56:08.535: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar 23 00:56:10.606: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-71ccac02-4d06-11e9-96f5-ea7d86f92d02", GenerateName:"", Namespace:"e2e-tests-pods-g7sz5", SelfLink:"/api/v1/namespaces/e2e-tests-pods-g7sz5/pods/pod-submit-remove-71ccac02-4d06-11e9-96f5-ea7d86f92d02", UID:"71cbe254-4d06-11e9-9a5c-0646f33e71ba", ResourceVersion:"12673", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688899368, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"589215398"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.2.137/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-tzff7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422f15f00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tzff7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421d25b18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"node-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc422f758c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421d25b60)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421d25b80)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421d25b88), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899368, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899369, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899369, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899368, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.45.82", PodIP:"10.42.2.137", StartTime:(*v1.Time)(0xc4223f89e0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4223f8a00), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d", ContainerID:"docker://066f9445345039791913a0692a396e4b9f3e6cb80d89af1d00612964be4a1151"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar 23 00:56:15.617: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:56:15.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-g7sz5" for this suite.
Mar 23 00:56:21.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:56:21.676: INFO: namespace: e2e-tests-pods-g7sz5, resource: bindings, ignored listing per whitelist
Mar 23 00:56:21.711: INFO: namespace e2e-tests-pods-g7sz5 deletion completed in 6.088226132s

• [SLOW TEST:13.176 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:56:21.711: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-79a7db3b-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 00:56:21.778: INFO: Waiting up to 5m0s for pod "pod-secrets-79a865e9-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-secrets-9ntcp" to be "success or failure"
Mar 23 00:56:21.785: INFO: Pod "pod-secrets-79a865e9-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 6.977493ms
Mar 23 00:56:23.788: INFO: Pod "pod-secrets-79a865e9-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009747815s
STEP: Saw pod success
Mar 23 00:56:23.788: INFO: Pod "pod-secrets-79a865e9-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:56:23.790: INFO: Trying to get logs from node node-2 pod pod-secrets-79a865e9-4d06-11e9-96f5-ea7d86f92d02 container secret-volume-test: <nil>
STEP: delete the pod
Mar 23 00:56:23.803: INFO: Waiting for pod pod-secrets-79a865e9-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:56:23.805: INFO: Pod pod-secrets-79a865e9-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:56:23.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9ntcp" for this suite.
Mar 23 00:56:29.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:56:29.856: INFO: namespace: e2e-tests-secrets-9ntcp, resource: bindings, ignored listing per whitelist
Mar 23 00:56:29.888: INFO: namespace e2e-tests-secrets-9ntcp deletion completed in 6.079992638s

• [SLOW TEST:8.177 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:56:29.889: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 00:56:29.945: INFO: (0) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.745833ms)
Mar 23 00:56:29.947: INFO: (1) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.44286ms)
Mar 23 00:56:29.950: INFO: (2) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.516154ms)
Mar 23 00:56:29.952: INFO: (3) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.520788ms)
Mar 23 00:56:29.955: INFO: (4) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.370403ms)
Mar 23 00:56:29.957: INFO: (5) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.48108ms)
Mar 23 00:56:29.959: INFO: (6) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.330453ms)
Mar 23 00:56:29.962: INFO: (7) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.584717ms)
Mar 23 00:56:29.967: INFO: (8) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.733352ms)
Mar 23 00:56:29.970: INFO: (9) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.094828ms)
Mar 23 00:56:29.973: INFO: (10) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.793054ms)
Mar 23 00:56:29.975: INFO: (11) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.606841ms)
Mar 23 00:56:29.978: INFO: (12) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.602669ms)
Mar 23 00:56:29.980: INFO: (13) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.505327ms)
Mar 23 00:56:29.983: INFO: (14) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.429183ms)
Mar 23 00:56:29.985: INFO: (15) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.487693ms)
Mar 23 00:56:29.988: INFO: (16) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.593118ms)
Mar 23 00:56:29.990: INFO: (17) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.421183ms)
Mar 23 00:56:29.993: INFO: (18) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.515002ms)
Mar 23 00:56:29.996: INFO: (19) /api/v1/nodes/node-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.533018ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:56:29.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-s7kpn" for this suite.
Mar 23 00:56:36.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:56:36.048: INFO: namespace: e2e-tests-proxy-s7kpn, resource: bindings, ignored listing per whitelist
Mar 23 00:56:36.090: INFO: namespace e2e-tests-proxy-s7kpn deletion completed in 6.091145909s

• [SLOW TEST:6.201 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:56:36.090: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-8239358c-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 00:56:36.151: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8239ad46-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-4vddx" to be "success or failure"
Mar 23 00:56:36.153: INFO: Pod "pod-projected-configmaps-8239ad46-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.096536ms
Mar 23 00:56:38.156: INFO: Pod "pod-projected-configmaps-8239ad46-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004915664s
STEP: Saw pod success
Mar 23 00:56:38.156: INFO: Pod "pod-projected-configmaps-8239ad46-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:56:38.158: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-8239ad46-4d06-11e9-96f5-ea7d86f92d02 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 23 00:56:38.174: INFO: Waiting for pod pod-projected-configmaps-8239ad46-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:56:38.175: INFO: Pod pod-projected-configmaps-8239ad46-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:56:38.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4vddx" for this suite.
Mar 23 00:56:44.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:56:44.225: INFO: namespace: e2e-tests-projected-4vddx, resource: bindings, ignored listing per whitelist
Mar 23 00:56:44.271: INFO: namespace e2e-tests-projected-4vddx deletion completed in 6.092925592s

• [SLOW TEST:8.182 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:56:44.271: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-t9mqm
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-t9mqm
STEP: Deleting pre-stop pod
Mar 23 00:56:55.383: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:56:55.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-t9mqm" for this suite.
Mar 23 00:57:33.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:57:33.469: INFO: namespace: e2e-tests-prestop-t9mqm, resource: bindings, ignored listing per whitelist
Mar 23 00:57:33.477: INFO: namespace e2e-tests-prestop-t9mqm deletion completed in 38.085384941s

• [SLOW TEST:49.205 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:57:33.477: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar 23 00:57:33.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 --namespace=e2e-tests-kubectl-pfjvj run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 23 00:57:35.442: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 23 00:57:35.442: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:57:37.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pfjvj" for this suite.
Mar 23 00:57:43.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:57:43.510: INFO: namespace: e2e-tests-kubectl-pfjvj, resource: bindings, ignored listing per whitelist
Mar 23 00:57:43.536: INFO: namespace e2e-tests-kubectl-pfjvj deletion completed in 6.086822791s

• [SLOW TEST:10.060 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:57:43.537: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 23 00:57:46.113: INFO: Successfully updated pod "pod-update-activedeadlineseconds-aa6cee72-4d06-11e9-96f5-ea7d86f92d02"
Mar 23 00:57:46.113: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-aa6cee72-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-pods-vbtqn" to be "terminated due to deadline exceeded"
Mar 23 00:57:46.116: INFO: Pod "pod-update-activedeadlineseconds-aa6cee72-4d06-11e9-96f5-ea7d86f92d02": Phase="Running", Reason="", readiness=true. Elapsed: 2.858223ms
Mar 23 00:57:48.118: INFO: Pod "pod-update-activedeadlineseconds-aa6cee72-4d06-11e9-96f5-ea7d86f92d02": Phase="Running", Reason="", readiness=true. Elapsed: 2.005758477s
Mar 23 00:57:50.121: INFO: Pod "pod-update-activedeadlineseconds-aa6cee72-4d06-11e9-96f5-ea7d86f92d02": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.008526728s
Mar 23 00:57:50.121: INFO: Pod "pod-update-activedeadlineseconds-aa6cee72-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:57:50.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vbtqn" for this suite.
Mar 23 00:57:56.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:57:56.152: INFO: namespace: e2e-tests-pods-vbtqn, resource: bindings, ignored listing per whitelist
Mar 23 00:57:56.216: INFO: namespace e2e-tests-pods-vbtqn deletion completed in 6.091235452s

• [SLOW TEST:12.679 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:57:56.216: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 23 00:57:56.273: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:57:58.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-9pdt2" for this suite.
Mar 23 00:58:04.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:58:04.616: INFO: namespace: e2e-tests-init-container-9pdt2, resource: bindings, ignored listing per whitelist
Mar 23 00:58:04.634: INFO: namespace e2e-tests-init-container-9pdt2 deletion completed in 6.090585175s

• [SLOW TEST:8.418 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:58:04.634: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-b700cd1b-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating configMap with name cm-test-opt-upd-b700cd64-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b700cd1b-4d06-11e9-96f5-ea7d86f92d02
STEP: Updating configmap cm-test-opt-upd-b700cd64-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating configMap with name cm-test-opt-create-b700cd82-4d06-11e9-96f5-ea7d86f92d02
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:58:10.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d4bvm" for this suite.
Mar 23 00:58:22.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:58:22.849: INFO: namespace: e2e-tests-projected-d4bvm, resource: bindings, ignored listing per whitelist
Mar 23 00:58:22.864: INFO: namespace e2e-tests-projected-d4bvm deletion completed in 12.085124998s

• [SLOW TEST:18.230 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:58:22.864: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c1ddcb14-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 00:58:22.926: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1de3a39-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-configmap-85rjr" to be "success or failure"
Mar 23 00:58:22.937: INFO: Pod "pod-configmaps-c1de3a39-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 11.054247ms
Mar 23 00:58:24.940: INFO: Pod "pod-configmaps-c1de3a39-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014199614s
STEP: Saw pod success
Mar 23 00:58:24.940: INFO: Pod "pod-configmaps-c1de3a39-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:58:24.942: INFO: Trying to get logs from node node-2 pod pod-configmaps-c1de3a39-4d06-11e9-96f5-ea7d86f92d02 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 23 00:58:24.956: INFO: Waiting for pod pod-configmaps-c1de3a39-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:58:24.958: INFO: Pod pod-configmaps-c1de3a39-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:58:24.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-85rjr" for this suite.
Mar 23 00:58:30.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:58:31.033: INFO: namespace: e2e-tests-configmap-85rjr, resource: bindings, ignored listing per whitelist
Mar 23 00:58:31.048: INFO: namespace e2e-tests-configmap-85rjr deletion completed in 6.086209968s

• [SLOW TEST:8.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:58:31.048: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 23 00:58:33.626: INFO: Successfully updated pod "annotationupdatec6bdf919-4d06-11e9-96f5-ea7d86f92d02"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:58:35.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f88fb" for this suite.
Mar 23 00:58:57.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:58:57.689: INFO: namespace: e2e-tests-projected-f88fb, resource: bindings, ignored listing per whitelist
Mar 23 00:58:57.725: INFO: namespace e2e-tests-projected-f88fb deletion completed in 22.082535002s

• [SLOW TEST:26.677 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:58:57.725: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-d6a53199-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating secret with name secret-projected-all-test-volume-d6a53180-4d06-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar 23 00:58:57.789: INFO: Waiting up to 5m0s for pod "projected-volume-d6a5314c-4d06-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-f88pv" to be "success or failure"
Mar 23 00:58:57.795: INFO: Pod "projected-volume-d6a5314c-4d06-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 5.173312ms
Mar 23 00:58:59.797: INFO: Pod "projected-volume-d6a5314c-4d06-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007989067s
STEP: Saw pod success
Mar 23 00:58:59.797: INFO: Pod "projected-volume-d6a5314c-4d06-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 00:58:59.800: INFO: Trying to get logs from node node-2 pod projected-volume-d6a5314c-4d06-11e9-96f5-ea7d86f92d02 container projected-all-volume-test: <nil>
STEP: delete the pod
Mar 23 00:58:59.817: INFO: Waiting for pod projected-volume-d6a5314c-4d06-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 00:58:59.818: INFO: Pod projected-volume-d6a5314c-4d06-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 00:58:59.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f88pv" for this suite.
Mar 23 00:59:05.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 00:59:05.889: INFO: namespace: e2e-tests-projected-f88pv, resource: bindings, ignored listing per whitelist
Mar 23 00:59:05.905: INFO: namespace e2e-tests-projected-f88pv deletion completed in 6.083306826s

• [SLOW TEST:8.180 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 00:59:05.905: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-gdcdx
Mar 23 00:59:07.970: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-gdcdx
STEP: checking the pod's current state and verifying that restartCount is present
Mar 23 00:59:07.972: INFO: Initial restart count of pod liveness-http is 0
Mar 23 00:59:19.991: INFO: Restart count of pod e2e-tests-container-probe-gdcdx/liveness-http is now 1 (12.019004926s elapsed)
Mar 23 00:59:40.021: INFO: Restart count of pod e2e-tests-container-probe-gdcdx/liveness-http is now 2 (32.048905411s elapsed)
Mar 23 01:00:00.059: INFO: Restart count of pod e2e-tests-container-probe-gdcdx/liveness-http is now 3 (52.086918077s elapsed)
Mar 23 01:00:20.112: INFO: Restart count of pod e2e-tests-container-probe-gdcdx/liveness-http is now 4 (1m12.140020479s elapsed)
Mar 23 01:01:20.202: INFO: Restart count of pod e2e-tests-container-probe-gdcdx/liveness-http is now 5 (2m12.229141028s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:01:20.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gdcdx" for this suite.
Mar 23 01:01:26.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:01:26.283: INFO: namespace: e2e-tests-container-probe-gdcdx, resource: bindings, ignored listing per whitelist
Mar 23 01:01:26.307: INFO: namespace e2e-tests-container-probe-gdcdx deletion completed in 6.093354241s

• [SLOW TEST:140.402 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:01:26.307: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar 23 01:01:26.367: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-c8bmg" to be "success or failure"
Mar 23 01:01:26.372: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.24752ms
Mar 23 01:01:28.377: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009900192s
STEP: Saw pod success
Mar 23 01:01:28.377: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 23 01:01:28.379: INFO: Trying to get logs from node node-3 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar 23 01:01:28.394: INFO: Waiting for pod pod-host-path-test to disappear
Mar 23 01:01:28.396: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:01:28.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-c8bmg" for this suite.
Mar 23 01:01:34.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:01:34.478: INFO: namespace: e2e-tests-hostpath-c8bmg, resource: bindings, ignored listing per whitelist
Mar 23 01:01:34.483: INFO: namespace e2e-tests-hostpath-c8bmg deletion completed in 6.081651009s

• [SLOW TEST:8.176 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:01:34.484: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 01:01:34.542: INFO: Waiting up to 5m0s for pod "downwardapi-volume-341481ec-4d07-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-2dgwb" to be "success or failure"
Mar 23 01:01:34.546: INFO: Pod "downwardapi-volume-341481ec-4d07-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.762931ms
Mar 23 01:01:36.549: INFO: Pod "downwardapi-volume-341481ec-4d07-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006733008s
STEP: Saw pod success
Mar 23 01:01:36.549: INFO: Pod "downwardapi-volume-341481ec-4d07-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:01:36.551: INFO: Trying to get logs from node node-2 pod downwardapi-volume-341481ec-4d07-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 01:01:36.564: INFO: Waiting for pod downwardapi-volume-341481ec-4d07-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:01:36.567: INFO: Pod downwardapi-volume-341481ec-4d07-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:01:36.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2dgwb" for this suite.
Mar 23 01:01:42.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:01:42.602: INFO: namespace: e2e-tests-projected-2dgwb, resource: bindings, ignored listing per whitelist
Mar 23 01:01:42.651: INFO: namespace e2e-tests-projected-2dgwb deletion completed in 6.081033019s

• [SLOW TEST:8.168 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:01:42.651: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 01:01:44.734: INFO: Waiting up to 5m0s for pod "client-envvars-3a270560-4d07-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-pods-wfsmm" to be "success or failure"
Mar 23 01:01:44.745: INFO: Pod "client-envvars-3a270560-4d07-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 11.257331ms
Mar 23 01:01:46.748: INFO: Pod "client-envvars-3a270560-4d07-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014348767s
STEP: Saw pod success
Mar 23 01:01:46.748: INFO: Pod "client-envvars-3a270560-4d07-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:01:46.750: INFO: Trying to get logs from node node-2 pod client-envvars-3a270560-4d07-11e9-96f5-ea7d86f92d02 container env3cont: <nil>
STEP: delete the pod
Mar 23 01:01:46.764: INFO: Waiting for pod client-envvars-3a270560-4d07-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:01:46.766: INFO: Pod client-envvars-3a270560-4d07-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:01:46.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wfsmm" for this suite.
Mar 23 01:02:28.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:02:28.798: INFO: namespace: e2e-tests-pods-wfsmm, resource: bindings, ignored listing per whitelist
Mar 23 01:02:28.852: INFO: namespace e2e-tests-pods-wfsmm deletion completed in 42.082808938s

• [SLOW TEST:46.201 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:02:28.852: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 23 01:02:28.915: INFO: Waiting up to 5m0s for pod "downward-api-547cc822-4d07-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-9w9t7" to be "success or failure"
Mar 23 01:02:28.921: INFO: Pod "downward-api-547cc822-4d07-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 5.942812ms
Mar 23 01:02:30.924: INFO: Pod "downward-api-547cc822-4d07-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008835675s
STEP: Saw pod success
Mar 23 01:02:30.924: INFO: Pod "downward-api-547cc822-4d07-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:02:30.926: INFO: Trying to get logs from node node-2 pod downward-api-547cc822-4d07-11e9-96f5-ea7d86f92d02 container dapi-container: <nil>
STEP: delete the pod
Mar 23 01:02:30.940: INFO: Waiting for pod downward-api-547cc822-4d07-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:02:30.943: INFO: Pod downward-api-547cc822-4d07-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:02:30.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9w9t7" for this suite.
Mar 23 01:02:36.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:02:36.973: INFO: namespace: e2e-tests-downward-api-9w9t7, resource: bindings, ignored listing per whitelist
Mar 23 01:02:37.030: INFO: namespace e2e-tests-downward-api-9w9t7 deletion completed in 6.084042457s

• [SLOW TEST:8.177 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:02:37.030: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-595bd209-4d07-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 01:02:37.089: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-595c3448-4d07-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-s79bw" to be "success or failure"
Mar 23 01:02:37.091: INFO: Pod "pod-projected-secrets-595c3448-4d07-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.460224ms
Mar 23 01:02:39.094: INFO: Pod "pod-projected-secrets-595c3448-4d07-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004935258s
STEP: Saw pod success
Mar 23 01:02:39.094: INFO: Pod "pod-projected-secrets-595c3448-4d07-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:02:39.097: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-595c3448-4d07-11e9-96f5-ea7d86f92d02 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 23 01:02:39.111: INFO: Waiting for pod pod-projected-secrets-595c3448-4d07-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:02:39.114: INFO: Pod pod-projected-secrets-595c3448-4d07-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:02:39.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s79bw" for this suite.
Mar 23 01:02:45.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:02:45.134: INFO: namespace: e2e-tests-projected-s79bw, resource: bindings, ignored listing per whitelist
Mar 23 01:02:45.198: INFO: namespace e2e-tests-projected-s79bw deletion completed in 6.081510248s

• [SLOW TEST:8.168 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:02:45.198: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-5e3ab04e-4d07-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 01:02:45.259: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e3b1aee-4d07-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-configmap-x2t76" to be "success or failure"
Mar 23 01:02:45.262: INFO: Pod "pod-configmaps-5e3b1aee-4d07-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.588062ms
Mar 23 01:02:47.264: INFO: Pod "pod-configmaps-5e3b1aee-4d07-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005462427s
STEP: Saw pod success
Mar 23 01:02:47.264: INFO: Pod "pod-configmaps-5e3b1aee-4d07-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:02:47.266: INFO: Trying to get logs from node node-2 pod pod-configmaps-5e3b1aee-4d07-11e9-96f5-ea7d86f92d02 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 23 01:02:47.284: INFO: Waiting for pod pod-configmaps-5e3b1aee-4d07-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:02:47.286: INFO: Pod pod-configmaps-5e3b1aee-4d07-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:02:47.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x2t76" for this suite.
Mar 23 01:02:53.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:02:53.376: INFO: namespace: e2e-tests-configmap-x2t76, resource: bindings, ignored listing per whitelist
Mar 23 01:02:53.468: INFO: namespace e2e-tests-configmap-x2t76 deletion completed in 6.177744554s

• [SLOW TEST:8.270 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:02:53.468: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6327f38e-4d07-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 01:02:53.527: INFO: Waiting up to 5m0s for pod "pod-secrets-63286772-4d07-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-secrets-pxhjq" to be "success or failure"
Mar 23 01:02:53.534: INFO: Pod "pod-secrets-63286772-4d07-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 7.096797ms
Mar 23 01:02:55.537: INFO: Pod "pod-secrets-63286772-4d07-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01002568s
STEP: Saw pod success
Mar 23 01:02:55.537: INFO: Pod "pod-secrets-63286772-4d07-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:02:55.539: INFO: Trying to get logs from node node-2 pod pod-secrets-63286772-4d07-11e9-96f5-ea7d86f92d02 container secret-volume-test: <nil>
STEP: delete the pod
Mar 23 01:02:55.555: INFO: Waiting for pod pod-secrets-63286772-4d07-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:02:55.557: INFO: Pod pod-secrets-63286772-4d07-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:02:55.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pxhjq" for this suite.
Mar 23 01:03:01.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:03:01.643: INFO: namespace: e2e-tests-secrets-pxhjq, resource: bindings, ignored listing per whitelist
Mar 23 01:03:01.689: INFO: namespace e2e-tests-secrets-pxhjq deletion completed in 6.128581017s

• [SLOW TEST:8.220 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:03:01.689: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 23 01:03:01.749: INFO: Waiting up to 5m0s for pod "pod-680f5a94-4d07-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-vtnx4" to be "success or failure"
Mar 23 01:03:01.752: INFO: Pod "pod-680f5a94-4d07-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.14805ms
Mar 23 01:03:03.755: INFO: Pod "pod-680f5a94-4d07-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005698819s
STEP: Saw pod success
Mar 23 01:03:03.755: INFO: Pod "pod-680f5a94-4d07-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:03:03.758: INFO: Trying to get logs from node node-2 pod pod-680f5a94-4d07-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 01:03:03.774: INFO: Waiting for pod pod-680f5a94-4d07-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:03:03.776: INFO: Pod pod-680f5a94-4d07-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:03:03.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vtnx4" for this suite.
Mar 23 01:03:09.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:03:09.805: INFO: namespace: e2e-tests-emptydir-vtnx4, resource: bindings, ignored listing per whitelist
Mar 23 01:03:09.869: INFO: namespace e2e-tests-emptydir-vtnx4 deletion completed in 6.088926229s

• [SLOW TEST:8.180 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:03:09.869: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-6cef086c-4d07-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 01:03:09.929: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6cef761e-4d07-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-c8kcg" to be "success or failure"
Mar 23 01:03:09.931: INFO: Pod "pod-projected-secrets-6cef761e-4d07-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.143371ms
Mar 23 01:03:11.934: INFO: Pod "pod-projected-secrets-6cef761e-4d07-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005184677s
STEP: Saw pod success
Mar 23 01:03:11.934: INFO: Pod "pod-projected-secrets-6cef761e-4d07-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:03:11.936: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-6cef761e-4d07-11e9-96f5-ea7d86f92d02 container secret-volume-test: <nil>
STEP: delete the pod
Mar 23 01:03:11.953: INFO: Waiting for pod pod-projected-secrets-6cef761e-4d07-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:03:11.955: INFO: Pod pod-projected-secrets-6cef761e-4d07-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:03:11.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c8kcg" for this suite.
Mar 23 01:03:17.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:03:18.006: INFO: namespace: e2e-tests-projected-c8kcg, resource: bindings, ignored listing per whitelist
Mar 23 01:03:18.043: INFO: namespace e2e-tests-projected-c8kcg deletion completed in 6.084627934s

• [SLOW TEST:8.174 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:03:18.043: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar 23 01:03:18.100: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar 23 01:03:18.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:18.281: INFO: stderr: ""
Mar 23 01:03:18.282: INFO: stdout: "service/redis-slave created\n"
Mar 23 01:03:18.282: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar 23 01:03:18.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:18.449: INFO: stderr: ""
Mar 23 01:03:18.449: INFO: stdout: "service/redis-master created\n"
Mar 23 01:03:18.449: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 23 01:03:18.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:18.617: INFO: stderr: ""
Mar 23 01:03:18.617: INFO: stdout: "service/frontend created\n"
Mar 23 01:03:18.617: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar 23 01:03:18.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:18.783: INFO: stderr: ""
Mar 23 01:03:18.783: INFO: stdout: "deployment.extensions/frontend created\n"
Mar 23 01:03:18.784: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 23 01:03:18.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:18.953: INFO: stderr: ""
Mar 23 01:03:18.953: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar 23 01:03:18.953: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar 23 01:03:18.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:19.105: INFO: stderr: ""
Mar 23 01:03:19.105: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar 23 01:03:19.105: INFO: Waiting for all frontend pods to be Running.
Mar 23 01:03:34.156: INFO: Waiting for frontend to serve content.
Mar 23 01:03:39.172: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Mar 23 01:03:44.183: INFO: Trying to add a new entry to the guestbook.
Mar 23 01:03:44.192: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar 23 01:03:44.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:44.296: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 23 01:03:44.297: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar 23 01:03:44.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:44.399: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 23 01:03:44.399: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 23 01:03:44.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:44.498: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 23 01:03:44.498: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 23 01:03:44.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:44.588: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 23 01:03:44.589: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 23 01:03:44.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:44.699: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 23 01:03:44.699: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 23 01:03:44.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wt5mt'
Mar 23 01:03:44.824: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 23 01:03:44.824: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:03:44.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wt5mt" for this suite.
Mar 23 01:04:30.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:04:30.861: INFO: namespace: e2e-tests-kubectl-wt5mt, resource: bindings, ignored listing per whitelist
Mar 23 01:04:30.925: INFO: namespace e2e-tests-kubectl-wt5mt deletion completed in 46.092173115s

• [SLOW TEST:72.882 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:04:30.925: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 01:04:30.991: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d4070b3-4d07-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-grpvx" to be "success or failure"
Mar 23 01:04:30.996: INFO: Pod "downwardapi-volume-9d4070b3-4d07-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.746521ms
Mar 23 01:04:32.999: INFO: Pod "downwardapi-volume-9d4070b3-4d07-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00778065s
STEP: Saw pod success
Mar 23 01:04:32.999: INFO: Pod "downwardapi-volume-9d4070b3-4d07-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:04:33.001: INFO: Trying to get logs from node node-2 pod downwardapi-volume-9d4070b3-4d07-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 01:04:33.015: INFO: Waiting for pod downwardapi-volume-9d4070b3-4d07-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:04:33.018: INFO: Pod downwardapi-volume-9d4070b3-4d07-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:04:33.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-grpvx" for this suite.
Mar 23 01:04:39.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:04:39.096: INFO: namespace: e2e-tests-downward-api-grpvx, resource: bindings, ignored listing per whitelist
Mar 23 01:04:39.106: INFO: namespace e2e-tests-downward-api-grpvx deletion completed in 6.084641852s

• [SLOW TEST:8.181 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:04:39.106: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 01:04:39.162: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 23 01:04:44.165: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 23 01:04:44.165: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 23 01:04:46.167: INFO: Creating deployment "test-rollover-deployment"
Mar 23 01:04:46.173: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 23 01:04:48.178: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 23 01:04:48.182: INFO: Ensure that both replica sets have 1 created replica
Mar 23 01:04:48.186: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 23 01:04:48.192: INFO: Updating deployment test-rollover-deployment
Mar 23 01:04:48.192: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 23 01:04:50.199: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 23 01:04:50.205: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 23 01:04:50.211: INFO: all replica sets need to contain the pod-template-hash label
Mar 23 01:04:50.211: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899889, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 23 01:04:52.217: INFO: all replica sets need to contain the pod-template-hash label
Mar 23 01:04:52.217: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899889, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 23 01:04:54.216: INFO: all replica sets need to contain the pod-template-hash label
Mar 23 01:04:54.216: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899889, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 23 01:04:56.217: INFO: all replica sets need to contain the pod-template-hash label
Mar 23 01:04:56.217: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899889, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 23 01:04:58.216: INFO: all replica sets need to contain the pod-template-hash label
Mar 23 01:04:58.217: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899889, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688899886, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 23 01:05:00.218: INFO: 
Mar 23 01:05:00.218: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 23 01:05:00.227: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-lq7pl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lq7pl/deployments/test-rollover-deployment,UID:a64c9f95-4d07-11e9-9a5c-0646f33e71ba,ResourceVersion:14479,Generation:2,CreationTimestamp:2019-03-23 01:04:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-23 01:04:46 +0000 UTC 2019-03-23 01:04:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-23 01:04:59 +0000 UTC 2019-03-23 01:04:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 23 01:05:00.230: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-lq7pl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lq7pl/replicasets/test-rollover-deployment-5b76ff8c4,UID:a7816fdd-4d07-11e9-9a5c-0646f33e71ba,ResourceVersion:14470,Generation:2,CreationTimestamp:2019-03-23 01:04:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a64c9f95-4d07-11e9-9a5c-0646f33e71ba 0xc421abe117 0xc421abe118}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 23 01:05:00.230: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 23 01:05:00.230: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-lq7pl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lq7pl/replicasets/test-rollover-controller,UID:a21eace9-4d07-11e9-9a5c-0646f33e71ba,ResourceVersion:14478,Generation:2,CreationTimestamp:2019-03-23 01:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a64c9f95-4d07-11e9-9a5c-0646f33e71ba 0xc421abe04e 0xc421abe04f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 23 01:05:00.230: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-lq7pl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lq7pl/replicasets/test-rollover-deployment-6975f4fb87,UID:a64e5bff-4d07-11e9-9a5c-0646f33e71ba,ResourceVersion:14442,Generation:2,CreationTimestamp:2019-03-23 01:04:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a64c9f95-4d07-11e9-9a5c-0646f33e71ba 0xc421abe1d7 0xc421abe1d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 23 01:05:00.233: INFO: Pod "test-rollover-deployment-5b76ff8c4-d7px8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-d7px8,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-lq7pl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lq7pl/pods/test-rollover-deployment-5b76ff8c4-d7px8,UID:a7856567-4d07-11e9-9a5c-0646f33e71ba,ResourceVersion:14452,Generation:0,CreationTimestamp:2019-03-23 01:04:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.164/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 a7816fdd-4d07-11e9-9a5c-0646f33e71ba 0xc421abef80 0xc421abef81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-thz6x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-thz6x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-thz6x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421abeff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421abf010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:04:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:04:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:04:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:04:48 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:10.42.2.164,StartTime:2019-03-23 01:04:48 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-23 01:04:49 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3ca0e5eb1aff523532f25875e470dd1eb2afd15c8d58b224953d623ff0dbc73e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:05:00.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lq7pl" for this suite.
Mar 23 01:05:06.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:05:06.295: INFO: namespace: e2e-tests-deployment-lq7pl, resource: bindings, ignored listing per whitelist
Mar 23 01:05:06.326: INFO: namespace e2e-tests-deployment-lq7pl deletion completed in 6.088839335s

• [SLOW TEST:27.220 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:05:06.326: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 23 01:05:06.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:06.555: INFO: stderr: ""
Mar 23 01:05:06.555: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 23 01:05:06.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:06.642: INFO: stderr: ""
Mar 23 01:05:06.642: INFO: stdout: "update-demo-nautilus-7xhcd update-demo-nautilus-s8wm9 "
Mar 23 01:05:06.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-7xhcd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:06.734: INFO: stderr: ""
Mar 23 01:05:06.734: INFO: stdout: ""
Mar 23 01:05:06.734: INFO: update-demo-nautilus-7xhcd is created but not running
Mar 23 01:05:11.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:11.815: INFO: stderr: ""
Mar 23 01:05:11.815: INFO: stdout: "update-demo-nautilus-7xhcd update-demo-nautilus-s8wm9 "
Mar 23 01:05:11.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-7xhcd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:11.895: INFO: stderr: ""
Mar 23 01:05:11.895: INFO: stdout: "true"
Mar 23 01:05:11.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-7xhcd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:11.973: INFO: stderr: ""
Mar 23 01:05:11.973: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 23 01:05:11.973: INFO: validating pod update-demo-nautilus-7xhcd
Mar 23 01:05:11.978: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 23 01:05:11.978: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 23 01:05:11.978: INFO: update-demo-nautilus-7xhcd is verified up and running
Mar 23 01:05:11.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-s8wm9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:12.058: INFO: stderr: ""
Mar 23 01:05:12.058: INFO: stdout: "true"
Mar 23 01:05:12.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-s8wm9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:12.136: INFO: stderr: ""
Mar 23 01:05:12.136: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 23 01:05:12.136: INFO: validating pod update-demo-nautilus-s8wm9
Mar 23 01:05:12.140: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 23 01:05:12.140: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 23 01:05:12.140: INFO: update-demo-nautilus-s8wm9 is verified up and running
STEP: scaling down the replication controller
Mar 23 01:05:12.142: INFO: scanned /root for discovery docs: <nil>
Mar 23 01:05:12.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:13.246: INFO: stderr: ""
Mar 23 01:05:13.246: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 23 01:05:13.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:13.330: INFO: stderr: ""
Mar 23 01:05:13.330: INFO: stdout: "update-demo-nautilus-7xhcd update-demo-nautilus-s8wm9 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 23 01:05:18.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:18.409: INFO: stderr: ""
Mar 23 01:05:18.409: INFO: stdout: "update-demo-nautilus-7xhcd "
Mar 23 01:05:18.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-7xhcd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:18.490: INFO: stderr: ""
Mar 23 01:05:18.490: INFO: stdout: "true"
Mar 23 01:05:18.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-7xhcd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:18.568: INFO: stderr: ""
Mar 23 01:05:18.568: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 23 01:05:18.568: INFO: validating pod update-demo-nautilus-7xhcd
Mar 23 01:05:18.571: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 23 01:05:18.571: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 23 01:05:18.571: INFO: update-demo-nautilus-7xhcd is verified up and running
STEP: scaling up the replication controller
Mar 23 01:05:18.573: INFO: scanned /root for discovery docs: <nil>
Mar 23 01:05:18.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:19.677: INFO: stderr: ""
Mar 23 01:05:19.677: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 23 01:05:19.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:19.762: INFO: stderr: ""
Mar 23 01:05:19.762: INFO: stdout: "update-demo-nautilus-5vbvd update-demo-nautilus-7xhcd "
Mar 23 01:05:19.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-5vbvd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:19.840: INFO: stderr: ""
Mar 23 01:05:19.840: INFO: stdout: "true"
Mar 23 01:05:19.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-5vbvd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:19.918: INFO: stderr: ""
Mar 23 01:05:19.918: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 23 01:05:19.918: INFO: validating pod update-demo-nautilus-5vbvd
Mar 23 01:05:19.922: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 23 01:05:19.922: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 23 01:05:19.922: INFO: update-demo-nautilus-5vbvd is verified up and running
Mar 23 01:05:19.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-7xhcd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:20.001: INFO: stderr: ""
Mar 23 01:05:20.001: INFO: stdout: "true"
Mar 23 01:05:20.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-7xhcd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:20.079: INFO: stderr: ""
Mar 23 01:05:20.079: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 23 01:05:20.079: INFO: validating pod update-demo-nautilus-7xhcd
Mar 23 01:05:20.082: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 23 01:05:20.082: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 23 01:05:20.082: INFO: update-demo-nautilus-7xhcd is verified up and running
STEP: using delete to clean up resources
Mar 23 01:05:20.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:20.168: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 23 01:05:20.168: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 23 01:05:20.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-qfvnb'
Mar 23 01:05:20.303: INFO: stderr: "No resources found.\n"
Mar 23 01:05:20.303: INFO: stdout: ""
Mar 23 01:05:20.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -l name=update-demo --namespace=e2e-tests-kubectl-qfvnb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 23 01:05:20.411: INFO: stderr: ""
Mar 23 01:05:20.411: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:05:20.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qfvnb" for this suite.
Mar 23 01:05:26.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:05:26.466: INFO: namespace: e2e-tests-kubectl-qfvnb, resource: bindings, ignored listing per whitelist
Mar 23 01:05:26.571: INFO: namespace e2e-tests-kubectl-qfvnb deletion completed in 6.156535329s

• [SLOW TEST:20.245 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:05:26.572: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 23 01:05:29.469: INFO: Successfully updated pod "labelsupdatebe9954fa-4d07-11e9-96f5-ea7d86f92d02"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:05:33.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fsjqb" for this suite.
Mar 23 01:05:55.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:05:55.560: INFO: namespace: e2e-tests-projected-fsjqb, resource: bindings, ignored listing per whitelist
Mar 23 01:05:55.580: INFO: namespace e2e-tests-projected-fsjqb deletion completed in 22.086426878s

• [SLOW TEST:29.009 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:05:55.581: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 01:05:55.648: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar 23 01:05:55.653: INFO: Number of nodes with available pods: 0
Mar 23 01:05:55.653: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar 23 01:05:55.671: INFO: Number of nodes with available pods: 0
Mar 23 01:05:55.671: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:05:56.674: INFO: Number of nodes with available pods: 0
Mar 23 01:05:56.674: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:05:57.674: INFO: Number of nodes with available pods: 1
Mar 23 01:05:57.674: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar 23 01:05:57.686: INFO: Number of nodes with available pods: 1
Mar 23 01:05:57.686: INFO: Number of running nodes: 0, number of available pods: 1
Mar 23 01:05:58.689: INFO: Number of nodes with available pods: 0
Mar 23 01:05:58.689: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 23 01:05:58.697: INFO: Number of nodes with available pods: 0
Mar 23 01:05:58.697: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:05:59.700: INFO: Number of nodes with available pods: 0
Mar 23 01:05:59.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:00.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:00.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:01.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:01.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:02.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:02.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:03.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:03.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:04.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:04.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:05.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:05.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:06.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:06.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:07.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:07.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:08.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:08.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:09.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:09.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:10.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:10.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:11.706: INFO: Number of nodes with available pods: 0
Mar 23 01:06:11.706: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:12.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:12.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:13.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:13.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:14.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:14.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:15.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:15.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:16.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:16.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:17.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:17.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:18.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:18.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:19.702: INFO: Number of nodes with available pods: 0
Mar 23 01:06:19.702: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:20.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:20.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:21.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:21.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:22.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:22.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:23.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:23.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:24.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:24.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:25.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:25.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:26.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:26.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:27.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:27.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:28.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:28.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:29.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:29.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:30.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:30.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:31.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:31.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:32.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:32.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:33.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:33.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:34.708: INFO: Number of nodes with available pods: 0
Mar 23 01:06:34.708: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:35.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:35.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:36.812: INFO: Number of nodes with available pods: 0
Mar 23 01:06:36.812: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:37.701: INFO: Number of nodes with available pods: 0
Mar 23 01:06:37.701: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:38.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:38.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:39.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:39.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:40.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:40.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:41.700: INFO: Number of nodes with available pods: 0
Mar 23 01:06:41.700: INFO: Node node-1 is running more than one daemon pod
Mar 23 01:06:42.700: INFO: Number of nodes with available pods: 1
Mar 23 01:06:42.700: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-hvrk9, will wait for the garbage collector to delete the pods
Mar 23 01:06:42.762: INFO: Deleting {extensions DaemonSet} daemon-set took: 5.846204ms
Mar 23 01:06:42.863: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.232403ms
Mar 23 01:07:21.666: INFO: Number of nodes with available pods: 0
Mar 23 01:07:21.666: INFO: Number of running nodes: 0, number of available pods: 0
Mar 23 01:07:21.668: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hvrk9/daemonsets","resourceVersion":"14899"},"items":null}

Mar 23 01:07:21.670: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hvrk9/pods","resourceVersion":"14899"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:07:21.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hvrk9" for this suite.
Mar 23 01:07:27.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:07:27.748: INFO: namespace: e2e-tests-daemonsets-hvrk9, resource: bindings, ignored listing per whitelist
Mar 23 01:07:27.779: INFO: namespace e2e-tests-daemonsets-hvrk9 deletion completed in 6.087737043s

• [SLOW TEST:92.198 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:07:27.779: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar 23 01:07:27.839: INFO: Waiting up to 5m0s for pod "var-expansion-06a926fe-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-var-expansion-2qnvn" to be "success or failure"
Mar 23 01:07:27.841: INFO: Pod "var-expansion-06a926fe-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.287953ms
Mar 23 01:07:29.844: INFO: Pod "var-expansion-06a926fe-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005129772s
STEP: Saw pod success
Mar 23 01:07:29.844: INFO: Pod "var-expansion-06a926fe-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:07:29.846: INFO: Trying to get logs from node node-2 pod var-expansion-06a926fe-4d08-11e9-96f5-ea7d86f92d02 container dapi-container: <nil>
STEP: delete the pod
Mar 23 01:07:29.862: INFO: Waiting for pod var-expansion-06a926fe-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:07:29.864: INFO: Pod var-expansion-06a926fe-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:07:29.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-2qnvn" for this suite.
Mar 23 01:07:35.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:07:35.951: INFO: namespace: e2e-tests-var-expansion-2qnvn, resource: bindings, ignored listing per whitelist
Mar 23 01:07:35.956: INFO: namespace e2e-tests-var-expansion-2qnvn deletion completed in 6.088276074s

• [SLOW TEST:8.177 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:07:35.956: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 23 01:07:36.011: INFO: Waiting up to 5m0s for pod "pod-0b884d2a-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-vg72k" to be "success or failure"
Mar 23 01:07:36.014: INFO: Pod "pod-0b884d2a-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.946793ms
Mar 23 01:07:38.017: INFO: Pod "pod-0b884d2a-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006287426s
STEP: Saw pod success
Mar 23 01:07:38.017: INFO: Pod "pod-0b884d2a-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:07:38.019: INFO: Trying to get logs from node node-2 pod pod-0b884d2a-4d08-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 01:07:38.033: INFO: Waiting for pod pod-0b884d2a-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:07:38.035: INFO: Pod pod-0b884d2a-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:07:38.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vg72k" for this suite.
Mar 23 01:07:44.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:07:44.078: INFO: namespace: e2e-tests-emptydir-vg72k, resource: bindings, ignored listing per whitelist
Mar 23 01:07:44.123: INFO: namespace e2e-tests-emptydir-vg72k deletion completed in 6.084667988s

• [SLOW TEST:8.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:07:44.123: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 23 01:07:44.181: INFO: Waiting up to 5m0s for pod "pod-1066d349-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-jvnj9" to be "success or failure"
Mar 23 01:07:44.183: INFO: Pod "pod-1066d349-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07265ms
Mar 23 01:07:46.186: INFO: Pod "pod-1066d349-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004512645s
STEP: Saw pod success
Mar 23 01:07:46.186: INFO: Pod "pod-1066d349-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:07:46.187: INFO: Trying to get logs from node node-2 pod pod-1066d349-4d08-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 01:07:46.203: INFO: Waiting for pod pod-1066d349-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:07:46.206: INFO: Pod pod-1066d349-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:07:46.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jvnj9" for this suite.
Mar 23 01:07:52.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:07:52.260: INFO: namespace: e2e-tests-emptydir-jvnj9, resource: bindings, ignored listing per whitelist
Mar 23 01:07:52.413: INFO: namespace e2e-tests-emptydir-jvnj9 deletion completed in 6.203489096s

• [SLOW TEST:8.290 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:07:52.413: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 01:07:52.460: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 23 01:07:52.468: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 23 01:07:57.471: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 23 01:07:57.471: INFO: Creating deployment "test-rolling-update-deployment"
Mar 23 01:07:57.475: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 23 01:07:57.480: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 23 01:07:59.484: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 23 01:07:59.486: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 23 01:07:59.492: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-bxcvf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bxcvf/deployments/test-rolling-update-deployment,UID:1853710d-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15097,Generation:1,CreationTimestamp:2019-03-23 01:07:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-23 01:07:57 +0000 UTC 2019-03-23 01:07:57 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-23 01:07:59 +0000 UTC 2019-03-23 01:07:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 23 01:07:59.494: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-bxcvf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bxcvf/replicasets/test-rolling-update-deployment-65b7695dcf,UID:185536a9-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15088,Generation:1,CreationTimestamp:2019-03-23 01:07:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 1853710d-4d08-11e9-9a5c-0646f33e71ba 0xc421bd8e57 0xc421bd8e58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 23 01:07:59.495: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 23 01:07:59.495: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-bxcvf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bxcvf/replicasets/test-rolling-update-controller,UID:1556db5f-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15096,Generation:2,CreationTimestamp:2019-03-23 01:07:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 1853710d-4d08-11e9-9a5c-0646f33e71ba 0xc421bd8d6e 0xc421bd8d6f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 23 01:07:59.497: INFO: Pod "test-rolling-update-deployment-65b7695dcf-dkqcx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-dkqcx,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-bxcvf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bxcvf/pods/test-rolling-update-deployment-65b7695dcf-dkqcx,UID:1855ac1c-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15087,Generation:0,CreationTimestamp:2019-03-23 01:07:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.44/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 185536a9-4d08-11e9-9a5c-0646f33e71ba 0xc421bea807 0xc421bea808}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7qdbw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7qdbw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7qdbw true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bea880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bea8a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:07:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:07:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:07:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:07:57 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:10.42.1.44,StartTime:2019-03-23 01:07:57 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-23 01:07:58 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://6f1df28658a8d2541d664b4b0c9cb41481848378b9d1e801fc39e7c15e96d57b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:07:59.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bxcvf" for this suite.
Mar 23 01:08:05.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:08:05.529: INFO: namespace: e2e-tests-deployment-bxcvf, resource: bindings, ignored listing per whitelist
Mar 23 01:08:05.593: INFO: namespace e2e-tests-deployment-bxcvf deletion completed in 6.093168202s

• [SLOW TEST:13.181 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:08:05.594: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 01:08:05.650: INFO: Creating deployment "nginx-deployment"
Mar 23 01:08:05.654: INFO: Waiting for observed generation 1
Mar 23 01:08:07.661: INFO: Waiting for all required pods to come up
Mar 23 01:08:07.665: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar 23 01:08:09.673: INFO: Waiting for deployment "nginx-deployment" to complete
Mar 23 01:08:09.678: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar 23 01:08:09.683: INFO: Updating deployment nginx-deployment
Mar 23 01:08:09.683: INFO: Waiting for observed generation 2
Mar 23 01:08:11.691: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 23 01:08:11.695: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 23 01:08:11.697: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 23 01:08:11.703: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 23 01:08:11.703: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 23 01:08:11.706: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 23 01:08:11.711: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar 23 01:08:11.711: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar 23 01:08:11.719: INFO: Updating deployment nginx-deployment
Mar 23 01:08:11.719: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar 23 01:08:11.730: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 23 01:08:13.740: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 23 01:08:13.745: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4q4g4/deployments/nginx-deployment,UID:1d337782-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15515,Generation:3,CreationTimestamp:2019-03-23 01:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:9,UnavailableReplicas:24,Conditions:[{Available False 2019-03-23 01:08:11 +0000 UTC 2019-03-23 01:08:11 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-23 01:08:13 +0000 UTC 2019-03-23 01:08:05 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:9,CollisionCount:nil,},}

Mar 23 01:08:13.748: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4q4g4/replicasets/nginx-deployment-7dc8f79789,UID:1f9ad147-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15413,Generation:3,CreationTimestamp:2019-03-23 01:08:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 1d337782-4d08-11e9-9a5c-0646f33e71ba 0xc4232fdb07 0xc4232fdb08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 23 01:08:13.748: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar 23 01:08:13.748: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4q4g4/replicasets/nginx-deployment-7f9675fb8b,UID:1d33e6f3-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15513,Generation:3,CreationTimestamp:2019-03-23 01:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 1d337782-4d08-11e9-9a5c-0646f33e71ba 0xc4232fdbc7 0xc4232fdbc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:9,AvailableReplicas:9,Conditions:[],},}
Mar 23 01:08:13.755: INFO: Pod "nginx-deployment-7dc8f79789-2ww4l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2ww4l,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-2ww4l,UID:20d85644-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15505,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.40/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310e4c7 0xc42310e4c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310e540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310e560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.195,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.755: INFO: Pod "nginx-deployment-7dc8f79789-5vjsc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-5vjsc,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-5vjsc,UID:20d30e34-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15482,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.39/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310e630 0xc42310e631}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310e6b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310e6d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.195,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.756: INFO: Pod "nginx-deployment-7dc8f79789-9jx2h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9jx2h,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-9jx2h,UID:1f9b6f6b-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15346,Generation:0,CreationTimestamp:2019-03-23 01:08:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.175/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310e7a0 0xc42310e7a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310e820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310e840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:10.42.2.175,StartTime:2019-03-23 01:08:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.756: INFO: Pod "nginx-deployment-7dc8f79789-gpfw9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-gpfw9,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-gpfw9,UID:20d8b36b-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15516,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.42/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310e930 0xc42310e931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310e9b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310e9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.195,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.756: INFO: Pod "nginx-deployment-7dc8f79789-k4mbb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-k4mbb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-k4mbb,UID:1fa64481-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15488,Generation:0,CreationTimestamp:2019-03-23 01:08:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.176/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310eaa0 0xc42310eaa1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310eb20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310eb40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:10.42.2.176,StartTime:2019-03-23 01:08:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.756: INFO: Pod "nginx-deployment-7dc8f79789-lbjfj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-lbjfj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-lbjfj,UID:1f9c5931-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15477,Generation:0,CreationTimestamp:2019-03-23 01:08:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.49/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310ec30 0xc42310ec31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310ecb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310ecd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:,StartTime:2019-03-23 01:08:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.756: INFO: Pod "nginx-deployment-7dc8f79789-mz26j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mz26j,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-mz26j,UID:1fa76f17-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15331,Generation:0,CreationTimestamp:2019-03-23 01:08:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.50/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310edc0 0xc42310edc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310ee50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310ee70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:,StartTime:2019-03-23 01:08:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.756: INFO: Pod "nginx-deployment-7dc8f79789-n5ffw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-n5ffw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-n5ffw,UID:20d8a5a2-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15489,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.180/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310ef40 0xc42310ef41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310efc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310efe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.756: INFO: Pod "nginx-deployment-7dc8f79789-n8h8h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-n8h8h,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-n8h8h,UID:20d87e3c-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15490,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.53/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310f0c0 0xc42310f0c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310f140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310f160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.757: INFO: Pod "nginx-deployment-7dc8f79789-nk84s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nk84s,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-nk84s,UID:20d4ee92-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15480,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.178/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310f240 0xc42310f241}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310f2c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310f2e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.757: INFO: Pod "nginx-deployment-7dc8f79789-nz5bs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nz5bs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-nz5bs,UID:20d55927-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15471,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.51/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310f3b0 0xc42310f3b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310f430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310f450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.757: INFO: Pod "nginx-deployment-7dc8f79789-qr6rf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qr6rf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-qr6rf,UID:1f9c8b47-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15468,Generation:0,CreationTimestamp:2019-03-23 01:08:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.38/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310f520 0xc42310f521}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310f5a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310f5c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:09 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.195,PodIP:,StartTime:2019-03-23 01:08:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.757: INFO: Pod "nginx-deployment-7dc8f79789-skn8f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-skn8f,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7dc8f79789-skn8f,UID:20da45c5-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15495,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.54/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1f9ad147-4d08-11e9-9a5c-0646f33e71ba 0xc42310f6b0 0xc42310f6b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42310f730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42310f750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.757: INFO: Pod "nginx-deployment-7f9675fb8b-225gd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-225gd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-225gd,UID:20d8287c-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15486,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.179/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc42310fff0 0xc42310fff1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfe060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfe080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.758: INFO: Pod "nginx-deployment-7f9675fb8b-24kxb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-24kxb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-24kxb,UID:20da8765-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15445,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cfe137 0xc421cfe138}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfe1b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfe1d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.195,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.758: INFO: Pod "nginx-deployment-7f9675fb8b-2g8kc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2g8kc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-2g8kc,UID:20d20794-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15512,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.177/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cfe297 0xc421cfe298}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfe310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfe330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:10.42.2.177,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-23 01:08:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://93b243e5829e8541aca5d5e26bd0bd6f4a7f2181a08d7562f3a665f6bdc0b102}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.758: INFO: Pod "nginx-deployment-7f9675fb8b-2t7lt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2t7lt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-2t7lt,UID:1d3de27a-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15240,Generation:0,CreationTimestamp:2019-03-23 01:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.37/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cfe400 0xc421cfe401}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfe470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfe490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.195,PodIP:10.42.0.37,StartTime:2019-03-23 01:08:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-23 01:08:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://9e3f7d4597e75119fa9f1980f8647e48d985d52536635d36601db2f0d1d0e261}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.758: INFO: Pod "nginx-deployment-7f9675fb8b-7gnj7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7gnj7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-7gnj7,UID:20d84871-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15509,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.56/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cfe560 0xc421cfe561}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfe5d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfe5f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.758: INFO: Pod "nginx-deployment-7f9675fb8b-872tv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-872tv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-872tv,UID:20d71b5c-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15508,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.41/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cfe6b7 0xc421cfe6b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfe730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfe750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.195,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.758: INFO: Pod "nginx-deployment-7f9675fb8b-9nxs2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9nxs2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-9nxs2,UID:1d374f10-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15243,Generation:0,CreationTimestamp:2019-03-23 01:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.35/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cfe817 0xc421cfe818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfe890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfe8b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.195,PodIP:10.42.0.35,StartTime:2019-03-23 01:08:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-23 01:08:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://e8450d3e52def14ec7f1d3c9a8d4d573be14e018e8bf79270d54f14d7176a101}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.759: INFO: Pod "nginx-deployment-7f9675fb8b-b4jm4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-b4jm4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-b4jm4,UID:20d3dc84-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15476,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.52/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cfe980 0xc421cfe981}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfe9f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfea10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.759: INFO: Pod "nginx-deployment-7f9675fb8b-fqrp2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fqrp2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-fqrp2,UID:20da9289-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15503,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.55/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cfead7 0xc421cfead8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfeb50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfeb70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.759: INFO: Pod "nginx-deployment-7f9675fb8b-g4xpd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-g4xpd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-g4xpd,UID:1d3e759e-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15248,Generation:0,CreationTimestamp:2019-03-23 01:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.48/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cfec37 0xc421cfec38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfecc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfece0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:10.42.1.48,StartTime:2019-03-23 01:08:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-23 01:08:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://76bf6c4aa28b8b3fcc3ad5067f788e1303646c7eb845924dcef743a0d83b7f06}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.759: INFO: Pod "nginx-deployment-7f9675fb8b-hnvzk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hnvzk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-hnvzk,UID:20d7dce9-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15496,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.181/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cfedb0 0xc421cfedb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfee20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfee40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.759: INFO: Pod "nginx-deployment-7f9675fb8b-ht57l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ht57l,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-ht57l,UID:20da7051-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15433,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cfeef7 0xc421cfeef8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cfef70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cfef90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.195,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.759: INFO: Pod "nginx-deployment-7f9675fb8b-ltphc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ltphc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-ltphc,UID:20da56d1-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15502,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.183/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cff057 0xc421cff058}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cff0d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cff0f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.760: INFO: Pod "nginx-deployment-7f9675fb8b-pb8pc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pb8pc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-pb8pc,UID:1d38966c-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15261,Generation:0,CreationTimestamp:2019-03-23 01:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.174/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cff1b7 0xc421cff1b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cff230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cff250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:10.42.2.174,StartTime:2019-03-23 01:08:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-23 01:08:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://b7bed71ce9e5534bd855dedbec35db5f5be2bbd7e39592740fd04c27e1fb7a7a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.761: INFO: Pod "nginx-deployment-7f9675fb8b-prp2k" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-prp2k,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-prp2k,UID:1d387fbe-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15255,Generation:0,CreationTimestamp:2019-03-23 01:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.45/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cff320 0xc421cff321}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cff390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cff3b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:10.42.1.45,StartTime:2019-03-23 01:08:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-23 01:08:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://0b3f1a9b2c80c12c90e345723629f141bb9922eb8c22b06df355ac7ea6c2d05b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.761: INFO: Pod "nginx-deployment-7f9675fb8b-s64r9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-s64r9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-s64r9,UID:1d3d9a7b-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15258,Generation:0,CreationTimestamp:2019-03-23 01:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.46/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cff480 0xc421cff481}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cff4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cff510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:10.42.1.46,StartTime:2019-03-23 01:08:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-23 01:08:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://25ed38da536d87138890490cf080e002293953a491b2421a9cd1c84822000461}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.762: INFO: Pod "nginx-deployment-7f9675fb8b-sfz5x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sfz5x,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-sfz5x,UID:1d38a286-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15237,Generation:0,CreationTimestamp:2019-03-23 01:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.36/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cff5e0 0xc421cff5e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cff650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cff670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  }],Message:,Reason:,HostIP:172.31.37.195,PodIP:10.42.0.36,StartTime:2019-03-23 01:08:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-23 01:08:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://09c894e26afa3b09ae89213fa47b797305ef2ee9154ada36ad91f96b4e6d482f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.763: INFO: Pod "nginx-deployment-7f9675fb8b-vfm5n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vfm5n,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-vfm5n,UID:20da7bf3-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15510,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.57/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cff740 0xc421cff741}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cff7b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cff7d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.184,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.763: INFO: Pod "nginx-deployment-7f9675fb8b-zlbmk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zlbmk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-zlbmk,UID:1d35be0a-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15266,Generation:0,CreationTimestamp:2019-03-23 01:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.172/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cff897 0xc421cff898}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cff910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cff930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:05 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:10.42.2.172,StartTime:2019-03-23 01:08:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-23 01:08:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://2bddc22284d3dc718f725257978fcb2c1b12be07aa84921391408512d7cb5042}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 23 01:08:13.763: INFO: Pod "nginx-deployment-7f9675fb8b-zxqzk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zxqzk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4q4g4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4q4g4/pods/nginx-deployment-7f9675fb8b-zxqzk,UID:20d44b71-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:15500,Generation:0,CreationTimestamp:2019-03-23 01:08:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.182/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1d33e6f3-4d08-11e9-9a5c-0646f33e71ba 0xc421cffa00 0xc421cffa01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t4kmr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t4kmr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t4kmr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421cffa70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421cffa90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-23 01:08:11 +0000 UTC  }],Message:,Reason:,HostIP:172.31.45.82,PodIP:,StartTime:2019-03-23 01:08:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:08:13.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4q4g4" for this suite.
Mar 23 01:08:21.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:08:21.848: INFO: namespace: e2e-tests-deployment-4q4g4, resource: bindings, ignored listing per whitelist
Mar 23 01:08:21.863: INFO: namespace e2e-tests-deployment-4q4g4 deletion completed in 8.093578967s

• [SLOW TEST:16.269 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:08:21.863: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-rtqh
STEP: Creating a pod to test atomic-volume-subpath
Mar 23 01:08:21.944: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-rtqh" in namespace "e2e-tests-subpath-x4btf" to be "success or failure"
Mar 23 01:08:21.946: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.346404ms
Mar 23 01:08:23.949: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005344435s
Mar 23 01:08:25.952: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Running", Reason="", readiness=false. Elapsed: 4.008289083s
Mar 23 01:08:27.955: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Running", Reason="", readiness=false. Elapsed: 6.011197966s
Mar 23 01:08:29.957: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Running", Reason="", readiness=false. Elapsed: 8.013876215s
Mar 23 01:08:31.965: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Running", Reason="", readiness=false. Elapsed: 10.021452114s
Mar 23 01:08:33.968: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Running", Reason="", readiness=false. Elapsed: 12.024448333s
Mar 23 01:08:35.971: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Running", Reason="", readiness=false. Elapsed: 14.02745519s
Mar 23 01:08:37.974: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Running", Reason="", readiness=false. Elapsed: 16.030360715s
Mar 23 01:08:39.977: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Running", Reason="", readiness=false. Elapsed: 18.033303524s
Mar 23 01:08:41.980: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Running", Reason="", readiness=false. Elapsed: 20.036290929s
Mar 23 01:08:43.983: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Running", Reason="", readiness=false. Elapsed: 22.039421055s
Mar 23 01:08:45.986: INFO: Pod "pod-subpath-test-downwardapi-rtqh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.042604523s
STEP: Saw pod success
Mar 23 01:08:45.986: INFO: Pod "pod-subpath-test-downwardapi-rtqh" satisfied condition "success or failure"
Mar 23 01:08:45.988: INFO: Trying to get logs from node node-3 pod pod-subpath-test-downwardapi-rtqh container test-container-subpath-downwardapi-rtqh: <nil>
STEP: delete the pod
Mar 23 01:08:46.002: INFO: Waiting for pod pod-subpath-test-downwardapi-rtqh to disappear
Mar 23 01:08:46.010: INFO: Pod pod-subpath-test-downwardapi-rtqh no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-rtqh
Mar 23 01:08:46.010: INFO: Deleting pod "pod-subpath-test-downwardapi-rtqh" in namespace "e2e-tests-subpath-x4btf"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:08:46.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-x4btf" for this suite.
Mar 23 01:08:52.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:08:52.093: INFO: namespace: e2e-tests-subpath-x4btf, resource: bindings, ignored listing per whitelist
Mar 23 01:08:52.102: INFO: namespace e2e-tests-subpath-x4btf deletion completed in 6.087083709s

• [SLOW TEST:30.239 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:08:52.102: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 01:08:52.160: INFO: Waiting up to 5m0s for pod "downwardapi-volume-38ebbba0-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-downward-api-kxthj" to be "success or failure"
Mar 23 01:08:52.168: INFO: Pod "downwardapi-volume-38ebbba0-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 7.476623ms
Mar 23 01:08:54.170: INFO: Pod "downwardapi-volume-38ebbba0-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010371464s
STEP: Saw pod success
Mar 23 01:08:54.170: INFO: Pod "downwardapi-volume-38ebbba0-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:08:54.173: INFO: Trying to get logs from node node-2 pod downwardapi-volume-38ebbba0-4d08-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 01:08:54.187: INFO: Waiting for pod downwardapi-volume-38ebbba0-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:08:54.190: INFO: Pod downwardapi-volume-38ebbba0-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:08:54.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kxthj" for this suite.
Mar 23 01:09:00.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:09:00.256: INFO: namespace: e2e-tests-downward-api-kxthj, resource: bindings, ignored listing per whitelist
Mar 23 01:09:00.283: INFO: namespace e2e-tests-downward-api-kxthj deletion completed in 6.089812826s

• [SLOW TEST:8.181 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:09:00.283: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar 23 01:09:00.388: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-648197830 proxy --unix-socket=/tmp/kubectl-proxy-unix311990125/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:09:00.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-scwld" for this suite.
Mar 23 01:09:06.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:09:06.533: INFO: namespace: e2e-tests-kubectl-scwld, resource: bindings, ignored listing per whitelist
Mar 23 01:09:06.542: INFO: namespace e2e-tests-kubectl-scwld deletion completed in 6.08433376s

• [SLOW TEST:6.259 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:09:06.542: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-41879259-4d08-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 01:09:06.606: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-41880ae8-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-h7dhq" to be "success or failure"
Mar 23 01:09:06.610: INFO: Pod "pod-projected-configmaps-41880ae8-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.623486ms
Mar 23 01:09:08.613: INFO: Pod "pod-projected-configmaps-41880ae8-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00628386s
STEP: Saw pod success
Mar 23 01:09:08.613: INFO: Pod "pod-projected-configmaps-41880ae8-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:09:08.615: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-41880ae8-4d08-11e9-96f5-ea7d86f92d02 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 23 01:09:08.637: INFO: Waiting for pod pod-projected-configmaps-41880ae8-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:09:08.638: INFO: Pod pod-projected-configmaps-41880ae8-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:09:08.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h7dhq" for this suite.
Mar 23 01:09:14.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:09:14.673: INFO: namespace: e2e-tests-projected-h7dhq, resource: bindings, ignored listing per whitelist
Mar 23 01:09:14.726: INFO: namespace e2e-tests-projected-h7dhq deletion completed in 6.084644516s

• [SLOW TEST:8.184 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:09:14.726: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 23 01:09:14.789: INFO: Waiting up to 5m0s for pod "pod-46689e41-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-emptydir-wzlh8" to be "success or failure"
Mar 23 01:09:14.792: INFO: Pod "pod-46689e41-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.760936ms
Mar 23 01:09:16.795: INFO: Pod "pod-46689e41-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005677603s
STEP: Saw pod success
Mar 23 01:09:16.795: INFO: Pod "pod-46689e41-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:09:16.797: INFO: Trying to get logs from node node-2 pod pod-46689e41-4d08-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 01:09:16.814: INFO: Waiting for pod pod-46689e41-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:09:16.816: INFO: Pod pod-46689e41-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:09:16.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wzlh8" for this suite.
Mar 23 01:09:22.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:09:22.839: INFO: namespace: e2e-tests-emptydir-wzlh8, resource: bindings, ignored listing per whitelist
Mar 23 01:09:22.904: INFO: namespace e2e-tests-emptydir-wzlh8 deletion completed in 6.084102955s

• [SLOW TEST:8.177 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:09:22.904: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-4b47a8db-4d08-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 01:09:22.967: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4b482443-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-knxlg" to be "success or failure"
Mar 23 01:09:22.970: INFO: Pod "pod-projected-configmaps-4b482443-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.6406ms
Mar 23 01:09:24.973: INFO: Pod "pod-projected-configmaps-4b482443-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00662339s
STEP: Saw pod success
Mar 23 01:09:24.973: INFO: Pod "pod-projected-configmaps-4b482443-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:09:24.976: INFO: Trying to get logs from node node-2 pod pod-projected-configmaps-4b482443-4d08-11e9-96f5-ea7d86f92d02 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 23 01:09:24.990: INFO: Waiting for pod pod-projected-configmaps-4b482443-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:09:24.992: INFO: Pod pod-projected-configmaps-4b482443-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:09:24.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-knxlg" for this suite.
Mar 23 01:09:31.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:09:31.020: INFO: namespace: e2e-tests-projected-knxlg, resource: bindings, ignored listing per whitelist
Mar 23 01:09:31.081: INFO: namespace e2e-tests-projected-knxlg deletion completed in 6.085842848s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:09:31.081: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-qwwsp
I0323 01:09:31.136321      17 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-qwwsp, replica count: 1
I0323 01:09:32.186804      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0323 01:09:33.187024      17 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 23 01:09:33.296: INFO: Created: latency-svc-d9fvk
Mar 23 01:09:33.303: INFO: Got endpoints: latency-svc-d9fvk [16.406339ms]
Mar 23 01:09:33.312: INFO: Created: latency-svc-s6qhz
Mar 23 01:09:33.319: INFO: Got endpoints: latency-svc-s6qhz [15.638855ms]
Mar 23 01:09:33.320: INFO: Created: latency-svc-n2p6k
Mar 23 01:09:33.325: INFO: Got endpoints: latency-svc-n2p6k [21.71474ms]
Mar 23 01:09:33.328: INFO: Created: latency-svc-bgk6q
Mar 23 01:09:33.333: INFO: Got endpoints: latency-svc-bgk6q [29.697654ms]
Mar 23 01:09:33.339: INFO: Created: latency-svc-fcx4t
Mar 23 01:09:33.344: INFO: Created: latency-svc-jtzk6
Mar 23 01:09:33.350: INFO: Got endpoints: latency-svc-fcx4t [46.326918ms]
Mar 23 01:09:33.352: INFO: Got endpoints: latency-svc-jtzk6 [48.266732ms]
Mar 23 01:09:33.357: INFO: Created: latency-svc-t2gfh
Mar 23 01:09:33.362: INFO: Got endpoints: latency-svc-t2gfh [58.440713ms]
Mar 23 01:09:33.362: INFO: Created: latency-svc-drmgl
Mar 23 01:09:33.367: INFO: Got endpoints: latency-svc-drmgl [63.139994ms]
Mar 23 01:09:33.371: INFO: Created: latency-svc-sn67h
Mar 23 01:09:33.373: INFO: Got endpoints: latency-svc-sn67h [69.517023ms]
Mar 23 01:09:33.376: INFO: Created: latency-svc-7vgj5
Mar 23 01:09:33.381: INFO: Got endpoints: latency-svc-7vgj5 [77.443841ms]
Mar 23 01:09:33.382: INFO: Created: latency-svc-8drlp
Mar 23 01:09:33.385: INFO: Got endpoints: latency-svc-8drlp [81.508734ms]
Mar 23 01:09:33.393: INFO: Created: latency-svc-r5s5g
Mar 23 01:09:33.394: INFO: Got endpoints: latency-svc-r5s5g [90.737969ms]
Mar 23 01:09:33.397: INFO: Created: latency-svc-7jz2c
Mar 23 01:09:33.397: INFO: Got endpoints: latency-svc-7jz2c [93.764551ms]
Mar 23 01:09:33.401: INFO: Created: latency-svc-kq6px
Mar 23 01:09:33.405: INFO: Got endpoints: latency-svc-kq6px [101.728733ms]
Mar 23 01:09:33.407: INFO: Created: latency-svc-dsqx6
Mar 23 01:09:33.412: INFO: Created: latency-svc-ptvnb
Mar 23 01:09:33.412: INFO: Got endpoints: latency-svc-dsqx6 [108.587002ms]
Mar 23 01:09:33.417: INFO: Created: latency-svc-xp86b
Mar 23 01:09:33.422: INFO: Got endpoints: latency-svc-ptvnb [118.119381ms]
Mar 23 01:09:33.427: INFO: Got endpoints: latency-svc-xp86b [21.786502ms]
Mar 23 01:09:33.428: INFO: Created: latency-svc-4ksln
Mar 23 01:09:33.432: INFO: Got endpoints: latency-svc-4ksln [112.621871ms]
Mar 23 01:09:33.434: INFO: Created: latency-svc-gndg4
Mar 23 01:09:33.441: INFO: Got endpoints: latency-svc-gndg4 [115.510446ms]
Mar 23 01:09:33.443: INFO: Created: latency-svc-bxcrn
Mar 23 01:09:33.443: INFO: Got endpoints: latency-svc-bxcrn [110.178627ms]
Mar 23 01:09:33.446: INFO: Created: latency-svc-f8k58
Mar 23 01:09:33.450: INFO: Got endpoints: latency-svc-f8k58 [100.236468ms]
Mar 23 01:09:33.453: INFO: Created: latency-svc-5fg97
Mar 23 01:09:33.466: INFO: Got endpoints: latency-svc-5fg97 [114.411513ms]
Mar 23 01:09:33.478: INFO: Created: latency-svc-mc8mj
Mar 23 01:09:33.481: INFO: Got endpoints: latency-svc-mc8mj [118.584262ms]
Mar 23 01:09:33.485: INFO: Created: latency-svc-mnbb4
Mar 23 01:09:33.494: INFO: Got endpoints: latency-svc-mnbb4 [127.161974ms]
Mar 23 01:09:33.494: INFO: Created: latency-svc-wns7j
Mar 23 01:09:33.499: INFO: Created: latency-svc-s5dwt
Mar 23 01:09:33.500: INFO: Got endpoints: latency-svc-wns7j [127.033734ms]
Mar 23 01:09:33.505: INFO: Got endpoints: latency-svc-s5dwt [124.025077ms]
Mar 23 01:09:33.510: INFO: Created: latency-svc-2tmq7
Mar 23 01:09:33.514: INFO: Got endpoints: latency-svc-2tmq7 [129.100742ms]
Mar 23 01:09:33.516: INFO: Created: latency-svc-l6nj8
Mar 23 01:09:33.522: INFO: Got endpoints: latency-svc-l6nj8 [127.5895ms]
Mar 23 01:09:33.524: INFO: Created: latency-svc-m6nql
Mar 23 01:09:33.528: INFO: Got endpoints: latency-svc-m6nql [130.350998ms]
Mar 23 01:09:33.534: INFO: Created: latency-svc-85pwr
Mar 23 01:09:33.535: INFO: Got endpoints: latency-svc-85pwr [122.425708ms]
Mar 23 01:09:33.543: INFO: Created: latency-svc-7gqk9
Mar 23 01:09:33.547: INFO: Created: latency-svc-6gkq7
Mar 23 01:09:33.548: INFO: Got endpoints: latency-svc-7gqk9 [126.083295ms]
Mar 23 01:09:33.553: INFO: Got endpoints: latency-svc-6gkq7 [125.34404ms]
Mar 23 01:09:33.557: INFO: Created: latency-svc-pm829
Mar 23 01:09:33.557: INFO: Got endpoints: latency-svc-pm829 [125.731675ms]
Mar 23 01:09:33.561: INFO: Created: latency-svc-rxnkn
Mar 23 01:09:33.567: INFO: Got endpoints: latency-svc-rxnkn [126.196886ms]
Mar 23 01:09:33.577: INFO: Created: latency-svc-mj67n
Mar 23 01:09:33.580: INFO: Got endpoints: latency-svc-mj67n [136.074722ms]
Mar 23 01:09:33.587: INFO: Created: latency-svc-smvhw
Mar 23 01:09:33.593: INFO: Created: latency-svc-kqnjw
Mar 23 01:09:33.600: INFO: Got endpoints: latency-svc-smvhw [149.120805ms]
Mar 23 01:09:33.601: INFO: Created: latency-svc-6mmb4
Mar 23 01:09:33.611: INFO: Created: latency-svc-dwjtg
Mar 23 01:09:33.616: INFO: Created: latency-svc-4n2hj
Mar 23 01:09:33.620: INFO: Created: latency-svc-bnxwr
Mar 23 01:09:33.629: INFO: Created: latency-svc-kzhx4
Mar 23 01:09:33.633: INFO: Created: latency-svc-jdhcx
Mar 23 01:09:33.636: INFO: Created: latency-svc-ml7sx
Mar 23 01:09:33.643: INFO: Created: latency-svc-zsd8g
Mar 23 01:09:33.647: INFO: Created: latency-svc-45sn4
Mar 23 01:09:33.648: INFO: Got endpoints: latency-svc-kqnjw [182.121964ms]
Mar 23 01:09:33.652: INFO: Created: latency-svc-6jfb2
Mar 23 01:09:33.658: INFO: Created: latency-svc-f9xb2
Mar 23 01:09:33.660: INFO: Created: latency-svc-zv59g
Mar 23 01:09:33.666: INFO: Created: latency-svc-2pcnn
Mar 23 01:09:33.671: INFO: Created: latency-svc-vqrvg
Mar 23 01:09:33.678: INFO: Created: latency-svc-x4rw2
Mar 23 01:09:33.698: INFO: Got endpoints: latency-svc-6mmb4 [217.344481ms]
Mar 23 01:09:33.704: INFO: Created: latency-svc-bdsb8
Mar 23 01:09:33.747: INFO: Got endpoints: latency-svc-dwjtg [253.322396ms]
Mar 23 01:09:33.753: INFO: Created: latency-svc-lqx7l
Mar 23 01:09:33.797: INFO: Got endpoints: latency-svc-4n2hj [292.300461ms]
Mar 23 01:09:33.805: INFO: Created: latency-svc-v427r
Mar 23 01:09:33.847: INFO: Got endpoints: latency-svc-bnxwr [347.042521ms]
Mar 23 01:09:33.854: INFO: Created: latency-svc-257zx
Mar 23 01:09:33.898: INFO: Got endpoints: latency-svc-kzhx4 [383.36498ms]
Mar 23 01:09:33.909: INFO: Created: latency-svc-82nh8
Mar 23 01:09:33.947: INFO: Got endpoints: latency-svc-jdhcx [425.067215ms]
Mar 23 01:09:33.954: INFO: Created: latency-svc-w59cg
Mar 23 01:09:33.998: INFO: Got endpoints: latency-svc-ml7sx [469.874059ms]
Mar 23 01:09:34.003: INFO: Created: latency-svc-28q84
Mar 23 01:09:34.047: INFO: Got endpoints: latency-svc-zsd8g [512.484809ms]
Mar 23 01:09:34.054: INFO: Created: latency-svc-hcdbf
Mar 23 01:09:34.098: INFO: Got endpoints: latency-svc-45sn4 [549.603994ms]
Mar 23 01:09:34.103: INFO: Created: latency-svc-wzt5r
Mar 23 01:09:34.147: INFO: Got endpoints: latency-svc-6jfb2 [594.302192ms]
Mar 23 01:09:34.153: INFO: Created: latency-svc-zmp2x
Mar 23 01:09:34.197: INFO: Got endpoints: latency-svc-f9xb2 [639.638409ms]
Mar 23 01:09:34.204: INFO: Created: latency-svc-hb7nm
Mar 23 01:09:34.247: INFO: Got endpoints: latency-svc-zv59g [680.43656ms]
Mar 23 01:09:34.254: INFO: Created: latency-svc-kscvf
Mar 23 01:09:34.297: INFO: Got endpoints: latency-svc-2pcnn [717.831981ms]
Mar 23 01:09:34.303: INFO: Created: latency-svc-br9tt
Mar 23 01:09:34.347: INFO: Got endpoints: latency-svc-vqrvg [747.661023ms]
Mar 23 01:09:34.354: INFO: Created: latency-svc-g6msf
Mar 23 01:09:34.398: INFO: Got endpoints: latency-svc-x4rw2 [749.23618ms]
Mar 23 01:09:34.405: INFO: Created: latency-svc-b4n6p
Mar 23 01:09:34.447: INFO: Got endpoints: latency-svc-bdsb8 [749.147243ms]
Mar 23 01:09:34.454: INFO: Created: latency-svc-mhwlc
Mar 23 01:09:34.497: INFO: Got endpoints: latency-svc-lqx7l [749.763497ms]
Mar 23 01:09:34.504: INFO: Created: latency-svc-b8tv4
Mar 23 01:09:34.548: INFO: Got endpoints: latency-svc-v427r [750.311906ms]
Mar 23 01:09:34.555: INFO: Created: latency-svc-k7zg8
Mar 23 01:09:34.597: INFO: Got endpoints: latency-svc-257zx [749.942184ms]
Mar 23 01:09:34.604: INFO: Created: latency-svc-j25h2
Mar 23 01:09:34.649: INFO: Got endpoints: latency-svc-82nh8 [750.822944ms]
Mar 23 01:09:34.656: INFO: Created: latency-svc-rhp9p
Mar 23 01:09:34.697: INFO: Got endpoints: latency-svc-w59cg [750.10983ms]
Mar 23 01:09:34.705: INFO: Created: latency-svc-rhgwv
Mar 23 01:09:34.747: INFO: Got endpoints: latency-svc-28q84 [749.430237ms]
Mar 23 01:09:34.753: INFO: Created: latency-svc-wdtpw
Mar 23 01:09:34.803: INFO: Got endpoints: latency-svc-hcdbf [756.021788ms]
Mar 23 01:09:34.811: INFO: Created: latency-svc-qnskv
Mar 23 01:09:34.847: INFO: Got endpoints: latency-svc-wzt5r [749.689749ms]
Mar 23 01:09:34.854: INFO: Created: latency-svc-8czp2
Mar 23 01:09:34.898: INFO: Got endpoints: latency-svc-zmp2x [750.616739ms]
Mar 23 01:09:34.904: INFO: Created: latency-svc-z9ldz
Mar 23 01:09:34.947: INFO: Got endpoints: latency-svc-hb7nm [749.916467ms]
Mar 23 01:09:34.955: INFO: Created: latency-svc-gdqz2
Mar 23 01:09:34.999: INFO: Got endpoints: latency-svc-kscvf [751.407398ms]
Mar 23 01:09:35.007: INFO: Created: latency-svc-mvl7p
Mar 23 01:09:35.047: INFO: Got endpoints: latency-svc-br9tt [749.876888ms]
Mar 23 01:09:35.054: INFO: Created: latency-svc-68g7c
Mar 23 01:09:35.098: INFO: Got endpoints: latency-svc-g6msf [750.292568ms]
Mar 23 01:09:35.103: INFO: Created: latency-svc-mp4cd
Mar 23 01:09:35.147: INFO: Got endpoints: latency-svc-b4n6p [749.501753ms]
Mar 23 01:09:35.153: INFO: Created: latency-svc-g75hg
Mar 23 01:09:35.198: INFO: Got endpoints: latency-svc-mhwlc [750.508368ms]
Mar 23 01:09:35.204: INFO: Created: latency-svc-ttgnm
Mar 23 01:09:35.248: INFO: Got endpoints: latency-svc-b8tv4 [750.50001ms]
Mar 23 01:09:35.256: INFO: Created: latency-svc-fpd77
Mar 23 01:09:35.298: INFO: Got endpoints: latency-svc-k7zg8 [750.025245ms]
Mar 23 01:09:35.305: INFO: Created: latency-svc-qwqbq
Mar 23 01:09:35.350: INFO: Got endpoints: latency-svc-j25h2 [752.771736ms]
Mar 23 01:09:35.357: INFO: Created: latency-svc-9tprs
Mar 23 01:09:35.398: INFO: Got endpoints: latency-svc-rhp9p [749.440654ms]
Mar 23 01:09:35.408: INFO: Created: latency-svc-t59cs
Mar 23 01:09:35.447: INFO: Got endpoints: latency-svc-rhgwv [750.107022ms]
Mar 23 01:09:35.456: INFO: Created: latency-svc-wkr5f
Mar 23 01:09:35.497: INFO: Got endpoints: latency-svc-wdtpw [749.823814ms]
Mar 23 01:09:35.503: INFO: Created: latency-svc-txn6c
Mar 23 01:09:35.548: INFO: Got endpoints: latency-svc-qnskv [744.751532ms]
Mar 23 01:09:35.556: INFO: Created: latency-svc-qfs9d
Mar 23 01:09:35.598: INFO: Got endpoints: latency-svc-8czp2 [750.52322ms]
Mar 23 01:09:35.605: INFO: Created: latency-svc-pdt7c
Mar 23 01:09:35.647: INFO: Got endpoints: latency-svc-z9ldz [749.319968ms]
Mar 23 01:09:35.656: INFO: Created: latency-svc-stjs7
Mar 23 01:09:35.697: INFO: Got endpoints: latency-svc-gdqz2 [750.343986ms]
Mar 23 01:09:35.703: INFO: Created: latency-svc-xbz48
Mar 23 01:09:35.747: INFO: Got endpoints: latency-svc-mvl7p [748.289578ms]
Mar 23 01:09:35.754: INFO: Created: latency-svc-hx8pv
Mar 23 01:09:35.797: INFO: Got endpoints: latency-svc-68g7c [749.897463ms]
Mar 23 01:09:35.804: INFO: Created: latency-svc-n25wl
Mar 23 01:09:35.848: INFO: Got endpoints: latency-svc-mp4cd [750.378022ms]
Mar 23 01:09:35.854: INFO: Created: latency-svc-qr7dh
Mar 23 01:09:35.898: INFO: Got endpoints: latency-svc-g75hg [750.835199ms]
Mar 23 01:09:35.905: INFO: Created: latency-svc-4bm56
Mar 23 01:09:35.947: INFO: Got endpoints: latency-svc-ttgnm [749.511363ms]
Mar 23 01:09:35.953: INFO: Created: latency-svc-g26w7
Mar 23 01:09:35.998: INFO: Got endpoints: latency-svc-fpd77 [750.053192ms]
Mar 23 01:09:36.004: INFO: Created: latency-svc-l4m8m
Mar 23 01:09:36.048: INFO: Got endpoints: latency-svc-qwqbq [750.525208ms]
Mar 23 01:09:36.055: INFO: Created: latency-svc-z7txp
Mar 23 01:09:36.098: INFO: Got endpoints: latency-svc-9tprs [747.652769ms]
Mar 23 01:09:36.104: INFO: Created: latency-svc-qkcz4
Mar 23 01:09:36.147: INFO: Got endpoints: latency-svc-t59cs [749.412948ms]
Mar 23 01:09:36.156: INFO: Created: latency-svc-xkwwt
Mar 23 01:09:36.197: INFO: Got endpoints: latency-svc-wkr5f [749.947165ms]
Mar 23 01:09:36.205: INFO: Created: latency-svc-jvjzb
Mar 23 01:09:36.248: INFO: Got endpoints: latency-svc-txn6c [750.592855ms]
Mar 23 01:09:36.254: INFO: Created: latency-svc-gpkhw
Mar 23 01:09:36.297: INFO: Got endpoints: latency-svc-qfs9d [748.735026ms]
Mar 23 01:09:36.304: INFO: Created: latency-svc-wvp4v
Mar 23 01:09:36.347: INFO: Got endpoints: latency-svc-pdt7c [749.419261ms]
Mar 23 01:09:36.354: INFO: Created: latency-svc-rqtpf
Mar 23 01:09:36.397: INFO: Got endpoints: latency-svc-stjs7 [750.106569ms]
Mar 23 01:09:36.405: INFO: Created: latency-svc-mc9vt
Mar 23 01:09:36.447: INFO: Got endpoints: latency-svc-xbz48 [749.668186ms]
Mar 23 01:09:36.454: INFO: Created: latency-svc-pqstn
Mar 23 01:09:36.498: INFO: Got endpoints: latency-svc-hx8pv [750.986522ms]
Mar 23 01:09:36.506: INFO: Created: latency-svc-n5cz2
Mar 23 01:09:36.547: INFO: Got endpoints: latency-svc-n25wl [749.936343ms]
Mar 23 01:09:36.553: INFO: Created: latency-svc-8s774
Mar 23 01:09:36.598: INFO: Got endpoints: latency-svc-qr7dh [750.206884ms]
Mar 23 01:09:36.605: INFO: Created: latency-svc-m7kmh
Mar 23 01:09:36.648: INFO: Got endpoints: latency-svc-4bm56 [750.125494ms]
Mar 23 01:09:36.654: INFO: Created: latency-svc-wrb84
Mar 23 01:09:36.698: INFO: Got endpoints: latency-svc-g26w7 [750.326301ms]
Mar 23 01:09:36.704: INFO: Created: latency-svc-b5q8r
Mar 23 01:09:36.748: INFO: Got endpoints: latency-svc-l4m8m [749.865983ms]
Mar 23 01:09:36.756: INFO: Created: latency-svc-zc9kh
Mar 23 01:09:36.797: INFO: Got endpoints: latency-svc-z7txp [748.64255ms]
Mar 23 01:09:36.805: INFO: Created: latency-svc-c4gnf
Mar 23 01:09:36.847: INFO: Got endpoints: latency-svc-qkcz4 [749.487804ms]
Mar 23 01:09:36.855: INFO: Created: latency-svc-7h5vb
Mar 23 01:09:36.898: INFO: Got endpoints: latency-svc-xkwwt [750.173217ms]
Mar 23 01:09:36.905: INFO: Created: latency-svc-6s2lp
Mar 23 01:09:36.949: INFO: Got endpoints: latency-svc-jvjzb [751.077204ms]
Mar 23 01:09:36.957: INFO: Created: latency-svc-trxpl
Mar 23 01:09:37.001: INFO: Got endpoints: latency-svc-gpkhw [753.064777ms]
Mar 23 01:09:37.007: INFO: Created: latency-svc-zndjq
Mar 23 01:09:37.047: INFO: Got endpoints: latency-svc-wvp4v [750.281933ms]
Mar 23 01:09:37.053: INFO: Created: latency-svc-gnkdp
Mar 23 01:09:37.102: INFO: Got endpoints: latency-svc-rqtpf [754.563341ms]
Mar 23 01:09:37.119: INFO: Created: latency-svc-dwbmp
Mar 23 01:09:37.151: INFO: Got endpoints: latency-svc-mc9vt [753.523602ms]
Mar 23 01:09:37.168: INFO: Created: latency-svc-lnlqf
Mar 23 01:09:37.198: INFO: Got endpoints: latency-svc-pqstn [751.210744ms]
Mar 23 01:09:37.209: INFO: Created: latency-svc-rtv8n
Mar 23 01:09:37.260: INFO: Got endpoints: latency-svc-n5cz2 [761.612657ms]
Mar 23 01:09:37.274: INFO: Created: latency-svc-9jktl
Mar 23 01:09:37.297: INFO: Got endpoints: latency-svc-8s774 [750.185637ms]
Mar 23 01:09:37.316: INFO: Created: latency-svc-dxrtg
Mar 23 01:09:37.348: INFO: Got endpoints: latency-svc-m7kmh [749.964946ms]
Mar 23 01:09:37.357: INFO: Created: latency-svc-qtpq8
Mar 23 01:09:37.397: INFO: Got endpoints: latency-svc-wrb84 [749.094856ms]
Mar 23 01:09:37.405: INFO: Created: latency-svc-wxdss
Mar 23 01:09:37.447: INFO: Got endpoints: latency-svc-b5q8r [749.389151ms]
Mar 23 01:09:37.454: INFO: Created: latency-svc-xbxjb
Mar 23 01:09:37.498: INFO: Got endpoints: latency-svc-zc9kh [750.150147ms]
Mar 23 01:09:37.506: INFO: Created: latency-svc-jn7dx
Mar 23 01:09:37.548: INFO: Got endpoints: latency-svc-c4gnf [750.592632ms]
Mar 23 01:09:37.554: INFO: Created: latency-svc-mr79r
Mar 23 01:09:37.598: INFO: Got endpoints: latency-svc-7h5vb [750.2999ms]
Mar 23 01:09:37.604: INFO: Created: latency-svc-v25qb
Mar 23 01:09:37.647: INFO: Got endpoints: latency-svc-6s2lp [748.880451ms]
Mar 23 01:09:37.653: INFO: Created: latency-svc-vtprz
Mar 23 01:09:37.697: INFO: Got endpoints: latency-svc-trxpl [748.491649ms]
Mar 23 01:09:37.704: INFO: Created: latency-svc-hdwqs
Mar 23 01:09:37.747: INFO: Got endpoints: latency-svc-zndjq [746.270067ms]
Mar 23 01:09:37.754: INFO: Created: latency-svc-v5gcx
Mar 23 01:09:37.798: INFO: Got endpoints: latency-svc-gnkdp [750.411084ms]
Mar 23 01:09:37.804: INFO: Created: latency-svc-44tpg
Mar 23 01:09:37.848: INFO: Got endpoints: latency-svc-dwbmp [746.298636ms]
Mar 23 01:09:37.855: INFO: Created: latency-svc-2x5n4
Mar 23 01:09:37.898: INFO: Got endpoints: latency-svc-lnlqf [747.058949ms]
Mar 23 01:09:37.905: INFO: Created: latency-svc-kvr8p
Mar 23 01:09:37.947: INFO: Got endpoints: latency-svc-rtv8n [748.570486ms]
Mar 23 01:09:37.954: INFO: Created: latency-svc-fl9f7
Mar 23 01:09:37.998: INFO: Got endpoints: latency-svc-9jktl [738.153971ms]
Mar 23 01:09:38.005: INFO: Created: latency-svc-w9hr9
Mar 23 01:09:38.048: INFO: Got endpoints: latency-svc-dxrtg [750.07852ms]
Mar 23 01:09:38.054: INFO: Created: latency-svc-pp9qv
Mar 23 01:09:38.098: INFO: Got endpoints: latency-svc-qtpq8 [749.339977ms]
Mar 23 01:09:38.103: INFO: Created: latency-svc-j42qf
Mar 23 01:09:38.148: INFO: Got endpoints: latency-svc-wxdss [750.393605ms]
Mar 23 01:09:38.154: INFO: Created: latency-svc-dwkr2
Mar 23 01:09:38.197: INFO: Got endpoints: latency-svc-xbxjb [750.188632ms]
Mar 23 01:09:38.204: INFO: Created: latency-svc-szz7m
Mar 23 01:09:38.248: INFO: Got endpoints: latency-svc-jn7dx [750.130781ms]
Mar 23 01:09:38.256: INFO: Created: latency-svc-q6wjz
Mar 23 01:09:38.298: INFO: Got endpoints: latency-svc-mr79r [750.042671ms]
Mar 23 01:09:38.304: INFO: Created: latency-svc-nc2lp
Mar 23 01:09:38.347: INFO: Got endpoints: latency-svc-v25qb [749.344214ms]
Mar 23 01:09:38.353: INFO: Created: latency-svc-vw27g
Mar 23 01:09:38.398: INFO: Got endpoints: latency-svc-vtprz [751.177986ms]
Mar 23 01:09:38.405: INFO: Created: latency-svc-6d9g2
Mar 23 01:09:38.447: INFO: Got endpoints: latency-svc-hdwqs [750.019189ms]
Mar 23 01:09:38.453: INFO: Created: latency-svc-8lhzt
Mar 23 01:09:38.498: INFO: Got endpoints: latency-svc-v5gcx [750.576376ms]
Mar 23 01:09:38.504: INFO: Created: latency-svc-skpmr
Mar 23 01:09:38.548: INFO: Got endpoints: latency-svc-44tpg [750.127751ms]
Mar 23 01:09:38.554: INFO: Created: latency-svc-vzdwk
Mar 23 01:09:38.597: INFO: Got endpoints: latency-svc-2x5n4 [748.794643ms]
Mar 23 01:09:38.603: INFO: Created: latency-svc-v4lz8
Mar 23 01:09:38.649: INFO: Got endpoints: latency-svc-kvr8p [751.482901ms]
Mar 23 01:09:38.656: INFO: Created: latency-svc-vwvmd
Mar 23 01:09:38.697: INFO: Got endpoints: latency-svc-fl9f7 [750.056465ms]
Mar 23 01:09:38.703: INFO: Created: latency-svc-jxj95
Mar 23 01:09:38.748: INFO: Got endpoints: latency-svc-w9hr9 [749.680184ms]
Mar 23 01:09:38.757: INFO: Created: latency-svc-2lqxw
Mar 23 01:09:38.798: INFO: Got endpoints: latency-svc-pp9qv [750.091648ms]
Mar 23 01:09:38.804: INFO: Created: latency-svc-4gt8p
Mar 23 01:09:38.848: INFO: Got endpoints: latency-svc-j42qf [750.484845ms]
Mar 23 01:09:38.856: INFO: Created: latency-svc-w7nv4
Mar 23 01:09:38.898: INFO: Got endpoints: latency-svc-dwkr2 [749.708618ms]
Mar 23 01:09:38.905: INFO: Created: latency-svc-52cmd
Mar 23 01:09:38.947: INFO: Got endpoints: latency-svc-szz7m [749.93907ms]
Mar 23 01:09:38.954: INFO: Created: latency-svc-2bxm6
Mar 23 01:09:38.997: INFO: Got endpoints: latency-svc-q6wjz [749.189112ms]
Mar 23 01:09:39.005: INFO: Created: latency-svc-rcgm5
Mar 23 01:09:39.048: INFO: Got endpoints: latency-svc-nc2lp [749.457898ms]
Mar 23 01:09:39.054: INFO: Created: latency-svc-cdnm7
Mar 23 01:09:39.098: INFO: Got endpoints: latency-svc-vw27g [750.414462ms]
Mar 23 01:09:39.104: INFO: Created: latency-svc-vn6dv
Mar 23 01:09:39.147: INFO: Got endpoints: latency-svc-6d9g2 [749.29347ms]
Mar 23 01:09:39.153: INFO: Created: latency-svc-9kl5c
Mar 23 01:09:39.199: INFO: Got endpoints: latency-svc-8lhzt [751.776224ms]
Mar 23 01:09:39.207: INFO: Created: latency-svc-wgsjc
Mar 23 01:09:39.248: INFO: Got endpoints: latency-svc-skpmr [750.563117ms]
Mar 23 01:09:39.257: INFO: Created: latency-svc-sg6qd
Mar 23 01:09:39.298: INFO: Got endpoints: latency-svc-vzdwk [750.333686ms]
Mar 23 01:09:39.304: INFO: Created: latency-svc-gv4qf
Mar 23 01:09:39.347: INFO: Got endpoints: latency-svc-v4lz8 [750.151504ms]
Mar 23 01:09:39.355: INFO: Created: latency-svc-9w7rt
Mar 23 01:09:39.398: INFO: Got endpoints: latency-svc-vwvmd [748.792278ms]
Mar 23 01:09:39.406: INFO: Created: latency-svc-nvr82
Mar 23 01:09:39.448: INFO: Got endpoints: latency-svc-jxj95 [750.873222ms]
Mar 23 01:09:39.455: INFO: Created: latency-svc-98jjc
Mar 23 01:09:39.498: INFO: Got endpoints: latency-svc-2lqxw [749.725851ms]
Mar 23 01:09:39.505: INFO: Created: latency-svc-gb6xj
Mar 23 01:09:39.547: INFO: Got endpoints: latency-svc-4gt8p [749.225062ms]
Mar 23 01:09:39.553: INFO: Created: latency-svc-56ph2
Mar 23 01:09:39.598: INFO: Got endpoints: latency-svc-w7nv4 [749.812861ms]
Mar 23 01:09:39.622: INFO: Created: latency-svc-sljxj
Mar 23 01:09:39.647: INFO: Got endpoints: latency-svc-52cmd [749.357546ms]
Mar 23 01:09:39.653: INFO: Created: latency-svc-w4x6p
Mar 23 01:09:39.698: INFO: Got endpoints: latency-svc-2bxm6 [750.695049ms]
Mar 23 01:09:39.712: INFO: Created: latency-svc-q98j8
Mar 23 01:09:39.748: INFO: Got endpoints: latency-svc-rcgm5 [750.497574ms]
Mar 23 01:09:39.754: INFO: Created: latency-svc-sjhm9
Mar 23 01:09:39.798: INFO: Got endpoints: latency-svc-cdnm7 [750.629016ms]
Mar 23 01:09:39.806: INFO: Created: latency-svc-46d2f
Mar 23 01:09:39.848: INFO: Got endpoints: latency-svc-vn6dv [750.187579ms]
Mar 23 01:09:39.855: INFO: Created: latency-svc-xrtjd
Mar 23 01:09:39.898: INFO: Got endpoints: latency-svc-9kl5c [750.303641ms]
Mar 23 01:09:39.904: INFO: Created: latency-svc-zxlfq
Mar 23 01:09:39.948: INFO: Got endpoints: latency-svc-wgsjc [748.623882ms]
Mar 23 01:09:39.954: INFO: Created: latency-svc-7cffw
Mar 23 01:09:39.997: INFO: Got endpoints: latency-svc-sg6qd [748.905358ms]
Mar 23 01:09:40.004: INFO: Created: latency-svc-xbj5r
Mar 23 01:09:40.047: INFO: Got endpoints: latency-svc-gv4qf [748.928699ms]
Mar 23 01:09:40.053: INFO: Created: latency-svc-fwm5v
Mar 23 01:09:40.098: INFO: Got endpoints: latency-svc-9w7rt [750.162648ms]
Mar 23 01:09:40.104: INFO: Created: latency-svc-mk8rv
Mar 23 01:09:40.147: INFO: Got endpoints: latency-svc-nvr82 [748.886857ms]
Mar 23 01:09:40.155: INFO: Created: latency-svc-whl74
Mar 23 01:09:40.198: INFO: Got endpoints: latency-svc-98jjc [749.335933ms]
Mar 23 01:09:40.203: INFO: Created: latency-svc-q2z4l
Mar 23 01:09:40.247: INFO: Got endpoints: latency-svc-gb6xj [749.400791ms]
Mar 23 01:09:40.254: INFO: Created: latency-svc-xnxrr
Mar 23 01:09:40.301: INFO: Got endpoints: latency-svc-56ph2 [753.607515ms]
Mar 23 01:09:40.307: INFO: Created: latency-svc-kqdv5
Mar 23 01:09:40.347: INFO: Got endpoints: latency-svc-sljxj [749.100007ms]
Mar 23 01:09:40.353: INFO: Created: latency-svc-vtxdt
Mar 23 01:09:40.398: INFO: Got endpoints: latency-svc-w4x6p [750.679475ms]
Mar 23 01:09:40.407: INFO: Created: latency-svc-jncxh
Mar 23 01:09:40.448: INFO: Got endpoints: latency-svc-q98j8 [749.941273ms]
Mar 23 01:09:40.455: INFO: Created: latency-svc-cv2dx
Mar 23 01:09:40.498: INFO: Got endpoints: latency-svc-sjhm9 [750.52609ms]
Mar 23 01:09:40.507: INFO: Created: latency-svc-5dpnx
Mar 23 01:09:40.548: INFO: Got endpoints: latency-svc-46d2f [750.128108ms]
Mar 23 01:09:40.555: INFO: Created: latency-svc-pvmhb
Mar 23 01:09:40.597: INFO: Got endpoints: latency-svc-xrtjd [749.655326ms]
Mar 23 01:09:40.605: INFO: Created: latency-svc-l8xxb
Mar 23 01:09:40.648: INFO: Got endpoints: latency-svc-zxlfq [750.178247ms]
Mar 23 01:09:40.655: INFO: Created: latency-svc-9th94
Mar 23 01:09:40.703: INFO: Got endpoints: latency-svc-7cffw [755.345343ms]
Mar 23 01:09:40.710: INFO: Created: latency-svc-5jzs5
Mar 23 01:09:40.747: INFO: Got endpoints: latency-svc-xbj5r [749.714046ms]
Mar 23 01:09:40.754: INFO: Created: latency-svc-s59jn
Mar 23 01:09:40.799: INFO: Got endpoints: latency-svc-fwm5v [751.232207ms]
Mar 23 01:09:40.805: INFO: Created: latency-svc-pxb2f
Mar 23 01:09:40.848: INFO: Got endpoints: latency-svc-mk8rv [750.021508ms]
Mar 23 01:09:40.858: INFO: Created: latency-svc-v8svk
Mar 23 01:09:40.899: INFO: Got endpoints: latency-svc-whl74 [751.867524ms]
Mar 23 01:09:40.907: INFO: Created: latency-svc-d9p9r
Mar 23 01:09:40.947: INFO: Got endpoints: latency-svc-q2z4l [749.706981ms]
Mar 23 01:09:40.954: INFO: Created: latency-svc-pwzcs
Mar 23 01:09:40.997: INFO: Got endpoints: latency-svc-xnxrr [750.340541ms]
Mar 23 01:09:41.004: INFO: Created: latency-svc-tdwmh
Mar 23 01:09:41.047: INFO: Got endpoints: latency-svc-kqdv5 [746.670889ms]
Mar 23 01:09:41.055: INFO: Created: latency-svc-2jbbb
Mar 23 01:09:41.097: INFO: Got endpoints: latency-svc-vtxdt [750.153824ms]
Mar 23 01:09:41.105: INFO: Created: latency-svc-nvs6z
Mar 23 01:09:41.148: INFO: Got endpoints: latency-svc-jncxh [749.851889ms]
Mar 23 01:09:41.198: INFO: Got endpoints: latency-svc-cv2dx [749.637594ms]
Mar 23 01:09:41.248: INFO: Got endpoints: latency-svc-5dpnx [749.648924ms]
Mar 23 01:09:41.298: INFO: Got endpoints: latency-svc-pvmhb [749.301989ms]
Mar 23 01:09:41.348: INFO: Got endpoints: latency-svc-l8xxb [750.328351ms]
Mar 23 01:09:41.398: INFO: Got endpoints: latency-svc-9th94 [749.975821ms]
Mar 23 01:09:41.448: INFO: Got endpoints: latency-svc-5jzs5 [744.354542ms]
Mar 23 01:09:41.498: INFO: Got endpoints: latency-svc-s59jn [751.124052ms]
Mar 23 01:09:41.548: INFO: Got endpoints: latency-svc-pxb2f [749.230418ms]
Mar 23 01:09:41.597: INFO: Got endpoints: latency-svc-v8svk [749.672595ms]
Mar 23 01:09:41.648: INFO: Got endpoints: latency-svc-d9p9r [748.707657ms]
Mar 23 01:09:41.698: INFO: Got endpoints: latency-svc-pwzcs [750.902287ms]
Mar 23 01:09:41.747: INFO: Got endpoints: latency-svc-tdwmh [749.811581ms]
Mar 23 01:09:41.797: INFO: Got endpoints: latency-svc-2jbbb [749.981571ms]
Mar 23 01:09:41.847: INFO: Got endpoints: latency-svc-nvs6z [749.890083ms]
Mar 23 01:09:41.847: INFO: Latencies: [15.638855ms 21.71474ms 21.786502ms 29.697654ms 46.326918ms 48.266732ms 58.440713ms 63.139994ms 69.517023ms 77.443841ms 81.508734ms 90.737969ms 93.764551ms 100.236468ms 101.728733ms 108.587002ms 110.178627ms 112.621871ms 114.411513ms 115.510446ms 118.119381ms 118.584262ms 122.425708ms 124.025077ms 125.34404ms 125.731675ms 126.083295ms 126.196886ms 127.033734ms 127.161974ms 127.5895ms 129.100742ms 130.350998ms 136.074722ms 149.120805ms 182.121964ms 217.344481ms 253.322396ms 292.300461ms 347.042521ms 383.36498ms 425.067215ms 469.874059ms 512.484809ms 549.603994ms 594.302192ms 639.638409ms 680.43656ms 717.831981ms 738.153971ms 744.354542ms 744.751532ms 746.270067ms 746.298636ms 746.670889ms 747.058949ms 747.652769ms 747.661023ms 748.289578ms 748.491649ms 748.570486ms 748.623882ms 748.64255ms 748.707657ms 748.735026ms 748.792278ms 748.794643ms 748.880451ms 748.886857ms 748.905358ms 748.928699ms 749.094856ms 749.100007ms 749.147243ms 749.189112ms 749.225062ms 749.230418ms 749.23618ms 749.29347ms 749.301989ms 749.319968ms 749.335933ms 749.339977ms 749.344214ms 749.357546ms 749.389151ms 749.400791ms 749.412948ms 749.419261ms 749.430237ms 749.440654ms 749.457898ms 749.487804ms 749.501753ms 749.511363ms 749.637594ms 749.648924ms 749.655326ms 749.668186ms 749.672595ms 749.680184ms 749.689749ms 749.706981ms 749.708618ms 749.714046ms 749.725851ms 749.763497ms 749.811581ms 749.812861ms 749.823814ms 749.851889ms 749.865983ms 749.876888ms 749.890083ms 749.897463ms 749.916467ms 749.936343ms 749.93907ms 749.941273ms 749.942184ms 749.947165ms 749.964946ms 749.975821ms 749.981571ms 750.019189ms 750.021508ms 750.025245ms 750.042671ms 750.053192ms 750.056465ms 750.07852ms 750.091648ms 750.106569ms 750.107022ms 750.10983ms 750.125494ms 750.127751ms 750.128108ms 750.130781ms 750.150147ms 750.151504ms 750.153824ms 750.162648ms 750.173217ms 750.178247ms 750.185637ms 750.187579ms 750.188632ms 750.206884ms 750.281933ms 750.292568ms 750.2999ms 750.303641ms 750.311906ms 750.326301ms 750.328351ms 750.333686ms 750.340541ms 750.343986ms 750.378022ms 750.393605ms 750.411084ms 750.414462ms 750.484845ms 750.497574ms 750.50001ms 750.508368ms 750.52322ms 750.525208ms 750.52609ms 750.563117ms 750.576376ms 750.592632ms 750.592855ms 750.616739ms 750.629016ms 750.679475ms 750.695049ms 750.822944ms 750.835199ms 750.873222ms 750.902287ms 750.986522ms 751.077204ms 751.124052ms 751.177986ms 751.210744ms 751.232207ms 751.407398ms 751.482901ms 751.776224ms 751.867524ms 752.771736ms 753.064777ms 753.523602ms 753.607515ms 754.563341ms 755.345343ms 756.021788ms 761.612657ms]
Mar 23 01:09:41.847: INFO: 50 %ile: 749.680184ms
Mar 23 01:09:41.847: INFO: 90 %ile: 750.873222ms
Mar 23 01:09:41.847: INFO: 99 %ile: 756.021788ms
Mar 23 01:09:41.847: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:09:41.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-qwwsp" for this suite.
Mar 23 01:10:03.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:10:03.900: INFO: namespace: e2e-tests-svc-latency-qwwsp, resource: bindings, ignored listing per whitelist
Mar 23 01:10:03.937: INFO: namespace e2e-tests-svc-latency-qwwsp deletion completed in 22.085936981s

• [SLOW TEST:32.856 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:10:03.937: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 23 01:10:03.992: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:10:07.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-ff4wx" for this suite.
Mar 23 01:10:13.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:10:13.338: INFO: namespace: e2e-tests-init-container-ff4wx, resource: bindings, ignored listing per whitelist
Mar 23 01:10:13.377: INFO: namespace e2e-tests-init-container-ff4wx deletion completed in 6.093460337s

• [SLOW TEST:9.440 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:10:13.377: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-9v6bz/configmap-test-695d4d28-4d08-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume configMaps
Mar 23 01:10:13.439: INFO: Waiting up to 5m0s for pod "pod-configmaps-695dc523-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-configmap-9v6bz" to be "success or failure"
Mar 23 01:10:13.443: INFO: Pod "pod-configmaps-695dc523-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.493741ms
Mar 23 01:10:15.446: INFO: Pod "pod-configmaps-695dc523-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006342289s
STEP: Saw pod success
Mar 23 01:10:15.446: INFO: Pod "pod-configmaps-695dc523-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:10:15.448: INFO: Trying to get logs from node node-2 pod pod-configmaps-695dc523-4d08-11e9-96f5-ea7d86f92d02 container env-test: <nil>
STEP: delete the pod
Mar 23 01:10:15.464: INFO: Waiting for pod pod-configmaps-695dc523-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:10:15.466: INFO: Pod pod-configmaps-695dc523-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:10:15.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9v6bz" for this suite.
Mar 23 01:10:21.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:10:21.937: INFO: namespace: e2e-tests-configmap-9v6bz, resource: bindings, ignored listing per whitelist
Mar 23 01:10:22.001: INFO: namespace e2e-tests-configmap-9v6bz deletion completed in 6.530948644s

• [SLOW TEST:8.624 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:10:22.001: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-25cnq
Mar 23 01:10:24.064: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-25cnq
STEP: checking the pod's current state and verifying that restartCount is present
Mar 23 01:10:24.068: INFO: Initial restart count of pod liveness-exec is 0
Mar 23 01:11:18.148: INFO: Restart count of pod e2e-tests-container-probe-25cnq/liveness-exec is now 1 (54.080220574s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:11:18.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-25cnq" for this suite.
Mar 23 01:11:24.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:11:24.234: INFO: namespace: e2e-tests-container-probe-25cnq, resource: bindings, ignored listing per whitelist
Mar 23 01:11:24.246: INFO: namespace e2e-tests-container-probe-25cnq deletion completed in 6.085104395s

• [SLOW TEST:62.245 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:11:24.246: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 23 01:11:26.830: INFO: Successfully updated pod "annotationupdate939b86ef-4d08-11e9-96f5-ea7d86f92d02"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:11:30.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jfz8n" for this suite.
Mar 23 01:11:52.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:11:52.886: INFO: namespace: e2e-tests-downward-api-jfz8n, resource: bindings, ignored listing per whitelist
Mar 23 01:11:52.943: INFO: namespace e2e-tests-downward-api-jfz8n deletion completed in 22.088067393s

• [SLOW TEST:28.697 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:11:52.943: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar 23 01:11:52.998: INFO: Waiting up to 5m0s for pod "var-expansion-a4b57dc7-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-var-expansion-s9w52" to be "success or failure"
Mar 23 01:11:53.000: INFO: Pod "var-expansion-a4b57dc7-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.228426ms
Mar 23 01:11:55.004: INFO: Pod "var-expansion-a4b57dc7-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005379863s
STEP: Saw pod success
Mar 23 01:11:55.004: INFO: Pod "var-expansion-a4b57dc7-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:11:55.006: INFO: Trying to get logs from node node-2 pod var-expansion-a4b57dc7-4d08-11e9-96f5-ea7d86f92d02 container dapi-container: <nil>
STEP: delete the pod
Mar 23 01:11:55.020: INFO: Waiting for pod var-expansion-a4b57dc7-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:11:55.022: INFO: Pod var-expansion-a4b57dc7-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:11:55.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-s9w52" for this suite.
Mar 23 01:12:01.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:12:01.104: INFO: namespace: e2e-tests-var-expansion-s9w52, resource: bindings, ignored listing per whitelist
Mar 23 01:12:01.112: INFO: namespace e2e-tests-var-expansion-s9w52 deletion completed in 6.087187273s

• [SLOW TEST:8.169 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:12:01.112: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar 23 01:12:01.173: INFO: Waiting up to 5m0s for pod "client-containers-a994d659-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-containers-9mbdm" to be "success or failure"
Mar 23 01:12:01.176: INFO: Pod "client-containers-a994d659-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.728627ms
Mar 23 01:12:03.179: INFO: Pod "client-containers-a994d659-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005790489s
STEP: Saw pod success
Mar 23 01:12:03.179: INFO: Pod "client-containers-a994d659-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:12:03.181: INFO: Trying to get logs from node node-2 pod client-containers-a994d659-4d08-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 01:12:03.195: INFO: Waiting for pod client-containers-a994d659-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:12:03.197: INFO: Pod client-containers-a994d659-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:12:03.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9mbdm" for this suite.
Mar 23 01:12:09.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:12:09.262: INFO: namespace: e2e-tests-containers-9mbdm, resource: bindings, ignored listing per whitelist
Mar 23 01:12:09.285: INFO: namespace e2e-tests-containers-9mbdm deletion completed in 6.083802912s

• [SLOW TEST:8.172 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:12:09.285: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 01:12:09.347: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ae73dbc6-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-sqp2z" to be "success or failure"
Mar 23 01:12:09.351: INFO: Pod "downwardapi-volume-ae73dbc6-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 3.106789ms
Mar 23 01:12:11.353: INFO: Pod "downwardapi-volume-ae73dbc6-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005807695s
STEP: Saw pod success
Mar 23 01:12:11.353: INFO: Pod "downwardapi-volume-ae73dbc6-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:12:11.355: INFO: Trying to get logs from node node-2 pod downwardapi-volume-ae73dbc6-4d08-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 01:12:11.372: INFO: Waiting for pod downwardapi-volume-ae73dbc6-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:12:11.374: INFO: Pod downwardapi-volume-ae73dbc6-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:12:11.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sqp2z" for this suite.
Mar 23 01:12:17.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:12:17.418: INFO: namespace: e2e-tests-projected-sqp2z, resource: bindings, ignored listing per whitelist
Mar 23 01:12:17.460: INFO: namespace e2e-tests-projected-sqp2z deletion completed in 6.082258482s

• [SLOW TEST:8.175 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:12:17.460: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 23 01:12:17.540: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-a,UID:b356638d-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17793,Generation:0,CreationTimestamp:2019-03-23 01:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 23 01:12:17.540: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-a,UID:b356638d-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17793,Generation:0,CreationTimestamp:2019-03-23 01:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar 23 01:12:27.546: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-a,UID:b356638d-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17809,Generation:0,CreationTimestamp:2019-03-23 01:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 23 01:12:27.546: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-a,UID:b356638d-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17809,Generation:0,CreationTimestamp:2019-03-23 01:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 23 01:12:37.551: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-a,UID:b356638d-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17826,Generation:0,CreationTimestamp:2019-03-23 01:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 23 01:12:37.551: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-a,UID:b356638d-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17826,Generation:0,CreationTimestamp:2019-03-23 01:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar 23 01:12:47.556: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-a,UID:b356638d-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17843,Generation:0,CreationTimestamp:2019-03-23 01:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 23 01:12:47.556: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-a,UID:b356638d-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17843,Generation:0,CreationTimestamp:2019-03-23 01:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 23 01:12:57.562: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-b,UID:cb310eb7-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17859,Generation:0,CreationTimestamp:2019-03-23 01:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 23 01:12:57.562: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-b,UID:cb310eb7-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17859,Generation:0,CreationTimestamp:2019-03-23 01:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar 23 01:13:07.567: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-b,UID:cb310eb7-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17876,Generation:0,CreationTimestamp:2019-03-23 01:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 23 01:13:07.567: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zhx6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-zhx6f/configmaps/e2e-watch-test-configmap-b,UID:cb310eb7-4d08-11e9-9a5c-0646f33e71ba,ResourceVersion:17876,Generation:0,CreationTimestamp:2019-03-23 01:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:13:17.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zhx6f" for this suite.
Mar 23 01:13:23.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:13:23.622: INFO: namespace: e2e-tests-watch-zhx6f, resource: bindings, ignored listing per whitelist
Mar 23 01:13:23.657: INFO: namespace e2e-tests-watch-zhx6f deletion completed in 6.085118842s

• [SLOW TEST:66.197 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:13:23.657: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar 23 01:13:23.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:24.205: INFO: stderr: ""
Mar 23 01:13:24.205: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 23 01:13:24.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:24.297: INFO: stderr: ""
Mar 23 01:13:24.297: INFO: stdout: "update-demo-nautilus-dn4qc update-demo-nautilus-jncx2 "
Mar 23 01:13:24.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-dn4qc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:24.377: INFO: stderr: ""
Mar 23 01:13:24.377: INFO: stdout: ""
Mar 23 01:13:24.377: INFO: update-demo-nautilus-dn4qc is created but not running
Mar 23 01:13:29.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:29.457: INFO: stderr: ""
Mar 23 01:13:29.457: INFO: stdout: "update-demo-nautilus-dn4qc update-demo-nautilus-jncx2 "
Mar 23 01:13:29.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-dn4qc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:29.536: INFO: stderr: ""
Mar 23 01:13:29.536: INFO: stdout: "true"
Mar 23 01:13:29.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-dn4qc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:29.613: INFO: stderr: ""
Mar 23 01:13:29.613: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 23 01:13:29.613: INFO: validating pod update-demo-nautilus-dn4qc
Mar 23 01:13:29.617: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 23 01:13:29.617: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 23 01:13:29.617: INFO: update-demo-nautilus-dn4qc is verified up and running
Mar 23 01:13:29.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-jncx2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:29.694: INFO: stderr: ""
Mar 23 01:13:29.694: INFO: stdout: "true"
Mar 23 01:13:29.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-nautilus-jncx2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:29.773: INFO: stderr: ""
Mar 23 01:13:29.773: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 23 01:13:29.773: INFO: validating pod update-demo-nautilus-jncx2
Mar 23 01:13:29.777: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 23 01:13:29.777: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 23 01:13:29.777: INFO: update-demo-nautilus-jncx2 is verified up and running
STEP: rolling-update to new replication controller
Mar 23 01:13:29.779: INFO: scanned /root for discovery docs: <nil>
Mar 23 01:13:29.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:52.191: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 23 01:13:52.191: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 23 01:13:52.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:52.272: INFO: stderr: ""
Mar 23 01:13:52.272: INFO: stdout: "update-demo-kitten-2qpv4 update-demo-kitten-6pr5z "
Mar 23 01:13:52.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-kitten-2qpv4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:52.348: INFO: stderr: ""
Mar 23 01:13:52.348: INFO: stdout: "true"
Mar 23 01:13:52.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-kitten-2qpv4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:52.426: INFO: stderr: ""
Mar 23 01:13:52.426: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 23 01:13:52.426: INFO: validating pod update-demo-kitten-2qpv4
Mar 23 01:13:52.430: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 23 01:13:52.430: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 23 01:13:52.430: INFO: update-demo-kitten-2qpv4 is verified up and running
Mar 23 01:13:52.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-kitten-6pr5z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:52.511: INFO: stderr: ""
Mar 23 01:13:52.511: INFO: stdout: "true"
Mar 23 01:13:52.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods update-demo-kitten-6pr5z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ccflk'
Mar 23 01:13:52.587: INFO: stderr: ""
Mar 23 01:13:52.587: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 23 01:13:52.587: INFO: validating pod update-demo-kitten-6pr5z
Mar 23 01:13:52.591: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 23 01:13:52.591: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 23 01:13:52.591: INFO: update-demo-kitten-6pr5z is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:13:52.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ccflk" for this suite.
Mar 23 01:14:14.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:14:14.630: INFO: namespace: e2e-tests-kubectl-ccflk, resource: bindings, ignored listing per whitelist
Mar 23 01:14:14.681: INFO: namespace e2e-tests-kubectl-ccflk deletion completed in 22.086359072s

• [SLOW TEST:51.024 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:14:14.681: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-f931c660-4d08-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 01:14:14.744: INFO: Waiting up to 5m0s for pod "pod-secrets-f9322abf-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-secrets-5xkq2" to be "success or failure"
Mar 23 01:14:14.747: INFO: Pod "pod-secrets-f9322abf-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.805891ms
Mar 23 01:14:16.750: INFO: Pod "pod-secrets-f9322abf-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005795095s
STEP: Saw pod success
Mar 23 01:14:16.750: INFO: Pod "pod-secrets-f9322abf-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:14:16.752: INFO: Trying to get logs from node node-2 pod pod-secrets-f9322abf-4d08-11e9-96f5-ea7d86f92d02 container secret-volume-test: <nil>
STEP: delete the pod
Mar 23 01:14:16.766: INFO: Waiting for pod pod-secrets-f9322abf-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:14:16.769: INFO: Pod pod-secrets-f9322abf-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:14:16.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5xkq2" for this suite.
Mar 23 01:14:22.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:14:22.801: INFO: namespace: e2e-tests-secrets-5xkq2, resource: bindings, ignored listing per whitelist
Mar 23 01:14:22.862: INFO: namespace e2e-tests-secrets-5xkq2 deletion completed in 6.089795193s

• [SLOW TEST:8.181 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:14:22.862: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-fe1902d1-4d08-11e9-96f5-ea7d86f92d02
STEP: Creating a pod to test consume secrets
Mar 23 01:14:22.977: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fe197815-4d08-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-h6l6k" to be "success or failure"
Mar 23 01:14:22.981: INFO: Pod "pod-projected-secrets-fe197815-4d08-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.825451ms
Mar 23 01:14:24.985: INFO: Pod "pod-projected-secrets-fe197815-4d08-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007866089s
STEP: Saw pod success
Mar 23 01:14:24.985: INFO: Pod "pod-projected-secrets-fe197815-4d08-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:14:24.987: INFO: Trying to get logs from node node-2 pod pod-projected-secrets-fe197815-4d08-11e9-96f5-ea7d86f92d02 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 23 01:14:25.000: INFO: Waiting for pod pod-projected-secrets-fe197815-4d08-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:14:25.003: INFO: Pod pod-projected-secrets-fe197815-4d08-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:14:25.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h6l6k" for this suite.
Mar 23 01:14:31.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:14:31.038: INFO: namespace: e2e-tests-projected-h6l6k, resource: bindings, ignored listing per whitelist
Mar 23 01:14:31.094: INFO: namespace e2e-tests-projected-h6l6k deletion completed in 6.087641381s

• [SLOW TEST:8.232 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:14:31.095: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar 23 01:14:31.152: INFO: Waiting up to 5m0s for pod "client-containers-02f9c461-4d09-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-containers-9km44" to be "success or failure"
Mar 23 01:14:31.154: INFO: Pod "client-containers-02f9c461-4d09-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020254ms
Mar 23 01:14:33.157: INFO: Pod "client-containers-02f9c461-4d09-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00493464s
STEP: Saw pod success
Mar 23 01:14:33.157: INFO: Pod "client-containers-02f9c461-4d09-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:14:33.160: INFO: Trying to get logs from node node-2 pod client-containers-02f9c461-4d09-11e9-96f5-ea7d86f92d02 container test-container: <nil>
STEP: delete the pod
Mar 23 01:14:33.180: INFO: Waiting for pod client-containers-02f9c461-4d09-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:14:33.183: INFO: Pod client-containers-02f9c461-4d09-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:14:33.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9km44" for this suite.
Mar 23 01:14:39.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:14:39.252: INFO: namespace: e2e-tests-containers-9km44, resource: bindings, ignored listing per whitelist
Mar 23 01:14:39.265: INFO: namespace e2e-tests-containers-9km44 deletion completed in 6.078326646s

• [SLOW TEST:8.170 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:14:39.265: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Mar 23 01:14:39.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 create -f - --namespace=e2e-tests-kubectl-jf2gc'
Mar 23 01:14:39.466: INFO: stderr: ""
Mar 23 01:14:39.466: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar 23 01:14:40.469: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 01:14:40.469: INFO: Found 0 / 1
Mar 23 01:14:41.469: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 01:14:41.469: INFO: Found 1 / 1
Mar 23 01:14:41.469: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 23 01:14:41.471: INFO: Selector matched 1 pods for map[app:redis]
Mar 23 01:14:41.471: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar 23 01:14:41.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 logs redis-master-4wqc6 redis-master --namespace=e2e-tests-kubectl-jf2gc'
Mar 23 01:14:41.562: INFO: stderr: ""
Mar 23 01:14:41.562: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 23 Mar 01:14:40.279 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 23 Mar 01:14:40.280 # Server started, Redis version 3.2.12\n1:M 23 Mar 01:14:40.280 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 23 Mar 01:14:40.280 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar 23 01:14:41.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 log redis-master-4wqc6 redis-master --namespace=e2e-tests-kubectl-jf2gc --tail=1'
Mar 23 01:14:41.649: INFO: stderr: ""
Mar 23 01:14:41.649: INFO: stdout: "1:M 23 Mar 01:14:40.280 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar 23 01:14:41.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 log redis-master-4wqc6 redis-master --namespace=e2e-tests-kubectl-jf2gc --limit-bytes=1'
Mar 23 01:14:41.738: INFO: stderr: ""
Mar 23 01:14:41.738: INFO: stdout: " "
STEP: exposing timestamps
Mar 23 01:14:41.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 log redis-master-4wqc6 redis-master --namespace=e2e-tests-kubectl-jf2gc --tail=1 --timestamps'
Mar 23 01:14:41.827: INFO: stderr: ""
Mar 23 01:14:41.827: INFO: stdout: "2019-03-23T01:14:40.281424167Z 1:M 23 Mar 01:14:40.280 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar 23 01:14:44.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 log redis-master-4wqc6 redis-master --namespace=e2e-tests-kubectl-jf2gc --since=1s'
Mar 23 01:14:44.416: INFO: stderr: ""
Mar 23 01:14:44.416: INFO: stdout: ""
Mar 23 01:14:44.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 log redis-master-4wqc6 redis-master --namespace=e2e-tests-kubectl-jf2gc --since=24h'
Mar 23 01:14:44.506: INFO: stderr: ""
Mar 23 01:14:44.506: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 23 Mar 01:14:40.279 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 23 Mar 01:14:40.280 # Server started, Redis version 3.2.12\n1:M 23 Mar 01:14:40.280 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 23 Mar 01:14:40.280 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Mar 23 01:14:44.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jf2gc'
Mar 23 01:14:44.590: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 23 01:14:44.590: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar 23 01:14:44.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-jf2gc'
Mar 23 01:14:44.674: INFO: stderr: "No resources found.\n"
Mar 23 01:14:44.674: INFO: stdout: ""
Mar 23 01:14:44.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 get pods -l name=nginx --namespace=e2e-tests-kubectl-jf2gc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 23 01:14:44.753: INFO: stderr: ""
Mar 23 01:14:44.753: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:14:44.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jf2gc" for this suite.
Mar 23 01:15:06.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:15:06.777: INFO: namespace: e2e-tests-kubectl-jf2gc, resource: bindings, ignored listing per whitelist
Mar 23 01:15:06.843: INFO: namespace e2e-tests-kubectl-jf2gc deletion completed in 22.086122347s

• [SLOW TEST:27.578 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:15:06.843: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar 23 01:15:07.420: INFO: created pod pod-service-account-defaultsa
Mar 23 01:15:07.420: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 23 01:15:07.425: INFO: created pod pod-service-account-mountsa
Mar 23 01:15:07.425: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 23 01:15:07.430: INFO: created pod pod-service-account-nomountsa
Mar 23 01:15:07.430: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 23 01:15:07.438: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 23 01:15:07.438: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 23 01:15:07.445: INFO: created pod pod-service-account-mountsa-mountspec
Mar 23 01:15:07.445: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 23 01:15:07.452: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 23 01:15:07.452: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 23 01:15:07.456: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 23 01:15:07.456: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 23 01:15:07.461: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 23 01:15:07.461: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 23 01:15:07.475: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 23 01:15:07.475: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:15:07.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-kghms" for this suite.
Mar 23 01:15:13.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:15:13.559: INFO: namespace: e2e-tests-svcaccounts-kghms, resource: bindings, ignored listing per whitelist
Mar 23 01:15:13.602: INFO: namespace e2e-tests-svcaccounts-kghms deletion completed in 6.117576814s

• [SLOW TEST:6.759 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:15:13.603: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar 23 01:15:13.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 cluster-info'
Mar 23 01:15:13.797: INFO: stderr: ""
Mar 23 01:15:13.797: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:15:13.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-77xxq" for this suite.
Mar 23 01:15:19.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:15:19.817: INFO: namespace: e2e-tests-kubectl-77xxq, resource: bindings, ignored listing per whitelist
Mar 23 01:15:19.888: INFO: namespace e2e-tests-kubectl-77xxq deletion completed in 6.086793213s

• [SLOW TEST:6.286 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:15:19.888: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 23 01:15:19.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 version'
Mar 23 01:15:20.015: INFO: stderr: ""
Mar 23 01:15:20.015: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.6\", GitCommit:\"ab91afd7062d4240e95e51ac00a18bd58fddd365\", GitTreeState:\"clean\", BuildDate:\"2019-02-26T12:49:28Z\", GoVersion:\"go1.10.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:15:20.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4q55g" for this suite.
Mar 23 01:15:26.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:15:26.113: INFO: namespace: e2e-tests-kubectl-4q55g, resource: bindings, ignored listing per whitelist
Mar 23 01:15:26.117: INFO: namespace e2e-tests-kubectl-4q55g deletion completed in 6.097611052s

• [SLOW TEST:6.228 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:15:26.117: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 23 01:15:26.180: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23c5c33a-4d09-11e9-96f5-ea7d86f92d02" in namespace "e2e-tests-projected-xrq9m" to be "success or failure"
Mar 23 01:15:26.183: INFO: Pod "downwardapi-volume-23c5c33a-4d09-11e9-96f5-ea7d86f92d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.779889ms
Mar 23 01:15:28.186: INFO: Pod "downwardapi-volume-23c5c33a-4d09-11e9-96f5-ea7d86f92d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005592381s
STEP: Saw pod success
Mar 23 01:15:28.186: INFO: Pod "downwardapi-volume-23c5c33a-4d09-11e9-96f5-ea7d86f92d02" satisfied condition "success or failure"
Mar 23 01:15:28.188: INFO: Trying to get logs from node node-2 pod downwardapi-volume-23c5c33a-4d09-11e9-96f5-ea7d86f92d02 container client-container: <nil>
STEP: delete the pod
Mar 23 01:15:28.205: INFO: Waiting for pod downwardapi-volume-23c5c33a-4d09-11e9-96f5-ea7d86f92d02 to disappear
Mar 23 01:15:28.207: INFO: Pod downwardapi-volume-23c5c33a-4d09-11e9-96f5-ea7d86f92d02 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:15:28.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xrq9m" for this suite.
Mar 23 01:15:34.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:15:34.229: INFO: namespace: e2e-tests-projected-xrq9m, resource: bindings, ignored listing per whitelist
Mar 23 01:15:34.302: INFO: namespace e2e-tests-projected-xrq9m deletion completed in 6.092333636s

• [SLOW TEST:8.185 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 23 01:15:34.303: INFO: >>> kubeConfig: /tmp/kubeconfig-648197830
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zwhjj
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar 23 01:15:34.369: INFO: Found 0 stateful pods, waiting for 3
Mar 23 01:15:44.372: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 23 01:15:44.372: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 23 01:15:44.372: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 23 01:15:44.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-zwhjj ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 23 01:15:44.531: INFO: stderr: ""
Mar 23 01:15:44.531: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 23 01:15:44.531: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 23 01:15:54.558: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar 23 01:16:04.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-zwhjj ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 01:16:04.736: INFO: stderr: ""
Mar 23 01:16:04.736: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 23 01:16:04.736: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 23 01:16:24.752: INFO: Waiting for StatefulSet e2e-tests-statefulset-zwhjj/ss2 to complete update
Mar 23 01:16:24.752: INFO: Waiting for Pod e2e-tests-statefulset-zwhjj/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Mar 23 01:16:34.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-zwhjj ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 23 01:16:34.894: INFO: stderr: ""
Mar 23 01:16:34.895: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 23 01:16:34.895: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 23 01:16:44.922: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar 23 01:16:54.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-648197830 exec --namespace=e2e-tests-statefulset-zwhjj ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 23 01:16:55.088: INFO: stderr: ""
Mar 23 01:16:55.088: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 23 01:16:55.088: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 23 01:17:15.102: INFO: Waiting for StatefulSet e2e-tests-statefulset-zwhjj/ss2 to complete update
Mar 23 01:17:15.103: INFO: Waiting for Pod e2e-tests-statefulset-zwhjj/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 23 01:17:25.108: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zwhjj
Mar 23 01:17:25.110: INFO: Scaling statefulset ss2 to 0
Mar 23 01:17:55.122: INFO: Waiting for statefulset status.replicas updated to 0
Mar 23 01:17:55.124: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 23 01:17:55.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zwhjj" for this suite.
Mar 23 01:18:01.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 23 01:18:01.186: INFO: namespace: e2e-tests-statefulset-zwhjj, resource: bindings, ignored listing per whitelist
Mar 23 01:18:01.238: INFO: namespace e2e-tests-statefulset-zwhjj deletion completed in 6.099203247s

• [SLOW TEST:146.935 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSMar 23 01:18:01.238: INFO: Running AfterSuite actions on all node
Mar 23 01:18:01.238: INFO: Running AfterSuite actions on node 1
Mar 23 01:18:01.238: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 4928.063 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h22m8.833644221s
Test Suite Passed
