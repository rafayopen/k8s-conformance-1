Mar 26 05:38:41.692: INFO: Overriding default scale value of zero to 1
Mar 26 05:38:41.693: INFO: Overriding default milliseconds value of zero to 5000
I0326 05:38:43.117511      14 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-414927603
I0326 05:38:43.118027      14 e2e.go:304] Starting e2e run "69c77669-4f89-11e9-8fea-5694fc6fbac7" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1553578721 - Will randomize all specs
Will run 188 of 1814 specs

Mar 26 05:38:43.620: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 05:38:43.626: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 26 05:38:43.661: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 26 05:38:43.917: INFO: The status of Pod rke-ingress-controller-deploy-job-w8l9x is Succeeded, skipping waiting
Mar 26 05:38:43.917: INFO: The status of Pod rke-kubedns-addon-deploy-job-69jrs is Succeeded, skipping waiting
Mar 26 05:38:43.917: INFO: The status of Pod rke-metrics-addon-deploy-job-bsrr2 is Succeeded, skipping waiting
Mar 26 05:38:43.917: INFO: The status of Pod rke-network-plugin-deploy-job-xl4m5 is Succeeded, skipping waiting
Mar 26 05:38:43.917: INFO: 9 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 26 05:38:43.918: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Mar 26 05:38:43.918: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 26 05:38:43.969: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Mar 26 05:38:43.969: INFO: e2e test version: v1.12.1
Mar 26 05:38:43.984: INFO: kube-apiserver version: v1.12.6
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:38:44.002: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
Mar 26 05:38:44.570: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 26 05:38:44.697: INFO: Waiting up to 5m0s for pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-mxbw5" to be "success or failure"
Mar 26 05:38:44.774: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 76.576896ms
Mar 26 05:38:46.781: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083564481s
Mar 26 05:38:48.797: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.100025392s
Mar 26 05:38:50.805: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.107834305s
Mar 26 05:38:52.814: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.116331296s
Mar 26 05:38:54.826: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.128724479s
Mar 26 05:38:56.841: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.143361533s
Mar 26 05:38:58.876: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.178309038s
Mar 26 05:39:00.882: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.184607552s
Mar 26 05:39:02.893: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.195393151s
Mar 26 05:39:04.910: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.212580053s
Mar 26 05:39:06.917: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 22.219974736s
Mar 26 05:39:08.927: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.229575007s
STEP: Saw pod success
Mar 26 05:39:08.927: INFO: Pod "pod-6b995792-4f89-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:39:08.934: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-6b995792-4f89-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 05:39:09.015: INFO: Waiting for pod pod-6b995792-4f89-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:39:09.040: INFO: Pod pod-6b995792-4f89-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:39:09.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mxbw5" for this suite.
Mar 26 05:39:15.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:39:15.308: INFO: namespace: e2e-tests-emptydir-mxbw5, resource: bindings, ignored listing per whitelist
Mar 26 05:39:15.431: INFO: namespace e2e-tests-emptydir-mxbw5 deletion completed in 6.371258582s

• [SLOW TEST:31.430 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:39:15.434: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar 26 05:39:15.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 cluster-info'
Mar 26 05:39:16.139: INFO: stderr: ""
Mar 26 05:39:16.139: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:39:16.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-77pb5" for this suite.
Mar 26 05:39:22.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:39:22.356: INFO: namespace: e2e-tests-kubectl-77pb5, resource: bindings, ignored listing per whitelist
Mar 26 05:39:22.502: INFO: namespace e2e-tests-kubectl-77pb5 deletion completed in 6.344140807s

• [SLOW TEST:7.069 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:39:22.504: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Mar 26 05:39:22.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-xzsb9'
Mar 26 05:39:23.268: INFO: stderr: ""
Mar 26 05:39:23.268: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar 26 05:39:24.276: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 05:39:24.276: INFO: Found 0 / 1
Mar 26 05:39:25.297: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 05:39:25.297: INFO: Found 0 / 1
Mar 26 05:39:26.276: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 05:39:26.276: INFO: Found 0 / 1
Mar 26 05:39:27.275: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 05:39:27.276: INFO: Found 1 / 1
Mar 26 05:39:27.276: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 26 05:39:27.281: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 05:39:27.281: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar 26 05:39:27.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 logs redis-master-r69f2 redis-master --namespace=e2e-tests-kubectl-xzsb9'
Mar 26 05:39:27.501: INFO: stderr: ""
Mar 26 05:39:27.502: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 Mar 05:39:26.841 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 Mar 05:39:26.841 # Server started, Redis version 3.2.12\n1:M 26 Mar 05:39:26.841 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 Mar 05:39:26.841 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar 26 05:39:27.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 log redis-master-r69f2 redis-master --namespace=e2e-tests-kubectl-xzsb9 --tail=1'
Mar 26 05:39:27.710: INFO: stderr: ""
Mar 26 05:39:27.710: INFO: stdout: "1:M 26 Mar 05:39:26.841 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar 26 05:39:27.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 log redis-master-r69f2 redis-master --namespace=e2e-tests-kubectl-xzsb9 --limit-bytes=1'
Mar 26 05:39:27.904: INFO: stderr: ""
Mar 26 05:39:27.904: INFO: stdout: " "
STEP: exposing timestamps
Mar 26 05:39:27.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 log redis-master-r69f2 redis-master --namespace=e2e-tests-kubectl-xzsb9 --tail=1 --timestamps'
Mar 26 05:39:28.103: INFO: stderr: ""
Mar 26 05:39:28.103: INFO: stdout: "2019-03-26T05:39:26.84218959Z 1:M 26 Mar 05:39:26.841 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar 26 05:39:30.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 log redis-master-r69f2 redis-master --namespace=e2e-tests-kubectl-xzsb9 --since=1s'
Mar 26 05:39:30.886: INFO: stderr: ""
Mar 26 05:39:30.886: INFO: stdout: ""
Mar 26 05:39:30.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 log redis-master-r69f2 redis-master --namespace=e2e-tests-kubectl-xzsb9 --since=24h'
Mar 26 05:39:31.109: INFO: stderr: ""
Mar 26 05:39:31.109: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 Mar 05:39:26.841 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 Mar 05:39:26.841 # Server started, Redis version 3.2.12\n1:M 26 Mar 05:39:26.841 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 Mar 05:39:26.841 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Mar 26 05:39:31.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xzsb9'
Mar 26 05:39:31.290: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 05:39:31.290: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar 26 05:39:31.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-xzsb9'
Mar 26 05:39:31.576: INFO: stderr: "No resources found.\n"
Mar 26 05:39:31.576: INFO: stdout: ""
Mar 26 05:39:31.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -l name=nginx --namespace=e2e-tests-kubectl-xzsb9 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 26 05:39:31.750: INFO: stderr: ""
Mar 26 05:39:31.750: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:39:31.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xzsb9" for this suite.
Mar 26 05:39:55.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:39:55.958: INFO: namespace: e2e-tests-kubectl-xzsb9, resource: bindings, ignored listing per whitelist
Mar 26 05:39:56.126: INFO: namespace e2e-tests-kubectl-xzsb9 deletion completed in 24.363157068s

• [SLOW TEST:33.622 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:39:56.128: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar 26 05:39:56.435: INFO: Waiting up to 5m0s for pod "var-expansion-96675faf-4f89-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-var-expansion-jffbk" to be "success or failure"
Mar 26 05:39:56.449: INFO: Pod "var-expansion-96675faf-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.34305ms
Mar 26 05:39:58.456: INFO: Pod "var-expansion-96675faf-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019481995s
Mar 26 05:40:00.525: INFO: Pod "var-expansion-96675faf-4f89-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.088402442s
STEP: Saw pod success
Mar 26 05:40:00.525: INFO: Pod "var-expansion-96675faf-4f89-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:40:00.578: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod var-expansion-96675faf-4f89-11e9-8fea-5694fc6fbac7 container dapi-container: <nil>
STEP: delete the pod
Mar 26 05:40:00.706: INFO: Waiting for pod var-expansion-96675faf-4f89-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:40:00.729: INFO: Pod var-expansion-96675faf-4f89-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:40:00.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-jffbk" for this suite.
Mar 26 05:40:06.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:40:06.943: INFO: namespace: e2e-tests-var-expansion-jffbk, resource: bindings, ignored listing per whitelist
Mar 26 05:40:07.108: INFO: namespace e2e-tests-var-expansion-jffbk deletion completed in 6.349653456s

• [SLOW TEST:10.980 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:40:07.110: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 26 05:40:15.668: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 26 05:40:15.682: INFO: Pod pod-with-poststart-http-hook still exists
Mar 26 05:40:17.731: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 26 05:40:17.740: INFO: Pod pod-with-poststart-http-hook still exists
Mar 26 05:40:19.682: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 26 05:40:19.694: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:40:19.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-5kw2r" for this suite.
Mar 26 05:40:43.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:40:44.061: INFO: namespace: e2e-tests-container-lifecycle-hook-5kw2r, resource: bindings, ignored listing per whitelist
Mar 26 05:40:44.061: INFO: namespace e2e-tests-container-lifecycle-hook-5kw2r deletion completed in 24.341698355s

• [SLOW TEST:36.951 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:40:44.063: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-b2efc8e8-4f89-11e9-8fea-5694fc6fbac7
STEP: Creating secret with name s-test-opt-upd-b2efc95b-4f89-11e9-8fea-5694fc6fbac7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b2efc8e8-4f89-11e9-8fea-5694fc6fbac7
STEP: Updating secret s-test-opt-upd-b2efc95b-4f89-11e9-8fea-5694fc6fbac7
STEP: Creating secret with name s-test-opt-create-b2efc97f-4f89-11e9-8fea-5694fc6fbac7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:41:59.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vj8nm" for this suite.
Mar 26 05:42:23.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:42:23.861: INFO: namespace: e2e-tests-projected-vj8nm, resource: bindings, ignored listing per whitelist
Mar 26 05:42:26.578: INFO: namespace e2e-tests-projected-vj8nm deletion completed in 27.436460421s

• [SLOW TEST:102.515 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:42:26.579: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 05:42:27.038: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f02e6474-4f89-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-mr4rl" to be "success or failure"
Mar 26 05:42:27.054: INFO: Pod "downwardapi-volume-f02e6474-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.132286ms
Mar 26 05:42:29.063: INFO: Pod "downwardapi-volume-f02e6474-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024491242s
Mar 26 05:42:31.087: INFO: Pod "downwardapi-volume-f02e6474-4f89-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048659903s
STEP: Saw pod success
Mar 26 05:42:31.087: INFO: Pod "downwardapi-volume-f02e6474-4f89-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:42:31.093: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downwardapi-volume-f02e6474-4f89-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 05:42:31.164: INFO: Waiting for pod downwardapi-volume-f02e6474-4f89-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:42:31.172: INFO: Pod downwardapi-volume-f02e6474-4f89-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:42:31.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mr4rl" for this suite.
Mar 26 05:42:37.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:42:37.464: INFO: namespace: e2e-tests-projected-mr4rl, resource: bindings, ignored listing per whitelist
Mar 26 05:42:37.581: INFO: namespace e2e-tests-projected-mr4rl deletion completed in 6.385428186s

• [SLOW TEST:11.002 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:42:37.582: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar 26 05:42:37.807: INFO: Waiting up to 5m0s for pod "pod-f6975bf8-4f89-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-qvq9k" to be "success or failure"
Mar 26 05:42:37.834: INFO: Pod "pod-f6975bf8-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.078541ms
Mar 26 05:42:39.842: INFO: Pod "pod-f6975bf8-4f89-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016302706s
Mar 26 05:42:41.848: INFO: Pod "pod-f6975bf8-4f89-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022889626s
STEP: Saw pod success
Mar 26 05:42:41.849: INFO: Pod "pod-f6975bf8-4f89-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:42:41.854: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-f6975bf8-4f89-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 05:42:42.008: INFO: Waiting for pod pod-f6975bf8-4f89-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:42:42.019: INFO: Pod pod-f6975bf8-4f89-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:42:42.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qvq9k" for this suite.
Mar 26 05:42:48.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:42:48.323: INFO: namespace: e2e-tests-emptydir-qvq9k, resource: bindings, ignored listing per whitelist
Mar 26 05:42:48.353: INFO: namespace e2e-tests-emptydir-qvq9k deletion completed in 6.320433827s

• [SLOW TEST:10.772 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:42:48.355: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 05:42:48.534: INFO: Creating ReplicaSet my-hostname-basic-fd015d7a-4f89-11e9-8fea-5694fc6fbac7
Mar 26 05:42:48.557: INFO: Pod name my-hostname-basic-fd015d7a-4f89-11e9-8fea-5694fc6fbac7: Found 0 pods out of 1
Mar 26 05:42:53.565: INFO: Pod name my-hostname-basic-fd015d7a-4f89-11e9-8fea-5694fc6fbac7: Found 1 pods out of 1
Mar 26 05:42:53.565: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-fd015d7a-4f89-11e9-8fea-5694fc6fbac7" is running
Mar 26 05:42:53.571: INFO: Pod "my-hostname-basic-fd015d7a-4f89-11e9-8fea-5694fc6fbac7-65r4z" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 05:42:48 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 05:42:52 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 05:42:52 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 05:42:48 +0000 UTC Reason: Message:}])
Mar 26 05:42:53.571: INFO: Trying to dial the pod
Mar 26 05:42:58.598: INFO: Controller my-hostname-basic-fd015d7a-4f89-11e9-8fea-5694fc6fbac7: Got expected result from replica 1 [my-hostname-basic-fd015d7a-4f89-11e9-8fea-5694fc6fbac7-65r4z]: "my-hostname-basic-fd015d7a-4f89-11e9-8fea-5694fc6fbac7-65r4z", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:42:58.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-jlttp" for this suite.
Mar 26 05:43:04.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:43:04.879: INFO: namespace: e2e-tests-replicaset-jlttp, resource: bindings, ignored listing per whitelist
Mar 26 05:43:04.919: INFO: namespace e2e-tests-replicaset-jlttp deletion completed in 6.309077248s

• [SLOW TEST:16.564 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:43:04.921: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0326 05:43:06.348761      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 05:43:06.348: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:43:06.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-tzjx2" for this suite.
Mar 26 05:43:12.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:43:12.569: INFO: namespace: e2e-tests-gc-tzjx2, resource: bindings, ignored listing per whitelist
Mar 26 05:43:12.665: INFO: namespace e2e-tests-gc-tzjx2 deletion completed in 6.306830455s

• [SLOW TEST:7.745 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:43:12.668: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 26 05:43:12.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-7hss7'
Mar 26 05:43:13.085: INFO: stderr: ""
Mar 26 05:43:13.085: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Mar 26 05:43:13.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7hss7'
Mar 26 05:43:15.421: INFO: stderr: ""
Mar 26 05:43:15.422: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:43:15.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7hss7" for this suite.
Mar 26 05:43:21.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:43:21.800: INFO: namespace: e2e-tests-kubectl-7hss7, resource: bindings, ignored listing per whitelist
Mar 26 05:43:21.884: INFO: namespace e2e-tests-kubectl-7hss7 deletion completed in 6.404891762s

• [SLOW TEST:9.217 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:43:21.913: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-nprwd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 26 05:43:22.074: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 26 05:43:48.590: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.42.3.3:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nprwd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 05:43:48.590: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 05:43:48.779: INFO: Found all expected endpoints: [netserver-0]
Mar 26 05:43:48.789: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.42.1.7:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nprwd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 05:43:48.789: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 05:43:48.953: INFO: Found all expected endpoints: [netserver-1]
Mar 26 05:43:48.960: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.42.2.14:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nprwd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 05:43:48.960: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 05:43:49.168: INFO: Found all expected endpoints: [netserver-2]
Mar 26 05:43:49.173: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.42.0.6:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nprwd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 05:43:49.173: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 05:43:49.370: INFO: Found all expected endpoints: [netserver-3]
Mar 26 05:43:49.378: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.42.4.6:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nprwd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 05:43:49.378: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 05:43:49.511: INFO: Found all expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:43:49.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-nprwd" for this suite.
Mar 26 05:44:15.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:44:15.856: INFO: namespace: e2e-tests-pod-network-test-nprwd, resource: bindings, ignored listing per whitelist
Mar 26 05:44:15.887: INFO: namespace e2e-tests-pod-network-test-nprwd deletion completed in 26.36390267s

• [SLOW TEST:53.974 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:44:15.889: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 26 05:44:20.353: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:20.370: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:22.370: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:22.377: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:24.370: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:24.378: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:26.371: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:26.378: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:28.370: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:28.377: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:30.371: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:30.378: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:32.371: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:32.377: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:34.370: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:34.380: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:36.371: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:36.383: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:38.370: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:38.377: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:40.377: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:40.385: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:42.370: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:42.379: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:44.370: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:44.376: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:46.371: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:46.378: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:48.370: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:48.376: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:50.384: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:50.391: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 26 05:44:52.370: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 26 05:44:52.378: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:44:52.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-7d6z9" for this suite.
Mar 26 05:45:16.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:45:16.608: INFO: namespace: e2e-tests-container-lifecycle-hook-7d6z9, resource: bindings, ignored listing per whitelist
Mar 26 05:45:16.718: INFO: namespace e2e-tests-container-lifecycle-hook-7d6z9 deletion completed in 24.328848121s

• [SLOW TEST:60.829 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:45:16.720: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 26 05:45:17.158: INFO: Number of nodes with available pods: 0
Mar 26 05:45:17.158: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:45:18.354: INFO: Number of nodes with available pods: 0
Mar 26 05:45:18.354: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:45:19.188: INFO: Number of nodes with available pods: 0
Mar 26 05:45:19.188: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:45:20.315: INFO: Number of nodes with available pods: 4
Mar 26 05:45:20.316: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:45:21.178: INFO: Number of nodes with available pods: 5
Mar 26 05:45:21.178: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 26 05:45:21.289: INFO: Number of nodes with available pods: 4
Mar 26 05:45:21.289: INFO: Node k8s-conformance-cluster-1-12-worker-1 is running more than one daemon pod
Mar 26 05:45:22.315: INFO: Number of nodes with available pods: 5
Mar 26 05:45:22.315: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-ds7cl, will wait for the garbage collector to delete the pods
Mar 26 05:45:22.401: INFO: Deleting {extensions DaemonSet} daemon-set took: 20.375935ms
Mar 26 05:45:22.601: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.628675ms
Mar 26 05:46:07.506: INFO: Number of nodes with available pods: 0
Mar 26 05:46:07.507: INFO: Number of running nodes: 0, number of available pods: 0
Mar 26 05:46:07.513: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-ds7cl/daemonsets","resourceVersion":"32301"},"items":null}

Mar 26 05:46:07.517: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-ds7cl/pods","resourceVersion":"32301"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:46:07.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-ds7cl" for this suite.
Mar 26 05:46:13.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:46:13.631: INFO: namespace: e2e-tests-daemonsets-ds7cl, resource: bindings, ignored listing per whitelist
Mar 26 05:46:13.832: INFO: namespace e2e-tests-daemonsets-ds7cl deletion completed in 6.27251012s

• [SLOW TEST:57.112 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:46:13.834: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 05:46:14.097: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7785b9e4-4f8a-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-cqpcj" to be "success or failure"
Mar 26 05:46:14.114: INFO: Pod "downwardapi-volume-7785b9e4-4f8a-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 17.045166ms
Mar 26 05:46:16.122: INFO: Pod "downwardapi-volume-7785b9e4-4f8a-11e9-8fea-5694fc6fbac7": Phase="Running", Reason="", readiness=true. Elapsed: 2.025303214s
Mar 26 05:46:18.136: INFO: Pod "downwardapi-volume-7785b9e4-4f8a-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038453752s
STEP: Saw pod success
Mar 26 05:46:18.136: INFO: Pod "downwardapi-volume-7785b9e4-4f8a-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:46:18.144: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downwardapi-volume-7785b9e4-4f8a-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 05:46:18.236: INFO: Waiting for pod downwardapi-volume-7785b9e4-4f8a-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:46:18.243: INFO: Pod downwardapi-volume-7785b9e4-4f8a-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:46:18.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cqpcj" for this suite.
Mar 26 05:46:24.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:46:24.525: INFO: namespace: e2e-tests-projected-cqpcj, resource: bindings, ignored listing per whitelist
Mar 26 05:46:24.591: INFO: namespace e2e-tests-projected-cqpcj deletion completed in 6.328927976s

• [SLOW TEST:10.757 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:46:24.592: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 26 05:46:24.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-qdgwm'
Mar 26 05:46:24.961: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 26 05:46:24.961: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Mar 26 05:46:29.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-qdgwm'
Mar 26 05:46:29.250: INFO: stderr: ""
Mar 26 05:46:29.250: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:46:29.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qdgwm" for this suite.
Mar 26 05:46:35.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:46:35.514: INFO: namespace: e2e-tests-kubectl-qdgwm, resource: bindings, ignored listing per whitelist
Mar 26 05:46:35.658: INFO: namespace e2e-tests-kubectl-qdgwm deletion completed in 6.394951225s

• [SLOW TEST:11.066 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:46:35.679: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-9bbvb
Mar 26 05:46:38.065: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-9bbvb
STEP: checking the pod's current state and verifying that restartCount is present
Mar 26 05:46:38.071: INFO: Initial restart count of pod liveness-exec is 0
Mar 26 05:47:26.563: INFO: Restart count of pod e2e-tests-container-probe-9bbvb/liveness-exec is now 1 (48.492022295s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:47:26.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9bbvb" for this suite.
Mar 26 05:47:33.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:47:33.444: INFO: namespace: e2e-tests-container-probe-9bbvb, resource: bindings, ignored listing per whitelist
Mar 26 05:47:33.475: INFO: namespace e2e-tests-container-probe-9bbvb deletion completed in 6.599720292s

• [SLOW TEST:57.797 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:47:33.477: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-tjr2
STEP: Creating a pod to test atomic-volume-subpath
Mar 26 05:47:33.827: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-tjr2" in namespace "e2e-tests-subpath-xngv5" to be "success or failure"
Mar 26 05:47:33.892: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Pending", Reason="", readiness=false. Elapsed: 65.683765ms
Mar 26 05:47:35.900: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073754836s
Mar 26 05:47:37.907: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Running", Reason="", readiness=false. Elapsed: 4.080865953s
Mar 26 05:47:39.915: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Running", Reason="", readiness=false. Elapsed: 6.088206492s
Mar 26 05:47:41.924: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Running", Reason="", readiness=false. Elapsed: 8.097892758s
Mar 26 05:47:43.933: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Running", Reason="", readiness=false. Elapsed: 10.106904244s
Mar 26 05:47:45.940: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Running", Reason="", readiness=false. Elapsed: 12.113141161s
Mar 26 05:47:47.946: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Running", Reason="", readiness=false. Elapsed: 14.119589681s
Mar 26 05:47:49.959: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Running", Reason="", readiness=false. Elapsed: 16.132836489s
Mar 26 05:47:51.975: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Running", Reason="", readiness=false. Elapsed: 18.148334896s
Mar 26 05:47:53.981: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Running", Reason="", readiness=false. Elapsed: 20.154894167s
Mar 26 05:47:55.988: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Running", Reason="", readiness=false. Elapsed: 22.161533111s
Mar 26 05:47:57.996: INFO: Pod "pod-subpath-test-secret-tjr2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.169363413s
STEP: Saw pod success
Mar 26 05:47:57.996: INFO: Pod "pod-subpath-test-secret-tjr2" satisfied condition "success or failure"
Mar 26 05:47:58.009: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-subpath-test-secret-tjr2 container test-container-subpath-secret-tjr2: <nil>
STEP: delete the pod
Mar 26 05:47:58.146: INFO: Waiting for pod pod-subpath-test-secret-tjr2 to disappear
Mar 26 05:47:58.195: INFO: Pod pod-subpath-test-secret-tjr2 no longer exists
STEP: Deleting pod pod-subpath-test-secret-tjr2
Mar 26 05:47:58.196: INFO: Deleting pod "pod-subpath-test-secret-tjr2" in namespace "e2e-tests-subpath-xngv5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:47:58.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xngv5" for this suite.
Mar 26 05:48:04.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:48:04.424: INFO: namespace: e2e-tests-subpath-xngv5, resource: bindings, ignored listing per whitelist
Mar 26 05:48:04.594: INFO: namespace e2e-tests-subpath-xngv5 deletion completed in 6.374803417s

• [SLOW TEST:31.117 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:48:04.596: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4hk7h
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-4hk7h
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-4hk7h
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-4hk7h
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-4hk7h
Mar 26 05:48:09.171: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4hk7h, name: ss-0, uid: bbc85545-4f8a-11e9-b22a-90b8d090d774, status phase: Failed. Waiting for statefulset controller to delete.
Mar 26 05:48:09.194: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4hk7h, name: ss-0, uid: bbc85545-4f8a-11e9-b22a-90b8d090d774, status phase: Failed. Waiting for statefulset controller to delete.
Mar 26 05:48:09.215: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-4hk7h
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-4hk7h
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-4hk7h and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 26 05:48:13.359: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4hk7h
Mar 26 05:48:13.364: INFO: Scaling statefulset ss to 0
Mar 26 05:48:23.426: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 05:48:23.432: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:48:23.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4hk7h" for this suite.
Mar 26 05:48:31.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:48:31.647: INFO: namespace: e2e-tests-statefulset-4hk7h, resource: bindings, ignored listing per whitelist
Mar 26 05:48:31.795: INFO: namespace e2e-tests-statefulset-4hk7h deletion completed in 8.311956847s

• [SLOW TEST:27.199 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:48:31.799: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar 26 05:48:32.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:48:32.563: INFO: stderr: ""
Mar 26 05:48:32.563: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 26 05:48:32.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:48:32.773: INFO: stderr: ""
Mar 26 05:48:32.773: INFO: stdout: "update-demo-nautilus-gtdt8 update-demo-nautilus-pbtd9 "
Mar 26 05:48:32.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-gtdt8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:48:32.966: INFO: stderr: ""
Mar 26 05:48:32.966: INFO: stdout: ""
Mar 26 05:48:32.966: INFO: update-demo-nautilus-gtdt8 is created but not running
Mar 26 05:48:37.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:48:38.130: INFO: stderr: ""
Mar 26 05:48:38.130: INFO: stdout: "update-demo-nautilus-gtdt8 update-demo-nautilus-pbtd9 "
Mar 26 05:48:38.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-gtdt8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:48:38.301: INFO: stderr: ""
Mar 26 05:48:38.301: INFO: stdout: "true"
Mar 26 05:48:38.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-gtdt8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:48:38.490: INFO: stderr: ""
Mar 26 05:48:38.490: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 05:48:38.490: INFO: validating pod update-demo-nautilus-gtdt8
Mar 26 05:48:38.505: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 05:48:38.505: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 05:48:38.505: INFO: update-demo-nautilus-gtdt8 is verified up and running
Mar 26 05:48:38.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-pbtd9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:48:38.709: INFO: stderr: ""
Mar 26 05:48:38.709: INFO: stdout: "true"
Mar 26 05:48:38.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-pbtd9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:48:39.032: INFO: stderr: ""
Mar 26 05:48:39.032: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 05:48:39.032: INFO: validating pod update-demo-nautilus-pbtd9
Mar 26 05:48:39.045: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 05:48:39.045: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 05:48:39.045: INFO: update-demo-nautilus-pbtd9 is verified up and running
STEP: rolling-update to new replication controller
Mar 26 05:48:39.047: INFO: scanned /root for discovery docs: <nil>
Mar 26 05:48:39.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:49:02.108: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 26 05:49:02.109: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 26 05:49:02.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:49:02.550: INFO: stderr: ""
Mar 26 05:49:02.550: INFO: stdout: "update-demo-kitten-kmbkg update-demo-kitten-s6gnd "
Mar 26 05:49:02.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-kitten-kmbkg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:49:02.908: INFO: stderr: ""
Mar 26 05:49:02.908: INFO: stdout: "true"
Mar 26 05:49:02.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-kitten-kmbkg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:49:03.307: INFO: stderr: ""
Mar 26 05:49:03.307: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 26 05:49:03.307: INFO: validating pod update-demo-kitten-kmbkg
Mar 26 05:49:03.326: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 26 05:49:03.326: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 26 05:49:03.326: INFO: update-demo-kitten-kmbkg is verified up and running
Mar 26 05:49:03.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-kitten-s6gnd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:49:03.696: INFO: stderr: ""
Mar 26 05:49:03.696: INFO: stdout: "true"
Mar 26 05:49:03.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-kitten-s6gnd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hx6db'
Mar 26 05:49:04.049: INFO: stderr: ""
Mar 26 05:49:04.049: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 26 05:49:04.049: INFO: validating pod update-demo-kitten-s6gnd
Mar 26 05:49:04.063: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 26 05:49:04.063: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 26 05:49:04.063: INFO: update-demo-kitten-s6gnd is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:49:04.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hx6db" for this suite.
Mar 26 05:49:28.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:49:28.322: INFO: namespace: e2e-tests-kubectl-hx6db, resource: bindings, ignored listing per whitelist
Mar 26 05:49:28.348: INFO: namespace e2e-tests-kubectl-hx6db deletion completed in 24.272799149s

• [SLOW TEST:56.550 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:49:28.350: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-eb788dbe-4f8a-11e9-8fea-5694fc6fbac7
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-eb788dbe-4f8a-11e9-8fea-5694fc6fbac7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:49:32.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7mmzf" for this suite.
Mar 26 05:49:54.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:49:55.080: INFO: namespace: e2e-tests-configmap-7mmzf, resource: bindings, ignored listing per whitelist
Mar 26 05:49:55.157: INFO: namespace e2e-tests-configmap-7mmzf deletion completed in 22.392022977s

• [SLOW TEST:26.807 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:49:55.160: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-fb6be9b3-4f8a-11e9-8fea-5694fc6fbac7
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-fb6be9b3-4f8a-11e9-8fea-5694fc6fbac7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:49:59.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hd8rg" for this suite.
Mar 26 05:50:23.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:50:23.667: INFO: namespace: e2e-tests-projected-hd8rg, resource: bindings, ignored listing per whitelist
Mar 26 05:50:23.818: INFO: namespace e2e-tests-projected-hd8rg deletion completed in 24.296230619s

• [SLOW TEST:28.658 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:50:23.820: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0326 05:51:04.096947      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 05:51:04.097: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:51:04.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-28ctc" for this suite.
Mar 26 05:51:14.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:51:14.185: INFO: namespace: e2e-tests-gc-28ctc, resource: bindings, ignored listing per whitelist
Mar 26 05:51:14.428: INFO: namespace e2e-tests-gc-28ctc deletion completed in 10.318180814s

• [SLOW TEST:50.609 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:51:14.431: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-2aa8c1c7-4f8b-11e9-8fea-5694fc6fbac7
Mar 26 05:51:14.660: INFO: Pod name my-hostname-basic-2aa8c1c7-4f8b-11e9-8fea-5694fc6fbac7: Found 0 pods out of 1
Mar 26 05:51:19.672: INFO: Pod name my-hostname-basic-2aa8c1c7-4f8b-11e9-8fea-5694fc6fbac7: Found 1 pods out of 1
Mar 26 05:51:19.672: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-2aa8c1c7-4f8b-11e9-8fea-5694fc6fbac7" are running
Mar 26 05:51:19.680: INFO: Pod "my-hostname-basic-2aa8c1c7-4f8b-11e9-8fea-5694fc6fbac7-2qcwc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 05:51:14 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 05:51:16 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 05:51:16 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-26 05:51:14 +0000 UTC Reason: Message:}])
Mar 26 05:51:19.681: INFO: Trying to dial the pod
Mar 26 05:51:24.702: INFO: Controller my-hostname-basic-2aa8c1c7-4f8b-11e9-8fea-5694fc6fbac7: Got expected result from replica 1 [my-hostname-basic-2aa8c1c7-4f8b-11e9-8fea-5694fc6fbac7-2qcwc]: "my-hostname-basic-2aa8c1c7-4f8b-11e9-8fea-5694fc6fbac7-2qcwc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:51:24.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-kxs5m" for this suite.
Mar 26 05:51:30.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:51:31.173: INFO: namespace: e2e-tests-replication-controller-kxs5m, resource: bindings, ignored listing per whitelist
Mar 26 05:51:31.223: INFO: namespace e2e-tests-replication-controller-kxs5m deletion completed in 6.509020869s

• [SLOW TEST:16.793 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:51:31.225: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 26 05:51:31.483: INFO: Waiting up to 5m0s for pod "pod-34b0c896-4f8b-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-ntt2r" to be "success or failure"
Mar 26 05:51:31.516: INFO: Pod "pod-34b0c896-4f8b-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 32.792057ms
Mar 26 05:51:33.523: INFO: Pod "pod-34b0c896-4f8b-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040425972s
Mar 26 05:51:35.531: INFO: Pod "pod-34b0c896-4f8b-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048146387s
STEP: Saw pod success
Mar 26 05:51:35.531: INFO: Pod "pod-34b0c896-4f8b-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:51:35.536: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-34b0c896-4f8b-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 05:51:35.677: INFO: Waiting for pod pod-34b0c896-4f8b-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:51:35.708: INFO: Pod pod-34b0c896-4f8b-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:51:35.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ntt2r" for this suite.
Mar 26 05:51:41.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:51:41.942: INFO: namespace: e2e-tests-emptydir-ntt2r, resource: bindings, ignored listing per whitelist
Mar 26 05:51:41.996: INFO: namespace e2e-tests-emptydir-ntt2r deletion completed in 6.273050269s

• [SLOW TEST:10.772 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:51:42.002: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 26 05:51:42.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-wwq88'
Mar 26 05:51:42.975: INFO: stderr: ""
Mar 26 05:51:42.975: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 26 05:51:42.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wwq88'
Mar 26 05:51:43.170: INFO: stderr: ""
Mar 26 05:51:43.171: INFO: stdout: "update-demo-nautilus-7c874 update-demo-nautilus-k55vh "
Mar 26 05:51:43.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-7c874 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wwq88'
Mar 26 05:51:43.403: INFO: stderr: ""
Mar 26 05:51:43.403: INFO: stdout: ""
Mar 26 05:51:43.403: INFO: update-demo-nautilus-7c874 is created but not running
Mar 26 05:51:48.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wwq88'
Mar 26 05:51:48.600: INFO: stderr: ""
Mar 26 05:51:48.600: INFO: stdout: "update-demo-nautilus-7c874 update-demo-nautilus-k55vh "
Mar 26 05:51:48.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-7c874 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wwq88'
Mar 26 05:51:48.755: INFO: stderr: ""
Mar 26 05:51:48.755: INFO: stdout: "true"
Mar 26 05:51:48.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-7c874 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wwq88'
Mar 26 05:51:48.919: INFO: stderr: ""
Mar 26 05:51:48.919: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 05:51:48.919: INFO: validating pod update-demo-nautilus-7c874
Mar 26 05:51:48.926: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 05:51:48.926: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 05:51:48.926: INFO: update-demo-nautilus-7c874 is verified up and running
Mar 26 05:51:48.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-k55vh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wwq88'
Mar 26 05:51:49.096: INFO: stderr: ""
Mar 26 05:51:49.096: INFO: stdout: "true"
Mar 26 05:51:49.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-k55vh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wwq88'
Mar 26 05:51:49.257: INFO: stderr: ""
Mar 26 05:51:49.257: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 05:51:49.257: INFO: validating pod update-demo-nautilus-k55vh
Mar 26 05:51:49.266: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 05:51:49.266: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 05:51:49.266: INFO: update-demo-nautilus-k55vh is verified up and running
STEP: using delete to clean up resources
Mar 26 05:51:49.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wwq88'
Mar 26 05:51:49.458: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 05:51:49.458: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 26 05:51:49.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-wwq88'
Mar 26 05:51:49.665: INFO: stderr: "No resources found.\n"
Mar 26 05:51:49.665: INFO: stdout: ""
Mar 26 05:51:49.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -l name=update-demo --namespace=e2e-tests-kubectl-wwq88 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 26 05:51:49.832: INFO: stderr: ""
Mar 26 05:51:49.832: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:51:49.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wwq88" for this suite.
Mar 26 05:51:55.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:51:56.153: INFO: namespace: e2e-tests-kubectl-wwq88, resource: bindings, ignored listing per whitelist
Mar 26 05:51:56.221: INFO: namespace e2e-tests-kubectl-wwq88 deletion completed in 6.379540854s

• [SLOW TEST:14.220 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:51:56.226: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 26 05:51:56.459: INFO: Waiting up to 5m0s for pod "pod-43962201-4f8b-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-hpx58" to be "success or failure"
Mar 26 05:51:56.471: INFO: Pod "pod-43962201-4f8b-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 11.403356ms
Mar 26 05:51:58.482: INFO: Pod "pod-43962201-4f8b-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022532791s
STEP: Saw pod success
Mar 26 05:51:58.482: INFO: Pod "pod-43962201-4f8b-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:51:58.488: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-43962201-4f8b-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 05:51:58.596: INFO: Waiting for pod pod-43962201-4f8b-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:51:58.616: INFO: Pod pod-43962201-4f8b-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:51:58.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hpx58" for this suite.
Mar 26 05:52:04.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:52:04.937: INFO: namespace: e2e-tests-emptydir-hpx58, resource: bindings, ignored listing per whitelist
Mar 26 05:52:04.972: INFO: namespace e2e-tests-emptydir-hpx58 deletion completed in 6.318858317s

• [SLOW TEST:8.747 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:52:04.974: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 26 05:52:05.168: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-a,UID:48c76b8d-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33901,Generation:0,CreationTimestamp:2019-03-26 05:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 26 05:52:05.168: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-a,UID:48c76b8d-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33901,Generation:0,CreationTimestamp:2019-03-26 05:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar 26 05:52:15.186: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-a,UID:48c76b8d-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33919,Generation:0,CreationTimestamp:2019-03-26 05:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 26 05:52:15.186: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-a,UID:48c76b8d-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33919,Generation:0,CreationTimestamp:2019-03-26 05:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 26 05:52:25.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-a,UID:48c76b8d-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33938,Generation:0,CreationTimestamp:2019-03-26 05:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 26 05:52:25.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-a,UID:48c76b8d-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33938,Generation:0,CreationTimestamp:2019-03-26 05:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar 26 05:52:35.385: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-a,UID:48c76b8d-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33956,Generation:0,CreationTimestamp:2019-03-26 05:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 26 05:52:35.386: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-a,UID:48c76b8d-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33956,Generation:0,CreationTimestamp:2019-03-26 05:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 26 05:52:45.407: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-b,UID:60c1d099-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33973,Generation:0,CreationTimestamp:2019-03-26 05:52:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 26 05:52:45.407: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-b,UID:60c1d099-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33973,Generation:0,CreationTimestamp:2019-03-26 05:52:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar 26 05:52:55.428: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-b,UID:60c1d099-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33991,Generation:0,CreationTimestamp:2019-03-26 05:52:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 26 05:52:55.429: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qkbgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-qkbgl/configmaps/e2e-watch-test-configmap-b,UID:60c1d099-4f8b-11e9-b22a-90b8d090d774,ResourceVersion:33991,Generation:0,CreationTimestamp:2019-03-26 05:52:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:53:05.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qkbgl" for this suite.
Mar 26 05:53:11.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:53:11.691: INFO: namespace: e2e-tests-watch-qkbgl, resource: bindings, ignored listing per whitelist
Mar 26 05:53:11.789: INFO: namespace e2e-tests-watch-qkbgl deletion completed in 6.342473786s

• [SLOW TEST:66.815 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:53:11.790: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-vkpjx A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-vkpjx;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-vkpjx A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-vkpjx;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-vkpjx.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-vkpjx.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-vkpjx.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-vkpjx.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-vkpjx.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-vkpjx.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-vkpjx.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-vkpjx.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-vkpjx.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-vkpjx.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-vkpjx.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-vkpjx.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-vkpjx.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 34.123.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.123.34_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 34.123.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.123.34_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-vkpjx A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-vkpjx;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-vkpjx A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-vkpjx;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-vkpjx.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-vkpjx.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-vkpjx.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-vkpjx.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-vkpjx.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-vkpjx.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-vkpjx.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-vkpjx.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-vkpjx.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-vkpjx.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-vkpjx.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-vkpjx.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-vkpjx.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 34.123.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.123.34_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 34.123.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.123.34_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 26 05:53:42.727: INFO: DNS probes using e2e-tests-dns-vkpjx/dns-test-70bb760c-4f8b-11e9-8fea-5694fc6fbac7 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:53:43.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-vkpjx" for this suite.
Mar 26 05:53:49.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:53:49.131: INFO: namespace: e2e-tests-dns-vkpjx, resource: bindings, ignored listing per whitelist
Mar 26 05:53:49.301: INFO: namespace e2e-tests-dns-vkpjx deletion completed in 6.272752876s

• [SLOW TEST:37.510 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:53:49.301: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-86f8a92c-4f8b-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 05:53:49.526: INFO: Waiting up to 5m0s for pod "pod-configmaps-86fa4d69-4f8b-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-configmap-fdpqw" to be "success or failure"
Mar 26 05:53:49.575: INFO: Pod "pod-configmaps-86fa4d69-4f8b-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 48.497215ms
Mar 26 05:53:51.597: INFO: Pod "pod-configmaps-86fa4d69-4f8b-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.070373612s
STEP: Saw pod success
Mar 26 05:53:51.597: INFO: Pod "pod-configmaps-86fa4d69-4f8b-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:53:51.610: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-configmaps-86fa4d69-4f8b-11e9-8fea-5694fc6fbac7 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 05:53:51.688: INFO: Waiting for pod pod-configmaps-86fa4d69-4f8b-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:53:51.695: INFO: Pod pod-configmaps-86fa4d69-4f8b-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:53:51.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fdpqw" for this suite.
Mar 26 05:53:57.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:53:57.920: INFO: namespace: e2e-tests-configmap-fdpqw, resource: bindings, ignored listing per whitelist
Mar 26 05:53:57.981: INFO: namespace e2e-tests-configmap-fdpqw deletion completed in 6.273061543s

• [SLOW TEST:8.681 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:53:57.984: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-6sjnk.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-6sjnk.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-6sjnk.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-6sjnk.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-6sjnk.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-6sjnk.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 26 05:54:44.438: INFO: DNS probes using e2e-tests-dns-6sjnk/dns-test-8c2457ef-4f8b-11e9-8fea-5694fc6fbac7 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:54:44.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-6sjnk" for this suite.
Mar 26 05:54:50.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:54:50.845: INFO: namespace: e2e-tests-dns-6sjnk, resource: bindings, ignored listing per whitelist
Mar 26 05:54:50.950: INFO: namespace e2e-tests-dns-6sjnk deletion completed in 6.326729651s

• [SLOW TEST:52.967 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:54:50.952: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 05:54:51.187: INFO: Waiting up to 5m0s for pod "downwardapi-volume-abb93416-4f8b-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-gpk42" to be "success or failure"
Mar 26 05:54:51.236: INFO: Pod "downwardapi-volume-abb93416-4f8b-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 48.504343ms
Mar 26 05:54:53.249: INFO: Pod "downwardapi-volume-abb93416-4f8b-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.060801447s
STEP: Saw pod success
Mar 26 05:54:53.249: INFO: Pod "downwardapi-volume-abb93416-4f8b-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:54:53.270: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downwardapi-volume-abb93416-4f8b-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 05:54:53.357: INFO: Waiting for pod downwardapi-volume-abb93416-4f8b-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:54:53.406: INFO: Pod downwardapi-volume-abb93416-4f8b-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:54:53.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gpk42" for this suite.
Mar 26 05:54:59.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:54:59.657: INFO: namespace: e2e-tests-projected-gpk42, resource: bindings, ignored listing per whitelist
Mar 26 05:54:59.665: INFO: namespace e2e-tests-projected-gpk42 deletion completed in 6.235994568s

• [SLOW TEST:8.713 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:54:59.671: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-sfp4z
Mar 26 05:55:03.927: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-sfp4z
STEP: checking the pod's current state and verifying that restartCount is present
Mar 26 05:55:03.931: INFO: Initial restart count of pod liveness-http is 0
Mar 26 05:55:15.983: INFO: Restart count of pod e2e-tests-container-probe-sfp4z/liveness-http is now 1 (12.051651669s elapsed)
Mar 26 05:55:36.090: INFO: Restart count of pod e2e-tests-container-probe-sfp4z/liveness-http is now 2 (32.158820495s elapsed)
Mar 26 05:55:56.169: INFO: Restart count of pod e2e-tests-container-probe-sfp4z/liveness-http is now 3 (52.237594249s elapsed)
Mar 26 05:56:40.385: INFO: Restart count of pod e2e-tests-container-probe-sfp4z/liveness-http is now 4 (1m36.453401483s elapsed)
Mar 26 05:56:56.453: INFO: Restart count of pod e2e-tests-container-probe-sfp4z/liveness-http is now 5 (1m52.521548567s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:56:56.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-sfp4z" for this suite.
Mar 26 05:57:02.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:57:02.864: INFO: namespace: e2e-tests-container-probe-sfp4z, resource: bindings, ignored listing per whitelist
Mar 26 05:57:02.925: INFO: namespace e2e-tests-container-probe-sfp4z deletion completed in 6.382270824s

• [SLOW TEST:123.255 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:57:02.927: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar 26 05:57:03.810: INFO: created pod pod-service-account-defaultsa
Mar 26 05:57:03.811: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 26 05:57:03.835: INFO: created pod pod-service-account-mountsa
Mar 26 05:57:03.835: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 26 05:57:03.853: INFO: created pod pod-service-account-nomountsa
Mar 26 05:57:03.853: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 26 05:57:03.937: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 26 05:57:03.938: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 26 05:57:03.994: INFO: created pod pod-service-account-mountsa-mountspec
Mar 26 05:57:03.994: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 26 05:57:04.074: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 26 05:57:04.074: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 26 05:57:04.133: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 26 05:57:04.133: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 26 05:57:04.210: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 26 05:57:04.210: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 26 05:57:04.347: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 26 05:57:04.347: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:57:04.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-74z4f" for this suite.
Mar 26 05:57:13.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:57:13.205: INFO: namespace: e2e-tests-svcaccounts-74z4f, resource: bindings, ignored listing per whitelist
Mar 26 05:57:13.411: INFO: namespace e2e-tests-svcaccounts-74z4f deletion completed in 8.794905516s

• [SLOW TEST:10.485 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:57:13.412: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 05:57:13.635: INFO: (0) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 9.667422ms)
Mar 26 05:57:13.642: INFO: (1) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.44457ms)
Mar 26 05:57:13.649: INFO: (2) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.723581ms)
Mar 26 05:57:13.656: INFO: (3) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.30724ms)
Mar 26 05:57:13.665: INFO: (4) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.259228ms)
Mar 26 05:57:13.671: INFO: (5) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.002282ms)
Mar 26 05:57:13.677: INFO: (6) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.186452ms)
Mar 26 05:57:13.686: INFO: (7) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.397847ms)
Mar 26 05:57:13.694: INFO: (8) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.005193ms)
Mar 26 05:57:13.702: INFO: (9) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.181095ms)
Mar 26 05:57:13.709: INFO: (10) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.012716ms)
Mar 26 05:57:13.716: INFO: (11) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.653722ms)
Mar 26 05:57:13.722: INFO: (12) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.297985ms)
Mar 26 05:57:13.730: INFO: (13) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.00269ms)
Mar 26 05:57:13.736: INFO: (14) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.632532ms)
Mar 26 05:57:13.745: INFO: (15) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 9.052018ms)
Mar 26 05:57:13.752: INFO: (16) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.381099ms)
Mar 26 05:57:13.759: INFO: (17) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.978037ms)
Mar 26 05:57:13.766: INFO: (18) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.305489ms)
Mar 26 05:57:13.774: INFO: (19) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.392409ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:57:13.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-gfb82" for this suite.
Mar 26 05:57:19.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:57:19.898: INFO: namespace: e2e-tests-proxy-gfb82, resource: bindings, ignored listing per whitelist
Mar 26 05:57:20.044: INFO: namespace e2e-tests-proxy-gfb82 deletion completed in 6.260573022s

• [SLOW TEST:6.633 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:57:20.046: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 26 05:57:25.249: INFO: Successfully updated pod "pod-update-04977056-4f8c-11e9-8fea-5694fc6fbac7"
STEP: verifying the updated pod is in kubernetes
Mar 26 05:57:25.452: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:57:25.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rvtfc" for this suite.
Mar 26 05:57:49.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:57:49.944: INFO: namespace: e2e-tests-pods-rvtfc, resource: bindings, ignored listing per whitelist
Mar 26 05:57:50.028: INFO: namespace e2e-tests-pods-rvtfc deletion completed in 24.470822634s

• [SLOW TEST:29.983 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:57:50.031: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 05:57:50.263: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1676f3ab-4f8c-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-jqtsb" to be "success or failure"
Mar 26 05:57:50.288: INFO: Pod "downwardapi-volume-1676f3ab-4f8c-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.913218ms
Mar 26 05:57:52.295: INFO: Pod "downwardapi-volume-1676f3ab-4f8c-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032146885s
STEP: Saw pod success
Mar 26 05:57:52.295: INFO: Pod "downwardapi-volume-1676f3ab-4f8c-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:57:52.300: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downwardapi-volume-1676f3ab-4f8c-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 05:57:52.372: INFO: Waiting for pod downwardapi-volume-1676f3ab-4f8c-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:57:52.382: INFO: Pod downwardapi-volume-1676f3ab-4f8c-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:57:52.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jqtsb" for this suite.
Mar 26 05:57:58.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:57:58.783: INFO: namespace: e2e-tests-downward-api-jqtsb, resource: bindings, ignored listing per whitelist
Mar 26 05:57:58.889: INFO: namespace e2e-tests-downward-api-jqtsb deletion completed in 6.476734068s

• [SLOW TEST:8.858 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:57:58.890: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 05:57:59.138: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1bbf7454-4f8c-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-lhfc7" to be "success or failure"
Mar 26 05:57:59.151: INFO: Pod "downwardapi-volume-1bbf7454-4f8c-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.083728ms
Mar 26 05:58:01.159: INFO: Pod "downwardapi-volume-1bbf7454-4f8c-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021681484s
Mar 26 05:58:03.169: INFO: Pod "downwardapi-volume-1bbf7454-4f8c-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031364746s
STEP: Saw pod success
Mar 26 05:58:03.169: INFO: Pod "downwardapi-volume-1bbf7454-4f8c-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:58:03.189: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod downwardapi-volume-1bbf7454-4f8c-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 05:58:03.424: INFO: Waiting for pod downwardapi-volume-1bbf7454-4f8c-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:58:03.470: INFO: Pod downwardapi-volume-1bbf7454-4f8c-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:58:03.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lhfc7" for this suite.
Mar 26 05:58:09.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:58:09.691: INFO: namespace: e2e-tests-downward-api-lhfc7, resource: bindings, ignored listing per whitelist
Mar 26 05:58:09.766: INFO: namespace e2e-tests-downward-api-lhfc7 deletion completed in 6.28065144s

• [SLOW TEST:10.876 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:58:09.768: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-vz2mf/configmap-test-22444bd0-4f8c-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 05:58:10.089: INFO: Waiting up to 5m0s for pod "pod-configmaps-22468f24-4f8c-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-configmap-vz2mf" to be "success or failure"
Mar 26 05:58:10.139: INFO: Pod "pod-configmaps-22468f24-4f8c-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 49.189979ms
Mar 26 05:58:12.146: INFO: Pod "pod-configmaps-22468f24-4f8c-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.056123213s
STEP: Saw pod success
Mar 26 05:58:12.146: INFO: Pod "pod-configmaps-22468f24-4f8c-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 05:58:12.152: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-configmaps-22468f24-4f8c-11e9-8fea-5694fc6fbac7 container env-test: <nil>
STEP: delete the pod
Mar 26 05:58:12.213: INFO: Waiting for pod pod-configmaps-22468f24-4f8c-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 05:58:12.220: INFO: Pod pod-configmaps-22468f24-4f8c-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:58:12.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vz2mf" for this suite.
Mar 26 05:58:18.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:58:18.346: INFO: namespace: e2e-tests-configmap-vz2mf, resource: bindings, ignored listing per whitelist
Mar 26 05:58:18.537: INFO: namespace e2e-tests-configmap-vz2mf deletion completed in 6.303438597s

• [SLOW TEST:8.769 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:58:18.539: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-xd79f
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 26 05:58:18.735: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 26 05:58:41.275: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.28:8080/dial?request=hostName&protocol=http&host=10.42.3.9&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xd79f PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 05:58:41.276: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 05:58:41.426: INFO: Waiting for endpoints: map[]
Mar 26 05:58:41.435: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.28:8080/dial?request=hostName&protocol=http&host=10.42.2.21&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xd79f PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 05:58:41.436: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 05:58:41.593: INFO: Waiting for endpoints: map[]
Mar 26 05:58:41.599: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.28:8080/dial?request=hostName&protocol=http&host=10.42.0.27&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xd79f PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 05:58:41.600: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 05:58:41.762: INFO: Waiting for endpoints: map[]
Mar 26 05:58:41.767: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.28:8080/dial?request=hostName&protocol=http&host=10.42.1.28&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xd79f PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 05:58:41.768: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 05:58:41.992: INFO: Waiting for endpoints: map[]
Mar 26 05:58:42.000: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.28:8080/dial?request=hostName&protocol=http&host=10.42.4.12&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xd79f PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 05:58:42.000: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 05:58:42.161: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 05:58:42.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-xd79f" for this suite.
Mar 26 05:59:06.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 05:59:06.257: INFO: namespace: e2e-tests-pod-network-test-xd79f, resource: bindings, ignored listing per whitelist
Mar 26 05:59:06.458: INFO: namespace e2e-tests-pod-network-test-xd79f deletion completed in 24.282134657s

• [SLOW TEST:47.920 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 05:59:06.462: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 05:59:06.754: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar 26 05:59:06.774: INFO: Number of nodes with available pods: 0
Mar 26 05:59:06.774: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar 26 05:59:06.876: INFO: Number of nodes with available pods: 0
Mar 26 05:59:06.876: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:07.882: INFO: Number of nodes with available pods: 0
Mar 26 05:59:07.882: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:08.882: INFO: Number of nodes with available pods: 1
Mar 26 05:59:08.882: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar 26 05:59:08.978: INFO: Number of nodes with available pods: 1
Mar 26 05:59:08.979: INFO: Number of running nodes: 0, number of available pods: 1
Mar 26 05:59:09.988: INFO: Number of nodes with available pods: 0
Mar 26 05:59:09.988: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 26 05:59:10.026: INFO: Number of nodes with available pods: 0
Mar 26 05:59:10.027: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:11.034: INFO: Number of nodes with available pods: 0
Mar 26 05:59:11.034: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:12.035: INFO: Number of nodes with available pods: 0
Mar 26 05:59:12.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:13.034: INFO: Number of nodes with available pods: 0
Mar 26 05:59:13.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:14.053: INFO: Number of nodes with available pods: 0
Mar 26 05:59:14.053: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:15.036: INFO: Number of nodes with available pods: 0
Mar 26 05:59:15.037: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:16.035: INFO: Number of nodes with available pods: 0
Mar 26 05:59:16.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:17.035: INFO: Number of nodes with available pods: 0
Mar 26 05:59:17.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:18.036: INFO: Number of nodes with available pods: 0
Mar 26 05:59:18.036: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:19.034: INFO: Number of nodes with available pods: 0
Mar 26 05:59:19.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:20.036: INFO: Number of nodes with available pods: 0
Mar 26 05:59:20.037: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:21.040: INFO: Number of nodes with available pods: 0
Mar 26 05:59:21.041: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:22.035: INFO: Number of nodes with available pods: 0
Mar 26 05:59:22.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:23.035: INFO: Number of nodes with available pods: 0
Mar 26 05:59:23.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:24.040: INFO: Number of nodes with available pods: 0
Mar 26 05:59:24.041: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:25.037: INFO: Number of nodes with available pods: 0
Mar 26 05:59:25.037: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:26.072: INFO: Number of nodes with available pods: 0
Mar 26 05:59:26.073: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:27.033: INFO: Number of nodes with available pods: 0
Mar 26 05:59:27.034: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:28.035: INFO: Number of nodes with available pods: 0
Mar 26 05:59:28.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:29.036: INFO: Number of nodes with available pods: 0
Mar 26 05:59:29.036: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:30.082: INFO: Number of nodes with available pods: 0
Mar 26 05:59:30.082: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:31.035: INFO: Number of nodes with available pods: 0
Mar 26 05:59:31.036: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:32.042: INFO: Number of nodes with available pods: 0
Mar 26 05:59:32.043: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:33.033: INFO: Number of nodes with available pods: 0
Mar 26 05:59:33.034: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:34.036: INFO: Number of nodes with available pods: 0
Mar 26 05:59:34.036: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:35.034: INFO: Number of nodes with available pods: 0
Mar 26 05:59:35.034: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:36.035: INFO: Number of nodes with available pods: 0
Mar 26 05:59:36.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:37.035: INFO: Number of nodes with available pods: 0
Mar 26 05:59:37.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:38.034: INFO: Number of nodes with available pods: 0
Mar 26 05:59:38.034: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:39.035: INFO: Number of nodes with available pods: 0
Mar 26 05:59:39.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:40.076: INFO: Number of nodes with available pods: 0
Mar 26 05:59:40.076: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:41.033: INFO: Number of nodes with available pods: 0
Mar 26 05:59:41.034: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:42.033: INFO: Number of nodes with available pods: 0
Mar 26 05:59:42.034: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:43.034: INFO: Number of nodes with available pods: 0
Mar 26 05:59:43.035: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:44.114: INFO: Number of nodes with available pods: 0
Mar 26 05:59:44.115: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:45.037: INFO: Number of nodes with available pods: 0
Mar 26 05:59:45.038: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 05:59:46.034: INFO: Number of nodes with available pods: 1
Mar 26 05:59:46.035: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-6rnqz, will wait for the garbage collector to delete the pods
Mar 26 05:59:46.141: INFO: Deleting {extensions DaemonSet} daemon-set took: 34.723835ms
Mar 26 05:59:46.242: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.496304ms
Mar 26 06:00:19.261: INFO: Number of nodes with available pods: 0
Mar 26 06:00:19.262: INFO: Number of running nodes: 0, number of available pods: 0
Mar 26 06:00:19.267: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-6rnqz/daemonsets","resourceVersion":"35422"},"items":null}

Mar 26 06:00:19.275: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-6rnqz/pods","resourceVersion":"35422"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:00:19.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-6rnqz" for this suite.
Mar 26 06:00:25.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:00:25.537: INFO: namespace: e2e-tests-daemonsets-6rnqz, resource: bindings, ignored listing per whitelist
Mar 26 06:00:25.631: INFO: namespace e2e-tests-daemonsets-6rnqz deletion completed in 6.250323519s

• [SLOW TEST:79.170 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:00:25.639: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 26 06:00:25.888: INFO: Waiting up to 5m0s for pod "pod-73386baf-4f8c-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-5rlnw" to be "success or failure"
Mar 26 06:00:25.944: INFO: Pod "pod-73386baf-4f8c-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 54.929709ms
Mar 26 06:00:27.951: INFO: Pod "pod-73386baf-4f8c-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062451001s
Mar 26 06:00:29.959: INFO: Pod "pod-73386baf-4f8c-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069720294s
STEP: Saw pod success
Mar 26 06:00:29.959: INFO: Pod "pod-73386baf-4f8c-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:00:29.964: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-73386baf-4f8c-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 06:00:30.069: INFO: Waiting for pod pod-73386baf-4f8c-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:00:30.093: INFO: Pod pod-73386baf-4f8c-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:00:30.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5rlnw" for this suite.
Mar 26 06:00:36.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:00:36.307: INFO: namespace: e2e-tests-emptydir-5rlnw, resource: bindings, ignored listing per whitelist
Mar 26 06:00:36.459: INFO: namespace e2e-tests-emptydir-5rlnw deletion completed in 6.353115211s

• [SLOW TEST:10.821 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:00:36.500: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:00:58.812: INFO: Container started at 2019-03-26 06:00:38 +0000 UTC, pod became ready at 2019-03-26 06:00:56 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:00:58.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gzswv" for this suite.
Mar 26 06:01:22.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:01:23.068: INFO: namespace: e2e-tests-container-probe-gzswv, resource: bindings, ignored listing per whitelist
Mar 26 06:01:23.090: INFO: namespace e2e-tests-container-probe-gzswv deletion completed in 24.265659838s

• [SLOW TEST:46.591 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:01:23.091: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 26 06:01:23.362: INFO: Waiting up to 5m0s for pod "pod-957b0811-4f8c-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-tkm9m" to be "success or failure"
Mar 26 06:01:23.390: INFO: Pod "pod-957b0811-4f8c-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 28.070712ms
Mar 26 06:01:25.396: INFO: Pod "pod-957b0811-4f8c-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033834391s
STEP: Saw pod success
Mar 26 06:01:25.396: INFO: Pod "pod-957b0811-4f8c-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:01:25.401: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-957b0811-4f8c-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 06:01:25.501: INFO: Waiting for pod pod-957b0811-4f8c-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:01:25.558: INFO: Pod pod-957b0811-4f8c-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:01:25.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tkm9m" for this suite.
Mar 26 06:01:31.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:01:31.676: INFO: namespace: e2e-tests-emptydir-tkm9m, resource: bindings, ignored listing per whitelist
Mar 26 06:01:31.920: INFO: namespace e2e-tests-emptydir-tkm9m deletion completed in 6.330971639s

• [SLOW TEST:8.829 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:01:31.922: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 26 06:01:38.286: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 06:01:38.294: INFO: Pod pod-with-prestop-http-hook still exists
Mar 26 06:01:40.294: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 06:01:40.304: INFO: Pod pod-with-prestop-http-hook still exists
Mar 26 06:01:42.294: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 06:01:42.304: INFO: Pod pod-with-prestop-http-hook still exists
Mar 26 06:01:44.294: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 06:01:44.304: INFO: Pod pod-with-prestop-http-hook still exists
Mar 26 06:01:46.296: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 06:01:46.304: INFO: Pod pod-with-prestop-http-hook still exists
Mar 26 06:01:48.295: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 06:01:48.305: INFO: Pod pod-with-prestop-http-hook still exists
Mar 26 06:01:50.294: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 06:01:50.304: INFO: Pod pod-with-prestop-http-hook still exists
Mar 26 06:01:52.294: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 26 06:01:52.300: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:01:52.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-l57hh" for this suite.
Mar 26 06:02:16.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:02:16.452: INFO: namespace: e2e-tests-container-lifecycle-hook-l57hh, resource: bindings, ignored listing per whitelist
Mar 26 06:02:16.593: INFO: namespace e2e-tests-container-lifecycle-hook-l57hh deletion completed in 24.26536637s

• [SLOW TEST:44.671 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:02:16.595: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:02:16.811: INFO: Creating deployment "nginx-deployment"
Mar 26 06:02:16.827: INFO: Waiting for observed generation 1
Mar 26 06:02:18.909: INFO: Waiting for all required pods to come up
Mar 26 06:02:18.921: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar 26 06:02:20.978: INFO: Waiting for deployment "nginx-deployment" to complete
Mar 26 06:02:20.997: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar 26 06:02:21.023: INFO: Updating deployment nginx-deployment
Mar 26 06:02:21.024: INFO: Waiting for observed generation 2
Mar 26 06:02:23.189: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 26 06:02:23.362: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 26 06:02:23.720: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 26 06:02:24.067: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 26 06:02:24.067: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 26 06:02:24.180: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 26 06:02:24.407: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar 26 06:02:24.407: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar 26 06:02:24.651: INFO: Updating deployment nginx-deployment
Mar 26 06:02:24.652: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar 26 06:02:25.116: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 26 06:02:27.016: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 26 06:02:30.106: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-d58ng,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d58ng/deployments/nginx-deployment,UID:b55a5ba4-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36150,Generation:3,CreationTimestamp:2019-03-26 06:02:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-03-26 06:02:24 +0000 UTC 2019-03-26 06:02:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-26 06:02:29 +0000 UTC 2019-03-26 06:02:16 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar 26 06:02:30.460: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-d58ng,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d58ng/replicasets/nginx-deployment-7dc8f79789,UID:b7dcba2a-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36112,Generation:3,CreationTimestamp:2019-03-26 06:02:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b55a5ba4-4f8c-11e9-b22a-90b8d090d774 0xc4215094b7 0xc4215094b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 06:02:30.460: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar 26 06:02:30.460: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-d58ng,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d58ng/replicasets/nginx-deployment-7f9675fb8b,UID:b55ecae8-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36107,Generation:3,CreationTimestamp:2019-03-26 06:02:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b55a5ba4-4f8c-11e9-b22a-90b8d090d774 0xc421509577 0xc421509578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Mar 26 06:02:30.800: INFO: Pod "nginx-deployment-7dc8f79789-7t2w6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7t2w6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-7t2w6,UID:ba2d0290-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36071,Generation:0,CreationTimestamp:2019-03-26 06:02:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247a0a7 0xc42247a0a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247a110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247a130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.101,PodIP:,StartTime:2019-03-26 06:02:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.801: INFO: Pod "nginx-deployment-7dc8f79789-dbjhx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dbjhx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-dbjhx,UID:baed8c39-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36163,Generation:0,CreationTimestamp:2019-03-26 06:02:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.17/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247a200 0xc42247a201}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247a270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247a290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:27 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.94,PodIP:,StartTime:2019-03-26 06:02:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.808: INFO: Pod "nginx-deployment-7dc8f79789-f5b62" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-f5b62,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-f5b62,UID:ba981c29-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36154,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.29/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247a360 0xc42247a361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247a3d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247a3f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.51,PodIP:,StartTime:2019-03-26 06:02:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.808: INFO: Pod "nginx-deployment-7dc8f79789-gvwvm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-gvwvm,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-gvwvm,UID:b83fd200-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36162,Generation:0,CreationTimestamp:2019-03-26 06:02:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.4.16/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247a4c0 0xc42247a4c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247a530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247a550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.91,PodIP:,StartTime:2019-03-26 06:02:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.809: INFO: Pod "nginx-deployment-7dc8f79789-k4xsf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-k4xsf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-k4xsf,UID:b7ded726-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36144,Generation:0,CreationTimestamp:2019-03-26 06:02:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.13/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247a630 0xc42247a631}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247a6a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247a6c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.94,PodIP:,StartTime:2019-03-26 06:02:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.809: INFO: Pod "nginx-deployment-7dc8f79789-mkt6h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mkt6h,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-mkt6h,UID:b7e52362-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36038,Generation:0,CreationTimestamp:2019-03-26 06:02:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.33/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247a7a0 0xc42247a7a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247a810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247a830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.101,PodIP:,StartTime:2019-03-26 06:02:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.809: INFO: Pod "nginx-deployment-7dc8f79789-mqlfj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mqlfj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-mqlfj,UID:ba996a71-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36135,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247a900 0xc42247a901}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247a970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247a990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.91,PodIP:,StartTime:2019-03-26 06:02:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.809: INFO: Pod "nginx-deployment-7dc8f79789-qfwhm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qfwhm,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-qfwhm,UID:ba8dd813-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36139,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.27/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247aa60 0xc42247aa61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247aad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247aaf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.51,PodIP:,StartTime:2019-03-26 06:02:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.810: INFO: Pod "nginx-deployment-7dc8f79789-qhcbx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qhcbx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-qhcbx,UID:b81add77-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36108,Generation:0,CreationTimestamp:2019-03-26 06:02:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.25/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247abc0 0xc42247abc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247ac30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247ac50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.51,PodIP:,StartTime:2019-03-26 06:02:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.810: INFO: Pod "nginx-deployment-7dc8f79789-qs7b6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qs7b6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-qs7b6,UID:b7e4a853-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36035,Generation:0,CreationTimestamp:2019-03-26 06:02:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.36/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247ad30 0xc42247ad31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247ada0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247adc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:21 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.8,PodIP:,StartTime:2019-03-26 06:02:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.821: INFO: Pod "nginx-deployment-7dc8f79789-s2rxt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-s2rxt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-s2rxt,UID:ba4e317e-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36104,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247ae90 0xc42247ae91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247af00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247af20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.8,PodIP:,StartTime:2019-03-26 06:02:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.821: INFO: Pod "nginx-deployment-7dc8f79789-sls4g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-sls4g,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-sls4g,UID:ba97de27-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36155,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.16/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247aff0 0xc42247aff1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247b060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247b080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.94,PodIP:,StartTime:2019-03-26 06:02:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.822: INFO: Pod "nginx-deployment-7dc8f79789-x858m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-x858m,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7dc8f79789-x858m,UID:ba4302c5-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36136,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.4.18/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 b7dcba2a-4f8c-11e9-b22a-90b8d090d774 0xc42247b150 0xc42247b151}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247b1c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247b1e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.91,PodIP:,StartTime:2019-03-26 06:02:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.823: INFO: Pod "nginx-deployment-7f9675fb8b-5b8hh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5b8hh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-5b8hh,UID:ba4cb607-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36105,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc42247b2a0 0xc42247b2a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247b300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247b320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.101,PodIP:,StartTime:2019-03-26 06:02:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.824: INFO: Pod "nginx-deployment-7f9675fb8b-6kvzs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6kvzs,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-6kvzs,UID:b56690bf-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:35932,Generation:0,CreationTimestamp:2019-03-26 06:02:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.1.32/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc42247b3e7 0xc42247b3e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247b450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247b470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:16 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.101,PodIP:10.42.1.32,StartTime:2019-03-26 06:02:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 06:02:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://1f783faa613d1553ab42fd92a9293e4af5af3c834fbe210a24d2973f3ed71d67}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.824: INFO: Pod "nginx-deployment-7f9675fb8b-6td8m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6td8m,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-6td8m,UID:b56c22ba-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:35933,Generation:0,CreationTimestamp:2019-03-26 06:02:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.35/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc42247b540 0xc42247b541}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247b5a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247b5c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:16 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.8,PodIP:10.42.0.35,StartTime:2019-03-26 06:02:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 06:02:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://c7a2d7c4b9cbb47b295bd966620ae438f060a953abea5e328d38739199f1e640}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.824: INFO: Pod "nginx-deployment-7f9675fb8b-7gstn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7gstn,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-7gstn,UID:ba4ea748-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36129,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.26/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc42247b690 0xc42247b691}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247b6f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247b710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.51,PodIP:,StartTime:2019-03-26 06:02:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.825: INFO: Pod "nginx-deployment-7f9675fb8b-7zzcl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7zzcl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-7zzcl,UID:ba2b1bf7-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36095,Generation:0,CreationTimestamp:2019-03-26 06:02:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc42247b7e0 0xc42247b7e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247b840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247b870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.101,PodIP:,StartTime:2019-03-26 06:02:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.825: INFO: Pod "nginx-deployment-7f9675fb8b-92m66" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-92m66,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-92m66,UID:ba939dd3-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36117,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc42247b947 0xc42247b948}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247b9b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247b9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.91,PodIP:,StartTime:2019-03-26 06:02:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.825: INFO: Pod "nginx-deployment-7f9675fb8b-b29gs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-b29gs,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-b29gs,UID:ba97384f-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36130,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc42247ba80 0xc42247ba81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247bae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247bb00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.8,PodIP:,StartTime:2019-03-26 06:02:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.825: INFO: Pod "nginx-deployment-7f9675fb8b-fbsz9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fbsz9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-fbsz9,UID:ba155fda-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36067,Generation:0,CreationTimestamp:2019-03-26 06:02:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc42247bbc0 0xc42247bbc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247bc20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247bc40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:24 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.8,PodIP:,StartTime:2019-03-26 06:02:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.825: INFO: Pod "nginx-deployment-7f9675fb8b-fv8pg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fv8pg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-fv8pg,UID:b587b389-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:35901,Generation:0,CreationTimestamp:2019-03-26 06:02:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.23/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc42247bd50 0xc42247bd51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247bdb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247bdd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:17 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.51,PodIP:10.42.2.23,StartTime:2019-03-26 06:02:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 06:02:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://53d022f2a7d26c40cb3f86f1b7bebc5541bf342882959551a0590dea6b00841a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.826: INFO: Pod "nginx-deployment-7f9675fb8b-h678q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-h678q,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-h678q,UID:ba4f4b71-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36137,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.4.17/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc42247bea0 0xc42247bea1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42247bf00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42247bf20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.91,PodIP:,StartTime:2019-03-26 06:02:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.826: INFO: Pod "nginx-deployment-7f9675fb8b-hcmtt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hcmtt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-hcmtt,UID:b57846eb-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:35900,Generation:0,CreationTimestamp:2019-03-26 06:02:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.4.14/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc42247bff0 0xc42247bff1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212f6050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212f6070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:17 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.91,PodIP:10.42.4.14,StartTime:2019-03-26 06:02:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 06:02:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://3de976e9f455735b001357200ba1ee7bc59a988a5676bd0e2f2e4cfd41f51b56}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.826: INFO: Pod "nginx-deployment-7f9675fb8b-hcp4h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hcp4h,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-hcp4h,UID:b57551b4-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:35894,Generation:0,CreationTimestamp:2019-03-26 06:02:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.22/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc4212f6140 0xc4212f6141}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212f61a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212f61c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:17 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.51,PodIP:10.42.2.22,StartTime:2019-03-26 06:02:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 06:02:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://4ad3479dc3ab446f502adf36d9319072d2075a7a22234a692bf55e7e382b4d29}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.828: INFO: Pod "nginx-deployment-7f9675fb8b-k824k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-k824k,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-k824k,UID:ba99a972-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36127,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc4212f6290 0xc4212f6291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212f62f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212f6310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.101,PodIP:,StartTime:2019-03-26 06:02:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.829: INFO: Pod "nginx-deployment-7f9675fb8b-mgndj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mgndj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-mgndj,UID:b588daec-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:35895,Generation:0,CreationTimestamp:2019-03-26 06:02:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.4.13/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc4212f63d7 0xc4212f63d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212f6440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212f6460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:17 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.91,PodIP:10.42.4.13,StartTime:2019-03-26 06:02:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 06:02:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://c57949e3bc27b027307a8c818451052052923bbc69fcdb13b7241c8ae01e047f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.829: INFO: Pod "nginx-deployment-7f9675fb8b-nffhm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nffhm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-nffhm,UID:ba4ec817-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36161,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.14/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc4212f6530 0xc4212f6531}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212f6590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212f65b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.94,PodIP:10.42.3.14,StartTime:2019-03-26 06:02:25 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 06:02:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://0725277dc0c4b120d0281a81ff98ea555e6399bc953549274a7af25504985109}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.829: INFO: Pod "nginx-deployment-7f9675fb8b-ng2rr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ng2rr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-ng2rr,UID:ba998c76-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36145,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.2.28/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc4212f6680 0xc4212f6681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212f66e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212f6700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  }],Message:,Reason:,HostIP:72.2.115.51,PodIP:,StartTime:2019-03-26 06:02:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.829: INFO: Pod "nginx-deployment-7f9675fb8b-qkjff" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qkjff,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-qkjff,UID:ba2ce77d-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36092,Generation:0,CreationTimestamp:2019-03-26 06:02:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc4212f67b0 0xc4212f67b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212f6810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212f6830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:25 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.8,PodIP:,StartTime:2019-03-26 06:02:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.829: INFO: Pod "nginx-deployment-7f9675fb8b-rhfth" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rhfth,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-rhfth,UID:b588fa08-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:35914,Generation:0,CreationTimestamp:2019-03-26 06:02:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.11/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc4212f68f0 0xc4212f68f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212f6950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212f6970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:17 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.94,PodIP:10.42.3.11,StartTime:2019-03-26 06:02:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 06:02:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://4d42bfa697154b69ccc83f2c16d4b864da1c8ac225c41f59ed90bce89072e724}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.829: INFO: Pod "nginx-deployment-7f9675fb8b-shlzt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-shlzt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-shlzt,UID:b56c7181-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:35910,Generation:0,CreationTimestamp:2019-03-26 06:02:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.10/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc4212f6a40 0xc4212f6a41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212f6aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212f6ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:16 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.94,PodIP:10.42.3.10,StartTime:2019-03-26 06:02:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 06:02:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://722f90037747761533687fd68fad195c5b6400a18e6b3524e02a4878b58d840b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 26 06:02:30.829: INFO: Pod "nginx-deployment-7f9675fb8b-vxs2q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vxs2q,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-d58ng,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d58ng/pods/nginx-deployment-7f9675fb8b-vxs2q,UID:ba9a5906-4f8c-11e9-b22a-90b8d090d774,ResourceVersion:36152,Generation:0,CreationTimestamp:2019-03-26 06:02:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.3.15/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b b55ecae8-4f8c-11e9-b22a-90b8d090d774 0xc4212f6ba0 0xc4212f6ba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qs7b6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qs7b6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qs7b6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-worker1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4212f6c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212f6c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:02:26 +0000 UTC  }],Message:,Reason:,HostIP:72.2.114.94,PodIP:,StartTime:2019-03-26 06:02:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:02:30.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-d58ng" for this suite.
Mar 26 06:02:55.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:02:55.825: INFO: namespace: e2e-tests-deployment-d58ng, resource: bindings, ignored listing per whitelist
Mar 26 06:02:55.933: INFO: namespace e2e-tests-deployment-d58ng deletion completed in 24.718978823s

• [SLOW TEST:39.339 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:02:55.934: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-gvf22
I0326 06:02:56.203409      14 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-gvf22, replica count: 1
I0326 06:02:57.254248      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0326 06:02:58.254931      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0326 06:02:59.256591      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 26 06:02:59.414: INFO: Created: latency-svc-mtcvr
Mar 26 06:02:59.496: INFO: Got endpoints: latency-svc-mtcvr [137.08461ms]
Mar 26 06:02:59.640: INFO: Created: latency-svc-9t2dg
Mar 26 06:02:59.660: INFO: Got endpoints: latency-svc-9t2dg [162.950744ms]
Mar 26 06:02:59.706: INFO: Created: latency-svc-xw9lk
Mar 26 06:02:59.775: INFO: Got endpoints: latency-svc-xw9lk [276.386388ms]
Mar 26 06:02:59.813: INFO: Created: latency-svc-v6qn2
Mar 26 06:02:59.888: INFO: Created: latency-svc-8dx7p
Mar 26 06:02:59.944: INFO: Got endpoints: latency-svc-v6qn2 [446.221616ms]
Mar 26 06:02:59.974: INFO: Got endpoints: latency-svc-8dx7p [475.356864ms]
Mar 26 06:03:00.023: INFO: Created: latency-svc-xq4qd
Mar 26 06:03:00.088: INFO: Created: latency-svc-x5j2b
Mar 26 06:03:00.156: INFO: Got endpoints: latency-svc-xq4qd [649.45413ms]
Mar 26 06:03:00.243: INFO: Got endpoints: latency-svc-x5j2b [744.388158ms]
Mar 26 06:03:00.245: INFO: Created: latency-svc-qthng
Mar 26 06:03:00.291: INFO: Got endpoints: latency-svc-qthng [791.568719ms]
Mar 26 06:03:00.350: INFO: Created: latency-svc-j2rtw
Mar 26 06:03:00.419: INFO: Got endpoints: latency-svc-j2rtw [919.075243ms]
Mar 26 06:03:00.432: INFO: Created: latency-svc-pr89x
Mar 26 06:03:00.495: INFO: Got endpoints: latency-svc-pr89x [995.720915ms]
Mar 26 06:03:00.521: INFO: Created: latency-svc-6cjn6
Mar 26 06:03:00.598: INFO: Created: latency-svc-gtnl5
Mar 26 06:03:00.606: INFO: Got endpoints: latency-svc-6cjn6 [1.106519176s]
Mar 26 06:03:00.630: INFO: Got endpoints: latency-svc-gtnl5 [211.269159ms]
Mar 26 06:03:00.659: INFO: Created: latency-svc-7qjw4
Mar 26 06:03:00.711: INFO: Got endpoints: latency-svc-7qjw4 [1.211082769s]
Mar 26 06:03:00.741: INFO: Created: latency-svc-mfwt8
Mar 26 06:03:00.774: INFO: Got endpoints: latency-svc-mfwt8 [1.271036881s]
Mar 26 06:03:00.791: INFO: Created: latency-svc-4rgjv
Mar 26 06:03:00.846: INFO: Created: latency-svc-qkf4r
Mar 26 06:03:00.858: INFO: Got endpoints: latency-svc-4rgjv [1.354454418s]
Mar 26 06:03:00.905: INFO: Got endpoints: latency-svc-qkf4r [1.401523859s]
Mar 26 06:03:00.952: INFO: Created: latency-svc-x6lsm
Mar 26 06:03:00.996: INFO: Got endpoints: latency-svc-x6lsm [1.491421012s]
Mar 26 06:03:01.085: INFO: Created: latency-svc-wvcdf
Mar 26 06:03:01.115: INFO: Created: latency-svc-f7rsm
Mar 26 06:03:01.134: INFO: Got endpoints: latency-svc-wvcdf [1.474159541s]
Mar 26 06:03:01.230: INFO: Created: latency-svc-c6gpd
Mar 26 06:03:01.231: INFO: Got endpoints: latency-svc-f7rsm [1.455664952s]
Mar 26 06:03:01.243: INFO: Created: latency-svc-5kt6m
Mar 26 06:03:01.268: INFO: Got endpoints: latency-svc-c6gpd [1.323958807s]
Mar 26 06:03:01.292: INFO: Got endpoints: latency-svc-5kt6m [1.317777379s]
Mar 26 06:03:01.337: INFO: Created: latency-svc-wk7ww
Mar 26 06:03:01.374: INFO: Created: latency-svc-98894
Mar 26 06:03:01.398: INFO: Got endpoints: latency-svc-wk7ww [1.241905672s]
Mar 26 06:03:01.424: INFO: Got endpoints: latency-svc-98894 [1.179978156s]
Mar 26 06:03:01.479: INFO: Created: latency-svc-hxt2l
Mar 26 06:03:01.524: INFO: Created: latency-svc-j9cwq
Mar 26 06:03:01.541: INFO: Got endpoints: latency-svc-hxt2l [1.045792709s]
Mar 26 06:03:01.584: INFO: Created: latency-svc-mzv4g
Mar 26 06:03:01.588: INFO: Got endpoints: latency-svc-j9cwq [1.297439334s]
Mar 26 06:03:01.651: INFO: Got endpoints: latency-svc-mzv4g [1.044086688s]
Mar 26 06:03:01.701: INFO: Created: latency-svc-2ngb8
Mar 26 06:03:01.733: INFO: Got endpoints: latency-svc-2ngb8 [1.103210449s]
Mar 26 06:03:01.772: INFO: Created: latency-svc-zwbmx
Mar 26 06:03:01.789: INFO: Created: latency-svc-kln8x
Mar 26 06:03:01.809: INFO: Got endpoints: latency-svc-zwbmx [1.076730214s]
Mar 26 06:03:01.860: INFO: Got endpoints: latency-svc-kln8x [1.085795632s]
Mar 26 06:03:01.903: INFO: Created: latency-svc-nf8xm
Mar 26 06:03:02.010: INFO: Got endpoints: latency-svc-nf8xm [1.151729331s]
Mar 26 06:03:02.055: INFO: Created: latency-svc-dcpd6
Mar 26 06:03:02.121: INFO: Created: latency-svc-p6zlx
Mar 26 06:03:02.153: INFO: Got endpoints: latency-svc-dcpd6 [1.201609075s]
Mar 26 06:03:02.209: INFO: Created: latency-svc-thtzd
Mar 26 06:03:02.214: INFO: Got endpoints: latency-svc-p6zlx [1.218160492s]
Mar 26 06:03:02.258: INFO: Got endpoints: latency-svc-thtzd [1.123365346s]
Mar 26 06:03:02.345: INFO: Created: latency-svc-g46v8
Mar 26 06:03:02.346: INFO: Got endpoints: latency-svc-g46v8 [1.115168098s]
Mar 26 06:03:02.347: INFO: Created: latency-svc-245cj
Mar 26 06:03:02.454: INFO: Got endpoints: latency-svc-245cj [1.185118753s]
Mar 26 06:03:02.459: INFO: Created: latency-svc-8nj7v
Mar 26 06:03:02.480: INFO: Got endpoints: latency-svc-8nj7v [1.188460822s]
Mar 26 06:03:02.499: INFO: Created: latency-svc-l78gj
Mar 26 06:03:02.532: INFO: Created: latency-svc-mh4kn
Mar 26 06:03:02.536: INFO: Got endpoints: latency-svc-l78gj [1.137755526s]
Mar 26 06:03:02.550: INFO: Got endpoints: latency-svc-mh4kn [1.126114262s]
Mar 26 06:03:02.574: INFO: Created: latency-svc-2pcfx
Mar 26 06:03:02.585: INFO: Got endpoints: latency-svc-2pcfx [1.043504175s]
Mar 26 06:03:02.598: INFO: Created: latency-svc-d44hd
Mar 26 06:03:02.610: INFO: Got endpoints: latency-svc-d44hd [1.021816088s]
Mar 26 06:03:02.622: INFO: Created: latency-svc-p2g5z
Mar 26 06:03:02.632: INFO: Got endpoints: latency-svc-p2g5z [981.270483ms]
Mar 26 06:03:02.647: INFO: Created: latency-svc-2gwpg
Mar 26 06:03:02.665: INFO: Got endpoints: latency-svc-2gwpg [931.454101ms]
Mar 26 06:03:02.669: INFO: Created: latency-svc-vzjmn
Mar 26 06:03:02.681: INFO: Got endpoints: latency-svc-vzjmn [872.157517ms]
Mar 26 06:03:02.694: INFO: Created: latency-svc-fjgz2
Mar 26 06:03:02.703: INFO: Got endpoints: latency-svc-fjgz2 [842.871645ms]
Mar 26 06:03:02.716: INFO: Created: latency-svc-fb42g
Mar 26 06:03:02.726: INFO: Got endpoints: latency-svc-fb42g [715.657579ms]
Mar 26 06:03:02.741: INFO: Created: latency-svc-n2669
Mar 26 06:03:02.751: INFO: Got endpoints: latency-svc-n2669 [597.240856ms]
Mar 26 06:03:02.763: INFO: Created: latency-svc-q8w9p
Mar 26 06:03:02.774: INFO: Created: latency-svc-mb72t
Mar 26 06:03:02.782: INFO: Got endpoints: latency-svc-q8w9p [568.086032ms]
Mar 26 06:03:02.816: INFO: Got endpoints: latency-svc-mb72t [558.139196ms]
Mar 26 06:03:02.824: INFO: Created: latency-svc-zkgrs
Mar 26 06:03:02.833: INFO: Got endpoints: latency-svc-zkgrs [486.741272ms]
Mar 26 06:03:02.849: INFO: Created: latency-svc-vmvk6
Mar 26 06:03:02.856: INFO: Got endpoints: latency-svc-vmvk6 [402.240058ms]
Mar 26 06:03:02.870: INFO: Created: latency-svc-t8crs
Mar 26 06:03:02.883: INFO: Got endpoints: latency-svc-t8crs [402.254388ms]
Mar 26 06:03:02.904: INFO: Created: latency-svc-kbhkk
Mar 26 06:03:02.915: INFO: Got endpoints: latency-svc-kbhkk [379.501574ms]
Mar 26 06:03:02.931: INFO: Created: latency-svc-lr4zt
Mar 26 06:03:02.949: INFO: Created: latency-svc-2lc4n
Mar 26 06:03:02.953: INFO: Got endpoints: latency-svc-lr4zt [403.104843ms]
Mar 26 06:03:02.984: INFO: Got endpoints: latency-svc-2lc4n [398.528273ms]
Mar 26 06:03:02.987: INFO: Created: latency-svc-w6mw5
Mar 26 06:03:03.002: INFO: Created: latency-svc-br94v
Mar 26 06:03:03.017: INFO: Got endpoints: latency-svc-w6mw5 [406.846751ms]
Mar 26 06:03:03.030: INFO: Got endpoints: latency-svc-br94v [397.655696ms]
Mar 26 06:03:03.050: INFO: Created: latency-svc-gmmv4
Mar 26 06:03:03.078: INFO: Got endpoints: latency-svc-gmmv4 [412.33952ms]
Mar 26 06:03:03.081: INFO: Created: latency-svc-q7fhm
Mar 26 06:03:03.093: INFO: Created: latency-svc-brv6x
Mar 26 06:03:03.098: INFO: Got endpoints: latency-svc-q7fhm [416.478579ms]
Mar 26 06:03:03.115: INFO: Created: latency-svc-jf7zk
Mar 26 06:03:03.125: INFO: Got endpoints: latency-svc-jf7zk [399.090337ms]
Mar 26 06:03:03.126: INFO: Got endpoints: latency-svc-brv6x [422.305761ms]
Mar 26 06:03:03.143: INFO: Created: latency-svc-25n6p
Mar 26 06:03:03.160: INFO: Got endpoints: latency-svc-25n6p [408.773981ms]
Mar 26 06:03:03.169: INFO: Created: latency-svc-ncrdx
Mar 26 06:03:03.182: INFO: Got endpoints: latency-svc-ncrdx [399.807742ms]
Mar 26 06:03:03.213: INFO: Created: latency-svc-zd9kk
Mar 26 06:03:03.237: INFO: Created: latency-svc-9cgv7
Mar 26 06:03:03.251: INFO: Got endpoints: latency-svc-zd9kk [434.516157ms]
Mar 26 06:03:03.267: INFO: Got endpoints: latency-svc-9cgv7 [433.510844ms]
Mar 26 06:03:03.288: INFO: Created: latency-svc-qftwk
Mar 26 06:03:03.311: INFO: Created: latency-svc-b9q5p
Mar 26 06:03:03.320: INFO: Got endpoints: latency-svc-qftwk [463.875606ms]
Mar 26 06:03:03.335: INFO: Got endpoints: latency-svc-b9q5p [451.857366ms]
Mar 26 06:03:03.345: INFO: Created: latency-svc-xs9gg
Mar 26 06:03:03.362: INFO: Got endpoints: latency-svc-xs9gg [446.4987ms]
Mar 26 06:03:03.390: INFO: Created: latency-svc-m8vtt
Mar 26 06:03:03.404: INFO: Got endpoints: latency-svc-m8vtt [450.849607ms]
Mar 26 06:03:03.427: INFO: Created: latency-svc-4vwj2
Mar 26 06:03:03.430: INFO: Got endpoints: latency-svc-4vwj2 [446.551842ms]
Mar 26 06:03:03.455: INFO: Created: latency-svc-qm92v
Mar 26 06:03:03.462: INFO: Got endpoints: latency-svc-qm92v [444.754691ms]
Mar 26 06:03:03.470: INFO: Created: latency-svc-g6gbt
Mar 26 06:03:03.492: INFO: Got endpoints: latency-svc-g6gbt [461.868688ms]
Mar 26 06:03:03.529: INFO: Created: latency-svc-4h8c8
Mar 26 06:03:03.544: INFO: Got endpoints: latency-svc-4h8c8 [466.368377ms]
Mar 26 06:03:03.545: INFO: Created: latency-svc-bd8lc
Mar 26 06:03:03.554: INFO: Got endpoints: latency-svc-bd8lc [456.221432ms]
Mar 26 06:03:03.584: INFO: Created: latency-svc-9vbcb
Mar 26 06:03:03.591: INFO: Got endpoints: latency-svc-9vbcb [466.094423ms]
Mar 26 06:03:03.607: INFO: Created: latency-svc-lrhb8
Mar 26 06:03:03.637: INFO: Created: latency-svc-4rqxr
Mar 26 06:03:03.645: INFO: Got endpoints: latency-svc-lrhb8 [519.377475ms]
Mar 26 06:03:03.657: INFO: Got endpoints: latency-svc-4rqxr [497.189454ms]
Mar 26 06:03:03.685: INFO: Created: latency-svc-2kfq9
Mar 26 06:03:03.735: INFO: Created: latency-svc-6zh6c
Mar 26 06:03:03.736: INFO: Got endpoints: latency-svc-2kfq9 [554.024337ms]
Mar 26 06:03:03.761: INFO: Got endpoints: latency-svc-6zh6c [510.054982ms]
Mar 26 06:03:03.777: INFO: Created: latency-svc-dp6pr
Mar 26 06:03:03.788: INFO: Got endpoints: latency-svc-dp6pr [521.499981ms]
Mar 26 06:03:03.817: INFO: Created: latency-svc-whxlp
Mar 26 06:03:03.838: INFO: Created: latency-svc-qmlx6
Mar 26 06:03:03.850: INFO: Got endpoints: latency-svc-whxlp [529.999221ms]
Mar 26 06:03:03.867: INFO: Got endpoints: latency-svc-qmlx6 [531.909934ms]
Mar 26 06:03:03.880: INFO: Created: latency-svc-bvcd2
Mar 26 06:03:03.888: INFO: Got endpoints: latency-svc-bvcd2 [525.805695ms]
Mar 26 06:03:03.914: INFO: Created: latency-svc-8bkgg
Mar 26 06:03:03.919: INFO: Got endpoints: latency-svc-8bkgg [514.980115ms]
Mar 26 06:03:03.939: INFO: Created: latency-svc-twvb7
Mar 26 06:03:03.978: INFO: Created: latency-svc-xm6rx
Mar 26 06:03:03.984: INFO: Got endpoints: latency-svc-xm6rx [522.114257ms]
Mar 26 06:03:03.985: INFO: Got endpoints: latency-svc-twvb7 [554.306362ms]
Mar 26 06:03:04.009: INFO: Created: latency-svc-n5kzf
Mar 26 06:03:04.024: INFO: Got endpoints: latency-svc-n5kzf [532.364129ms]
Mar 26 06:03:04.052: INFO: Created: latency-svc-x96k7
Mar 26 06:03:04.054: INFO: Got endpoints: latency-svc-x96k7 [509.384318ms]
Mar 26 06:03:04.084: INFO: Created: latency-svc-hlmgx
Mar 26 06:03:04.119: INFO: Created: latency-svc-8n895
Mar 26 06:03:04.120: INFO: Got endpoints: latency-svc-hlmgx [565.123894ms]
Mar 26 06:03:04.153: INFO: Created: latency-svc-6mjwf
Mar 26 06:03:04.159: INFO: Got endpoints: latency-svc-8n895 [567.294251ms]
Mar 26 06:03:04.186: INFO: Created: latency-svc-fwkn7
Mar 26 06:03:04.208: INFO: Got endpoints: latency-svc-6mjwf [562.441168ms]
Mar 26 06:03:04.224: INFO: Got endpoints: latency-svc-fwkn7 [566.526119ms]
Mar 26 06:03:04.242: INFO: Created: latency-svc-n78kb
Mar 26 06:03:04.264: INFO: Got endpoints: latency-svc-n78kb [527.84597ms]
Mar 26 06:03:04.306: INFO: Created: latency-svc-6rzxr
Mar 26 06:03:04.336: INFO: Got endpoints: latency-svc-6rzxr [575.322651ms]
Mar 26 06:03:04.364: INFO: Created: latency-svc-87t52
Mar 26 06:03:04.377: INFO: Got endpoints: latency-svc-87t52 [588.422082ms]
Mar 26 06:03:04.394: INFO: Created: latency-svc-48gck
Mar 26 06:03:04.454: INFO: Got endpoints: latency-svc-48gck [603.276413ms]
Mar 26 06:03:04.483: INFO: Created: latency-svc-8z842
Mar 26 06:03:04.508: INFO: Created: latency-svc-shkd6
Mar 26 06:03:04.520: INFO: Got endpoints: latency-svc-8z842 [652.787428ms]
Mar 26 06:03:04.530: INFO: Got endpoints: latency-svc-shkd6 [642.328324ms]
Mar 26 06:03:04.562: INFO: Created: latency-svc-sxkbv
Mar 26 06:03:04.576: INFO: Got endpoints: latency-svc-sxkbv [656.96836ms]
Mar 26 06:03:04.620: INFO: Created: latency-svc-lzd9t
Mar 26 06:03:04.657: INFO: Created: latency-svc-z2pqg
Mar 26 06:03:04.676: INFO: Got endpoints: latency-svc-lzd9t [691.580786ms]
Mar 26 06:03:04.701: INFO: Got endpoints: latency-svc-z2pqg [715.804456ms]
Mar 26 06:03:04.712: INFO: Created: latency-svc-kdjln
Mar 26 06:03:04.751: INFO: Created: latency-svc-qssxr
Mar 26 06:03:04.763: INFO: Got endpoints: latency-svc-kdjln [739.07881ms]
Mar 26 06:03:04.768: INFO: Got endpoints: latency-svc-qssxr [713.734526ms]
Mar 26 06:03:04.792: INFO: Created: latency-svc-999b5
Mar 26 06:03:04.830: INFO: Created: latency-svc-2st7w
Mar 26 06:03:04.837: INFO: Got endpoints: latency-svc-999b5 [717.361527ms]
Mar 26 06:03:04.854: INFO: Got endpoints: latency-svc-2st7w [694.583652ms]
Mar 26 06:03:04.875: INFO: Created: latency-svc-zm2f2
Mar 26 06:03:04.899: INFO: Created: latency-svc-vtr5d
Mar 26 06:03:04.906: INFO: Got endpoints: latency-svc-zm2f2 [697.866348ms]
Mar 26 06:03:04.930: INFO: Got endpoints: latency-svc-vtr5d [706.699673ms]
Mar 26 06:03:04.948: INFO: Created: latency-svc-462b4
Mar 26 06:03:04.965: INFO: Got endpoints: latency-svc-462b4 [700.426298ms]
Mar 26 06:03:04.992: INFO: Created: latency-svc-rkrsw
Mar 26 06:03:05.018: INFO: Created: latency-svc-m9585
Mar 26 06:03:05.032: INFO: Got endpoints: latency-svc-rkrsw [695.343724ms]
Mar 26 06:03:05.042: INFO: Created: latency-svc-rxs89
Mar 26 06:03:05.093: INFO: Got endpoints: latency-svc-m9585 [715.907786ms]
Mar 26 06:03:05.120: INFO: Got endpoints: latency-svc-rxs89 [666.194242ms]
Mar 26 06:03:05.158: INFO: Created: latency-svc-8q2q4
Mar 26 06:03:05.178: INFO: Got endpoints: latency-svc-8q2q4 [658.423366ms]
Mar 26 06:03:05.213: INFO: Created: latency-svc-7hk9g
Mar 26 06:03:05.241: INFO: Created: latency-svc-jc8dd
Mar 26 06:03:05.258: INFO: Got endpoints: latency-svc-7hk9g [727.661876ms]
Mar 26 06:03:05.314: INFO: Got endpoints: latency-svc-jc8dd [737.258694ms]
Mar 26 06:03:05.336: INFO: Created: latency-svc-j7ngk
Mar 26 06:03:05.360: INFO: Got endpoints: latency-svc-j7ngk [684.313245ms]
Mar 26 06:03:05.402: INFO: Created: latency-svc-rg4db
Mar 26 06:03:05.435: INFO: Created: latency-svc-zgx5q
Mar 26 06:03:05.451: INFO: Got endpoints: latency-svc-rg4db [750.680483ms]
Mar 26 06:03:05.511: INFO: Created: latency-svc-lwjxc
Mar 26 06:03:05.511: INFO: Got endpoints: latency-svc-zgx5q [747.609333ms]
Mar 26 06:03:05.567: INFO: Created: latency-svc-nz59h
Mar 26 06:03:05.567: INFO: Got endpoints: latency-svc-lwjxc [799.491548ms]
Mar 26 06:03:05.601: INFO: Created: latency-svc-4j2sh
Mar 26 06:03:05.614: INFO: Got endpoints: latency-svc-nz59h [777.260514ms]
Mar 26 06:03:05.644: INFO: Created: latency-svc-lgskk
Mar 26 06:03:05.658: INFO: Got endpoints: latency-svc-4j2sh [804.11933ms]
Mar 26 06:03:05.672: INFO: Got endpoints: latency-svc-lgskk [766.025735ms]
Mar 26 06:03:05.694: INFO: Created: latency-svc-bgjrn
Mar 26 06:03:05.714: INFO: Got endpoints: latency-svc-bgjrn [783.131262ms]
Mar 26 06:03:05.737: INFO: Created: latency-svc-nxksj
Mar 26 06:03:05.770: INFO: Created: latency-svc-fvl7v
Mar 26 06:03:05.784: INFO: Got endpoints: latency-svc-nxksj [819.29293ms]
Mar 26 06:03:05.796: INFO: Got endpoints: latency-svc-fvl7v [764.327317ms]
Mar 26 06:03:05.829: INFO: Created: latency-svc-hhgp9
Mar 26 06:03:05.846: INFO: Got endpoints: latency-svc-hhgp9 [753.081343ms]
Mar 26 06:03:05.868: INFO: Created: latency-svc-dbbzw
Mar 26 06:03:05.893: INFO: Got endpoints: latency-svc-dbbzw [772.730395ms]
Mar 26 06:03:05.969: INFO: Created: latency-svc-4hpth
Mar 26 06:03:05.997: INFO: Created: latency-svc-k6z5b
Mar 26 06:03:06.006: INFO: Got endpoints: latency-svc-4hpth [827.776653ms]
Mar 26 06:03:06.051: INFO: Got endpoints: latency-svc-k6z5b [792.853179ms]
Mar 26 06:03:06.053: INFO: Created: latency-svc-tg4rv
Mar 26 06:03:06.091: INFO: Created: latency-svc-tmlvb
Mar 26 06:03:06.098: INFO: Got endpoints: latency-svc-tg4rv [784.023712ms]
Mar 26 06:03:06.139: INFO: Created: latency-svc-j8dq6
Mar 26 06:03:06.154: INFO: Got endpoints: latency-svc-tmlvb [793.35111ms]
Mar 26 06:03:06.176: INFO: Created: latency-svc-5lsd2
Mar 26 06:03:06.195: INFO: Got endpoints: latency-svc-j8dq6 [743.718944ms]
Mar 26 06:03:06.218: INFO: Got endpoints: latency-svc-5lsd2 [706.635257ms]
Mar 26 06:03:06.243: INFO: Created: latency-svc-924qs
Mar 26 06:03:06.262: INFO: Created: latency-svc-r9nxq
Mar 26 06:03:06.298: INFO: Created: latency-svc-dqnkw
Mar 26 06:03:06.308: INFO: Got endpoints: latency-svc-r9nxq [693.342731ms]
Mar 26 06:03:06.309: INFO: Got endpoints: latency-svc-924qs [741.656985ms]
Mar 26 06:03:06.346: INFO: Created: latency-svc-8hcc7
Mar 26 06:03:06.404: INFO: Got endpoints: latency-svc-8hcc7 [731.961119ms]
Mar 26 06:03:06.407: INFO: Got endpoints: latency-svc-dqnkw [748.329679ms]
Mar 26 06:03:06.411: INFO: Created: latency-svc-qcrlv
Mar 26 06:03:06.443: INFO: Created: latency-svc-n7nhf
Mar 26 06:03:06.450: INFO: Got endpoints: latency-svc-qcrlv [736.223026ms]
Mar 26 06:03:06.489: INFO: Got endpoints: latency-svc-n7nhf [703.905761ms]
Mar 26 06:03:06.510: INFO: Created: latency-svc-5mk4p
Mar 26 06:03:06.530: INFO: Got endpoints: latency-svc-5mk4p [733.79334ms]
Mar 26 06:03:06.538: INFO: Created: latency-svc-64fs7
Mar 26 06:03:06.587: INFO: Created: latency-svc-nkxw2
Mar 26 06:03:06.600: INFO: Got endpoints: latency-svc-64fs7 [753.671298ms]
Mar 26 06:03:06.620: INFO: Got endpoints: latency-svc-nkxw2 [727.514224ms]
Mar 26 06:03:06.639: INFO: Created: latency-svc-pvs2m
Mar 26 06:03:06.660: INFO: Got endpoints: latency-svc-pvs2m [653.86189ms]
Mar 26 06:03:06.675: INFO: Created: latency-svc-ldjtz
Mar 26 06:03:06.693: INFO: Got endpoints: latency-svc-ldjtz [641.236443ms]
Mar 26 06:03:06.712: INFO: Created: latency-svc-k2zl7
Mar 26 06:03:06.741: INFO: Got endpoints: latency-svc-k2zl7 [642.701839ms]
Mar 26 06:03:06.769: INFO: Created: latency-svc-mwxwb
Mar 26 06:03:06.804: INFO: Created: latency-svc-q4qk2
Mar 26 06:03:06.828: INFO: Got endpoints: latency-svc-mwxwb [674.479546ms]
Mar 26 06:03:06.860: INFO: Created: latency-svc-62bhf
Mar 26 06:03:06.890: INFO: Got endpoints: latency-svc-q4qk2 [694.793066ms]
Mar 26 06:03:06.897: INFO: Got endpoints: latency-svc-62bhf [679.470136ms]
Mar 26 06:03:06.925: INFO: Created: latency-svc-fhg7w
Mar 26 06:03:06.967: INFO: Got endpoints: latency-svc-fhg7w [658.560138ms]
Mar 26 06:03:06.997: INFO: Created: latency-svc-gn4mj
Mar 26 06:03:07.017: INFO: Created: latency-svc-tvhj6
Mar 26 06:03:07.026: INFO: Got endpoints: latency-svc-gn4mj [716.843761ms]
Mar 26 06:03:07.048: INFO: Got endpoints: latency-svc-tvhj6 [643.360544ms]
Mar 26 06:03:07.091: INFO: Created: latency-svc-qbjg7
Mar 26 06:03:07.105: INFO: Got endpoints: latency-svc-qbjg7 [698.260873ms]
Mar 26 06:03:07.142: INFO: Created: latency-svc-x8jq8
Mar 26 06:03:07.160: INFO: Got endpoints: latency-svc-x8jq8 [709.366906ms]
Mar 26 06:03:07.193: INFO: Created: latency-svc-6vm4c
Mar 26 06:03:07.219: INFO: Got endpoints: latency-svc-6vm4c [729.92984ms]
Mar 26 06:03:07.238: INFO: Created: latency-svc-5htng
Mar 26 06:03:07.266: INFO: Got endpoints: latency-svc-5htng [735.992633ms]
Mar 26 06:03:07.291: INFO: Created: latency-svc-wrbpv
Mar 26 06:03:07.325: INFO: Created: latency-svc-hqz52
Mar 26 06:03:07.332: INFO: Got endpoints: latency-svc-wrbpv [731.487572ms]
Mar 26 06:03:07.368: INFO: Got endpoints: latency-svc-hqz52 [747.154474ms]
Mar 26 06:03:07.378: INFO: Created: latency-svc-kbnz8
Mar 26 06:03:07.388: INFO: Got endpoints: latency-svc-kbnz8 [727.725098ms]
Mar 26 06:03:07.418: INFO: Created: latency-svc-4dxk4
Mar 26 06:03:07.481: INFO: Created: latency-svc-42czn
Mar 26 06:03:07.504: INFO: Got endpoints: latency-svc-42czn [762.8421ms]
Mar 26 06:03:07.504: INFO: Got endpoints: latency-svc-4dxk4 [811.540496ms]
Mar 26 06:03:07.547: INFO: Created: latency-svc-sftmq
Mar 26 06:03:07.560: INFO: Got endpoints: latency-svc-sftmq [731.053295ms]
Mar 26 06:03:07.578: INFO: Created: latency-svc-pf528
Mar 26 06:03:07.609: INFO: Got endpoints: latency-svc-pf528 [719.019544ms]
Mar 26 06:03:07.611: INFO: Created: latency-svc-xjsjk
Mar 26 06:03:07.636: INFO: Created: latency-svc-l7c4l
Mar 26 06:03:07.657: INFO: Got endpoints: latency-svc-xjsjk [759.611508ms]
Mar 26 06:03:07.679: INFO: Got endpoints: latency-svc-l7c4l [712.331006ms]
Mar 26 06:03:07.698: INFO: Created: latency-svc-zwbbf
Mar 26 06:03:07.722: INFO: Got endpoints: latency-svc-zwbbf [695.533779ms]
Mar 26 06:03:07.744: INFO: Created: latency-svc-sls8w
Mar 26 06:03:07.813: INFO: Got endpoints: latency-svc-sls8w [765.087519ms]
Mar 26 06:03:07.855: INFO: Created: latency-svc-5k7pf
Mar 26 06:03:07.889: INFO: Created: latency-svc-j4qf9
Mar 26 06:03:07.899: INFO: Got endpoints: latency-svc-5k7pf [793.584137ms]
Mar 26 06:03:07.938: INFO: Got endpoints: latency-svc-j4qf9 [778.556538ms]
Mar 26 06:03:07.944: INFO: Created: latency-svc-cbvgw
Mar 26 06:03:07.969: INFO: Got endpoints: latency-svc-cbvgw [750.630546ms]
Mar 26 06:03:08.008: INFO: Created: latency-svc-d42zv
Mar 26 06:03:08.057: INFO: Got endpoints: latency-svc-d42zv [789.996436ms]
Mar 26 06:03:08.070: INFO: Created: latency-svc-csjxw
Mar 26 06:03:08.149: INFO: Created: latency-svc-j72l7
Mar 26 06:03:08.163: INFO: Got endpoints: latency-svc-csjxw [831.776213ms]
Mar 26 06:03:08.173: INFO: Got endpoints: latency-svc-j72l7 [805.164021ms]
Mar 26 06:03:08.201: INFO: Created: latency-svc-xx8pk
Mar 26 06:03:08.216: INFO: Got endpoints: latency-svc-xx8pk [828.311739ms]
Mar 26 06:03:08.241: INFO: Created: latency-svc-sgwph
Mar 26 06:03:08.261: INFO: Got endpoints: latency-svc-sgwph [756.90115ms]
Mar 26 06:03:08.299: INFO: Created: latency-svc-d5r8d
Mar 26 06:03:08.317: INFO: Got endpoints: latency-svc-d5r8d [811.719922ms]
Mar 26 06:03:08.342: INFO: Created: latency-svc-r5jz9
Mar 26 06:03:08.345: INFO: Got endpoints: latency-svc-r5jz9 [785.562891ms]
Mar 26 06:03:08.377: INFO: Created: latency-svc-ppl6v
Mar 26 06:03:08.394: INFO: Got endpoints: latency-svc-ppl6v [784.661439ms]
Mar 26 06:03:08.418: INFO: Created: latency-svc-lz9wm
Mar 26 06:03:08.454: INFO: Got endpoints: latency-svc-lz9wm [797.296746ms]
Mar 26 06:03:08.469: INFO: Created: latency-svc-4bz5h
Mar 26 06:03:08.494: INFO: Got endpoints: latency-svc-4bz5h [814.516377ms]
Mar 26 06:03:08.566: INFO: Created: latency-svc-h76cz
Mar 26 06:03:08.591: INFO: Created: latency-svc-rfbjd
Mar 26 06:03:08.609: INFO: Got endpoints: latency-svc-h76cz [887.448622ms]
Mar 26 06:03:08.626: INFO: Got endpoints: latency-svc-rfbjd [812.620471ms]
Mar 26 06:03:08.644: INFO: Created: latency-svc-8pqnv
Mar 26 06:03:08.659: INFO: Got endpoints: latency-svc-8pqnv [760.199294ms]
Mar 26 06:03:08.674: INFO: Created: latency-svc-7w9q8
Mar 26 06:03:08.716: INFO: Got endpoints: latency-svc-7w9q8 [777.994361ms]
Mar 26 06:03:08.722: INFO: Created: latency-svc-n2m89
Mar 26 06:03:08.735: INFO: Got endpoints: latency-svc-n2m89 [765.419895ms]
Mar 26 06:03:08.780: INFO: Created: latency-svc-cpk8f
Mar 26 06:03:08.793: INFO: Got endpoints: latency-svc-cpk8f [736.428357ms]
Mar 26 06:03:08.828: INFO: Created: latency-svc-vmqtw
Mar 26 06:03:08.857: INFO: Got endpoints: latency-svc-vmqtw [693.681354ms]
Mar 26 06:03:08.881: INFO: Created: latency-svc-7rhzz
Mar 26 06:03:08.918: INFO: Got endpoints: latency-svc-7rhzz [745.345734ms]
Mar 26 06:03:08.948: INFO: Created: latency-svc-bms6j
Mar 26 06:03:08.994: INFO: Got endpoints: latency-svc-bms6j [777.705229ms]
Mar 26 06:03:09.055: INFO: Created: latency-svc-8sbpc
Mar 26 06:03:09.112: INFO: Created: latency-svc-zhc7s
Mar 26 06:03:09.125: INFO: Got endpoints: latency-svc-8sbpc [863.967448ms]
Mar 26 06:03:09.206: INFO: Got endpoints: latency-svc-zhc7s [889.179828ms]
Mar 26 06:03:09.240: INFO: Created: latency-svc-69bbv
Mar 26 06:03:09.258: INFO: Got endpoints: latency-svc-69bbv [912.361353ms]
Mar 26 06:03:09.302: INFO: Created: latency-svc-hhx55
Mar 26 06:03:09.361: INFO: Got endpoints: latency-svc-hhx55 [966.493793ms]
Mar 26 06:03:09.391: INFO: Created: latency-svc-dgqz5
Mar 26 06:03:09.405: INFO: Got endpoints: latency-svc-dgqz5 [950.371349ms]
Mar 26 06:03:09.484: INFO: Created: latency-svc-tzpj4
Mar 26 06:03:09.619: INFO: Created: latency-svc-cjvhk
Mar 26 06:03:09.631: INFO: Created: latency-svc-w9lx2
Mar 26 06:03:09.672: INFO: Created: latency-svc-ppf2k
Mar 26 06:03:09.689: INFO: Got endpoints: latency-svc-tzpj4 [1.194692095s]
Mar 26 06:03:09.708: INFO: Got endpoints: latency-svc-ppf2k [1.04936275s]
Mar 26 06:03:09.721: INFO: Got endpoints: latency-svc-cjvhk [1.111148414s]
Mar 26 06:03:09.759: INFO: Created: latency-svc-cnj4q
Mar 26 06:03:09.770: INFO: Got endpoints: latency-svc-w9lx2 [1.14396202s]
Mar 26 06:03:09.813: INFO: Created: latency-svc-n6b6l
Mar 26 06:03:09.814: INFO: Got endpoints: latency-svc-cnj4q [1.097282203s]
Mar 26 06:03:09.838: INFO: Got endpoints: latency-svc-n6b6l [1.103042216s]
Mar 26 06:03:09.856: INFO: Created: latency-svc-4hss4
Mar 26 06:03:09.877: INFO: Got endpoints: latency-svc-4hss4 [1.083678114s]
Mar 26 06:03:09.918: INFO: Created: latency-svc-bfbl7
Mar 26 06:03:09.935: INFO: Created: latency-svc-wcq8s
Mar 26 06:03:09.956: INFO: Got endpoints: latency-svc-wcq8s [1.037664189s]
Mar 26 06:03:09.956: INFO: Got endpoints: latency-svc-bfbl7 [1.099053832s]
Mar 26 06:03:09.973: INFO: Created: latency-svc-kbf9f
Mar 26 06:03:09.985: INFO: Got endpoints: latency-svc-kbf9f [990.92116ms]
Mar 26 06:03:09.985: INFO: Latencies: [162.950744ms 211.269159ms 276.386388ms 379.501574ms 397.655696ms 398.528273ms 399.090337ms 399.807742ms 402.240058ms 402.254388ms 403.104843ms 406.846751ms 408.773981ms 412.33952ms 416.478579ms 422.305761ms 433.510844ms 434.516157ms 444.754691ms 446.221616ms 446.4987ms 446.551842ms 450.849607ms 451.857366ms 456.221432ms 461.868688ms 463.875606ms 466.094423ms 466.368377ms 475.356864ms 486.741272ms 497.189454ms 509.384318ms 510.054982ms 514.980115ms 519.377475ms 521.499981ms 522.114257ms 525.805695ms 527.84597ms 529.999221ms 531.909934ms 532.364129ms 554.024337ms 554.306362ms 558.139196ms 562.441168ms 565.123894ms 566.526119ms 567.294251ms 568.086032ms 575.322651ms 588.422082ms 597.240856ms 603.276413ms 641.236443ms 642.328324ms 642.701839ms 643.360544ms 649.45413ms 652.787428ms 653.86189ms 656.96836ms 658.423366ms 658.560138ms 666.194242ms 674.479546ms 679.470136ms 684.313245ms 691.580786ms 693.342731ms 693.681354ms 694.583652ms 694.793066ms 695.343724ms 695.533779ms 697.866348ms 698.260873ms 700.426298ms 703.905761ms 706.635257ms 706.699673ms 709.366906ms 712.331006ms 713.734526ms 715.657579ms 715.804456ms 715.907786ms 716.843761ms 717.361527ms 719.019544ms 727.514224ms 727.661876ms 727.725098ms 729.92984ms 731.053295ms 731.487572ms 731.961119ms 733.79334ms 735.992633ms 736.223026ms 736.428357ms 737.258694ms 739.07881ms 741.656985ms 743.718944ms 744.388158ms 745.345734ms 747.154474ms 747.609333ms 748.329679ms 750.630546ms 750.680483ms 753.081343ms 753.671298ms 756.90115ms 759.611508ms 760.199294ms 762.8421ms 764.327317ms 765.087519ms 765.419895ms 766.025735ms 772.730395ms 777.260514ms 777.705229ms 777.994361ms 778.556538ms 783.131262ms 784.023712ms 784.661439ms 785.562891ms 789.996436ms 791.568719ms 792.853179ms 793.35111ms 793.584137ms 797.296746ms 799.491548ms 804.11933ms 805.164021ms 811.540496ms 811.719922ms 812.620471ms 814.516377ms 819.29293ms 827.776653ms 828.311739ms 831.776213ms 842.871645ms 863.967448ms 872.157517ms 887.448622ms 889.179828ms 912.361353ms 919.075243ms 931.454101ms 950.371349ms 966.493793ms 981.270483ms 990.92116ms 995.720915ms 1.021816088s 1.037664189s 1.043504175s 1.044086688s 1.045792709s 1.04936275s 1.076730214s 1.083678114s 1.085795632s 1.097282203s 1.099053832s 1.103042216s 1.103210449s 1.106519176s 1.111148414s 1.115168098s 1.123365346s 1.126114262s 1.137755526s 1.14396202s 1.151729331s 1.179978156s 1.185118753s 1.188460822s 1.194692095s 1.201609075s 1.211082769s 1.218160492s 1.241905672s 1.271036881s 1.297439334s 1.317777379s 1.323958807s 1.354454418s 1.401523859s 1.455664952s 1.474159541s 1.491421012s]
Mar 26 06:03:09.986: INFO: 50 %ile: 736.223026ms
Mar 26 06:03:09.986: INFO: 90 %ile: 1.137755526s
Mar 26 06:03:09.986: INFO: 99 %ile: 1.474159541s
Mar 26 06:03:09.986: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:03:09.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-gvf22" for this suite.
Mar 26 06:03:44.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:03:44.162: INFO: namespace: e2e-tests-svc-latency-gvf22, resource: bindings, ignored listing per whitelist
Mar 26 06:03:44.287: INFO: namespace e2e-tests-svc-latency-gvf22 deletion completed in 34.277677926s

• [SLOW TEST:48.353 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:03:44.288: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 26 06:03:44.498: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:03:48.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-flwld" for this suite.
Mar 26 06:03:54.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:03:54.410: INFO: namespace: e2e-tests-init-container-flwld, resource: bindings, ignored listing per whitelist
Mar 26 06:03:54.419: INFO: namespace e2e-tests-init-container-flwld deletion completed in 6.274139481s

• [SLOW TEST:10.132 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:03:54.421: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Mar 26 06:03:58.837: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:04:23.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-7qgc8" for this suite.
Mar 26 06:04:30.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:04:30.204: INFO: namespace: e2e-tests-namespaces-7qgc8, resource: bindings, ignored listing per whitelist
Mar 26 06:04:30.413: INFO: namespace e2e-tests-namespaces-7qgc8 deletion completed in 6.413838078s
STEP: Destroying namespace "e2e-tests-nsdeletetest-8thq8" for this suite.
Mar 26 06:04:30.418: INFO: Namespace e2e-tests-nsdeletetest-8thq8 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-zx5qd" for this suite.
Mar 26 06:04:36.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:04:36.720: INFO: namespace: e2e-tests-nsdeletetest-zx5qd, resource: bindings, ignored listing per whitelist
Mar 26 06:04:37.167: INFO: namespace e2e-tests-nsdeletetest-zx5qd deletion completed in 6.749122568s

• [SLOW TEST:42.747 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:04:37.169: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 26 06:04:37.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-q2knf'
Mar 26 06:04:37.810: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 26 06:04:37.810: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Mar 26 06:04:37.828: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Mar 26 06:04:37.868: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar 26 06:04:37.997: INFO: scanned /root for discovery docs: <nil>
Mar 26 06:04:37.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-q2knf'
Mar 26 06:04:54.191: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 26 06:04:54.191: INFO: stdout: "Created e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d\nScaling up e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar 26 06:04:54.191: INFO: stdout: "Created e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d\nScaling up e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar 26 06:04:54.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-q2knf'
Mar 26 06:04:54.356: INFO: stderr: ""
Mar 26 06:04:54.356: INFO: stdout: "e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d-kfj77 "
Mar 26 06:04:54.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d-kfj77 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-q2knf'
Mar 26 06:04:54.557: INFO: stderr: ""
Mar 26 06:04:54.557: INFO: stdout: "true"
Mar 26 06:04:54.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d-kfj77 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-q2knf'
Mar 26 06:04:54.715: INFO: stderr: ""
Mar 26 06:04:54.715: INFO: stdout: "nginx:1.14-alpine"
Mar 26 06:04:54.715: INFO: e2e-test-nginx-rc-7b5d31cccb79c80be15ddf4c3593d89d-kfj77 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Mar 26 06:04:54.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-q2knf'
Mar 26 06:04:54.908: INFO: stderr: ""
Mar 26 06:04:54.908: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:04:54.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q2knf" for this suite.
Mar 26 06:05:01.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:05:01.128: INFO: namespace: e2e-tests-kubectl-q2knf, resource: bindings, ignored listing per whitelist
Mar 26 06:05:01.362: INFO: namespace e2e-tests-kubectl-q2knf deletion completed in 6.420181352s

• [SLOW TEST:24.193 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:05:01.363: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:05:01.587: INFO: Creating deployment "test-recreate-deployment"
Mar 26 06:05:01.602: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 26 06:05:01.658: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Mar 26 06:05:03.675: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 26 06:05:03.684: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 26 06:05:03.698: INFO: Updating deployment test-recreate-deployment
Mar 26 06:05:03.699: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 26 06:05:04.185: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-tw9p2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tw9p2/deployments/test-recreate-deployment,UID:1790d662-4f8d-11e9-b22a-90b8d090d774,ResourceVersion:38271,Generation:2,CreationTimestamp:2019-03-26 06:05:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-26 06:05:04 +0000 UTC 2019-03-26 06:05:04 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-26 06:05:04 +0000 UTC 2019-03-26 06:05:01 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar 26 06:05:04.215: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-tw9p2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tw9p2/replicasets/test-recreate-deployment-7cf749666b,UID:18ef741d-4f8d-11e9-b22a-90b8d090d774,ResourceVersion:38267,Generation:1,CreationTimestamp:2019-03-26 06:05:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1790d662-4f8d-11e9-b22a-90b8d090d774 0xc4215b6697 0xc4215b6698}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 06:05:04.215: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 26 06:05:04.215: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-tw9p2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tw9p2/replicasets/test-recreate-deployment-79f694ff59,UID:17941599-4f8d-11e9-b22a-90b8d090d774,ResourceVersion:38259,Generation:2,CreationTimestamp:2019-03-26 06:05:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1790d662-4f8d-11e9-b22a-90b8d090d774 0xc4215b65d7 0xc4215b65d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 06:05:04.230: INFO: Pod "test-recreate-deployment-7cf749666b-c4pdn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-c4pdn,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-tw9p2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tw9p2/pods/test-recreate-deployment-7cf749666b-c4pdn,UID:18f284d2-4f8d-11e9-b22a-90b8d090d774,ResourceVersion:38272,Generation:0,CreationTimestamp:2019-03-26 06:05:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 18ef741d-4f8d-11e9-b22a-90b8d090d774 0xc4215b6f17 0xc4215b6f18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-92lbc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-92lbc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-92lbc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-etcd-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215b6f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215b6fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:05:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:05:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:05:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:05:03 +0000 UTC  }],Message:,Reason:,HostIP:72.2.112.101,PodIP:,StartTime:2019-03-26 06:05:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:05:04.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-tw9p2" for this suite.
Mar 26 06:05:10.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:05:10.406: INFO: namespace: e2e-tests-deployment-tw9p2, resource: bindings, ignored listing per whitelist
Mar 26 06:05:10.767: INFO: namespace e2e-tests-deployment-tw9p2 deletion completed in 6.523460708s

• [SLOW TEST:9.404 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:05:10.770: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 06:05:11.209: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d47527e-4f8d-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-ntcvd" to be "success or failure"
Mar 26 06:05:11.255: INFO: Pod "downwardapi-volume-1d47527e-4f8d-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 45.353738ms
Mar 26 06:05:13.281: INFO: Pod "downwardapi-volume-1d47527e-4f8d-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071236888s
Mar 26 06:05:15.294: INFO: Pod "downwardapi-volume-1d47527e-4f8d-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.083935701s
STEP: Saw pod success
Mar 26 06:05:15.294: INFO: Pod "downwardapi-volume-1d47527e-4f8d-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:05:15.299: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod downwardapi-volume-1d47527e-4f8d-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 06:05:15.370: INFO: Waiting for pod downwardapi-volume-1d47527e-4f8d-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:05:15.397: INFO: Pod downwardapi-volume-1d47527e-4f8d-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:05:15.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ntcvd" for this suite.
Mar 26 06:05:21.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:05:21.926: INFO: namespace: e2e-tests-downward-api-ntcvd, resource: bindings, ignored listing per whitelist
Mar 26 06:05:21.932: INFO: namespace e2e-tests-downward-api-ntcvd deletion completed in 6.518284869s

• [SLOW TEST:11.162 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:05:21.934: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-23de1003-4f8d-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 06:05:22.267: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-23df474d-4f8d-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-mg557" to be "success or failure"
Mar 26 06:05:22.279: INFO: Pod "pod-projected-secrets-23df474d-4f8d-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 11.563902ms
Mar 26 06:05:24.295: INFO: Pod "pod-projected-secrets-23df474d-4f8d-11e9-8fea-5694fc6fbac7": Phase="Running", Reason="", readiness=true. Elapsed: 2.027278694s
Mar 26 06:05:26.318: INFO: Pod "pod-projected-secrets-23df474d-4f8d-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050422652s
STEP: Saw pod success
Mar 26 06:05:26.318: INFO: Pod "pod-projected-secrets-23df474d-4f8d-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:05:26.327: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-projected-secrets-23df474d-4f8d-11e9-8fea-5694fc6fbac7 container secret-volume-test: <nil>
STEP: delete the pod
Mar 26 06:05:26.462: INFO: Waiting for pod pod-projected-secrets-23df474d-4f8d-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:05:26.467: INFO: Pod pod-projected-secrets-23df474d-4f8d-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:05:26.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mg557" for this suite.
Mar 26 06:05:32.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:05:32.924: INFO: namespace: e2e-tests-projected-mg557, resource: bindings, ignored listing per whitelist
Mar 26 06:05:32.930: INFO: namespace e2e-tests-projected-mg557 deletion completed in 6.442082698s

• [SLOW TEST:10.997 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:05:32.933: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 26 06:05:33.312: INFO: Waiting up to 5m0s for pod "downward-api-2a7485af-4f8d-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-chggl" to be "success or failure"
Mar 26 06:05:33.356: INFO: Pod "downward-api-2a7485af-4f8d-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 29.640159ms
Mar 26 06:05:35.380: INFO: Pod "downward-api-2a7485af-4f8d-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053469837s
STEP: Saw pod success
Mar 26 06:05:35.380: INFO: Pod "downward-api-2a7485af-4f8d-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:05:35.393: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod downward-api-2a7485af-4f8d-11e9-8fea-5694fc6fbac7 container dapi-container: <nil>
STEP: delete the pod
Mar 26 06:05:35.493: INFO: Waiting for pod downward-api-2a7485af-4f8d-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:05:35.513: INFO: Pod downward-api-2a7485af-4f8d-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:05:35.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-chggl" for this suite.
Mar 26 06:05:41.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:05:41.670: INFO: namespace: e2e-tests-downward-api-chggl, resource: bindings, ignored listing per whitelist
Mar 26 06:05:41.956: INFO: namespace e2e-tests-downward-api-chggl deletion completed in 6.414834284s

• [SLOW TEST:9.024 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:05:41.958: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ndw9v
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 26 06:05:42.261: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 26 06:06:06.884: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.48:8080/dial?request=hostName&protocol=udp&host=10.42.0.48&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-ndw9v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:06:06.884: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:06:07.065: INFO: Waiting for endpoints: map[]
Mar 26 06:06:07.073: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.48:8080/dial?request=hostName&protocol=udp&host=10.42.2.37&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-ndw9v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:06:07.073: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:06:07.262: INFO: Waiting for endpoints: map[]
Mar 26 06:06:07.269: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.48:8080/dial?request=hostName&protocol=udp&host=10.42.4.26&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-ndw9v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:06:07.270: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:06:07.450: INFO: Waiting for endpoints: map[]
Mar 26 06:06:07.456: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.48:8080/dial?request=hostName&protocol=udp&host=10.42.1.47&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-ndw9v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:06:07.456: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:06:07.628: INFO: Waiting for endpoints: map[]
Mar 26 06:06:07.651: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.48:8080/dial?request=hostName&protocol=udp&host=10.42.3.25&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-ndw9v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:06:07.651: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:06:07.898: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:06:07.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ndw9v" for this suite.
Mar 26 06:06:31.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:06:32.206: INFO: namespace: e2e-tests-pod-network-test-ndw9v, resource: bindings, ignored listing per whitelist
Mar 26 06:06:32.304: INFO: namespace e2e-tests-pod-network-test-ndw9v deletion completed in 24.395301297s

• [SLOW TEST:50.347 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:06:32.306: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:06:32.682: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4dcd9bb8-4f8d-11e9-b22a-90b8d090d774", Controller:(*bool)(0xc422e1d68e), BlockOwnerDeletion:(*bool)(0xc422e1d68f)}}
Mar 26 06:06:32.717: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"4dc5067e-4f8d-11e9-b22a-90b8d090d774", Controller:(*bool)(0xc422e1dade), BlockOwnerDeletion:(*bool)(0xc422e1dadf)}}
Mar 26 06:06:32.759: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4dc7ddbf-4f8d-11e9-b22a-90b8d090d774", Controller:(*bool)(0xc421eca15e), BlockOwnerDeletion:(*bool)(0xc421eca15f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:06:37.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4vxkj" for this suite.
Mar 26 06:06:43.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:06:43.925: INFO: namespace: e2e-tests-gc-4vxkj, resource: bindings, ignored listing per whitelist
Mar 26 06:06:44.085: INFO: namespace e2e-tests-gc-4vxkj deletion completed in 6.273182587s

• [SLOW TEST:11.780 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:06:44.088: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 26 06:06:44.373: INFO: Waiting up to 5m0s for pod "pod-54d085b2-4f8d-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-m8vf4" to be "success or failure"
Mar 26 06:06:44.402: INFO: Pod "pod-54d085b2-4f8d-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 29.032845ms
Mar 26 06:06:46.408: INFO: Pod "pod-54d085b2-4f8d-11e9-8fea-5694fc6fbac7": Phase="Running", Reason="", readiness=true. Elapsed: 2.034707608s
Mar 26 06:06:48.416: INFO: Pod "pod-54d085b2-4f8d-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04254143s
STEP: Saw pod success
Mar 26 06:06:48.416: INFO: Pod "pod-54d085b2-4f8d-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:06:48.423: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-54d085b2-4f8d-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 06:06:48.534: INFO: Waiting for pod pod-54d085b2-4f8d-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:06:48.550: INFO: Pod pod-54d085b2-4f8d-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:06:48.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-m8vf4" for this suite.
Mar 26 06:06:54.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:06:54.841: INFO: namespace: e2e-tests-emptydir-m8vf4, resource: bindings, ignored listing per whitelist
Mar 26 06:06:54.862: INFO: namespace e2e-tests-emptydir-m8vf4 deletion completed in 6.298226187s

• [SLOW TEST:10.774 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:06:54.863: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 26 06:06:55.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-65tfd'
Mar 26 06:06:55.404: INFO: stderr: ""
Mar 26 06:06:55.404: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 26 06:06:56.434: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 06:06:56.434: INFO: Found 0 / 1
Mar 26 06:06:57.411: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 06:06:57.411: INFO: Found 0 / 1
Mar 26 06:06:58.413: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 06:06:58.413: INFO: Found 1 / 1
Mar 26 06:06:58.413: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar 26 06:06:58.420: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 06:06:58.420: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 26 06:06:58.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 patch pod redis-master-lqmwk --namespace=e2e-tests-kubectl-65tfd -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 26 06:06:58.592: INFO: stderr: ""
Mar 26 06:06:58.592: INFO: stdout: "pod/redis-master-lqmwk patched\n"
STEP: checking annotations
Mar 26 06:06:58.597: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 06:06:58.597: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:06:58.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-65tfd" for this suite.
Mar 26 06:07:23.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:07:24.962: INFO: namespace: e2e-tests-kubectl-65tfd, resource: bindings, ignored listing per whitelist
Mar 26 06:07:26.705: INFO: namespace e2e-tests-kubectl-65tfd deletion completed in 28.090717753s

• [SLOW TEST:31.842 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:07:26.706: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-prdkl
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-prdkl
STEP: Deleting pre-stop pod
Mar 26 06:07:41.217: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:07:41.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-prdkl" for this suite.
Mar 26 06:08:25.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:08:25.420: INFO: namespace: e2e-tests-prestop-prdkl, resource: bindings, ignored listing per whitelist
Mar 26 06:08:25.707: INFO: namespace e2e-tests-prestop-prdkl deletion completed in 44.403683706s

• [SLOW TEST:59.001 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:08:25.708: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 26 06:08:25.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-hwz4j'
Mar 26 06:08:26.086: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 26 06:08:26.086: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Mar 26 06:08:28.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-hwz4j'
Mar 26 06:08:28.539: INFO: stderr: ""
Mar 26 06:08:28.539: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:08:28.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hwz4j" for this suite.
Mar 26 06:08:50.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:08:50.775: INFO: namespace: e2e-tests-kubectl-hwz4j, resource: bindings, ignored listing per whitelist
Mar 26 06:08:50.924: INFO: namespace e2e-tests-kubectl-hwz4j deletion completed in 22.348296697s

• [SLOW TEST:25.216 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:08:50.927: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 26 06:08:51.290: INFO: PodSpec: initContainers in spec.initContainers
Mar 26 06:09:38.774: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-a07aea0d-4f8d-11e9-8fea-5694fc6fbac7", GenerateName:"", Namespace:"e2e-tests-init-container-6c6xs", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-6c6xs/pods/pod-init-a07aea0d-4f8d-11e9-8fea-5694fc6fbac7", UID:"a07bbab6-4f8d-11e9-b22a-90b8d090d774", ResourceVersion:"39245", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63689177331, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"290377176", "name":"foo"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.1.51/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-m5lpv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420888840), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m5lpv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m5lpv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m5lpv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421145d68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-conformance-cluster-1-12-etcd-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc42213d800), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421145de0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421145e00)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421145e08), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689177331, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689177331, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689177331, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689177331, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"72.2.112.101", PodIP:"10.42.1.51", StartTime:(*v1.Time)(0xc4229936e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4224659d0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc422465a40)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://6ede91ee0285252a9800544a2877a63a77b72df0f1f87f6464add039804fa17e"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc422993720), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc422993700), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:09:38.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6c6xs" for this suite.
Mar 26 06:10:02.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:10:02.951: INFO: namespace: e2e-tests-init-container-6c6xs, resource: bindings, ignored listing per whitelist
Mar 26 06:10:03.240: INFO: namespace e2e-tests-init-container-6c6xs deletion completed in 24.362353171s

• [SLOW TEST:72.314 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:10:03.242: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar 26 06:10:03.496: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-414927603 proxy --unix-socket=/tmp/kubectl-proxy-unix705787830/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:10:03.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8c26d" for this suite.
Mar 26 06:10:09.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:10:09.953: INFO: namespace: e2e-tests-kubectl-8c26d, resource: bindings, ignored listing per whitelist
Mar 26 06:10:10.285: INFO: namespace e2e-tests-kubectl-8c26d deletion completed in 6.573876934s

• [SLOW TEST:7.044 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:10:10.287: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-cfea4aa1-4f8d-11e9-8fea-5694fc6fbac7
STEP: Creating secret with name s-test-opt-upd-cfea4b0b-4f8d-11e9-8fea-5694fc6fbac7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-cfea4aa1-4f8d-11e9-8fea-5694fc6fbac7
STEP: Updating secret s-test-opt-upd-cfea4b0b-4f8d-11e9-8fea-5694fc6fbac7
STEP: Creating secret with name s-test-opt-create-cfea4b42-4f8d-11e9-8fea-5694fc6fbac7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:10:15.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9v85m" for this suite.
Mar 26 06:10:39.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:10:39.442: INFO: namespace: e2e-tests-secrets-9v85m, resource: bindings, ignored listing per whitelist
Mar 26 06:10:39.661: INFO: namespace e2e-tests-secrets-9v85m deletion completed in 24.322813964s

• [SLOW TEST:29.375 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:10:39.663: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 26 06:10:39.878: INFO: namespace e2e-tests-kubectl-7t2ld
Mar 26 06:10:39.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-7t2ld'
Mar 26 06:10:40.365: INFO: stderr: ""
Mar 26 06:10:40.365: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 26 06:10:41.394: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 06:10:41.395: INFO: Found 1 / 1
Mar 26 06:10:41.395: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 26 06:10:41.439: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 06:10:41.439: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 26 06:10:41.439: INFO: wait on redis-master startup in e2e-tests-kubectl-7t2ld 
Mar 26 06:10:41.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 logs redis-master-sjjmm redis-master --namespace=e2e-tests-kubectl-7t2ld'
Mar 26 06:10:41.678: INFO: stderr: ""
Mar 26 06:10:41.678: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 Mar 06:10:41.271 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 Mar 06:10:41.271 # Server started, Redis version 3.2.12\n1:M 26 Mar 06:10:41.271 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 Mar 06:10:41.271 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar 26 06:10:41.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-7t2ld'
Mar 26 06:10:41.925: INFO: stderr: ""
Mar 26 06:10:41.925: INFO: stdout: "service/rm2 exposed\n"
Mar 26 06:10:41.942: INFO: Service rm2 in namespace e2e-tests-kubectl-7t2ld found.
STEP: exposing service
Mar 26 06:10:43.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-7t2ld'
Mar 26 06:10:44.272: INFO: stderr: ""
Mar 26 06:10:44.272: INFO: stdout: "service/rm3 exposed\n"
Mar 26 06:10:44.288: INFO: Service rm3 in namespace e2e-tests-kubectl-7t2ld found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:10:46.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7t2ld" for this suite.
Mar 26 06:11:10.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:11:10.481: INFO: namespace: e2e-tests-kubectl-7t2ld, resource: bindings, ignored listing per whitelist
Mar 26 06:11:10.657: INFO: namespace e2e-tests-kubectl-7t2ld deletion completed in 24.316457706s

• [SLOW TEST:30.994 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:11:10.658: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar 26 06:11:10.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 --namespace=e2e-tests-kubectl-zjqvr run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 26 06:11:13.296: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 26 06:11:13.296: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:11:15.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zjqvr" for this suite.
Mar 26 06:11:21.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:11:21.715: INFO: namespace: e2e-tests-kubectl-zjqvr, resource: bindings, ignored listing per whitelist
Mar 26 06:11:21.786: INFO: namespace e2e-tests-kubectl-zjqvr deletion completed in 6.440451407s

• [SLOW TEST:11.128 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:11:21.788: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-fa5234d9-4f8d-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:11:22.077: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fa556afc-4f8d-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-72nrr" to be "success or failure"
Mar 26 06:11:22.093: INFO: Pod "pod-projected-configmaps-fa556afc-4f8d-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.220553ms
Mar 26 06:11:24.101: INFO: Pod "pod-projected-configmaps-fa556afc-4f8d-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023109613s
STEP: Saw pod success
Mar 26 06:11:24.101: INFO: Pod "pod-projected-configmaps-fa556afc-4f8d-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:11:24.108: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-projected-configmaps-fa556afc-4f8d-11e9-8fea-5694fc6fbac7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:11:24.162: INFO: Waiting for pod pod-projected-configmaps-fa556afc-4f8d-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:11:24.178: INFO: Pod pod-projected-configmaps-fa556afc-4f8d-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:11:24.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-72nrr" for this suite.
Mar 26 06:11:30.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:11:30.620: INFO: namespace: e2e-tests-projected-72nrr, resource: bindings, ignored listing per whitelist
Mar 26 06:11:30.654: INFO: namespace e2e-tests-projected-72nrr deletion completed in 6.438513631s

• [SLOW TEST:8.867 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:11:30.656: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ffa72aac-4f8d-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:11:31.000: INFO: Waiting up to 5m0s for pod "pod-configmaps-ffa87d4a-4f8d-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-configmap-fdz44" to be "success or failure"
Mar 26 06:11:31.040: INFO: Pod "pod-configmaps-ffa87d4a-4f8d-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 39.011106ms
Mar 26 06:11:33.073: INFO: Pod "pod-configmaps-ffa87d4a-4f8d-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072912703s
Mar 26 06:11:35.122: INFO: Pod "pod-configmaps-ffa87d4a-4f8d-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.121650027s
STEP: Saw pod success
Mar 26 06:11:35.123: INFO: Pod "pod-configmaps-ffa87d4a-4f8d-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:11:35.133: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-configmaps-ffa87d4a-4f8d-11e9-8fea-5694fc6fbac7 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:11:35.217: INFO: Waiting for pod pod-configmaps-ffa87d4a-4f8d-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:11:35.224: INFO: Pod pod-configmaps-ffa87d4a-4f8d-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:11:35.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fdz44" for this suite.
Mar 26 06:11:41.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:11:41.361: INFO: namespace: e2e-tests-configmap-fdz44, resource: bindings, ignored listing per whitelist
Mar 26 06:11:41.621: INFO: namespace e2e-tests-configmap-fdz44 deletion completed in 6.387460119s

• [SLOW TEST:10.966 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:11:41.624: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 26 06:11:41.868: INFO: Waiting up to 5m0s for pod "pod-06239488-4f8e-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-nqksv" to be "success or failure"
Mar 26 06:11:41.898: INFO: Pod "pod-06239488-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 28.953584ms
Mar 26 06:11:43.916: INFO: Pod "pod-06239488-4f8e-11e9-8fea-5694fc6fbac7": Phase="Running", Reason="", readiness=true. Elapsed: 2.047346762s
Mar 26 06:11:45.932: INFO: Pod "pod-06239488-4f8e-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063196138s
STEP: Saw pod success
Mar 26 06:11:45.932: INFO: Pod "pod-06239488-4f8e-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:11:45.957: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-06239488-4f8e-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 06:11:46.070: INFO: Waiting for pod pod-06239488-4f8e-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:11:46.080: INFO: Pod pod-06239488-4f8e-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:11:46.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nqksv" for this suite.
Mar 26 06:11:52.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:11:52.340: INFO: namespace: e2e-tests-emptydir-nqksv, resource: bindings, ignored listing per whitelist
Mar 26 06:11:52.362: INFO: namespace e2e-tests-emptydir-nqksv deletion completed in 6.258581321s

• [SLOW TEST:10.738 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:11:52.365: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0c881b79-4f8e-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 06:11:52.614: INFO: Waiting up to 5m0s for pod "pod-secrets-0c8c5b3b-4f8e-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-secrets-49mpk" to be "success or failure"
Mar 26 06:11:52.753: INFO: Pod "pod-secrets-0c8c5b3b-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 139.079349ms
Mar 26 06:11:54.778: INFO: Pod "pod-secrets-0c8c5b3b-4f8e-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.164147556s
STEP: Saw pod success
Mar 26 06:11:54.779: INFO: Pod "pod-secrets-0c8c5b3b-4f8e-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:11:54.785: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-secrets-0c8c5b3b-4f8e-11e9-8fea-5694fc6fbac7 container secret-volume-test: <nil>
STEP: delete the pod
Mar 26 06:11:54.862: INFO: Waiting for pod pod-secrets-0c8c5b3b-4f8e-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:11:54.883: INFO: Pod pod-secrets-0c8c5b3b-4f8e-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:11:54.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-49mpk" for this suite.
Mar 26 06:12:00.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:12:01.218: INFO: namespace: e2e-tests-secrets-49mpk, resource: bindings, ignored listing per whitelist
Mar 26 06:12:01.277: INFO: namespace e2e-tests-secrets-49mpk deletion completed in 6.371744336s

• [SLOW TEST:8.913 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:12:01.281: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-11dae2f2-4f8e-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 06:12:01.537: INFO: Waiting up to 5m0s for pod "pod-secrets-11dc1466-4f8e-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-secrets-6tpp7" to be "success or failure"
Mar 26 06:12:01.565: INFO: Pod "pod-secrets-11dc1466-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 27.57579ms
Mar 26 06:12:03.594: INFO: Pod "pod-secrets-11dc1466-4f8e-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.056411563s
STEP: Saw pod success
Mar 26 06:12:03.594: INFO: Pod "pod-secrets-11dc1466-4f8e-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:12:03.601: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-secrets-11dc1466-4f8e-11e9-8fea-5694fc6fbac7 container secret-volume-test: <nil>
STEP: delete the pod
Mar 26 06:12:03.686: INFO: Waiting for pod pod-secrets-11dc1466-4f8e-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:12:03.697: INFO: Pod pod-secrets-11dc1466-4f8e-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:12:03.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6tpp7" for this suite.
Mar 26 06:12:09.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:12:09.986: INFO: namespace: e2e-tests-secrets-6tpp7, resource: bindings, ignored listing per whitelist
Mar 26 06:12:10.053: INFO: namespace e2e-tests-secrets-6tpp7 deletion completed in 6.340769201s

• [SLOW TEST:8.773 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:12:10.054: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 26 06:12:10.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-x2nqk'
Mar 26 06:12:10.516: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 26 06:12:10.516: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar 26 06:12:10.586: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-m67mn]
Mar 26 06:12:10.586: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-m67mn" in namespace "e2e-tests-kubectl-x2nqk" to be "running and ready"
Mar 26 06:12:10.613: INFO: Pod "e2e-test-nginx-rc-m67mn": Phase="Pending", Reason="", readiness=false. Elapsed: 26.812694ms
Mar 26 06:12:12.620: INFO: Pod "e2e-test-nginx-rc-m67mn": Phase="Running", Reason="", readiness=true. Elapsed: 2.034052489s
Mar 26 06:12:12.620: INFO: Pod "e2e-test-nginx-rc-m67mn" satisfied condition "running and ready"
Mar 26 06:12:12.620: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-m67mn]
Mar 26 06:12:12.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-x2nqk'
Mar 26 06:12:12.825: INFO: stderr: ""
Mar 26 06:12:12.825: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Mar 26 06:12:12.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-x2nqk'
Mar 26 06:12:13.025: INFO: stderr: ""
Mar 26 06:12:13.025: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:12:13.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x2nqk" for this suite.
Mar 26 06:12:37.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:12:37.376: INFO: namespace: e2e-tests-kubectl-x2nqk, resource: bindings, ignored listing per whitelist
Mar 26 06:12:37.388: INFO: namespace e2e-tests-kubectl-x2nqk deletion completed in 24.273021667s

• [SLOW TEST:27.334 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:12:37.394: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-2762b8ae-4f8e-11e9-8fea-5694fc6fbac7
STEP: Creating configMap with name cm-test-opt-upd-2762b90d-4f8e-11e9-8fea-5694fc6fbac7
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2762b8ae-4f8e-11e9-8fea-5694fc6fbac7
STEP: Updating configmap cm-test-opt-upd-2762b90d-4f8e-11e9-8fea-5694fc6fbac7
STEP: Creating configMap with name cm-test-opt-create-2762b926-4f8e-11e9-8fea-5694fc6fbac7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:14:01.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-55954" for this suite.
Mar 26 06:14:25.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:14:25.389: INFO: namespace: e2e-tests-configmap-55954, resource: bindings, ignored listing per whitelist
Mar 26 06:14:25.389: INFO: namespace e2e-tests-configmap-55954 deletion completed in 24.348525108s

• [SLOW TEST:107.995 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:14:25.398: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-67c96905-4f8e-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 06:14:25.697: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-67cb4da8-4f8e-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-k9w8p" to be "success or failure"
Mar 26 06:14:25.759: INFO: Pod "pod-projected-secrets-67cb4da8-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 61.309187ms
Mar 26 06:14:27.776: INFO: Pod "pod-projected-secrets-67cb4da8-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077828289s
Mar 26 06:14:29.783: INFO: Pod "pod-projected-secrets-67cb4da8-4f8e-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.085689618s
STEP: Saw pod success
Mar 26 06:14:29.784: INFO: Pod "pod-projected-secrets-67cb4da8-4f8e-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:14:29.789: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-projected-secrets-67cb4da8-4f8e-11e9-8fea-5694fc6fbac7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 26 06:14:29.888: INFO: Waiting for pod pod-projected-secrets-67cb4da8-4f8e-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:14:29.902: INFO: Pod pod-projected-secrets-67cb4da8-4f8e-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:14:29.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k9w8p" for this suite.
Mar 26 06:14:36.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:14:36.158: INFO: namespace: e2e-tests-projected-k9w8p, resource: bindings, ignored listing per whitelist
Mar 26 06:14:36.383: INFO: namespace e2e-tests-projected-k9w8p deletion completed in 6.453771012s

• [SLOW TEST:10.986 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:14:36.386: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:14:36.829: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 26 06:14:36.852: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 26 06:14:41.859: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 26 06:14:41.859: INFO: Creating deployment "test-rolling-update-deployment"
Mar 26 06:14:41.872: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 26 06:14:41.888: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 26 06:14:43.961: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 26 06:14:43.978: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689177682, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689177682, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689177683, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689177681, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 06:14:45.986: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 26 06:14:46.003: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-wn2tn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wn2tn/deployments/test-rolling-update-deployment,UID:716f5503-4f8e-11e9-b22a-90b8d090d774,ResourceVersion:40273,Generation:1,CreationTimestamp:2019-03-26 06:14:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-26 06:14:42 +0000 UTC 2019-03-26 06:14:42 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-26 06:14:44 +0000 UTC 2019-03-26 06:14:41 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 26 06:14:46.024: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-wn2tn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wn2tn/replicasets/test-rolling-update-deployment-65b7695dcf,UID:71764bb2-4f8e-11e9-b22a-90b8d090d774,ResourceVersion:40264,Generation:1,CreationTimestamp:2019-03-26 06:14:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 716f5503-4f8e-11e9-b22a-90b8d090d774 0xc42151b567 0xc42151b568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 26 06:14:46.024: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 26 06:14:46.024: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-wn2tn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wn2tn/replicasets/test-rolling-update-controller,UID:6e6fee30-4f8e-11e9-b22a-90b8d090d774,ResourceVersion:40272,Generation:2,CreationTimestamp:2019-03-26 06:14:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 716f5503-4f8e-11e9-b22a-90b8d090d774 0xc42151afae 0xc42151afaf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 06:14:46.044: INFO: Pod "test-rolling-update-deployment-65b7695dcf-8gdql" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-8gdql,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-wn2tn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wn2tn/pods/test-rolling-update-deployment-65b7695dcf-8gdql,UID:7178bcf4-4f8e-11e9-b22a-90b8d090d774,ResourceVersion:40263,Generation:0,CreationTimestamp:2019-03-26 06:14:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.59/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 71764bb2-4f8e-11e9-b22a-90b8d090d774 0xc420fa62b7 0xc420fa62b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8cxlj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8cxlj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-8cxlj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420fa63a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420fa63c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:14:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:14:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:14:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:14:41 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.8,PodIP:10.42.0.59,StartTime:2019-03-26 06:14:41 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-26 06:14:43 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://51c39c9e0d99121bd75c05089b20876b95bc9cd49cdc086b71323c81ea7edb66}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:14:46.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-wn2tn" for this suite.
Mar 26 06:14:52.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:14:52.594: INFO: namespace: e2e-tests-deployment-wn2tn, resource: bindings, ignored listing per whitelist
Mar 26 06:14:52.594: INFO: namespace e2e-tests-deployment-wn2tn deletion completed in 6.533981056s

• [SLOW TEST:16.209 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:14:52.595: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7808cde1-4f8e-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:14:52.982: INFO: Waiting up to 5m0s for pod "pod-configmaps-780b06c5-4f8e-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-configmap-j9m2k" to be "success or failure"
Mar 26 06:14:53.028: INFO: Pod "pod-configmaps-780b06c5-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 45.219428ms
Mar 26 06:14:55.039: INFO: Pod "pod-configmaps-780b06c5-4f8e-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.056287732s
STEP: Saw pod success
Mar 26 06:14:55.039: INFO: Pod "pod-configmaps-780b06c5-4f8e-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:14:55.045: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-configmaps-780b06c5-4f8e-11e9-8fea-5694fc6fbac7 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:14:55.140: INFO: Waiting for pod pod-configmaps-780b06c5-4f8e-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:14:55.148: INFO: Pod pod-configmaps-780b06c5-4f8e-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:14:55.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-j9m2k" for this suite.
Mar 26 06:15:01.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:15:01.787: INFO: namespace: e2e-tests-configmap-j9m2k, resource: bindings, ignored listing per whitelist
Mar 26 06:15:01.797: INFO: namespace e2e-tests-configmap-j9m2k deletion completed in 6.627265849s

• [SLOW TEST:9.204 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:15:01.819: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7d9a6565-4f8e-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:15:02.376: INFO: Waiting up to 5m0s for pod "pod-configmaps-7da09a27-4f8e-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-configmap-tn4jk" to be "success or failure"
Mar 26 06:15:02.434: INFO: Pod "pod-configmaps-7da09a27-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 56.388911ms
Mar 26 06:15:04.441: INFO: Pod "pod-configmaps-7da09a27-4f8e-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.063936158s
STEP: Saw pod success
Mar 26 06:15:04.442: INFO: Pod "pod-configmaps-7da09a27-4f8e-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:15:04.454: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-configmaps-7da09a27-4f8e-11e9-8fea-5694fc6fbac7 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:15:04.550: INFO: Waiting for pod pod-configmaps-7da09a27-4f8e-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:15:04.603: INFO: Pod pod-configmaps-7da09a27-4f8e-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:15:04.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tn4jk" for this suite.
Mar 26 06:15:10.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:15:10.871: INFO: namespace: e2e-tests-configmap-tn4jk, resource: bindings, ignored listing per whitelist
Mar 26 06:15:10.918: INFO: namespace e2e-tests-configmap-tn4jk deletion completed in 6.298492689s

• [SLOW TEST:9.100 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:15:10.920: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-82e1ad92-4f8e-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:15:11.159: INFO: Waiting up to 5m0s for pod "pod-configmaps-82e2edf4-4f8e-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-configmap-xrsr6" to be "success or failure"
Mar 26 06:15:11.191: INFO: Pod "pod-configmaps-82e2edf4-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 31.698668ms
Mar 26 06:15:13.198: INFO: Pod "pod-configmaps-82e2edf4-4f8e-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038778819s
STEP: Saw pod success
Mar 26 06:15:13.198: INFO: Pod "pod-configmaps-82e2edf4-4f8e-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:15:13.251: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-configmaps-82e2edf4-4f8e-11e9-8fea-5694fc6fbac7 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:15:13.336: INFO: Waiting for pod pod-configmaps-82e2edf4-4f8e-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:15:13.345: INFO: Pod pod-configmaps-82e2edf4-4f8e-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:15:13.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xrsr6" for this suite.
Mar 26 06:15:19.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:15:19.579: INFO: namespace: e2e-tests-configmap-xrsr6, resource: bindings, ignored listing per whitelist
Mar 26 06:15:19.715: INFO: namespace e2e-tests-configmap-xrsr6 deletion completed in 6.34754629s

• [SLOW TEST:8.795 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:15:19.716: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-trn2z
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-trn2z to expose endpoints map[]
Mar 26 06:15:20.034: INFO: Get endpoints failed (23.031368ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar 26 06:15:21.050: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-trn2z exposes endpoints map[] (1.039444888s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-trn2z
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-trn2z to expose endpoints map[pod1:[100]]
Mar 26 06:15:23.221: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-trn2z exposes endpoints map[pod1:[100]] (2.15631387s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-trn2z
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-trn2z to expose endpoints map[pod1:[100] pod2:[101]]
Mar 26 06:15:25.370: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-trn2z exposes endpoints map[pod2:[101] pod1:[100]] (2.140113442s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-trn2z
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-trn2z to expose endpoints map[pod2:[101]]
Mar 26 06:15:25.514: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-trn2z exposes endpoints map[pod2:[101]] (84.570733ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-trn2z
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-trn2z to expose endpoints map[]
Mar 26 06:15:26.627: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-trn2z exposes endpoints map[] (1.087145854s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:15:26.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-trn2z" for this suite.
Mar 26 06:15:32.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:15:33.157: INFO: namespace: e2e-tests-services-trn2z, resource: bindings, ignored listing per whitelist
Mar 26 06:15:33.173: INFO: namespace e2e-tests-services-trn2z deletion completed in 6.309283526s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:13.458 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:15:33.175: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 06:15:33.439: INFO: Waiting up to 5m0s for pod "downwardapi-volume-902c1052-4f8e-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-mqcrk" to be "success or failure"
Mar 26 06:15:33.467: INFO: Pod "downwardapi-volume-902c1052-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 27.277577ms
Mar 26 06:15:35.481: INFO: Pod "downwardapi-volume-902c1052-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041802528s
Mar 26 06:15:37.513: INFO: Pod "downwardapi-volume-902c1052-4f8e-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.073316262s
STEP: Saw pod success
Mar 26 06:15:37.513: INFO: Pod "downwardapi-volume-902c1052-4f8e-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:15:37.522: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod downwardapi-volume-902c1052-4f8e-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 06:15:37.607: INFO: Waiting for pod downwardapi-volume-902c1052-4f8e-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:15:37.649: INFO: Pod downwardapi-volume-902c1052-4f8e-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:15:37.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mqcrk" for this suite.
Mar 26 06:15:43.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:15:43.868: INFO: namespace: e2e-tests-downward-api-mqcrk, resource: bindings, ignored listing per whitelist
Mar 26 06:15:44.103: INFO: namespace e2e-tests-downward-api-mqcrk deletion completed in 6.431363115s

• [SLOW TEST:10.929 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:15:44.105: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-69fw
STEP: Creating a pod to test atomic-volume-subpath
Mar 26 06:15:44.416: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-69fw" in namespace "e2e-tests-subpath-8kmrg" to be "success or failure"
Mar 26 06:15:44.436: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Pending", Reason="", readiness=false. Elapsed: 20.000074ms
Mar 26 06:15:46.453: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036471599s
Mar 26 06:15:48.460: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Running", Reason="", readiness=false. Elapsed: 4.043409462s
Mar 26 06:15:50.468: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Running", Reason="", readiness=false. Elapsed: 6.051624668s
Mar 26 06:15:52.475: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Running", Reason="", readiness=false. Elapsed: 8.05852277s
Mar 26 06:15:54.483: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Running", Reason="", readiness=false. Elapsed: 10.066075571s
Mar 26 06:15:56.509: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Running", Reason="", readiness=false. Elapsed: 12.092562653s
Mar 26 06:15:58.526: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Running", Reason="", readiness=false. Elapsed: 14.109761834s
Mar 26 06:16:00.541: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Running", Reason="", readiness=false. Elapsed: 16.124909702s
Mar 26 06:16:02.549: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Running", Reason="", readiness=false. Elapsed: 18.133004674s
Mar 26 06:16:04.563: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Running", Reason="", readiness=false. Elapsed: 20.147018349s
Mar 26 06:16:06.570: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Running", Reason="", readiness=false. Elapsed: 22.153599256s
Mar 26 06:16:08.580: INFO: Pod "pod-subpath-test-configmap-69fw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.163195936s
STEP: Saw pod success
Mar 26 06:16:08.580: INFO: Pod "pod-subpath-test-configmap-69fw" satisfied condition "success or failure"
Mar 26 06:16:08.586: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-subpath-test-configmap-69fw container test-container-subpath-configmap-69fw: <nil>
STEP: delete the pod
Mar 26 06:16:08.670: INFO: Waiting for pod pod-subpath-test-configmap-69fw to disappear
Mar 26 06:16:08.677: INFO: Pod pod-subpath-test-configmap-69fw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-69fw
Mar 26 06:16:08.677: INFO: Deleting pod "pod-subpath-test-configmap-69fw" in namespace "e2e-tests-subpath-8kmrg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:16:08.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8kmrg" for this suite.
Mar 26 06:16:14.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:16:14.778: INFO: namespace: e2e-tests-subpath-8kmrg, resource: bindings, ignored listing per whitelist
Mar 26 06:16:14.986: INFO: namespace e2e-tests-subpath-8kmrg deletion completed in 6.28812787s

• [SLOW TEST:30.881 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:16:14.989: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a91e1903-4f8e-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 06:16:15.317: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a9208d4e-4f8e-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-9f9cp" to be "success or failure"
Mar 26 06:16:15.365: INFO: Pod "pod-projected-secrets-a9208d4e-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 48.667733ms
Mar 26 06:16:17.377: INFO: Pod "pod-projected-secrets-a9208d4e-4f8e-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.060066421s
STEP: Saw pod success
Mar 26 06:16:17.377: INFO: Pod "pod-projected-secrets-a9208d4e-4f8e-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:16:17.387: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-projected-secrets-a9208d4e-4f8e-11e9-8fea-5694fc6fbac7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 26 06:16:17.601: INFO: Waiting for pod pod-projected-secrets-a9208d4e-4f8e-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:16:17.644: INFO: Pod pod-projected-secrets-a9208d4e-4f8e-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:16:17.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9f9cp" for this suite.
Mar 26 06:16:23.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:16:23.884: INFO: namespace: e2e-tests-projected-9f9cp, resource: bindings, ignored listing per whitelist
Mar 26 06:16:23.890: INFO: namespace e2e-tests-projected-9f9cp deletion completed in 6.235662933s

• [SLOW TEST:8.902 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:16:23.892: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 26 06:16:24.211: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 26 06:16:24.261: INFO: Waiting for terminating namespaces to be deleted...
Mar 26 06:16:24.268: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-control-1 before test
Mar 26 06:16:24.295: INFO: rke-kubedns-addon-deploy-job-69jrs from kube-system started at 2019-03-26 00:53:12 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.296: INFO: 	Container rke-kubedns-addon-pod ready: false, restart count 0
Mar 26 06:16:24.296: INFO: rke-network-plugin-deploy-job-xl4m5 from kube-system started at 2019-03-26 00:53:02 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.296: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 26 06:16:24.296: INFO: cattle-node-agent-hnjxf from cattle-system started at 2019-03-26 00:54:37 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.296: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:16:24.296: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-sw4jz from heptio-sonobuoy started at 2019-03-26 05:38:40 +0000 UTC (2 container statuses recorded)
Mar 26 06:16:24.296: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 26 06:16:24.297: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:16:24.297: INFO: calico-node-g2rd4 from kube-system started at 2019-03-26 00:53:07 +0000 UTC (2 container statuses recorded)
Mar 26 06:16:24.297: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:16:24.297: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:16:24.297: INFO: rke-metrics-addon-deploy-job-bsrr2 from kube-system started at 2019-03-26 00:53:23 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.297: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 26 06:16:24.297: INFO: rke-ingress-controller-deploy-job-w8l9x from kube-system started at 2019-03-26 00:53:35 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.297: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 26 06:16:24.297: INFO: nginx-ingress-controller-5qkcf from ingress-nginx started at 2019-03-26 05:38:03 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.297: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:16:24.297: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-etcd-1 before test
Mar 26 06:16:24.375: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-r228k from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:16:24.375: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 26 06:16:24.375: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:16:24.375: INFO: calico-node-zbl4q from kube-system started at 2019-03-26 00:53:07 +0000 UTC (2 container statuses recorded)
Mar 26 06:16:24.375: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:16:24.375: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:16:24.375: INFO: cattle-node-agent-88rnp from cattle-system started at 2019-03-26 00:54:01 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.376: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:16:24.376: INFO: nginx-ingress-controller-glb5c from ingress-nginx started at 2019-03-26 05:38:15 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.376: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:16:24.376: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-worker-1 before test
Mar 26 06:16:24.394: INFO: kube-dns-ddddcfcc8-75rhb from kube-system started at 2019-03-26 00:55:08 +0000 UTC (3 container statuses recorded)
Mar 26 06:16:24.394: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 06:16:24.395: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 06:16:24.395: INFO: 	Container sidecar ready: true, restart count 0
Mar 26 06:16:24.395: INFO: default-http-backend-5bdd9fdd69-b5f6t from ingress-nginx started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.395: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 26 06:16:24.395: INFO: cattle-cluster-agent-6f575d9bcf-rjz7h from cattle-system started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.395: INFO: 	Container cluster-register ready: true, restart count 0
Mar 26 06:16:24.395: INFO: calico-node-4hkk8 from kube-system started at 2019-03-26 00:54:48 +0000 UTC (2 container statuses recorded)
Mar 26 06:16:24.395: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:16:24.395: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:16:24.395: INFO: metrics-server-5444cf6dfc-jk9bb from kube-system started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.395: INFO: 	Container metrics-server ready: true, restart count 0
Mar 26 06:16:24.395: INFO: nginx-ingress-controller-hbcdq from ingress-nginx started at 2019-03-26 00:55:09 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.395: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:16:24.395: INFO: cattle-node-agent-2vwcr from cattle-system started at 2019-03-26 00:55:09 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.395: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:16:24.395: INFO: kube-dns-autoscaler-689f6f9756-vwph6 from kube-system started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.395: INFO: 	Container autoscaler ready: true, restart count 0
Mar 26 06:16:24.396: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-psbcr from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:16:24.396: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 26 06:16:24.396: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:16:24.396: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-worker1-1 before test
Mar 26 06:16:24.422: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-26 05:38:36 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.422: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 26 06:16:24.422: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-rb6hz from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:16:24.422: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 26 06:16:24.422: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:16:24.422: INFO: calico-node-4njnj from kube-system started at 2019-03-26 01:46:41 +0000 UTC (2 container statuses recorded)
Mar 26 06:16:24.422: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:16:24.422: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:16:24.427: INFO: cattle-node-agent-9qhk4 from cattle-system started at 2019-03-26 01:47:20 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.427: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:16:24.427: INFO: sonobuoy-e2e-job-2791eb3c35d44121 from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:16:24.427: INFO: 	Container e2e ready: true, restart count 0
Mar 26 06:16:24.427: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:16:24.427: INFO: nginx-ingress-controller-rsjr4 from ingress-nginx started at 2019-03-26 01:47:20 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.427: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:16:24.427: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-worker1-2 before test
Mar 26 06:16:24.444: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-l2r6z from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:16:24.445: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 26 06:16:24.445: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:16:24.445: INFO: calico-node-l244q from kube-system started at 2019-03-26 01:45:53 +0000 UTC (2 container statuses recorded)
Mar 26 06:16:24.445: INFO: 	Container calico-node ready: true, restart count 1
Mar 26 06:16:24.445: INFO: 	Container install-cni ready: true, restart count 1
Mar 26 06:16:24.445: INFO: nginx-ingress-controller-lvkkc from ingress-nginx started at 2019-03-26 01:46:33 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.445: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:16:24.445: INFO: cattle-node-agent-8rc72 from cattle-system started at 2019-03-26 01:46:33 +0000 UTC (1 container statuses recorded)
Mar 26 06:16:24.445: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:16:24.445: INFO: kube-dns-ddddcfcc8-8hxnz from kube-system started at 2019-03-26 01:46:46 +0000 UTC (3 container statuses recorded)
Mar 26 06:16:24.445: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 06:16:24.445: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 06:16:24.445: INFO: 	Container sidecar ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158f6dac96966bc0], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:16:25.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-jdfdw" for this suite.
Mar 26 06:16:31.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:16:31.662: INFO: namespace: e2e-tests-sched-pred-jdfdw, resource: bindings, ignored listing per whitelist
Mar 26 06:16:31.871: INFO: namespace e2e-tests-sched-pred-jdfdw deletion completed in 6.329478213s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.980 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:16:31.873: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:16:34.322: INFO: Waiting up to 5m0s for pod "client-envvars-b4702963-4f8e-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-pods-fb6bx" to be "success or failure"
Mar 26 06:16:34.386: INFO: Pod "client-envvars-b4702963-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 63.07619ms
Mar 26 06:16:36.392: INFO: Pod "client-envvars-b4702963-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069292724s
Mar 26 06:16:38.398: INFO: Pod "client-envvars-b4702963-4f8e-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.075869652s
STEP: Saw pod success
Mar 26 06:16:38.399: INFO: Pod "client-envvars-b4702963-4f8e-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:16:38.405: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod client-envvars-b4702963-4f8e-11e9-8fea-5694fc6fbac7 container env3cont: <nil>
STEP: delete the pod
Mar 26 06:16:38.470: INFO: Waiting for pod client-envvars-b4702963-4f8e-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:16:38.497: INFO: Pod client-envvars-b4702963-4f8e-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:16:38.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fb6bx" for this suite.
Mar 26 06:17:30.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:17:30.748: INFO: namespace: e2e-tests-pods-fb6bx, resource: bindings, ignored listing per whitelist
Mar 26 06:17:30.856: INFO: namespace e2e-tests-pods-fb6bx deletion completed in 52.325434417s

• [SLOW TEST:58.984 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:17:30.858: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-d65021ff-4f8e-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:17:31.139: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d651d1bd-4f8e-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-2h62w" to be "success or failure"
Mar 26 06:17:31.165: INFO: Pod "pod-projected-configmaps-d651d1bd-4f8e-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 25.654374ms
Mar 26 06:17:33.171: INFO: Pod "pod-projected-configmaps-d651d1bd-4f8e-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032402647s
STEP: Saw pod success
Mar 26 06:17:33.171: INFO: Pod "pod-projected-configmaps-d651d1bd-4f8e-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:17:33.177: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-projected-configmaps-d651d1bd-4f8e-11e9-8fea-5694fc6fbac7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:17:33.253: INFO: Waiting for pod pod-projected-configmaps-d651d1bd-4f8e-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:17:33.269: INFO: Pod pod-projected-configmaps-d651d1bd-4f8e-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:17:33.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2h62w" for this suite.
Mar 26 06:17:39.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:17:39.547: INFO: namespace: e2e-tests-projected-2h62w, resource: bindings, ignored listing per whitelist
Mar 26 06:17:39.562: INFO: namespace e2e-tests-projected-2h62w deletion completed in 6.270833478s

• [SLOW TEST:8.704 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:17:39.564: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:17:39.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 version --client'
Mar 26 06:17:39.852: INFO: stderr: ""
Mar 26 06:17:39.852: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar 26 06:17:39.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-jzsvm'
Mar 26 06:17:40.666: INFO: stderr: ""
Mar 26 06:17:40.666: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar 26 06:17:40.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-jzsvm'
Mar 26 06:17:41.500: INFO: stderr: ""
Mar 26 06:17:41.500: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 26 06:17:42.508: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 06:17:42.508: INFO: Found 0 / 1
Mar 26 06:17:43.507: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 06:17:43.507: INFO: Found 1 / 1
Mar 26 06:17:43.507: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 26 06:17:43.514: INFO: Selector matched 1 pods for map[app:redis]
Mar 26 06:17:43.514: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 26 06:17:43.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 describe pod redis-master-7v7h7 --namespace=e2e-tests-kubectl-jzsvm'
Mar 26 06:17:43.702: INFO: stderr: ""
Mar 26 06:17:43.702: INFO: stdout: "Name:               redis-master-7v7h7\nNamespace:          e2e-tests-kubectl-jzsvm\nPriority:           0\nPriorityClassName:  <none>\nNode:               k8s-conformance-cluster-1-12-control-1/72.2.113.8\nStart Time:         Tue, 26 Mar 2019 06:17:40 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.42.0.65/32\nStatus:             Running\nIP:                 10.42.0.65\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://9b1d8184aa98df065f92d29cdbdc3d5014a8096ad831357c1b43c67db5c43a6c\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 26 Mar 2019 06:17:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-286m7 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-286m7:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-286m7\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                             Message\n  ----    ------     ----  ----                                             -------\n  Normal  Scheduled  3s    default-scheduler                                Successfully assigned e2e-tests-kubectl-jzsvm/redis-master-7v7h7 to k8s-conformance-cluster-1-12-control-1\n  Normal  Pulled     1s    kubelet, k8s-conformance-cluster-1-12-control-1  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, k8s-conformance-cluster-1-12-control-1  Created container\n  Normal  Started    1s    kubelet, k8s-conformance-cluster-1-12-control-1  Started container\n"
Mar 26 06:17:43.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 describe rc redis-master --namespace=e2e-tests-kubectl-jzsvm'
Mar 26 06:17:43.925: INFO: stderr: ""
Mar 26 06:17:43.925: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-jzsvm\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-7v7h7\n"
Mar 26 06:17:43.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 describe service redis-master --namespace=e2e-tests-kubectl-jzsvm'
Mar 26 06:17:44.100: INFO: stderr: ""
Mar 26 06:17:44.100: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-jzsvm\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.43.69.67\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.42.0.65:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 26 06:17:44.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 describe node k8s-conformance-cluster-1-12-control-1'
Mar 26 06:17:44.339: INFO: stderr: ""
Mar 26 06:17:44.339: INFO: stdout: "Name:               k8s-conformance-cluster-1-12-control-1\nRoles:              controlplane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=k8s-conformance-cluster-1-12-control-1\n                    node-role.kubernetes.io/controlplane=true\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 72.2.113.8/22\n                    rke.cattle.io/external-ip: 72.2.113.8\n                    rke.cattle.io/internal-ip: 72.2.113.8\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 26 Mar 2019 00:52:50 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Tue, 26 Mar 2019 06:17:38 +0000   Tue, 26 Mar 2019 00:52:50 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Tue, 26 Mar 2019 06:17:38 +0000   Tue, 26 Mar 2019 00:52:50 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 26 Mar 2019 06:17:38 +0000   Tue, 26 Mar 2019 00:52:50 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 26 Mar 2019 06:17:38 +0000   Tue, 26 Mar 2019 00:52:50 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 26 Mar 2019 06:17:38 +0000   Tue, 26 Mar 2019 00:54:36 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  72.2.113.8\n  Hostname:    k8s-conformance-cluster-1-12-control-1\nCapacity:\n cpu:                1\n ephemeral-storage:  7688776Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1790180Ki\n pods:               110\nAllocatable:\n cpu:                1\n ephemeral-storage:  7085975950\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1687780Ki\n pods:               110\nSystem Info:\n Machine ID:                 3e608929fbd39b959f388bf468c9f0b1\n System UUID:                88ECBE8B-187B-6349-A406-846BC5204149\n Boot ID:                    89013972-c44a-4761-9b0e-932bf78d2349\n Kernel Version:             4.4.0-137-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.12.6\n Kube-Proxy Version:         v1.12.6\nPodCIDR:                     10.42.0.0/24\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  cattle-system              cattle-node-agent-hnjxf                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  e2e-tests-kubectl-jzsvm    redis-master-7v7h7                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-sw4jz    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  ingress-nginx              nginx-ingress-controller-5qkcf                             0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-g2rd4                                          250m (25%)    0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       250m (25%)  0 (0%)\n  memory    0 (0%)      0 (0%)\nEvents:     <none>\n"
Mar 26 06:17:44.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 describe namespace e2e-tests-kubectl-jzsvm'
Mar 26 06:17:44.527: INFO: stderr: ""
Mar 26 06:17:44.527: INFO: stdout: "Name:         e2e-tests-kubectl-jzsvm\nLabels:       e2e-framework=kubectl\n              e2e-run=69c77669-4f89-11e9-8fea-5694fc6fbac7\nAnnotations:  cattle.io/status:\n                {\"Conditions\":[{\"Type\":\"ResourceQuotaInit\",\"Status\":\"True\",\"Message\":\"\",\"LastUpdateTime\":\"2019-03-26T06:17:40Z\"},{\"Type\":\"InitialRolesPopu...\n              lifecycle.cattle.io/create.namespace-auth: true\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:17:44.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jzsvm" for this suite.
Mar 26 06:18:08.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:18:08.761: INFO: namespace: e2e-tests-kubectl-jzsvm, resource: bindings, ignored listing per whitelist
Mar 26 06:18:08.879: INFO: namespace e2e-tests-kubectl-jzsvm deletion completed in 24.339984457s

• [SLOW TEST:29.315 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:18:08.881: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qbdzr
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar 26 06:18:09.114: INFO: Found 0 stateful pods, waiting for 3
Mar 26 06:18:19.122: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 06:18:19.122: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 06:18:19.122: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 06:18:19.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qbdzr ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 06:18:19.453: INFO: stderr: ""
Mar 26 06:18:19.453: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 06:18:19.453: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 26 06:18:29.517: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar 26 06:18:39.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qbdzr ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 06:18:40.014: INFO: stderr: ""
Mar 26 06:18:40.014: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 06:18:40.014: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 06:18:50.058: INFO: Waiting for StatefulSet e2e-tests-statefulset-qbdzr/ss2 to complete update
Mar 26 06:18:50.058: INFO: Waiting for Pod e2e-tests-statefulset-qbdzr/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 06:18:50.058: INFO: Waiting for Pod e2e-tests-statefulset-qbdzr/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 06:19:00.092: INFO: Waiting for StatefulSet e2e-tests-statefulset-qbdzr/ss2 to complete update
Mar 26 06:19:00.092: INFO: Waiting for Pod e2e-tests-statefulset-qbdzr/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 06:19:10.073: INFO: Waiting for StatefulSet e2e-tests-statefulset-qbdzr/ss2 to complete update
Mar 26 06:19:10.073: INFO: Waiting for Pod e2e-tests-statefulset-qbdzr/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Mar 26 06:19:20.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qbdzr ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 06:19:20.409: INFO: stderr: ""
Mar 26 06:19:20.409: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 06:19:20.409: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 06:19:30.484: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar 26 06:19:40.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qbdzr ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 06:19:40.906: INFO: stderr: ""
Mar 26 06:19:40.906: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 06:19:40.906: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 06:20:00.951: INFO: Waiting for StatefulSet e2e-tests-statefulset-qbdzr/ss2 to complete update
Mar 26 06:20:00.951: INFO: Waiting for Pod e2e-tests-statefulset-qbdzr/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 26 06:20:10.966: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qbdzr
Mar 26 06:20:10.973: INFO: Scaling statefulset ss2 to 0
Mar 26 06:20:51.005: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 06:20:51.012: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:20:51.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qbdzr" for this suite.
Mar 26 06:20:59.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:20:59.217: INFO: namespace: e2e-tests-statefulset-qbdzr, resource: bindings, ignored listing per whitelist
Mar 26 06:20:59.337: INFO: namespace e2e-tests-statefulset-qbdzr deletion completed in 8.266603763s

• [SLOW TEST:170.457 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:20:59.339: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 06:20:59.525: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5288bc8f-4f8f-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-h58gc" to be "success or failure"
Mar 26 06:20:59.582: INFO: Pod "downwardapi-volume-5288bc8f-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 56.50881ms
Mar 26 06:21:01.589: INFO: Pod "downwardapi-volume-5288bc8f-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063271025s
Mar 26 06:21:03.596: INFO: Pod "downwardapi-volume-5288bc8f-4f8f-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06993553s
STEP: Saw pod success
Mar 26 06:21:03.596: INFO: Pod "downwardapi-volume-5288bc8f-4f8f-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:21:03.601: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod downwardapi-volume-5288bc8f-4f8f-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 06:21:03.689: INFO: Waiting for pod downwardapi-volume-5288bc8f-4f8f-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:21:03.723: INFO: Pod downwardapi-volume-5288bc8f-4f8f-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:21:03.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h58gc" for this suite.
Mar 26 06:21:09.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:21:09.916: INFO: namespace: e2e-tests-projected-h58gc, resource: bindings, ignored listing per whitelist
Mar 26 06:21:10.003: INFO: namespace e2e-tests-projected-h58gc deletion completed in 6.255746431s

• [SLOW TEST:10.665 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:21:10.005: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-58ecd266-4f8f-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:21:10.265: INFO: Waiting up to 5m0s for pod "pod-configmaps-58ee312c-4f8f-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-configmap-4z45j" to be "success or failure"
Mar 26 06:21:10.291: INFO: Pod "pod-configmaps-58ee312c-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 25.70345ms
Mar 26 06:21:12.297: INFO: Pod "pod-configmaps-58ee312c-4f8f-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032463414s
STEP: Saw pod success
Mar 26 06:21:12.298: INFO: Pod "pod-configmaps-58ee312c-4f8f-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:21:12.303: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-configmaps-58ee312c-4f8f-11e9-8fea-5694fc6fbac7 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:21:12.362: INFO: Waiting for pod pod-configmaps-58ee312c-4f8f-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:21:12.368: INFO: Pod pod-configmaps-58ee312c-4f8f-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:21:12.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4z45j" for this suite.
Mar 26 06:21:18.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:21:18.641: INFO: namespace: e2e-tests-configmap-4z45j, resource: bindings, ignored listing per whitelist
Mar 26 06:21:18.707: INFO: namespace e2e-tests-configmap-4z45j deletion completed in 6.321689091s

• [SLOW TEST:8.702 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:21:18.709: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar 26 06:21:18.891: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-414927603 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:21:19.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bdzm7" for this suite.
Mar 26 06:21:25.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:21:25.179: INFO: namespace: e2e-tests-kubectl-bdzm7, resource: bindings, ignored listing per whitelist
Mar 26 06:21:25.262: INFO: namespace e2e-tests-kubectl-bdzm7 deletion completed in 6.222146301s

• [SLOW TEST:6.554 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:21:25.264: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar 26 06:21:25.487: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xdld2,SelfLink:/api/v1/namespaces/e2e-tests-watch-xdld2/configmaps/e2e-watch-test-watch-closed,UID:62009121-4f8f-11e9-b22a-90b8d090d774,ResourceVersion:41854,Generation:0,CreationTimestamp:2019-03-26 06:21:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 26 06:21:25.487: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xdld2,SelfLink:/api/v1/namespaces/e2e-tests-watch-xdld2/configmaps/e2e-watch-test-watch-closed,UID:62009121-4f8f-11e9-b22a-90b8d090d774,ResourceVersion:41855,Generation:0,CreationTimestamp:2019-03-26 06:21:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 26 06:21:25.516: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xdld2,SelfLink:/api/v1/namespaces/e2e-tests-watch-xdld2/configmaps/e2e-watch-test-watch-closed,UID:62009121-4f8f-11e9-b22a-90b8d090d774,ResourceVersion:41856,Generation:0,CreationTimestamp:2019-03-26 06:21:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 26 06:21:25.516: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xdld2,SelfLink:/api/v1/namespaces/e2e-tests-watch-xdld2/configmaps/e2e-watch-test-watch-closed,UID:62009121-4f8f-11e9-b22a-90b8d090d774,ResourceVersion:41857,Generation:0,CreationTimestamp:2019-03-26 06:21:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:21:25.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-xdld2" for this suite.
Mar 26 06:21:31.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:21:31.604: INFO: namespace: e2e-tests-watch-xdld2, resource: bindings, ignored listing per whitelist
Mar 26 06:21:31.811: INFO: namespace e2e-tests-watch-xdld2 deletion completed in 6.28627948s

• [SLOW TEST:6.548 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:21:31.815: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar 26 06:21:32.576: INFO: Waiting up to 5m0s for pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-h5wjp" in namespace "e2e-tests-svcaccounts-nhbln" to be "success or failure"
Mar 26 06:21:32.603: INFO: Pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-h5wjp": Phase="Pending", Reason="", readiness=false. Elapsed: 27.005745ms
Mar 26 06:21:34.614: INFO: Pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-h5wjp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038307105s
Mar 26 06:21:36.623: INFO: Pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-h5wjp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046785082s
STEP: Saw pod success
Mar 26 06:21:36.623: INFO: Pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-h5wjp" satisfied condition "success or failure"
Mar 26 06:21:36.629: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-h5wjp container token-test: <nil>
STEP: delete the pod
Mar 26 06:21:36.685: INFO: Waiting for pod pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-h5wjp to disappear
Mar 26 06:21:36.703: INFO: Pod pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-h5wjp no longer exists
STEP: Creating a pod to test consume service account root CA
Mar 26 06:21:36.740: INFO: Waiting up to 5m0s for pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-m5gnx" in namespace "e2e-tests-svcaccounts-nhbln" to be "success or failure"
Mar 26 06:21:36.765: INFO: Pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-m5gnx": Phase="Pending", Reason="", readiness=false. Elapsed: 24.753364ms
Mar 26 06:21:38.778: INFO: Pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-m5gnx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036854661s
STEP: Saw pod success
Mar 26 06:21:38.778: INFO: Pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-m5gnx" satisfied condition "success or failure"
Mar 26 06:21:38.792: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-worker-1 pod pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-m5gnx container root-ca-test: <nil>
STEP: delete the pod
Mar 26 06:21:38.872: INFO: Waiting for pod pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-m5gnx to disappear
Mar 26 06:21:38.883: INFO: Pod pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-m5gnx no longer exists
STEP: Creating a pod to test consume service account namespace
Mar 26 06:21:38.916: INFO: Waiting up to 5m0s for pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-prpkb" in namespace "e2e-tests-svcaccounts-nhbln" to be "success or failure"
Mar 26 06:21:38.940: INFO: Pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-prpkb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.194325ms
Mar 26 06:21:40.949: INFO: Pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-prpkb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033456253s
STEP: Saw pod success
Mar 26 06:21:40.950: INFO: Pod "pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-prpkb" satisfied condition "success or failure"
Mar 26 06:21:40.959: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-worker1-2 pod pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-prpkb container namespace-test: <nil>
STEP: delete the pod
Mar 26 06:21:41.034: INFO: Waiting for pod pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-prpkb to disappear
Mar 26 06:21:41.052: INFO: Pod pod-service-account-663bc022-4f8f-11e9-8fea-5694fc6fbac7-prpkb no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:21:41.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-nhbln" for this suite.
Mar 26 06:21:47.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:21:47.276: INFO: namespace: e2e-tests-svcaccounts-nhbln, resource: bindings, ignored listing per whitelist
Mar 26 06:21:47.380: INFO: namespace e2e-tests-svcaccounts-nhbln deletion completed in 6.303654091s

• [SLOW TEST:15.566 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:21:47.381: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-kr8gq
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-kr8gq
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-kr8gq
Mar 26 06:21:47.706: INFO: Found 0 stateful pods, waiting for 1
Mar 26 06:21:57.723: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 26 06:21:57.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-kr8gq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 06:21:58.022: INFO: stderr: ""
Mar 26 06:21:58.022: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 06:21:58.022: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 06:21:58.029: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 26 06:22:08.035: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 06:22:08.035: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 06:22:08.067: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999739s
Mar 26 06:22:09.075: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990588789s
Mar 26 06:22:10.081: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.983174687s
Mar 26 06:22:11.115: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.976964195s
Mar 26 06:22:12.124: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.941899617s
Mar 26 06:22:13.134: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.933175542s
Mar 26 06:22:14.141: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.923793875s
Mar 26 06:22:15.149: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.916479441s
Mar 26 06:22:16.156: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.9086294s
Mar 26 06:22:17.164: INFO: Verifying statefulset ss doesn't scale past 1 for another 901.292169ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-kr8gq
Mar 26 06:22:18.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-kr8gq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 06:22:18.481: INFO: stderr: ""
Mar 26 06:22:18.481: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 06:22:18.481: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 06:22:18.487: INFO: Found 1 stateful pods, waiting for 3
Mar 26 06:22:28.495: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 06:22:28.496: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 06:22:28.496: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar 26 06:22:28.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-kr8gq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 06:22:28.803: INFO: stderr: ""
Mar 26 06:22:28.803: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 06:22:28.803: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 06:22:28.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-kr8gq ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 06:22:29.135: INFO: stderr: ""
Mar 26 06:22:29.135: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 06:22:29.135: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 06:22:29.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-kr8gq ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 06:22:29.414: INFO: stderr: ""
Mar 26 06:22:29.414: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 06:22:29.414: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 06:22:29.414: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 06:22:29.420: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 26 06:22:39.437: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 06:22:39.438: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 06:22:39.438: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 06:22:39.474: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999346s
Mar 26 06:22:40.483: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.9857816s
Mar 26 06:22:41.491: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.976779496s
Mar 26 06:22:42.499: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.969219254s
Mar 26 06:22:43.506: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.961224337s
Mar 26 06:22:44.516: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.953764524s
Mar 26 06:22:45.524: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.943693199s
Mar 26 06:22:46.532: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.936008099s
Mar 26 06:22:47.543: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.927766156s
Mar 26 06:22:48.568: INFO: Verifying statefulset ss doesn't scale past 3 for another 917.284525ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-kr8gq
Mar 26 06:22:49.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-kr8gq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 06:22:49.934: INFO: stderr: ""
Mar 26 06:22:49.934: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 06:22:49.934: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 06:22:49.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-kr8gq ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 06:22:50.238: INFO: stderr: ""
Mar 26 06:22:50.238: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 06:22:50.238: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 06:22:50.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-kr8gq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 06:22:50.507: INFO: stderr: ""
Mar 26 06:22:50.507: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 06:22:50.507: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 06:22:50.507: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 26 06:23:30.539: INFO: Deleting all statefulset in ns e2e-tests-statefulset-kr8gq
Mar 26 06:23:30.545: INFO: Scaling statefulset ss to 0
Mar 26 06:23:30.567: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 06:23:30.573: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:23:30.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-kr8gq" for this suite.
Mar 26 06:23:36.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:23:36.822: INFO: namespace: e2e-tests-statefulset-kr8gq, resource: bindings, ignored listing per whitelist
Mar 26 06:23:36.925: INFO: namespace e2e-tests-statefulset-kr8gq deletion completed in 6.305993653s

• [SLOW TEST:109.544 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:23:36.927: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar 26 06:23:37.158: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-qkr78" to be "success or failure"
Mar 26 06:23:37.194: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 35.44644ms
Mar 26 06:23:39.206: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048143206s
Mar 26 06:23:41.216: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057518517s
STEP: Saw pod success
Mar 26 06:23:41.216: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 26 06:23:41.222: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar 26 06:23:41.279: INFO: Waiting for pod pod-host-path-test to disappear
Mar 26 06:23:41.317: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:23:41.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-qkr78" for this suite.
Mar 26 06:23:47.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:23:47.414: INFO: namespace: e2e-tests-hostpath-qkr78, resource: bindings, ignored listing per whitelist
Mar 26 06:23:47.584: INFO: namespace e2e-tests-hostpath-qkr78 deletion completed in 6.258102591s

• [SLOW TEST:10.657 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:23:47.586: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-ghqz
STEP: Creating a pod to test atomic-volume-subpath
Mar 26 06:23:47.876: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ghqz" in namespace "e2e-tests-subpath-nvcr8" to be "success or failure"
Mar 26 06:23:47.914: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Pending", Reason="", readiness=false. Elapsed: 38.269624ms
Mar 26 06:23:49.921: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044545838s
Mar 26 06:23:51.931: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Running", Reason="", readiness=false. Elapsed: 4.055387732s
Mar 26 06:23:53.937: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Running", Reason="", readiness=false. Elapsed: 6.06106221s
Mar 26 06:23:55.944: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Running", Reason="", readiness=false. Elapsed: 8.067523732s
Mar 26 06:23:57.984: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Running", Reason="", readiness=false. Elapsed: 10.108492391s
Mar 26 06:23:59.992: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Running", Reason="", readiness=false. Elapsed: 12.116211769s
Mar 26 06:24:01.999: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Running", Reason="", readiness=false. Elapsed: 14.122651555s
Mar 26 06:24:04.008: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Running", Reason="", readiness=false. Elapsed: 16.131615653s
Mar 26 06:24:06.015: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Running", Reason="", readiness=false. Elapsed: 18.139375972s
Mar 26 06:24:08.026: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Running", Reason="", readiness=false. Elapsed: 20.149534824s
Mar 26 06:24:10.034: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Running", Reason="", readiness=false. Elapsed: 22.157911311s
Mar 26 06:24:12.042: INFO: Pod "pod-subpath-test-configmap-ghqz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.165985486s
STEP: Saw pod success
Mar 26 06:24:12.042: INFO: Pod "pod-subpath-test-configmap-ghqz" satisfied condition "success or failure"
Mar 26 06:24:12.047: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-subpath-test-configmap-ghqz container test-container-subpath-configmap-ghqz: <nil>
STEP: delete the pod
Mar 26 06:24:12.104: INFO: Waiting for pod pod-subpath-test-configmap-ghqz to disappear
Mar 26 06:24:12.118: INFO: Pod pod-subpath-test-configmap-ghqz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ghqz
Mar 26 06:24:12.118: INFO: Deleting pod "pod-subpath-test-configmap-ghqz" in namespace "e2e-tests-subpath-nvcr8"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:24:12.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-nvcr8" for this suite.
Mar 26 06:24:18.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:24:18.295: INFO: namespace: e2e-tests-subpath-nvcr8, resource: bindings, ignored listing per whitelist
Mar 26 06:24:18.485: INFO: namespace e2e-tests-subpath-nvcr8 deletion completed in 6.327437662s

• [SLOW TEST:30.900 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:24:18.486: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 26 06:24:18.729: INFO: Waiting up to 5m0s for pod "downward-api-c942d686-4f8f-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-8frqz" to be "success or failure"
Mar 26 06:24:18.779: INFO: Pod "downward-api-c942d686-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 50.190517ms
Mar 26 06:24:20.801: INFO: Pod "downward-api-c942d686-4f8f-11e9-8fea-5694fc6fbac7": Phase="Running", Reason="", readiness=true. Elapsed: 2.072466833s
Mar 26 06:24:22.812: INFO: Pod "downward-api-c942d686-4f8f-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.083610764s
STEP: Saw pod success
Mar 26 06:24:22.812: INFO: Pod "downward-api-c942d686-4f8f-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:24:22.837: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod downward-api-c942d686-4f8f-11e9-8fea-5694fc6fbac7 container dapi-container: <nil>
STEP: delete the pod
Mar 26 06:24:23.066: INFO: Waiting for pod downward-api-c942d686-4f8f-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:24:23.080: INFO: Pod downward-api-c942d686-4f8f-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:24:23.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8frqz" for this suite.
Mar 26 06:24:29.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:24:29.269: INFO: namespace: e2e-tests-downward-api-8frqz, resource: bindings, ignored listing per whitelist
Mar 26 06:24:29.367: INFO: namespace e2e-tests-downward-api-8frqz deletion completed in 6.265035724s

• [SLOW TEST:10.882 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:24:29.369: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 06:24:29.578: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfb90b48-4f8f-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-7j9mn" to be "success or failure"
Mar 26 06:24:29.609: INFO: Pod "downwardapi-volume-cfb90b48-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 30.656923ms
Mar 26 06:24:31.619: INFO: Pod "downwardapi-volume-cfb90b48-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040740139s
Mar 26 06:24:33.626: INFO: Pod "downwardapi-volume-cfb90b48-4f8f-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048111959s
STEP: Saw pod success
Mar 26 06:24:33.627: INFO: Pod "downwardapi-volume-cfb90b48-4f8f-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:24:33.638: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downwardapi-volume-cfb90b48-4f8f-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 06:24:33.692: INFO: Waiting for pod downwardapi-volume-cfb90b48-4f8f-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:24:33.705: INFO: Pod downwardapi-volume-cfb90b48-4f8f-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:24:33.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7j9mn" for this suite.
Mar 26 06:24:39.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:24:39.986: INFO: namespace: e2e-tests-downward-api-7j9mn, resource: bindings, ignored listing per whitelist
Mar 26 06:24:39.991: INFO: namespace e2e-tests-downward-api-7j9mn deletion completed in 6.271908922s

• [SLOW TEST:10.622 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:24:39.993: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d61164f3-4f8f-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:24:40.212: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d6134fc0-4f8f-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-sflgj" to be "success or failure"
Mar 26 06:24:40.258: INFO: Pod "pod-projected-configmaps-d6134fc0-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 45.700311ms
Mar 26 06:24:42.269: INFO: Pod "pod-projected-configmaps-d6134fc0-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056692051s
Mar 26 06:24:44.279: INFO: Pod "pod-projected-configmaps-d6134fc0-4f8f-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06707421s
STEP: Saw pod success
Mar 26 06:24:44.279: INFO: Pod "pod-projected-configmaps-d6134fc0-4f8f-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:24:44.285: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-projected-configmaps-d6134fc0-4f8f-11e9-8fea-5694fc6fbac7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:24:44.373: INFO: Waiting for pod pod-projected-configmaps-d6134fc0-4f8f-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:24:44.388: INFO: Pod pod-projected-configmaps-d6134fc0-4f8f-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:24:44.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sflgj" for this suite.
Mar 26 06:24:50.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:24:50.600: INFO: namespace: e2e-tests-projected-sflgj, resource: bindings, ignored listing per whitelist
Mar 26 06:24:50.689: INFO: namespace e2e-tests-projected-sflgj deletion completed in 6.285949455s

• [SLOW TEST:10.696 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:24:50.691: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-dc7b97ae-4f8f-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:24:50.971: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dc7c9a50-4f8f-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-5rhwh" to be "success or failure"
Mar 26 06:24:51.019: INFO: Pod "pod-projected-configmaps-dc7c9a50-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 47.723156ms
Mar 26 06:24:53.028: INFO: Pod "pod-projected-configmaps-dc7c9a50-4f8f-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.056555796s
STEP: Saw pod success
Mar 26 06:24:53.028: INFO: Pod "pod-projected-configmaps-dc7c9a50-4f8f-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:24:53.039: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-projected-configmaps-dc7c9a50-4f8f-11e9-8fea-5694fc6fbac7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:24:53.115: INFO: Waiting for pod pod-projected-configmaps-dc7c9a50-4f8f-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:24:53.124: INFO: Pod pod-projected-configmaps-dc7c9a50-4f8f-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:24:53.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5rhwh" for this suite.
Mar 26 06:24:59.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:24:59.261: INFO: namespace: e2e-tests-projected-5rhwh, resource: bindings, ignored listing per whitelist
Mar 26 06:24:59.421: INFO: namespace e2e-tests-projected-5rhwh deletion completed in 6.280309427s

• [SLOW TEST:8.730 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:24:59.422: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 06:24:59.611: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e1a2f11c-4f8f-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-t4brr" to be "success or failure"
Mar 26 06:24:59.654: INFO: Pod "downwardapi-volume-e1a2f11c-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 42.737973ms
Mar 26 06:25:01.691: INFO: Pod "downwardapi-volume-e1a2f11c-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079565578s
Mar 26 06:25:03.703: INFO: Pod "downwardapi-volume-e1a2f11c-4f8f-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.091758692s
STEP: Saw pod success
Mar 26 06:25:03.703: INFO: Pod "downwardapi-volume-e1a2f11c-4f8f-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:25:03.711: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod downwardapi-volume-e1a2f11c-4f8f-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 06:25:03.783: INFO: Waiting for pod downwardapi-volume-e1a2f11c-4f8f-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:25:03.845: INFO: Pod downwardapi-volume-e1a2f11c-4f8f-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:25:03.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t4brr" for this suite.
Mar 26 06:25:11.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:25:12.108: INFO: namespace: e2e-tests-downward-api-t4brr, resource: bindings, ignored listing per whitelist
Mar 26 06:25:12.271: INFO: namespace e2e-tests-downward-api-t4brr deletion completed in 8.388832193s

• [SLOW TEST:12.850 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:25:12.274: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar 26 06:25:12.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 api-versions'
Mar 26 06:25:12.944: INFO: stderr: ""
Mar 26 06:25:12.944: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:25:12.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l6md5" for this suite.
Mar 26 06:25:19.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:25:19.171: INFO: namespace: e2e-tests-kubectl-l6md5, resource: bindings, ignored listing per whitelist
Mar 26 06:25:19.189: INFO: namespace e2e-tests-kubectl-l6md5 deletion completed in 6.229131681s

• [SLOW TEST:6.916 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:25:19.191: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar 26 06:25:19.417: INFO: Waiting up to 5m0s for pod "var-expansion-ed6e2b67-4f8f-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-var-expansion-6s7jv" to be "success or failure"
Mar 26 06:25:19.441: INFO: Pod "var-expansion-ed6e2b67-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 23.124724ms
Mar 26 06:25:21.451: INFO: Pod "var-expansion-ed6e2b67-4f8f-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033785933s
STEP: Saw pod success
Mar 26 06:25:21.451: INFO: Pod "var-expansion-ed6e2b67-4f8f-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:25:21.473: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod var-expansion-ed6e2b67-4f8f-11e9-8fea-5694fc6fbac7 container dapi-container: <nil>
STEP: delete the pod
Mar 26 06:25:21.550: INFO: Waiting for pod var-expansion-ed6e2b67-4f8f-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:25:21.566: INFO: Pod var-expansion-ed6e2b67-4f8f-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:25:21.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6s7jv" for this suite.
Mar 26 06:25:27.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:25:27.645: INFO: namespace: e2e-tests-var-expansion-6s7jv, resource: bindings, ignored listing per whitelist
Mar 26 06:25:27.892: INFO: namespace e2e-tests-var-expansion-6s7jv deletion completed in 6.310305216s

• [SLOW TEST:8.701 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:25:27.894: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f2adeb16-4f8f-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 06:25:28.220: INFO: Waiting up to 5m0s for pod "pod-secrets-f2af77ce-4f8f-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-secrets-kz4lj" to be "success or failure"
Mar 26 06:25:28.265: INFO: Pod "pod-secrets-f2af77ce-4f8f-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 44.464047ms
Mar 26 06:25:30.274: INFO: Pod "pod-secrets-f2af77ce-4f8f-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053266881s
STEP: Saw pod success
Mar 26 06:25:30.274: INFO: Pod "pod-secrets-f2af77ce-4f8f-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:25:30.279: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-secrets-f2af77ce-4f8f-11e9-8fea-5694fc6fbac7 container secret-volume-test: <nil>
STEP: delete the pod
Mar 26 06:25:30.373: INFO: Waiting for pod pod-secrets-f2af77ce-4f8f-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:25:30.388: INFO: Pod pod-secrets-f2af77ce-4f8f-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:25:30.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kz4lj" for this suite.
Mar 26 06:25:36.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:25:36.481: INFO: namespace: e2e-tests-secrets-kz4lj, resource: bindings, ignored listing per whitelist
Mar 26 06:25:36.724: INFO: namespace e2e-tests-secrets-kz4lj deletion completed in 6.319940922s

• [SLOW TEST:8.831 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:25:36.726: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-72pl6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-72pl6 to expose endpoints map[]
Mar 26 06:25:37.005: INFO: Get endpoints failed (12.666675ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar 26 06:25:38.012: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-72pl6 exposes endpoints map[] (1.020245193s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-72pl6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-72pl6 to expose endpoints map[pod1:[80]]
Mar 26 06:25:41.111: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-72pl6 exposes endpoints map[pod1:[80]] (3.07084112s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-72pl6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-72pl6 to expose endpoints map[pod1:[80] pod2:[80]]
Mar 26 06:25:43.313: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-72pl6 exposes endpoints map[pod1:[80] pod2:[80]] (2.178779171s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-72pl6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-72pl6 to expose endpoints map[pod2:[80]]
Mar 26 06:25:43.370: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-72pl6 exposes endpoints map[pod2:[80]] (46.849053ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-72pl6
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-72pl6 to expose endpoints map[]
Mar 26 06:25:44.467: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-72pl6 exposes endpoints map[] (1.056964376s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:25:44.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-72pl6" for this suite.
Mar 26 06:25:50.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:25:50.807: INFO: namespace: e2e-tests-services-72pl6, resource: bindings, ignored listing per whitelist
Mar 26 06:25:50.839: INFO: namespace e2e-tests-services-72pl6 deletion completed in 6.293026267s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:14.114 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:25:50.839: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-004c267e-4f90-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:25:51.077: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-005062d1-4f90-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-xb2c4" to be "success or failure"
Mar 26 06:25:51.099: INFO: Pod "pod-projected-configmaps-005062d1-4f90-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 21.251615ms
Mar 26 06:25:53.105: INFO: Pod "pod-projected-configmaps-005062d1-4f90-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028084074s
STEP: Saw pod success
Mar 26 06:25:53.105: INFO: Pod "pod-projected-configmaps-005062d1-4f90-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:25:53.114: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-projected-configmaps-005062d1-4f90-11e9-8fea-5694fc6fbac7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:25:53.179: INFO: Waiting for pod pod-projected-configmaps-005062d1-4f90-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:25:53.192: INFO: Pod pod-projected-configmaps-005062d1-4f90-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:25:53.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xb2c4" for this suite.
Mar 26 06:25:59.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:25:59.409: INFO: namespace: e2e-tests-projected-xb2c4, resource: bindings, ignored listing per whitelist
Mar 26 06:25:59.486: INFO: namespace e2e-tests-projected-xb2c4 deletion completed in 6.272569255s

• [SLOW TEST:8.647 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:25:59.490: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Mar 26 06:26:05.882: INFO: 0 pods remaining
Mar 26 06:26:05.882: INFO: 0 pods has nil DeletionTimestamp
Mar 26 06:26:05.882: INFO: 
STEP: Gathering metrics
W0326 06:26:06.766102      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 06:26:06.766: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:26:06.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mbcxg" for this suite.
Mar 26 06:26:14.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:26:14.981: INFO: namespace: e2e-tests-gc-mbcxg, resource: bindings, ignored listing per whitelist
Mar 26 06:26:15.026: INFO: namespace e2e-tests-gc-mbcxg deletion completed in 8.249937223s

• [SLOW TEST:15.536 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:26:15.035: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-t8cnc
Mar 26 06:26:17.285: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-t8cnc
STEP: checking the pod's current state and verifying that restartCount is present
Mar 26 06:26:17.290: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:30:18.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-t8cnc" for this suite.
Mar 26 06:30:24.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:30:24.885: INFO: namespace: e2e-tests-container-probe-t8cnc, resource: bindings, ignored listing per whitelist
Mar 26 06:30:24.904: INFO: namespace e2e-tests-container-probe-t8cnc deletion completed in 6.249236626s

• [SLOW TEST:249.870 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:30:24.907: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 26 06:30:29.851: INFO: Successfully updated pod "annotationupdatea3b547b2-4f90-11e9-8fea-5694fc6fbac7"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:30:31.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ngrkf" for this suite.
Mar 26 06:30:56.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:30:56.247: INFO: namespace: e2e-tests-projected-ngrkf, resource: bindings, ignored listing per whitelist
Mar 26 06:30:56.300: INFO: namespace e2e-tests-projected-ngrkf deletion completed in 24.319770529s

• [SLOW TEST:31.393 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:30:56.302: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar 26 06:30:58.587: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-b65ecdc0-4f90-11e9-8fea-5694fc6fbac7,GenerateName:,Namespace:e2e-tests-events-ms9h7,SelfLink:/api/v1/namespaces/e2e-tests-events-ms9h7/pods/send-events-b65ecdc0-4f90-11e9-8fea-5694fc6fbac7,UID:b660657f-4f90-11e9-b22a-90b8d090d774,ResourceVersion:43869,Generation:0,CreationTimestamp:2019-03-26 06:30:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 506215924,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.81/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ks8tj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ks8tj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-ks8tj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420c4ae30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420c4ae50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:30:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:30:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:30:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:30:56 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.8,PodIP:10.42.0.81,StartTime:2019-03-26 06:30:56 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-26 06:30:57 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://0773c63fe2115d4a0315a953d5887815a3d807cf4f45252841da37d513668a7b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar 26 06:31:00.594: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar 26 06:31:02.602: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:31:02.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-ms9h7" for this suite.
Mar 26 06:31:42.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:31:42.943: INFO: namespace: e2e-tests-events-ms9h7, resource: bindings, ignored listing per whitelist
Mar 26 06:31:42.963: INFO: namespace e2e-tests-events-ms9h7 deletion completed in 40.303745311s

• [SLOW TEST:46.662 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:31:42.966: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:31:43.166: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:31:44.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-44jhz" for this suite.
Mar 26 06:31:50.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:31:50.390: INFO: namespace: e2e-tests-custom-resource-definition-44jhz, resource: bindings, ignored listing per whitelist
Mar 26 06:31:50.581: INFO: namespace e2e-tests-custom-resource-definition-44jhz deletion completed in 6.247455151s

• [SLOW TEST:7.615 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:31:50.583: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar 26 06:31:50.843: INFO: Waiting up to 5m0s for pod "client-containers-d6ba3979-4f90-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-containers-m6qf9" to be "success or failure"
Mar 26 06:31:50.863: INFO: Pod "client-containers-d6ba3979-4f90-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 19.200381ms
Mar 26 06:31:52.869: INFO: Pod "client-containers-d6ba3979-4f90-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025300227s
Mar 26 06:31:54.874: INFO: Pod "client-containers-d6ba3979-4f90-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030681764s
STEP: Saw pod success
Mar 26 06:31:54.874: INFO: Pod "client-containers-d6ba3979-4f90-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:31:54.882: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod client-containers-d6ba3979-4f90-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 06:31:54.941: INFO: Waiting for pod client-containers-d6ba3979-4f90-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:31:54.996: INFO: Pod client-containers-d6ba3979-4f90-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:31:54.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-m6qf9" for this suite.
Mar 26 06:32:01.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:32:01.298: INFO: namespace: e2e-tests-containers-m6qf9, resource: bindings, ignored listing per whitelist
Mar 26 06:32:01.358: INFO: namespace e2e-tests-containers-m6qf9 deletion completed in 6.347971157s

• [SLOW TEST:10.776 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:32:01.360: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-dd21efb7-4f90-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:32:01.570: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dd235449-4f90-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-xmkzq" to be "success or failure"
Mar 26 06:32:01.627: INFO: Pod "pod-projected-configmaps-dd235449-4f90-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 57.203181ms
Mar 26 06:32:03.635: INFO: Pod "pod-projected-configmaps-dd235449-4f90-11e9-8fea-5694fc6fbac7": Phase="Running", Reason="", readiness=true. Elapsed: 2.065310911s
Mar 26 06:32:05.641: INFO: Pod "pod-projected-configmaps-dd235449-4f90-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070767241s
STEP: Saw pod success
Mar 26 06:32:05.641: INFO: Pod "pod-projected-configmaps-dd235449-4f90-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:32:05.645: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-projected-configmaps-dd235449-4f90-11e9-8fea-5694fc6fbac7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:32:05.732: INFO: Waiting for pod pod-projected-configmaps-dd235449-4f90-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:32:05.740: INFO: Pod pod-projected-configmaps-dd235449-4f90-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:32:05.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xmkzq" for this suite.
Mar 26 06:32:11.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:32:12.017: INFO: namespace: e2e-tests-projected-xmkzq, resource: bindings, ignored listing per whitelist
Mar 26 06:32:12.023: INFO: namespace e2e-tests-projected-xmkzq deletion completed in 6.268225568s

• [SLOW TEST:10.664 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:32:12.024: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 26 06:32:12.264: INFO: Waiting up to 5m0s for pod "downward-api-e383374a-4f90-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-5t5g5" to be "success or failure"
Mar 26 06:32:12.289: INFO: Pod "downward-api-e383374a-4f90-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.304212ms
Mar 26 06:32:14.300: INFO: Pod "downward-api-e383374a-4f90-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03546215s
STEP: Saw pod success
Mar 26 06:32:14.300: INFO: Pod "downward-api-e383374a-4f90-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:32:14.304: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downward-api-e383374a-4f90-11e9-8fea-5694fc6fbac7 container dapi-container: <nil>
STEP: delete the pod
Mar 26 06:32:14.416: INFO: Waiting for pod downward-api-e383374a-4f90-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:32:14.424: INFO: Pod downward-api-e383374a-4f90-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:32:14.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5t5g5" for this suite.
Mar 26 06:32:20.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:32:20.609: INFO: namespace: e2e-tests-downward-api-5t5g5, resource: bindings, ignored listing per whitelist
Mar 26 06:32:20.716: INFO: namespace e2e-tests-downward-api-5t5g5 deletion completed in 6.27129576s

• [SLOW TEST:8.692 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:32:20.720: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 26 06:32:20.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:21.741: INFO: stderr: ""
Mar 26 06:32:21.741: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 26 06:32:21.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:22.089: INFO: stderr: ""
Mar 26 06:32:22.089: INFO: stdout: "update-demo-nautilus-hxwpz update-demo-nautilus-mfr4d "
Mar 26 06:32:22.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-hxwpz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:22.487: INFO: stderr: ""
Mar 26 06:32:22.487: INFO: stdout: ""
Mar 26 06:32:22.487: INFO: update-demo-nautilus-hxwpz is created but not running
Mar 26 06:32:27.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:27.730: INFO: stderr: ""
Mar 26 06:32:27.731: INFO: stdout: "update-demo-nautilus-hxwpz update-demo-nautilus-mfr4d "
Mar 26 06:32:27.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-hxwpz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:27.997: INFO: stderr: ""
Mar 26 06:32:27.997: INFO: stdout: "true"
Mar 26 06:32:27.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-hxwpz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:28.265: INFO: stderr: ""
Mar 26 06:32:28.265: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 06:32:28.265: INFO: validating pod update-demo-nautilus-hxwpz
Mar 26 06:32:28.471: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 06:32:28.471: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 06:32:28.471: INFO: update-demo-nautilus-hxwpz is verified up and running
Mar 26 06:32:28.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-mfr4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:28.791: INFO: stderr: ""
Mar 26 06:32:28.791: INFO: stdout: "true"
Mar 26 06:32:28.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-mfr4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:29.151: INFO: stderr: ""
Mar 26 06:32:29.151: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 06:32:29.151: INFO: validating pod update-demo-nautilus-mfr4d
Mar 26 06:32:29.424: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 06:32:29.424: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 06:32:29.424: INFO: update-demo-nautilus-mfr4d is verified up and running
STEP: scaling down the replication controller
Mar 26 06:32:29.427: INFO: scanned /root for discovery docs: <nil>
Mar 26 06:32:29.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:30.928: INFO: stderr: ""
Mar 26 06:32:30.929: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 26 06:32:30.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:31.105: INFO: stderr: ""
Mar 26 06:32:31.105: INFO: stdout: "update-demo-nautilus-hxwpz update-demo-nautilus-mfr4d "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 26 06:32:36.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:36.270: INFO: stderr: ""
Mar 26 06:32:36.270: INFO: stdout: "update-demo-nautilus-hxwpz update-demo-nautilus-mfr4d "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 26 06:32:41.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:41.492: INFO: stderr: ""
Mar 26 06:32:41.492: INFO: stdout: "update-demo-nautilus-mfr4d "
Mar 26 06:32:41.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-mfr4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:41.653: INFO: stderr: ""
Mar 26 06:32:41.653: INFO: stdout: "true"
Mar 26 06:32:41.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-mfr4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:41.814: INFO: stderr: ""
Mar 26 06:32:41.814: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 06:32:41.814: INFO: validating pod update-demo-nautilus-mfr4d
Mar 26 06:32:41.823: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 06:32:41.823: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 06:32:41.823: INFO: update-demo-nautilus-mfr4d is verified up and running
STEP: scaling up the replication controller
Mar 26 06:32:41.829: INFO: scanned /root for discovery docs: <nil>
Mar 26 06:32:41.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:43.078: INFO: stderr: ""
Mar 26 06:32:43.078: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 26 06:32:43.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:43.260: INFO: stderr: ""
Mar 26 06:32:43.260: INFO: stdout: "update-demo-nautilus-mfr4d update-demo-nautilus-wjrzj "
Mar 26 06:32:43.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-mfr4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:43.487: INFO: stderr: ""
Mar 26 06:32:43.487: INFO: stdout: "true"
Mar 26 06:32:43.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-mfr4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:43.657: INFO: stderr: ""
Mar 26 06:32:43.657: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 06:32:43.657: INFO: validating pod update-demo-nautilus-mfr4d
Mar 26 06:32:43.667: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 06:32:43.668: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 06:32:43.668: INFO: update-demo-nautilus-mfr4d is verified up and running
Mar 26 06:32:43.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-wjrzj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:43.822: INFO: stderr: ""
Mar 26 06:32:43.822: INFO: stdout: ""
Mar 26 06:32:43.822: INFO: update-demo-nautilus-wjrzj is created but not running
Mar 26 06:32:48.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:48.992: INFO: stderr: ""
Mar 26 06:32:48.993: INFO: stdout: "update-demo-nautilus-mfr4d update-demo-nautilus-wjrzj "
Mar 26 06:32:48.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-mfr4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:49.202: INFO: stderr: ""
Mar 26 06:32:49.202: INFO: stdout: "true"
Mar 26 06:32:49.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-mfr4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:49.346: INFO: stderr: ""
Mar 26 06:32:49.346: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 06:32:49.346: INFO: validating pod update-demo-nautilus-mfr4d
Mar 26 06:32:49.357: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 06:32:49.357: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 06:32:49.357: INFO: update-demo-nautilus-mfr4d is verified up and running
Mar 26 06:32:49.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-wjrzj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:49.500: INFO: stderr: ""
Mar 26 06:32:49.500: INFO: stdout: "true"
Mar 26 06:32:49.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods update-demo-nautilus-wjrzj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:49.661: INFO: stderr: ""
Mar 26 06:32:49.661: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 26 06:32:49.661: INFO: validating pod update-demo-nautilus-wjrzj
Mar 26 06:32:49.670: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 26 06:32:49.671: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 26 06:32:49.671: INFO: update-demo-nautilus-wjrzj is verified up and running
STEP: using delete to clean up resources
Mar 26 06:32:49.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:49.843: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 06:32:49.843: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 26 06:32:49.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-b9shs'
Mar 26 06:32:50.046: INFO: stderr: "No resources found.\n"
Mar 26 06:32:50.046: INFO: stdout: ""
Mar 26 06:32:50.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -l name=update-demo --namespace=e2e-tests-kubectl-b9shs -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 26 06:32:50.218: INFO: stderr: ""
Mar 26 06:32:50.218: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:32:50.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b9shs" for this suite.
Mar 26 06:33:14.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:33:14.472: INFO: namespace: e2e-tests-kubectl-b9shs, resource: bindings, ignored listing per whitelist
Mar 26 06:33:14.521: INFO: namespace e2e-tests-kubectl-b9shs deletion completed in 24.287255768s

• [SLOW TEST:53.802 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:33:14.523: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 26 06:33:14.711: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 26 06:33:14.745: INFO: Waiting for terminating namespaces to be deleted...
Mar 26 06:33:14.751: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-control-1 before test
Mar 26 06:33:14.770: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-sw4jz from heptio-sonobuoy started at 2019-03-26 05:38:40 +0000 UTC (2 container statuses recorded)
Mar 26 06:33:14.770: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 26 06:33:14.770: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:33:14.771: INFO: calico-node-g2rd4 from kube-system started at 2019-03-26 00:53:07 +0000 UTC (2 container statuses recorded)
Mar 26 06:33:14.771: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:33:14.771: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:33:14.771: INFO: rke-metrics-addon-deploy-job-bsrr2 from kube-system started at 2019-03-26 00:53:23 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.771: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 26 06:33:14.771: INFO: rke-ingress-controller-deploy-job-w8l9x from kube-system started at 2019-03-26 00:53:35 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.771: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 26 06:33:14.771: INFO: nginx-ingress-controller-5qkcf from ingress-nginx started at 2019-03-26 05:38:03 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.771: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:33:14.771: INFO: rke-kubedns-addon-deploy-job-69jrs from kube-system started at 2019-03-26 00:53:12 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.771: INFO: 	Container rke-kubedns-addon-pod ready: false, restart count 0
Mar 26 06:33:14.771: INFO: rke-network-plugin-deploy-job-xl4m5 from kube-system started at 2019-03-26 00:53:02 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.771: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 26 06:33:14.771: INFO: cattle-node-agent-hnjxf from cattle-system started at 2019-03-26 00:54:37 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.772: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:33:14.772: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-etcd-1 before test
Mar 26 06:33:14.786: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-r228k from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:33:14.786: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 26 06:33:14.787: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:33:14.787: INFO: calico-node-zbl4q from kube-system started at 2019-03-26 00:53:07 +0000 UTC (2 container statuses recorded)
Mar 26 06:33:14.787: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:33:14.787: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:33:14.787: INFO: cattle-node-agent-88rnp from cattle-system started at 2019-03-26 00:54:01 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.787: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:33:14.788: INFO: nginx-ingress-controller-glb5c from ingress-nginx started at 2019-03-26 05:38:15 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.788: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:33:14.788: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-worker-1 before test
Mar 26 06:33:14.810: INFO: calico-node-4hkk8 from kube-system started at 2019-03-26 00:54:48 +0000 UTC (2 container statuses recorded)
Mar 26 06:33:14.810: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:33:14.811: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:33:14.811: INFO: metrics-server-5444cf6dfc-jk9bb from kube-system started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.811: INFO: 	Container metrics-server ready: true, restart count 0
Mar 26 06:33:14.811: INFO: nginx-ingress-controller-hbcdq from ingress-nginx started at 2019-03-26 00:55:09 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.811: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:33:14.811: INFO: cattle-node-agent-2vwcr from cattle-system started at 2019-03-26 00:55:09 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.812: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:33:14.812: INFO: kube-dns-autoscaler-689f6f9756-vwph6 from kube-system started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.812: INFO: 	Container autoscaler ready: true, restart count 0
Mar 26 06:33:14.812: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-psbcr from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:33:14.812: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 26 06:33:14.812: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:33:14.813: INFO: kube-dns-ddddcfcc8-75rhb from kube-system started at 2019-03-26 00:55:08 +0000 UTC (3 container statuses recorded)
Mar 26 06:33:14.813: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 06:33:14.813: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 06:33:14.813: INFO: 	Container sidecar ready: true, restart count 0
Mar 26 06:33:14.813: INFO: default-http-backend-5bdd9fdd69-b5f6t from ingress-nginx started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.813: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 26 06:33:14.814: INFO: cattle-cluster-agent-6f575d9bcf-rjz7h from cattle-system started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.814: INFO: 	Container cluster-register ready: true, restart count 0
Mar 26 06:33:14.814: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-worker1-1 before test
Mar 26 06:33:14.835: INFO: calico-node-4njnj from kube-system started at 2019-03-26 01:46:41 +0000 UTC (2 container statuses recorded)
Mar 26 06:33:14.836: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:33:14.836: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:33:14.836: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-26 05:38:36 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.836: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 26 06:33:14.837: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-rb6hz from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:33:14.837: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 26 06:33:14.837: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:33:14.838: INFO: nginx-ingress-controller-rsjr4 from ingress-nginx started at 2019-03-26 01:47:20 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.838: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:33:14.838: INFO: cattle-node-agent-9qhk4 from cattle-system started at 2019-03-26 01:47:20 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.838: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:33:14.838: INFO: sonobuoy-e2e-job-2791eb3c35d44121 from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:33:14.838: INFO: 	Container e2e ready: true, restart count 0
Mar 26 06:33:14.840: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:33:14.840: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-worker1-2 before test
Mar 26 06:33:14.858: INFO: calico-node-l244q from kube-system started at 2019-03-26 01:45:53 +0000 UTC (2 container statuses recorded)
Mar 26 06:33:14.858: INFO: 	Container calico-node ready: true, restart count 1
Mar 26 06:33:14.858: INFO: 	Container install-cni ready: true, restart count 1
Mar 26 06:33:14.858: INFO: nginx-ingress-controller-lvkkc from ingress-nginx started at 2019-03-26 01:46:33 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.858: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:33:14.858: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-l2r6z from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:33:14.858: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 26 06:33:14.858: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:33:14.858: INFO: cattle-node-agent-8rc72 from cattle-system started at 2019-03-26 01:46:33 +0000 UTC (1 container statuses recorded)
Mar 26 06:33:14.858: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:33:14.858: INFO: kube-dns-ddddcfcc8-8hxnz from kube-system started at 2019-03-26 01:46:46 +0000 UTC (3 container statuses recorded)
Mar 26 06:33:14.858: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 06:33:14.858: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 06:33:14.858: INFO: 	Container sidecar ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-0b46512a-4f91-11e9-8fea-5694fc6fbac7 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-0b46512a-4f91-11e9-8fea-5694fc6fbac7 off the node k8s-conformance-cluster-1-12-etcd-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-0b46512a-4f91-11e9-8fea-5694fc6fbac7
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:33:21.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-8bkpn" for this suite.
Mar 26 06:33:31.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:33:31.338: INFO: namespace: e2e-tests-sched-pred-8bkpn, resource: bindings, ignored listing per whitelist
Mar 26 06:33:31.508: INFO: namespace e2e-tests-sched-pred-8bkpn deletion completed in 10.362925085s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:16.986 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:33:31.516: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-12e5b70c-4f91-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 06:33:31.773: INFO: Waiting up to 5m0s for pod "pod-secrets-12e80c2e-4f91-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-secrets-mdtmc" to be "success or failure"
Mar 26 06:33:31.832: INFO: Pod "pod-secrets-12e80c2e-4f91-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 58.72819ms
Mar 26 06:33:33.840: INFO: Pod "pod-secrets-12e80c2e-4f91-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.066715316s
STEP: Saw pod success
Mar 26 06:33:33.840: INFO: Pod "pod-secrets-12e80c2e-4f91-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:33:33.846: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-secrets-12e80c2e-4f91-11e9-8fea-5694fc6fbac7 container secret-env-test: <nil>
STEP: delete the pod
Mar 26 06:33:33.936: INFO: Waiting for pod pod-secrets-12e80c2e-4f91-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:33:33.995: INFO: Pod pod-secrets-12e80c2e-4f91-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:33:33.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mdtmc" for this suite.
Mar 26 06:33:40.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:33:40.130: INFO: namespace: e2e-tests-secrets-mdtmc, resource: bindings, ignored listing per whitelist
Mar 26 06:33:40.293: INFO: namespace e2e-tests-secrets-mdtmc deletion completed in 6.283604505s

• [SLOW TEST:8.778 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:33:40.296: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-181e3993-4f91-11e9-8fea-5694fc6fbac7
STEP: Creating secret with name secret-projected-all-test-volume-181e397e-4f91-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar 26 06:33:40.555: INFO: Waiting up to 5m0s for pod "projected-volume-181e3934-4f91-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-8qr29" to be "success or failure"
Mar 26 06:33:40.603: INFO: Pod "projected-volume-181e3934-4f91-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 47.13408ms
Mar 26 06:33:42.611: INFO: Pod "projected-volume-181e3934-4f91-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055767766s
Mar 26 06:33:44.618: INFO: Pod "projected-volume-181e3934-4f91-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062339359s
STEP: Saw pod success
Mar 26 06:33:44.618: INFO: Pod "projected-volume-181e3934-4f91-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:33:44.623: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod projected-volume-181e3934-4f91-11e9-8fea-5694fc6fbac7 container projected-all-volume-test: <nil>
STEP: delete the pod
Mar 26 06:33:44.674: INFO: Waiting for pod projected-volume-181e3934-4f91-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:33:44.682: INFO: Pod projected-volume-181e3934-4f91-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:33:44.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8qr29" for this suite.
Mar 26 06:33:50.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:33:50.940: INFO: namespace: e2e-tests-projected-8qr29, resource: bindings, ignored listing per whitelist
Mar 26 06:33:50.953: INFO: namespace e2e-tests-projected-8qr29 deletion completed in 6.259354452s

• [SLOW TEST:10.658 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:33:50.954: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:33:51.169: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 26 06:33:56.176: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 26 06:33:56.177: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 26 06:33:58.183: INFO: Creating deployment "test-rollover-deployment"
Mar 26 06:33:58.203: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 26 06:34:00.219: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 26 06:34:00.231: INFO: Ensure that both replica sets have 1 created replica
Mar 26 06:34:00.243: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 26 06:34:00.264: INFO: Updating deployment test-rollover-deployment
Mar 26 06:34:00.264: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 26 06:34:02.299: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 26 06:34:02.309: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 26 06:34:02.319: INFO: all replica sets need to contain the pod-template-hash label
Mar 26 06:34:02.320: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178842, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 06:34:04.335: INFO: all replica sets need to contain the pod-template-hash label
Mar 26 06:34:04.335: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178842, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 06:34:06.338: INFO: all replica sets need to contain the pod-template-hash label
Mar 26 06:34:06.338: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178842, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 06:34:08.336: INFO: all replica sets need to contain the pod-template-hash label
Mar 26 06:34:08.336: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178842, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 06:34:10.332: INFO: all replica sets need to contain the pod-template-hash label
Mar 26 06:34:10.332: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178842, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 06:34:12.569: INFO: 
Mar 26 06:34:12.570: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178852, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689178838, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 26 06:34:14.333: INFO: 
Mar 26 06:34:14.333: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 26 06:34:14.352: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-rq5bn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rq5bn/deployments/test-rollover-deployment,UID:22a85647-4f91-11e9-b22a-90b8d090d774,ResourceVersion:44629,Generation:2,CreationTimestamp:2019-03-26 06:33:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-26 06:33:58 +0000 UTC 2019-03-26 06:33:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-26 06:34:12 +0000 UTC 2019-03-26 06:33:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 26 06:34:14.367: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-rq5bn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rq5bn/replicasets/test-rollover-deployment-5b76ff8c4,UID:23e4a5df-4f91-11e9-b22a-90b8d090d774,ResourceVersion:44618,Generation:2,CreationTimestamp:2019-03-26 06:34:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 22a85647-4f91-11e9-b22a-90b8d090d774 0xc42234f397 0xc42234f398}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 26 06:34:14.367: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 26 06:34:14.367: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-rq5bn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rq5bn/replicasets/test-rollover-controller,UID:1e774145-4f91-11e9-b22a-90b8d090d774,ResourceVersion:44628,Generation:2,CreationTimestamp:2019-03-26 06:33:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 22a85647-4f91-11e9-b22a-90b8d090d774 0xc42234f2ce 0xc42234f2cf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 06:34:14.367: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-rq5bn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rq5bn/replicasets/test-rollover-deployment-6975f4fb87,UID:22aeec6d-4f91-11e9-b22a-90b8d090d774,ResourceVersion:44590,Generation:2,CreationTimestamp:2019-03-26 06:33:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 22a85647-4f91-11e9-b22a-90b8d090d774 0xc42234f457 0xc42234f458}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 26 06:34:14.374: INFO: Pod "test-rollover-deployment-5b76ff8c4-s66sz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-s66sz,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-rq5bn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rq5bn/pods/test-rollover-deployment-5b76ff8c4-s66sz,UID:23efcda4-4f91-11e9-b22a-90b8d090d774,ResourceVersion:44598,Generation:0,CreationTimestamp:2019-03-26 06:34:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.87/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 23e4a5df-4f91-11e9-b22a-90b8d090d774 0xc421d6e120 0xc421d6e121}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rfqxb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rfqxb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rfqxb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d6e180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d6e1a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:34:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:34:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:34:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:34:00 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.8,PodIP:10.42.0.87,StartTime:2019-03-26 06:34:00 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-26 06:34:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1adc8bbbd3509231ef73a29d6c88d36e1da6d4721d73e414e8907494d0914769}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:34:14.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rq5bn" for this suite.
Mar 26 06:34:22.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:34:22.665: INFO: namespace: e2e-tests-deployment-rq5bn, resource: bindings, ignored listing per whitelist
Mar 26 06:34:22.724: INFO: namespace e2e-tests-deployment-rq5bn deletion completed in 8.339739977s

• [SLOW TEST:31.770 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:34:22.728: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-p9rp2 in namespace e2e-tests-proxy-2752m
I0326 06:34:23.047053      14 runners.go:180] Created replication controller with name: proxy-service-p9rp2, namespace: e2e-tests-proxy-2752m, replica count: 1
I0326 06:34:24.098068      14 runners.go:180] proxy-service-p9rp2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0326 06:34:25.098548      14 runners.go:180] proxy-service-p9rp2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0326 06:34:26.098902      14 runners.go:180] proxy-service-p9rp2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0326 06:34:27.099358      14 runners.go:180] proxy-service-p9rp2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0326 06:34:28.099685      14 runners.go:180] proxy-service-p9rp2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0326 06:34:29.099986      14 runners.go:180] proxy-service-p9rp2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0326 06:34:30.100367      14 runners.go:180] proxy-service-p9rp2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0326 06:34:31.100676      14 runners.go:180] proxy-service-p9rp2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0326 06:34:32.100977      14 runners.go:180] proxy-service-p9rp2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0326 06:34:33.101341      14 runners.go:180] proxy-service-p9rp2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0326 06:34:34.101757      14 runners.go:180] proxy-service-p9rp2 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 26 06:34:34.108: INFO: setup took 11.123261159s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar 26 06:34:34.140: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 30.311789ms)
Mar 26 06:34:34.140: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 30.030188ms)
Mar 26 06:34:34.155: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 43.308954ms)
Mar 26 06:34:34.155: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 44.874577ms)
Mar 26 06:34:34.178: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 66.921181ms)
Mar 26 06:34:34.178: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 68.172413ms)
Mar 26 06:34:34.199: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 87.563559ms)
Mar 26 06:34:34.204: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 92.992933ms)
Mar 26 06:34:34.205: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 93.910567ms)
Mar 26 06:34:34.206: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 94.391815ms)
Mar 26 06:34:34.207: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 95.96431ms)
Mar 26 06:34:34.208: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 96.499208ms)
Mar 26 06:34:34.221: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 109.035454ms)
Mar 26 06:34:34.222: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 110.366735ms)
Mar 26 06:34:34.223: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 114.977468ms)
Mar 26 06:34:34.224: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 113.07005ms)
Mar 26 06:34:34.247: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 22.804216ms)
Mar 26 06:34:34.248: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 22.380053ms)
Mar 26 06:34:34.249: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 23.867509ms)
Mar 26 06:34:34.252: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 27.361623ms)
Mar 26 06:34:34.252: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 27.971181ms)
Mar 26 06:34:34.253: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 27.747707ms)
Mar 26 06:34:34.261: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 35.657531ms)
Mar 26 06:34:34.265: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 38.657679ms)
Mar 26 06:34:34.265: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 38.299091ms)
Mar 26 06:34:34.266: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 41.349314ms)
Mar 26 06:34:34.273: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 46.086922ms)
Mar 26 06:34:34.273: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 46.967478ms)
Mar 26 06:34:34.273: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 47.372111ms)
Mar 26 06:34:34.274: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 46.294721ms)
Mar 26 06:34:34.274: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 47.105938ms)
Mar 26 06:34:34.274: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 47.462942ms)
Mar 26 06:34:34.296: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 19.994625ms)
Mar 26 06:34:34.299: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 22.811221ms)
Mar 26 06:34:34.311: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 34.982026ms)
Mar 26 06:34:34.313: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 37.637422ms)
Mar 26 06:34:34.314: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 38.038326ms)
Mar 26 06:34:34.335: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 60.428505ms)
Mar 26 06:34:34.336: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 59.793989ms)
Mar 26 06:34:34.336: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 60.205436ms)
Mar 26 06:34:34.336: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 60.496521ms)
Mar 26 06:34:34.339: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 62.591056ms)
Mar 26 06:34:34.339: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 62.913824ms)
Mar 26 06:34:34.339: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 63.45935ms)
Mar 26 06:34:34.340: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 63.816727ms)
Mar 26 06:34:34.340: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 63.996428ms)
Mar 26 06:34:34.340: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 64.931725ms)
Mar 26 06:34:34.341: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 65.133798ms)
Mar 26 06:34:34.369: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 28.07485ms)
Mar 26 06:34:34.370: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 28.089445ms)
Mar 26 06:34:34.371: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 28.481747ms)
Mar 26 06:34:34.372: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 30.017598ms)
Mar 26 06:34:34.385: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 41.763704ms)
Mar 26 06:34:34.387: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 43.855716ms)
Mar 26 06:34:34.392: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 48.620939ms)
Mar 26 06:34:34.392: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 49.515889ms)
Mar 26 06:34:34.392: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 49.554892ms)
Mar 26 06:34:34.394: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 52.579523ms)
Mar 26 06:34:34.396: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 52.016971ms)
Mar 26 06:34:34.400: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 57.359292ms)
Mar 26 06:34:34.401: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 59.345742ms)
Mar 26 06:34:34.401: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 58.206803ms)
Mar 26 06:34:34.402: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 60.500389ms)
Mar 26 06:34:34.402: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 59.116162ms)
Mar 26 06:34:34.426: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 22.941205ms)
Mar 26 06:34:34.427: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 24.124417ms)
Mar 26 06:34:34.436: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 30.81451ms)
Mar 26 06:34:34.438: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 34.017829ms)
Mar 26 06:34:34.438: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 34.399585ms)
Mar 26 06:34:34.440: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 35.192401ms)
Mar 26 06:34:34.443: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 39.168402ms)
Mar 26 06:34:34.445: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 40.076248ms)
Mar 26 06:34:34.445: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 41.687714ms)
Mar 26 06:34:34.446: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 40.553488ms)
Mar 26 06:34:34.455: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 52.731117ms)
Mar 26 06:34:34.462: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 56.527051ms)
Mar 26 06:34:34.464: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 59.39884ms)
Mar 26 06:34:34.464: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 60.712306ms)
Mar 26 06:34:34.465: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 61.136657ms)
Mar 26 06:34:34.467: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 62.191676ms)
Mar 26 06:34:34.490: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 22.780886ms)
Mar 26 06:34:34.491: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 24.130558ms)
Mar 26 06:34:34.492: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 24.347306ms)
Mar 26 06:34:34.499: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 29.75672ms)
Mar 26 06:34:34.503: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 35.510759ms)
Mar 26 06:34:34.506: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 38.044697ms)
Mar 26 06:34:34.506: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 37.50624ms)
Mar 26 06:34:34.506: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 38.902319ms)
Mar 26 06:34:34.509: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 39.209731ms)
Mar 26 06:34:34.510: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 41.4524ms)
Mar 26 06:34:34.511: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 41.98794ms)
Mar 26 06:34:34.512: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 42.649049ms)
Mar 26 06:34:34.515: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 46.155674ms)
Mar 26 06:34:34.516: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 47.687861ms)
Mar 26 06:34:34.516: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 47.969729ms)
Mar 26 06:34:34.516: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 48.341235ms)
Mar 26 06:34:34.540: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 22.847264ms)
Mar 26 06:34:34.543: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 26.052577ms)
Mar 26 06:34:34.544: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 26.889891ms)
Mar 26 06:34:34.550: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 32.416257ms)
Mar 26 06:34:34.552: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 33.703705ms)
Mar 26 06:34:34.566: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 48.260637ms)
Mar 26 06:34:34.569: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 50.803469ms)
Mar 26 06:34:34.571: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 51.960556ms)
Mar 26 06:34:34.572: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 52.832157ms)
Mar 26 06:34:34.572: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 54.187915ms)
Mar 26 06:34:34.573: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 55.743652ms)
Mar 26 06:34:34.573: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 55.46554ms)
Mar 26 06:34:34.573: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 54.654075ms)
Mar 26 06:34:34.573: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 54.44893ms)
Mar 26 06:34:34.574: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 54.841273ms)
Mar 26 06:34:34.574: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 55.579661ms)
Mar 26 06:34:34.603: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 26.627447ms)
Mar 26 06:34:34.607: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 32.10079ms)
Mar 26 06:34:34.607: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 32.221436ms)
Mar 26 06:34:34.608: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 33.264935ms)
Mar 26 06:34:34.608: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 31.564195ms)
Mar 26 06:34:34.608: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 31.824197ms)
Mar 26 06:34:34.608: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 32.474906ms)
Mar 26 06:34:34.608: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 31.402027ms)
Mar 26 06:34:34.608: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 31.619793ms)
Mar 26 06:34:34.615: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 40.075406ms)
Mar 26 06:34:34.616: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 38.932226ms)
Mar 26 06:34:34.620: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 44.121476ms)
Mar 26 06:34:34.626: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 50.583421ms)
Mar 26 06:34:34.632: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 56.34438ms)
Mar 26 06:34:34.634: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 58.279396ms)
Mar 26 06:34:34.634: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 58.323715ms)
Mar 26 06:34:34.659: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 23.793828ms)
Mar 26 06:34:34.660: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 25.277969ms)
Mar 26 06:34:34.660: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 25.665844ms)
Mar 26 06:34:34.662: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 25.911221ms)
Mar 26 06:34:34.684: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 48.634037ms)
Mar 26 06:34:34.685: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 50.259945ms)
Mar 26 06:34:34.686: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 49.723407ms)
Mar 26 06:34:34.686: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 51.1905ms)
Mar 26 06:34:34.687: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 50.25589ms)
Mar 26 06:34:34.687: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 50.201373ms)
Mar 26 06:34:34.687: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 52.02512ms)
Mar 26 06:34:34.687: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 52.144034ms)
Mar 26 06:34:34.688: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 51.891561ms)
Mar 26 06:34:34.689: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 53.478492ms)
Mar 26 06:34:34.689: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 55.325329ms)
Mar 26 06:34:34.691: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 54.986624ms)
Mar 26 06:34:34.714: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 22.158534ms)
Mar 26 06:34:34.714: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 21.748026ms)
Mar 26 06:34:34.716: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 23.874809ms)
Mar 26 06:34:34.717: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 25.127088ms)
Mar 26 06:34:34.733: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 40.360078ms)
Mar 26 06:34:34.741: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 48.330368ms)
Mar 26 06:34:34.747: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 54.509018ms)
Mar 26 06:34:34.747: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 54.885765ms)
Mar 26 06:34:34.747: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 54.645561ms)
Mar 26 06:34:34.748: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 55.000992ms)
Mar 26 06:34:34.748: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 55.307379ms)
Mar 26 06:34:34.748: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 54.953676ms)
Mar 26 06:34:34.748: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 55.257053ms)
Mar 26 06:34:34.748: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 55.279892ms)
Mar 26 06:34:34.748: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 55.263498ms)
Mar 26 06:34:34.748: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 55.411327ms)
Mar 26 06:34:34.771: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 22.663699ms)
Mar 26 06:34:34.773: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 24.849915ms)
Mar 26 06:34:34.814: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 62.825953ms)
Mar 26 06:34:34.820: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 69.381397ms)
Mar 26 06:34:34.820: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 68.625528ms)
Mar 26 06:34:34.820: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 69.078445ms)
Mar 26 06:34:34.820: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 69.584039ms)
Mar 26 06:34:34.820: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 68.933591ms)
Mar 26 06:34:34.820: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 69.720885ms)
Mar 26 06:34:34.820: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 71.414854ms)
Mar 26 06:34:34.827: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 75.425232ms)
Mar 26 06:34:34.827: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 76.692447ms)
Mar 26 06:34:34.827: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 77.839347ms)
Mar 26 06:34:34.831: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 82.184525ms)
Mar 26 06:34:34.835: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 84.261852ms)
Mar 26 06:34:34.835: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 84.222079ms)
Mar 26 06:34:34.863: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 27.492492ms)
Mar 26 06:34:34.864: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 28.42105ms)
Mar 26 06:34:34.865: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 29.239876ms)
Mar 26 06:34:34.865: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 29.699897ms)
Mar 26 06:34:34.866: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 29.863266ms)
Mar 26 06:34:34.867: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 30.846421ms)
Mar 26 06:34:34.889: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 53.281182ms)
Mar 26 06:34:34.889: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 51.695827ms)
Mar 26 06:34:34.890: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 53.922285ms)
Mar 26 06:34:34.891: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 52.825427ms)
Mar 26 06:34:34.891: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 53.611491ms)
Mar 26 06:34:34.891: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 54.384694ms)
Mar 26 06:34:34.896: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 59.351841ms)
Mar 26 06:34:34.897: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 59.514987ms)
Mar 26 06:34:34.899: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 61.195807ms)
Mar 26 06:34:34.900: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 62.490552ms)
Mar 26 06:34:34.925: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 24.773668ms)
Mar 26 06:34:34.926: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 25.815222ms)
Mar 26 06:34:34.927: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 25.785419ms)
Mar 26 06:34:34.928: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 26.83747ms)
Mar 26 06:34:34.928: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 26.736351ms)
Mar 26 06:34:34.936: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 33.517891ms)
Mar 26 06:34:34.936: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 34.520134ms)
Mar 26 06:34:34.940: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 38.407281ms)
Mar 26 06:34:34.941: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 38.835788ms)
Mar 26 06:34:34.941: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 40.153794ms)
Mar 26 06:34:34.944: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 41.130372ms)
Mar 26 06:34:34.944: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 41.898463ms)
Mar 26 06:34:34.944: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 43.625402ms)
Mar 26 06:34:34.945: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 43.660706ms)
Mar 26 06:34:34.948: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 45.051614ms)
Mar 26 06:34:34.948: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 46.004092ms)
Mar 26 06:34:34.973: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 24.000254ms)
Mar 26 06:34:34.974: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 25.451648ms)
Mar 26 06:34:35.016: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 65.842281ms)
Mar 26 06:34:35.017: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 67.353946ms)
Mar 26 06:34:35.018: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 66.859704ms)
Mar 26 06:34:35.018: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 67.771647ms)
Mar 26 06:34:35.019: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 69.972088ms)
Mar 26 06:34:35.023: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 73.318931ms)
Mar 26 06:34:35.024: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 75.198952ms)
Mar 26 06:34:35.025: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 75.787493ms)
Mar 26 06:34:35.026: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 76.102666ms)
Mar 26 06:34:35.027: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 76.544098ms)
Mar 26 06:34:35.028: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 77.490642ms)
Mar 26 06:34:35.030: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 79.727847ms)
Mar 26 06:34:35.031: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 81.482454ms)
Mar 26 06:34:35.032: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 81.745166ms)
Mar 26 06:34:35.059: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 26.615249ms)
Mar 26 06:34:35.063: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 29.550688ms)
Mar 26 06:34:35.074: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 40.818948ms)
Mar 26 06:34:35.081: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 47.318584ms)
Mar 26 06:34:35.083: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 47.643761ms)
Mar 26 06:34:35.084: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 50.404124ms)
Mar 26 06:34:35.084: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 49.07867ms)
Mar 26 06:34:35.084: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 49.586602ms)
Mar 26 06:34:35.085: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 52.138017ms)
Mar 26 06:34:35.086: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 50.000294ms)
Mar 26 06:34:35.089: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 54.296277ms)
Mar 26 06:34:35.090: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 54.573083ms)
Mar 26 06:34:35.091: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 56.495948ms)
Mar 26 06:34:35.092: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 57.763144ms)
Mar 26 06:34:35.093: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 58.10983ms)
Mar 26 06:34:35.094: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 58.54697ms)
Mar 26 06:34:35.114: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 20.391222ms)
Mar 26 06:34:35.116: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 20.804496ms)
Mar 26 06:34:35.117: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 22.125318ms)
Mar 26 06:34:35.135: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 39.661241ms)
Mar 26 06:34:35.136: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 39.249478ms)
Mar 26 06:34:35.136: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 39.745193ms)
Mar 26 06:34:35.137: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 40.930117ms)
Mar 26 06:34:35.139: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 42.911269ms)
Mar 26 06:34:35.141: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 44.537642ms)
Mar 26 06:34:35.142: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 45.384358ms)
Mar 26 06:34:35.147: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 52.2354ms)
Mar 26 06:34:35.147: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 51.695357ms)
Mar 26 06:34:35.149: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 53.614412ms)
Mar 26 06:34:35.152: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 54.663476ms)
Mar 26 06:34:35.153: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 56.657413ms)
Mar 26 06:34:35.153: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 58.156479ms)
Mar 26 06:34:35.174: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 20.860389ms)
Mar 26 06:34:35.178: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 23.945391ms)
Mar 26 06:34:35.178: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 24.012607ms)
Mar 26 06:34:35.179: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 23.676492ms)
Mar 26 06:34:35.180: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 25.282515ms)
Mar 26 06:34:35.181: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 25.138112ms)
Mar 26 06:34:35.181: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 25.299351ms)
Mar 26 06:34:35.182: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 26.412639ms)
Mar 26 06:34:35.188: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 32.932123ms)
Mar 26 06:34:35.192: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 35.81457ms)
Mar 26 06:34:35.193: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 37.868689ms)
Mar 26 06:34:35.193: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 36.974818ms)
Mar 26 06:34:35.194: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 39.167304ms)
Mar 26 06:34:35.195: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 40.758927ms)
Mar 26 06:34:35.197: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 42.855744ms)
Mar 26 06:34:35.198: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 41.122578ms)
Mar 26 06:34:35.219: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 20.604226ms)
Mar 26 06:34:35.221: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 22.887749ms)
Mar 26 06:34:35.236: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 37.641073ms)
Mar 26 06:34:35.245: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 44.693731ms)
Mar 26 06:34:35.247: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 46.958375ms)
Mar 26 06:34:35.248: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 49.83009ms)
Mar 26 06:34:35.249: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 50.46711ms)
Mar 26 06:34:35.249: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 50.270368ms)
Mar 26 06:34:35.249: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 50.227209ms)
Mar 26 06:34:35.249: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 50.381523ms)
Mar 26 06:34:35.251: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 51.475684ms)
Mar 26 06:34:35.253: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 53.933853ms)
Mar 26 06:34:35.255: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 54.821284ms)
Mar 26 06:34:35.255: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 55.489107ms)
Mar 26 06:34:35.256: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 55.9154ms)
Mar 26 06:34:35.259: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 58.988382ms)
Mar 26 06:34:35.286: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 26.617139ms)
Mar 26 06:34:35.289: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 28.763815ms)
Mar 26 06:34:35.290: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 29.213634ms)
Mar 26 06:34:35.290: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 30.443581ms)
Mar 26 06:34:35.290: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 30.219121ms)
Mar 26 06:34:35.292: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 31.044476ms)
Mar 26 06:34:35.295: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 33.540034ms)
Mar 26 06:34:35.296: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 34.189612ms)
Mar 26 06:34:35.296: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 34.468525ms)
Mar 26 06:34:35.297: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 35.315201ms)
Mar 26 06:34:35.311: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 50.053623ms)
Mar 26 06:34:35.311: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 50.322767ms)
Mar 26 06:34:35.313: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 52.692219ms)
Mar 26 06:34:35.313: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 52.844201ms)
Mar 26 06:34:35.313: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 53.875431ms)
Mar 26 06:34:35.314: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 53.447122ms)
Mar 26 06:34:35.353: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 38.66713ms)
Mar 26 06:34:35.359: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll/proxy/rewriteme"... (200; 43.853177ms)
Mar 26 06:34:35.359: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:443/proxy/... (200; 42.667682ms)
Mar 26 06:34:35.359: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:460/proxy/: tls baz (200; 43.802918ms)
Mar 26 06:34:35.359: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:1080/proxy/... (200; 44.092561ms)
Mar 26 06:34:35.363: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/https:proxy-service-p9rp2-5l5ll:462/proxy/: tls qux (200; 46.642826ms)
Mar 26 06:34:35.363: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:160/proxy/: foo (200; 47.145266ms)
Mar 26 06:34:35.366: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname1/proxy/: tls baz (200; 50.998586ms)
Mar 26 06:34:35.366: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:1080/proxy/rewri... (200; 49.465671ms)
Mar 26 06:34:35.367: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname1/proxy/: foo (200; 51.737336ms)
Mar 26 06:34:35.367: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/http:proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 50.354052ms)
Mar 26 06:34:35.368: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/pods/proxy-service-p9rp2-5l5ll:162/proxy/: bar (200; 50.783588ms)
Mar 26 06:34:35.368: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname1/proxy/: foo (200; 52.972623ms)
Mar 26 06:34:35.369: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/services/proxy-service-p9rp2:portname2/proxy/: bar (200; 51.537815ms)
Mar 26 06:34:35.369: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/services/http:proxy-service-p9rp2:portname2/proxy/: bar (200; 53.569701ms)
Mar 26 06:34:35.370: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2752m/services/https:proxy-service-p9rp2:tlsportname2/proxy/: tls qux (200; 53.464832ms)
STEP: deleting { ReplicationController} proxy-service-p9rp2 in namespace e2e-tests-proxy-2752m, will wait for the garbage collector to delete the pods
Mar 26 06:34:35.440: INFO: Deleting { ReplicationController} proxy-service-p9rp2 took: 14.314762ms
Mar 26 06:34:35.540: INFO: Terminating { ReplicationController} proxy-service-p9rp2 pods took: 100.512852ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:34:38.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-2752m" for this suite.
Mar 26 06:34:44.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:34:44.630: INFO: namespace: e2e-tests-proxy-2752m, resource: bindings, ignored listing per whitelist
Mar 26 06:34:44.705: INFO: namespace e2e-tests-proxy-2752m deletion completed in 6.330541611s

• [SLOW TEST:21.977 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:34:44.707: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar 26 06:34:44.946: INFO: Waiting up to 5m0s for pod "var-expansion-3e85de74-4f91-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-var-expansion-vkdg6" to be "success or failure"
Mar 26 06:34:44.958: INFO: Pod "var-expansion-3e85de74-4f91-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.195529ms
Mar 26 06:34:46.977: INFO: Pod "var-expansion-3e85de74-4f91-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029605735s
STEP: Saw pod success
Mar 26 06:34:46.977: INFO: Pod "var-expansion-3e85de74-4f91-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:34:46.990: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod var-expansion-3e85de74-4f91-11e9-8fea-5694fc6fbac7 container dapi-container: <nil>
STEP: delete the pod
Mar 26 06:34:47.087: INFO: Waiting for pod var-expansion-3e85de74-4f91-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:34:47.095: INFO: Pod var-expansion-3e85de74-4f91-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:34:47.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-vkdg6" for this suite.
Mar 26 06:34:53.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:34:53.322: INFO: namespace: e2e-tests-var-expansion-vkdg6, resource: bindings, ignored listing per whitelist
Mar 26 06:34:53.373: INFO: namespace e2e-tests-var-expansion-vkdg6 deletion completed in 6.267556647s

• [SLOW TEST:8.667 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:34:53.377: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-43b1bf3e-4f91-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:34:53.634: INFO: Waiting up to 5m0s for pod "pod-configmaps-43b31ae1-4f91-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-configmap-jq2hv" to be "success or failure"
Mar 26 06:34:53.664: INFO: Pod "pod-configmaps-43b31ae1-4f91-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 29.87394ms
Mar 26 06:34:55.672: INFO: Pod "pod-configmaps-43b31ae1-4f91-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03762287s
STEP: Saw pod success
Mar 26 06:34:55.672: INFO: Pod "pod-configmaps-43b31ae1-4f91-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:34:55.678: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-configmaps-43b31ae1-4f91-11e9-8fea-5694fc6fbac7 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 06:34:55.731: INFO: Waiting for pod pod-configmaps-43b31ae1-4f91-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:34:55.745: INFO: Pod pod-configmaps-43b31ae1-4f91-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:34:55.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jq2hv" for this suite.
Mar 26 06:35:01.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:35:01.873: INFO: namespace: e2e-tests-configmap-jq2hv, resource: bindings, ignored listing per whitelist
Mar 26 06:35:02.097: INFO: namespace e2e-tests-configmap-jq2hv deletion completed in 6.32367304s

• [SLOW TEST:8.721 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:35:02.099: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:35:02.380: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar 26 06:35:02.415: INFO: Number of nodes with available pods: 0
Mar 26 06:35:02.416: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 06:35:03.450: INFO: Number of nodes with available pods: 0
Mar 26 06:35:03.451: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 06:35:04.455: INFO: Number of nodes with available pods: 1
Mar 26 06:35:04.455: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 06:35:05.447: INFO: Number of nodes with available pods: 5
Mar 26 06:35:05.447: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar 26 06:35:05.509: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:05.509: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:05.509: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:05.509: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:05.510: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:06.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:06.546: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:06.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:06.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:06.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:07.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:07.546: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:07.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:07.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:07.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:08.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:08.546: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:08.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:08.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:08.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:09.548: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:09.548: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:09.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:09.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:09.548: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:10.555: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:10.555: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:10.555: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:10.555: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:10.555: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:11.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:11.547: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:11.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:11.547: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:11.547: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:12.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:12.545: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:12.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:12.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:12.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:13.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:13.545: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:13.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:13.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:13.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:14.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:14.546: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:14.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:14.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:14.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:15.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:15.544: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:15.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:15.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:15.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:16.552: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:16.552: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:16.552: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:16.552: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:16.552: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:17.550: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:17.551: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:17.551: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:17.551: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:17.551: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:18.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:18.546: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:18.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:18.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:18.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:19.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:19.546: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:19.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:19.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:19.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:20.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:20.545: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:20.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:20.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:20.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:21.552: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:21.553: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:21.553: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:21.553: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:21.553: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:22.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:22.544: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:22.544: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:22.544: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:22.544: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:23.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:23.547: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:23.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:23.547: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:23.547: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:24.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:24.546: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:24.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:24.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:24.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:25.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:25.545: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:25.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:25.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:25.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:26.548: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:26.548: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:26.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:26.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:26.548: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:27.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:27.546: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:27.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:27.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:27.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:28.551: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:28.552: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:28.552: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:28.552: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:28.552: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:29.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:29.546: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:29.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:29.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:29.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:30.556: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:30.557: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:30.557: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:30.557: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:30.557: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:31.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:31.547: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:31.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:31.547: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:31.547: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:32.571: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:32.571: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:32.571: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:32.571: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:32.571: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:33.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:33.547: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:33.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:33.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:33.548: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:34.549: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:34.549: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:34.549: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:34.549: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:34.549: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:35.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:35.548: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:35.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:35.549: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:35.549: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:36.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:36.548: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:36.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:36.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:36.548: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:37.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:37.546: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:37.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:37.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:37.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:38.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:38.547: INFO: Wrong image for pod: daemon-set-hc4kc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:38.547: INFO: Pod daemon-set-hc4kc is not available
Mar 26 06:35:38.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:38.547: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:38.547: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:39.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:39.546: INFO: Pod daemon-set-jdxcb is not available
Mar 26 06:35:39.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:39.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:39.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:40.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:40.546: INFO: Pod daemon-set-jdxcb is not available
Mar 26 06:35:40.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:40.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:40.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:41.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:41.544: INFO: Pod daemon-set-jdxcb is not available
Mar 26 06:35:41.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:41.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:41.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:42.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:42.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:42.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:42.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:43.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:43.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:43.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:43.548: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:44.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:44.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:44.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:44.548: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:45.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:45.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:45.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:45.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:46.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:46.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:46.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:46.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:47.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:47.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:47.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:47.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:48.574: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:48.574: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:48.574: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:48.574: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:49.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:49.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:49.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:49.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:50.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:50.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:50.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:50.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:51.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:51.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:51.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:51.547: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:52.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:52.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:52.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:52.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:53.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:53.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:53.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:53.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:54.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:54.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:54.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:54.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:55.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:55.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:55.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:55.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:56.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:56.544: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:56.544: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:56.544: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:57.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:57.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:57.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:57.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:58.568: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:58.568: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:58.568: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:58.568: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:59.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:59.544: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:59.544: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:35:59.544: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:00.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:00.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:00.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:00.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:01.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:01.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:01.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:01.548: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:02.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:02.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:02.547: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:02.548: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:03.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:03.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:03.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:03.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:04.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:04.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:04.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:04.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:05.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:05.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:05.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:05.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:06.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:06.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:06.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:06.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:07.557: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:07.557: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:07.557: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:07.557: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:08.548: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:08.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:08.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:08.548: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:09.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:09.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:09.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:09.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:10.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:10.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:10.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:10.548: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:11.548: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:11.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:11.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:11.548: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:12.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:12.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:12.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:12.546: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:13.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:13.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:13.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:13.545: INFO: Wrong image for pod: daemon-set-k2lcm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:13.545: INFO: Pod daemon-set-k2lcm is not available
Mar 26 06:36:14.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:14.545: INFO: Pod daemon-set-6mcsv is not available
Mar 26 06:36:14.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:14.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:15.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:15.544: INFO: Pod daemon-set-6mcsv is not available
Mar 26 06:36:15.544: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:15.544: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:16.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:16.546: INFO: Pod daemon-set-6mcsv is not available
Mar 26 06:36:16.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:16.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:17.548: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:17.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:17.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:18.549: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:18.549: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:18.549: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:19.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:19.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:19.547: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:20.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:20.557: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:20.557: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:21.566: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:21.566: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:21.566: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:22.548: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:22.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:22.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:23.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:23.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:23.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:24.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:24.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:24.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:25.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:25.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:25.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:26.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:26.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:26.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:27.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:27.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:27.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:28.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:28.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:28.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:29.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:29.544: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:29.544: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:30.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:30.544: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:30.544: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:31.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:31.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:31.547: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:32.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:32.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:32.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:33.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:33.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:33.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:34.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:34.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:34.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:35.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:35.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:35.547: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:36.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:36.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:36.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:37.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:37.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:37.547: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:38.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:38.544: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:38.544: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:39.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:39.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:39.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:40.568: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:40.569: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:40.569: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:41.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:41.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:41.547: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:42.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:42.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:42.548: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:43.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:43.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:43.546: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:44.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:44.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:44.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:45.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:45.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:45.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:46.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:46.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:46.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:47.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:47.544: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:47.545: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:48.570: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:48.570: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:48.570: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:48.571: INFO: Pod daemon-set-jzbkd is not available
Mar 26 06:36:49.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:49.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:49.547: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:49.547: INFO: Pod daemon-set-jzbkd is not available
Mar 26 06:36:50.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:50.544: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:50.544: INFO: Wrong image for pod: daemon-set-jzbkd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:50.544: INFO: Pod daemon-set-jzbkd is not available
Mar 26 06:36:51.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:51.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:51.546: INFO: Pod daemon-set-mbvv4 is not available
Mar 26 06:36:52.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:52.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:52.547: INFO: Pod daemon-set-mbvv4 is not available
Mar 26 06:36:53.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:53.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:54.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:54.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:55.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:55.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:56.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:56.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:57.552: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:57.552: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:58.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:58.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:59.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:36:59.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:00.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:00.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:01.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:01.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:02.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:02.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:03.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:03.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:04.549: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:04.549: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:05.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:05.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:06.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:06.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:07.563: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:07.564: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:08.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:08.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:09.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:09.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:10.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:10.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:11.562: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:11.563: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:12.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:12.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:13.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:13.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:14.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:14.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:15.554: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:15.554: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:16.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:16.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:17.549: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:17.550: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:18.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:18.547: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:19.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:19.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:20.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:20.548: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:21.575: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:21.576: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:22.639: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:22.639: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:23.627: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:23.627: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:24.623: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:24.624: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:24.624: INFO: Pod daemon-set-jsrw9 is not available
Mar 26 06:37:25.616: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:25.617: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:25.617: INFO: Pod daemon-set-jsrw9 is not available
Mar 26 06:37:26.613: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:26.614: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:26.614: INFO: Pod daemon-set-jsrw9 is not available
Mar 26 06:37:27.636: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:27.636: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:27.637: INFO: Pod daemon-set-jsrw9 is not available
Mar 26 06:37:28.655: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:28.655: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:28.655: INFO: Pod daemon-set-jsrw9 is not available
Mar 26 06:37:29.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:29.545: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:29.545: INFO: Pod daemon-set-jsrw9 is not available
Mar 26 06:37:30.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:30.546: INFO: Wrong image for pod: daemon-set-jsrw9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:30.546: INFO: Pod daemon-set-jsrw9 is not available
Mar 26 06:37:31.591: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:32.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:32.547: INFO: Pod daemon-set-svq4v is not available
Mar 26 06:37:33.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:33.546: INFO: Pod daemon-set-svq4v is not available
Mar 26 06:37:34.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:35.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:36.551: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:37.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:38.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:39.593: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:40.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:41.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:42.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:43.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:44.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:45.563: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:46.550: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:47.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:48.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:49.599: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:50.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:51.550: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:52.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:53.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:54.548: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:55.553: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:56.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:57.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:58.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:37:59.555: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:00.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:01.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:02.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:03.578: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:04.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:05.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:06.544: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:06.545: INFO: Pod daemon-set-5mwn6 is not available
Mar 26 06:38:07.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:07.545: INFO: Pod daemon-set-5mwn6 is not available
Mar 26 06:38:08.543: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:08.543: INFO: Pod daemon-set-5mwn6 is not available
Mar 26 06:38:09.545: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:09.546: INFO: Pod daemon-set-5mwn6 is not available
Mar 26 06:38:10.547: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:10.547: INFO: Pod daemon-set-5mwn6 is not available
Mar 26 06:38:11.546: INFO: Wrong image for pod: daemon-set-5mwn6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 26 06:38:11.546: INFO: Pod daemon-set-5mwn6 is not available
Mar 26 06:38:12.547: INFO: Pod daemon-set-qbwx7 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar 26 06:38:12.578: INFO: Number of nodes with available pods: 4
Mar 26 06:38:12.579: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:38:13.600: INFO: Number of nodes with available pods: 4
Mar 26 06:38:13.601: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:38:14.598: INFO: Number of nodes with available pods: 5
Mar 26 06:38:14.598: INFO: Number of running nodes: 5, number of available pods: 5
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-f5gzt, will wait for the garbage collector to delete the pods
Mar 26 06:38:14.761: INFO: Deleting {extensions DaemonSet} daemon-set took: 71.118123ms
Mar 26 06:38:15.263: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 501.013108ms
Mar 26 06:38:27.469: INFO: Number of nodes with available pods: 0
Mar 26 06:38:27.469: INFO: Number of running nodes: 0, number of available pods: 0
Mar 26 06:38:27.474: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-f5gzt/daemonsets","resourceVersion":"45413"},"items":null}

Mar 26 06:38:27.481: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-f5gzt/pods","resourceVersion":"45413"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:38:27.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-f5gzt" for this suite.
Mar 26 06:38:35.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:38:35.737: INFO: namespace: e2e-tests-daemonsets-f5gzt, resource: bindings, ignored listing per whitelist
Mar 26 06:38:35.989: INFO: namespace e2e-tests-daemonsets-f5gzt deletion completed in 8.387841891s

• [SLOW TEST:213.890 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:38:35.989: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-ltcn9/secret-test-c8603bdb-4f91-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 06:38:36.285: INFO: Waiting up to 5m0s for pod "pod-configmaps-c866d870-4f91-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-secrets-ltcn9" to be "success or failure"
Mar 26 06:38:36.336: INFO: Pod "pod-configmaps-c866d870-4f91-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 50.55256ms
Mar 26 06:38:38.360: INFO: Pod "pod-configmaps-c866d870-4f91-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074896149s
Mar 26 06:38:40.368: INFO: Pod "pod-configmaps-c866d870-4f91-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.082509905s
STEP: Saw pod success
Mar 26 06:38:40.368: INFO: Pod "pod-configmaps-c866d870-4f91-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:38:40.374: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-configmaps-c866d870-4f91-11e9-8fea-5694fc6fbac7 container env-test: <nil>
STEP: delete the pod
Mar 26 06:38:40.472: INFO: Waiting for pod pod-configmaps-c866d870-4f91-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:38:40.482: INFO: Pod pod-configmaps-c866d870-4f91-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:38:40.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ltcn9" for this suite.
Mar 26 06:38:46.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:38:46.749: INFO: namespace: e2e-tests-secrets-ltcn9, resource: bindings, ignored listing per whitelist
Mar 26 06:38:46.966: INFO: namespace e2e-tests-secrets-ltcn9 deletion completed in 6.461275685s

• [SLOW TEST:10.977 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:38:46.967: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 06:38:47.263: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cef289d1-4f91-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-7xl6n" to be "success or failure"
Mar 26 06:38:47.288: INFO: Pod "downwardapi-volume-cef289d1-4f91-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.631823ms
Mar 26 06:38:49.296: INFO: Pod "downwardapi-volume-cef289d1-4f91-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032005887s
Mar 26 06:38:51.313: INFO: Pod "downwardapi-volume-cef289d1-4f91-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049565427s
STEP: Saw pod success
Mar 26 06:38:51.313: INFO: Pod "downwardapi-volume-cef289d1-4f91-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:38:51.335: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downwardapi-volume-cef289d1-4f91-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 06:38:51.623: INFO: Waiting for pod downwardapi-volume-cef289d1-4f91-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:38:51.662: INFO: Pod downwardapi-volume-cef289d1-4f91-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:38:51.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7xl6n" for this suite.
Mar 26 06:38:58.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:38:58.187: INFO: namespace: e2e-tests-downward-api-7xl6n, resource: bindings, ignored listing per whitelist
Mar 26 06:38:58.308: INFO: namespace e2e-tests-downward-api-7xl6n deletion completed in 6.274710307s

• [SLOW TEST:11.341 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:38:58.311: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 26 06:39:01.581: INFO: Successfully updated pod "labelsupdated5e6c37b-4f91-11e9-8fea-5694fc6fbac7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:39:05.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j9ckd" for this suite.
Mar 26 06:39:29.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:39:30.010: INFO: namespace: e2e-tests-downward-api-j9ckd, resource: bindings, ignored listing per whitelist
Mar 26 06:39:30.033: INFO: namespace e2e-tests-downward-api-j9ckd deletion completed in 24.338604966s

• [SLOW TEST:31.723 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:39:30.036: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 26 06:39:36.416: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dmwhx PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:39:36.416: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:39:36.635: INFO: Exec stderr: ""
Mar 26 06:39:36.636: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dmwhx PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:39:36.636: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:39:36.805: INFO: Exec stderr: ""
Mar 26 06:39:36.806: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dmwhx PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:39:36.806: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:39:36.975: INFO: Exec stderr: ""
Mar 26 06:39:36.976: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dmwhx PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:39:36.976: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:39:37.139: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 26 06:39:37.140: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dmwhx PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:39:37.140: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:39:37.286: INFO: Exec stderr: ""
Mar 26 06:39:37.287: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dmwhx PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:39:37.287: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:39:37.550: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 26 06:39:37.552: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dmwhx PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:39:37.552: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:39:37.757: INFO: Exec stderr: ""
Mar 26 06:39:37.759: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dmwhx PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:39:37.759: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:39:37.925: INFO: Exec stderr: ""
Mar 26 06:39:37.925: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dmwhx PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:39:37.926: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:39:38.133: INFO: Exec stderr: ""
Mar 26 06:39:38.135: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dmwhx PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:39:38.135: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:39:38.338: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:39:38.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-dmwhx" for this suite.
Mar 26 06:40:22.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:40:22.507: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-dmwhx, resource: bindings, ignored listing per whitelist
Mar 26 06:40:22.676: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-dmwhx deletion completed in 44.31703726s

• [SLOW TEST:52.641 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:40:22.679: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 26 06:40:22.931: INFO: Waiting up to 5m0s for pod "downward-api-07f8cec7-4f92-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-9pb2f" to be "success or failure"
Mar 26 06:40:22.949: INFO: Pod "downward-api-07f8cec7-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.060807ms
Mar 26 06:40:24.959: INFO: Pod "downward-api-07f8cec7-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027879079s
Mar 26 06:40:26.967: INFO: Pod "downward-api-07f8cec7-4f92-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035889347s
STEP: Saw pod success
Mar 26 06:40:26.967: INFO: Pod "downward-api-07f8cec7-4f92-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:40:26.973: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downward-api-07f8cec7-4f92-11e9-8fea-5694fc6fbac7 container dapi-container: <nil>
STEP: delete the pod
Mar 26 06:40:27.045: INFO: Waiting for pod downward-api-07f8cec7-4f92-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:40:27.062: INFO: Pod downward-api-07f8cec7-4f92-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:40:27.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9pb2f" for this suite.
Mar 26 06:40:33.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:40:33.286: INFO: namespace: e2e-tests-downward-api-9pb2f, resource: bindings, ignored listing per whitelist
Mar 26 06:40:33.373: INFO: namespace e2e-tests-downward-api-9pb2f deletion completed in 6.291729916s

• [SLOW TEST:10.695 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:40:33.375: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-dpf9l
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 26 06:40:33.645: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 26 06:40:54.298: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.42.0.94 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dpf9l PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:40:54.298: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:40:55.458: INFO: Found all expected endpoints: [netserver-0]
Mar 26 06:40:55.466: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.42.4.33 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dpf9l PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:40:55.466: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:40:56.609: INFO: Found all expected endpoints: [netserver-1]
Mar 26 06:40:56.617: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.42.2.45 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dpf9l PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:40:56.617: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:40:57.773: INFO: Found all expected endpoints: [netserver-2]
Mar 26 06:40:57.780: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.42.3.32 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dpf9l PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:40:57.780: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:40:58.940: INFO: Found all expected endpoints: [netserver-3]
Mar 26 06:40:58.947: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.42.1.93 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-dpf9l PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 26 06:40:58.947: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
Mar 26 06:41:00.097: INFO: Found all expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:41:00.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-dpf9l" for this suite.
Mar 26 06:41:24.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:41:24.365: INFO: namespace: e2e-tests-pod-network-test-dpf9l, resource: bindings, ignored listing per whitelist
Mar 26 06:41:24.447: INFO: namespace e2e-tests-pod-network-test-dpf9l deletion completed in 24.337627103s

• [SLOW TEST:51.073 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:41:24.450: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-jnx2z/configmap-test-2cc73d8a-4f92-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 06:41:24.709: INFO: Waiting up to 5m0s for pod "pod-configmaps-2cca87f5-4f92-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-configmap-jnx2z" to be "success or failure"
Mar 26 06:41:24.746: INFO: Pod "pod-configmaps-2cca87f5-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 35.996059ms
Mar 26 06:41:26.770: INFO: Pod "pod-configmaps-2cca87f5-4f92-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.061025741s
STEP: Saw pod success
Mar 26 06:41:26.771: INFO: Pod "pod-configmaps-2cca87f5-4f92-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:41:26.782: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-configmaps-2cca87f5-4f92-11e9-8fea-5694fc6fbac7 container env-test: <nil>
STEP: delete the pod
Mar 26 06:41:26.885: INFO: Waiting for pod pod-configmaps-2cca87f5-4f92-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:41:26.982: INFO: Pod pod-configmaps-2cca87f5-4f92-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:41:26.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jnx2z" for this suite.
Mar 26 06:41:33.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:41:33.140: INFO: namespace: e2e-tests-configmap-jnx2z, resource: bindings, ignored listing per whitelist
Mar 26 06:41:33.291: INFO: namespace e2e-tests-configmap-jnx2z deletion completed in 6.294421112s

• [SLOW TEST:8.841 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:41:33.296: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 26 06:41:33.530: INFO: Waiting up to 5m0s for pod "pod-32089c0c-4f92-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-dbzps" to be "success or failure"
Mar 26 06:41:33.570: INFO: Pod "pod-32089c0c-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 40.09899ms
Mar 26 06:41:35.576: INFO: Pod "pod-32089c0c-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046616681s
Mar 26 06:41:37.585: INFO: Pod "pod-32089c0c-4f92-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05496244s
STEP: Saw pod success
Mar 26 06:41:37.585: INFO: Pod "pod-32089c0c-4f92-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:41:37.591: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-32089c0c-4f92-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 06:41:37.670: INFO: Waiting for pod pod-32089c0c-4f92-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:41:37.681: INFO: Pod pod-32089c0c-4f92-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:41:37.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dbzps" for this suite.
Mar 26 06:41:43.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:41:43.851: INFO: namespace: e2e-tests-emptydir-dbzps, resource: bindings, ignored listing per whitelist
Mar 26 06:41:44.052: INFO: namespace e2e-tests-emptydir-dbzps deletion completed in 6.354881449s

• [SLOW TEST:10.757 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:41:44.056: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-38763518-4f92-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 06:41:44.305: INFO: Waiting up to 5m0s for pod "pod-secrets-38780749-4f92-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-secrets-g4h6c" to be "success or failure"
Mar 26 06:41:44.314: INFO: Pod "pod-secrets-38780749-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.706951ms
Mar 26 06:41:46.322: INFO: Pod "pod-secrets-38780749-4f92-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015953979s
STEP: Saw pod success
Mar 26 06:41:46.323: INFO: Pod "pod-secrets-38780749-4f92-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:41:46.329: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-secrets-38780749-4f92-11e9-8fea-5694fc6fbac7 container secret-volume-test: <nil>
STEP: delete the pod
Mar 26 06:41:46.423: INFO: Waiting for pod pod-secrets-38780749-4f92-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:41:46.437: INFO: Pod pod-secrets-38780749-4f92-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:41:46.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g4h6c" for this suite.
Mar 26 06:41:52.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:41:52.603: INFO: namespace: e2e-tests-secrets-g4h6c, resource: bindings, ignored listing per whitelist
Mar 26 06:41:52.720: INFO: namespace e2e-tests-secrets-g4h6c deletion completed in 6.262441408s

• [SLOW TEST:8.664 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:41:52.721: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 26 06:41:59.064: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 06:41:59.083: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 06:42:01.083: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 06:42:01.090: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 06:42:03.083: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 06:42:03.090: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 06:42:05.083: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 06:42:05.089: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 06:42:07.083: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 06:42:07.090: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 06:42:09.087: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 06:42:09.095: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 06:42:11.083: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 06:42:11.092: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 06:42:13.083: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 06:42:13.091: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 06:42:15.083: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 06:42:15.092: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 06:42:17.083: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 06:42:17.097: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 26 06:42:19.083: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 26 06:42:19.093: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:42:19.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-tsl56" for this suite.
Mar 26 06:42:47.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:42:47.270: INFO: namespace: e2e-tests-container-lifecycle-hook-tsl56, resource: bindings, ignored listing per whitelist
Mar 26 06:42:47.419: INFO: namespace e2e-tests-container-lifecycle-hook-tsl56 deletion completed in 28.284180828s

• [SLOW TEST:54.698 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:42:47.420: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Mar 26 06:42:47.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-rxzdf'
Mar 26 06:42:48.314: INFO: stderr: ""
Mar 26 06:42:48.314: INFO: stdout: "pod/pause created\n"
Mar 26 06:42:48.314: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 26 06:42:48.314: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-rxzdf" to be "running and ready"
Mar 26 06:42:48.326: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 12.794572ms
Mar 26 06:42:50.335: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.021006271s
Mar 26 06:42:50.335: INFO: Pod "pause" satisfied condition "running and ready"
Mar 26 06:42:50.335: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar 26 06:42:50.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-rxzdf'
Mar 26 06:42:50.546: INFO: stderr: ""
Mar 26 06:42:50.547: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar 26 06:42:50.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pod pause -L testing-label --namespace=e2e-tests-kubectl-rxzdf'
Mar 26 06:42:50.712: INFO: stderr: ""
Mar 26 06:42:50.712: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar 26 06:42:50.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 label pods pause testing-label- --namespace=e2e-tests-kubectl-rxzdf'
Mar 26 06:42:50.879: INFO: stderr: ""
Mar 26 06:42:50.879: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar 26 06:42:50.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pod pause -L testing-label --namespace=e2e-tests-kubectl-rxzdf'
Mar 26 06:42:51.056: INFO: stderr: ""
Mar 26 06:42:51.056: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Mar 26 06:42:51.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rxzdf'
Mar 26 06:42:51.259: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 06:42:51.259: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 26 06:42:51.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-rxzdf'
Mar 26 06:42:51.430: INFO: stderr: "No resources found.\n"
Mar 26 06:42:51.431: INFO: stdout: ""
Mar 26 06:42:51.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pods -l name=pause --namespace=e2e-tests-kubectl-rxzdf -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 26 06:42:51.606: INFO: stderr: ""
Mar 26 06:42:51.606: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:42:51.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rxzdf" for this suite.
Mar 26 06:42:57.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:42:57.876: INFO: namespace: e2e-tests-kubectl-rxzdf, resource: bindings, ignored listing per whitelist
Mar 26 06:42:57.908: INFO: namespace e2e-tests-kubectl-rxzdf deletion completed in 6.285510616s

• [SLOW TEST:10.488 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:42:57.910: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0326 06:43:28.742397      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 06:43:28.742: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:43:28.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-snrh9" for this suite.
Mar 26 06:43:36.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:43:37.055: INFO: namespace: e2e-tests-gc-snrh9, resource: bindings, ignored listing per whitelist
Mar 26 06:43:37.139: INFO: namespace e2e-tests-gc-snrh9 deletion completed in 8.385645103s

• [SLOW TEST:39.229 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:43:37.140: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 26 06:43:37.518: INFO: Waiting up to 5m0s for pod "pod-7bf45ca2-4f92-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-27szh" to be "success or failure"
Mar 26 06:43:37.583: INFO: Pod "pod-7bf45ca2-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 64.093317ms
Mar 26 06:43:39.592: INFO: Pod "pod-7bf45ca2-4f92-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.073231146s
STEP: Saw pod success
Mar 26 06:43:39.592: INFO: Pod "pod-7bf45ca2-4f92-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:43:39.599: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-7bf45ca2-4f92-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 06:43:39.695: INFO: Waiting for pod pod-7bf45ca2-4f92-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:43:39.714: INFO: Pod pod-7bf45ca2-4f92-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:43:39.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-27szh" for this suite.
Mar 26 06:43:45.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:43:45.991: INFO: namespace: e2e-tests-emptydir-27szh, resource: bindings, ignored listing per whitelist
Mar 26 06:43:46.015: INFO: namespace e2e-tests-emptydir-27szh deletion completed in 6.272603483s

• [SLOW TEST:8.875 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:43:46.019: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar 26 06:43:46.269: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5962v,SelfLink:/api/v1/namespaces/e2e-tests-watch-5962v/configmaps/e2e-watch-test-label-changed,UID:81273387-4f92-11e9-b22a-90b8d090d774,ResourceVersion:46713,Generation:0,CreationTimestamp:2019-03-26 06:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 26 06:43:46.269: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5962v,SelfLink:/api/v1/namespaces/e2e-tests-watch-5962v/configmaps/e2e-watch-test-label-changed,UID:81273387-4f92-11e9-b22a-90b8d090d774,ResourceVersion:46714,Generation:0,CreationTimestamp:2019-03-26 06:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 26 06:43:46.270: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5962v,SelfLink:/api/v1/namespaces/e2e-tests-watch-5962v/configmaps/e2e-watch-test-label-changed,UID:81273387-4f92-11e9-b22a-90b8d090d774,ResourceVersion:46715,Generation:0,CreationTimestamp:2019-03-26 06:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar 26 06:43:56.350: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5962v,SelfLink:/api/v1/namespaces/e2e-tests-watch-5962v/configmaps/e2e-watch-test-label-changed,UID:81273387-4f92-11e9-b22a-90b8d090d774,ResourceVersion:46735,Generation:0,CreationTimestamp:2019-03-26 06:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 26 06:43:56.350: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5962v,SelfLink:/api/v1/namespaces/e2e-tests-watch-5962v/configmaps/e2e-watch-test-label-changed,UID:81273387-4f92-11e9-b22a-90b8d090d774,ResourceVersion:46736,Generation:0,CreationTimestamp:2019-03-26 06:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 26 06:43:56.350: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5962v,SelfLink:/api/v1/namespaces/e2e-tests-watch-5962v/configmaps/e2e-watch-test-label-changed,UID:81273387-4f92-11e9-b22a-90b8d090d774,ResourceVersion:46737,Generation:0,CreationTimestamp:2019-03-26 06:43:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:43:56.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5962v" for this suite.
Mar 26 06:44:02.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:44:02.611: INFO: namespace: e2e-tests-watch-5962v, resource: bindings, ignored listing per whitelist
Mar 26 06:44:02.661: INFO: namespace e2e-tests-watch-5962v deletion completed in 6.299119816s

• [SLOW TEST:16.642 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:44:02.665: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-f7m9
STEP: Creating a pod to test atomic-volume-subpath
Mar 26 06:44:02.990: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-f7m9" in namespace "e2e-tests-subpath-8lvdl" to be "success or failure"
Mar 26 06:44:03.013: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.776244ms
Mar 26 06:44:05.022: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032176779s
Mar 26 06:44:07.030: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Running", Reason="", readiness=false. Elapsed: 4.039542864s
Mar 26 06:44:09.037: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Running", Reason="", readiness=false. Elapsed: 6.047124504s
Mar 26 06:44:11.056: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Running", Reason="", readiness=false. Elapsed: 8.0661031s
Mar 26 06:44:13.065: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Running", Reason="", readiness=false. Elapsed: 10.074746064s
Mar 26 06:44:15.072: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Running", Reason="", readiness=false. Elapsed: 12.081708327s
Mar 26 06:44:17.078: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Running", Reason="", readiness=false. Elapsed: 14.087963786s
Mar 26 06:44:19.085: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Running", Reason="", readiness=false. Elapsed: 16.095083043s
Mar 26 06:44:21.092: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Running", Reason="", readiness=false. Elapsed: 18.102153937s
Mar 26 06:44:23.099: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Running", Reason="", readiness=false. Elapsed: 20.108382411s
Mar 26 06:44:25.105: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Running", Reason="", readiness=false. Elapsed: 22.115075745s
Mar 26 06:44:27.112: INFO: Pod "pod-subpath-test-downwardapi-f7m9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.121801081s
STEP: Saw pod success
Mar 26 06:44:27.112: INFO: Pod "pod-subpath-test-downwardapi-f7m9" satisfied condition "success or failure"
Mar 26 06:44:27.118: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-subpath-test-downwardapi-f7m9 container test-container-subpath-downwardapi-f7m9: <nil>
STEP: delete the pod
Mar 26 06:44:27.236: INFO: Waiting for pod pod-subpath-test-downwardapi-f7m9 to disappear
Mar 26 06:44:27.244: INFO: Pod pod-subpath-test-downwardapi-f7m9 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-f7m9
Mar 26 06:44:27.244: INFO: Deleting pod "pod-subpath-test-downwardapi-f7m9" in namespace "e2e-tests-subpath-8lvdl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:44:27.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8lvdl" for this suite.
Mar 26 06:44:33.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:44:33.362: INFO: namespace: e2e-tests-subpath-8lvdl, resource: bindings, ignored listing per whitelist
Mar 26 06:44:33.543: INFO: namespace e2e-tests-subpath-8lvdl deletion completed in 6.278650401s

• [SLOW TEST:30.878 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:44:33.545: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 26 06:44:33.944: INFO: Waiting up to 5m0s for pod "pod-9d94d881-4f92-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-lzllx" to be "success or failure"
Mar 26 06:44:33.976: INFO: Pod "pod-9d94d881-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 32.529574ms
Mar 26 06:44:35.984: INFO: Pod "pod-9d94d881-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040420425s
Mar 26 06:44:37.993: INFO: Pod "pod-9d94d881-4f92-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048891711s
STEP: Saw pod success
Mar 26 06:44:37.993: INFO: Pod "pod-9d94d881-4f92-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:44:37.998: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-9d94d881-4f92-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 06:44:38.144: INFO: Waiting for pod pod-9d94d881-4f92-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:44:38.157: INFO: Pod pod-9d94d881-4f92-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:44:38.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lzllx" for this suite.
Mar 26 06:44:44.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:44:44.502: INFO: namespace: e2e-tests-emptydir-lzllx, resource: bindings, ignored listing per whitelist
Mar 26 06:44:44.514: INFO: namespace e2e-tests-emptydir-lzllx deletion completed in 6.344502748s

• [SLOW TEST:10.970 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:44:44.516: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:44:44.723: INFO: (0) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 9.121998ms)
Mar 26 06:44:44.732: INFO: (1) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.9814ms)
Mar 26 06:44:44.739: INFO: (2) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.483355ms)
Mar 26 06:44:44.747: INFO: (3) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.103584ms)
Mar 26 06:44:44.755: INFO: (4) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.099157ms)
Mar 26 06:44:44.761: INFO: (5) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.349164ms)
Mar 26 06:44:44.770: INFO: (6) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.116172ms)
Mar 26 06:44:44.780: INFO: (7) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 10.211007ms)
Mar 26 06:44:44.798: INFO: (8) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 17.497765ms)
Mar 26 06:44:44.810: INFO: (9) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 12.229143ms)
Mar 26 06:44:44.818: INFO: (10) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.640089ms)
Mar 26 06:44:44.826: INFO: (11) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.951851ms)
Mar 26 06:44:44.835: INFO: (12) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.875876ms)
Mar 26 06:44:44.845: INFO: (13) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 9.412841ms)
Mar 26 06:44:44.853: INFO: (14) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.107432ms)
Mar 26 06:44:44.861: INFO: (15) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.379439ms)
Mar 26 06:44:44.869: INFO: (16) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.811166ms)
Mar 26 06:44:44.876: INFO: (17) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.262759ms)
Mar 26 06:44:44.884: INFO: (18) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.197604ms)
Mar 26 06:44:44.891: INFO: (19) /api/v1/nodes/k8s-conformance-cluster-1-12-control-1:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.894333ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:44:44.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-74cwt" for this suite.
Mar 26 06:44:50.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:44:51.023: INFO: namespace: e2e-tests-proxy-74cwt, resource: bindings, ignored listing per whitelist
Mar 26 06:44:51.174: INFO: namespace e2e-tests-proxy-74cwt deletion completed in 6.271213867s

• [SLOW TEST:6.659 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:44:51.176: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar 26 06:44:51.387: INFO: Waiting up to 5m0s for pod "pod-a7fc737c-4f92-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-k76jc" to be "success or failure"
Mar 26 06:44:51.420: INFO: Pod "pod-a7fc737c-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 32.593589ms
Mar 26 06:44:53.428: INFO: Pod "pod-a7fc737c-4f92-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040340657s
STEP: Saw pod success
Mar 26 06:44:53.428: INFO: Pod "pod-a7fc737c-4f92-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:44:53.434: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-a7fc737c-4f92-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 06:44:53.508: INFO: Waiting for pod pod-a7fc737c-4f92-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:44:53.530: INFO: Pod pod-a7fc737c-4f92-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:44:53.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-k76jc" for this suite.
Mar 26 06:44:59.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:44:59.778: INFO: namespace: e2e-tests-emptydir-k76jc, resource: bindings, ignored listing per whitelist
Mar 26 06:44:59.835: INFO: namespace e2e-tests-emptydir-k76jc deletion completed in 6.279728774s

• [SLOW TEST:8.660 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:44:59.837: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 06:45:00.114: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ad309244-4f92-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-w9m4r" to be "success or failure"
Mar 26 06:45:00.172: INFO: Pod "downwardapi-volume-ad309244-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 57.755721ms
Mar 26 06:45:02.182: INFO: Pod "downwardapi-volume-ad309244-4f92-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.067383687s
STEP: Saw pod success
Mar 26 06:45:02.182: INFO: Pod "downwardapi-volume-ad309244-4f92-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:45:02.187: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod downwardapi-volume-ad309244-4f92-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 06:45:02.290: INFO: Waiting for pod downwardapi-volume-ad309244-4f92-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:45:02.329: INFO: Pod downwardapi-volume-ad309244-4f92-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:45:02.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w9m4r" for this suite.
Mar 26 06:45:08.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:45:08.481: INFO: namespace: e2e-tests-projected-w9m4r, resource: bindings, ignored listing per whitelist
Mar 26 06:45:08.618: INFO: namespace e2e-tests-projected-w9m4r deletion completed in 6.266613043s

• [SLOW TEST:8.781 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:45:08.619: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 06:45:08.939: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b272164e-4f92-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-44jvq" to be "success or failure"
Mar 26 06:45:08.958: INFO: Pod "downwardapi-volume-b272164e-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 19.38554ms
Mar 26 06:45:10.970: INFO: Pod "downwardapi-volume-b272164e-4f92-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030919379s
STEP: Saw pod success
Mar 26 06:45:10.970: INFO: Pod "downwardapi-volume-b272164e-4f92-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:45:10.979: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downwardapi-volume-b272164e-4f92-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 06:45:11.085: INFO: Waiting for pod downwardapi-volume-b272164e-4f92-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:45:11.094: INFO: Pod downwardapi-volume-b272164e-4f92-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:45:11.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-44jvq" for this suite.
Mar 26 06:45:17.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:45:17.399: INFO: namespace: e2e-tests-projected-44jvq, resource: bindings, ignored listing per whitelist
Mar 26 06:45:17.410: INFO: namespace e2e-tests-projected-44jvq deletion completed in 6.285067096s

• [SLOW TEST:8.792 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:45:17.412: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:46:17.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zdhw4" for this suite.
Mar 26 06:46:41.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:46:41.753: INFO: namespace: e2e-tests-container-probe-zdhw4, resource: bindings, ignored listing per whitelist
Mar 26 06:46:41.892: INFO: namespace e2e-tests-container-probe-zdhw4 deletion completed in 24.281526753s

• [SLOW TEST:84.480 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:46:41.894: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar 26 06:46:42.123: INFO: Waiting up to 5m0s for pod "client-containers-e9fdcc47-4f92-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-containers-7c5f2" to be "success or failure"
Mar 26 06:46:42.151: INFO: Pod "client-containers-e9fdcc47-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 27.819669ms
Mar 26 06:46:44.161: INFO: Pod "client-containers-e9fdcc47-4f92-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037643763s
STEP: Saw pod success
Mar 26 06:46:44.161: INFO: Pod "client-containers-e9fdcc47-4f92-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:46:44.165: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod client-containers-e9fdcc47-4f92-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 06:46:44.227: INFO: Waiting for pod client-containers-e9fdcc47-4f92-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:46:44.234: INFO: Pod client-containers-e9fdcc47-4f92-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:46:44.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7c5f2" for this suite.
Mar 26 06:46:50.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:46:50.519: INFO: namespace: e2e-tests-containers-7c5f2, resource: bindings, ignored listing per whitelist
Mar 26 06:46:50.532: INFO: namespace e2e-tests-containers-7c5f2 deletion completed in 6.264797223s

• [SLOW TEST:8.639 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:46:50.534: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 26 06:46:50.756: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:46:54.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-j42ch" for this suite.
Mar 26 06:47:01.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:47:01.348: INFO: namespace: e2e-tests-init-container-j42ch, resource: bindings, ignored listing per whitelist
Mar 26 06:47:01.363: INFO: namespace e2e-tests-init-container-j42ch deletion completed in 6.3434129s

• [SLOW TEST:10.830 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:47:01.367: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 06:47:01.570: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f593ed3f-4f92-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-6qps5" to be "success or failure"
Mar 26 06:47:01.590: INFO: Pod "downwardapi-volume-f593ed3f-4f92-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 19.634342ms
Mar 26 06:47:03.597: INFO: Pod "downwardapi-volume-f593ed3f-4f92-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026991527s
STEP: Saw pod success
Mar 26 06:47:03.597: INFO: Pod "downwardapi-volume-f593ed3f-4f92-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:47:03.604: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downwardapi-volume-f593ed3f-4f92-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 06:47:03.677: INFO: Waiting for pod downwardapi-volume-f593ed3f-4f92-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:47:03.707: INFO: Pod downwardapi-volume-f593ed3f-4f92-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:47:03.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6qps5" for this suite.
Mar 26 06:47:09.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:47:09.958: INFO: namespace: e2e-tests-downward-api-6qps5, resource: bindings, ignored listing per whitelist
Mar 26 06:47:09.990: INFO: namespace e2e-tests-downward-api-6qps5 deletion completed in 6.254676914s

• [SLOW TEST:8.624 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:47:09.992: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar 26 06:47:12.356: INFO: Pod pod-hostip-fac4c077-4f92-11e9-8fea-5694fc6fbac7 has hostIP: 72.2.113.8
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:47:12.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-lxsg6" for this suite.
Mar 26 06:47:36.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:47:36.451: INFO: namespace: e2e-tests-pods-lxsg6, resource: bindings, ignored listing per whitelist
Mar 26 06:47:36.669: INFO: namespace e2e-tests-pods-lxsg6 deletion completed in 24.300816543s

• [SLOW TEST:26.678 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:47:36.670: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 26 06:47:36.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-b6mfd'
Mar 26 06:47:37.116: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar 26 06:47:37.116: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Mar 26 06:47:37.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-b6mfd'
Mar 26 06:47:37.315: INFO: stderr: ""
Mar 26 06:47:37.315: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:47:37.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b6mfd" for this suite.
Mar 26 06:47:43.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:47:43.608: INFO: namespace: e2e-tests-kubectl-b6mfd, resource: bindings, ignored listing per whitelist
Mar 26 06:47:43.615: INFO: namespace e2e-tests-kubectl-b6mfd deletion completed in 6.271141603s

• [SLOW TEST:6.945 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:47:43.618: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:47:43.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-dgw6q" for this suite.
Mar 26 06:47:49.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:47:50.092: INFO: namespace: e2e-tests-services-dgw6q, resource: bindings, ignored listing per whitelist
Mar 26 06:47:50.127: INFO: namespace e2e-tests-services-dgw6q deletion completed in 6.279213298s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.510 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:47:50.129: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 26 06:47:50.357: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:47:54.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-5cbls" for this suite.
Mar 26 06:48:18.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:48:18.675: INFO: namespace: e2e-tests-init-container-5cbls, resource: bindings, ignored listing per whitelist
Mar 26 06:48:18.754: INFO: namespace e2e-tests-init-container-5cbls deletion completed in 24.303518714s

• [SLOW TEST:28.625 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:48:18.757: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 06:48:19.055: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23c20f2a-4f93-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-jgxg7" to be "success or failure"
Mar 26 06:48:19.092: INFO: Pod "downwardapi-volume-23c20f2a-4f93-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 37.252136ms
Mar 26 06:48:21.110: INFO: Pod "downwardapi-volume-23c20f2a-4f93-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055008132s
Mar 26 06:48:23.121: INFO: Pod "downwardapi-volume-23c20f2a-4f93-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066237822s
STEP: Saw pod success
Mar 26 06:48:23.121: INFO: Pod "downwardapi-volume-23c20f2a-4f93-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:48:23.135: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downwardapi-volume-23c20f2a-4f93-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 06:48:23.197: INFO: Waiting for pod downwardapi-volume-23c20f2a-4f93-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:48:23.206: INFO: Pod downwardapi-volume-23c20f2a-4f93-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:48:23.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jgxg7" for this suite.
Mar 26 06:48:29.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:48:29.461: INFO: namespace: e2e-tests-projected-jgxg7, resource: bindings, ignored listing per whitelist
Mar 26 06:48:29.498: INFO: namespace e2e-tests-projected-jgxg7 deletion completed in 6.275094423s

• [SLOW TEST:10.742 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:48:29.501: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 26 06:48:29.780: INFO: Number of nodes with available pods: 0
Mar 26 06:48:29.781: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 06:48:30.862: INFO: Number of nodes with available pods: 0
Mar 26 06:48:30.862: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 06:48:31.840: INFO: Number of nodes with available pods: 4
Mar 26 06:48:31.840: INFO: Node k8s-conformance-cluster-1-12-control-1 is running more than one daemon pod
Mar 26 06:48:32.806: INFO: Number of nodes with available pods: 5
Mar 26 06:48:32.806: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar 26 06:48:32.891: INFO: Number of nodes with available pods: 4
Mar 26 06:48:32.891: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:33.907: INFO: Number of nodes with available pods: 4
Mar 26 06:48:33.907: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:34.910: INFO: Number of nodes with available pods: 4
Mar 26 06:48:34.911: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:35.911: INFO: Number of nodes with available pods: 4
Mar 26 06:48:35.911: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:36.911: INFO: Number of nodes with available pods: 4
Mar 26 06:48:36.911: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:37.912: INFO: Number of nodes with available pods: 4
Mar 26 06:48:37.912: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:38.919: INFO: Number of nodes with available pods: 4
Mar 26 06:48:38.919: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:39.915: INFO: Number of nodes with available pods: 4
Mar 26 06:48:39.916: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:40.911: INFO: Number of nodes with available pods: 4
Mar 26 06:48:40.911: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:41.915: INFO: Number of nodes with available pods: 4
Mar 26 06:48:41.916: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:42.912: INFO: Number of nodes with available pods: 4
Mar 26 06:48:42.912: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:43.923: INFO: Number of nodes with available pods: 4
Mar 26 06:48:43.923: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:44.910: INFO: Number of nodes with available pods: 4
Mar 26 06:48:44.911: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:45.915: INFO: Number of nodes with available pods: 4
Mar 26 06:48:45.915: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:46.910: INFO: Number of nodes with available pods: 4
Mar 26 06:48:46.911: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:47.909: INFO: Number of nodes with available pods: 4
Mar 26 06:48:47.910: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:48.911: INFO: Number of nodes with available pods: 4
Mar 26 06:48:48.911: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:49.909: INFO: Number of nodes with available pods: 4
Mar 26 06:48:49.909: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:50.910: INFO: Number of nodes with available pods: 4
Mar 26 06:48:50.910: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:51.930: INFO: Number of nodes with available pods: 4
Mar 26 06:48:51.931: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:52.912: INFO: Number of nodes with available pods: 4
Mar 26 06:48:52.912: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:53.917: INFO: Number of nodes with available pods: 4
Mar 26 06:48:53.918: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:54.910: INFO: Number of nodes with available pods: 4
Mar 26 06:48:54.910: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:55.911: INFO: Number of nodes with available pods: 4
Mar 26 06:48:55.911: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:56.911: INFO: Number of nodes with available pods: 4
Mar 26 06:48:56.911: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:57.912: INFO: Number of nodes with available pods: 4
Mar 26 06:48:57.913: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:58.910: INFO: Number of nodes with available pods: 4
Mar 26 06:48:58.910: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:48:59.911: INFO: Number of nodes with available pods: 4
Mar 26 06:48:59.911: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:49:00.911: INFO: Number of nodes with available pods: 4
Mar 26 06:49:00.911: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:49:01.915: INFO: Number of nodes with available pods: 4
Mar 26 06:49:01.915: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:49:02.913: INFO: Number of nodes with available pods: 4
Mar 26 06:49:02.914: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:49:03.916: INFO: Number of nodes with available pods: 4
Mar 26 06:49:03.916: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:49:04.925: INFO: Number of nodes with available pods: 4
Mar 26 06:49:04.925: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:49:05.913: INFO: Number of nodes with available pods: 4
Mar 26 06:49:05.913: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:49:06.914: INFO: Number of nodes with available pods: 4
Mar 26 06:49:06.914: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:49:07.915: INFO: Number of nodes with available pods: 4
Mar 26 06:49:07.916: INFO: Node k8s-conformance-cluster-1-12-etcd-1 is running more than one daemon pod
Mar 26 06:49:08.914: INFO: Number of nodes with available pods: 5
Mar 26 06:49:08.914: INFO: Number of running nodes: 5, number of available pods: 5
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-mkbwh, will wait for the garbage collector to delete the pods
Mar 26 06:49:09.004: INFO: Deleting {extensions DaemonSet} daemon-set took: 26.669587ms
Mar 26 06:49:09.205: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 201.163875ms
Mar 26 06:49:52.013: INFO: Number of nodes with available pods: 0
Mar 26 06:49:52.013: INFO: Number of running nodes: 0, number of available pods: 0
Mar 26 06:49:52.019: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-mkbwh/daemonsets","resourceVersion":"47936"},"items":null}

Mar 26 06:49:52.024: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-mkbwh/pods","resourceVersion":"47936"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:49:52.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-mkbwh" for this suite.
Mar 26 06:50:00.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:50:00.204: INFO: namespace: e2e-tests-daemonsets-mkbwh, resource: bindings, ignored listing per whitelist
Mar 26 06:50:00.423: INFO: namespace e2e-tests-daemonsets-mkbwh deletion completed in 8.331821401s

• [SLOW TEST:90.923 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:50:00.425: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 26 06:50:00.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-x6wkc'
Mar 26 06:50:00.811: INFO: stderr: ""
Mar 26 06:50:00.811: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar 26 06:50:05.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-x6wkc -o json'
Mar 26 06:50:06.039: INFO: stderr: ""
Mar 26 06:50:06.039: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.42.0.108/32\"\n        },\n        \"creationTimestamp\": \"2019-03-26T06:50:00Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-x6wkc\",\n        \"resourceVersion\": \"48014\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-x6wkc/pods/e2e-test-nginx-pod\",\n        \"uid\": \"606a9c27-4f93-11e9-b22a-90b8d090d774\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-c5rh7\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"k8s-conformance-cluster-1-12-control-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-c5rh7\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-c5rh7\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-26T06:50:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-26T06:50:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-26T06:50:02Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-26T06:50:00Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://fe71701e61ddeb40551fb5973694e23dff5e34abff14290ebafba2d7055e400c\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-26T06:50:02Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"72.2.113.8\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.0.108\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-26T06:50:00Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar 26 06:50:06.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 replace -f - --namespace=e2e-tests-kubectl-x6wkc'
Mar 26 06:50:06.382: INFO: stderr: ""
Mar 26 06:50:06.382: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Mar 26 06:50:06.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-x6wkc'
Mar 26 06:50:10.854: INFO: stderr: ""
Mar 26 06:50:10.854: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:50:10.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x6wkc" for this suite.
Mar 26 06:50:16.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:50:17.201: INFO: namespace: e2e-tests-kubectl-x6wkc, resource: bindings, ignored listing per whitelist
Mar 26 06:50:17.201: INFO: namespace e2e-tests-kubectl-x6wkc deletion completed in 6.332495108s

• [SLOW TEST:16.776 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:50:17.202: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar 26 06:50:21.580: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-6a5a9151-4f93-11e9-8fea-5694fc6fbac7", GenerateName:"", Namespace:"e2e-tests-pods-9p2kh", SelfLink:"/api/v1/namespaces/e2e-tests-pods-9p2kh/pods/pod-submit-remove-6a5a9151-4f93-11e9-8fea-5694fc6fbac7", UID:"6a6252b3-4f93-11e9-b22a-90b8d090d774", ResourceVersion:"48083", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63689179817, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"461800633"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.1.107/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-t6zlw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc423044c00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-t6zlw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421cffe28), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-conformance-cluster-1-12-etcd-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4229886c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421cffe60)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421cffe80)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421cffe88), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689179817, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689179819, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689179819, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689179817, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"72.2.112.101", PodIP:"10.42.1.107", StartTime:(*v1.Time)(0xc4211bb8c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4211bb8e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d", ContainerID:"docker://01faae4c5789634f510fe990b027035d131b55a32cd599672da6a3b8fd271b10"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:50:31.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9p2kh" for this suite.
Mar 26 06:50:38.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:50:38.224: INFO: namespace: e2e-tests-pods-9p2kh, resource: bindings, ignored listing per whitelist
Mar 26 06:50:38.244: INFO: namespace e2e-tests-pods-9p2kh deletion completed in 6.28510983s

• [SLOW TEST:21.044 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:50:38.247: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:50:44.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-ndjsl" for this suite.
Mar 26 06:50:50.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:50:51.151: INFO: namespace: e2e-tests-namespaces-ndjsl, resource: bindings, ignored listing per whitelist
Mar 26 06:50:51.152: INFO: namespace e2e-tests-namespaces-ndjsl deletion completed in 6.399924219s
STEP: Destroying namespace "e2e-tests-nsdeletetest-hc679" for this suite.
Mar 26 06:50:51.159: INFO: Namespace e2e-tests-nsdeletetest-hc679 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-ztrcq" for this suite.
Mar 26 06:50:57.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:50:57.351: INFO: namespace: e2e-tests-nsdeletetest-ztrcq, resource: bindings, ignored listing per whitelist
Mar 26 06:50:57.427: INFO: namespace e2e-tests-nsdeletetest-ztrcq deletion completed in 6.268256436s

• [SLOW TEST:19.180 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:50:57.429: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jq25m
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar 26 06:50:57.706: INFO: Found 0 stateful pods, waiting for 3
Mar 26 06:51:07.714: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 06:51:07.715: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 06:51:07.715: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 26 06:51:07.763: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar 26 06:51:17.842: INFO: Updating stateful set ss2
Mar 26 06:51:17.894: INFO: Waiting for Pod e2e-tests-statefulset-jq25m/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar 26 06:51:28.231: INFO: Found 1 stateful pods, waiting for 3
Mar 26 06:51:38.239: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 06:51:38.239: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 06:51:38.239: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar 26 06:51:38.279: INFO: Updating stateful set ss2
Mar 26 06:51:38.299: INFO: Waiting for Pod e2e-tests-statefulset-jq25m/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 06:51:48.315: INFO: Waiting for Pod e2e-tests-statefulset-jq25m/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 06:51:58.341: INFO: Updating stateful set ss2
Mar 26 06:51:58.357: INFO: Waiting for StatefulSet e2e-tests-statefulset-jq25m/ss2 to complete update
Mar 26 06:51:58.357: INFO: Waiting for Pod e2e-tests-statefulset-jq25m/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 26 06:52:08.373: INFO: Waiting for StatefulSet e2e-tests-statefulset-jq25m/ss2 to complete update
Mar 26 06:52:08.373: INFO: Waiting for Pod e2e-tests-statefulset-jq25m/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 26 06:52:18.376: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jq25m
Mar 26 06:52:18.382: INFO: Scaling statefulset ss2 to 0
Mar 26 06:52:48.418: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 06:52:48.424: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:52:48.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jq25m" for this suite.
Mar 26 06:52:56.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:52:56.690: INFO: namespace: e2e-tests-statefulset-jq25m, resource: bindings, ignored listing per whitelist
Mar 26 06:52:56.757: INFO: namespace e2e-tests-statefulset-jq25m deletion completed in 8.271464505s

• [SLOW TEST:119.329 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:52:56.758: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c968e1d5-4f93-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 06:52:56.962: INFO: Waiting up to 5m0s for pod "pod-secrets-c969fd2c-4f93-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-secrets-nljrl" to be "success or failure"
Mar 26 06:52:57.093: INFO: Pod "pod-secrets-c969fd2c-4f93-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 130.292438ms
Mar 26 06:52:59.099: INFO: Pod "pod-secrets-c969fd2c-4f93-11e9-8fea-5694fc6fbac7": Phase="Running", Reason="", readiness=true. Elapsed: 2.136240113s
Mar 26 06:53:01.105: INFO: Pod "pod-secrets-c969fd2c-4f93-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.142303537s
STEP: Saw pod success
Mar 26 06:53:01.105: INFO: Pod "pod-secrets-c969fd2c-4f93-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:53:01.112: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-secrets-c969fd2c-4f93-11e9-8fea-5694fc6fbac7 container secret-volume-test: <nil>
STEP: delete the pod
Mar 26 06:53:01.215: INFO: Waiting for pod pod-secrets-c969fd2c-4f93-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:53:01.258: INFO: Pod pod-secrets-c969fd2c-4f93-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:53:01.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nljrl" for this suite.
Mar 26 06:53:07.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:53:07.448: INFO: namespace: e2e-tests-secrets-nljrl, resource: bindings, ignored listing per whitelist
Mar 26 06:53:07.649: INFO: namespace e2e-tests-secrets-nljrl deletion completed in 6.363354541s

• [SLOW TEST:10.891 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:53:07.651: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar 26 06:53:07.841: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar 26 06:53:07.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:08.612: INFO: stderr: ""
Mar 26 06:53:08.612: INFO: stdout: "service/redis-slave created\n"
Mar 26 06:53:08.612: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar 26 06:53:08.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:09.031: INFO: stderr: ""
Mar 26 06:53:09.031: INFO: stdout: "service/redis-master created\n"
Mar 26 06:53:09.031: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 26 06:53:09.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:09.460: INFO: stderr: ""
Mar 26 06:53:09.460: INFO: stdout: "service/frontend created\n"
Mar 26 06:53:09.461: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar 26 06:53:09.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:09.884: INFO: stderr: ""
Mar 26 06:53:09.884: INFO: stdout: "deployment.extensions/frontend created\n"
Mar 26 06:53:09.884: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 26 06:53:09.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:10.514: INFO: stderr: ""
Mar 26 06:53:10.514: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar 26 06:53:10.514: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar 26 06:53:10.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 create -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:11.137: INFO: stderr: ""
Mar 26 06:53:11.137: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar 26 06:53:11.137: INFO: Waiting for all frontend pods to be Running.
Mar 26 06:53:56.190: INFO: Waiting for frontend to serve content.
Mar 26 06:53:56.227: INFO: Trying to add a new entry to the guestbook.
Mar 26 06:53:56.263: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar 26 06:53:56.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:56.722: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 06:53:56.722: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar 26 06:53:56.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:56.936: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 06:53:56.936: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 26 06:53:56.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:57.168: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 06:53:57.168: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 26 06:53:57.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:57.354: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 06:53:57.354: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 26 06:53:57.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:57.648: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 06:53:57.648: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 26 06:53:57.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-smprf'
Mar 26 06:53:57.995: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 26 06:53:57.995: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:53:57.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-smprf" for this suite.
Mar 26 06:54:38.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:54:38.349: INFO: namespace: e2e-tests-kubectl-smprf, resource: bindings, ignored listing per whitelist
Mar 26 06:54:38.390: INFO: namespace e2e-tests-kubectl-smprf deletion completed in 40.358536699s

• [SLOW TEST:90.739 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:54:38.391: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 26 06:54:43.155: INFO: Successfully updated pod "pod-update-activedeadlineseconds-05fb2bce-4f94-11e9-8fea-5694fc6fbac7"
Mar 26 06:54:43.155: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-05fb2bce-4f94-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-pods-p5dvc" to be "terminated due to deadline exceeded"
Mar 26 06:54:43.188: INFO: Pod "pod-update-activedeadlineseconds-05fb2bce-4f94-11e9-8fea-5694fc6fbac7": Phase="Running", Reason="", readiness=true. Elapsed: 32.485717ms
Mar 26 06:54:45.196: INFO: Pod "pod-update-activedeadlineseconds-05fb2bce-4f94-11e9-8fea-5694fc6fbac7": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.040977292s
Mar 26 06:54:45.197: INFO: Pod "pod-update-activedeadlineseconds-05fb2bce-4f94-11e9-8fea-5694fc6fbac7" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:54:45.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-p5dvc" for this suite.
Mar 26 06:54:51.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:54:51.491: INFO: namespace: e2e-tests-pods-p5dvc, resource: bindings, ignored listing per whitelist
Mar 26 06:54:51.503: INFO: namespace e2e-tests-pods-p5dvc deletion completed in 6.290153395s

• [SLOW TEST:13.113 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:54:51.506: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 26 06:54:54.411: INFO: Successfully updated pod "annotationupdate0dd32c42-4f94-11e9-8fea-5694fc6fbac7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:54:56.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mq98z" for this suite.
Mar 26 06:55:20.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:55:20.717: INFO: namespace: e2e-tests-downward-api-mq98z, resource: bindings, ignored listing per whitelist
Mar 26 06:55:20.895: INFO: namespace e2e-tests-downward-api-mq98z deletion completed in 24.424316352s

• [SLOW TEST:29.390 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:55:20.900: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 26 06:55:23.732: INFO: Successfully updated pod "labelsupdate1f5686a9-4f94-11e9-8fea-5694fc6fbac7"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:55:25.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7zcwn" for this suite.
Mar 26 06:55:49.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:55:49.975: INFO: namespace: e2e-tests-projected-7zcwn, resource: bindings, ignored listing per whitelist
Mar 26 06:55:50.100: INFO: namespace e2e-tests-projected-7zcwn deletion completed in 24.305874488s

• [SLOW TEST:29.200 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:55:50.102: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:55:50.315: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 26 06:55:55.322: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 26 06:55:55.323: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 26 06:55:55.370: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-8l5m2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8l5m2/deployments/test-cleanup-deployment,UID:33bd65f1-4f94-11e9-b22a-90b8d090d774,ResourceVersion:49371,Generation:1,CreationTimestamp:2019-03-26 06:55:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar 26 06:55:55.392: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Mar 26 06:55:55.392: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar 26 06:55:55.392: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-8l5m2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8l5m2/replicasets/test-cleanup-controller,UID:30bc2589-4f94-11e9-b22a-90b8d090d774,ResourceVersion:49372,Generation:1,CreationTimestamp:2019-03-26 06:55:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 33bd65f1-4f94-11e9-b22a-90b8d090d774 0xc421e3eaa7 0xc421e3eaa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 26 06:55:55.419: INFO: Pod "test-cleanup-controller-4j6xp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-4j6xp,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-8l5m2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8l5m2/pods/test-cleanup-controller-4j6xp,UID:30c20d4b-4f94-11e9-b22a-90b8d090d774,ResourceVersion:49364,Generation:0,CreationTimestamp:2019-03-26 06:55:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.42.0.116/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 30bc2589-4f94-11e9-b22a-90b8d090d774 0xc421e3f1b7 0xc421e3f1b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fsgdl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fsgdl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fsgdl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-conformance-cluster-1-12-control-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e3f220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e3f240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:55:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:55:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:55:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 06:55:50 +0000 UTC  }],Message:,Reason:,HostIP:72.2.113.8,PodIP:10.42.0.116,StartTime:2019-03-26 06:55:50 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-26 06:55:52 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://f21bac0249753a6bf8982da6d115e12f079148f496d2440cada04e890567a928}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:55:55.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8l5m2" for this suite.
Mar 26 06:56:03.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:56:03.657: INFO: namespace: e2e-tests-deployment-8l5m2, resource: bindings, ignored listing per whitelist
Mar 26 06:56:03.878: INFO: namespace e2e-tests-deployment-8l5m2 deletion completed in 8.423845267s

• [SLOW TEST:13.776 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:56:03.880: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar 26 06:56:04.064: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 26 06:56:04.109: INFO: Waiting for terminating namespaces to be deleted...
Mar 26 06:56:04.117: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-control-1 before test
Mar 26 06:56:04.136: INFO: rke-kubedns-addon-deploy-job-69jrs from kube-system started at 2019-03-26 00:53:12 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.136: INFO: 	Container rke-kubedns-addon-pod ready: false, restart count 0
Mar 26 06:56:04.136: INFO: cattle-node-agent-hnjxf from cattle-system started at 2019-03-26 00:54:37 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.136: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:56:04.136: INFO: rke-network-plugin-deploy-job-xl4m5 from kube-system started at 2019-03-26 00:53:02 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.136: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 26 06:56:04.136: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-sw4jz from heptio-sonobuoy started at 2019-03-26 05:38:40 +0000 UTC (2 container statuses recorded)
Mar 26 06:56:04.136: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 26 06:56:04.137: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 26 06:56:04.137: INFO: rke-metrics-addon-deploy-job-bsrr2 from kube-system started at 2019-03-26 00:53:23 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.137: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 26 06:56:04.137: INFO: rke-ingress-controller-deploy-job-w8l9x from kube-system started at 2019-03-26 00:53:35 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.137: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 26 06:56:04.137: INFO: nginx-ingress-controller-5qkcf from ingress-nginx started at 2019-03-26 05:38:03 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.137: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:56:04.137: INFO: calico-node-g2rd4 from kube-system started at 2019-03-26 00:53:07 +0000 UTC (2 container statuses recorded)
Mar 26 06:56:04.137: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:56:04.137: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:56:04.137: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-etcd-1 before test
Mar 26 06:56:04.151: INFO: nginx-ingress-controller-glb5c from ingress-nginx started at 2019-03-26 05:38:15 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.152: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:56:04.152: INFO: calico-node-zbl4q from kube-system started at 2019-03-26 00:53:07 +0000 UTC (2 container statuses recorded)
Mar 26 06:56:04.152: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:56:04.152: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:56:04.152: INFO: cattle-node-agent-88rnp from cattle-system started at 2019-03-26 00:54:01 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.152: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:56:04.152: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-r228k from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:56:04.152: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 26 06:56:04.152: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 26 06:56:04.155: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-worker-1 before test
Mar 26 06:56:04.175: INFO: kube-dns-autoscaler-689f6f9756-vwph6 from kube-system started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.175: INFO: 	Container autoscaler ready: true, restart count 0
Mar 26 06:56:04.175: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-psbcr from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:56:04.175: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 26 06:56:04.175: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 26 06:56:04.175: INFO: kube-dns-ddddcfcc8-75rhb from kube-system started at 2019-03-26 00:55:08 +0000 UTC (3 container statuses recorded)
Mar 26 06:56:04.175: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 06:56:04.176: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 06:56:04.176: INFO: 	Container sidecar ready: true, restart count 0
Mar 26 06:56:04.176: INFO: default-http-backend-5bdd9fdd69-b5f6t from ingress-nginx started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.176: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 26 06:56:04.176: INFO: cattle-cluster-agent-6f575d9bcf-rjz7h from cattle-system started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.176: INFO: 	Container cluster-register ready: true, restart count 0
Mar 26 06:56:04.176: INFO: nginx-ingress-controller-hbcdq from ingress-nginx started at 2019-03-26 00:55:09 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.176: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:56:04.176: INFO: cattle-node-agent-2vwcr from cattle-system started at 2019-03-26 00:55:09 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.176: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:56:04.176: INFO: calico-node-4hkk8 from kube-system started at 2019-03-26 00:54:48 +0000 UTC (2 container statuses recorded)
Mar 26 06:56:04.176: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:56:04.177: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:56:04.177: INFO: metrics-server-5444cf6dfc-jk9bb from kube-system started at 2019-03-26 00:55:08 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.177: INFO: 	Container metrics-server ready: true, restart count 0
Mar 26 06:56:04.177: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-worker1-1 before test
Mar 26 06:56:04.197: INFO: nginx-ingress-controller-rsjr4 from ingress-nginx started at 2019-03-26 01:47:20 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.197: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:56:04.198: INFO: cattle-node-agent-9qhk4 from cattle-system started at 2019-03-26 01:47:20 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.198: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:56:04.198: INFO: sonobuoy-e2e-job-2791eb3c35d44121 from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:56:04.198: INFO: 	Container e2e ready: true, restart count 0
Mar 26 06:56:04.198: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 26 06:56:04.198: INFO: calico-node-4njnj from kube-system started at 2019-03-26 01:46:41 +0000 UTC (2 container statuses recorded)
Mar 26 06:56:04.198: INFO: 	Container calico-node ready: true, restart count 0
Mar 26 06:56:04.199: INFO: 	Container install-cni ready: true, restart count 0
Mar 26 06:56:04.199: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-26 05:38:36 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.199: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 26 06:56:04.199: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-rb6hz from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:56:04.199: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 26 06:56:04.199: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 26 06:56:04.199: INFO: 
Logging pods the kubelet thinks is on node k8s-conformance-cluster-1-12-worker1-2 before test
Mar 26 06:56:04.220: INFO: sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-l2r6z from heptio-sonobuoy started at 2019-03-26 05:38:39 +0000 UTC (2 container statuses recorded)
Mar 26 06:56:04.222: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 26 06:56:04.222: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 26 06:56:04.222: INFO: calico-node-l244q from kube-system started at 2019-03-26 01:45:53 +0000 UTC (2 container statuses recorded)
Mar 26 06:56:04.223: INFO: 	Container calico-node ready: true, restart count 1
Mar 26 06:56:04.223: INFO: 	Container install-cni ready: true, restart count 1
Mar 26 06:56:04.223: INFO: nginx-ingress-controller-lvkkc from ingress-nginx started at 2019-03-26 01:46:33 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.223: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 26 06:56:04.223: INFO: cattle-node-agent-8rc72 from cattle-system started at 2019-03-26 01:46:33 +0000 UTC (1 container statuses recorded)
Mar 26 06:56:04.223: INFO: 	Container agent ready: true, restart count 0
Mar 26 06:56:04.223: INFO: kube-dns-ddddcfcc8-8hxnz from kube-system started at 2019-03-26 01:46:46 +0000 UTC (3 container statuses recorded)
Mar 26 06:56:04.223: INFO: 	Container dnsmasq ready: true, restart count 0
Mar 26 06:56:04.223: INFO: 	Container kubedns ready: true, restart count 0
Mar 26 06:56:04.223: INFO: 	Container sidecar ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node k8s-conformance-cluster-1-12-control-1
STEP: verifying the node has the label node k8s-conformance-cluster-1-12-etcd-1
STEP: verifying the node has the label node k8s-conformance-cluster-1-12-worker-1
STEP: verifying the node has the label node k8s-conformance-cluster-1-12-worker1-1
STEP: verifying the node has the label node k8s-conformance-cluster-1-12-worker1-2
Mar 26 06:56:04.551: INFO: Pod cattle-cluster-agent-6f575d9bcf-rjz7h requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker-1
Mar 26 06:56:04.551: INFO: Pod cattle-node-agent-2vwcr requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker-1
Mar 26 06:56:04.551: INFO: Pod cattle-node-agent-88rnp requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-etcd-1
Mar 26 06:56:04.551: INFO: Pod cattle-node-agent-8rc72 requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker1-2
Mar 26 06:56:04.551: INFO: Pod cattle-node-agent-9qhk4 requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker1-1
Mar 26 06:56:04.551: INFO: Pod cattle-node-agent-hnjxf requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-control-1
Mar 26 06:56:04.551: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker1-1
Mar 26 06:56:04.551: INFO: Pod sonobuoy-e2e-job-2791eb3c35d44121 requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker1-1
Mar 26 06:56:04.551: INFO: Pod sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-l2r6z requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker1-2
Mar 26 06:56:04.552: INFO: Pod sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-psbcr requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker-1
Mar 26 06:56:04.552: INFO: Pod sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-r228k requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-etcd-1
Mar 26 06:56:04.552: INFO: Pod sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-rb6hz requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker1-1
Mar 26 06:56:04.552: INFO: Pod sonobuoy-systemd-logs-daemon-set-0473c2a1e48b478a-sw4jz requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-control-1
Mar 26 06:56:04.552: INFO: Pod default-http-backend-5bdd9fdd69-b5f6t requesting resource cpu=10m on Node k8s-conformance-cluster-1-12-worker-1
Mar 26 06:56:04.552: INFO: Pod nginx-ingress-controller-5qkcf requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-control-1
Mar 26 06:56:04.552: INFO: Pod nginx-ingress-controller-glb5c requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-etcd-1
Mar 26 06:56:04.552: INFO: Pod nginx-ingress-controller-hbcdq requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker-1
Mar 26 06:56:04.552: INFO: Pod nginx-ingress-controller-lvkkc requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker1-2
Mar 26 06:56:04.552: INFO: Pod nginx-ingress-controller-rsjr4 requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker1-1
Mar 26 06:56:04.552: INFO: Pod calico-node-4hkk8 requesting resource cpu=250m on Node k8s-conformance-cluster-1-12-worker-1
Mar 26 06:56:04.552: INFO: Pod calico-node-4njnj requesting resource cpu=250m on Node k8s-conformance-cluster-1-12-worker1-1
Mar 26 06:56:04.552: INFO: Pod calico-node-g2rd4 requesting resource cpu=250m on Node k8s-conformance-cluster-1-12-control-1
Mar 26 06:56:04.553: INFO: Pod calico-node-l244q requesting resource cpu=250m on Node k8s-conformance-cluster-1-12-worker1-2
Mar 26 06:56:04.553: INFO: Pod calico-node-zbl4q requesting resource cpu=250m on Node k8s-conformance-cluster-1-12-etcd-1
Mar 26 06:56:04.553: INFO: Pod kube-dns-autoscaler-689f6f9756-vwph6 requesting resource cpu=20m on Node k8s-conformance-cluster-1-12-worker-1
Mar 26 06:56:04.553: INFO: Pod kube-dns-ddddcfcc8-75rhb requesting resource cpu=260m on Node k8s-conformance-cluster-1-12-worker-1
Mar 26 06:56:04.553: INFO: Pod kube-dns-ddddcfcc8-8hxnz requesting resource cpu=260m on Node k8s-conformance-cluster-1-12-worker1-2
Mar 26 06:56:04.553: INFO: Pod metrics-server-5444cf6dfc-jk9bb requesting resource cpu=0m on Node k8s-conformance-cluster-1-12-worker-1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-393c91d4-4f94-11e9-8fea-5694fc6fbac7.158f6fd6bf93b1c1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-fdkzm/filler-pod-393c91d4-4f94-11e9-8fea-5694fc6fbac7 to k8s-conformance-cluster-1-12-worker1-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-393c91d4-4f94-11e9-8fea-5694fc6fbac7.158f6fd6f96b0d17], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-393c91d4-4f94-11e9-8fea-5694fc6fbac7.158f6fd722694a82], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-393c91d4-4f94-11e9-8fea-5694fc6fbac7.158f6fd7245a2b63], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-393c91d4-4f94-11e9-8fea-5694fc6fbac7.158f6fd72c23d3f3], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3941f371-4f94-11e9-8fea-5694fc6fbac7.158f6fd6c2c38019], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-fdkzm/filler-pod-3941f371-4f94-11e9-8fea-5694fc6fbac7 to k8s-conformance-cluster-1-12-worker1-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3941f371-4f94-11e9-8fea-5694fc6fbac7.158f6fd6f71f369f], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3941f371-4f94-11e9-8fea-5694fc6fbac7.158f6fd717743291], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3941f371-4f94-11e9-8fea-5694fc6fbac7.158f6fd71a01fcbc], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3941f371-4f94-11e9-8fea-5694fc6fbac7.158f6fd71e757c1a], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-39453e6c-4f94-11e9-8fea-5694fc6fbac7.158f6fd6c494741f], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-fdkzm/filler-pod-39453e6c-4f94-11e9-8fea-5694fc6fbac7 to k8s-conformance-cluster-1-12-control-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-39453e6c-4f94-11e9-8fea-5694fc6fbac7.158f6fd72308c596], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-39453e6c-4f94-11e9-8fea-5694fc6fbac7.158f6fd728948c16], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-39453e6c-4f94-11e9-8fea-5694fc6fbac7.158f6fd73932b90b], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3948b09e-4f94-11e9-8fea-5694fc6fbac7.158f6fd6c918f22b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-fdkzm/filler-pod-3948b09e-4f94-11e9-8fea-5694fc6fbac7 to k8s-conformance-cluster-1-12-etcd-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3948b09e-4f94-11e9-8fea-5694fc6fbac7.158f6fd72144f63b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3948b09e-4f94-11e9-8fea-5694fc6fbac7.158f6fd7245628b3], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3948b09e-4f94-11e9-8fea-5694fc6fbac7.158f6fd736b6ba92], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3953808c-4f94-11e9-8fea-5694fc6fbac7.158f6fd6d130c065], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-fdkzm/filler-pod-3953808c-4f94-11e9-8fea-5694fc6fbac7 to k8s-conformance-cluster-1-12-worker-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3953808c-4f94-11e9-8fea-5694fc6fbac7.158f6fd7058326f2], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3953808c-4f94-11e9-8fea-5694fc6fbac7.158f6fd72e50564e], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3953808c-4f94-11e9-8fea-5694fc6fbac7.158f6fd72f9905c3], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3953808c-4f94-11e9-8fea-5694fc6fbac7.158f6fd733ac1458], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158f6fd74be6c338], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 Insufficient cpu.]
STEP: removing the label node off the node k8s-conformance-cluster-1-12-control-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-conformance-cluster-1-12-etcd-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-conformance-cluster-1-12-worker-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-conformance-cluster-1-12-worker1-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-conformance-cluster-1-12-worker1-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:56:08.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-fdkzm" for this suite.
Mar 26 06:56:16.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:56:16.603: INFO: namespace: e2e-tests-sched-pred-fdkzm, resource: bindings, ignored listing per whitelist
Mar 26 06:56:16.770: INFO: namespace e2e-tests-sched-pred-fdkzm deletion completed in 8.352218249s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:12.891 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:56:16.772: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 26 06:56:17.055: INFO: Waiting up to 5m0s for pod "downward-api-40abafd9-4f94-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-t7fxg" to be "success or failure"
Mar 26 06:56:17.087: INFO: Pod "downward-api-40abafd9-4f94-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 32.065703ms
Mar 26 06:56:19.106: INFO: Pod "downward-api-40abafd9-4f94-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050756701s
STEP: Saw pod success
Mar 26 06:56:19.106: INFO: Pod "downward-api-40abafd9-4f94-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:56:19.115: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod downward-api-40abafd9-4f94-11e9-8fea-5694fc6fbac7 container dapi-container: <nil>
STEP: delete the pod
Mar 26 06:56:19.205: INFO: Waiting for pod downward-api-40abafd9-4f94-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:56:19.217: INFO: Pod downward-api-40abafd9-4f94-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:56:19.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t7fxg" for this suite.
Mar 26 06:56:25.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:56:25.404: INFO: namespace: e2e-tests-downward-api-t7fxg, resource: bindings, ignored listing per whitelist
Mar 26 06:56:25.518: INFO: namespace e2e-tests-downward-api-t7fxg deletion completed in 6.272493677s

• [SLOW TEST:8.747 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:56:25.520: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 06:56:25.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 version'
Mar 26 06:56:25.838: INFO: stderr: ""
Mar 26 06:56:25.838: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.6\", GitCommit:\"ab91afd7062d4240e95e51ac00a18bd58fddd365\", GitTreeState:\"clean\", BuildDate:\"2019-02-26T12:49:28Z\", GoVersion:\"go1.10.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:56:25.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4zqg5" for this suite.
Mar 26 06:56:31.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:56:32.136: INFO: namespace: e2e-tests-kubectl-4zqg5, resource: bindings, ignored listing per whitelist
Mar 26 06:56:32.159: INFO: namespace e2e-tests-kubectl-4zqg5 deletion completed in 6.30928045s

• [SLOW TEST:6.640 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:56:32.161: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-49cf9522-4f94-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 06:56:32.390: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-49d12517-4f94-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-zkqcp" to be "success or failure"
Mar 26 06:56:32.414: INFO: Pod "pod-projected-secrets-49d12517-4f94-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 23.984082ms
Mar 26 06:56:34.421: INFO: Pod "pod-projected-secrets-49d12517-4f94-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030870715s
STEP: Saw pod success
Mar 26 06:56:34.421: INFO: Pod "pod-projected-secrets-49d12517-4f94-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 06:56:34.427: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-projected-secrets-49d12517-4f94-11e9-8fea-5694fc6fbac7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 26 06:56:34.510: INFO: Waiting for pod pod-projected-secrets-49d12517-4f94-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 06:56:34.549: INFO: Pod pod-projected-secrets-49d12517-4f94-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 06:56:34.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zkqcp" for this suite.
Mar 26 06:56:40.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 06:56:40.736: INFO: namespace: e2e-tests-projected-zkqcp, resource: bindings, ignored listing per whitelist
Mar 26 06:56:40.916: INFO: namespace e2e-tests-projected-zkqcp deletion completed in 6.329073791s

• [SLOW TEST:8.755 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 06:56:40.917: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-78sbs
Mar 26 06:56:45.213: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-78sbs
STEP: checking the pod's current state and verifying that restartCount is present
Mar 26 06:56:45.220: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:00:46.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-78sbs" for this suite.
Mar 26 07:00:52.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:00:52.760: INFO: namespace: e2e-tests-container-probe-78sbs, resource: bindings, ignored listing per whitelist
Mar 26 07:00:52.896: INFO: namespace e2e-tests-container-probe-78sbs deletion completed in 6.38402804s

• [SLOW TEST:251.980 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:00:52.898: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar 26 07:00:53.117: INFO: Waiting up to 5m0s for pod "client-containers-e537ec77-4f94-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-containers-xqkwm" to be "success or failure"
Mar 26 07:00:53.138: INFO: Pod "client-containers-e537ec77-4f94-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.996388ms
Mar 26 07:00:55.147: INFO: Pod "client-containers-e537ec77-4f94-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029654078s
STEP: Saw pod success
Mar 26 07:00:55.147: INFO: Pod "client-containers-e537ec77-4f94-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:00:55.155: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod client-containers-e537ec77-4f94-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 07:00:55.227: INFO: Waiting for pod client-containers-e537ec77-4f94-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:00:55.238: INFO: Pod client-containers-e537ec77-4f94-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:00:55.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-xqkwm" for this suite.
Mar 26 07:01:01.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:01:01.600: INFO: namespace: e2e-tests-containers-xqkwm, resource: bindings, ignored listing per whitelist
Mar 26 07:01:01.633: INFO: namespace e2e-tests-containers-xqkwm deletion completed in 6.362138516s

• [SLOW TEST:8.735 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:01:01.634: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 07:01:01.908: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea70f98e-4f94-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-downward-api-kbwm9" to be "success or failure"
Mar 26 07:01:01.947: INFO: Pod "downwardapi-volume-ea70f98e-4f94-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 38.795387ms
Mar 26 07:01:03.953: INFO: Pod "downwardapi-volume-ea70f98e-4f94-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044509148s
STEP: Saw pod success
Mar 26 07:01:03.953: INFO: Pod "downwardapi-volume-ea70f98e-4f94-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:01:03.958: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod downwardapi-volume-ea70f98e-4f94-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 07:01:04.040: INFO: Waiting for pod downwardapi-volume-ea70f98e-4f94-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:01:04.062: INFO: Pod downwardapi-volume-ea70f98e-4f94-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:01:04.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kbwm9" for this suite.
Mar 26 07:01:10.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:01:10.249: INFO: namespace: e2e-tests-downward-api-kbwm9, resource: bindings, ignored listing per whitelist
Mar 26 07:01:10.411: INFO: namespace e2e-tests-downward-api-kbwm9 deletion completed in 6.312317303s

• [SLOW TEST:8.778 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:01:10.412: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-efabef44-4f94-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 07:01:10.674: INFO: Waiting up to 5m0s for pod "pod-secrets-efadb8bf-4f94-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-secrets-sjng4" to be "success or failure"
Mar 26 07:01:10.701: INFO: Pod "pod-secrets-efadb8bf-4f94-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 26.545535ms
Mar 26 07:01:12.711: INFO: Pod "pod-secrets-efadb8bf-4f94-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036820756s
STEP: Saw pod success
Mar 26 07:01:12.711: INFO: Pod "pod-secrets-efadb8bf-4f94-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:01:12.718: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-secrets-efadb8bf-4f94-11e9-8fea-5694fc6fbac7 container secret-volume-test: <nil>
STEP: delete the pod
Mar 26 07:01:12.758: INFO: Waiting for pod pod-secrets-efadb8bf-4f94-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:01:12.773: INFO: Pod pod-secrets-efadb8bf-4f94-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:01:12.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sjng4" for this suite.
Mar 26 07:01:18.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:01:19.080: INFO: namespace: e2e-tests-secrets-sjng4, resource: bindings, ignored listing per whitelist
Mar 26 07:01:19.125: INFO: namespace e2e-tests-secrets-sjng4 deletion completed in 6.33163583s

• [SLOW TEST:8.713 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:01:19.129: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-cp7gg
Mar 26 07:01:21.385: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-cp7gg
STEP: checking the pod's current state and verifying that restartCount is present
Mar 26 07:01:21.389: INFO: Initial restart count of pod liveness-http is 0
Mar 26 07:01:45.513: INFO: Restart count of pod e2e-tests-container-probe-cp7gg/liveness-http is now 1 (24.123597377s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:01:45.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cp7gg" for this suite.
Mar 26 07:01:51.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:01:51.800: INFO: namespace: e2e-tests-container-probe-cp7gg, resource: bindings, ignored listing per whitelist
Mar 26 07:01:52.057: INFO: namespace e2e-tests-container-probe-cp7gg deletion completed in 6.403152789s

• [SLOW TEST:32.929 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:01:52.059: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0879b5eb-4f95-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 07:01:52.453: INFO: Waiting up to 5m0s for pod "pod-secrets-0892ff64-4f95-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-secrets-v7k7h" to be "success or failure"
Mar 26 07:01:52.474: INFO: Pod "pod-secrets-0892ff64-4f95-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 19.566484ms
Mar 26 07:01:54.482: INFO: Pod "pod-secrets-0892ff64-4f95-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027914527s
STEP: Saw pod success
Mar 26 07:01:54.482: INFO: Pod "pod-secrets-0892ff64-4f95-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:01:54.488: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-secrets-0892ff64-4f95-11e9-8fea-5694fc6fbac7 container secret-volume-test: <nil>
STEP: delete the pod
Mar 26 07:01:54.574: INFO: Waiting for pod pod-secrets-0892ff64-4f95-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:01:54.580: INFO: Pod pod-secrets-0892ff64-4f95-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:01:54.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v7k7h" for this suite.
Mar 26 07:02:00.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:02:00.707: INFO: namespace: e2e-tests-secrets-v7k7h, resource: bindings, ignored listing per whitelist
Mar 26 07:02:00.920: INFO: namespace e2e-tests-secrets-v7k7h deletion completed in 6.311735544s
STEP: Destroying namespace "e2e-tests-secret-namespace-r24tm" for this suite.
Mar 26 07:02:06.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:02:07.156: INFO: namespace: e2e-tests-secret-namespace-r24tm, resource: bindings, ignored listing per whitelist
Mar 26 07:02:07.228: INFO: namespace e2e-tests-secret-namespace-r24tm deletion completed in 6.307531721s

• [SLOW TEST:15.169 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:02:07.230: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0326 07:02:17.514872      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 07:02:17.515: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:02:17.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kvvm4" for this suite.
Mar 26 07:02:31.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:02:31.741: INFO: namespace: e2e-tests-gc-kvvm4, resource: bindings, ignored listing per whitelist
Mar 26 07:02:31.859: INFO: namespace e2e-tests-gc-kvvm4 deletion completed in 14.322577627s

• [SLOW TEST:24.629 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:02:31.862: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-rwj8
STEP: Creating a pod to test atomic-volume-subpath
Mar 26 07:02:32.158: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-rwj8" in namespace "e2e-tests-subpath-rbph2" to be "success or failure"
Mar 26 07:02:32.188: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Pending", Reason="", readiness=false. Elapsed: 29.754844ms
Mar 26 07:02:34.212: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054266798s
Mar 26 07:02:36.224: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Running", Reason="", readiness=false. Elapsed: 4.066509217s
Mar 26 07:02:38.244: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Running", Reason="", readiness=false. Elapsed: 6.086528885s
Mar 26 07:02:40.263: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Running", Reason="", readiness=false. Elapsed: 8.105362891s
Mar 26 07:02:42.272: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Running", Reason="", readiness=false. Elapsed: 10.11358086s
Mar 26 07:02:44.280: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Running", Reason="", readiness=false. Elapsed: 12.121855902s
Mar 26 07:02:46.293: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Running", Reason="", readiness=false. Elapsed: 14.135511851s
Mar 26 07:02:48.305: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Running", Reason="", readiness=false. Elapsed: 16.147019076s
Mar 26 07:02:50.331: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Running", Reason="", readiness=false. Elapsed: 18.172687175s
Mar 26 07:02:52.338: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Running", Reason="", readiness=false. Elapsed: 20.179585344s
Mar 26 07:02:54.353: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Running", Reason="", readiness=false. Elapsed: 22.194702147s
Mar 26 07:02:56.363: INFO: Pod "pod-subpath-test-projected-rwj8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.204912081s
STEP: Saw pod success
Mar 26 07:02:56.363: INFO: Pod "pod-subpath-test-projected-rwj8" satisfied condition "success or failure"
Mar 26 07:02:56.371: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-subpath-test-projected-rwj8 container test-container-subpath-projected-rwj8: <nil>
STEP: delete the pod
Mar 26 07:02:56.524: INFO: Waiting for pod pod-subpath-test-projected-rwj8 to disappear
Mar 26 07:02:56.543: INFO: Pod pod-subpath-test-projected-rwj8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-rwj8
Mar 26 07:02:56.544: INFO: Deleting pod "pod-subpath-test-projected-rwj8" in namespace "e2e-tests-subpath-rbph2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:02:56.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rbph2" for this suite.
Mar 26 07:03:02.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:03:02.634: INFO: namespace: e2e-tests-subpath-rbph2, resource: bindings, ignored listing per whitelist
Mar 26 07:03:02.816: INFO: namespace e2e-tests-subpath-rbph2 deletion completed in 6.255394962s

• [SLOW TEST:30.954 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:03:02.818: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-32b6f621-4f95-11e9-8fea-5694fc6fbac7
STEP: Creating configMap with name cm-test-opt-upd-32b6f68e-4f95-11e9-8fea-5694fc6fbac7
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-32b6f621-4f95-11e9-8fea-5694fc6fbac7
STEP: Updating configmap cm-test-opt-upd-32b6f68e-4f95-11e9-8fea-5694fc6fbac7
STEP: Creating configMap with name cm-test-opt-create-32b6f6b3-4f95-11e9-8fea-5694fc6fbac7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:04:38.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sb9z5" for this suite.
Mar 26 07:05:02.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:05:02.983: INFO: namespace: e2e-tests-projected-sb9z5, resource: bindings, ignored listing per whitelist
Mar 26 07:05:03.016: INFO: namespace e2e-tests-projected-sb9z5 deletion completed in 24.306981954s

• [SLOW TEST:120.199 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:05:03.018: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-7a4f6449-4f95-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 07:05:03.266: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7a50ef3c-4f95-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-2crdl" to be "success or failure"
Mar 26 07:05:03.282: INFO: Pod "pod-projected-secrets-7a50ef3c-4f95-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.448432ms
Mar 26 07:05:05.291: INFO: Pod "pod-projected-secrets-7a50ef3c-4f95-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024821675s
STEP: Saw pod success
Mar 26 07:05:05.291: INFO: Pod "pod-projected-secrets-7a50ef3c-4f95-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:05:05.297: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-projected-secrets-7a50ef3c-4f95-11e9-8fea-5694fc6fbac7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 26 07:05:05.362: INFO: Waiting for pod pod-projected-secrets-7a50ef3c-4f95-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:05:05.380: INFO: Pod pod-projected-secrets-7a50ef3c-4f95-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:05:05.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2crdl" for this suite.
Mar 26 07:05:11.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:05:11.665: INFO: namespace: e2e-tests-projected-2crdl, resource: bindings, ignored listing per whitelist
Mar 26 07:05:11.684: INFO: namespace e2e-tests-projected-2crdl deletion completed in 6.293919371s

• [SLOW TEST:8.667 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:05:11.684: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 07:05:11.916: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f78e032-4f95-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-9dgc7" to be "success or failure"
Mar 26 07:05:11.947: INFO: Pod "downwardapi-volume-7f78e032-4f95-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 29.054772ms
Mar 26 07:05:13.958: INFO: Pod "downwardapi-volume-7f78e032-4f95-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039662543s
STEP: Saw pod success
Mar 26 07:05:13.958: INFO: Pod "downwardapi-volume-7f78e032-4f95-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:05:13.969: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod downwardapi-volume-7f78e032-4f95-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 07:05:14.121: INFO: Waiting for pod downwardapi-volume-7f78e032-4f95-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:05:14.130: INFO: Pod downwardapi-volume-7f78e032-4f95-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:05:14.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9dgc7" for this suite.
Mar 26 07:05:20.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:05:20.276: INFO: namespace: e2e-tests-projected-9dgc7, resource: bindings, ignored listing per whitelist
Mar 26 07:05:20.416: INFO: namespace e2e-tests-projected-9dgc7 deletion completed in 6.265130561s

• [SLOW TEST:8.732 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:05:20.418: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 26 07:05:20.668: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Mar 26 07:05:20.682: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lp795/daemonsets","resourceVersion":"51016"},"items":null}

Mar 26 07:05:20.697: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lp795/pods","resourceVersion":"51016"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:05:20.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lp795" for this suite.
Mar 26 07:05:26.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:05:26.986: INFO: namespace: e2e-tests-daemonsets-lp795, resource: bindings, ignored listing per whitelist
Mar 26 07:05:27.118: INFO: namespace e2e-tests-daemonsets-lp795 deletion completed in 6.30067913s

S [SKIPPING] [6.701 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar 26 07:05:20.668: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:05:27.120: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-88b01a0d-4f95-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume secrets
Mar 26 07:05:27.414: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-88b2d02c-4f95-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-7d4m5" to be "success or failure"
Mar 26 07:05:27.458: INFO: Pod "pod-projected-secrets-88b2d02c-4f95-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 44.073986ms
Mar 26 07:05:29.466: INFO: Pod "pod-projected-secrets-88b2d02c-4f95-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051912563s
Mar 26 07:05:31.475: INFO: Pod "pod-projected-secrets-88b2d02c-4f95-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060649848s
STEP: Saw pod success
Mar 26 07:05:31.475: INFO: Pod "pod-projected-secrets-88b2d02c-4f95-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:05:31.481: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod pod-projected-secrets-88b2d02c-4f95-11e9-8fea-5694fc6fbac7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 26 07:05:31.571: INFO: Waiting for pod pod-projected-secrets-88b2d02c-4f95-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:05:31.588: INFO: Pod pod-projected-secrets-88b2d02c-4f95-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:05:31.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7d4m5" for this suite.
Mar 26 07:05:37.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:05:37.826: INFO: namespace: e2e-tests-projected-7d4m5, resource: bindings, ignored listing per whitelist
Mar 26 07:05:37.985: INFO: namespace e2e-tests-projected-7d4m5 deletion completed in 6.382568392s

• [SLOW TEST:10.866 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:05:37.987: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:05:38.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mf44f" for this suite.
Mar 26 07:06:02.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:06:02.439: INFO: namespace: e2e-tests-pods-mf44f, resource: bindings, ignored listing per whitelist
Mar 26 07:06:02.514: INFO: namespace e2e-tests-pods-mf44f deletion completed in 24.267601463s

• [SLOW TEST:24.528 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:06:02.516: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar 26 07:06:02.733: INFO: Waiting up to 5m0s for pod "client-containers-9dc5cccd-4f95-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-containers-7s6z9" to be "success or failure"
Mar 26 07:06:02.740: INFO: Pod "client-containers-9dc5cccd-4f95-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.891993ms
Mar 26 07:06:04.746: INFO: Pod "client-containers-9dc5cccd-4f95-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012965744s
Mar 26 07:06:06.753: INFO: Pod "client-containers-9dc5cccd-4f95-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019827809s
STEP: Saw pod success
Mar 26 07:06:06.753: INFO: Pod "client-containers-9dc5cccd-4f95-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:06:06.758: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod client-containers-9dc5cccd-4f95-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 07:06:06.869: INFO: Waiting for pod client-containers-9dc5cccd-4f95-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:06:06.912: INFO: Pod client-containers-9dc5cccd-4f95-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:06:06.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7s6z9" for this suite.
Mar 26 07:06:12.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:06:13.045: INFO: namespace: e2e-tests-containers-7s6z9, resource: bindings, ignored listing per whitelist
Mar 26 07:06:13.218: INFO: namespace e2e-tests-containers-7s6z9 deletion completed in 6.28495025s

• [SLOW TEST:10.703 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:06:13.219: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 26 07:06:13.453: INFO: Waiting up to 5m0s for pod "pod-a427acf9-4f95-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-c2mrb" to be "success or failure"
Mar 26 07:06:13.484: INFO: Pod "pod-a427acf9-4f95-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 30.801314ms
Mar 26 07:06:15.491: INFO: Pod "pod-a427acf9-4f95-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037239549s
Mar 26 07:06:17.498: INFO: Pod "pod-a427acf9-4f95-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044393995s
STEP: Saw pod success
Mar 26 07:06:17.498: INFO: Pod "pod-a427acf9-4f95-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:06:17.504: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-a427acf9-4f95-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 07:06:17.574: INFO: Waiting for pod pod-a427acf9-4f95-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:06:17.582: INFO: Pod pod-a427acf9-4f95-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:06:17.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c2mrb" for this suite.
Mar 26 07:06:23.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:06:23.850: INFO: namespace: e2e-tests-emptydir-c2mrb, resource: bindings, ignored listing per whitelist
Mar 26 07:06:23.902: INFO: namespace e2e-tests-emptydir-c2mrb deletion completed in 6.298692797s

• [SLOW TEST:10.683 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:06:23.904: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar 26 07:06:24.181: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-cdcrf,SelfLink:/api/v1/namespaces/e2e-tests-watch-cdcrf/configmaps/e2e-watch-test-resource-version,UID:aa86163f-4f95-11e9-b22a-90b8d090d774,ResourceVersion:51262,Generation:0,CreationTimestamp:2019-03-26 07:06:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 26 07:06:24.181: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-cdcrf,SelfLink:/api/v1/namespaces/e2e-tests-watch-cdcrf/configmaps/e2e-watch-test-resource-version,UID:aa86163f-4f95-11e9-b22a-90b8d090d774,ResourceVersion:51263,Generation:0,CreationTimestamp:2019-03-26 07:06:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:06:24.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-cdcrf" for this suite.
Mar 26 07:06:30.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:06:30.260: INFO: namespace: e2e-tests-watch-cdcrf, resource: bindings, ignored listing per whitelist
Mar 26 07:06:30.498: INFO: namespace e2e-tests-watch-cdcrf deletion completed in 6.305384511s

• [SLOW TEST:6.595 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:06:30.499: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 26 07:06:30.750: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ae775b92-4f95-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-5cfrl" to be "success or failure"
Mar 26 07:06:30.784: INFO: Pod "downwardapi-volume-ae775b92-4f95-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 34.026935ms
Mar 26 07:06:32.794: INFO: Pod "downwardapi-volume-ae775b92-4f95-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043628479s
STEP: Saw pod success
Mar 26 07:06:32.794: INFO: Pod "downwardapi-volume-ae775b92-4f95-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:06:32.801: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-control-1 pod downwardapi-volume-ae775b92-4f95-11e9-8fea-5694fc6fbac7 container client-container: <nil>
STEP: delete the pod
Mar 26 07:06:32.909: INFO: Waiting for pod downwardapi-volume-ae775b92-4f95-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:06:32.936: INFO: Pod downwardapi-volume-ae775b92-4f95-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:06:32.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5cfrl" for this suite.
Mar 26 07:06:39.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:06:39.164: INFO: namespace: e2e-tests-projected-5cfrl, resource: bindings, ignored listing per whitelist
Mar 26 07:06:39.307: INFO: namespace e2e-tests-projected-5cfrl deletion completed in 6.324457336s

• [SLOW TEST:8.809 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:06:39.309: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 26 07:06:39.526: INFO: Waiting up to 5m0s for pod "pod-b3b1babf-4f95-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-emptydir-wf67x" to be "success or failure"
Mar 26 07:06:39.547: INFO: Pod "pod-b3b1babf-4f95-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.077938ms
Mar 26 07:06:41.555: INFO: Pod "pod-b3b1babf-4f95-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028485716s
STEP: Saw pod success
Mar 26 07:06:41.556: INFO: Pod "pod-b3b1babf-4f95-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:06:41.561: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-b3b1babf-4f95-11e9-8fea-5694fc6fbac7 container test-container: <nil>
STEP: delete the pod
Mar 26 07:06:41.654: INFO: Waiting for pod pod-b3b1babf-4f95-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:06:41.662: INFO: Pod pod-b3b1babf-4f95-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:06:41.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wf67x" for this suite.
Mar 26 07:06:47.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:06:47.909: INFO: namespace: e2e-tests-emptydir-wf67x, resource: bindings, ignored listing per whitelist
Mar 26 07:06:47.932: INFO: namespace e2e-tests-emptydir-wf67x deletion completed in 6.253882973s

• [SLOW TEST:8.624 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:06:47.934: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qkp2p
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-qkp2p
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-qkp2p
Mar 26 07:06:48.245: INFO: Found 0 stateful pods, waiting for 1
Mar 26 07:06:58.251: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 26 07:06:58.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 07:06:58.531: INFO: stderr: ""
Mar 26 07:06:58.531: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 07:06:58.531: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 07:06:58.537: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 26 07:07:08.544: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 07:07:08.544: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 07:07:08.610: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 26 07:07:08.610: INFO: ss-0  k8s-conformance-cluster-1-12-control-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  }]
Mar 26 07:07:08.611: INFO: ss-1                                          Pending         []
Mar 26 07:07:08.611: INFO: 
Mar 26 07:07:08.611: INFO: StatefulSet ss has not reached scale 3, at 2
Mar 26 07:07:09.622: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.969046179s
Mar 26 07:07:10.630: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.958102704s
Mar 26 07:07:11.639: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.949598059s
Mar 26 07:07:12.646: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.941158749s
Mar 26 07:07:13.654: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.933717813s
Mar 26 07:07:14.662: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.925684999s
Mar 26 07:07:15.675: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.917619633s
Mar 26 07:07:16.684: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.905131334s
Mar 26 07:07:17.694: INFO: Verifying statefulset ss doesn't scale past 3 for another 896.205962ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-qkp2p
Mar 26 07:07:18.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:07:19.065: INFO: stderr: ""
Mar 26 07:07:19.065: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 07:07:19.065: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 07:07:19.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:07:19.520: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 26 07:07:19.520: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 07:07:19.520: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 07:07:19.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:07:19.802: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 26 07:07:19.802: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 26 07:07:19.802: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 26 07:07:19.810: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 07:07:19.810: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 26 07:07:19.810: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar 26 07:07:19.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 07:07:20.142: INFO: stderr: ""
Mar 26 07:07:20.142: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 07:07:20.142: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 07:07:20.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 07:07:20.550: INFO: stderr: ""
Mar 26 07:07:20.550: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 07:07:20.550: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 07:07:20.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 26 07:07:20.804: INFO: stderr: ""
Mar 26 07:07:20.804: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 26 07:07:20.804: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 26 07:07:20.804: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 07:07:20.815: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 26 07:07:30.829: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 07:07:30.829: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 07:07:30.829: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 26 07:07:31.004: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 26 07:07:31.005: INFO: ss-0  k8s-conformance-cluster-1-12-control-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  }]
Mar 26 07:07:31.005: INFO: ss-1  k8s-conformance-cluster-1-12-etcd-1     Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:31.005: INFO: ss-2  k8s-conformance-cluster-1-12-worker1-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:31.005: INFO: 
Mar 26 07:07:31.005: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 26 07:07:32.014: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 26 07:07:32.014: INFO: ss-0  k8s-conformance-cluster-1-12-control-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  }]
Mar 26 07:07:32.014: INFO: ss-1  k8s-conformance-cluster-1-12-etcd-1     Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:32.014: INFO: ss-2  k8s-conformance-cluster-1-12-worker1-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:32.014: INFO: 
Mar 26 07:07:32.014: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 26 07:07:33.042: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 26 07:07:33.042: INFO: ss-0  k8s-conformance-cluster-1-12-control-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  }]
Mar 26 07:07:33.042: INFO: ss-1  k8s-conformance-cluster-1-12-etcd-1     Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:33.043: INFO: ss-2  k8s-conformance-cluster-1-12-worker1-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:33.043: INFO: 
Mar 26 07:07:33.043: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 26 07:07:34.055: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 26 07:07:34.056: INFO: ss-0  k8s-conformance-cluster-1-12-control-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  }]
Mar 26 07:07:34.056: INFO: ss-1  k8s-conformance-cluster-1-12-etcd-1     Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:34.056: INFO: ss-2  k8s-conformance-cluster-1-12-worker1-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:34.056: INFO: 
Mar 26 07:07:34.056: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 26 07:07:35.068: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 26 07:07:35.069: INFO: ss-0  k8s-conformance-cluster-1-12-control-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  }]
Mar 26 07:07:35.069: INFO: ss-1  k8s-conformance-cluster-1-12-etcd-1     Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:35.069: INFO: ss-2  k8s-conformance-cluster-1-12-worker1-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:35.069: INFO: 
Mar 26 07:07:35.069: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 26 07:07:36.077: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 26 07:07:36.078: INFO: ss-0  k8s-conformance-cluster-1-12-control-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  }]
Mar 26 07:07:36.078: INFO: ss-1  k8s-conformance-cluster-1-12-etcd-1     Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:36.078: INFO: ss-2  k8s-conformance-cluster-1-12-worker1-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:36.078: INFO: 
Mar 26 07:07:36.078: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 26 07:07:37.115: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 26 07:07:37.115: INFO: ss-0  k8s-conformance-cluster-1-12-control-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  }]
Mar 26 07:07:37.115: INFO: ss-1  k8s-conformance-cluster-1-12-etcd-1     Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:37.115: INFO: ss-2  k8s-conformance-cluster-1-12-worker1-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:37.115: INFO: 
Mar 26 07:07:37.115: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 26 07:07:38.125: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 26 07:07:38.125: INFO: ss-0  k8s-conformance-cluster-1-12-control-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  }]
Mar 26 07:07:38.125: INFO: ss-1  k8s-conformance-cluster-1-12-etcd-1     Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:38.125: INFO: ss-2  k8s-conformance-cluster-1-12-worker1-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:38.125: INFO: 
Mar 26 07:07:38.126: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 26 07:07:39.134: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 26 07:07:39.134: INFO: ss-0  k8s-conformance-cluster-1-12-control-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  }]
Mar 26 07:07:39.134: INFO: ss-1  k8s-conformance-cluster-1-12-etcd-1     Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:39.134: INFO: 
Mar 26 07:07:39.134: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 26 07:07:40.153: INFO: POD   NODE                                    PHASE    GRACE  CONDITIONS
Mar 26 07:07:40.153: INFO: ss-0  k8s-conformance-cluster-1-12-control-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:06:48 +0000 UTC  }]
Mar 26 07:07:40.153: INFO: ss-1  k8s-conformance-cluster-1-12-etcd-1     Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-26 07:07:08 +0000 UTC  }]
Mar 26 07:07:40.153: INFO: 
Mar 26 07:07:40.153: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-qkp2p
Mar 26 07:07:41.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:07:41.397: INFO: rc: 1
Mar 26 07:07:41.397: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc4215be8a0 exit status 1 <nil> <nil> true [0xc4210fc278 0xc4210fc290 0xc4210fc2a8] [0xc4210fc278 0xc4210fc290 0xc4210fc2a8] [0xc4210fc288 0xc4210fc2a0] [0x8fd520 0x8fd520] 0xc422977020 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Mar 26 07:07:51.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:07:51.532: INFO: rc: 1
Mar 26 07:07:51.532: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215becf0 exit status 1 <nil> <nil> true [0xc4210fc2b0 0xc4210fc2c8 0xc4210fc2e0] [0xc4210fc2b0 0xc4210fc2c8 0xc4210fc2e0] [0xc4210fc2c0 0xc4210fc2d8] [0x8fd520 0x8fd520] 0xc422977140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:08:01.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:08:01.673: INFO: rc: 1
Mar 26 07:08:01.673: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215bf0e0 exit status 1 <nil> <nil> true [0xc4210fc2e8 0xc4210fc300 0xc4210fc318] [0xc4210fc2e8 0xc4210fc300 0xc4210fc318] [0xc4210fc2f8 0xc4210fc310] [0x8fd520 0x8fd520] 0xc422977260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:08:11.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:08:11.804: INFO: rc: 1
Mar 26 07:08:11.804: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4215bf4d0 exit status 1 <nil> <nil> true [0xc4210fc320 0xc4210fc338 0xc4210fc350] [0xc4210fc320 0xc4210fc338 0xc4210fc350] [0xc4210fc330 0xc4210fc348] [0x8fd520 0x8fd520] 0xc422977380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:08:21.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:08:21.966: INFO: rc: 1
Mar 26 07:08:21.967: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c2720 exit status 1 <nil> <nil> true [0xc421f56020 0xc421f56038 0xc421f56050] [0xc421f56020 0xc421f56038 0xc421f56050] [0xc421f56030 0xc421f56048] [0x8fd520 0x8fd520] 0xc42145a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:08:31.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:08:32.133: INFO: rc: 1
Mar 26 07:08:32.133: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c2b10 exit status 1 <nil> <nil> true [0xc421f56058 0xc421f56070 0xc421f56088] [0xc421f56058 0xc421f56070 0xc421f56088] [0xc421f56068 0xc421f56080] [0x8fd520 0x8fd520] 0xc42145a720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:08:42.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:08:42.293: INFO: rc: 1
Mar 26 07:08:42.293: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c2f00 exit status 1 <nil> <nil> true [0xc421f56090 0xc421f560a8 0xc421f560c0] [0xc421f56090 0xc421f560a8 0xc421f560c0] [0xc421f560a0 0xc421f560b8] [0x8fd520 0x8fd520] 0xc42145a840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:08:52.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:08:52.446: INFO: rc: 1
Mar 26 07:08:52.446: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c3410 exit status 1 <nil> <nil> true [0xc421f560c8 0xc421f560e0 0xc421f56100] [0xc421f560c8 0xc421f560e0 0xc421f56100] [0xc421f560d8 0xc421f560f8] [0x8fd520 0x8fd520] 0xc42145a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:09:02.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:09:02.614: INFO: rc: 1
Mar 26 07:09:02.614: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c3830 exit status 1 <nil> <nil> true [0xc421f56108 0xc421f56120 0xc421f56138] [0xc421f56108 0xc421f56120 0xc421f56138] [0xc421f56118 0xc421f56130] [0x8fd520 0x8fd520] 0xc42145aa80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:09:12.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:09:12.758: INFO: rc: 1
Mar 26 07:09:12.758: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c3cb0 exit status 1 <nil> <nil> true [0xc421f56140 0xc421f56158 0xc421f56170] [0xc421f56140 0xc421f56158 0xc421f56170] [0xc421f56150 0xc421f56168] [0x8fd520 0x8fd520] 0xc42145aba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:09:22.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:09:22.905: INFO: rc: 1
Mar 26 07:09:22.906: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fc150 exit status 1 <nil> <nil> true [0xc421f56178 0xc421f56190 0xc421f561a8] [0xc421f56178 0xc421f56190 0xc421f561a8] [0xc421f56188 0xc421f561a0] [0x8fd520 0x8fd520] 0xc42145acc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:09:32.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:09:33.132: INFO: rc: 1
Mar 26 07:09:33.132: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fc5a0 exit status 1 <nil> <nil> true [0xc421f561b0 0xc421f561c8 0xc421f561e0] [0xc421f561b0 0xc421f561c8 0xc421f561e0] [0xc421f561c0 0xc421f561d8] [0x8fd520 0x8fd520] 0xc42145ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:09:43.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:09:43.274: INFO: rc: 1
Mar 26 07:09:43.274: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fc9f0 exit status 1 <nil> <nil> true [0xc421f561e8 0xc421f56200 0xc421f56218] [0xc421f561e8 0xc421f56200 0xc421f56218] [0xc421f561f8 0xc421f56210] [0x8fd520 0x8fd520] 0xc42145af00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:09:53.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:09:53.447: INFO: rc: 1
Mar 26 07:09:53.448: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fcde0 exit status 1 <nil> <nil> true [0xc421f56220 0xc421f56238 0xc421f56250] [0xc421f56220 0xc421f56238 0xc421f56250] [0xc421f56230 0xc421f56248] [0x8fd520 0x8fd520] 0xc42145b0e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:10:03.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:10:03.594: INFO: rc: 1
Mar 26 07:10:03.595: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fd320 exit status 1 <nil> <nil> true [0xc421f56258 0xc421f56270 0xc421f56288] [0xc421f56258 0xc421f56270 0xc421f56288] [0xc421f56268 0xc421f56280] [0x8fd520 0x8fd520] 0xc42145b200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:10:13.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:10:13.763: INFO: rc: 1
Mar 26 07:10:13.763: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fd710 exit status 1 <nil> <nil> true [0xc421f56290 0xc421f562a8 0xc421f562c0] [0xc421f56290 0xc421f562a8 0xc421f562c0] [0xc421f562a0 0xc421f562b8] [0x8fd520 0x8fd520] 0xc42145b320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:10:23.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:10:23.913: INFO: rc: 1
Mar 26 07:10:23.913: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c2750 exit status 1 <nil> <nil> true [0xc421f56020 0xc421f56038 0xc421f56050] [0xc421f56020 0xc421f56038 0xc421f56050] [0xc421f56030 0xc421f56048] [0x8fd520 0x8fd520] 0xc42145a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:10:33.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:10:34.059: INFO: rc: 1
Mar 26 07:10:34.059: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c2b70 exit status 1 <nil> <nil> true [0xc421f56058 0xc421f56070 0xc421f56088] [0xc421f56058 0xc421f56070 0xc421f56088] [0xc421f56068 0xc421f56080] [0x8fd520 0x8fd520] 0xc42145a720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:10:44.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:10:44.223: INFO: rc: 1
Mar 26 07:10:44.223: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c3050 exit status 1 <nil> <nil> true [0xc421f56090 0xc421f560a8 0xc421f560c0] [0xc421f56090 0xc421f560a8 0xc421f560c0] [0xc421f560a0 0xc421f560b8] [0x8fd520 0x8fd520] 0xc42145a840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:10:54.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:10:54.382: INFO: rc: 1
Mar 26 07:10:54.382: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c34d0 exit status 1 <nil> <nil> true [0xc421f560c8 0xc421f560e0 0xc421f56100] [0xc421f560c8 0xc421f560e0 0xc421f56100] [0xc421f560d8 0xc421f560f8] [0x8fd520 0x8fd520] 0xc42145a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:11:04.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:11:04.542: INFO: rc: 1
Mar 26 07:11:04.542: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c3920 exit status 1 <nil> <nil> true [0xc421f56108 0xc421f56120 0xc421f56138] [0xc421f56108 0xc421f56120 0xc421f56138] [0xc421f56118 0xc421f56130] [0x8fd520 0x8fd520] 0xc42145aa80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:11:14.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:11:14.707: INFO: rc: 1
Mar 26 07:11:14.707: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c3e30 exit status 1 <nil> <nil> true [0xc421f56140 0xc421f56158 0xc421f56170] [0xc421f56140 0xc421f56158 0xc421f56170] [0xc421f56150 0xc421f56168] [0x8fd520 0x8fd520] 0xc42145aba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:11:24.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:11:24.871: INFO: rc: 1
Mar 26 07:11:24.871: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fc2a0 exit status 1 <nil> <nil> true [0xc421f56178 0xc421f56190 0xc421f561a8] [0xc421f56178 0xc421f56190 0xc421f561a8] [0xc421f56188 0xc421f561a0] [0x8fd520 0x8fd520] 0xc42145acc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:11:34.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:11:35.017: INFO: rc: 1
Mar 26 07:11:35.017: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fc750 exit status 1 <nil> <nil> true [0xc421f561b0 0xc421f561c8 0xc421f561e0] [0xc421f561b0 0xc421f561c8 0xc421f561e0] [0xc421f561c0 0xc421f561d8] [0x8fd520 0x8fd520] 0xc42145ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:11:45.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:11:45.177: INFO: rc: 1
Mar 26 07:11:45.177: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fcba0 exit status 1 <nil> <nil> true [0xc421f561e8 0xc421f56200 0xc421f56218] [0xc421f561e8 0xc421f56200 0xc421f56218] [0xc421f561f8 0xc421f56210] [0x8fd520 0x8fd520] 0xc42145af00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:11:55.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:11:55.329: INFO: rc: 1
Mar 26 07:11:55.329: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fd050 exit status 1 <nil> <nil> true [0xc421f56220 0xc421f56238 0xc421f56250] [0xc421f56220 0xc421f56238 0xc421f56250] [0xc421f56230 0xc421f56248] [0x8fd520 0x8fd520] 0xc42145b0e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:12:05.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:12:05.479: INFO: rc: 1
Mar 26 07:12:05.479: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fd530 exit status 1 <nil> <nil> true [0xc421f56258 0xc421f56270 0xc421f56288] [0xc421f56258 0xc421f56270 0xc421f56288] [0xc421f56268 0xc421f56280] [0x8fd520 0x8fd520] 0xc42145b200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:12:15.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:12:15.613: INFO: rc: 1
Mar 26 07:12:15.613: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4225fd950 exit status 1 <nil> <nil> true [0xc421f56290 0xc421f562a8 0xc421f562c0] [0xc421f56290 0xc421f562a8 0xc421f562c0] [0xc421f562a0 0xc421f562b8] [0x8fd520 0x8fd520] 0xc42145b320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:12:25.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:12:25.882: INFO: rc: 1
Mar 26 07:12:25.882: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c2720 exit status 1 <nil> <nil> true [0xc421f56020 0xc421f56038 0xc421f56050] [0xc421f56020 0xc421f56038 0xc421f56050] [0xc421f56030 0xc421f56048] [0x8fd520 0x8fd520] 0xc42145a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:12:35.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:12:36.236: INFO: rc: 1
Mar 26 07:12:36.236: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4227c2b40 exit status 1 <nil> <nil> true [0xc421f56058 0xc421f56070 0xc421f56088] [0xc421f56058 0xc421f56070 0xc421f56088] [0xc421f56068 0xc421f56080] [0x8fd520 0x8fd520] 0xc42145a720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Mar 26 07:12:46.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-414927603 exec --namespace=e2e-tests-statefulset-qkp2p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 26 07:12:46.383: INFO: rc: 1
Mar 26 07:12:46.383: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Mar 26 07:12:46.383: INFO: Scaling statefulset ss to 0
Mar 26 07:12:46.402: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 26 07:12:46.409: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qkp2p
Mar 26 07:12:46.415: INFO: Scaling statefulset ss to 0
Mar 26 07:12:46.433: INFO: Waiting for statefulset status.replicas updated to 0
Mar 26 07:12:46.439: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:12:46.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qkp2p" for this suite.
Mar 26 07:12:54.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:12:54.673: INFO: namespace: e2e-tests-statefulset-qkp2p, resource: bindings, ignored listing per whitelist
Mar 26 07:12:54.792: INFO: namespace e2e-tests-statefulset-qkp2p deletion completed in 8.27656932s

• [SLOW TEST:366.858 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:12:54.794: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-93806020-4f96-11e9-8fea-5694fc6fbac7
STEP: Creating a pod to test consume configMaps
Mar 26 07:12:55.023: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9382708a-4f96-11e9-8fea-5694fc6fbac7" in namespace "e2e-tests-projected-smtgm" to be "success or failure"
Mar 26 07:12:55.043: INFO: Pod "pod-projected-configmaps-9382708a-4f96-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 19.624622ms
Mar 26 07:12:57.050: INFO: Pod "pod-projected-configmaps-9382708a-4f96-11e9-8fea-5694fc6fbac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026865936s
Mar 26 07:12:59.058: INFO: Pod "pod-projected-configmaps-9382708a-4f96-11e9-8fea-5694fc6fbac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034133761s
STEP: Saw pod success
Mar 26 07:12:59.058: INFO: Pod "pod-projected-configmaps-9382708a-4f96-11e9-8fea-5694fc6fbac7" satisfied condition "success or failure"
Mar 26 07:12:59.064: INFO: Trying to get logs from node k8s-conformance-cluster-1-12-etcd-1 pod pod-projected-configmaps-9382708a-4f96-11e9-8fea-5694fc6fbac7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 26 07:12:59.162: INFO: Waiting for pod pod-projected-configmaps-9382708a-4f96-11e9-8fea-5694fc6fbac7 to disappear
Mar 26 07:12:59.185: INFO: Pod pod-projected-configmaps-9382708a-4f96-11e9-8fea-5694fc6fbac7 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:12:59.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-smtgm" for this suite.
Mar 26 07:13:05.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:13:05.318: INFO: namespace: e2e-tests-projected-smtgm, resource: bindings, ignored listing per whitelist
Mar 26 07:13:05.468: INFO: namespace e2e-tests-projected-smtgm deletion completed in 6.268009534s

• [SLOW TEST:10.674 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:13:05.470: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0326 07:13:15.954866      14 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 26 07:13:15.955: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:13:15.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hn2hr" for this suite.
Mar 26 07:13:24.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:13:24.092: INFO: namespace: e2e-tests-gc-hn2hr, resource: bindings, ignored listing per whitelist
Mar 26 07:13:24.231: INFO: namespace e2e-tests-gc-hn2hr deletion completed in 8.26637002s

• [SLOW TEST:18.762 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar 26 07:13:24.237: INFO: >>> kubeConfig: /tmp/kubeconfig-414927603
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-a511543d-4f96-11e9-8fea-5694fc6fbac7
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar 26 07:13:26.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x24zd" for this suite.
Mar 26 07:13:50.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 26 07:13:51.009: INFO: namespace: e2e-tests-configmap-x24zd, resource: bindings, ignored listing per whitelist
Mar 26 07:13:51.026: INFO: namespace e2e-tests-configmap-x24zd deletion completed in 24.416873559s

• [SLOW TEST:26.790 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSMar 26 07:13:51.027: INFO: Running AfterSuite actions on all node
Mar 26 07:13:51.027: INFO: Running AfterSuite actions on node 1
Mar 26 07:13:51.027: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5707.408 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h35m9.754932317s
Test Suite Passed
