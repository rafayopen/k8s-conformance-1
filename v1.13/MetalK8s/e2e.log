I0906 11:33:03.868653      17 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-878575678
I0906 11:33:03.868895      17 e2e.go:224] Starting e2e run "163fbf4b-d09a-11e9-9cef-86a5da7a2260" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1567769582 - Will randomize all specs
Will run 201 of 1946 specs

Sep  6 11:33:04.125: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:33:04.152: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep  6 11:33:04.177: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  6 11:33:04.214: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  6 11:33:04.214: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Sep  6 11:33:04.214: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep  6 11:33:04.227: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Sep  6 11:33:04.227: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Sep  6 11:33:04.227: INFO: e2e test version: v1.13.0
Sep  6 11:33:04.229: INFO: kube-apiserver version: v1.13.10
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:33:04.229: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
Sep  6 11:33:04.334: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-1727191e-d09a-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 11:33:04.365: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1727ffa7-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-5kbkr" to be "success or failure"
Sep  6 11:33:04.420: INFO: Pod "pod-projected-secrets-1727ffa7-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 54.60925ms
Sep  6 11:33:06.424: INFO: Pod "pod-projected-secrets-1727ffa7-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058666547s
Sep  6 11:33:08.430: INFO: Pod "pod-projected-secrets-1727ffa7-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06484626s
STEP: Saw pod success
Sep  6 11:33:08.430: INFO: Pod "pod-projected-secrets-1727ffa7-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:33:08.436: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-secrets-1727ffa7-d09a-11e9-9cef-86a5da7a2260 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  6 11:33:08.539: INFO: Waiting for pod pod-projected-secrets-1727ffa7-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:33:08.544: INFO: Pod pod-projected-secrets-1727ffa7-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:33:08.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5kbkr" for this suite.
Sep  6 11:33:14.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:33:14.575: INFO: namespace: e2e-tests-projected-5kbkr, resource: bindings, ignored listing per whitelist
Sep  6 11:33:14.713: INFO: namespace e2e-tests-projected-5kbkr deletion completed in 6.16676312s

• [SLOW TEST:10.485 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:33:14.714: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-1d609941-d09a-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 11:33:14.811: INFO: Waiting up to 5m0s for pod "pod-configmaps-1d6297ea-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-configmap-kj25j" to be "success or failure"
Sep  6 11:33:14.813: INFO: Pod "pod-configmaps-1d6297ea-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.360555ms
Sep  6 11:33:16.819: INFO: Pod "pod-configmaps-1d6297ea-d09a-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.007713269s
Sep  6 11:33:18.822: INFO: Pod "pod-configmaps-1d6297ea-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01122048s
STEP: Saw pod success
Sep  6 11:33:18.822: INFO: Pod "pod-configmaps-1d6297ea-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:33:18.825: INFO: Trying to get logs from node metalk8s-22 pod pod-configmaps-1d6297ea-d09a-11e9-9cef-86a5da7a2260 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 11:33:19.370: INFO: Waiting for pod pod-configmaps-1d6297ea-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:33:19.376: INFO: Pod pod-configmaps-1d6297ea-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:33:19.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kj25j" for this suite.
Sep  6 11:33:25.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:33:25.503: INFO: namespace: e2e-tests-configmap-kj25j, resource: bindings, ignored listing per whitelist
Sep  6 11:33:25.581: INFO: namespace e2e-tests-configmap-kj25j deletion completed in 6.191896008s

• [SLOW TEST:10.867 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:33:25.581: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0906 11:33:26.742767      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 11:33:26.742: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:33:26.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k5lkh" for this suite.
Sep  6 11:33:32.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:33:32.861: INFO: namespace: e2e-tests-gc-k5lkh, resource: bindings, ignored listing per whitelist
Sep  6 11:33:32.913: INFO: namespace e2e-tests-gc-k5lkh deletion completed in 6.1676531s

• [SLOW TEST:7.332 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:33:32.913: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-kmjg9/configmap-test-2838ae10-d09a-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 11:33:33.016: INFO: Waiting up to 5m0s for pod "pod-configmaps-283c23f2-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-configmap-kmjg9" to be "success or failure"
Sep  6 11:33:33.024: INFO: Pod "pod-configmaps-283c23f2-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 7.292721ms
Sep  6 11:33:35.028: INFO: Pod "pod-configmaps-283c23f2-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0115022s
Sep  6 11:33:37.033: INFO: Pod "pod-configmaps-283c23f2-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016864604s
STEP: Saw pod success
Sep  6 11:33:37.033: INFO: Pod "pod-configmaps-283c23f2-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:33:37.039: INFO: Trying to get logs from node metalk8s-22 pod pod-configmaps-283c23f2-d09a-11e9-9cef-86a5da7a2260 container env-test: <nil>
STEP: delete the pod
Sep  6 11:33:37.071: INFO: Waiting for pod pod-configmaps-283c23f2-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:33:37.075: INFO: Pod pod-configmaps-283c23f2-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:33:37.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kmjg9" for this suite.
Sep  6 11:33:43.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:33:43.177: INFO: namespace: e2e-tests-configmap-kmjg9, resource: bindings, ignored listing per whitelist
Sep  6 11:33:43.243: INFO: namespace e2e-tests-configmap-kmjg9 deletion completed in 6.153792215s

• [SLOW TEST:10.330 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:33:43.243: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-7ddrr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  6 11:33:43.314: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  6 11:34:07.407: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.233.217.86 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7ddrr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:34:07.407: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:34:08.616: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:34:08.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-7ddrr" for this suite.
Sep  6 11:34:32.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:34:32.755: INFO: namespace: e2e-tests-pod-network-test-7ddrr, resource: bindings, ignored listing per whitelist
Sep  6 11:34:32.796: INFO: namespace e2e-tests-pod-network-test-7ddrr deletion completed in 24.176074956s

• [SLOW TEST:49.552 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:34:32.796: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Sep  6 11:34:32.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 --namespace=e2e-tests-kubectl-48dhf run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep  6 11:34:34.476: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep  6 11:34:34.476: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:34:36.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-48dhf" for this suite.
Sep  6 11:34:42.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:34:42.601: INFO: namespace: e2e-tests-kubectl-48dhf, resource: bindings, ignored listing per whitelist
Sep  6 11:34:42.680: INFO: namespace e2e-tests-kubectl-48dhf deletion completed in 6.195621164s

• [SLOW TEST:9.884 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:34:42.680: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 11:34:42.816: INFO: Waiting up to 5m0s for pod "downwardapi-volume-51d65f8d-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-dj9mq" to be "success or failure"
Sep  6 11:34:42.826: INFO: Pod "downwardapi-volume-51d65f8d-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 10.193227ms
Sep  6 11:34:44.830: INFO: Pod "downwardapi-volume-51d65f8d-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014250078s
STEP: Saw pod success
Sep  6 11:34:44.830: INFO: Pod "downwardapi-volume-51d65f8d-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:34:44.835: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-51d65f8d-d09a-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 11:34:44.868: INFO: Waiting for pod downwardapi-volume-51d65f8d-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:34:44.875: INFO: Pod downwardapi-volume-51d65f8d-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:34:44.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dj9mq" for this suite.
Sep  6 11:34:50.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:34:50.998: INFO: namespace: e2e-tests-projected-dj9mq, resource: bindings, ignored listing per whitelist
Sep  6 11:34:51.009: INFO: namespace e2e-tests-projected-dj9mq deletion completed in 6.130817203s

• [SLOW TEST:8.329 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:34:51.009: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-56c46198-d09a-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 11:34:51.092: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-56c59866-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-vm24f" to be "success or failure"
Sep  6 11:34:51.098: INFO: Pod "pod-projected-configmaps-56c59866-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 6.002173ms
Sep  6 11:34:53.102: INFO: Pod "pod-projected-configmaps-56c59866-d09a-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.009170945s
Sep  6 11:34:55.106: INFO: Pod "pod-projected-configmaps-56c59866-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013678635s
STEP: Saw pod success
Sep  6 11:34:55.106: INFO: Pod "pod-projected-configmaps-56c59866-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:34:55.111: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-configmaps-56c59866-d09a-11e9-9cef-86a5da7a2260 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 11:34:55.131: INFO: Waiting for pod pod-projected-configmaps-56c59866-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:34:55.139: INFO: Pod pod-projected-configmaps-56c59866-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:34:55.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vm24f" for this suite.
Sep  6 11:35:01.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:35:01.183: INFO: namespace: e2e-tests-projected-vm24f, resource: bindings, ignored listing per whitelist
Sep  6 11:35:01.290: INFO: namespace e2e-tests-projected-vm24f deletion completed in 6.148371698s

• [SLOW TEST:10.281 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:35:01.290: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Sep  6 11:35:03.415: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:35:27.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-p4qdr" for this suite.
Sep  6 11:35:33.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:35:33.496: INFO: namespace: e2e-tests-namespaces-p4qdr, resource: bindings, ignored listing per whitelist
Sep  6 11:35:33.568: INFO: namespace e2e-tests-namespaces-p4qdr deletion completed in 6.103884494s
STEP: Destroying namespace "e2e-tests-nsdeletetest-7md97" for this suite.
Sep  6 11:35:33.570: INFO: Namespace e2e-tests-nsdeletetest-7md97 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-jk4mr" for this suite.
Sep  6 11:35:39.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:35:39.701: INFO: namespace: e2e-tests-nsdeletetest-jk4mr, resource: bindings, ignored listing per whitelist
Sep  6 11:35:39.760: INFO: namespace e2e-tests-nsdeletetest-jk4mr deletion completed in 6.190447432s

• [SLOW TEST:38.470 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:35:39.761: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 11:35:39.847: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:35:42.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zrsr8" for this suite.
Sep  6 11:36:26.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:36:26.198: INFO: namespace: e2e-tests-pods-zrsr8, resource: bindings, ignored listing per whitelist
Sep  6 11:36:26.240: INFO: namespace e2e-tests-pods-zrsr8 deletion completed in 44.202931955s

• [SLOW TEST:46.479 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:36:26.240: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Sep  6 11:36:26.364: INFO: Waiting up to 5m0s for pod "client-containers-8f8eaa01-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-containers-7pgjn" to be "success or failure"
Sep  6 11:36:26.369: INFO: Pod "client-containers-8f8eaa01-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 5.018635ms
Sep  6 11:36:28.379: INFO: Pod "client-containers-8f8eaa01-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014972971s
Sep  6 11:36:30.384: INFO: Pod "client-containers-8f8eaa01-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020131049s
STEP: Saw pod success
Sep  6 11:36:30.384: INFO: Pod "client-containers-8f8eaa01-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:36:30.388: INFO: Trying to get logs from node metalk8s-22 pod client-containers-8f8eaa01-d09a-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 11:36:30.434: INFO: Waiting for pod client-containers-8f8eaa01-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:36:30.449: INFO: Pod client-containers-8f8eaa01-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:36:30.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7pgjn" for this suite.
Sep  6 11:36:36.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:36:36.547: INFO: namespace: e2e-tests-containers-7pgjn, resource: bindings, ignored listing per whitelist
Sep  6 11:36:36.602: INFO: namespace e2e-tests-containers-7pgjn deletion completed in 6.146785446s

• [SLOW TEST:10.362 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:36:36.603: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-95b34292-d09a-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 11:36:36.709: INFO: Waiting up to 5m0s for pod "pod-secrets-95b9a497-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-secrets-pqpk9" to be "success or failure"
Sep  6 11:36:36.726: INFO: Pod "pod-secrets-95b9a497-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 17.046631ms
Sep  6 11:36:38.728: INFO: Pod "pod-secrets-95b9a497-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019781566s
STEP: Saw pod success
Sep  6 11:36:38.728: INFO: Pod "pod-secrets-95b9a497-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:36:38.731: INFO: Trying to get logs from node metalk8s-22 pod pod-secrets-95b9a497-d09a-11e9-9cef-86a5da7a2260 container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 11:36:38.745: INFO: Waiting for pod pod-secrets-95b9a497-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:36:38.750: INFO: Pod pod-secrets-95b9a497-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:36:38.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pqpk9" for this suite.
Sep  6 11:36:44.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:36:44.873: INFO: namespace: e2e-tests-secrets-pqpk9, resource: bindings, ignored listing per whitelist
Sep  6 11:36:44.900: INFO: namespace e2e-tests-secrets-pqpk9 deletion completed in 6.147363255s
STEP: Destroying namespace "e2e-tests-secret-namespace-phv9c" for this suite.
Sep  6 11:36:50.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:36:50.944: INFO: namespace: e2e-tests-secret-namespace-phv9c, resource: bindings, ignored listing per whitelist
Sep  6 11:36:51.075: INFO: namespace e2e-tests-secret-namespace-phv9c deletion completed in 6.175255123s

• [SLOW TEST:14.472 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:36:51.075: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 11:36:51.159: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e5663b2-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-hr8dx" to be "success or failure"
Sep  6 11:36:51.168: INFO: Pod "downwardapi-volume-9e5663b2-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 8.765216ms
Sep  6 11:36:53.174: INFO: Pod "downwardapi-volume-9e5663b2-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01465162s
Sep  6 11:36:55.178: INFO: Pod "downwardapi-volume-9e5663b2-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018559522s
STEP: Saw pod success
Sep  6 11:36:55.178: INFO: Pod "downwardapi-volume-9e5663b2-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:36:55.181: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-9e5663b2-d09a-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 11:36:55.201: INFO: Waiting for pod downwardapi-volume-9e5663b2-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:36:55.203: INFO: Pod downwardapi-volume-9e5663b2-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:36:55.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hr8dx" for this suite.
Sep  6 11:37:01.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:37:01.249: INFO: namespace: e2e-tests-projected-hr8dx, resource: bindings, ignored listing per whitelist
Sep  6 11:37:01.424: INFO: namespace e2e-tests-projected-hr8dx deletion completed in 6.218263483s

• [SLOW TEST:10.349 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:37:01.425: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 11:37:01.563: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a48a2130-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-dshm5" to be "success or failure"
Sep  6 11:37:01.565: INFO: Pod "downwardapi-volume-a48a2130-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.455775ms
Sep  6 11:37:03.573: INFO: Pod "downwardapi-volume-a48a2130-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009842695s
STEP: Saw pod success
Sep  6 11:37:03.573: INFO: Pod "downwardapi-volume-a48a2130-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:37:03.575: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-a48a2130-d09a-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 11:37:03.599: INFO: Waiting for pod downwardapi-volume-a48a2130-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:37:03.602: INFO: Pod downwardapi-volume-a48a2130-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:37:03.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dshm5" for this suite.
Sep  6 11:37:09.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:37:09.672: INFO: namespace: e2e-tests-downward-api-dshm5, resource: bindings, ignored listing per whitelist
Sep  6 11:37:09.762: INFO: namespace e2e-tests-downward-api-dshm5 deletion completed in 6.155653503s

• [SLOW TEST:8.337 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:37:09.762: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 11:37:09.852: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a97870a0-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-rx7hm" to be "success or failure"
Sep  6 11:37:09.868: INFO: Pod "downwardapi-volume-a97870a0-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 16.178106ms
Sep  6 11:37:11.873: INFO: Pod "downwardapi-volume-a97870a0-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021028581s
STEP: Saw pod success
Sep  6 11:37:11.873: INFO: Pod "downwardapi-volume-a97870a0-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:37:11.889: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-a97870a0-d09a-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 11:37:11.919: INFO: Waiting for pod downwardapi-volume-a97870a0-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:37:11.926: INFO: Pod downwardapi-volume-a97870a0-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:37:11.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rx7hm" for this suite.
Sep  6 11:37:17.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:37:17.951: INFO: namespace: e2e-tests-projected-rx7hm, resource: bindings, ignored listing per whitelist
Sep  6 11:37:18.112: INFO: namespace e2e-tests-projected-rx7hm deletion completed in 6.181832029s

• [SLOW TEST:8.350 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:37:18.112: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  6 11:37:18.232: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  6 11:37:18.240: INFO: Waiting for terminating namespaces to be deleted...
Sep  6 11:37:18.242: INFO: 
Logging pods the kubelet thinks is on node metalk8s-22 before test
Sep  6 11:37:18.254: INFO: kube-state-metrics-86b8b5b6cd-wkhwt from metalk8s-monitoring started at 2019-09-06 11:16:38 +0000 UTC (4 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container addon-resizer ready: true, restart count 0
Sep  6 11:37:18.254: INFO: 	Container kube-rbac-proxy-main ready: true, restart count 0
Sep  6 11:37:18.254: INFO: 	Container kube-rbac-proxy-self ready: true, restart count 0
Sep  6 11:37:18.254: INFO: 	Container kube-state-metrics ready: true, restart count 0
Sep  6 11:37:18.254: INFO: etcd-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:37:18.254: INFO: repositories-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:37:18.254: INFO: kube-scheduler-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:37:18.254: INFO: calico-node-qnjrt from kube-system started at 2019-09-06 11:16:12 +0000 UTC (1 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container calico-node ready: true, restart count 0
Sep  6 11:37:18.254: INFO: coredns-75d9fb9567-jc986 from kube-system started at 2019-09-06 11:16:15 +0000 UTC (1 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container coredns ready: true, restart count 0
Sep  6 11:37:18.254: INFO: prometheus-k8s-0 from metalk8s-monitoring started at 2019-09-06 11:16:45 +0000 UTC (3 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container prometheus ready: true, restart count 1
Sep  6 11:37:18.254: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Sep  6 11:37:18.254: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Sep  6 11:37:18.254: INFO: nginx-ingress-default-backend-6d7c5f49bd-tn6dj from metalk8s-ingress started at 2019-09-06 11:16:50 +0000 UTC (1 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Sep  6 11:37:18.254: INFO: alertmanager-main-2 from metalk8s-monitoring started at 2019-09-06 11:16:56 +0000 UTC (2 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container alertmanager ready: true, restart count 0
Sep  6 11:37:18.254: INFO: 	Container config-reloader ready: true, restart count 0
Sep  6 11:37:18.254: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-06 11:32:30 +0000 UTC (1 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  6 11:37:18.254: INFO: kube-apiserver-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:37:18.254: INFO: coredns-75d9fb9567-ttgdv from kube-system started at 2019-09-06 11:16:15 +0000 UTC (1 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container coredns ready: true, restart count 0
Sep  6 11:37:18.254: INFO: prometheus-k8s-1 from metalk8s-monitoring started at 2019-09-06 11:16:45 +0000 UTC (3 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container prometheus ready: true, restart count 1
Sep  6 11:37:18.254: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Sep  6 11:37:18.254: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Sep  6 11:37:18.254: INFO: nginx-ingress-controller-v46nl from metalk8s-ingress started at 2019-09-06 11:16:49 +0000 UTC (1 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  6 11:37:18.254: INFO: sonobuoy-e2e-job-686830808f80405c from heptio-sonobuoy started at 2019-09-06 11:32:36 +0000 UTC (2 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container e2e ready: true, restart count 0
Sep  6 11:37:18.254: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 11:37:18.254: INFO: kube-controller-manager-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:37:18.254: INFO: kube-proxy-7cpsq from kube-system started at 2019-09-06 11:16:04 +0000 UTC (1 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  6 11:37:18.254: INFO: prometheus-adapter-9cfc8ff6d-swmpn from metalk8s-monitoring started at 2019-09-06 11:16:31 +0000 UTC (1 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container prometheus-adapter ready: true, restart count 0
Sep  6 11:37:18.254: INFO: salt-master-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:37:18.254: INFO: prometheus-operator-5f67d45986-pvgjz from metalk8s-monitoring started at 2019-09-06 11:16:18 +0000 UTC (1 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container prometheus-operator ready: true, restart count 0
Sep  6 11:37:18.254: INFO: sonobuoy-systemd-logs-daemon-set-1a98abcdad7f4913-gsb5x from heptio-sonobuoy started at 2019-09-06 11:32:36 +0000 UTC (2 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 11:37:18.254: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  6 11:37:18.254: INFO: calico-kube-controllers-5fb4b978ff-hj8s4 from kube-system started at 2019-09-06 11:16:12 +0000 UTC (1 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep  6 11:37:18.254: INFO: alertmanager-main-0 from metalk8s-monitoring started at 2019-09-06 11:16:38 +0000 UTC (2 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container alertmanager ready: true, restart count 0
Sep  6 11:37:18.254: INFO: 	Container config-reloader ready: true, restart count 0
Sep  6 11:37:18.254: INFO: node-exporter-pvl9b from metalk8s-monitoring started at 2019-09-06 11:16:40 +0000 UTC (2 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Sep  6 11:37:18.254: INFO: 	Container node-exporter ready: true, restart count 0
Sep  6 11:37:18.254: INFO: grafana-5c9b84b94f-qrc6b from metalk8s-monitoring started at 2019-09-06 11:16:46 +0000 UTC (1 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container grafana ready: true, restart count 0
Sep  6 11:37:18.254: INFO: alertmanager-main-1 from metalk8s-monitoring started at 2019-09-06 11:16:50 +0000 UTC (2 container statuses recorded)
Sep  6 11:37:18.254: INFO: 	Container alertmanager ready: true, restart count 0
Sep  6 11:37:18.254: INFO: 	Container config-reloader ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-afb4a625-d09a-11e9-9cef-86a5da7a2260 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-afb4a625-d09a-11e9-9cef-86a5da7a2260 off the node metalk8s-22
STEP: verifying the node doesn't have the label kubernetes.io/e2e-afb4a625-d09a-11e9-9cef-86a5da7a2260
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:37:22.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-gnp98" for this suite.
Sep  6 11:37:34.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:37:34.439: INFO: namespace: e2e-tests-sched-pred-gnp98, resource: bindings, ignored listing per whitelist
Sep  6 11:37:34.451: INFO: namespace e2e-tests-sched-pred-gnp98 deletion completed in 12.09402317s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.340 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:37:34.451: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Sep  6 11:37:34.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-2zwl6'
Sep  6 11:37:34.714: INFO: stderr: ""
Sep  6 11:37:34.714: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 11:37:34.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2zwl6'
Sep  6 11:37:34.826: INFO: stderr: ""
Sep  6 11:37:34.826: INFO: stdout: "update-demo-nautilus-vbwf2 update-demo-nautilus-z6wg5 "
Sep  6 11:37:34.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-vbwf2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2zwl6'
Sep  6 11:37:34.899: INFO: stderr: ""
Sep  6 11:37:34.899: INFO: stdout: ""
Sep  6 11:37:34.899: INFO: update-demo-nautilus-vbwf2 is created but not running
Sep  6 11:37:39.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2zwl6'
Sep  6 11:37:39.995: INFO: stderr: ""
Sep  6 11:37:39.995: INFO: stdout: "update-demo-nautilus-vbwf2 update-demo-nautilus-z6wg5 "
Sep  6 11:37:39.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-vbwf2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2zwl6'
Sep  6 11:37:40.110: INFO: stderr: ""
Sep  6 11:37:40.110: INFO: stdout: "true"
Sep  6 11:37:40.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-vbwf2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2zwl6'
Sep  6 11:37:40.263: INFO: stderr: ""
Sep  6 11:37:40.263: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 11:37:40.263: INFO: validating pod update-demo-nautilus-vbwf2
Sep  6 11:37:40.268: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 11:37:40.268: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 11:37:40.268: INFO: update-demo-nautilus-vbwf2 is verified up and running
Sep  6 11:37:40.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-z6wg5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2zwl6'
Sep  6 11:37:40.355: INFO: stderr: ""
Sep  6 11:37:40.355: INFO: stdout: "true"
Sep  6 11:37:40.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-z6wg5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2zwl6'
Sep  6 11:37:40.438: INFO: stderr: ""
Sep  6 11:37:40.438: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 11:37:40.438: INFO: validating pod update-demo-nautilus-z6wg5
Sep  6 11:37:40.444: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 11:37:40.444: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 11:37:40.444: INFO: update-demo-nautilus-z6wg5 is verified up and running
STEP: using delete to clean up resources
Sep  6 11:37:40.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2zwl6'
Sep  6 11:37:40.561: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 11:37:40.562: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  6 11:37:40.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-2zwl6'
Sep  6 11:37:40.706: INFO: stderr: "No resources found.\n"
Sep  6 11:37:40.706: INFO: stdout: ""
Sep  6 11:37:40.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -l name=update-demo --namespace=e2e-tests-kubectl-2zwl6 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  6 11:37:40.811: INFO: stderr: ""
Sep  6 11:37:40.811: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:37:40.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2zwl6" for this suite.
Sep  6 11:38:02.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:38:02.904: INFO: namespace: e2e-tests-kubectl-2zwl6, resource: bindings, ignored listing per whitelist
Sep  6 11:38:02.948: INFO: namespace e2e-tests-kubectl-2zwl6 deletion completed in 22.133820413s

• [SLOW TEST:28.496 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:38:02.948: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 11:38:03.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-gmhnr'
Sep  6 11:38:03.170: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  6 11:38:03.170: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Sep  6 11:38:05.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-gmhnr'
Sep  6 11:38:05.339: INFO: stderr: ""
Sep  6 11:38:05.339: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:38:05.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gmhnr" for this suite.
Sep  6 11:38:11.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:38:11.435: INFO: namespace: e2e-tests-kubectl-gmhnr, resource: bindings, ignored listing per whitelist
Sep  6 11:38:11.553: INFO: namespace e2e-tests-kubectl-gmhnr deletion completed in 6.204712957s

• [SLOW TEST:8.605 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:38:11.553: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  6 11:38:11.696: INFO: Waiting up to 5m0s for pod "pod-ce565296-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-5j8n2" to be "success or failure"
Sep  6 11:38:11.722: INFO: Pod "pod-ce565296-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 25.708417ms
Sep  6 11:38:13.727: INFO: Pod "pod-ce565296-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030252128s
Sep  6 11:38:15.730: INFO: Pod "pod-ce565296-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03331157s
STEP: Saw pod success
Sep  6 11:38:15.730: INFO: Pod "pod-ce565296-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:38:15.733: INFO: Trying to get logs from node metalk8s-22 pod pod-ce565296-d09a-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 11:38:15.761: INFO: Waiting for pod pod-ce565296-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:38:15.781: INFO: Pod pod-ce565296-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:38:15.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5j8n2" for this suite.
Sep  6 11:38:21.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:38:21.859: INFO: namespace: e2e-tests-emptydir-5j8n2, resource: bindings, ignored listing per whitelist
Sep  6 11:38:21.929: INFO: namespace e2e-tests-emptydir-5j8n2 deletion completed in 6.144032379s

• [SLOW TEST:10.376 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:38:21.929: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 11:38:22.024: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d47fb137-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-42gwb" to be "success or failure"
Sep  6 11:38:22.027: INFO: Pod "downwardapi-volume-d47fb137-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 3.240097ms
Sep  6 11:38:24.030: INFO: Pod "downwardapi-volume-d47fb137-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006519174s
Sep  6 11:38:26.034: INFO: Pod "downwardapi-volume-d47fb137-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01001656s
STEP: Saw pod success
Sep  6 11:38:26.034: INFO: Pod "downwardapi-volume-d47fb137-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:38:26.039: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-d47fb137-d09a-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 11:38:26.060: INFO: Waiting for pod downwardapi-volume-d47fb137-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:38:26.062: INFO: Pod downwardapi-volume-d47fb137-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:38:26.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-42gwb" for this suite.
Sep  6 11:38:32.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:38:32.146: INFO: namespace: e2e-tests-projected-42gwb, resource: bindings, ignored listing per whitelist
Sep  6 11:38:32.213: INFO: namespace e2e-tests-projected-42gwb deletion completed in 6.148862407s

• [SLOW TEST:10.284 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:38:32.214: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Sep  6 11:38:32.297: INFO: Waiting up to 5m0s for pod "client-containers-da9f2b88-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-containers-8ddg6" to be "success or failure"
Sep  6 11:38:32.299: INFO: Pod "client-containers-da9f2b88-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.233984ms
Sep  6 11:38:34.302: INFO: Pod "client-containers-da9f2b88-d09a-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.005373232s
Sep  6 11:38:36.305: INFO: Pod "client-containers-da9f2b88-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008513714s
STEP: Saw pod success
Sep  6 11:38:36.306: INFO: Pod "client-containers-da9f2b88-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:38:36.308: INFO: Trying to get logs from node metalk8s-22 pod client-containers-da9f2b88-d09a-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 11:38:36.326: INFO: Waiting for pod client-containers-da9f2b88-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:38:36.329: INFO: Pod client-containers-da9f2b88-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:38:36.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8ddg6" for this suite.
Sep  6 11:38:42.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:38:42.448: INFO: namespace: e2e-tests-containers-8ddg6, resource: bindings, ignored listing per whitelist
Sep  6 11:38:42.459: INFO: namespace e2e-tests-containers-8ddg6 deletion completed in 6.127940769s

• [SLOW TEST:10.246 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:38:42.460: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Sep  6 11:38:42.540: INFO: Waiting up to 5m0s for pod "pod-e0ba3931-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-xfthz" to be "success or failure"
Sep  6 11:38:42.544: INFO: Pod "pod-e0ba3931-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 3.923742ms
Sep  6 11:38:44.552: INFO: Pod "pod-e0ba3931-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011162478s
STEP: Saw pod success
Sep  6 11:38:44.552: INFO: Pod "pod-e0ba3931-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:38:44.559: INFO: Trying to get logs from node metalk8s-22 pod pod-e0ba3931-d09a-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 11:38:44.641: INFO: Waiting for pod pod-e0ba3931-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:38:44.643: INFO: Pod pod-e0ba3931-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:38:44.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xfthz" for this suite.
Sep  6 11:38:50.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:38:50.750: INFO: namespace: e2e-tests-emptydir-xfthz, resource: bindings, ignored listing per whitelist
Sep  6 11:38:50.779: INFO: namespace e2e-tests-emptydir-xfthz deletion completed in 6.133007014s

• [SLOW TEST:8.320 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:38:50.780: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-e5b016e4-d09a-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 11:38:50.874: INFO: Waiting up to 5m0s for pod "pod-configmaps-e5b130da-d09a-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-configmap-lvn6f" to be "success or failure"
Sep  6 11:38:50.883: INFO: Pod "pod-configmaps-e5b130da-d09a-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 9.255693ms
Sep  6 11:38:52.888: INFO: Pod "pod-configmaps-e5b130da-d09a-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01394133s
STEP: Saw pod success
Sep  6 11:38:52.888: INFO: Pod "pod-configmaps-e5b130da-d09a-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:38:52.891: INFO: Trying to get logs from node metalk8s-22 pod pod-configmaps-e5b130da-d09a-11e9-9cef-86a5da7a2260 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 11:38:52.904: INFO: Waiting for pod pod-configmaps-e5b130da-d09a-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:38:52.907: INFO: Pod pod-configmaps-e5b130da-d09a-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:38:52.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lvn6f" for this suite.
Sep  6 11:38:58.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:38:59.069: INFO: namespace: e2e-tests-configmap-lvn6f, resource: bindings, ignored listing per whitelist
Sep  6 11:38:59.071: INFO: namespace e2e-tests-configmap-lvn6f deletion completed in 6.159370245s

• [SLOW TEST:8.292 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:38:59.073: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Sep  6 11:39:01.192: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-eaa39ba6-d09a-11e9-9cef-86a5da7a2260", GenerateName:"", Namespace:"e2e-tests-pods-fgcq5", SelfLink:"/api/v1/namespaces/e2e-tests-pods-fgcq5/pods/pod-submit-remove-eaa39ba6-d09a-11e9-9cef-86a5da7a2260", UID:"eaa4b16d-d09a-11e9-baa3-fa163efa26fe", ResourceVersion:"3839", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703366739, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"164258211"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.233.217.109/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-td5sr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000a64f80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-td5sr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000df1b68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"metalk8s-22", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000894b40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000df1bb0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000df1bd0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000df1bd8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000df1bdc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703366739, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703366740, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703366740, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703366739, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.0.6", PodIP:"10.233.217.109", StartTime:(*v1.Time)(0xc0015461e0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001546200), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"containerd://212ea18bf81c56e5128405f5444e432aecee37719c50f05981dadb3ab2d9a968"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:39:11.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fgcq5" for this suite.
Sep  6 11:39:17.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:39:17.833: INFO: namespace: e2e-tests-pods-fgcq5, resource: bindings, ignored listing per whitelist
Sep  6 11:39:17.966: INFO: namespace e2e-tests-pods-fgcq5 deletion completed in 6.183902659s

• [SLOW TEST:18.893 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:39:17.966: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-mxt7
STEP: Creating a pod to test atomic-volume-subpath
Sep  6 11:39:18.098: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mxt7" in namespace "e2e-tests-subpath-74kcf" to be "success or failure"
Sep  6 11:39:18.103: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.672739ms
Sep  6 11:39:20.108: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00962254s
Sep  6 11:39:22.122: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Running", Reason="", readiness=false. Elapsed: 4.02365109s
Sep  6 11:39:24.126: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Running", Reason="", readiness=false. Elapsed: 6.027086109s
Sep  6 11:39:26.129: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Running", Reason="", readiness=false. Elapsed: 8.030575673s
Sep  6 11:39:28.133: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Running", Reason="", readiness=false. Elapsed: 10.034168665s
Sep  6 11:39:30.136: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Running", Reason="", readiness=false. Elapsed: 12.037535219s
Sep  6 11:39:32.140: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Running", Reason="", readiness=false. Elapsed: 14.040988055s
Sep  6 11:39:34.144: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Running", Reason="", readiness=false. Elapsed: 16.044913333s
Sep  6 11:39:36.147: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Running", Reason="", readiness=false. Elapsed: 18.048504812s
Sep  6 11:39:38.150: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Running", Reason="", readiness=false. Elapsed: 20.051464485s
Sep  6 11:39:40.156: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Running", Reason="", readiness=false. Elapsed: 22.057308896s
Sep  6 11:39:42.162: INFO: Pod "pod-subpath-test-configmap-mxt7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.063024002s
STEP: Saw pod success
Sep  6 11:39:42.162: INFO: Pod "pod-subpath-test-configmap-mxt7" satisfied condition "success or failure"
Sep  6 11:39:42.164: INFO: Trying to get logs from node metalk8s-22 pod pod-subpath-test-configmap-mxt7 container test-container-subpath-configmap-mxt7: <nil>
STEP: delete the pod
Sep  6 11:39:42.185: INFO: Waiting for pod pod-subpath-test-configmap-mxt7 to disappear
Sep  6 11:39:42.188: INFO: Pod pod-subpath-test-configmap-mxt7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-mxt7
Sep  6 11:39:42.188: INFO: Deleting pod "pod-subpath-test-configmap-mxt7" in namespace "e2e-tests-subpath-74kcf"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:39:42.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-74kcf" for this suite.
Sep  6 11:39:48.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:39:48.333: INFO: namespace: e2e-tests-subpath-74kcf, resource: bindings, ignored listing per whitelist
Sep  6 11:39:48.410: INFO: namespace e2e-tests-subpath-74kcf deletion completed in 6.215955704s

• [SLOW TEST:30.444 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:39:48.410: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:39:52.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-rbxq9" for this suite.
Sep  6 11:39:58.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:39:58.558: INFO: namespace: e2e-tests-kubelet-test-rbxq9, resource: bindings, ignored listing per whitelist
Sep  6 11:39:58.618: INFO: namespace e2e-tests-kubelet-test-rbxq9 deletion completed in 6.112180318s

• [SLOW TEST:10.208 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:39:58.618: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0e1c73fe-d09b-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 11:39:58.695: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0e1d6c68-d09b-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-6bqcf" to be "success or failure"
Sep  6 11:39:58.706: INFO: Pod "pod-projected-configmaps-0e1d6c68-d09b-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 10.442028ms
Sep  6 11:40:00.710: INFO: Pod "pod-projected-configmaps-0e1d6c68-d09b-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.015139482s
Sep  6 11:40:02.715: INFO: Pod "pod-projected-configmaps-0e1d6c68-d09b-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019605639s
STEP: Saw pod success
Sep  6 11:40:02.715: INFO: Pod "pod-projected-configmaps-0e1d6c68-d09b-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:40:02.732: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-configmaps-0e1d6c68-d09b-11e9-9cef-86a5da7a2260 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 11:40:02.763: INFO: Waiting for pod pod-projected-configmaps-0e1d6c68-d09b-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:40:02.784: INFO: Pod pod-projected-configmaps-0e1d6c68-d09b-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:40:02.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6bqcf" for this suite.
Sep  6 11:40:08.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:40:08.811: INFO: namespace: e2e-tests-projected-6bqcf, resource: bindings, ignored listing per whitelist
Sep  6 11:40:08.952: INFO: namespace e2e-tests-projected-6bqcf deletion completed in 6.163953769s

• [SLOW TEST:10.333 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:40:08.952: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rbgzt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  6 11:40:09.037: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  6 11:40:33.102: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.217.114:8080/dial?request=hostName&protocol=udp&host=10.233.217.113&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-rbgzt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:40:33.102: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:40:33.251: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:40:33.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rbgzt" for this suite.
Sep  6 11:40:55.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:40:55.313: INFO: namespace: e2e-tests-pod-network-test-rbgzt, resource: bindings, ignored listing per whitelist
Sep  6 11:40:55.377: INFO: namespace e2e-tests-pod-network-test-rbgzt deletion completed in 22.122431867s

• [SLOW TEST:46.424 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:40:55.377: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 11:40:55.453: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ff2446f-d09b-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-n5zjq" to be "success or failure"
Sep  6 11:40:55.459: INFO: Pod "downwardapi-volume-2ff2446f-d09b-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 5.409792ms
Sep  6 11:40:57.462: INFO: Pod "downwardapi-volume-2ff2446f-d09b-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.008211381s
Sep  6 11:40:59.465: INFO: Pod "downwardapi-volume-2ff2446f-d09b-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011799739s
STEP: Saw pod success
Sep  6 11:40:59.465: INFO: Pod "downwardapi-volume-2ff2446f-d09b-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:40:59.474: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-2ff2446f-d09b-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 11:40:59.494: INFO: Waiting for pod downwardapi-volume-2ff2446f-d09b-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:40:59.499: INFO: Pod downwardapi-volume-2ff2446f-d09b-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:40:59.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n5zjq" for this suite.
Sep  6 11:41:05.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:41:05.620: INFO: namespace: e2e-tests-projected-n5zjq, resource: bindings, ignored listing per whitelist
Sep  6 11:41:05.668: INFO: namespace e2e-tests-projected-n5zjq deletion completed in 6.165415584s

• [SLOW TEST:10.291 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:41:05.669: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 11:41:05.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 version --client'
Sep  6 11:41:05.846: INFO: stderr: ""
Sep  6 11:41:05.846: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Sep  6 11:41:05.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-srnjn'
Sep  6 11:41:06.070: INFO: stderr: ""
Sep  6 11:41:06.070: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep  6 11:41:06.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-srnjn'
Sep  6 11:41:06.269: INFO: stderr: ""
Sep  6 11:41:06.269: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  6 11:41:07.273: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 11:41:07.273: INFO: Found 0 / 1
Sep  6 11:41:08.275: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 11:41:08.275: INFO: Found 0 / 1
Sep  6 11:41:09.274: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 11:41:09.274: INFO: Found 1 / 1
Sep  6 11:41:09.274: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  6 11:41:09.277: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 11:41:09.277: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  6 11:41:09.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 describe pod redis-master-84v27 --namespace=e2e-tests-kubectl-srnjn'
Sep  6 11:41:09.428: INFO: stderr: ""
Sep  6 11:41:09.428: INFO: stdout: "Name:               redis-master-84v27\nNamespace:          e2e-tests-kubectl-srnjn\nPriority:           0\nPriorityClassName:  <none>\nNode:               metalk8s-22/10.10.0.6\nStart Time:         Fri, 06 Sep 2019 11:41:06 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.233.217.116/32\nStatus:             Running\nIP:                 10.233.217.116\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://9840019bfeaf1f11ce0726e7fa0120f7fd28ad74ada88730b787416ad53258ed\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 06 Sep 2019 11:41:08 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-lhnk9 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-lhnk9:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-lhnk9\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                  Message\n  ----    ------     ----  ----                  -------\n  Normal  Scheduled  3s    default-scheduler     Successfully assigned e2e-tests-kubectl-srnjn/redis-master-84v27 to metalk8s-22\n  Normal  Pulling    3s    kubelet, metalk8s-22  pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     1s    kubelet, metalk8s-22  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, metalk8s-22  Created container\n  Normal  Started    1s    kubelet, metalk8s-22  Started container\n"
Sep  6 11:41:09.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 describe rc redis-master --namespace=e2e-tests-kubectl-srnjn'
Sep  6 11:41:09.614: INFO: stderr: ""
Sep  6 11:41:09.614: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-srnjn\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-84v27\n"
Sep  6 11:41:09.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 describe service redis-master --namespace=e2e-tests-kubectl-srnjn'
Sep  6 11:41:09.788: INFO: stderr: ""
Sep  6 11:41:09.789: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-srnjn\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.102.194.194\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.233.217.116:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep  6 11:41:09.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 describe node metalk8s-22'
Sep  6 11:41:09.951: INFO: stderr: ""
Sep  6 11:41:09.951: INFO: stdout: "Name:               metalk8s-22\nRoles:              bootstrap,etcd,infra,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=metalk8s-22\n                    metalk8s.scality.com/version=2.2.0-dev\n                    node-role.kubernetes.io/bootstrap=\n                    node-role.kubernetes.io/etcd=\n                    node-role.kubernetes.io/infra=\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.20.0.31/16\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.233.217.64\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 06 Sep 2019 11:15:45 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 06 Sep 2019 11:16:19 +0000   Fri, 06 Sep 2019 11:16:19 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Fri, 06 Sep 2019 11:41:00 +0000   Fri, 06 Sep 2019 11:15:37 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 06 Sep 2019 11:41:00 +0000   Fri, 06 Sep 2019 11:15:37 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 06 Sep 2019 11:41:00 +0000   Fri, 06 Sep 2019 11:15:37 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 06 Sep 2019 11:41:00 +0000   Fri, 06 Sep 2019 11:15:37 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.10.0.6\n  Hostname:    metalk8s-22\nCapacity:\n cpu:                8\n ephemeral-storage:  41931756Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16266524Ki\n pods:               110\nAllocatable:\n cpu:                8\n ephemeral-storage:  38644306266\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16164124Ki\n pods:               110\nSystem Info:\n Machine ID:                 b30d0f2110ac3807b210c19ede3ce88f\n System UUID:                31F76EE4-8912-4F03-B876-A2DE5C54528B\n Boot ID:                    df78b683-5f72-41c0-9a46-1f9a36e74e6b\n Kernel Version:             3.10.0-862.3.2.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.4\n Kubelet Version:            v1.13.10\n Kube-Proxy Version:         v1.13.10\nPodCIDR:                     10.233.0.0/24\nNon-terminated Pods:         (27 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-srnjn    redis-master-84v27                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         8m39s\n  heptio-sonobuoy            sonobuoy-e2e-job-686830808f80405c                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         8m33s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-1a98abcdad7f4913-gsb5x    0 (0%)        0 (0%)      0 (0%)           0 (0%)         8m33s\n  kube-system                calico-kube-controllers-5fb4b978ff-hj8s4                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         24m\n  kube-system                calico-node-qnjrt                                          250m (3%)     0 (0%)      0 (0%)           0 (0%)         24m\n  kube-system                coredns-75d9fb9567-jc986                                   100m (1%)     0 (0%)      70Mi (0%)        170Mi (1%)     24m\n  kube-system                coredns-75d9fb9567-ttgdv                                   100m (1%)     0 (0%)      70Mi (0%)        170Mi (1%)     24m\n  kube-system                etcd-metalk8s-22                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         24m\n  kube-system                kube-apiserver-metalk8s-22                                 250m (3%)     0 (0%)      0 (0%)           0 (0%)         24m\n  kube-system                kube-controller-manager-metalk8s-22                        200m (2%)     0 (0%)      0 (0%)           0 (0%)         24m\n  kube-system                kube-proxy-7cpsq                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         25m\n  kube-system                kube-scheduler-metalk8s-22                                 100m (1%)     0 (0%)      0 (0%)           0 (0%)         24m\n  kube-system                repositories-metalk8s-22                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         24m\n  kube-system                salt-master-metalk8s-22                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         24m\n  metalk8s-ingress           nginx-ingress-controller-v46nl                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         24m\n  metalk8s-ingress           nginx-ingress-default-backend-6d7c5f49bd-tn6dj             0 (0%)        0 (0%)      0 (0%)           0 (0%)         24m\n  metalk8s-monitoring        alertmanager-main-0                                        50m (0%)      50m (0%)    210Mi (1%)       10Mi (0%)      24m\n  metalk8s-monitoring        alertmanager-main-1                                        50m (0%)      50m (0%)    210Mi (1%)       10Mi (0%)      24m\n  metalk8s-monitoring        alertmanager-main-2                                        50m (0%)      50m (0%)    210Mi (1%)       10Mi (0%)      24m\n  metalk8s-monitoring        grafana-5c9b84b94f-qrc6b                                   100m (1%)     200m (2%)   100Mi (0%)       200Mi (1%)     24m\n  metalk8s-monitoring        kube-state-metrics-86b8b5b6cd-wkhwt                        130m (1%)     190m (2%)   220Mi (1%)       260Mi (1%)     24m\n  metalk8s-monitoring        node-exporter-pvl9b                                        112m (1%)     270m (3%)   200Mi (1%)       220Mi (1%)     24m\n  metalk8s-monitoring        prometheus-adapter-9cfc8ff6d-swmpn                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         24m\n  metalk8s-monitoring        prometheus-k8s-0                                           75m (0%)      75m (0%)    460Mi (2%)       60Mi (0%)      24m\n  metalk8s-monitoring        prometheus-k8s-1                                           75m (0%)      75m (0%)    460Mi (2%)       60Mi (0%)      24m\n  metalk8s-monitoring        prometheus-operator-5f67d45986-pvgjz                       100m (1%)     200m (2%)   100Mi (0%)       200Mi (1%)     24m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests      Limits\n  --------           --------      ------\n  cpu                1742m (21%)   1160m (14%)\n  memory             2310Mi (14%)  1370Mi (8%)\n  ephemeral-storage  0 (0%)        0 (0%)\nEvents:\n  Type     Reason                   Age                From                     Message\n  ----     ------                   ----               ----                     -------\n  Normal   Starting                 26m                kubelet, metalk8s-22     Starting kubelet.\n  Warning  InvalidDiskCapacity      26m                kubelet, metalk8s-22     invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  26m (x8 over 26m)  kubelet, metalk8s-22     Node metalk8s-22 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    26m (x7 over 26m)  kubelet, metalk8s-22     Node metalk8s-22 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     26m (x7 over 26m)  kubelet, metalk8s-22     Node metalk8s-22 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  26m                kubelet, metalk8s-22     Updated Node Allocatable limit across pods\n  Normal   Starting                 25m                kube-proxy, metalk8s-22  Starting kube-proxy.\n"
Sep  6 11:41:09.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 describe namespace e2e-tests-kubectl-srnjn'
Sep  6 11:41:10.125: INFO: stderr: ""
Sep  6 11:41:10.125: INFO: stdout: "Name:         e2e-tests-kubectl-srnjn\nLabels:       e2e-framework=kubectl\n              e2e-run=163fbf4b-d09a-11e9-9cef-86a5da7a2260\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:41:10.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-srnjn" for this suite.
Sep  6 11:41:32.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:41:32.182: INFO: namespace: e2e-tests-kubectl-srnjn, resource: bindings, ignored listing per whitelist
Sep  6 11:41:32.240: INFO: namespace e2e-tests-kubectl-srnjn deletion completed in 22.111279458s

• [SLOW TEST:26.571 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:41:32.240: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep  6 11:41:32.319: INFO: Pod name pod-release: Found 0 pods out of 1
Sep  6 11:41:37.323: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:41:37.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-snvb2" for this suite.
Sep  6 11:41:43.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:41:43.452: INFO: namespace: e2e-tests-replication-controller-snvb2, resource: bindings, ignored listing per whitelist
Sep  6 11:41:43.582: INFO: namespace e2e-tests-replication-controller-snvb2 deletion completed in 6.215643359s

• [SLOW TEST:11.342 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:41:43.582: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  6 11:41:43.717: INFO: Waiting up to 5m0s for pod "pod-4cb6c513-d09b-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-b4qfz" to be "success or failure"
Sep  6 11:41:43.722: INFO: Pod "pod-4cb6c513-d09b-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 4.649516ms
Sep  6 11:41:45.726: INFO: Pod "pod-4cb6c513-d09b-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008491326s
Sep  6 11:41:47.730: INFO: Pod "pod-4cb6c513-d09b-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013395275s
STEP: Saw pod success
Sep  6 11:41:47.731: INFO: Pod "pod-4cb6c513-d09b-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:41:47.733: INFO: Trying to get logs from node metalk8s-22 pod pod-4cb6c513-d09b-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 11:41:47.756: INFO: Waiting for pod pod-4cb6c513-d09b-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:41:47.762: INFO: Pod pod-4cb6c513-d09b-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:41:47.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b4qfz" for this suite.
Sep  6 11:41:53.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:41:53.792: INFO: namespace: e2e-tests-emptydir-b4qfz, resource: bindings, ignored listing per whitelist
Sep  6 11:41:53.923: INFO: namespace e2e-tests-emptydir-b4qfz deletion completed in 6.157542238s

• [SLOW TEST:10.341 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:41:53.924: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-52dc5be3-d09b-11e9-9cef-86a5da7a2260
STEP: Creating configMap with name cm-test-opt-upd-52dc5c34-d09b-11e9-9cef-86a5da7a2260
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-52dc5be3-d09b-11e9-9cef-86a5da7a2260
STEP: Updating configmap cm-test-opt-upd-52dc5c34-d09b-11e9-9cef-86a5da7a2260
STEP: Creating configMap with name cm-test-opt-create-52dc5c53-d09b-11e9-9cef-86a5da7a2260
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:43:02.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pqlwb" for this suite.
Sep  6 11:43:24.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:43:24.598: INFO: namespace: e2e-tests-configmap-pqlwb, resource: bindings, ignored listing per whitelist
Sep  6 11:43:24.609: INFO: namespace e2e-tests-configmap-pqlwb deletion completed in 22.192058871s

• [SLOW TEST:90.685 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:43:24.609: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0906 11:43:30.824156      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 11:43:30.824: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:43:30.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xrvmw" for this suite.
Sep  6 11:43:36.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:43:36.871: INFO: namespace: e2e-tests-gc-xrvmw, resource: bindings, ignored listing per whitelist
Sep  6 11:43:36.953: INFO: namespace e2e-tests-gc-xrvmw deletion completed in 6.122413272s

• [SLOW TEST:12.344 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:43:36.954: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  6 11:43:37.026: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:43:40.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-ftw5r" for this suite.
Sep  6 11:44:04.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:44:04.645: INFO: namespace: e2e-tests-init-container-ftw5r, resource: bindings, ignored listing per whitelist
Sep  6 11:44:04.702: INFO: namespace e2e-tests-init-container-ftw5r deletion completed in 24.101599183s

• [SLOW TEST:27.748 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:44:04.702: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-a0ca8704-d09b-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 11:44:04.777: INFO: Waiting up to 5m0s for pod "pod-secrets-a0cb1b94-d09b-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-secrets-5btjz" to be "success or failure"
Sep  6 11:44:04.796: INFO: Pod "pod-secrets-a0cb1b94-d09b-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 19.027663ms
Sep  6 11:44:06.801: INFO: Pod "pod-secrets-a0cb1b94-d09b-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024040382s
STEP: Saw pod success
Sep  6 11:44:06.801: INFO: Pod "pod-secrets-a0cb1b94-d09b-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:44:06.803: INFO: Trying to get logs from node metalk8s-22 pod pod-secrets-a0cb1b94-d09b-11e9-9cef-86a5da7a2260 container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 11:44:06.822: INFO: Waiting for pod pod-secrets-a0cb1b94-d09b-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:44:06.825: INFO: Pod pod-secrets-a0cb1b94-d09b-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:44:06.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5btjz" for this suite.
Sep  6 11:44:12.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:44:12.903: INFO: namespace: e2e-tests-secrets-5btjz, resource: bindings, ignored listing per whitelist
Sep  6 11:44:13.016: INFO: namespace e2e-tests-secrets-5btjz deletion completed in 6.188208281s

• [SLOW TEST:8.314 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:44:13.017: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  6 11:44:15.677: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a5c298b0-d09b-11e9-9cef-86a5da7a2260"
Sep  6 11:44:15.677: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a5c298b0-d09b-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-pods-br7p8" to be "terminated due to deadline exceeded"
Sep  6 11:44:15.682: INFO: Pod "pod-update-activedeadlineseconds-a5c298b0-d09b-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 5.632344ms
Sep  6 11:44:17.686: INFO: Pod "pod-update-activedeadlineseconds-a5c298b0-d09b-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.009098181s
Sep  6 11:44:19.689: INFO: Pod "pod-update-activedeadlineseconds-a5c298b0-d09b-11e9-9cef-86a5da7a2260": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.012307356s
Sep  6 11:44:19.689: INFO: Pod "pod-update-activedeadlineseconds-a5c298b0-d09b-11e9-9cef-86a5da7a2260" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:44:19.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-br7p8" for this suite.
Sep  6 11:44:25.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:44:25.801: INFO: namespace: e2e-tests-pods-br7p8, resource: bindings, ignored listing per whitelist
Sep  6 11:44:25.829: INFO: namespace e2e-tests-pods-br7p8 deletion completed in 6.137335354s

• [SLOW TEST:12.812 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:44:25.829: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  6 11:44:25.929: INFO: Waiting up to 5m0s for pod "pod-ad64d288-d09b-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-lckm2" to be "success or failure"
Sep  6 11:44:25.954: INFO: Pod "pod-ad64d288-d09b-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 25.547986ms
Sep  6 11:44:27.959: INFO: Pod "pod-ad64d288-d09b-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030342328s
STEP: Saw pod success
Sep  6 11:44:27.959: INFO: Pod "pod-ad64d288-d09b-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:44:27.962: INFO: Trying to get logs from node metalk8s-22 pod pod-ad64d288-d09b-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 11:44:27.989: INFO: Waiting for pod pod-ad64d288-d09b-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:44:27.993: INFO: Pod pod-ad64d288-d09b-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:44:27.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lckm2" for this suite.
Sep  6 11:44:34.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:44:34.042: INFO: namespace: e2e-tests-emptydir-lckm2, resource: bindings, ignored listing per whitelist
Sep  6 11:44:34.134: INFO: namespace e2e-tests-emptydir-lckm2 deletion completed in 6.131758655s

• [SLOW TEST:8.305 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:44:34.134: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-b25f3267-d09b-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 11:44:34.288: INFO: Waiting up to 5m0s for pod "pod-configmaps-b260d8a0-d09b-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-configmap-txh2f" to be "success or failure"
Sep  6 11:44:34.298: INFO: Pod "pod-configmaps-b260d8a0-d09b-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 9.909668ms
Sep  6 11:44:36.303: INFO: Pod "pod-configmaps-b260d8a0-d09b-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014462596s
STEP: Saw pod success
Sep  6 11:44:36.303: INFO: Pod "pod-configmaps-b260d8a0-d09b-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:44:36.307: INFO: Trying to get logs from node metalk8s-22 pod pod-configmaps-b260d8a0-d09b-11e9-9cef-86a5da7a2260 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 11:44:36.361: INFO: Waiting for pod pod-configmaps-b260d8a0-d09b-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:44:36.380: INFO: Pod pod-configmaps-b260d8a0-d09b-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:44:36.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-txh2f" for this suite.
Sep  6 11:44:42.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:44:42.439: INFO: namespace: e2e-tests-configmap-txh2f, resource: bindings, ignored listing per whitelist
Sep  6 11:44:42.549: INFO: namespace e2e-tests-configmap-txh2f deletion completed in 6.155161061s

• [SLOW TEST:8.414 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:44:42.549: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:44:44.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-5f6l7" for this suite.
Sep  6 11:45:36.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:45:36.767: INFO: namespace: e2e-tests-kubelet-test-5f6l7, resource: bindings, ignored listing per whitelist
Sep  6 11:45:36.843: INFO: namespace e2e-tests-kubelet-test-5f6l7 deletion completed in 52.150352117s

• [SLOW TEST:54.294 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:45:36.843: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-gm46t
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-gm46t to expose endpoints map[]
Sep  6 11:45:36.935: INFO: Get endpoints failed (4.348943ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Sep  6 11:45:37.939: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-gm46t exposes endpoints map[] (1.007909731s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-gm46t
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-gm46t to expose endpoints map[pod1:[80]]
Sep  6 11:45:39.970: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-gm46t exposes endpoints map[pod1:[80]] (2.021724297s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-gm46t
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-gm46t to expose endpoints map[pod1:[80] pod2:[80]]
Sep  6 11:45:42.008: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-gm46t exposes endpoints map[pod1:[80] pod2:[80]] (2.028350916s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-gm46t
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-gm46t to expose endpoints map[pod2:[80]]
Sep  6 11:45:42.030: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-gm46t exposes endpoints map[pod2:[80]] (17.350358ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-gm46t
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-gm46t to expose endpoints map[]
Sep  6 11:45:43.054: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-gm46t exposes endpoints map[] (1.011844799s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:45:43.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-gm46t" for this suite.
Sep  6 11:46:05.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:46:05.218: INFO: namespace: e2e-tests-services-gm46t, resource: bindings, ignored listing per whitelist
Sep  6 11:46:05.281: INFO: namespace e2e-tests-services-gm46t deletion completed in 22.187459912s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.439 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:46:05.282: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  6 11:46:09.899: INFO: Successfully updated pod "pod-update-e8ac1b86-d09b-11e9-9cef-86a5da7a2260"
STEP: verifying the updated pod is in kubernetes
Sep  6 11:46:09.912: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:46:09.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kknwj" for this suite.
Sep  6 11:46:31.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:46:31.963: INFO: namespace: e2e-tests-pods-kknwj, resource: bindings, ignored listing per whitelist
Sep  6 11:46:32.046: INFO: namespace e2e-tests-pods-kknwj deletion completed in 22.131311824s

• [SLOW TEST:26.764 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:46:32.046: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep  6 11:46:32.172: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wl44t,SelfLink:/api/v1/namespaces/e2e-tests-watch-wl44t/configmaps/e2e-watch-test-resource-version,UID:f8a1a7b9-d09b-11e9-baa3-fa163efa26fe,ResourceVersion:5439,Generation:0,CreationTimestamp:2019-09-06 11:46:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  6 11:46:32.172: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wl44t,SelfLink:/api/v1/namespaces/e2e-tests-watch-wl44t/configmaps/e2e-watch-test-resource-version,UID:f8a1a7b9-d09b-11e9-baa3-fa163efa26fe,ResourceVersion:5440,Generation:0,CreationTimestamp:2019-09-06 11:46:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:46:32.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wl44t" for this suite.
Sep  6 11:46:38.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:46:38.218: INFO: namespace: e2e-tests-watch-wl44t, resource: bindings, ignored listing per whitelist
Sep  6 11:46:38.299: INFO: namespace e2e-tests-watch-wl44t deletion completed in 6.119406399s

• [SLOW TEST:6.252 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:46:38.299: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 11:46:38.373: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc584ab3-d09b-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-5jn4f" to be "success or failure"
Sep  6 11:46:38.403: INFO: Pod "downwardapi-volume-fc584ab3-d09b-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 29.845659ms
Sep  6 11:46:40.406: INFO: Pod "downwardapi-volume-fc584ab3-d09b-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.032933742s
Sep  6 11:46:42.411: INFO: Pod "downwardapi-volume-fc584ab3-d09b-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038589247s
STEP: Saw pod success
Sep  6 11:46:42.412: INFO: Pod "downwardapi-volume-fc584ab3-d09b-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:46:42.414: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-fc584ab3-d09b-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 11:46:42.441: INFO: Waiting for pod downwardapi-volume-fc584ab3-d09b-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:46:42.459: INFO: Pod downwardapi-volume-fc584ab3-d09b-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:46:42.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5jn4f" for this suite.
Sep  6 11:46:48.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:46:48.561: INFO: namespace: e2e-tests-downward-api-5jn4f, resource: bindings, ignored listing per whitelist
Sep  6 11:46:48.582: INFO: namespace e2e-tests-downward-api-5jn4f deletion completed in 6.115649283s

• [SLOW TEST:10.283 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:46:48.582: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  6 11:46:48.638: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  6 11:46:48.642: INFO: Waiting for terminating namespaces to be deleted...
Sep  6 11:46:48.643: INFO: 
Logging pods the kubelet thinks is on node metalk8s-22 before test
Sep  6 11:46:48.653: INFO: kube-state-metrics-86b8b5b6cd-wkhwt from metalk8s-monitoring started at 2019-09-06 11:16:38 +0000 UTC (4 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container addon-resizer ready: true, restart count 0
Sep  6 11:46:48.653: INFO: 	Container kube-rbac-proxy-main ready: true, restart count 0
Sep  6 11:46:48.653: INFO: 	Container kube-rbac-proxy-self ready: true, restart count 0
Sep  6 11:46:48.653: INFO: 	Container kube-state-metrics ready: true, restart count 0
Sep  6 11:46:48.653: INFO: etcd-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:46:48.653: INFO: repositories-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:46:48.653: INFO: kube-scheduler-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:46:48.653: INFO: calico-node-qnjrt from kube-system started at 2019-09-06 11:16:12 +0000 UTC (1 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container calico-node ready: true, restart count 0
Sep  6 11:46:48.653: INFO: coredns-75d9fb9567-jc986 from kube-system started at 2019-09-06 11:16:15 +0000 UTC (1 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container coredns ready: true, restart count 0
Sep  6 11:46:48.653: INFO: prometheus-k8s-0 from metalk8s-monitoring started at 2019-09-06 11:16:45 +0000 UTC (3 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container prometheus ready: true, restart count 1
Sep  6 11:46:48.653: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Sep  6 11:46:48.653: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Sep  6 11:46:48.653: INFO: nginx-ingress-default-backend-6d7c5f49bd-tn6dj from metalk8s-ingress started at 2019-09-06 11:16:50 +0000 UTC (1 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Sep  6 11:46:48.653: INFO: alertmanager-main-2 from metalk8s-monitoring started at 2019-09-06 11:16:56 +0000 UTC (2 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container alertmanager ready: true, restart count 0
Sep  6 11:46:48.653: INFO: 	Container config-reloader ready: true, restart count 0
Sep  6 11:46:48.653: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-06 11:32:30 +0000 UTC (1 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  6 11:46:48.653: INFO: kube-apiserver-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:46:48.653: INFO: coredns-75d9fb9567-ttgdv from kube-system started at 2019-09-06 11:16:15 +0000 UTC (1 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container coredns ready: true, restart count 0
Sep  6 11:46:48.653: INFO: prometheus-k8s-1 from metalk8s-monitoring started at 2019-09-06 11:16:45 +0000 UTC (3 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container prometheus ready: true, restart count 1
Sep  6 11:46:48.653: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Sep  6 11:46:48.653: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Sep  6 11:46:48.653: INFO: nginx-ingress-controller-v46nl from metalk8s-ingress started at 2019-09-06 11:16:49 +0000 UTC (1 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  6 11:46:48.653: INFO: sonobuoy-e2e-job-686830808f80405c from heptio-sonobuoy started at 2019-09-06 11:32:36 +0000 UTC (2 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container e2e ready: true, restart count 0
Sep  6 11:46:48.653: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 11:46:48.653: INFO: kube-controller-manager-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:46:48.653: INFO: kube-proxy-7cpsq from kube-system started at 2019-09-06 11:16:04 +0000 UTC (1 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  6 11:46:48.653: INFO: prometheus-adapter-9cfc8ff6d-swmpn from metalk8s-monitoring started at 2019-09-06 11:16:31 +0000 UTC (1 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container prometheus-adapter ready: true, restart count 0
Sep  6 11:46:48.653: INFO: salt-master-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:46:48.653: INFO: prometheus-operator-5f67d45986-pvgjz from metalk8s-monitoring started at 2019-09-06 11:16:18 +0000 UTC (1 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container prometheus-operator ready: true, restart count 0
Sep  6 11:46:48.653: INFO: sonobuoy-systemd-logs-daemon-set-1a98abcdad7f4913-gsb5x from heptio-sonobuoy started at 2019-09-06 11:32:36 +0000 UTC (2 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 11:46:48.653: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  6 11:46:48.653: INFO: calico-kube-controllers-5fb4b978ff-hj8s4 from kube-system started at 2019-09-06 11:16:12 +0000 UTC (1 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep  6 11:46:48.653: INFO: alertmanager-main-0 from metalk8s-monitoring started at 2019-09-06 11:16:38 +0000 UTC (2 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container alertmanager ready: true, restart count 0
Sep  6 11:46:48.653: INFO: 	Container config-reloader ready: true, restart count 0
Sep  6 11:46:48.653: INFO: node-exporter-pvl9b from metalk8s-monitoring started at 2019-09-06 11:16:40 +0000 UTC (2 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Sep  6 11:46:48.653: INFO: 	Container node-exporter ready: true, restart count 0
Sep  6 11:46:48.653: INFO: grafana-5c9b84b94f-qrc6b from metalk8s-monitoring started at 2019-09-06 11:16:46 +0000 UTC (1 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container grafana ready: true, restart count 0
Sep  6 11:46:48.653: INFO: alertmanager-main-1 from metalk8s-monitoring started at 2019-09-06 11:16:50 +0000 UTC (2 container statuses recorded)
Sep  6 11:46:48.653: INFO: 	Container alertmanager ready: true, restart count 0
Sep  6 11:46:48.653: INFO: 	Container config-reloader ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod sonobuoy requesting resource cpu=0m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod sonobuoy-e2e-job-686830808f80405c requesting resource cpu=0m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod sonobuoy-systemd-logs-daemon-set-1a98abcdad7f4913-gsb5x requesting resource cpu=0m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod calico-kube-controllers-5fb4b978ff-hj8s4 requesting resource cpu=0m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod calico-node-qnjrt requesting resource cpu=250m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod coredns-75d9fb9567-jc986 requesting resource cpu=100m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod coredns-75d9fb9567-ttgdv requesting resource cpu=100m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod etcd-metalk8s-22 requesting resource cpu=0m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod kube-apiserver-metalk8s-22 requesting resource cpu=250m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod kube-controller-manager-metalk8s-22 requesting resource cpu=200m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod kube-proxy-7cpsq requesting resource cpu=0m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod kube-scheduler-metalk8s-22 requesting resource cpu=100m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod repositories-metalk8s-22 requesting resource cpu=0m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod salt-master-metalk8s-22 requesting resource cpu=0m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod nginx-ingress-controller-v46nl requesting resource cpu=0m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod nginx-ingress-default-backend-6d7c5f49bd-tn6dj requesting resource cpu=0m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod alertmanager-main-0 requesting resource cpu=50m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod alertmanager-main-1 requesting resource cpu=50m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod alertmanager-main-2 requesting resource cpu=50m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod grafana-5c9b84b94f-qrc6b requesting resource cpu=100m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod kube-state-metrics-86b8b5b6cd-wkhwt requesting resource cpu=130m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod node-exporter-pvl9b requesting resource cpu=112m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod prometheus-adapter-9cfc8ff6d-swmpn requesting resource cpu=0m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod prometheus-k8s-0 requesting resource cpu=75m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod prometheus-k8s-1 requesting resource cpu=75m on Node metalk8s-22
Sep  6 11:46:48.680: INFO: Pod prometheus-operator-5f67d45986-pvgjz requesting resource cpu=100m on Node metalk8s-22
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-027e2b8f-d09c-11e9-9cef-86a5da7a2260.15c1d6e15b5cad67], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-gcnbf/filler-pod-027e2b8f-d09c-11e9-9cef-86a5da7a2260 to metalk8s-22]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-027e2b8f-d09c-11e9-9cef-86a5da7a2260.15c1d6e18abd52a4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-027e2b8f-d09c-11e9-9cef-86a5da7a2260.15c1d6e18d70a430], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-027e2b8f-d09c-11e9-9cef-86a5da7a2260.15c1d6e1990733da], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c1d6e24b76c369], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
STEP: removing the label node off the node metalk8s-22
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:46:53.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-gcnbf" for this suite.
Sep  6 11:46:59.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:46:59.819: INFO: namespace: e2e-tests-sched-pred-gcnbf, resource: bindings, ignored listing per whitelist
Sep  6 11:46:59.943: INFO: namespace e2e-tests-sched-pred-gcnbf deletion completed in 6.191333085s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.360 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:46:59.943: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 11:47:00.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-7s7wx'
Sep  6 11:47:00.384: INFO: stderr: ""
Sep  6 11:47:00.384: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Sep  6 11:47:00.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7s7wx'
Sep  6 11:47:02.805: INFO: stderr: ""
Sep  6 11:47:02.805: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:47:02.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7s7wx" for this suite.
Sep  6 11:47:08.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:47:08.916: INFO: namespace: e2e-tests-kubectl-7s7wx, resource: bindings, ignored listing per whitelist
Sep  6 11:47:08.925: INFO: namespace e2e-tests-kubectl-7s7wx deletion completed in 6.115758896s

• [SLOW TEST:8.982 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:47:08.925: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ndhfp
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  6 11:47:08.986: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  6 11:47:25.054: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.217.96:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ndhfp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:47:25.054: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:47:25.291: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:47:25.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ndhfp" for this suite.
Sep  6 11:47:47.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:47:47.385: INFO: namespace: e2e-tests-pod-network-test-ndhfp, resource: bindings, ignored listing per whitelist
Sep  6 11:47:47.452: INFO: namespace e2e-tests-pod-network-test-ndhfp deletion completed in 22.152981072s

• [SLOW TEST:38.527 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:47:47.452: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  6 11:47:47.576: INFO: Waiting up to 5m0s for pod "pod-2597b1c8-d09c-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-6q42q" to be "success or failure"
Sep  6 11:47:47.587: INFO: Pod "pod-2597b1c8-d09c-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 11.757297ms
Sep  6 11:47:49.592: INFO: Pod "pod-2597b1c8-d09c-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016310302s
STEP: Saw pod success
Sep  6 11:47:49.592: INFO: Pod "pod-2597b1c8-d09c-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:47:49.594: INFO: Trying to get logs from node metalk8s-22 pod pod-2597b1c8-d09c-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 11:47:49.623: INFO: Waiting for pod pod-2597b1c8-d09c-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:47:49.627: INFO: Pod pod-2597b1c8-d09c-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:47:49.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6q42q" for this suite.
Sep  6 11:47:55.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:47:55.746: INFO: namespace: e2e-tests-emptydir-6q42q, resource: bindings, ignored listing per whitelist
Sep  6 11:47:55.779: INFO: namespace e2e-tests-emptydir-6q42q deletion completed in 6.13700513s

• [SLOW TEST:8.327 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:47:55.779: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 11:47:55.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-n7sfw'
Sep  6 11:47:56.085: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  6 11:47:56.085: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Sep  6 11:47:56.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-n7sfw'
Sep  6 11:47:56.232: INFO: stderr: ""
Sep  6 11:47:56.232: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:47:56.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n7sfw" for this suite.
Sep  6 11:48:02.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:48:02.278: INFO: namespace: e2e-tests-kubectl-n7sfw, resource: bindings, ignored listing per whitelist
Sep  6 11:48:02.378: INFO: namespace e2e-tests-kubectl-n7sfw deletion completed in 6.138474786s

• [SLOW TEST:6.598 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:48:02.378: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep  6 11:48:08.544: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gpvlt PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:48:08.544: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:48:08.789: INFO: Exec stderr: ""
Sep  6 11:48:08.790: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gpvlt PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:48:08.790: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:48:09.040: INFO: Exec stderr: ""
Sep  6 11:48:09.040: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gpvlt PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:48:09.040: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:48:09.310: INFO: Exec stderr: ""
Sep  6 11:48:09.310: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gpvlt PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:48:09.310: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:48:09.563: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep  6 11:48:09.563: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gpvlt PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:48:09.563: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:48:09.804: INFO: Exec stderr: ""
Sep  6 11:48:09.804: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gpvlt PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:48:09.804: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:48:10.055: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep  6 11:48:10.055: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gpvlt PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:48:10.055: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:48:10.372: INFO: Exec stderr: ""
Sep  6 11:48:10.372: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gpvlt PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:48:10.372: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:48:10.617: INFO: Exec stderr: ""
Sep  6 11:48:10.617: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gpvlt PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:48:10.617: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:48:10.855: INFO: Exec stderr: ""
Sep  6 11:48:10.855: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gpvlt PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 11:48:10.855: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 11:48:11.311: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:48:11.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-gpvlt" for this suite.
Sep  6 11:48:53.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:48:53.424: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-gpvlt, resource: bindings, ignored listing per whitelist
Sep  6 11:48:53.429: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-gpvlt deletion completed in 42.112693362s

• [SLOW TEST:51.051 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:48:53.429: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 11:48:53.507: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ce471e2-d09c-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-fmggx" to be "success or failure"
Sep  6 11:48:53.509: INFO: Pod "downwardapi-volume-4ce471e2-d09c-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104858ms
Sep  6 11:48:55.512: INFO: Pod "downwardapi-volume-4ce471e2-d09c-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005038538s
STEP: Saw pod success
Sep  6 11:48:55.512: INFO: Pod "downwardapi-volume-4ce471e2-d09c-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:48:55.515: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-4ce471e2-d09c-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 11:48:55.532: INFO: Waiting for pod downwardapi-volume-4ce471e2-d09c-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:48:55.536: INFO: Pod downwardapi-volume-4ce471e2-d09c-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:48:55.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fmggx" for this suite.
Sep  6 11:49:01.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:49:01.634: INFO: namespace: e2e-tests-downward-api-fmggx, resource: bindings, ignored listing per whitelist
Sep  6 11:49:01.697: INFO: namespace e2e-tests-downward-api-fmggx deletion completed in 6.158152714s

• [SLOW TEST:8.268 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:49:01.697: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-xzx4
STEP: Creating a pod to test atomic-volume-subpath
Sep  6 11:49:01.808: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-xzx4" in namespace "e2e-tests-subpath-fhwvw" to be "success or failure"
Sep  6 11:49:01.825: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.413895ms
Sep  6 11:49:03.829: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020455507s
Sep  6 11:49:05.835: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Running", Reason="", readiness=false. Elapsed: 4.026319624s
Sep  6 11:49:07.838: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Running", Reason="", readiness=false. Elapsed: 6.0293861s
Sep  6 11:49:09.845: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Running", Reason="", readiness=false. Elapsed: 8.036359278s
Sep  6 11:49:11.849: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Running", Reason="", readiness=false. Elapsed: 10.040389016s
Sep  6 11:49:13.852: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Running", Reason="", readiness=false. Elapsed: 12.043590434s
Sep  6 11:49:15.855: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Running", Reason="", readiness=false. Elapsed: 14.046343558s
Sep  6 11:49:17.858: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Running", Reason="", readiness=false. Elapsed: 16.049555934s
Sep  6 11:49:19.861: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Running", Reason="", readiness=false. Elapsed: 18.052938715s
Sep  6 11:49:21.865: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Running", Reason="", readiness=false. Elapsed: 20.056118697s
Sep  6 11:49:23.868: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Running", Reason="", readiness=false. Elapsed: 22.059270358s
Sep  6 11:49:25.872: INFO: Pod "pod-subpath-test-downwardapi-xzx4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.063265751s
STEP: Saw pod success
Sep  6 11:49:25.872: INFO: Pod "pod-subpath-test-downwardapi-xzx4" satisfied condition "success or failure"
Sep  6 11:49:25.877: INFO: Trying to get logs from node metalk8s-22 pod pod-subpath-test-downwardapi-xzx4 container test-container-subpath-downwardapi-xzx4: <nil>
STEP: delete the pod
Sep  6 11:49:25.896: INFO: Waiting for pod pod-subpath-test-downwardapi-xzx4 to disappear
Sep  6 11:49:25.902: INFO: Pod pod-subpath-test-downwardapi-xzx4 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-xzx4
Sep  6 11:49:25.902: INFO: Deleting pod "pod-subpath-test-downwardapi-xzx4" in namespace "e2e-tests-subpath-fhwvw"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:49:25.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-fhwvw" for this suite.
Sep  6 11:49:31.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:49:31.983: INFO: namespace: e2e-tests-subpath-fhwvw, resource: bindings, ignored listing per whitelist
Sep  6 11:49:32.026: INFO: namespace e2e-tests-subpath-fhwvw deletion completed in 6.116709424s

• [SLOW TEST:30.329 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:49:32.026: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-63e8ed4e-d09c-11e9-9cef-86a5da7a2260
STEP: Creating secret with name secret-projected-all-test-volume-63e8ed34-d09c-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep  6 11:49:32.136: INFO: Waiting up to 5m0s for pod "projected-volume-63e8ece5-d09c-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-dztgh" to be "success or failure"
Sep  6 11:49:32.140: INFO: Pod "projected-volume-63e8ece5-d09c-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 3.642563ms
Sep  6 11:49:34.143: INFO: Pod "projected-volume-63e8ece5-d09c-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007265499s
STEP: Saw pod success
Sep  6 11:49:34.144: INFO: Pod "projected-volume-63e8ece5-d09c-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:49:34.147: INFO: Trying to get logs from node metalk8s-22 pod projected-volume-63e8ece5-d09c-11e9-9cef-86a5da7a2260 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep  6 11:49:34.188: INFO: Waiting for pod projected-volume-63e8ece5-d09c-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:49:34.201: INFO: Pod projected-volume-63e8ece5-d09c-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:49:34.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dztgh" for this suite.
Sep  6 11:49:40.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:49:40.329: INFO: namespace: e2e-tests-projected-dztgh, resource: bindings, ignored listing per whitelist
Sep  6 11:49:40.350: INFO: namespace e2e-tests-projected-dztgh deletion completed in 6.121404671s

• [SLOW TEST:8.324 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:49:40.350: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 11:49:40.481: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"68e2a5b5-d09c-11e9-baa3-fa163efa26fe", Controller:(*bool)(0xc001fa3826), BlockOwnerDeletion:(*bool)(0xc001fa3827)}}
Sep  6 11:49:40.501: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"68dfa605-d09c-11e9-baa3-fa163efa26fe", Controller:(*bool)(0xc001a9c89a), BlockOwnerDeletion:(*bool)(0xc001a9c89b)}}
Sep  6 11:49:40.524: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"68e03fee-d09c-11e9-baa3-fa163efa26fe", Controller:(*bool)(0xc001a92f8a), BlockOwnerDeletion:(*bool)(0xc001a92f8b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:49:45.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rtrb5" for this suite.
Sep  6 11:49:51.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:49:51.591: INFO: namespace: e2e-tests-gc-rtrb5, resource: bindings, ignored listing per whitelist
Sep  6 11:49:51.681: INFO: namespace e2e-tests-gc-rtrb5 deletion completed in 6.130350937s

• [SLOW TEST:11.331 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:49:51.682: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep  6 11:49:51.760: INFO: Waiting up to 5m0s for pod "pod-6f9cf3cf-d09c-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-pv6c7" to be "success or failure"
Sep  6 11:49:51.763: INFO: Pod "pod-6f9cf3cf-d09c-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 3.166181ms
Sep  6 11:49:53.771: INFO: Pod "pod-6f9cf3cf-d09c-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010844851s
STEP: Saw pod success
Sep  6 11:49:53.771: INFO: Pod "pod-6f9cf3cf-d09c-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:49:53.774: INFO: Trying to get logs from node metalk8s-22 pod pod-6f9cf3cf-d09c-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 11:49:53.813: INFO: Waiting for pod pod-6f9cf3cf-d09c-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:49:53.816: INFO: Pod pod-6f9cf3cf-d09c-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:49:53.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pv6c7" for this suite.
Sep  6 11:49:59.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:49:59.859: INFO: namespace: e2e-tests-emptydir-pv6c7, resource: bindings, ignored listing per whitelist
Sep  6 11:49:59.927: INFO: namespace e2e-tests-emptydir-pv6c7 deletion completed in 6.108292797s

• [SLOW TEST:8.245 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:49:59.927: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Sep  6 11:49:59.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-knnfw'
Sep  6 11:50:00.201: INFO: stderr: ""
Sep  6 11:50:00.201: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  6 11:50:01.204: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 11:50:01.204: INFO: Found 0 / 1
Sep  6 11:50:02.206: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 11:50:02.206: INFO: Found 1 / 1
Sep  6 11:50:02.206: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep  6 11:50:02.215: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 11:50:02.215: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  6 11:50:02.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 patch pod redis-master-b8sl6 --namespace=e2e-tests-kubectl-knnfw -p {"metadata":{"annotations":{"x":"y"}}}'
Sep  6 11:50:02.409: INFO: stderr: ""
Sep  6 11:50:02.409: INFO: stdout: "pod/redis-master-b8sl6 patched\n"
STEP: checking annotations
Sep  6 11:50:02.412: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 11:50:02.412: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:50:02.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-knnfw" for this suite.
Sep  6 11:50:26.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:50:26.515: INFO: namespace: e2e-tests-kubectl-knnfw, resource: bindings, ignored listing per whitelist
Sep  6 11:50:26.554: INFO: namespace e2e-tests-kubectl-knnfw deletion completed in 24.136971122s

• [SLOW TEST:26.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:50:26.555: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-8468c393-d09c-11e9-9cef-86a5da7a2260
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:50:28.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hqgxm" for this suite.
Sep  6 11:50:50.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:50:50.742: INFO: namespace: e2e-tests-configmap-hqgxm, resource: bindings, ignored listing per whitelist
Sep  6 11:50:50.845: INFO: namespace e2e-tests-configmap-hqgxm deletion completed in 22.155970767s

• [SLOW TEST:24.290 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:50:50.845: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-92e3f033-d09c-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 11:50:50.957: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-92e4f34b-d09c-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-crrjq" to be "success or failure"
Sep  6 11:50:50.963: INFO: Pod "pod-projected-secrets-92e4f34b-d09c-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 6.079474ms
Sep  6 11:50:52.969: INFO: Pod "pod-projected-secrets-92e4f34b-d09c-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012044489s
STEP: Saw pod success
Sep  6 11:50:52.969: INFO: Pod "pod-projected-secrets-92e4f34b-d09c-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:50:52.971: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-secrets-92e4f34b-d09c-11e9-9cef-86a5da7a2260 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  6 11:50:52.987: INFO: Waiting for pod pod-projected-secrets-92e4f34b-d09c-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:50:52.991: INFO: Pod pod-projected-secrets-92e4f34b-d09c-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:50:52.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-crrjq" for this suite.
Sep  6 11:50:59.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:50:59.176: INFO: namespace: e2e-tests-projected-crrjq, resource: bindings, ignored listing per whitelist
Sep  6 11:50:59.184: INFO: namespace e2e-tests-projected-crrjq deletion completed in 6.187777921s

• [SLOW TEST:8.339 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:50:59.184: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  6 11:50:59.269: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:51:01.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-55bpz" for this suite.
Sep  6 11:51:07.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:51:08.051: INFO: namespace: e2e-tests-init-container-55bpz, resource: bindings, ignored listing per whitelist
Sep  6 11:51:08.085: INFO: namespace e2e-tests-init-container-55bpz deletion completed in 6.151198638s

• [SLOW TEST:8.901 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:51:08.085: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  6 11:51:08.159: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  6 11:51:08.165: INFO: Waiting for terminating namespaces to be deleted...
Sep  6 11:51:08.167: INFO: 
Logging pods the kubelet thinks is on node metalk8s-22 before test
Sep  6 11:51:08.181: INFO: calico-kube-controllers-5fb4b978ff-hj8s4 from kube-system started at 2019-09-06 11:16:12 +0000 UTC (1 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep  6 11:51:08.181: INFO: alertmanager-main-0 from metalk8s-monitoring started at 2019-09-06 11:16:38 +0000 UTC (2 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container alertmanager ready: true, restart count 0
Sep  6 11:51:08.181: INFO: 	Container config-reloader ready: true, restart count 0
Sep  6 11:51:08.181: INFO: node-exporter-pvl9b from metalk8s-monitoring started at 2019-09-06 11:16:40 +0000 UTC (2 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Sep  6 11:51:08.181: INFO: 	Container node-exporter ready: true, restart count 0
Sep  6 11:51:08.181: INFO: grafana-5c9b84b94f-qrc6b from metalk8s-monitoring started at 2019-09-06 11:16:46 +0000 UTC (1 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container grafana ready: true, restart count 0
Sep  6 11:51:08.181: INFO: alertmanager-main-1 from metalk8s-monitoring started at 2019-09-06 11:16:50 +0000 UTC (2 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container alertmanager ready: true, restart count 0
Sep  6 11:51:08.181: INFO: 	Container config-reloader ready: true, restart count 0
Sep  6 11:51:08.181: INFO: kube-state-metrics-86b8b5b6cd-wkhwt from metalk8s-monitoring started at 2019-09-06 11:16:38 +0000 UTC (4 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container addon-resizer ready: true, restart count 0
Sep  6 11:51:08.181: INFO: 	Container kube-rbac-proxy-main ready: true, restart count 0
Sep  6 11:51:08.181: INFO: 	Container kube-rbac-proxy-self ready: true, restart count 0
Sep  6 11:51:08.181: INFO: 	Container kube-state-metrics ready: true, restart count 0
Sep  6 11:51:08.181: INFO: etcd-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:51:08.181: INFO: repositories-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:51:08.181: INFO: kube-scheduler-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:51:08.181: INFO: calico-node-qnjrt from kube-system started at 2019-09-06 11:16:12 +0000 UTC (1 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container calico-node ready: true, restart count 0
Sep  6 11:51:08.181: INFO: coredns-75d9fb9567-jc986 from kube-system started at 2019-09-06 11:16:15 +0000 UTC (1 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container coredns ready: true, restart count 0
Sep  6 11:51:08.181: INFO: prometheus-k8s-0 from metalk8s-monitoring started at 2019-09-06 11:16:45 +0000 UTC (3 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container prometheus ready: true, restart count 1
Sep  6 11:51:08.181: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Sep  6 11:51:08.181: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Sep  6 11:51:08.181: INFO: nginx-ingress-default-backend-6d7c5f49bd-tn6dj from metalk8s-ingress started at 2019-09-06 11:16:50 +0000 UTC (1 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container nginx-ingress-default-backend ready: true, restart count 0
Sep  6 11:51:08.181: INFO: alertmanager-main-2 from metalk8s-monitoring started at 2019-09-06 11:16:56 +0000 UTC (2 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container alertmanager ready: true, restart count 0
Sep  6 11:51:08.181: INFO: 	Container config-reloader ready: true, restart count 0
Sep  6 11:51:08.181: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-06 11:32:30 +0000 UTC (1 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  6 11:51:08.181: INFO: kube-apiserver-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:51:08.181: INFO: coredns-75d9fb9567-ttgdv from kube-system started at 2019-09-06 11:16:15 +0000 UTC (1 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container coredns ready: true, restart count 0
Sep  6 11:51:08.181: INFO: prometheus-k8s-1 from metalk8s-monitoring started at 2019-09-06 11:16:45 +0000 UTC (3 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container prometheus ready: true, restart count 1
Sep  6 11:51:08.181: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Sep  6 11:51:08.181: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Sep  6 11:51:08.181: INFO: nginx-ingress-controller-v46nl from metalk8s-ingress started at 2019-09-06 11:16:49 +0000 UTC (1 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Sep  6 11:51:08.181: INFO: sonobuoy-e2e-job-686830808f80405c from heptio-sonobuoy started at 2019-09-06 11:32:36 +0000 UTC (2 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container e2e ready: true, restart count 0
Sep  6 11:51:08.181: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 11:51:08.181: INFO: kube-controller-manager-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:51:08.181: INFO: kube-proxy-7cpsq from kube-system started at 2019-09-06 11:16:04 +0000 UTC (1 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  6 11:51:08.181: INFO: prometheus-adapter-9cfc8ff6d-swmpn from metalk8s-monitoring started at 2019-09-06 11:16:31 +0000 UTC (1 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container prometheus-adapter ready: true, restart count 0
Sep  6 11:51:08.181: INFO: salt-master-metalk8s-22 from kube-system started at <nil> (0 container statuses recorded)
Sep  6 11:51:08.181: INFO: prometheus-operator-5f67d45986-pvgjz from metalk8s-monitoring started at 2019-09-06 11:16:18 +0000 UTC (1 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container prometheus-operator ready: true, restart count 0
Sep  6 11:51:08.181: INFO: sonobuoy-systemd-logs-daemon-set-1a98abcdad7f4913-gsb5x from heptio-sonobuoy started at 2019-09-06 11:32:36 +0000 UTC (2 container statuses recorded)
Sep  6 11:51:08.181: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  6 11:51:08.181: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c1d71dc794943b], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:51:09.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-thg2g" for this suite.
Sep  6 11:51:15.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:51:15.297: INFO: namespace: e2e-tests-sched-pred-thg2g, resource: bindings, ignored listing per whitelist
Sep  6 11:51:15.351: INFO: namespace e2e-tests-sched-pred-thg2g deletion completed in 6.140092822s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.266 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:51:15.351: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep  6 11:51:15.465: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bb6jr,SelfLink:/api/v1/namespaces/e2e-tests-watch-bb6jr/configmaps/e2e-watch-test-watch-closed,UID:a17ff080-d09c-11e9-baa3-fa163efa26fe,ResourceVersion:6458,Generation:0,CreationTimestamp:2019-09-06 11:51:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  6 11:51:15.465: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bb6jr,SelfLink:/api/v1/namespaces/e2e-tests-watch-bb6jr/configmaps/e2e-watch-test-watch-closed,UID:a17ff080-d09c-11e9-baa3-fa163efa26fe,ResourceVersion:6459,Generation:0,CreationTimestamp:2019-09-06 11:51:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep  6 11:51:15.489: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bb6jr,SelfLink:/api/v1/namespaces/e2e-tests-watch-bb6jr/configmaps/e2e-watch-test-watch-closed,UID:a17ff080-d09c-11e9-baa3-fa163efa26fe,ResourceVersion:6460,Generation:0,CreationTimestamp:2019-09-06 11:51:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  6 11:51:15.489: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bb6jr,SelfLink:/api/v1/namespaces/e2e-tests-watch-bb6jr/configmaps/e2e-watch-test-watch-closed,UID:a17ff080-d09c-11e9-baa3-fa163efa26fe,ResourceVersion:6461,Generation:0,CreationTimestamp:2019-09-06 11:51:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:51:15.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-bb6jr" for this suite.
Sep  6 11:51:21.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:51:21.631: INFO: namespace: e2e-tests-watch-bb6jr, resource: bindings, ignored listing per whitelist
Sep  6 11:51:21.638: INFO: namespace e2e-tests-watch-bb6jr deletion completed in 6.145812633s

• [SLOW TEST:6.287 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:51:21.639: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 11:51:21.720: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a53b78e2-d09c-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-bg9ls" to be "success or failure"
Sep  6 11:51:21.733: INFO: Pod "downwardapi-volume-a53b78e2-d09c-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 13.260892ms
Sep  6 11:51:23.736: INFO: Pod "downwardapi-volume-a53b78e2-d09c-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.016306983s
Sep  6 11:51:25.739: INFO: Pod "downwardapi-volume-a53b78e2-d09c-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019127688s
STEP: Saw pod success
Sep  6 11:51:25.739: INFO: Pod "downwardapi-volume-a53b78e2-d09c-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:51:25.750: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-a53b78e2-d09c-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 11:51:25.767: INFO: Waiting for pod downwardapi-volume-a53b78e2-d09c-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:51:25.770: INFO: Pod downwardapi-volume-a53b78e2-d09c-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:51:25.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bg9ls" for this suite.
Sep  6 11:51:31.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:51:31.815: INFO: namespace: e2e-tests-downward-api-bg9ls, resource: bindings, ignored listing per whitelist
Sep  6 11:51:31.881: INFO: namespace e2e-tests-downward-api-bg9ls deletion completed in 6.10918412s

• [SLOW TEST:10.243 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:51:31.881: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 11:51:53.982: INFO: Container started at 2019-09-06 11:51:34 +0000 UTC, pod became ready at 2019-09-06 11:51:52 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:51:53.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rm62p" for this suite.
Sep  6 11:52:15.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:52:16.098: INFO: namespace: e2e-tests-container-probe-rm62p, resource: bindings, ignored listing per whitelist
Sep  6 11:52:16.118: INFO: namespace e2e-tests-container-probe-rm62p deletion completed in 22.132199682s

• [SLOW TEST:44.237 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:52:16.118: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-z524g
Sep  6 11:52:18.211: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-z524g
STEP: checking the pod's current state and verifying that restartCount is present
Sep  6 11:52:18.214: INFO: Initial restart count of pod liveness-exec is 0
Sep  6 11:53:04.306: INFO: Restart count of pod e2e-tests-container-probe-z524g/liveness-exec is now 1 (46.092549475s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:53:04.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-z524g" for this suite.
Sep  6 11:53:10.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:53:10.396: INFO: namespace: e2e-tests-container-probe-z524g, resource: bindings, ignored listing per whitelist
Sep  6 11:53:10.492: INFO: namespace e2e-tests-container-probe-z524g deletion completed in 6.165165353s

• [SLOW TEST:54.374 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:53:10.492: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0906 11:53:20.700768      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 11:53:20.700: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:53:20.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9vms6" for this suite.
Sep  6 11:53:26.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:53:26.748: INFO: namespace: e2e-tests-gc-9vms6, resource: bindings, ignored listing per whitelist
Sep  6 11:53:27.035: INFO: namespace e2e-tests-gc-9vms6 deletion completed in 6.330475468s

• [SLOW TEST:16.543 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:53:27.036: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Sep  6 11:53:27.802: INFO: Waiting up to 5m0s for pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-7bpv4" in namespace "e2e-tests-svcaccounts-5l8sl" to be "success or failure"
Sep  6 11:53:27.820: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-7bpv4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.469996ms
Sep  6 11:53:29.828: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-7bpv4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025271453s
Sep  6 11:53:31.831: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-7bpv4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028798153s
STEP: Saw pod success
Sep  6 11:53:31.831: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-7bpv4" satisfied condition "success or failure"
Sep  6 11:53:31.834: INFO: Trying to get logs from node metalk8s-22 pod pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-7bpv4 container token-test: <nil>
STEP: delete the pod
Sep  6 11:53:31.853: INFO: Waiting for pod pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-7bpv4 to disappear
Sep  6 11:53:31.856: INFO: Pod pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-7bpv4 no longer exists
STEP: Creating a pod to test consume service account root CA
Sep  6 11:53:31.860: INFO: Waiting up to 5m0s for pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-6f6tn" in namespace "e2e-tests-svcaccounts-5l8sl" to be "success or failure"
Sep  6 11:53:31.864: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-6f6tn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.067408ms
Sep  6 11:53:33.867: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-6f6tn": Phase="Running", Reason="", readiness=false. Elapsed: 2.007677651s
Sep  6 11:53:35.871: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-6f6tn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011316572s
STEP: Saw pod success
Sep  6 11:53:35.871: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-6f6tn" satisfied condition "success or failure"
Sep  6 11:53:35.878: INFO: Trying to get logs from node metalk8s-22 pod pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-6f6tn container root-ca-test: <nil>
STEP: delete the pod
Sep  6 11:53:35.908: INFO: Waiting for pod pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-6f6tn to disappear
Sep  6 11:53:35.910: INFO: Pod pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-6f6tn no longer exists
STEP: Creating a pod to test consume service account namespace
Sep  6 11:53:35.916: INFO: Waiting up to 5m0s for pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-hf8s5" in namespace "e2e-tests-svcaccounts-5l8sl" to be "success or failure"
Sep  6 11:53:35.919: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-hf8s5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.427374ms
Sep  6 11:53:37.922: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-hf8s5": Phase="Running", Reason="", readiness=false. Elapsed: 2.006611208s
Sep  6 11:53:39.926: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-hf8s5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009923991s
STEP: Saw pod success
Sep  6 11:53:39.926: INFO: Pod "pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-hf8s5" satisfied condition "success or failure"
Sep  6 11:53:39.928: INFO: Trying to get logs from node metalk8s-22 pod pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-hf8s5 container namespace-test: <nil>
STEP: delete the pod
Sep  6 11:53:39.950: INFO: Waiting for pod pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-hf8s5 to disappear
Sep  6 11:53:39.956: INFO: Pod pod-service-account-f05f9604-d09c-11e9-9cef-86a5da7a2260-hf8s5 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:53:39.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-5l8sl" for this suite.
Sep  6 11:53:45.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:53:46.040: INFO: namespace: e2e-tests-svcaccounts-5l8sl, resource: bindings, ignored listing per whitelist
Sep  6 11:53:46.090: INFO: namespace e2e-tests-svcaccounts-5l8sl deletion completed in 6.131414179s

• [SLOW TEST:19.055 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:53:46.091: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fb5703b8-d09c-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 11:53:46.199: INFO: Waiting up to 5m0s for pod "pod-secrets-fb57ad8c-d09c-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-secrets-bsdbm" to be "success or failure"
Sep  6 11:53:46.207: INFO: Pod "pod-secrets-fb57ad8c-d09c-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 8.514939ms
Sep  6 11:53:48.219: INFO: Pod "pod-secrets-fb57ad8c-d09c-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019912019s
STEP: Saw pod success
Sep  6 11:53:48.219: INFO: Pod "pod-secrets-fb57ad8c-d09c-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:53:48.224: INFO: Trying to get logs from node metalk8s-22 pod pod-secrets-fb57ad8c-d09c-11e9-9cef-86a5da7a2260 container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 11:53:48.256: INFO: Waiting for pod pod-secrets-fb57ad8c-d09c-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:53:48.264: INFO: Pod pod-secrets-fb57ad8c-d09c-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:53:48.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bsdbm" for this suite.
Sep  6 11:53:54.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:53:54.403: INFO: namespace: e2e-tests-secrets-bsdbm, resource: bindings, ignored listing per whitelist
Sep  6 11:53:54.459: INFO: namespace e2e-tests-secrets-bsdbm deletion completed in 6.187306323s

• [SLOW TEST:8.369 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:53:54.459: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-0050be0c-d09d-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 11:53:54.536: INFO: Waiting up to 5m0s for pod "pod-configmaps-0051517c-d09d-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-configmap-949v6" to be "success or failure"
Sep  6 11:53:54.541: INFO: Pod "pod-configmaps-0051517c-d09d-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 4.661389ms
Sep  6 11:53:56.551: INFO: Pod "pod-configmaps-0051517c-d09d-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014887562s
STEP: Saw pod success
Sep  6 11:53:56.551: INFO: Pod "pod-configmaps-0051517c-d09d-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:53:56.554: INFO: Trying to get logs from node metalk8s-22 pod pod-configmaps-0051517c-d09d-11e9-9cef-86a5da7a2260 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 11:53:56.583: INFO: Waiting for pod pod-configmaps-0051517c-d09d-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:53:56.590: INFO: Pod pod-configmaps-0051517c-d09d-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:53:56.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-949v6" for this suite.
Sep  6 11:54:02.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:54:02.776: INFO: namespace: e2e-tests-configmap-949v6, resource: bindings, ignored listing per whitelist
Sep  6 11:54:02.814: INFO: namespace e2e-tests-configmap-949v6 deletion completed in 6.214065396s

• [SLOW TEST:8.355 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:54:02.815: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 11:54:02.926: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Sep  6 11:54:02.933: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zwcq9/daemonsets","resourceVersion":"7285"},"items":null}

Sep  6 11:54:02.937: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zwcq9/pods","resourceVersion":"7285"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:54:02.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zwcq9" for this suite.
Sep  6 11:54:08.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:54:09.062: INFO: namespace: e2e-tests-daemonsets-zwcq9, resource: bindings, ignored listing per whitelist
Sep  6 11:54:09.084: INFO: namespace e2e-tests-daemonsets-zwcq9 deletion completed in 6.138086357s

S [SKIPPING] [6.270 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Sep  6 11:54:02.926: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:54:09.084: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0906 11:54:39.752021      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 11:54:39.752: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:54:39.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6ndmn" for this suite.
Sep  6 11:54:45.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:54:45.891: INFO: namespace: e2e-tests-gc-6ndmn, resource: bindings, ignored listing per whitelist
Sep  6 11:54:45.993: INFO: namespace e2e-tests-gc-6ndmn deletion completed in 6.238474646s

• [SLOW TEST:36.909 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:54:45.994: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:55:09.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-ffcn6" for this suite.
Sep  6 11:55:15.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:55:15.335: INFO: namespace: e2e-tests-container-runtime-ffcn6, resource: bindings, ignored listing per whitelist
Sep  6 11:55:15.498: INFO: namespace e2e-tests-container-runtime-ffcn6 deletion completed in 6.194812017s

• [SLOW TEST:29.504 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:55:15.498: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 11:55:15.628: INFO: Waiting up to 5m0s for pod "downwardapi-volume-30a55d58-d09d-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-7rxb5" to be "success or failure"
Sep  6 11:55:15.637: INFO: Pod "downwardapi-volume-30a55d58-d09d-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 8.445912ms
Sep  6 11:55:17.641: INFO: Pod "downwardapi-volume-30a55d58-d09d-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.012413826s
Sep  6 11:55:19.645: INFO: Pod "downwardapi-volume-30a55d58-d09d-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016470224s
STEP: Saw pod success
Sep  6 11:55:19.645: INFO: Pod "downwardapi-volume-30a55d58-d09d-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:55:19.648: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-30a55d58-d09d-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 11:55:19.667: INFO: Waiting for pod downwardapi-volume-30a55d58-d09d-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:55:19.673: INFO: Pod downwardapi-volume-30a55d58-d09d-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:55:19.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7rxb5" for this suite.
Sep  6 11:55:25.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:55:25.805: INFO: namespace: e2e-tests-downward-api-7rxb5, resource: bindings, ignored listing per whitelist
Sep  6 11:55:25.817: INFO: namespace e2e-tests-downward-api-7rxb5 deletion completed in 6.139436069s

• [SLOW TEST:10.319 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:55:25.817: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  6 11:55:28.449: INFO: Successfully updated pod "labelsupdate36c870fc-d09d-11e9-9cef-86a5da7a2260"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:55:32.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-flg7k" for this suite.
Sep  6 11:55:54.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:55:54.642: INFO: namespace: e2e-tests-downward-api-flg7k, resource: bindings, ignored listing per whitelist
Sep  6 11:55:54.644: INFO: namespace e2e-tests-downward-api-flg7k deletion completed in 22.150755756s

• [SLOW TEST:28.827 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:55:54.644: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Sep  6 11:55:54.719: INFO: Waiting up to 5m0s for pod "var-expansion-47f37751-d09d-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-var-expansion-6hzkt" to be "success or failure"
Sep  6 11:55:54.722: INFO: Pod "var-expansion-47f37751-d09d-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 3.194792ms
Sep  6 11:55:56.725: INFO: Pod "var-expansion-47f37751-d09d-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006295033s
STEP: Saw pod success
Sep  6 11:55:56.725: INFO: Pod "var-expansion-47f37751-d09d-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:55:56.727: INFO: Trying to get logs from node metalk8s-22 pod var-expansion-47f37751-d09d-11e9-9cef-86a5da7a2260 container dapi-container: <nil>
STEP: delete the pod
Sep  6 11:55:56.743: INFO: Waiting for pod var-expansion-47f37751-d09d-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:55:56.750: INFO: Pod var-expansion-47f37751-d09d-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:55:56.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6hzkt" for this suite.
Sep  6 11:56:02.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:56:02.798: INFO: namespace: e2e-tests-var-expansion-6hzkt, resource: bindings, ignored listing per whitelist
Sep  6 11:56:02.922: INFO: namespace e2e-tests-var-expansion-6hzkt deletion completed in 6.169840962s

• [SLOW TEST:8.278 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:56:02.922: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:56:05.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-k2fjk" for this suite.
Sep  6 11:56:43.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:56:43.132: INFO: namespace: e2e-tests-kubelet-test-k2fjk, resource: bindings, ignored listing per whitelist
Sep  6 11:56:43.217: INFO: namespace e2e-tests-kubelet-test-k2fjk deletion completed in 38.190463547s

• [SLOW TEST:40.294 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:56:43.217: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-64efc775-d09d-11e9-9cef-86a5da7a2260
STEP: Creating secret with name s-test-opt-upd-64efc7dc-d09d-11e9-9cef-86a5da7a2260
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-64efc775-d09d-11e9-9cef-86a5da7a2260
STEP: Updating secret s-test-opt-upd-64efc7dc-d09d-11e9-9cef-86a5da7a2260
STEP: Creating secret with name s-test-opt-create-64efc7fc-d09d-11e9-9cef-86a5da7a2260
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:56:47.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fs9th" for this suite.
Sep  6 11:57:09.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:57:09.529: INFO: namespace: e2e-tests-secrets-fs9th, resource: bindings, ignored listing per whitelist
Sep  6 11:57:09.554: INFO: namespace e2e-tests-secrets-fs9th deletion completed in 22.110475167s

• [SLOW TEST:26.337 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:57:09.554: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-z7d62
I0906 11:57:09.615618      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-z7d62, replica count: 1
I0906 11:57:10.666311      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0906 11:57:11.666643      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  6 11:57:11.798: INFO: Created: latency-svc-x2z9h
Sep  6 11:57:11.815: INFO: Got endpoints: latency-svc-x2z9h [48.497717ms]
Sep  6 11:57:11.832: INFO: Created: latency-svc-77g8k
Sep  6 11:57:11.837: INFO: Got endpoints: latency-svc-77g8k [21.367313ms]
Sep  6 11:57:11.858: INFO: Created: latency-svc-tbp9m
Sep  6 11:57:11.872: INFO: Got endpoints: latency-svc-tbp9m [56.335521ms]
Sep  6 11:57:11.877: INFO: Created: latency-svc-ptk9h
Sep  6 11:57:11.885: INFO: Got endpoints: latency-svc-ptk9h [68.54833ms]
Sep  6 11:57:11.899: INFO: Created: latency-svc-l2gbn
Sep  6 11:57:11.912: INFO: Created: latency-svc-wdwp4
Sep  6 11:57:11.912: INFO: Got endpoints: latency-svc-l2gbn [93.351359ms]
Sep  6 11:57:11.920: INFO: Got endpoints: latency-svc-wdwp4 [99.610268ms]
Sep  6 11:57:11.934: INFO: Created: latency-svc-w5l8h
Sep  6 11:57:11.939: INFO: Got endpoints: latency-svc-w5l8h [116.835993ms]
Sep  6 11:57:11.948: INFO: Created: latency-svc-dxv68
Sep  6 11:57:11.956: INFO: Got endpoints: latency-svc-dxv68 [133.530804ms]
Sep  6 11:57:11.958: INFO: Created: latency-svc-vmnq2
Sep  6 11:57:11.986: INFO: Got endpoints: latency-svc-vmnq2 [163.890991ms]
Sep  6 11:57:11.992: INFO: Created: latency-svc-gjwmc
Sep  6 11:57:11.998: INFO: Got endpoints: latency-svc-gjwmc [175.287679ms]
Sep  6 11:57:12.007: INFO: Created: latency-svc-lc92g
Sep  6 11:57:12.012: INFO: Got endpoints: latency-svc-lc92g [190.028723ms]
Sep  6 11:57:12.021: INFO: Created: latency-svc-4zm9r
Sep  6 11:57:12.025: INFO: Got endpoints: latency-svc-4zm9r [202.85422ms]
Sep  6 11:57:12.035: INFO: Created: latency-svc-8fb28
Sep  6 11:57:12.038: INFO: Got endpoints: latency-svc-8fb28 [215.944579ms]
Sep  6 11:57:12.050: INFO: Created: latency-svc-bs72b
Sep  6 11:57:12.053: INFO: Got endpoints: latency-svc-bs72b [230.970846ms]
Sep  6 11:57:12.057: INFO: Created: latency-svc-ltkch
Sep  6 11:57:12.062: INFO: Got endpoints: latency-svc-ltkch [245.430718ms]
Sep  6 11:57:12.065: INFO: Created: latency-svc-t9bwg
Sep  6 11:57:12.073: INFO: Got endpoints: latency-svc-t9bwg [250.437531ms]
Sep  6 11:57:12.137: INFO: Created: latency-svc-hpjb7
Sep  6 11:57:12.142: INFO: Got endpoints: latency-svc-hpjb7 [79.978886ms]
Sep  6 11:57:12.168: INFO: Created: latency-svc-mfthk
Sep  6 11:57:12.172: INFO: Got endpoints: latency-svc-mfthk [335.391737ms]
Sep  6 11:57:12.202: INFO: Created: latency-svc-v2npc
Sep  6 11:57:12.216: INFO: Got endpoints: latency-svc-v2npc [343.529682ms]
Sep  6 11:57:12.227: INFO: Created: latency-svc-srhj4
Sep  6 11:57:12.277: INFO: Got endpoints: latency-svc-srhj4 [392.401899ms]
Sep  6 11:57:12.281: INFO: Created: latency-svc-ssjgx
Sep  6 11:57:12.305: INFO: Got endpoints: latency-svc-ssjgx [392.186218ms]
Sep  6 11:57:12.328: INFO: Created: latency-svc-f8nqr
Sep  6 11:57:12.332: INFO: Got endpoints: latency-svc-f8nqr [412.07953ms]
Sep  6 11:57:12.352: INFO: Created: latency-svc-v7f4b
Sep  6 11:57:12.366: INFO: Got endpoints: latency-svc-v7f4b [427.084749ms]
Sep  6 11:57:12.391: INFO: Created: latency-svc-6qfdt
Sep  6 11:57:12.394: INFO: Got endpoints: latency-svc-6qfdt [437.796543ms]
Sep  6 11:57:12.400: INFO: Created: latency-svc-vvjtd
Sep  6 11:57:12.402: INFO: Got endpoints: latency-svc-vvjtd [415.999969ms]
Sep  6 11:57:12.410: INFO: Created: latency-svc-rxqn8
Sep  6 11:57:12.413: INFO: Got endpoints: latency-svc-rxqn8 [415.796867ms]
Sep  6 11:57:12.428: INFO: Created: latency-svc-4722f
Sep  6 11:57:12.431: INFO: Got endpoints: latency-svc-4722f [418.610402ms]
Sep  6 11:57:12.448: INFO: Created: latency-svc-785b2
Sep  6 11:57:12.450: INFO: Got endpoints: latency-svc-785b2 [424.947169ms]
Sep  6 11:57:12.454: INFO: Created: latency-svc-g9zzl
Sep  6 11:57:12.473: INFO: Got endpoints: latency-svc-g9zzl [434.773392ms]
Sep  6 11:57:12.498: INFO: Created: latency-svc-zvxpl
Sep  6 11:57:12.527: INFO: Got endpoints: latency-svc-zvxpl [474.259633ms]
Sep  6 11:57:12.563: INFO: Created: latency-svc-qp9d9
Sep  6 11:57:12.567: INFO: Got endpoints: latency-svc-qp9d9 [494.291709ms]
Sep  6 11:57:12.597: INFO: Created: latency-svc-6vqv4
Sep  6 11:57:12.609: INFO: Got endpoints: latency-svc-6vqv4 [467.608254ms]
Sep  6 11:57:12.615: INFO: Created: latency-svc-8752t
Sep  6 11:57:12.619: INFO: Got endpoints: latency-svc-8752t [447.212468ms]
Sep  6 11:57:12.639: INFO: Created: latency-svc-czkcq
Sep  6 11:57:12.658: INFO: Got endpoints: latency-svc-czkcq [441.797109ms]
Sep  6 11:57:12.658: INFO: Created: latency-svc-9kdw8
Sep  6 11:57:12.669: INFO: Got endpoints: latency-svc-9kdw8 [391.866064ms]
Sep  6 11:57:12.673: INFO: Created: latency-svc-vlq62
Sep  6 11:57:12.680: INFO: Got endpoints: latency-svc-vlq62 [375.564414ms]
Sep  6 11:57:12.688: INFO: Created: latency-svc-dprsd
Sep  6 11:57:12.709: INFO: Got endpoints: latency-svc-dprsd [376.606861ms]
Sep  6 11:57:12.715: INFO: Created: latency-svc-9lqrp
Sep  6 11:57:12.715: INFO: Got endpoints: latency-svc-9lqrp [348.162603ms]
Sep  6 11:57:12.730: INFO: Created: latency-svc-4zbq2
Sep  6 11:57:12.753: INFO: Got endpoints: latency-svc-4zbq2 [358.787596ms]
Sep  6 11:57:12.755: INFO: Created: latency-svc-s2pdz
Sep  6 11:57:12.775: INFO: Got endpoints: latency-svc-s2pdz [372.377176ms]
Sep  6 11:57:12.783: INFO: Created: latency-svc-6dpkt
Sep  6 11:57:12.794: INFO: Got endpoints: latency-svc-6dpkt [380.085928ms]
Sep  6 11:57:12.801: INFO: Created: latency-svc-8xc8v
Sep  6 11:57:12.811: INFO: Got endpoints: latency-svc-8xc8v [379.914051ms]
Sep  6 11:57:12.811: INFO: Created: latency-svc-qpwpf
Sep  6 11:57:12.819: INFO: Got endpoints: latency-svc-qpwpf [369.420135ms]
Sep  6 11:57:12.840: INFO: Created: latency-svc-s28fg
Sep  6 11:57:12.844: INFO: Created: latency-svc-4wkss
Sep  6 11:57:12.852: INFO: Got endpoints: latency-svc-4wkss [324.216028ms]
Sep  6 11:57:12.852: INFO: Got endpoints: latency-svc-s28fg [378.690353ms]
Sep  6 11:57:12.877: INFO: Created: latency-svc-nvqpl
Sep  6 11:57:12.906: INFO: Created: latency-svc-kx9dn
Sep  6 11:57:12.906: INFO: Got endpoints: latency-svc-nvqpl [338.992363ms]
Sep  6 11:57:12.965: INFO: Got endpoints: latency-svc-kx9dn [355.236948ms]
Sep  6 11:57:13.043: INFO: Created: latency-svc-gphhk
Sep  6 11:57:13.053: INFO: Got endpoints: latency-svc-gphhk [433.673407ms]
Sep  6 11:57:13.086: INFO: Created: latency-svc-9zs76
Sep  6 11:57:13.086: INFO: Got endpoints: latency-svc-9zs76 [428.517381ms]
Sep  6 11:57:13.095: INFO: Created: latency-svc-nqfgb
Sep  6 11:57:13.099: INFO: Got endpoints: latency-svc-nqfgb [429.809171ms]
Sep  6 11:57:13.113: INFO: Created: latency-svc-dlqt5
Sep  6 11:57:13.135: INFO: Got endpoints: latency-svc-dlqt5 [454.726568ms]
Sep  6 11:57:13.135: INFO: Created: latency-svc-s66gp
Sep  6 11:57:13.138: INFO: Got endpoints: latency-svc-s66gp [429.42325ms]
Sep  6 11:57:13.166: INFO: Created: latency-svc-j9rgn
Sep  6 11:57:13.193: INFO: Got endpoints: latency-svc-j9rgn [477.666148ms]
Sep  6 11:57:13.202: INFO: Created: latency-svc-rbr7k
Sep  6 11:57:13.208: INFO: Got endpoints: latency-svc-rbr7k [454.708569ms]
Sep  6 11:57:13.227: INFO: Created: latency-svc-2hc29
Sep  6 11:57:13.268: INFO: Created: latency-svc-krwg4
Sep  6 11:57:13.268: INFO: Got endpoints: latency-svc-2hc29 [493.239596ms]
Sep  6 11:57:13.281: INFO: Got endpoints: latency-svc-krwg4 [487.536152ms]
Sep  6 11:57:13.304: INFO: Created: latency-svc-fg8cz
Sep  6 11:57:13.314: INFO: Created: latency-svc-7qcjd
Sep  6 11:57:13.319: INFO: Got endpoints: latency-svc-fg8cz [508.033854ms]
Sep  6 11:57:13.323: INFO: Got endpoints: latency-svc-7qcjd [503.084868ms]
Sep  6 11:57:13.326: INFO: Created: latency-svc-zs2sl
Sep  6 11:57:13.332: INFO: Got endpoints: latency-svc-zs2sl [480.312129ms]
Sep  6 11:57:13.351: INFO: Created: latency-svc-lvrc6
Sep  6 11:57:13.355: INFO: Got endpoints: latency-svc-lvrc6 [502.908318ms]
Sep  6 11:57:13.360: INFO: Created: latency-svc-2f8hp
Sep  6 11:57:13.381: INFO: Got endpoints: latency-svc-2f8hp [474.624074ms]
Sep  6 11:57:13.385: INFO: Created: latency-svc-qksc5
Sep  6 11:57:13.402: INFO: Created: latency-svc-j8g4s
Sep  6 11:57:13.407: INFO: Got endpoints: latency-svc-qksc5 [442.40546ms]
Sep  6 11:57:13.453: INFO: Created: latency-svc-r9m5b
Sep  6 11:57:13.471: INFO: Got endpoints: latency-svc-j8g4s [418.045858ms]
Sep  6 11:57:13.506: INFO: Got endpoints: latency-svc-r9m5b [419.597698ms]
Sep  6 11:57:13.507: INFO: Created: latency-svc-kjxcq
Sep  6 11:57:13.529: INFO: Created: latency-svc-krtvk
Sep  6 11:57:13.563: INFO: Got endpoints: latency-svc-kjxcq [463.736083ms]
Sep  6 11:57:13.563: INFO: Created: latency-svc-qzt9n
Sep  6 11:57:13.574: INFO: Created: latency-svc-xq6xh
Sep  6 11:57:13.596: INFO: Created: latency-svc-pbdxg
Sep  6 11:57:13.629: INFO: Got endpoints: latency-svc-krtvk [494.396715ms]
Sep  6 11:57:13.635: INFO: Created: latency-svc-lmtx6
Sep  6 11:57:13.648: INFO: Created: latency-svc-kk6pt
Sep  6 11:57:13.687: INFO: Created: latency-svc-59lj7
Sep  6 11:57:13.687: INFO: Got endpoints: latency-svc-qzt9n [549.24437ms]
Sep  6 11:57:13.706: INFO: Created: latency-svc-d2kps
Sep  6 11:57:13.707: INFO: Got endpoints: latency-svc-xq6xh [513.889334ms]
Sep  6 11:57:13.721: INFO: Created: latency-svc-nscgd
Sep  6 11:57:13.741: INFO: Created: latency-svc-8bc26
Sep  6 11:57:13.755: INFO: Created: latency-svc-b7xrs
Sep  6 11:57:13.759: INFO: Got endpoints: latency-svc-pbdxg [551.4843ms]
Sep  6 11:57:13.766: INFO: Created: latency-svc-65z42
Sep  6 11:57:13.781: INFO: Created: latency-svc-dnbv2
Sep  6 11:57:13.806: INFO: Created: latency-svc-ktxzd
Sep  6 11:57:13.813: INFO: Got endpoints: latency-svc-lmtx6 [544.692765ms]
Sep  6 11:57:13.830: INFO: Created: latency-svc-thvfq
Sep  6 11:57:13.856: INFO: Got endpoints: latency-svc-kk6pt [574.422606ms]
Sep  6 11:57:13.863: INFO: Created: latency-svc-nbrp9
Sep  6 11:57:13.881: INFO: Created: latency-svc-nsnb4
Sep  6 11:57:13.884: INFO: Created: latency-svc-469d2
Sep  6 11:57:13.901: INFO: Created: latency-svc-fsfm4
Sep  6 11:57:13.905: INFO: Got endpoints: latency-svc-59lj7 [585.831998ms]
Sep  6 11:57:13.909: INFO: Created: latency-svc-blp5f
Sep  6 11:57:13.916: INFO: Created: latency-svc-hbg2h
Sep  6 11:57:13.952: INFO: Created: latency-svc-sjgl7
Sep  6 11:57:13.968: INFO: Got endpoints: latency-svc-d2kps [644.766949ms]
Sep  6 11:57:13.984: INFO: Created: latency-svc-bnlp6
Sep  6 11:57:14.003: INFO: Got endpoints: latency-svc-nscgd [670.999533ms]
Sep  6 11:57:14.033: INFO: Created: latency-svc-zj6br
Sep  6 11:57:14.057: INFO: Got endpoints: latency-svc-8bc26 [701.880122ms]
Sep  6 11:57:14.073: INFO: Created: latency-svc-v9rqt
Sep  6 11:57:14.105: INFO: Got endpoints: latency-svc-b7xrs [724.615495ms]
Sep  6 11:57:14.121: INFO: Created: latency-svc-8zrsf
Sep  6 11:57:14.166: INFO: Got endpoints: latency-svc-65z42 [759.172079ms]
Sep  6 11:57:14.198: INFO: Created: latency-svc-9zkpc
Sep  6 11:57:14.204: INFO: Got endpoints: latency-svc-dnbv2 [732.926766ms]
Sep  6 11:57:14.228: INFO: Created: latency-svc-4gtrh
Sep  6 11:57:14.256: INFO: Got endpoints: latency-svc-ktxzd [750.010024ms]
Sep  6 11:57:14.308: INFO: Got endpoints: latency-svc-thvfq [745.344508ms]
Sep  6 11:57:14.311: INFO: Created: latency-svc-qc8ml
Sep  6 11:57:14.322: INFO: Created: latency-svc-jllbm
Sep  6 11:57:14.355: INFO: Got endpoints: latency-svc-nbrp9 [725.077487ms]
Sep  6 11:57:14.374: INFO: Created: latency-svc-zw4c8
Sep  6 11:57:14.422: INFO: Got endpoints: latency-svc-nsnb4 [734.560685ms]
Sep  6 11:57:14.440: INFO: Created: latency-svc-qzzm7
Sep  6 11:57:14.454: INFO: Got endpoints: latency-svc-469d2 [747.179516ms]
Sep  6 11:57:14.469: INFO: Created: latency-svc-nc8cv
Sep  6 11:57:14.514: INFO: Got endpoints: latency-svc-fsfm4 [755.195479ms]
Sep  6 11:57:14.548: INFO: Created: latency-svc-4rrj6
Sep  6 11:57:14.557: INFO: Got endpoints: latency-svc-blp5f [744.432648ms]
Sep  6 11:57:14.601: INFO: Created: latency-svc-w6p74
Sep  6 11:57:14.663: INFO: Got endpoints: latency-svc-hbg2h [807.05234ms]
Sep  6 11:57:14.679: INFO: Got endpoints: latency-svc-sjgl7 [773.63558ms]
Sep  6 11:57:14.687: INFO: Created: latency-svc-bl9mb
Sep  6 11:57:14.753: INFO: Got endpoints: latency-svc-bnlp6 [784.862255ms]
Sep  6 11:57:14.774: INFO: Got endpoints: latency-svc-zj6br [771.179788ms]
Sep  6 11:57:14.815: INFO: Created: latency-svc-tj9g2
Sep  6 11:57:14.815: INFO: Got endpoints: latency-svc-v9rqt [758.307394ms]
Sep  6 11:57:14.825: INFO: Created: latency-svc-w6zxr
Sep  6 11:57:14.846: INFO: Created: latency-svc-jfmdt
Sep  6 11:57:14.854: INFO: Got endpoints: latency-svc-8zrsf [748.550048ms]
Sep  6 11:57:14.869: INFO: Created: latency-svc-xgvc2
Sep  6 11:57:14.889: INFO: Created: latency-svc-hc49l
Sep  6 11:57:14.910: INFO: Got endpoints: latency-svc-9zkpc [743.823408ms]
Sep  6 11:57:14.943: INFO: Created: latency-svc-4v46h
Sep  6 11:57:14.955: INFO: Got endpoints: latency-svc-4gtrh [751.199858ms]
Sep  6 11:57:14.975: INFO: Created: latency-svc-bg66l
Sep  6 11:57:15.005: INFO: Got endpoints: latency-svc-qc8ml [748.514632ms]
Sep  6 11:57:15.024: INFO: Created: latency-svc-46b6j
Sep  6 11:57:15.053: INFO: Got endpoints: latency-svc-jllbm [745.235236ms]
Sep  6 11:57:15.072: INFO: Created: latency-svc-9vhtk
Sep  6 11:57:15.108: INFO: Got endpoints: latency-svc-zw4c8 [752.905645ms]
Sep  6 11:57:15.122: INFO: Created: latency-svc-84bfq
Sep  6 11:57:15.154: INFO: Got endpoints: latency-svc-qzzm7 [732.135581ms]
Sep  6 11:57:15.176: INFO: Created: latency-svc-594pw
Sep  6 11:57:15.206: INFO: Got endpoints: latency-svc-nc8cv [752.143306ms]
Sep  6 11:57:15.218: INFO: Created: latency-svc-2ttlw
Sep  6 11:57:15.254: INFO: Got endpoints: latency-svc-4rrj6 [739.791356ms]
Sep  6 11:57:15.265: INFO: Created: latency-svc-m9wcb
Sep  6 11:57:15.304: INFO: Got endpoints: latency-svc-w6p74 [746.782332ms]
Sep  6 11:57:15.316: INFO: Created: latency-svc-b6lb2
Sep  6 11:57:15.356: INFO: Got endpoints: latency-svc-bl9mb [693.004329ms]
Sep  6 11:57:15.368: INFO: Created: latency-svc-8qsn2
Sep  6 11:57:15.404: INFO: Got endpoints: latency-svc-tj9g2 [724.927262ms]
Sep  6 11:57:15.417: INFO: Created: latency-svc-fmhrq
Sep  6 11:57:15.455: INFO: Got endpoints: latency-svc-w6zxr [702.033907ms]
Sep  6 11:57:15.474: INFO: Created: latency-svc-ppgmg
Sep  6 11:57:15.505: INFO: Got endpoints: latency-svc-jfmdt [730.79263ms]
Sep  6 11:57:15.527: INFO: Created: latency-svc-qcw77
Sep  6 11:57:15.555: INFO: Got endpoints: latency-svc-xgvc2 [740.326649ms]
Sep  6 11:57:15.573: INFO: Created: latency-svc-95w6j
Sep  6 11:57:15.603: INFO: Got endpoints: latency-svc-hc49l [748.799895ms]
Sep  6 11:57:15.614: INFO: Created: latency-svc-7d954
Sep  6 11:57:15.660: INFO: Got endpoints: latency-svc-4v46h [750.163975ms]
Sep  6 11:57:15.670: INFO: Created: latency-svc-4lsfm
Sep  6 11:57:15.709: INFO: Got endpoints: latency-svc-bg66l [753.849291ms]
Sep  6 11:57:15.722: INFO: Created: latency-svc-mkn8j
Sep  6 11:57:15.753: INFO: Got endpoints: latency-svc-46b6j [748.822478ms]
Sep  6 11:57:15.770: INFO: Created: latency-svc-wqcmm
Sep  6 11:57:15.804: INFO: Got endpoints: latency-svc-9vhtk [750.9251ms]
Sep  6 11:57:15.819: INFO: Created: latency-svc-5fqh7
Sep  6 11:57:15.853: INFO: Got endpoints: latency-svc-84bfq [745.709539ms]
Sep  6 11:57:15.866: INFO: Created: latency-svc-hqjbm
Sep  6 11:57:15.903: INFO: Got endpoints: latency-svc-594pw [749.101367ms]
Sep  6 11:57:15.914: INFO: Created: latency-svc-tggjm
Sep  6 11:57:15.960: INFO: Got endpoints: latency-svc-2ttlw [753.215519ms]
Sep  6 11:57:15.969: INFO: Created: latency-svc-rrgbw
Sep  6 11:57:16.003: INFO: Got endpoints: latency-svc-m9wcb [749.088013ms]
Sep  6 11:57:16.017: INFO: Created: latency-svc-pmq92
Sep  6 11:57:16.062: INFO: Got endpoints: latency-svc-b6lb2 [758.168251ms]
Sep  6 11:57:16.072: INFO: Created: latency-svc-xdk6q
Sep  6 11:57:16.107: INFO: Got endpoints: latency-svc-8qsn2 [750.957375ms]
Sep  6 11:57:16.125: INFO: Created: latency-svc-h8jwt
Sep  6 11:57:16.157: INFO: Got endpoints: latency-svc-fmhrq [753.200687ms]
Sep  6 11:57:16.168: INFO: Created: latency-svc-s5gk8
Sep  6 11:57:16.203: INFO: Got endpoints: latency-svc-ppgmg [748.187021ms]
Sep  6 11:57:16.214: INFO: Created: latency-svc-wk5bs
Sep  6 11:57:16.254: INFO: Got endpoints: latency-svc-qcw77 [748.717755ms]
Sep  6 11:57:16.264: INFO: Created: latency-svc-gvxhw
Sep  6 11:57:16.311: INFO: Got endpoints: latency-svc-95w6j [755.33938ms]
Sep  6 11:57:16.321: INFO: Created: latency-svc-wfq9d
Sep  6 11:57:16.356: INFO: Got endpoints: latency-svc-7d954 [752.615403ms]
Sep  6 11:57:16.367: INFO: Created: latency-svc-56dzb
Sep  6 11:57:16.403: INFO: Got endpoints: latency-svc-4lsfm [742.954816ms]
Sep  6 11:57:16.416: INFO: Created: latency-svc-fxxsl
Sep  6 11:57:16.454: INFO: Got endpoints: latency-svc-mkn8j [744.51529ms]
Sep  6 11:57:16.463: INFO: Created: latency-svc-gxjbh
Sep  6 11:57:16.503: INFO: Got endpoints: latency-svc-wqcmm [749.542018ms]
Sep  6 11:57:16.512: INFO: Created: latency-svc-xjk76
Sep  6 11:57:16.553: INFO: Got endpoints: latency-svc-5fqh7 [748.946388ms]
Sep  6 11:57:16.564: INFO: Created: latency-svc-pjp4b
Sep  6 11:57:16.603: INFO: Got endpoints: latency-svc-hqjbm [750.079947ms]
Sep  6 11:57:16.613: INFO: Created: latency-svc-b7clc
Sep  6 11:57:16.654: INFO: Got endpoints: latency-svc-tggjm [751.076946ms]
Sep  6 11:57:16.665: INFO: Created: latency-svc-b44h2
Sep  6 11:57:16.703: INFO: Got endpoints: latency-svc-rrgbw [743.423406ms]
Sep  6 11:57:16.727: INFO: Created: latency-svc-nll9b
Sep  6 11:57:16.753: INFO: Got endpoints: latency-svc-pmq92 [749.327373ms]
Sep  6 11:57:16.767: INFO: Created: latency-svc-slnn9
Sep  6 11:57:16.805: INFO: Got endpoints: latency-svc-xdk6q [743.053667ms]
Sep  6 11:57:16.840: INFO: Created: latency-svc-hdr4j
Sep  6 11:57:16.854: INFO: Got endpoints: latency-svc-h8jwt [746.746347ms]
Sep  6 11:57:16.865: INFO: Created: latency-svc-stmrf
Sep  6 11:57:16.905: INFO: Got endpoints: latency-svc-s5gk8 [748.018529ms]
Sep  6 11:57:16.921: INFO: Created: latency-svc-5h9d5
Sep  6 11:57:16.953: INFO: Got endpoints: latency-svc-wk5bs [750.115651ms]
Sep  6 11:57:16.961: INFO: Created: latency-svc-djzcc
Sep  6 11:57:17.007: INFO: Got endpoints: latency-svc-gvxhw [753.113158ms]
Sep  6 11:57:17.017: INFO: Created: latency-svc-mcb27
Sep  6 11:57:17.054: INFO: Got endpoints: latency-svc-wfq9d [742.969378ms]
Sep  6 11:57:17.066: INFO: Created: latency-svc-77sjw
Sep  6 11:57:17.104: INFO: Got endpoints: latency-svc-56dzb [748.131347ms]
Sep  6 11:57:17.113: INFO: Created: latency-svc-pzxbg
Sep  6 11:57:17.154: INFO: Got endpoints: latency-svc-fxxsl [750.89306ms]
Sep  6 11:57:17.169: INFO: Created: latency-svc-kr5jz
Sep  6 11:57:17.205: INFO: Got endpoints: latency-svc-gxjbh [750.707324ms]
Sep  6 11:57:17.226: INFO: Created: latency-svc-4pc6d
Sep  6 11:57:17.258: INFO: Got endpoints: latency-svc-xjk76 [754.937162ms]
Sep  6 11:57:17.270: INFO: Created: latency-svc-b8clz
Sep  6 11:57:17.304: INFO: Got endpoints: latency-svc-pjp4b [750.267734ms]
Sep  6 11:57:17.319: INFO: Created: latency-svc-zhcnn
Sep  6 11:57:17.354: INFO: Got endpoints: latency-svc-b7clc [750.359569ms]
Sep  6 11:57:17.382: INFO: Created: latency-svc-744dw
Sep  6 11:57:17.405: INFO: Got endpoints: latency-svc-b44h2 [750.110465ms]
Sep  6 11:57:17.419: INFO: Created: latency-svc-dqscz
Sep  6 11:57:17.453: INFO: Got endpoints: latency-svc-nll9b [750.256074ms]
Sep  6 11:57:17.462: INFO: Created: latency-svc-9wl7c
Sep  6 11:57:17.505: INFO: Got endpoints: latency-svc-slnn9 [752.118844ms]
Sep  6 11:57:17.517: INFO: Created: latency-svc-n66f4
Sep  6 11:57:17.554: INFO: Got endpoints: latency-svc-hdr4j [748.882148ms]
Sep  6 11:57:17.569: INFO: Created: latency-svc-8qkqb
Sep  6 11:57:17.606: INFO: Got endpoints: latency-svc-stmrf [752.649068ms]
Sep  6 11:57:17.622: INFO: Created: latency-svc-98g2t
Sep  6 11:57:17.655: INFO: Got endpoints: latency-svc-5h9d5 [749.914276ms]
Sep  6 11:57:17.675: INFO: Created: latency-svc-8s5w4
Sep  6 11:57:17.714: INFO: Got endpoints: latency-svc-djzcc [760.511185ms]
Sep  6 11:57:17.745: INFO: Created: latency-svc-dzv7t
Sep  6 11:57:17.755: INFO: Got endpoints: latency-svc-mcb27 [748.291833ms]
Sep  6 11:57:17.774: INFO: Created: latency-svc-cbxx8
Sep  6 11:57:17.806: INFO: Got endpoints: latency-svc-77sjw [752.647496ms]
Sep  6 11:57:17.831: INFO: Created: latency-svc-2t674
Sep  6 11:57:17.854: INFO: Got endpoints: latency-svc-pzxbg [750.405416ms]
Sep  6 11:57:17.874: INFO: Created: latency-svc-hcg8n
Sep  6 11:57:17.904: INFO: Got endpoints: latency-svc-kr5jz [749.15836ms]
Sep  6 11:57:17.920: INFO: Created: latency-svc-7r559
Sep  6 11:57:17.953: INFO: Got endpoints: latency-svc-4pc6d [748.584497ms]
Sep  6 11:57:17.962: INFO: Created: latency-svc-tbzdn
Sep  6 11:57:18.007: INFO: Got endpoints: latency-svc-b8clz [748.883313ms]
Sep  6 11:57:18.018: INFO: Created: latency-svc-tklvz
Sep  6 11:57:18.085: INFO: Got endpoints: latency-svc-zhcnn [781.331391ms]
Sep  6 11:57:18.145: INFO: Got endpoints: latency-svc-744dw [790.810666ms]
Sep  6 11:57:18.147: INFO: Created: latency-svc-gkk6g
Sep  6 11:57:18.155: INFO: Got endpoints: latency-svc-dqscz [750.391528ms]
Sep  6 11:57:18.167: INFO: Created: latency-svc-rz2sj
Sep  6 11:57:18.181: INFO: Created: latency-svc-qk6kl
Sep  6 11:57:18.204: INFO: Got endpoints: latency-svc-9wl7c [750.503157ms]
Sep  6 11:57:18.230: INFO: Created: latency-svc-2s8g5
Sep  6 11:57:18.255: INFO: Got endpoints: latency-svc-n66f4 [749.740209ms]
Sep  6 11:57:18.268: INFO: Created: latency-svc-g9ddq
Sep  6 11:57:18.312: INFO: Got endpoints: latency-svc-8qkqb [757.929566ms]
Sep  6 11:57:18.329: INFO: Created: latency-svc-nbxz9
Sep  6 11:57:18.353: INFO: Got endpoints: latency-svc-98g2t [747.10698ms]
Sep  6 11:57:18.364: INFO: Created: latency-svc-jmjfx
Sep  6 11:57:18.407: INFO: Got endpoints: latency-svc-8s5w4 [751.859511ms]
Sep  6 11:57:18.425: INFO: Created: latency-svc-4l2fl
Sep  6 11:57:18.455: INFO: Got endpoints: latency-svc-dzv7t [741.344222ms]
Sep  6 11:57:18.485: INFO: Created: latency-svc-dbwqv
Sep  6 11:57:18.504: INFO: Got endpoints: latency-svc-cbxx8 [748.41044ms]
Sep  6 11:57:18.519: INFO: Created: latency-svc-2kzmd
Sep  6 11:57:18.555: INFO: Got endpoints: latency-svc-2t674 [748.297713ms]
Sep  6 11:57:18.587: INFO: Created: latency-svc-vt7r2
Sep  6 11:57:18.605: INFO: Got endpoints: latency-svc-hcg8n [750.288463ms]
Sep  6 11:57:18.615: INFO: Created: latency-svc-n5nxp
Sep  6 11:57:18.657: INFO: Got endpoints: latency-svc-7r559 [752.998875ms]
Sep  6 11:57:18.670: INFO: Created: latency-svc-2hd49
Sep  6 11:57:18.703: INFO: Got endpoints: latency-svc-tbzdn [750.048413ms]
Sep  6 11:57:18.712: INFO: Created: latency-svc-cjsq4
Sep  6 11:57:18.754: INFO: Got endpoints: latency-svc-tklvz [746.932052ms]
Sep  6 11:57:18.770: INFO: Created: latency-svc-dp7xc
Sep  6 11:57:18.807: INFO: Got endpoints: latency-svc-gkk6g [722.066657ms]
Sep  6 11:57:18.827: INFO: Created: latency-svc-lnc4f
Sep  6 11:57:18.859: INFO: Got endpoints: latency-svc-rz2sj [714.5343ms]
Sep  6 11:57:18.878: INFO: Created: latency-svc-6nf24
Sep  6 11:57:18.908: INFO: Got endpoints: latency-svc-qk6kl [752.674397ms]
Sep  6 11:57:18.918: INFO: Created: latency-svc-qdkbr
Sep  6 11:57:18.954: INFO: Got endpoints: latency-svc-2s8g5 [749.516784ms]
Sep  6 11:57:18.969: INFO: Created: latency-svc-62wbq
Sep  6 11:57:19.011: INFO: Got endpoints: latency-svc-g9ddq [755.77562ms]
Sep  6 11:57:19.029: INFO: Created: latency-svc-cnrvd
Sep  6 11:57:19.053: INFO: Got endpoints: latency-svc-nbxz9 [740.960613ms]
Sep  6 11:57:19.062: INFO: Created: latency-svc-grvfq
Sep  6 11:57:19.107: INFO: Got endpoints: latency-svc-jmjfx [753.419672ms]
Sep  6 11:57:19.127: INFO: Created: latency-svc-8w6bk
Sep  6 11:57:19.161: INFO: Got endpoints: latency-svc-4l2fl [754.264825ms]
Sep  6 11:57:19.176: INFO: Created: latency-svc-bhh8m
Sep  6 11:57:19.207: INFO: Got endpoints: latency-svc-dbwqv [752.231219ms]
Sep  6 11:57:19.228: INFO: Created: latency-svc-zld4n
Sep  6 11:57:19.262: INFO: Got endpoints: latency-svc-2kzmd [757.911378ms]
Sep  6 11:57:19.294: INFO: Created: latency-svc-8j8nr
Sep  6 11:57:19.325: INFO: Got endpoints: latency-svc-vt7r2 [769.710518ms]
Sep  6 11:57:19.336: INFO: Created: latency-svc-5grsm
Sep  6 11:57:19.356: INFO: Got endpoints: latency-svc-n5nxp [751.450623ms]
Sep  6 11:57:19.365: INFO: Created: latency-svc-j2dwc
Sep  6 11:57:19.404: INFO: Got endpoints: latency-svc-2hd49 [746.870769ms]
Sep  6 11:57:19.415: INFO: Created: latency-svc-l9mkg
Sep  6 11:57:19.455: INFO: Got endpoints: latency-svc-cjsq4 [751.457719ms]
Sep  6 11:57:19.464: INFO: Created: latency-svc-rl7vp
Sep  6 11:57:19.505: INFO: Got endpoints: latency-svc-dp7xc [750.372945ms]
Sep  6 11:57:19.515: INFO: Created: latency-svc-gqczl
Sep  6 11:57:19.553: INFO: Got endpoints: latency-svc-lnc4f [746.063867ms]
Sep  6 11:57:19.572: INFO: Created: latency-svc-599mq
Sep  6 11:57:19.604: INFO: Got endpoints: latency-svc-6nf24 [745.016006ms]
Sep  6 11:57:19.618: INFO: Created: latency-svc-phg9c
Sep  6 11:57:19.659: INFO: Got endpoints: latency-svc-qdkbr [751.369685ms]
Sep  6 11:57:19.709: INFO: Got endpoints: latency-svc-62wbq [755.044689ms]
Sep  6 11:57:19.757: INFO: Got endpoints: latency-svc-cnrvd [746.180918ms]
Sep  6 11:57:19.807: INFO: Got endpoints: latency-svc-grvfq [754.015848ms]
Sep  6 11:57:19.855: INFO: Got endpoints: latency-svc-8w6bk [747.821343ms]
Sep  6 11:57:19.904: INFO: Got endpoints: latency-svc-bhh8m [742.864993ms]
Sep  6 11:57:19.955: INFO: Got endpoints: latency-svc-zld4n [747.70719ms]
Sep  6 11:57:20.007: INFO: Got endpoints: latency-svc-8j8nr [744.890401ms]
Sep  6 11:57:20.054: INFO: Got endpoints: latency-svc-5grsm [729.236815ms]
Sep  6 11:57:20.104: INFO: Got endpoints: latency-svc-j2dwc [748.264791ms]
Sep  6 11:57:20.154: INFO: Got endpoints: latency-svc-l9mkg [750.803679ms]
Sep  6 11:57:20.227: INFO: Got endpoints: latency-svc-rl7vp [772.559951ms]
Sep  6 11:57:20.260: INFO: Got endpoints: latency-svc-gqczl [755.553774ms]
Sep  6 11:57:20.304: INFO: Got endpoints: latency-svc-599mq [750.693506ms]
Sep  6 11:57:20.359: INFO: Got endpoints: latency-svc-phg9c [754.241211ms]
Sep  6 11:57:20.359: INFO: Latencies: [21.367313ms 56.335521ms 68.54833ms 79.978886ms 93.351359ms 99.610268ms 116.835993ms 133.530804ms 163.890991ms 175.287679ms 190.028723ms 202.85422ms 215.944579ms 230.970846ms 245.430718ms 250.437531ms 324.216028ms 335.391737ms 338.992363ms 343.529682ms 348.162603ms 355.236948ms 358.787596ms 369.420135ms 372.377176ms 375.564414ms 376.606861ms 378.690353ms 379.914051ms 380.085928ms 391.866064ms 392.186218ms 392.401899ms 412.07953ms 415.796867ms 415.999969ms 418.045858ms 418.610402ms 419.597698ms 424.947169ms 427.084749ms 428.517381ms 429.42325ms 429.809171ms 433.673407ms 434.773392ms 437.796543ms 441.797109ms 442.40546ms 447.212468ms 454.708569ms 454.726568ms 463.736083ms 467.608254ms 474.259633ms 474.624074ms 477.666148ms 480.312129ms 487.536152ms 493.239596ms 494.291709ms 494.396715ms 502.908318ms 503.084868ms 508.033854ms 513.889334ms 544.692765ms 549.24437ms 551.4843ms 574.422606ms 585.831998ms 644.766949ms 670.999533ms 693.004329ms 701.880122ms 702.033907ms 714.5343ms 722.066657ms 724.615495ms 724.927262ms 725.077487ms 729.236815ms 730.79263ms 732.135581ms 732.926766ms 734.560685ms 739.791356ms 740.326649ms 740.960613ms 741.344222ms 742.864993ms 742.954816ms 742.969378ms 743.053667ms 743.423406ms 743.823408ms 744.432648ms 744.51529ms 744.890401ms 745.016006ms 745.235236ms 745.344508ms 745.709539ms 746.063867ms 746.180918ms 746.746347ms 746.782332ms 746.870769ms 746.932052ms 747.10698ms 747.179516ms 747.70719ms 747.821343ms 748.018529ms 748.131347ms 748.187021ms 748.264791ms 748.291833ms 748.297713ms 748.41044ms 748.514632ms 748.550048ms 748.584497ms 748.717755ms 748.799895ms 748.822478ms 748.882148ms 748.883313ms 748.946388ms 749.088013ms 749.101367ms 749.15836ms 749.327373ms 749.516784ms 749.542018ms 749.740209ms 749.914276ms 750.010024ms 750.048413ms 750.079947ms 750.110465ms 750.115651ms 750.163975ms 750.256074ms 750.267734ms 750.288463ms 750.359569ms 750.372945ms 750.391528ms 750.405416ms 750.503157ms 750.693506ms 750.707324ms 750.803679ms 750.89306ms 750.9251ms 750.957375ms 751.076946ms 751.199858ms 751.369685ms 751.450623ms 751.457719ms 751.859511ms 752.118844ms 752.143306ms 752.231219ms 752.615403ms 752.647496ms 752.649068ms 752.674397ms 752.905645ms 752.998875ms 753.113158ms 753.200687ms 753.215519ms 753.419672ms 753.849291ms 754.015848ms 754.241211ms 754.264825ms 754.937162ms 755.044689ms 755.195479ms 755.33938ms 755.553774ms 755.77562ms 757.911378ms 757.929566ms 758.168251ms 758.307394ms 759.172079ms 760.511185ms 769.710518ms 771.179788ms 772.559951ms 773.63558ms 781.331391ms 784.862255ms 790.810666ms 807.05234ms]
Sep  6 11:57:20.359: INFO: 50 %ile: 745.235236ms
Sep  6 11:57:20.359: INFO: 90 %ile: 754.937162ms
Sep  6 11:57:20.359: INFO: 99 %ile: 790.810666ms
Sep  6 11:57:20.359: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:57:20.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-z7d62" for this suite.
Sep  6 11:57:36.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:57:36.498: INFO: namespace: e2e-tests-svc-latency-z7d62, resource: bindings, ignored listing per whitelist
Sep  6 11:57:36.516: INFO: namespace e2e-tests-svc-latency-z7d62 deletion completed in 16.153475243s

• [SLOW TEST:26.962 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:57:36.516: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  6 11:57:36.642: INFO: Waiting up to 5m0s for pod "downward-api-84b3fc9f-d09d-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-bdblq" to be "success or failure"
Sep  6 11:57:36.661: INFO: Pod "downward-api-84b3fc9f-d09d-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 18.370567ms
Sep  6 11:57:38.666: INFO: Pod "downward-api-84b3fc9f-d09d-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.023916446s
Sep  6 11:57:40.669: INFO: Pod "downward-api-84b3fc9f-d09d-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027034495s
STEP: Saw pod success
Sep  6 11:57:40.669: INFO: Pod "downward-api-84b3fc9f-d09d-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:57:40.672: INFO: Trying to get logs from node metalk8s-22 pod downward-api-84b3fc9f-d09d-11e9-9cef-86a5da7a2260 container dapi-container: <nil>
STEP: delete the pod
Sep  6 11:57:40.690: INFO: Waiting for pod downward-api-84b3fc9f-d09d-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:57:40.696: INFO: Pod downward-api-84b3fc9f-d09d-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:57:40.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bdblq" for this suite.
Sep  6 11:57:46.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:57:46.819: INFO: namespace: e2e-tests-downward-api-bdblq, resource: bindings, ignored listing per whitelist
Sep  6 11:57:46.881: INFO: namespace e2e-tests-downward-api-bdblq deletion completed in 6.181759396s

• [SLOW TEST:10.365 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:57:46.881: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 11:57:46.957: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep  6 11:57:46.970: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep  6 11:57:51.974: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  6 11:57:51.974: INFO: Creating deployment "test-rolling-update-deployment"
Sep  6 11:57:51.978: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep  6 11:57:51.983: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep  6 11:57:53.996: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep  6 11:57:53.998: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  6 11:57:54.006: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-89qpb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-89qpb/deployments/test-rolling-update-deployment,UID:8dd8e882-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9398,Generation:1,CreationTimestamp:2019-09-06 11:57:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-06 11:57:52 +0000 UTC 2019-09-06 11:57:52 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-06 11:57:53 +0000 UTC 2019-09-06 11:57:51 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  6 11:57:54.010: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-89qpb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-89qpb/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:8ddbca0b-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9389,Generation:1,CreationTimestamp:2019-09-06 11:57:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 8dd8e882-d09d-11e9-baa3-fa163efa26fe 0xc002421e57 0xc002421e58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  6 11:57:54.010: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep  6 11:57:54.010: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-89qpb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-89qpb/replicasets/test-rolling-update-controller,UID:8adb55d7-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9397,Generation:2,CreationTimestamp:2019-09-06 11:57:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 8dd8e882-d09d-11e9-baa3-fa163efa26fe 0xc002421d7f 0xc002421d90}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 11:57:54.014: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-7lhr9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-7lhr9,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-89qpb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-89qpb/pods/test-rolling-update-deployment-68b55d7bc6-7lhr9,UID:8ddc4806-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9388,Generation:0,CreationTimestamp:2019-09-06 11:57:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.93/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 8ddbca0b-d09d-11e9-baa3-fa163efa26fe 0xc00222cf17 0xc00222cf18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ck6h6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ck6h6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-ck6h6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00222cf90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00222cfb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:57:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:57:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:57:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:57:52 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.93,StartTime:2019-09-06 11:57:52 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-06 11:57:53 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://23820f7380db4d8e85db492f2d2b0c9ebe8cf647b61e05f059e6de6a5325a160}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:57:54.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-89qpb" for this suite.
Sep  6 11:58:00.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:58:00.072: INFO: namespace: e2e-tests-deployment-89qpb, resource: bindings, ignored listing per whitelist
Sep  6 11:58:00.113: INFO: namespace e2e-tests-deployment-89qpb deletion completed in 6.096382074s

• [SLOW TEST:13.232 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:58:00.113: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Sep  6 11:58:00.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:00.556: INFO: stderr: ""
Sep  6 11:58:00.556: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 11:58:00.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:00.679: INFO: stderr: ""
Sep  6 11:58:00.679: INFO: stdout: "update-demo-nautilus-8tdkw update-demo-nautilus-vqsbf "
Sep  6 11:58:00.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-8tdkw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:00.776: INFO: stderr: ""
Sep  6 11:58:00.776: INFO: stdout: ""
Sep  6 11:58:00.776: INFO: update-demo-nautilus-8tdkw is created but not running
Sep  6 11:58:05.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:05.962: INFO: stderr: ""
Sep  6 11:58:05.962: INFO: stdout: "update-demo-nautilus-8tdkw update-demo-nautilus-vqsbf "
Sep  6 11:58:05.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-8tdkw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:06.103: INFO: stderr: ""
Sep  6 11:58:06.104: INFO: stdout: "true"
Sep  6 11:58:06.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-8tdkw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:06.228: INFO: stderr: ""
Sep  6 11:58:06.228: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 11:58:06.228: INFO: validating pod update-demo-nautilus-8tdkw
Sep  6 11:58:06.233: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 11:58:06.233: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 11:58:06.233: INFO: update-demo-nautilus-8tdkw is verified up and running
Sep  6 11:58:06.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-vqsbf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:06.370: INFO: stderr: ""
Sep  6 11:58:06.370: INFO: stdout: "true"
Sep  6 11:58:06.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-vqsbf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:06.470: INFO: stderr: ""
Sep  6 11:58:06.470: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 11:58:06.470: INFO: validating pod update-demo-nautilus-vqsbf
Sep  6 11:58:06.475: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 11:58:06.475: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 11:58:06.475: INFO: update-demo-nautilus-vqsbf is verified up and running
STEP: scaling down the replication controller
Sep  6 11:58:06.477: INFO: scanned /root for discovery docs: <nil>
Sep  6 11:58:06.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:07.649: INFO: stderr: ""
Sep  6 11:58:07.649: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 11:58:07.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:07.756: INFO: stderr: ""
Sep  6 11:58:07.756: INFO: stdout: "update-demo-nautilus-8tdkw update-demo-nautilus-vqsbf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  6 11:58:12.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:12.844: INFO: stderr: ""
Sep  6 11:58:12.844: INFO: stdout: "update-demo-nautilus-vqsbf "
Sep  6 11:58:12.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-vqsbf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:13.048: INFO: stderr: ""
Sep  6 11:58:13.048: INFO: stdout: "true"
Sep  6 11:58:13.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-vqsbf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:13.198: INFO: stderr: ""
Sep  6 11:58:13.198: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 11:58:13.198: INFO: validating pod update-demo-nautilus-vqsbf
Sep  6 11:58:13.204: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 11:58:13.204: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 11:58:13.204: INFO: update-demo-nautilus-vqsbf is verified up and running
STEP: scaling up the replication controller
Sep  6 11:58:13.206: INFO: scanned /root for discovery docs: <nil>
Sep  6 11:58:13.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:14.383: INFO: stderr: ""
Sep  6 11:58:14.383: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 11:58:14.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:14.505: INFO: stderr: ""
Sep  6 11:58:14.505: INFO: stdout: "update-demo-nautilus-np792 update-demo-nautilus-vqsbf "
Sep  6 11:58:14.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-np792 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:14.606: INFO: stderr: ""
Sep  6 11:58:14.606: INFO: stdout: ""
Sep  6 11:58:14.606: INFO: update-demo-nautilus-np792 is created but not running
Sep  6 11:58:19.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:19.724: INFO: stderr: ""
Sep  6 11:58:19.724: INFO: stdout: "update-demo-nautilus-np792 update-demo-nautilus-vqsbf "
Sep  6 11:58:19.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-np792 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:19.849: INFO: stderr: ""
Sep  6 11:58:19.849: INFO: stdout: "true"
Sep  6 11:58:19.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-np792 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:19.981: INFO: stderr: ""
Sep  6 11:58:19.981: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 11:58:19.981: INFO: validating pod update-demo-nautilus-np792
Sep  6 11:58:19.985: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 11:58:19.985: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 11:58:19.985: INFO: update-demo-nautilus-np792 is verified up and running
Sep  6 11:58:19.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-vqsbf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:20.073: INFO: stderr: ""
Sep  6 11:58:20.073: INFO: stdout: "true"
Sep  6 11:58:20.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-vqsbf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:20.196: INFO: stderr: ""
Sep  6 11:58:20.196: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 11:58:20.196: INFO: validating pod update-demo-nautilus-vqsbf
Sep  6 11:58:20.202: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 11:58:20.202: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 11:58:20.202: INFO: update-demo-nautilus-vqsbf is verified up and running
STEP: using delete to clean up resources
Sep  6 11:58:20.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:20.349: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 11:58:20.349: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  6 11:58:20.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-qgc27'
Sep  6 11:58:20.519: INFO: stderr: "No resources found.\n"
Sep  6 11:58:20.519: INFO: stdout: ""
Sep  6 11:58:20.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -l name=update-demo --namespace=e2e-tests-kubectl-qgc27 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  6 11:58:20.645: INFO: stderr: ""
Sep  6 11:58:20.645: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:58:20.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qgc27" for this suite.
Sep  6 11:58:42.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:58:42.801: INFO: namespace: e2e-tests-kubectl-qgc27, resource: bindings, ignored listing per whitelist
Sep  6 11:58:42.821: INFO: namespace e2e-tests-kubectl-qgc27 deletion completed in 22.169756314s

• [SLOW TEST:42.708 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:58:42.821: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 11:58:42.930: INFO: Creating deployment "nginx-deployment"
Sep  6 11:58:42.935: INFO: Waiting for observed generation 1
Sep  6 11:58:44.945: INFO: Waiting for all required pods to come up
Sep  6 11:58:44.954: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep  6 11:58:50.989: INFO: Waiting for deployment "nginx-deployment" to complete
Sep  6 11:58:50.994: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep  6 11:58:51.000: INFO: Updating deployment nginx-deployment
Sep  6 11:58:51.000: INFO: Waiting for observed generation 2
Sep  6 11:58:53.010: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep  6 11:58:53.012: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep  6 11:58:53.014: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  6 11:58:53.029: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep  6 11:58:53.029: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep  6 11:58:53.032: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  6 11:58:53.036: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep  6 11:58:53.036: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep  6 11:58:53.043: INFO: Updating deployment nginx-deployment
Sep  6 11:58:53.043: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep  6 11:58:53.048: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep  6 11:58:53.051: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  6 11:58:53.060: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rkbl7/deployments/nginx-deployment,UID:ac382c2f-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9880,Generation:3,CreationTimestamp:2019-09-06 11:58:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-09-06 11:58:51 +0000 UTC 2019-09-06 11:58:42 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-09-06 11:58:53 +0000 UTC 2019-09-06 11:58:53 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep  6 11:58:53.068: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rkbl7/replicasets/nginx-deployment-65bbdb5f8,UID:b107c93d-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9876,Generation:3,CreationTimestamp:2019-09-06 11:58:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment ac382c2f-d09d-11e9-baa3-fa163efa26fe 0xc000dad1d7 0xc000dad1d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 11:58:53.068: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep  6 11:58:53.068: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rkbl7/replicasets/nginx-deployment-555b55d965,UID:ac39d2c5-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9875,Generation:3,CreationTimestamp:2019-09-06 11:58:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment ac382c2f-d09d-11e9-baa3-fa163efa26fe 0xc000dad0e7 0xc000dad0e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep  6 11:58:53.093: INFO: Pod "nginx-deployment-555b55d965-2pjqj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2pjqj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-2pjqj,UID:ac459bde-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9740,Generation:0,CreationTimestamp:2019-09-06 11:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.98/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000e1db60 0xc000e1db61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e1dbf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e1dc40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.98,StartTime:2019-09-06 11:58:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 11:58:45 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://e49a89e5217e908615fea01663b2700109e9719b704522a68c4ab303e9ac1f96}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.094: INFO: Pod "nginx-deployment-555b55d965-6rhnk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6rhnk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-6rhnk,UID:b242ae6b-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9890,Generation:0,CreationTimestamp:2019-09-06 11:58:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000e1dda0 0xc000e1dda1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e1de30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e1dea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.094: INFO: Pod "nginx-deployment-555b55d965-79cxb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-79cxb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-79cxb,UID:ac51c54e-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9770,Generation:0,CreationTimestamp:2019-09-06 11:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.104/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000e1df17 0xc000e1df18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000492370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0004923b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.104,StartTime:2019-09-06 11:58:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 11:58:46 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://82fabbe976155c366dabafaaf74e11d4a10b5097782a80b8f21664420fa88b0d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.095: INFO: Pod "nginx-deployment-555b55d965-87n9m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-87n9m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-87n9m,UID:ac4a6416-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9750,Generation:0,CreationTimestamp:2019-09-06 11:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.101/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000492560 0xc000492561}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000492660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0004926a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.101,StartTime:2019-09-06 11:58:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 11:58:46 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://37b38a31b9508e7a442368b65ab3f0b915ccfdb2cb20d562806a0146488b2b50}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.095: INFO: Pod "nginx-deployment-555b55d965-8b7rg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8b7rg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-8b7rg,UID:b242bf48-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9892,Generation:0,CreationTimestamp:2019-09-06 11:58:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc0004928a0 0xc0004928a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000492a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000492a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.095: INFO: Pod "nginx-deployment-555b55d965-8c2qd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8c2qd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-8c2qd,UID:ac51c78f-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9755,Generation:0,CreationTimestamp:2019-09-06 11:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.100/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000492af7 0xc000492af8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000492fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000492fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.100,StartTime:2019-09-06 11:58:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 11:58:45 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://bca3ebfa38f35c034d207acc95b4ac4522f3a21a029015878b00b5d2d4382e1b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.095: INFO: Pod "nginx-deployment-555b55d965-8z7vm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8z7vm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-8z7vm,UID:ac556b94-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9767,Generation:0,CreationTimestamp:2019-09-06 11:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.102/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000493730 0xc000493731}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000493840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000493860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.102,StartTime:2019-09-06 11:58:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 11:58:46 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://4545158165896adbbceeb255aa190d1df5fe4db175b7de2434375a7e13123a37}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.095: INFO: Pod "nginx-deployment-555b55d965-g5w7q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g5w7q,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-g5w7q,UID:ac41fb6c-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9727,Generation:0,CreationTimestamp:2019-09-06 11:58:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.97/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000493a80 0xc000493a81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000493c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000493cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.97,StartTime:2019-09-06 11:58:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 11:58:44 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://1e83344ed85b4a87cd0d03937a5e55b26bda8d577d573b0af915ad45f0360068}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.095: INFO: Pod "nginx-deployment-555b55d965-gw9fm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gw9fm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-gw9fm,UID:b241754b-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9884,Generation:0,CreationTimestamp:2019-09-06 11:58:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000493e70 0xc000493e71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000378560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000378680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.096: INFO: Pod "nginx-deployment-555b55d965-ltc8q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ltc8q,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-ltc8q,UID:ac51e9f6-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9733,Generation:0,CreationTimestamp:2019-09-06 11:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.99/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc0003790e0 0xc0003790e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000054680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0000546f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.99,StartTime:2019-09-06 11:58:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 11:58:45 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://0ee5f7689fccd7cdc26ae4da8783b28f5926ba0a9a7daba8007560ce2a4c6dc7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.096: INFO: Pod "nginx-deployment-555b55d965-nv2jn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nv2jn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-nv2jn,UID:b2418a70-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9887,Generation:0,CreationTimestamp:2019-09-06 11:58:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc0000548d0 0xc0000548d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000054b70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000054ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.096: INFO: Pod "nginx-deployment-555b55d965-pqwsn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pqwsn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-pqwsn,UID:b2428824-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9886,Generation:0,CreationTimestamp:2019-09-06 11:58:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000054c80 0xc000054c81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000054d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000054d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.096: INFO: Pod "nginx-deployment-555b55d965-q4gm8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q4gm8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-q4gm8,UID:b242bd8d-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9891,Generation:0,CreationTimestamp:2019-09-06 11:58:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000054e27 0xc000054e28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000055610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000055650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.096: INFO: Pod "nginx-deployment-555b55d965-sxhwn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-sxhwn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-sxhwn,UID:ac55961a-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9773,Generation:0,CreationTimestamp:2019-09-06 11:58:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.105/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc0000556c7 0xc0000556c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0000557d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0000558a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:43 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.105,StartTime:2019-09-06 11:58:43 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 11:58:46 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://a860b1b528f80f78e045b66b9c9bed42a5b0f621a0fee1b7e5cb8d0df24ecf4c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.096: INFO: Pod "nginx-deployment-555b55d965-x5kc9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-x5kc9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-x5kc9,UID:b243ef01-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9894,Generation:0,CreationTimestamp:2019-09-06 11:58:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000055a20 0xc000055a21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000055ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000055ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.096: INFO: Pod "nginx-deployment-555b55d965-xcvtt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xcvtt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-555b55d965-xcvtt,UID:b240b446-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9882,Generation:0,CreationTimestamp:2019-09-06 11:58:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ac39d2c5-d09d-11e9-baa3-fa163efa26fe 0xc000055d37 0xc000055d38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000055dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000055de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:53 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.098: INFO: Pod "nginx-deployment-65bbdb5f8-295rt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-295rt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-65bbdb5f8-295rt,UID:b2436960-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9893,Generation:0,CreationTimestamp:2019-09-06 11:58:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b107c93d-d09d-11e9-baa3-fa163efa26fe 0xc000055e70 0xc000055e71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000055ef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000055f10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.098: INFO: Pod "nginx-deployment-65bbdb5f8-bsg8n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bsg8n,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-65bbdb5f8-bsg8n,UID:b10895b7-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9836,Generation:0,CreationTimestamp:2019-09-06 11:58:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.107/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b107c93d-d09d-11e9-baa3-fa163efa26fe 0xc000055f67 0xc000055f68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000447a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000447a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:,StartTime:2019-09-06 11:58:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.098: INFO: Pod "nginx-deployment-65bbdb5f8-k2cjc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-k2cjc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-65bbdb5f8-k2cjc,UID:b11cd5af-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9846,Generation:0,CreationTimestamp:2019-09-06 11:58:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.108/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b107c93d-d09d-11e9-baa3-fa163efa26fe 0xc0003105b0 0xc0003105b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000310c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000310ca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:,StartTime:2019-09-06 11:58:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.098: INFO: Pod "nginx-deployment-65bbdb5f8-nh8v7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-nh8v7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-65bbdb5f8-nh8v7,UID:b10aabb5-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9860,Generation:0,CreationTimestamp:2019-09-06 11:58:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.109/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b107c93d-d09d-11e9-baa3-fa163efa26fe 0xc000311130 0xc000311131}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000311280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000311540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:,StartTime:2019-09-06 11:58:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.098: INFO: Pod "nginx-deployment-65bbdb5f8-v7m4t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-v7m4t,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-65bbdb5f8-v7m4t,UID:b11e5e15-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9866,Generation:0,CreationTimestamp:2019-09-06 11:58:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.110/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b107c93d-d09d-11e9-baa3-fa163efa26fe 0xc000311d40 0xc000311d41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001836060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018361e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:,StartTime:2019-09-06 11:58:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  6 11:58:53.098: INFO: Pod "nginx-deployment-65bbdb5f8-xgrhb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xgrhb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-rkbl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rkbl7/pods/nginx-deployment-65bbdb5f8-xgrhb,UID:b10a8e3e-d09d-11e9-baa3-fa163efa26fe,ResourceVersion:9867,Generation:0,CreationTimestamp:2019-09-06 11:58:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.111/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b107c93d-d09d-11e9-baa3-fa163efa26fe 0xc001836390 0xc001836391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zck4m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zck4m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zck4m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001836410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001836430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 11:58:51 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:,StartTime:2019-09-06 11:58:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:58:53.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rkbl7" for this suite.
Sep  6 11:59:01.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:59:01.260: INFO: namespace: e2e-tests-deployment-rkbl7, resource: bindings, ignored listing per whitelist
Sep  6 11:59:01.442: INFO: namespace e2e-tests-deployment-rkbl7 deletion completed in 8.333503897s

• [SLOW TEST:18.620 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:59:01.442: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b75540b6-d09d-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 11:59:01.592: INFO: Waiting up to 5m0s for pod "pod-secrets-b756690a-d09d-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-secrets-nc6g8" to be "success or failure"
Sep  6 11:59:01.596: INFO: Pod "pod-secrets-b756690a-d09d-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 3.896994ms
Sep  6 11:59:03.602: INFO: Pod "pod-secrets-b756690a-d09d-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010133766s
Sep  6 11:59:05.608: INFO: Pod "pod-secrets-b756690a-d09d-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016627028s
Sep  6 11:59:07.619: INFO: Pod "pod-secrets-b756690a-d09d-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 6.027643902s
Sep  6 11:59:09.624: INFO: Pod "pod-secrets-b756690a-d09d-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 8.031760611s
Sep  6 11:59:11.627: INFO: Pod "pod-secrets-b756690a-d09d-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.035520114s
STEP: Saw pod success
Sep  6 11:59:11.627: INFO: Pod "pod-secrets-b756690a-d09d-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 11:59:11.630: INFO: Trying to get logs from node metalk8s-22 pod pod-secrets-b756690a-d09d-11e9-9cef-86a5da7a2260 container secret-env-test: <nil>
STEP: delete the pod
Sep  6 11:59:11.649: INFO: Waiting for pod pod-secrets-b756690a-d09d-11e9-9cef-86a5da7a2260 to disappear
Sep  6 11:59:11.658: INFO: Pod pod-secrets-b756690a-d09d-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:59:11.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nc6g8" for this suite.
Sep  6 11:59:17.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:59:17.698: INFO: namespace: e2e-tests-secrets-nc6g8, resource: bindings, ignored listing per whitelist
Sep  6 11:59:17.837: INFO: namespace e2e-tests-secrets-nc6g8 deletion completed in 6.174800437s

• [SLOW TEST:16.395 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:59:17.837: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 11:59:17.954: INFO: (0) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 14.831968ms)
Sep  6 11:59:17.958: INFO: (1) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.555965ms)
Sep  6 11:59:17.963: INFO: (2) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.724835ms)
Sep  6 11:59:17.967: INFO: (3) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.248764ms)
Sep  6 11:59:17.972: INFO: (4) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.600664ms)
Sep  6 11:59:17.980: INFO: (5) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.315963ms)
Sep  6 11:59:17.988: INFO: (6) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.853395ms)
Sep  6 11:59:17.995: INFO: (7) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.423884ms)
Sep  6 11:59:18.001: INFO: (8) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.927225ms)
Sep  6 11:59:18.006: INFO: (9) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.754111ms)
Sep  6 11:59:18.011: INFO: (10) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.162424ms)
Sep  6 11:59:18.015: INFO: (11) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.829525ms)
Sep  6 11:59:18.020: INFO: (12) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.033667ms)
Sep  6 11:59:18.025: INFO: (13) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.222967ms)
Sep  6 11:59:18.030: INFO: (14) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.675208ms)
Sep  6 11:59:18.035: INFO: (15) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.156195ms)
Sep  6 11:59:18.040: INFO: (16) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.119747ms)
Sep  6 11:59:18.045: INFO: (17) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.479081ms)
Sep  6 11:59:18.049: INFO: (18) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.020683ms)
Sep  6 11:59:18.054: INFO: (19) /api/v1/nodes/metalk8s-22/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.118032ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:59:18.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-czvbv" for this suite.
Sep  6 11:59:24.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:59:24.085: INFO: namespace: e2e-tests-proxy-czvbv, resource: bindings, ignored listing per whitelist
Sep  6 11:59:24.184: INFO: namespace e2e-tests-proxy-czvbv deletion completed in 6.127174535s

• [SLOW TEST:6.347 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:59:24.184: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Sep  6 11:59:24.266: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-878575678 proxy --unix-socket=/tmp/kubectl-proxy-unix434343557/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 11:59:24.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qzgvf" for this suite.
Sep  6 11:59:30.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 11:59:30.452: INFO: namespace: e2e-tests-kubectl-qzgvf, resource: bindings, ignored listing per whitelist
Sep  6 11:59:30.645: INFO: namespace e2e-tests-kubectl-qzgvf deletion completed in 6.258679835s

• [SLOW TEST:6.461 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 11:59:30.645: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-8r9x5
Sep  6 11:59:32.762: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-8r9x5
STEP: checking the pod's current state and verifying that restartCount is present
Sep  6 11:59:32.764: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:03:34.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8r9x5" for this suite.
Sep  6 12:03:40.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:03:40.662: INFO: namespace: e2e-tests-container-probe-8r9x5, resource: bindings, ignored listing per whitelist
Sep  6 12:03:40.716: INFO: namespace e2e-tests-container-probe-8r9x5 deletion completed in 6.133839717s

• [SLOW TEST:250.071 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:03:40.717: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-r7gn
STEP: Creating a pod to test atomic-volume-subpath
Sep  6 12:03:40.836: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-r7gn" in namespace "e2e-tests-subpath-lzdk5" to be "success or failure"
Sep  6 12:03:40.843: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Pending", Reason="", readiness=false. Elapsed: 7.045639ms
Sep  6 12:03:42.864: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027786608s
Sep  6 12:03:44.874: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Running", Reason="", readiness=true. Elapsed: 4.038314527s
Sep  6 12:03:46.878: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Running", Reason="", readiness=false. Elapsed: 6.041809146s
Sep  6 12:03:48.881: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Running", Reason="", readiness=false. Elapsed: 8.044977974s
Sep  6 12:03:50.884: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Running", Reason="", readiness=false. Elapsed: 10.04830945s
Sep  6 12:03:52.887: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Running", Reason="", readiness=false. Elapsed: 12.051468445s
Sep  6 12:03:54.894: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Running", Reason="", readiness=false. Elapsed: 14.05775789s
Sep  6 12:03:56.897: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Running", Reason="", readiness=false. Elapsed: 16.060981389s
Sep  6 12:03:58.900: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Running", Reason="", readiness=false. Elapsed: 18.063942975s
Sep  6 12:04:00.903: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Running", Reason="", readiness=false. Elapsed: 20.067349704s
Sep  6 12:04:02.907: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Running", Reason="", readiness=false. Elapsed: 22.070910993s
Sep  6 12:04:04.912: INFO: Pod "pod-subpath-test-secret-r7gn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.075791326s
STEP: Saw pod success
Sep  6 12:04:04.912: INFO: Pod "pod-subpath-test-secret-r7gn" satisfied condition "success or failure"
Sep  6 12:04:04.915: INFO: Trying to get logs from node metalk8s-22 pod pod-subpath-test-secret-r7gn container test-container-subpath-secret-r7gn: <nil>
STEP: delete the pod
Sep  6 12:04:04.936: INFO: Waiting for pod pod-subpath-test-secret-r7gn to disappear
Sep  6 12:04:04.939: INFO: Pod pod-subpath-test-secret-r7gn no longer exists
STEP: Deleting pod pod-subpath-test-secret-r7gn
Sep  6 12:04:04.939: INFO: Deleting pod "pod-subpath-test-secret-r7gn" in namespace "e2e-tests-subpath-lzdk5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:04:04.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-lzdk5" for this suite.
Sep  6 12:04:10.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:04:11.099: INFO: namespace: e2e-tests-subpath-lzdk5, resource: bindings, ignored listing per whitelist
Sep  6 12:04:11.128: INFO: namespace e2e-tests-subpath-lzdk5 deletion completed in 6.182294891s

• [SLOW TEST:30.412 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:04:11.128: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-nz9sg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nz9sg to expose endpoints map[]
Sep  6 12:04:11.240: INFO: Get endpoints failed (4.777918ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep  6 12:04:12.243: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nz9sg exposes endpoints map[] (1.007773391s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-nz9sg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nz9sg to expose endpoints map[pod1:[100]]
Sep  6 12:04:14.278: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nz9sg exposes endpoints map[pod1:[100]] (2.026238357s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-nz9sg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nz9sg to expose endpoints map[pod1:[100] pod2:[101]]
Sep  6 12:04:16.317: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nz9sg exposes endpoints map[pod1:[100] pod2:[101]] (2.033965534s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-nz9sg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nz9sg to expose endpoints map[pod2:[101]]
Sep  6 12:04:17.359: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nz9sg exposes endpoints map[pod2:[101]] (1.033167197s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-nz9sg
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nz9sg to expose endpoints map[]
Sep  6 12:04:17.377: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nz9sg exposes endpoints map[] (12.16001ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:04:17.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-nz9sg" for this suite.
Sep  6 12:04:23.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:04:23.550: INFO: namespace: e2e-tests-services-nz9sg, resource: bindings, ignored listing per whitelist
Sep  6 12:04:23.555: INFO: namespace e2e-tests-services-nz9sg deletion completed in 6.14148731s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:12.427 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:04:23.555: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 12:04:23.631: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep  6 12:04:28.634: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  6 12:04:28.634: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  6 12:04:28.652: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-569cw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-569cw/deployments/test-cleanup-deployment,UID:7a46f2b6-d09e-11e9-baa3-fa163efa26fe,ResourceVersion:11080,Generation:1,CreationTimestamp:2019-09-06 12:04:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Sep  6 12:04:28.656: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Sep  6 12:04:28.656: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep  6 12:04:28.657: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-569cw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-569cw/replicasets/test-cleanup-controller,UID:77499d44-d09e-11e9-baa3-fa163efa26fe,ResourceVersion:11081,Generation:1,CreationTimestamp:2019-09-06 12:04:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 7a46f2b6-d09e-11e9-baa3-fa163efa26fe 0xc0021de717 0xc0021de718}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  6 12:04:28.670: INFO: Pod "test-cleanup-controller-hklhq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-hklhq,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-569cw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-569cw/pods/test-cleanup-controller-hklhq,UID:774b8423-d09e-11e9-baa3-fa163efa26fe,ResourceVersion:11073,Generation:0,CreationTimestamp:2019-09-06 12:04:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.89/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 77499d44-d09e-11e9-baa3-fa163efa26fe 0xc0021df6c7 0xc0021df6c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cg8lt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cg8lt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cg8lt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021df7a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021df7c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:04:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:04:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:04:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:04:23 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.89,StartTime:2019-09-06 12:04:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-06 12:04:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://65a9aba70a796262c078801c2dcd1bcae25e1658888753a34926a047b4e086d8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:04:28.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-569cw" for this suite.
Sep  6 12:04:34.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:04:34.813: INFO: namespace: e2e-tests-deployment-569cw, resource: bindings, ignored listing per whitelist
Sep  6 12:04:34.826: INFO: namespace e2e-tests-deployment-569cw deletion completed in 6.142952021s

• [SLOW TEST:11.271 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:04:34.826: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-5rl7b
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-5rl7b
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-5rl7b
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-5rl7b
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-5rl7b
Sep  6 12:04:38.960: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-5rl7b, name: ss-0, uid: 80325221-d09e-11e9-baa3-fa163efa26fe, status phase: Pending. Waiting for statefulset controller to delete.
Sep  6 12:04:39.166: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-5rl7b, name: ss-0, uid: 80325221-d09e-11e9-baa3-fa163efa26fe, status phase: Failed. Waiting for statefulset controller to delete.
Sep  6 12:04:39.170: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-5rl7b, name: ss-0, uid: 80325221-d09e-11e9-baa3-fa163efa26fe, status phase: Failed. Waiting for statefulset controller to delete.
Sep  6 12:04:39.177: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-5rl7b
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-5rl7b
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-5rl7b and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  6 12:04:43.209: INFO: Deleting all statefulset in ns e2e-tests-statefulset-5rl7b
Sep  6 12:04:43.212: INFO: Scaling statefulset ss to 0
Sep  6 12:04:53.232: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 12:04:53.234: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:04:53.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-5rl7b" for this suite.
Sep  6 12:04:59.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:04:59.346: INFO: namespace: e2e-tests-statefulset-5rl7b, resource: bindings, ignored listing per whitelist
Sep  6 12:04:59.398: INFO: namespace e2e-tests-statefulset-5rl7b deletion completed in 6.148871405s

• [SLOW TEST:24.572 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:04:59.398: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:04:59.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-fr8hd" for this suite.
Sep  6 12:05:05.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:05:05.747: INFO: namespace: e2e-tests-services-fr8hd, resource: bindings, ignored listing per whitelist
Sep  6 12:05:05.752: INFO: namespace e2e-tests-services-fr8hd deletion completed in 6.237843308s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.354 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:05:05.752: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Sep  6 12:05:06.004: INFO: Waiting up to 5m0s for pod "client-containers-908a1b10-d09e-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-containers-7g5fr" to be "success or failure"
Sep  6 12:05:06.036: INFO: Pod "client-containers-908a1b10-d09e-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 31.851994ms
Sep  6 12:05:08.039: INFO: Pod "client-containers-908a1b10-d09e-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.034984952s
Sep  6 12:05:10.043: INFO: Pod "client-containers-908a1b10-d09e-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038780991s
STEP: Saw pod success
Sep  6 12:05:10.043: INFO: Pod "client-containers-908a1b10-d09e-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:05:10.045: INFO: Trying to get logs from node metalk8s-22 pod client-containers-908a1b10-d09e-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 12:05:10.063: INFO: Waiting for pod client-containers-908a1b10-d09e-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:05:10.065: INFO: Pod client-containers-908a1b10-d09e-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:05:10.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7g5fr" for this suite.
Sep  6 12:05:16.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:05:16.089: INFO: namespace: e2e-tests-containers-7g5fr, resource: bindings, ignored listing per whitelist
Sep  6 12:05:16.189: INFO: namespace e2e-tests-containers-7g5fr deletion completed in 6.120409091s

• [SLOW TEST:10.437 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:05:16.189: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-96ad04fe-d09e-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 12:05:16.350: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-96ae5392-d09e-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-76kxp" to be "success or failure"
Sep  6 12:05:16.414: INFO: Pod "pod-projected-configmaps-96ae5392-d09e-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 64.302261ms
Sep  6 12:05:18.856: INFO: Pod "pod-projected-configmaps-96ae5392-d09e-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.50602278s
Sep  6 12:05:22.037: INFO: Pod "pod-projected-configmaps-96ae5392-d09e-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 5.687314286s
STEP: Saw pod success
Sep  6 12:05:22.037: INFO: Pod "pod-projected-configmaps-96ae5392-d09e-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:05:22.057: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-configmaps-96ae5392-d09e-11e9-9cef-86a5da7a2260 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 12:05:22.128: INFO: Waiting for pod pod-projected-configmaps-96ae5392-d09e-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:05:22.135: INFO: Pod pod-projected-configmaps-96ae5392-d09e-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:05:22.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-76kxp" for this suite.
Sep  6 12:05:28.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:05:28.221: INFO: namespace: e2e-tests-projected-76kxp, resource: bindings, ignored listing per whitelist
Sep  6 12:05:28.272: INFO: namespace e2e-tests-projected-76kxp deletion completed in 6.12936566s

• [SLOW TEST:12.084 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:05:28.273: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:05:32.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-jlzj8" for this suite.
Sep  6 12:06:10.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:06:10.430: INFO: namespace: e2e-tests-kubelet-test-jlzj8, resource: bindings, ignored listing per whitelist
Sep  6 12:06:10.523: INFO: namespace e2e-tests-kubelet-test-jlzj8 deletion completed in 38.144646526s

• [SLOW TEST:42.250 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:06:10.523: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 12:06:10.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-nqcmh'
Sep  6 12:06:10.914: INFO: stderr: ""
Sep  6 12:06:10.914: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep  6 12:06:15.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-nqcmh -o json'
Sep  6 12:06:16.093: INFO: stderr: ""
Sep  6 12:06:16.093: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.233.217.96/32\"\n        },\n        \"creationTimestamp\": \"2019-09-06T12:06:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-nqcmh\",\n        \"resourceVersion\": \"11540\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-nqcmh/pods/e2e-test-nginx-pod\",\n        \"uid\": \"b7388487-d09e-11e9-baa3-fa163efa26fe\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-fmwpk\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"metalk8s-22\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-fmwpk\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-fmwpk\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-06T12:06:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-06T12:06:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-06T12:06:12Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-06T12:06:10Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://20892b1549ddccfffaca6121159e32416ff42fd31bee5d6363f4efb7f37d72f0\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-06T12:06:11Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.0.6\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.217.96\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-06T12:06:10Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep  6 12:06:16.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 replace -f - --namespace=e2e-tests-kubectl-nqcmh'
Sep  6 12:06:16.398: INFO: stderr: ""
Sep  6 12:06:16.398: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Sep  6 12:06:16.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-nqcmh'
Sep  6 12:06:18.082: INFO: stderr: ""
Sep  6 12:06:18.082: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:06:18.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nqcmh" for this suite.
Sep  6 12:06:24.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:06:24.125: INFO: namespace: e2e-tests-kubectl-nqcmh, resource: bindings, ignored listing per whitelist
Sep  6 12:06:24.246: INFO: namespace e2e-tests-kubectl-nqcmh deletion completed in 6.154309975s

• [SLOW TEST:13.723 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:06:24.247: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  6 12:06:28.416: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  6 12:06:28.425: INFO: Pod pod-with-poststart-http-hook still exists
Sep  6 12:06:30.427: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  6 12:06:30.430: INFO: Pod pod-with-poststart-http-hook still exists
Sep  6 12:06:32.427: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  6 12:06:32.432: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:06:32.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-hs98w" for this suite.
Sep  6 12:06:54.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:06:54.580: INFO: namespace: e2e-tests-container-lifecycle-hook-hs98w, resource: bindings, ignored listing per whitelist
Sep  6 12:06:54.652: INFO: namespace e2e-tests-container-lifecycle-hook-hs98w deletion completed in 22.215363654s

• [SLOW TEST:30.405 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:06:54.652: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Sep  6 12:06:54.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-djpbr'
Sep  6 12:06:55.006: INFO: stderr: ""
Sep  6 12:06:55.007: INFO: stdout: "pod/pause created\n"
Sep  6 12:06:55.007: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep  6 12:06:55.007: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-djpbr" to be "running and ready"
Sep  6 12:06:55.039: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 31.974797ms
Sep  6 12:06:57.048: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.041148235s
Sep  6 12:06:57.048: INFO: Pod "pause" satisfied condition "running and ready"
Sep  6 12:06:57.048: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Sep  6 12:06:57.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-djpbr'
Sep  6 12:06:57.234: INFO: stderr: ""
Sep  6 12:06:57.234: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep  6 12:06:57.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pod pause -L testing-label --namespace=e2e-tests-kubectl-djpbr'
Sep  6 12:06:57.372: INFO: stderr: ""
Sep  6 12:06:57.372: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep  6 12:06:57.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 label pods pause testing-label- --namespace=e2e-tests-kubectl-djpbr'
Sep  6 12:06:57.508: INFO: stderr: ""
Sep  6 12:06:57.508: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep  6 12:06:57.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pod pause -L testing-label --namespace=e2e-tests-kubectl-djpbr'
Sep  6 12:06:57.647: INFO: stderr: ""
Sep  6 12:06:57.647: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Sep  6 12:06:57.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-djpbr'
Sep  6 12:06:57.846: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 12:06:57.846: INFO: stdout: "pod \"pause\" force deleted\n"
Sep  6 12:06:57.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-djpbr'
Sep  6 12:06:58.045: INFO: stderr: "No resources found.\n"
Sep  6 12:06:58.045: INFO: stdout: ""
Sep  6 12:06:58.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -l name=pause --namespace=e2e-tests-kubectl-djpbr -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  6 12:06:58.222: INFO: stderr: ""
Sep  6 12:06:58.222: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:06:58.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-djpbr" for this suite.
Sep  6 12:07:04.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:07:04.296: INFO: namespace: e2e-tests-kubectl-djpbr, resource: bindings, ignored listing per whitelist
Sep  6 12:07:04.396: INFO: namespace e2e-tests-kubectl-djpbr deletion completed in 6.169278078s

• [SLOW TEST:9.744 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:07:04.396: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9jxrz A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9jxrz;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9jxrz A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9jxrz;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9jxrz.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9jxrz.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9jxrz.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9jxrz.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9jxrz.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-9jxrz.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9jxrz.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-9jxrz.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9jxrz.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 21.120.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.120.21_udp@PTR;check="$$(dig +tcp +noall +answer +search 21.120.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.120.21_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9jxrz A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9jxrz;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9jxrz A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9jxrz;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9jxrz.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9jxrz.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9jxrz.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9jxrz.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9jxrz.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-9jxrz.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9jxrz.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-9jxrz.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9jxrz.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 21.120.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.120.21_udp@PTR;check="$$(dig +tcp +noall +answer +search 21.120.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.120.21_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  6 12:07:16.556: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.566: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.570: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9jxrz from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.578: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9jxrz from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.584: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9jxrz.svc from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.588: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9jxrz.svc from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.592: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.597: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.636: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.640: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.650: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9jxrz from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.655: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9jxrz from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.662: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9jxrz.svc from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.666: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9jxrz.svc from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.671: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.675: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc from pod e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260: the server could not find the requested resource (get pods dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260)
Sep  6 12:07:16.709: INFO: Lookups using e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-9jxrz wheezy_tcp@dns-test-service.e2e-tests-dns-9jxrz wheezy_udp@dns-test-service.e2e-tests-dns-9jxrz.svc wheezy_tcp@dns-test-service.e2e-tests-dns-9jxrz.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-9jxrz jessie_tcp@dns-test-service.e2e-tests-dns-9jxrz jessie_udp@dns-test-service.e2e-tests-dns-9jxrz.svc jessie_tcp@dns-test-service.e2e-tests-dns-9jxrz.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9jxrz.svc]

Sep  6 12:07:21.865: INFO: DNS probes using e2e-tests-dns-9jxrz/dns-test-d72e82d5-d09e-11e9-9cef-86a5da7a2260 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:07:22.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-9jxrz" for this suite.
Sep  6 12:07:28.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:07:28.111: INFO: namespace: e2e-tests-dns-9jxrz, resource: bindings, ignored listing per whitelist
Sep  6 12:07:28.151: INFO: namespace e2e-tests-dns-9jxrz deletion completed in 6.110280305s

• [SLOW TEST:23.754 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:07:28.151: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-pgzhq
Sep  6 12:07:30.254: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-pgzhq
STEP: checking the pod's current state and verifying that restartCount is present
Sep  6 12:07:30.257: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:11:31.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pgzhq" for this suite.
Sep  6 12:11:37.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:11:37.059: INFO: namespace: e2e-tests-container-probe-pgzhq, resource: bindings, ignored listing per whitelist
Sep  6 12:11:37.135: INFO: namespace e2e-tests-container-probe-pgzhq deletion completed in 6.119507192s

• [SLOW TEST:248.985 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:11:37.136: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 12:11:37.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-4z264'
Sep  6 12:11:37.503: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  6 12:11:37.503: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep  6 12:11:37.517: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-4sph9]
Sep  6 12:11:37.517: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-4sph9" in namespace "e2e-tests-kubectl-4z264" to be "running and ready"
Sep  6 12:11:37.534: INFO: Pod "e2e-test-nginx-rc-4sph9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.738181ms
Sep  6 12:11:39.537: INFO: Pod "e2e-test-nginx-rc-4sph9": Phase="Running", Reason="", readiness=true. Elapsed: 2.020468225s
Sep  6 12:11:39.537: INFO: Pod "e2e-test-nginx-rc-4sph9" satisfied condition "running and ready"
Sep  6 12:11:39.537: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-4sph9]
Sep  6 12:11:39.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-4z264'
Sep  6 12:11:39.679: INFO: stderr: ""
Sep  6 12:11:39.679: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Sep  6 12:11:39.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-4z264'
Sep  6 12:11:39.841: INFO: stderr: ""
Sep  6 12:11:39.841: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:11:39.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4z264" for this suite.
Sep  6 12:12:01.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:12:01.875: INFO: namespace: e2e-tests-kubectl-4z264, resource: bindings, ignored listing per whitelist
Sep  6 12:12:01.994: INFO: namespace e2e-tests-kubectl-4z264 deletion completed in 22.148512354s

• [SLOW TEST:24.858 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:12:01.994: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-888cb827-d09f-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 12:12:02.100: INFO: Waiting up to 5m0s for pod "pod-configmaps-888e2646-d09f-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-configmap-bnqzv" to be "success or failure"
Sep  6 12:12:02.106: INFO: Pod "pod-configmaps-888e2646-d09f-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 5.461039ms
Sep  6 12:12:04.110: INFO: Pod "pod-configmaps-888e2646-d09f-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010108478s
Sep  6 12:12:06.114: INFO: Pod "pod-configmaps-888e2646-d09f-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013459687s
STEP: Saw pod success
Sep  6 12:12:06.114: INFO: Pod "pod-configmaps-888e2646-d09f-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:12:06.116: INFO: Trying to get logs from node metalk8s-22 pod pod-configmaps-888e2646-d09f-11e9-9cef-86a5da7a2260 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 12:12:06.133: INFO: Waiting for pod pod-configmaps-888e2646-d09f-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:12:06.136: INFO: Pod pod-configmaps-888e2646-d09f-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:12:06.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bnqzv" for this suite.
Sep  6 12:12:12.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:12:12.344: INFO: namespace: e2e-tests-configmap-bnqzv, resource: bindings, ignored listing per whitelist
Sep  6 12:12:12.354: INFO: namespace e2e-tests-configmap-bnqzv deletion completed in 6.215224628s

• [SLOW TEST:10.360 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:12:12.354: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep  6 12:12:17.463: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:12:18.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-lrkh6" for this suite.
Sep  6 12:12:40.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:12:40.603: INFO: namespace: e2e-tests-replicaset-lrkh6, resource: bindings, ignored listing per whitelist
Sep  6 12:12:40.607: INFO: namespace e2e-tests-replicaset-lrkh6 deletion completed in 22.119653901s

• [SLOW TEST:28.253 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:12:40.608: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-9f9064f6-d09f-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 12:12:40.709: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9f9139ee-d09f-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-q78cb" to be "success or failure"
Sep  6 12:12:40.713: INFO: Pod "pod-projected-secrets-9f9139ee-d09f-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 4.587359ms
Sep  6 12:12:42.729: INFO: Pod "pod-projected-secrets-9f9139ee-d09f-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02008653s
STEP: Saw pod success
Sep  6 12:12:42.729: INFO: Pod "pod-projected-secrets-9f9139ee-d09f-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:12:42.736: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-secrets-9f9139ee-d09f-11e9-9cef-86a5da7a2260 container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 12:12:42.802: INFO: Waiting for pod pod-projected-secrets-9f9139ee-d09f-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:12:42.808: INFO: Pod pod-projected-secrets-9f9139ee-d09f-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:12:42.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q78cb" for this suite.
Sep  6 12:12:48.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:12:48.970: INFO: namespace: e2e-tests-projected-q78cb, resource: bindings, ignored listing per whitelist
Sep  6 12:12:48.983: INFO: namespace e2e-tests-projected-q78cb deletion completed in 6.163501901s

• [SLOW TEST:8.375 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:12:48.983: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7n64w
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-7n64w
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-7n64w
Sep  6 12:12:49.092: INFO: Found 0 stateful pods, waiting for 1
Sep  6 12:12:59.110: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep  6 12:12:59.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-7n64w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 12:12:59.475: INFO: stderr: ""
Sep  6 12:12:59.475: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 12:12:59.475: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 12:12:59.480: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  6 12:13:09.879: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 12:13:09.879: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 12:13:09.910: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Sep  6 12:13:09.910: INFO: ss-0  metalk8s-22  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:12:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:12:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:12:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:12:49 +0000 UTC  }]
Sep  6 12:13:09.910: INFO: 
Sep  6 12:13:09.910: INFO: StatefulSet ss has not reached scale 3, at 1
Sep  6 12:13:10.918: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991453779s
Sep  6 12:13:11.923: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.983079109s
Sep  6 12:13:12.928: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978803719s
Sep  6 12:13:13.932: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.973914919s
Sep  6 12:13:14.935: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.969824486s
Sep  6 12:13:15.939: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.966598705s
Sep  6 12:13:16.948: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.962922015s
Sep  6 12:13:17.953: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.95369563s
Sep  6 12:13:18.957: INFO: Verifying statefulset ss doesn't scale past 3 for another 948.688046ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-7n64w
Sep  6 12:13:19.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-7n64w ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:13:20.437: INFO: stderr: ""
Sep  6 12:13:20.437: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 12:13:20.437: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 12:13:20.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-7n64w ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:13:20.748: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Sep  6 12:13:20.748: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 12:13:20.748: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 12:13:20.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-7n64w ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:13:21.073: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Sep  6 12:13:21.073: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 12:13:21.073: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 12:13:21.082: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 12:13:21.082: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 12:13:21.082: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep  6 12:13:21.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-7n64w ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 12:13:21.436: INFO: stderr: ""
Sep  6 12:13:21.436: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 12:13:21.436: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 12:13:21.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-7n64w ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 12:13:21.745: INFO: stderr: ""
Sep  6 12:13:21.745: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 12:13:21.745: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 12:13:21.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-7n64w ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 12:13:22.077: INFO: stderr: ""
Sep  6 12:13:22.077: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 12:13:22.078: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 12:13:22.078: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 12:13:22.080: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep  6 12:13:32.089: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 12:13:32.089: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 12:13:32.089: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 12:13:32.103: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Sep  6 12:13:32.103: INFO: ss-0  metalk8s-22  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:12:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:12:49 +0000 UTC  }]
Sep  6 12:13:32.103: INFO: ss-1  metalk8s-22  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:32.103: INFO: ss-2  metalk8s-22  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:32.103: INFO: 
Sep  6 12:13:32.103: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  6 12:13:33.113: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Sep  6 12:13:33.113: INFO: ss-0  metalk8s-22  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:12:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:12:49 +0000 UTC  }]
Sep  6 12:13:33.113: INFO: ss-1  metalk8s-22  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:33.113: INFO: ss-2  metalk8s-22  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:33.113: INFO: 
Sep  6 12:13:33.113: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  6 12:13:34.121: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Sep  6 12:13:34.121: INFO: ss-0  metalk8s-22  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:12:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:12:49 +0000 UTC  }]
Sep  6 12:13:34.121: INFO: ss-1  metalk8s-22  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:34.121: INFO: ss-2  metalk8s-22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:34.121: INFO: 
Sep  6 12:13:34.121: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  6 12:13:35.127: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Sep  6 12:13:35.127: INFO: ss-1  metalk8s-22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:35.127: INFO: 
Sep  6 12:13:35.127: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 12:13:36.131: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Sep  6 12:13:36.131: INFO: ss-1  metalk8s-22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:36.131: INFO: 
Sep  6 12:13:36.131: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 12:13:37.134: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Sep  6 12:13:37.134: INFO: ss-1  metalk8s-22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:37.134: INFO: 
Sep  6 12:13:37.134: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 12:13:38.141: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Sep  6 12:13:38.141: INFO: ss-1  metalk8s-22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:38.141: INFO: 
Sep  6 12:13:38.141: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 12:13:39.145: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Sep  6 12:13:39.145: INFO: ss-1  metalk8s-22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:39.145: INFO: 
Sep  6 12:13:39.145: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 12:13:40.148: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Sep  6 12:13:40.148: INFO: ss-1  metalk8s-22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:40.148: INFO: 
Sep  6 12:13:40.148: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  6 12:13:41.152: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Sep  6 12:13:41.152: INFO: ss-1  metalk8s-22  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:13:09 +0000 UTC  }]
Sep  6 12:13:41.152: INFO: 
Sep  6 12:13:41.152: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-7n64w
Sep  6 12:13:42.158: INFO: Scaling statefulset ss to 0
Sep  6 12:13:42.169: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  6 12:13:42.173: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7n64w
Sep  6 12:13:42.175: INFO: Scaling statefulset ss to 0
Sep  6 12:13:42.184: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 12:13:42.187: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:13:42.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7n64w" for this suite.
Sep  6 12:13:48.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:13:48.300: INFO: namespace: e2e-tests-statefulset-7n64w, resource: bindings, ignored listing per whitelist
Sep  6 12:13:48.355: INFO: namespace e2e-tests-statefulset-7n64w deletion completed in 6.13985777s

• [SLOW TEST:59.372 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:13:48.356: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Sep  6 12:13:48.444: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-wlzhg" to be "success or failure"
Sep  6 12:13:48.448: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.358668ms
Sep  6 12:13:50.451: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006834094s
Sep  6 12:13:52.455: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010168535s
STEP: Saw pod success
Sep  6 12:13:52.455: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep  6 12:13:52.458: INFO: Trying to get logs from node metalk8s-22 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep  6 12:13:52.473: INFO: Waiting for pod pod-host-path-test to disappear
Sep  6 12:13:52.481: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:13:52.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-wlzhg" for this suite.
Sep  6 12:13:58.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:13:58.522: INFO: namespace: e2e-tests-hostpath-wlzhg, resource: bindings, ignored listing per whitelist
Sep  6 12:13:58.604: INFO: namespace e2e-tests-hostpath-wlzhg deletion completed in 6.119573327s

• [SLOW TEST:10.248 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:13:58.604: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 12:13:58.693: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep  6 12:13:58.705: INFO: Number of nodes with available pods: 0
Sep  6 12:13:58.705: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:13:59.711: INFO: Number of nodes with available pods: 0
Sep  6 12:13:59.711: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:14:00.712: INFO: Number of nodes with available pods: 0
Sep  6 12:14:00.712: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:14:01.711: INFO: Number of nodes with available pods: 1
Sep  6 12:14:01.711: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep  6 12:14:01.741: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:02.749: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:03.751: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:04.753: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:05.762: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:06.749: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:07.751: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:08.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:09.749: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:10.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:11.749: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:12.756: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:13.755: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:14.747: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:15.749: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:16.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:17.753: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:18.747: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:19.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:20.747: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:21.749: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:22.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:23.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:24.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:25.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:26.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:27.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:28.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:29.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:30.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:31.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:32.764: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:33.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:34.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:34.748: INFO: Pod daemon-set-pb4tg is not available
Sep  6 12:14:35.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:35.748: INFO: Pod daemon-set-pb4tg is not available
Sep  6 12:14:36.747: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:36.747: INFO: Pod daemon-set-pb4tg is not available
Sep  6 12:14:37.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:37.748: INFO: Pod daemon-set-pb4tg is not available
Sep  6 12:14:38.751: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:38.751: INFO: Pod daemon-set-pb4tg is not available
Sep  6 12:14:39.749: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:39.749: INFO: Pod daemon-set-pb4tg is not available
Sep  6 12:14:40.748: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:40.748: INFO: Pod daemon-set-pb4tg is not available
Sep  6 12:14:41.750: INFO: Wrong image for pod: daemon-set-pb4tg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  6 12:14:41.750: INFO: Pod daemon-set-pb4tg is not available
Sep  6 12:14:42.751: INFO: Pod daemon-set-rrsqg is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep  6 12:14:42.773: INFO: Number of nodes with available pods: 0
Sep  6 12:14:42.773: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:14:43.782: INFO: Number of nodes with available pods: 1
Sep  6 12:14:43.782: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-ptjmw, will wait for the garbage collector to delete the pods
Sep  6 12:14:43.856: INFO: Deleting DaemonSet.extensions daemon-set took: 7.565257ms
Sep  6 12:14:43.956: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.263135ms
Sep  6 12:14:47.859: INFO: Number of nodes with available pods: 0
Sep  6 12:14:47.859: INFO: Number of running nodes: 0, number of available pods: 0
Sep  6 12:14:47.861: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-ptjmw/daemonsets","resourceVersion":"12876"},"items":null}

Sep  6 12:14:47.863: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-ptjmw/pods","resourceVersion":"12876"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:14:47.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-ptjmw" for this suite.
Sep  6 12:14:53.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:14:53.915: INFO: namespace: e2e-tests-daemonsets-ptjmw, resource: bindings, ignored listing per whitelist
Sep  6 12:14:53.991: INFO: namespace e2e-tests-daemonsets-ptjmw deletion completed in 6.121449235s

• [SLOW TEST:55.387 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:14:53.992: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ef1593d8-d09f-11e9-9cef-86a5da7a2260
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-ef1593d8-d09f-11e9-9cef-86a5da7a2260
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:14:58.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g4d4c" for this suite.
Sep  6 12:15:20.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:15:20.201: INFO: namespace: e2e-tests-projected-g4d4c, resource: bindings, ignored listing per whitelist
Sep  6 12:15:20.327: INFO: namespace e2e-tests-projected-g4d4c deletion completed in 22.15346829s

• [SLOW TEST:26.335 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:15:20.327: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 12:15:20.461: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fec8fcd7-d09f-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-48cgr" to be "success or failure"
Sep  6 12:15:20.471: INFO: Pod "downwardapi-volume-fec8fcd7-d09f-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 10.048533ms
Sep  6 12:15:22.479: INFO: Pod "downwardapi-volume-fec8fcd7-d09f-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018119218s
STEP: Saw pod success
Sep  6 12:15:22.479: INFO: Pod "downwardapi-volume-fec8fcd7-d09f-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:15:22.484: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-fec8fcd7-d09f-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 12:15:22.511: INFO: Waiting for pod downwardapi-volume-fec8fcd7-d09f-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:15:22.528: INFO: Pod downwardapi-volume-fec8fcd7-d09f-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:15:22.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-48cgr" for this suite.
Sep  6 12:15:28.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:15:28.602: INFO: namespace: e2e-tests-downward-api-48cgr, resource: bindings, ignored listing per whitelist
Sep  6 12:15:28.681: INFO: namespace e2e-tests-downward-api-48cgr deletion completed in 6.149083097s

• [SLOW TEST:8.354 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:15:28.681: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 12:15:28.753: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03bb79bf-d0a0-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-7n2dm" to be "success or failure"
Sep  6 12:15:28.755: INFO: Pod "downwardapi-volume-03bb79bf-d0a0-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097976ms
Sep  6 12:15:30.760: INFO: Pod "downwardapi-volume-03bb79bf-d0a0-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007496876s
STEP: Saw pod success
Sep  6 12:15:30.760: INFO: Pod "downwardapi-volume-03bb79bf-d0a0-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:15:30.763: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-03bb79bf-d0a0-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 12:15:30.786: INFO: Waiting for pod downwardapi-volume-03bb79bf-d0a0-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:15:30.788: INFO: Pod downwardapi-volume-03bb79bf-d0a0-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:15:30.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7n2dm" for this suite.
Sep  6 12:15:36.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:15:36.854: INFO: namespace: e2e-tests-downward-api-7n2dm, resource: bindings, ignored listing per whitelist
Sep  6 12:15:36.958: INFO: namespace e2e-tests-downward-api-7n2dm deletion completed in 6.156135776s

• [SLOW TEST:8.278 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:15:36.959: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-g7qj
STEP: Creating a pod to test atomic-volume-subpath
Sep  6 12:15:37.043: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-g7qj" in namespace "e2e-tests-subpath-dgkr2" to be "success or failure"
Sep  6 12:15:37.046: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.359321ms
Sep  6 12:15:39.049: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005409745s
Sep  6 12:15:41.053: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Running", Reason="", readiness=false. Elapsed: 4.00974509s
Sep  6 12:15:43.163: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Running", Reason="", readiness=false. Elapsed: 6.120057151s
Sep  6 12:15:45.173: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Running", Reason="", readiness=false. Elapsed: 8.129672398s
Sep  6 12:15:47.176: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Running", Reason="", readiness=false. Elapsed: 10.133162388s
Sep  6 12:15:49.180: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Running", Reason="", readiness=false. Elapsed: 12.136376066s
Sep  6 12:15:51.183: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Running", Reason="", readiness=false. Elapsed: 14.140010217s
Sep  6 12:15:53.186: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Running", Reason="", readiness=false. Elapsed: 16.14292819s
Sep  6 12:15:55.191: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Running", Reason="", readiness=false. Elapsed: 18.147989585s
Sep  6 12:15:57.194: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Running", Reason="", readiness=false. Elapsed: 20.150980479s
Sep  6 12:15:59.197: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Running", Reason="", readiness=false. Elapsed: 22.154173814s
Sep  6 12:16:01.200: INFO: Pod "pod-subpath-test-configmap-g7qj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.157312101s
STEP: Saw pod success
Sep  6 12:16:01.201: INFO: Pod "pod-subpath-test-configmap-g7qj" satisfied condition "success or failure"
Sep  6 12:16:01.203: INFO: Trying to get logs from node metalk8s-22 pod pod-subpath-test-configmap-g7qj container test-container-subpath-configmap-g7qj: <nil>
STEP: delete the pod
Sep  6 12:16:01.220: INFO: Waiting for pod pod-subpath-test-configmap-g7qj to disappear
Sep  6 12:16:01.234: INFO: Pod pod-subpath-test-configmap-g7qj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-g7qj
Sep  6 12:16:01.234: INFO: Deleting pod "pod-subpath-test-configmap-g7qj" in namespace "e2e-tests-subpath-dgkr2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:16:01.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dgkr2" for this suite.
Sep  6 12:16:07.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:16:07.353: INFO: namespace: e2e-tests-subpath-dgkr2, resource: bindings, ignored listing per whitelist
Sep  6 12:16:07.404: INFO: namespace e2e-tests-subpath-dgkr2 deletion completed in 6.163126055s

• [SLOW TEST:30.445 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:16:07.404: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 12:16:07.511: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ad41381-d0a0-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-q4rdv" to be "success or failure"
Sep  6 12:16:07.533: INFO: Pod "downwardapi-volume-1ad41381-d0a0-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 21.866924ms
Sep  6 12:16:09.540: INFO: Pod "downwardapi-volume-1ad41381-d0a0-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028693158s
STEP: Saw pod success
Sep  6 12:16:09.540: INFO: Pod "downwardapi-volume-1ad41381-d0a0-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:16:09.542: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-1ad41381-d0a0-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 12:16:09.579: INFO: Waiting for pod downwardapi-volume-1ad41381-d0a0-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:16:09.583: INFO: Pod downwardapi-volume-1ad41381-d0a0-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:16:09.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q4rdv" for this suite.
Sep  6 12:16:15.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:16:15.640: INFO: namespace: e2e-tests-projected-q4rdv, resource: bindings, ignored listing per whitelist
Sep  6 12:16:15.733: INFO: namespace e2e-tests-projected-q4rdv deletion completed in 6.146652523s

• [SLOW TEST:8.329 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:16:15.733: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Sep  6 12:16:15.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 cluster-info'
Sep  6 12:16:16.050: INFO: stderr: ""
Sep  6 12:16:16.050: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:16:16.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tdprd" for this suite.
Sep  6 12:16:22.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:16:22.092: INFO: namespace: e2e-tests-kubectl-tdprd, resource: bindings, ignored listing per whitelist
Sep  6 12:16:22.181: INFO: namespace e2e-tests-kubectl-tdprd deletion completed in 6.12824977s

• [SLOW TEST:6.448 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:16:22.181: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Sep  6 12:16:22.253: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-878575678 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:16:22.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wv8rf" for this suite.
Sep  6 12:16:28.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:16:28.443: INFO: namespace: e2e-tests-kubectl-wv8rf, resource: bindings, ignored listing per whitelist
Sep  6 12:16:28.527: INFO: namespace e2e-tests-kubectl-wv8rf deletion completed in 6.150643829s

• [SLOW TEST:6.347 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:16:28.529: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-mpdvs
Sep  6 12:16:32.633: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-mpdvs
STEP: checking the pod's current state and verifying that restartCount is present
Sep  6 12:16:32.637: INFO: Initial restart count of pod liveness-http is 0
Sep  6 12:16:54.683: INFO: Restart count of pod e2e-tests-container-probe-mpdvs/liveness-http is now 1 (22.046248876s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:16:54.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mpdvs" for this suite.
Sep  6 12:17:00.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:17:00.754: INFO: namespace: e2e-tests-container-probe-mpdvs, resource: bindings, ignored listing per whitelist
Sep  6 12:17:00.844: INFO: namespace e2e-tests-container-probe-mpdvs deletion completed in 6.143506393s

• [SLOW TEST:32.316 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:17:00.845: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-3ab08a16-d0a0-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 12:17:00.969: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3ab14b39-d0a0-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-gztgw" to be "success or failure"
Sep  6 12:17:00.980: INFO: Pod "pod-projected-secrets-3ab14b39-d0a0-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 11.184106ms
Sep  6 12:17:02.985: INFO: Pod "pod-projected-secrets-3ab14b39-d0a0-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016507446s
STEP: Saw pod success
Sep  6 12:17:02.985: INFO: Pod "pod-projected-secrets-3ab14b39-d0a0-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:17:02.989: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-secrets-3ab14b39-d0a0-11e9-9cef-86a5da7a2260 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  6 12:17:03.019: INFO: Waiting for pod pod-projected-secrets-3ab14b39-d0a0-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:17:03.024: INFO: Pod pod-projected-secrets-3ab14b39-d0a0-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:17:03.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gztgw" for this suite.
Sep  6 12:17:09.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:17:09.204: INFO: namespace: e2e-tests-projected-gztgw, resource: bindings, ignored listing per whitelist
Sep  6 12:17:09.221: INFO: namespace e2e-tests-projected-gztgw deletion completed in 6.194000224s

• [SLOW TEST:8.376 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:17:09.221: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-tjjv4
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-tjjv4
STEP: Deleting pre-stop pod
Sep  6 12:17:20.386: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:17:20.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-tjjv4" for this suite.
Sep  6 12:17:58.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:17:58.526: INFO: namespace: e2e-tests-prestop-tjjv4, resource: bindings, ignored listing per whitelist
Sep  6 12:17:58.537: INFO: namespace e2e-tests-prestop-tjjv4 deletion completed in 38.144128806s

• [SLOW TEST:49.315 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:17:58.537: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  6 12:18:01.149: INFO: Successfully updated pod "annotationupdate5d0eb8ac-d0a0-11e9-9cef-86a5da7a2260"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:18:05.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w2cqg" for this suite.
Sep  6 12:18:27.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:18:27.231: INFO: namespace: e2e-tests-projected-w2cqg, resource: bindings, ignored listing per whitelist
Sep  6 12:18:27.323: INFO: namespace e2e-tests-projected-w2cqg deletion completed in 22.135729109s

• [SLOW TEST:28.786 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:18:27.323: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6e3756ee-d0a0-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 12:18:27.411: INFO: Waiting up to 5m0s for pod "pod-secrets-6e383257-d0a0-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-secrets-xpjz6" to be "success or failure"
Sep  6 12:18:27.416: INFO: Pod "pod-secrets-6e383257-d0a0-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 4.880072ms
Sep  6 12:18:29.426: INFO: Pod "pod-secrets-6e383257-d0a0-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014945133s
STEP: Saw pod success
Sep  6 12:18:29.426: INFO: Pod "pod-secrets-6e383257-d0a0-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:18:29.429: INFO: Trying to get logs from node metalk8s-22 pod pod-secrets-6e383257-d0a0-11e9-9cef-86a5da7a2260 container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 12:18:29.476: INFO: Waiting for pod pod-secrets-6e383257-d0a0-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:18:29.482: INFO: Pod pod-secrets-6e383257-d0a0-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:18:29.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xpjz6" for this suite.
Sep  6 12:18:35.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:18:35.616: INFO: namespace: e2e-tests-secrets-xpjz6, resource: bindings, ignored listing per whitelist
Sep  6 12:18:35.764: INFO: namespace e2e-tests-secrets-xpjz6 deletion completed in 6.265402798s

• [SLOW TEST:8.441 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:18:35.764: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-733f0e3e-d0a0-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 12:18:35.857: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7340edb6-d0a0-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-dk7nh" to be "success or failure"
Sep  6 12:18:35.866: INFO: Pod "pod-projected-secrets-7340edb6-d0a0-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 8.749757ms
Sep  6 12:18:37.869: INFO: Pod "pod-projected-secrets-7340edb6-d0a0-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011699489s
STEP: Saw pod success
Sep  6 12:18:37.869: INFO: Pod "pod-projected-secrets-7340edb6-d0a0-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:18:37.874: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-secrets-7340edb6-d0a0-11e9-9cef-86a5da7a2260 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  6 12:18:37.898: INFO: Waiting for pod pod-projected-secrets-7340edb6-d0a0-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:18:37.903: INFO: Pod pod-projected-secrets-7340edb6-d0a0-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:18:37.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dk7nh" for this suite.
Sep  6 12:18:43.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:18:44.100: INFO: namespace: e2e-tests-projected-dk7nh, resource: bindings, ignored listing per whitelist
Sep  6 12:18:44.152: INFO: namespace e2e-tests-projected-dk7nh deletion completed in 6.245654564s

• [SLOW TEST:8.388 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:18:44.152: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-78php
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Sep  6 12:18:44.283: INFO: Found 0 stateful pods, waiting for 3
Sep  6 12:18:54.290: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 12:18:54.290: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 12:18:54.290: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  6 12:18:54.317: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep  6 12:19:04.355: INFO: Updating stateful set ss2
Sep  6 12:19:04.363: INFO: Waiting for Pod e2e-tests-statefulset-78php/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Sep  6 12:19:14.485: INFO: Found 2 stateful pods, waiting for 3
Sep  6 12:19:24.489: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 12:19:24.489: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 12:19:24.489: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep  6 12:19:24.532: INFO: Updating stateful set ss2
Sep  6 12:19:24.540: INFO: Waiting for Pod e2e-tests-statefulset-78php/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  6 12:19:34.575: INFO: Updating stateful set ss2
Sep  6 12:19:34.583: INFO: Waiting for StatefulSet e2e-tests-statefulset-78php/ss2 to complete update
Sep  6 12:19:34.583: INFO: Waiting for Pod e2e-tests-statefulset-78php/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  6 12:19:44.627: INFO: Deleting all statefulset in ns e2e-tests-statefulset-78php
Sep  6 12:19:44.633: INFO: Scaling statefulset ss2 to 0
Sep  6 12:20:04.659: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 12:20:04.666: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:20:04.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-78php" for this suite.
Sep  6 12:20:10.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:20:10.850: INFO: namespace: e2e-tests-statefulset-78php, resource: bindings, ignored listing per whitelist
Sep  6 12:20:10.910: INFO: namespace e2e-tests-statefulset-78php deletion completed in 6.206146403s

• [SLOW TEST:86.758 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:20:10.911: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 12:20:11.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 version'
Sep  6 12:20:11.137: INFO: stderr: ""
Sep  6 12:20:11.137: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.10\", GitCommit:\"37d169313237cb4ceb2cc4bef300f2ae3053c1a2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T10:44:49Z\", GoVersion:\"go1.11.13\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:20:11.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6q29t" for this suite.
Sep  6 12:20:17.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:20:17.175: INFO: namespace: e2e-tests-kubectl-6q29t, resource: bindings, ignored listing per whitelist
Sep  6 12:20:17.298: INFO: namespace e2e-tests-kubectl-6q29t deletion completed in 6.156664359s

• [SLOW TEST:6.387 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:20:17.298: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-sn922/configmap-test-afc6beba-d0a0-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 12:20:17.414: INFO: Waiting up to 5m0s for pod "pod-configmaps-afc9b933-d0a0-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-configmap-sn922" to be "success or failure"
Sep  6 12:20:17.418: INFO: Pod "pod-configmaps-afc9b933-d0a0-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 3.170448ms
Sep  6 12:20:19.421: INFO: Pod "pod-configmaps-afc9b933-d0a0-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006409617s
STEP: Saw pod success
Sep  6 12:20:19.421: INFO: Pod "pod-configmaps-afc9b933-d0a0-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:20:19.424: INFO: Trying to get logs from node metalk8s-22 pod pod-configmaps-afc9b933-d0a0-11e9-9cef-86a5da7a2260 container env-test: <nil>
STEP: delete the pod
Sep  6 12:20:19.467: INFO: Waiting for pod pod-configmaps-afc9b933-d0a0-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:20:19.477: INFO: Pod pod-configmaps-afc9b933-d0a0-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:20:19.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sn922" for this suite.
Sep  6 12:20:25.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:20:25.519: INFO: namespace: e2e-tests-configmap-sn922, resource: bindings, ignored listing per whitelist
Sep  6 12:20:25.624: INFO: namespace e2e-tests-configmap-sn922 deletion completed in 6.139643174s

• [SLOW TEST:8.326 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:20:25.624: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  6 12:20:25.694: INFO: Waiting up to 5m0s for pod "pod-b4b864f1-d0a0-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-w8fc5" to be "success or failure"
Sep  6 12:20:25.705: INFO: Pod "pod-b4b864f1-d0a0-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 11.326547ms
Sep  6 12:20:27.718: INFO: Pod "pod-b4b864f1-d0a0-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023858422s
STEP: Saw pod success
Sep  6 12:20:27.718: INFO: Pod "pod-b4b864f1-d0a0-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:20:27.733: INFO: Trying to get logs from node metalk8s-22 pod pod-b4b864f1-d0a0-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 12:20:27.785: INFO: Waiting for pod pod-b4b864f1-d0a0-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:20:27.789: INFO: Pod pod-b4b864f1-d0a0-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:20:27.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w8fc5" for this suite.
Sep  6 12:20:33.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:20:33.856: INFO: namespace: e2e-tests-emptydir-w8fc5, resource: bindings, ignored listing per whitelist
Sep  6 12:20:33.919: INFO: namespace e2e-tests-emptydir-w8fc5 deletion completed in 6.127412953s

• [SLOW TEST:8.295 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:20:33.919: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-mdzs6 in namespace e2e-tests-proxy-2wr6t
I0906 12:20:34.046395      17 runners.go:184] Created replication controller with name: proxy-service-mdzs6, namespace: e2e-tests-proxy-2wr6t, replica count: 1
I0906 12:20:35.097087      17 runners.go:184] proxy-service-mdzs6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0906 12:20:36.097387      17 runners.go:184] proxy-service-mdzs6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0906 12:20:37.097583      17 runners.go:184] proxy-service-mdzs6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0906 12:20:38.097778      17 runners.go:184] proxy-service-mdzs6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0906 12:20:39.098075      17 runners.go:184] proxy-service-mdzs6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0906 12:20:40.098332      17 runners.go:184] proxy-service-mdzs6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0906 12:20:41.098595      17 runners.go:184] proxy-service-mdzs6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0906 12:20:42.098837      17 runners.go:184] proxy-service-mdzs6 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  6 12:20:42.103: INFO: setup took 8.097747712s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep  6 12:20:42.121: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 18.315743ms)
Sep  6 12:20:42.136: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 31.757959ms)
Sep  6 12:20:42.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 41.047447ms)
Sep  6 12:20:42.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 40.932763ms)
Sep  6 12:20:42.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 41.821067ms)
Sep  6 12:20:42.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 42.305462ms)
Sep  6 12:20:42.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 41.681668ms)
Sep  6 12:20:42.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 41.420138ms)
Sep  6 12:20:42.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 41.545408ms)
Sep  6 12:20:42.145: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 41.128423ms)
Sep  6 12:20:42.151: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 47.736357ms)
Sep  6 12:20:42.151: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 47.990953ms)
Sep  6 12:20:42.151: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 48.180323ms)
Sep  6 12:20:42.151: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 47.548817ms)
Sep  6 12:20:42.151: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 47.514045ms)
Sep  6 12:20:42.154: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 51.457404ms)
Sep  6 12:20:42.168: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 13.307457ms)
Sep  6 12:20:42.168: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 13.263826ms)
Sep  6 12:20:42.168: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 13.230162ms)
Sep  6 12:20:42.168: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 9.017549ms)
Sep  6 12:20:42.170: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 14.812582ms)
Sep  6 12:20:42.170: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 10.850176ms)
Sep  6 12:20:42.171: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 11.789319ms)
Sep  6 12:20:42.171: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 15.783928ms)
Sep  6 12:20:42.171: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 16.204389ms)
Sep  6 12:20:42.171: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 15.871805ms)
Sep  6 12:20:42.171: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 16.03929ms)
Sep  6 12:20:42.172: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 16.685721ms)
Sep  6 12:20:42.172: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 16.903241ms)
Sep  6 12:20:42.172: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 12.914987ms)
Sep  6 12:20:42.172: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 17.384369ms)
Sep  6 12:20:42.172: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 17.065997ms)
Sep  6 12:20:42.180: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 6.753095ms)
Sep  6 12:20:42.180: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 7.925625ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 10.614277ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 11.868248ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 11.750111ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 10.872333ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 10.675084ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 10.955852ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 10.891508ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 11.144296ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 10.830664ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 11.146224ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 11.866632ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 11.374287ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 12.320466ms)
Sep  6 12:20:42.184: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 12.075764ms)
Sep  6 12:20:42.190: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 5.278034ms)
Sep  6 12:20:42.197: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 10.474694ms)
Sep  6 12:20:42.199: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 12.565715ms)
Sep  6 12:20:42.199: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 12.1231ms)
Sep  6 12:20:42.199: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 12.24015ms)
Sep  6 12:20:42.199: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 12.098046ms)
Sep  6 12:20:42.199: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 12.905118ms)
Sep  6 12:20:42.199: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 13.155976ms)
Sep  6 12:20:42.199: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 13.82208ms)
Sep  6 12:20:42.199: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 13.97908ms)
Sep  6 12:20:42.199: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 12.243575ms)
Sep  6 12:20:42.199: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 14.128968ms)
Sep  6 12:20:42.199: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 13.7651ms)
Sep  6 12:20:42.200: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 12.901309ms)
Sep  6 12:20:42.200: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 14.46861ms)
Sep  6 12:20:42.200: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 14.313691ms)
Sep  6 12:20:42.213: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 11.882665ms)
Sep  6 12:20:42.213: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 12.144251ms)
Sep  6 12:20:42.213: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 12.077636ms)
Sep  6 12:20:42.213: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 11.946824ms)
Sep  6 12:20:42.213: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 11.384942ms)
Sep  6 12:20:42.220: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 18.558011ms)
Sep  6 12:20:42.220: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 18.785043ms)
Sep  6 12:20:42.220: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 18.459095ms)
Sep  6 12:20:42.220: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 18.768847ms)
Sep  6 12:20:42.220: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 18.307705ms)
Sep  6 12:20:42.220: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 19.178ms)
Sep  6 12:20:42.220: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 18.472974ms)
Sep  6 12:20:42.220: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 18.998689ms)
Sep  6 12:20:42.220: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 19.772621ms)
Sep  6 12:20:42.220: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 19.142766ms)
Sep  6 12:20:42.221: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 19.742782ms)
Sep  6 12:20:42.226: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 5.156236ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 9.350769ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 9.316492ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 9.156192ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 9.076622ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 9.55886ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 8.946544ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 9.983003ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 9.801881ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 9.72241ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 9.945076ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 8.954105ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 8.832001ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 8.954205ms)
Sep  6 12:20:42.231: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 9.799704ms)
Sep  6 12:20:42.232: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 9.524631ms)
Sep  6 12:20:42.243: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 11.199322ms)
Sep  6 12:20:42.243: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 11.365546ms)
Sep  6 12:20:42.243: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 11.823671ms)
Sep  6 12:20:42.245: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 13.418499ms)
Sep  6 12:20:42.245: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 13.312186ms)
Sep  6 12:20:42.245: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 10.091229ms)
Sep  6 12:20:42.245: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 13.479319ms)
Sep  6 12:20:42.245: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 10.178932ms)
Sep  6 12:20:42.245: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 13.579285ms)
Sep  6 12:20:42.246: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 13.762169ms)
Sep  6 12:20:42.246: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 13.892232ms)
Sep  6 12:20:42.246: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 14.26232ms)
Sep  6 12:20:42.246: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 10.681745ms)
Sep  6 12:20:42.246: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 10.972041ms)
Sep  6 12:20:42.246: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 14.093255ms)
Sep  6 12:20:42.247: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 15.041542ms)
Sep  6 12:20:42.258: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 11.051788ms)
Sep  6 12:20:42.258: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 10.340259ms)
Sep  6 12:20:42.258: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 10.438824ms)
Sep  6 12:20:42.258: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 10.428723ms)
Sep  6 12:20:42.258: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 10.587474ms)
Sep  6 12:20:42.258: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 10.576591ms)
Sep  6 12:20:42.264: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 16.80424ms)
Sep  6 12:20:42.264: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 17.212141ms)
Sep  6 12:20:42.264: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 16.851032ms)
Sep  6 12:20:42.265: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 17.747824ms)
Sep  6 12:20:42.266: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 18.499583ms)
Sep  6 12:20:42.266: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 18.263134ms)
Sep  6 12:20:42.266: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 18.160073ms)
Sep  6 12:20:42.266: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 17.621566ms)
Sep  6 12:20:42.266: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 17.68789ms)
Sep  6 12:20:42.266: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 18.163568ms)
Sep  6 12:20:42.275: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 7.14566ms)
Sep  6 12:20:42.275: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 8.972323ms)
Sep  6 12:20:42.275: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 8.81805ms)
Sep  6 12:20:42.275: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 7.110444ms)
Sep  6 12:20:42.275: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 7.112181ms)
Sep  6 12:20:42.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 12.057281ms)
Sep  6 12:20:42.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 12.475749ms)
Sep  6 12:20:42.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 10.319982ms)
Sep  6 12:20:42.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 11.807666ms)
Sep  6 12:20:42.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 12.099216ms)
Sep  6 12:20:42.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 10.422826ms)
Sep  6 12:20:42.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 10.584479ms)
Sep  6 12:20:42.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 11.950295ms)
Sep  6 12:20:42.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 10.818918ms)
Sep  6 12:20:42.278: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 12.04951ms)
Sep  6 12:20:42.279: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 13.213166ms)
Sep  6 12:20:42.284: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 5.031874ms)
Sep  6 12:20:42.284: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 4.91303ms)
Sep  6 12:20:42.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 10.842919ms)
Sep  6 12:20:42.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 10.633805ms)
Sep  6 12:20:42.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 10.812839ms)
Sep  6 12:20:42.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 10.901416ms)
Sep  6 12:20:42.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 10.798589ms)
Sep  6 12:20:42.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 10.712313ms)
Sep  6 12:20:42.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 10.882869ms)
Sep  6 12:20:42.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 10.830319ms)
Sep  6 12:20:42.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 10.923942ms)
Sep  6 12:20:42.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 11.106061ms)
Sep  6 12:20:42.290: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 11.051721ms)
Sep  6 12:20:42.291: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 12.08434ms)
Sep  6 12:20:42.291: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 12.185677ms)
Sep  6 12:20:42.291: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 12.04651ms)
Sep  6 12:20:42.307: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 15.863667ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 16.017136ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 15.945357ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 15.98642ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 16.039568ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 16.157257ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 16.169229ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 16.263587ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 16.399388ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 16.161899ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 16.532992ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 16.243879ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 16.445707ms)
Sep  6 12:20:42.308: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 16.326281ms)
Sep  6 12:20:42.307: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 15.843213ms)
Sep  6 12:20:42.310: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 18.481781ms)
Sep  6 12:20:42.325: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 14.57062ms)
Sep  6 12:20:42.328: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 17.087285ms)
Sep  6 12:20:42.328: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 17.02611ms)
Sep  6 12:20:42.328: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 17.327562ms)
Sep  6 12:20:42.328: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 17.191967ms)
Sep  6 12:20:42.329: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 18.038843ms)
Sep  6 12:20:42.333: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 22.195158ms)
Sep  6 12:20:42.333: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 21.807675ms)
Sep  6 12:20:42.333: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 22.246101ms)
Sep  6 12:20:42.333: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 22.231024ms)
Sep  6 12:20:42.333: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 22.152008ms)
Sep  6 12:20:42.334: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 23.037905ms)
Sep  6 12:20:42.334: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 22.86913ms)
Sep  6 12:20:42.334: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 23.196906ms)
Sep  6 12:20:42.335: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 24.046585ms)
Sep  6 12:20:42.336: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 24.912911ms)
Sep  6 12:20:42.346: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 10.50155ms)
Sep  6 12:20:42.348: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 12.126914ms)
Sep  6 12:20:42.348: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 11.958598ms)
Sep  6 12:20:42.348: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 12.14399ms)
Sep  6 12:20:42.349: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 12.522897ms)
Sep  6 12:20:42.349: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 12.670853ms)
Sep  6 12:20:42.349: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 12.224879ms)
Sep  6 12:20:42.349: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 12.314016ms)
Sep  6 12:20:42.349: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 12.819888ms)
Sep  6 12:20:42.349: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 12.76845ms)
Sep  6 12:20:42.349: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 12.429565ms)
Sep  6 12:20:42.349: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 12.70407ms)
Sep  6 12:20:42.351: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 14.901408ms)
Sep  6 12:20:42.351: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 15.39949ms)
Sep  6 12:20:42.351: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 15.369838ms)
Sep  6 12:20:42.352: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 16.124208ms)
Sep  6 12:20:42.357: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 4.389155ms)
Sep  6 12:20:42.358: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 5.35733ms)
Sep  6 12:20:42.361: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 8.336186ms)
Sep  6 12:20:42.361: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 8.361719ms)
Sep  6 12:20:42.361: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 8.552553ms)
Sep  6 12:20:42.361: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 8.434689ms)
Sep  6 12:20:42.361: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 8.601469ms)
Sep  6 12:20:42.361: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 8.755577ms)
Sep  6 12:20:42.362: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 8.666951ms)
Sep  6 12:20:42.362: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 8.716258ms)
Sep  6 12:20:42.365: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 11.850969ms)
Sep  6 12:20:42.365: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 12.058959ms)
Sep  6 12:20:42.365: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 12.06333ms)
Sep  6 12:20:42.365: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 12.090644ms)
Sep  6 12:20:42.365: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 12.126315ms)
Sep  6 12:20:42.365: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 12.274591ms)
Sep  6 12:20:42.371: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 5.717881ms)
Sep  6 12:20:42.371: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 5.797675ms)
Sep  6 12:20:42.371: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 5.738333ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 8.303262ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 8.20512ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 8.206122ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 8.30459ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 8.398867ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 8.524596ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 8.460986ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 8.228087ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 8.419508ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 8.316044ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 8.635345ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 8.598593ms)
Sep  6 12:20:42.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 8.686883ms)
Sep  6 12:20:42.378: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 3.331332ms)
Sep  6 12:20:42.379: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 4.405968ms)
Sep  6 12:20:42.379: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 4.681826ms)
Sep  6 12:20:42.383: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 8.622857ms)
Sep  6 12:20:42.383: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 9.100168ms)
Sep  6 12:20:42.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 12.039739ms)
Sep  6 12:20:42.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 11.351992ms)
Sep  6 12:20:42.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 11.769725ms)
Sep  6 12:20:42.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 11.487233ms)
Sep  6 12:20:42.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 11.27004ms)
Sep  6 12:20:42.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 11.183705ms)
Sep  6 12:20:42.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 11.629418ms)
Sep  6 12:20:42.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 11.773234ms)
Sep  6 12:20:42.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 11.118758ms)
Sep  6 12:20:42.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 11.020729ms)
Sep  6 12:20:42.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 10.949219ms)
Sep  6 12:20:42.396: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 9.146028ms)
Sep  6 12:20:42.396: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 9.8085ms)
Sep  6 12:20:42.396: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 9.618159ms)
Sep  6 12:20:42.396: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 9.601867ms)
Sep  6 12:20:42.398: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 11.046546ms)
Sep  6 12:20:42.398: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 11.047757ms)
Sep  6 12:20:42.398: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 11.281529ms)
Sep  6 12:20:42.398: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 10.992094ms)
Sep  6 12:20:42.398: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 10.913008ms)
Sep  6 12:20:42.398: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 11.084773ms)
Sep  6 12:20:42.398: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 11.579484ms)
Sep  6 12:20:42.398: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 11.069485ms)
Sep  6 12:20:42.398: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 11.1101ms)
Sep  6 12:20:42.404: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 17.494532ms)
Sep  6 12:20:42.404: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 17.739415ms)
Sep  6 12:20:42.404: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 17.628069ms)
Sep  6 12:20:42.407: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 2.977286ms)
Sep  6 12:20:42.409: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 4.016348ms)
Sep  6 12:20:42.409: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 4.011868ms)
Sep  6 12:20:42.409: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 4.321196ms)
Sep  6 12:20:42.411: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 5.409117ms)
Sep  6 12:20:42.411: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 4.887961ms)
Sep  6 12:20:42.411: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 5.89256ms)
Sep  6 12:20:42.412: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 7.922447ms)
Sep  6 12:20:42.412: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 6.557739ms)
Sep  6 12:20:42.412: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 7.151339ms)
Sep  6 12:20:42.412: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 6.511671ms)
Sep  6 12:20:42.412: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 7.206412ms)
Sep  6 12:20:42.412: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 6.912401ms)
Sep  6 12:20:42.412: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 7.748686ms)
Sep  6 12:20:42.413: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 7.382228ms)
Sep  6 12:20:42.413: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 7.973825ms)
Sep  6 12:20:42.417: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 3.4341ms)
Sep  6 12:20:42.429: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 15.05041ms)
Sep  6 12:20:42.429: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 14.681288ms)
Sep  6 12:20:42.435: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 21.083592ms)
Sep  6 12:20:42.435: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 20.871905ms)
Sep  6 12:20:42.436: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 22.3263ms)
Sep  6 12:20:42.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 23.216322ms)
Sep  6 12:20:42.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 22.201271ms)
Sep  6 12:20:42.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 22.74093ms)
Sep  6 12:20:42.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 22.320827ms)
Sep  6 12:20:42.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 23.806408ms)
Sep  6 12:20:42.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 22.186838ms)
Sep  6 12:20:42.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 22.119287ms)
Sep  6 12:20:42.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 22.59886ms)
Sep  6 12:20:42.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 23.169961ms)
Sep  6 12:20:42.444: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 29.362731ms)
Sep  6 12:20:42.455: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 8.916412ms)
Sep  6 12:20:42.455: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:462/proxy/: tls qux (200; 10.944486ms)
Sep  6 12:20:42.455: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:1080/proxy/rewri... (200; 11.072525ms)
Sep  6 12:20:42.455: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname2/proxy/: bar (200; 11.285771ms)
Sep  6 12:20:42.455: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 10.967985ms)
Sep  6 12:20:42.455: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname1/proxy/: foo (200; 11.448497ms)
Sep  6 12:20:42.455: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:460/proxy/: tls baz (200; 9.129964ms)
Sep  6 12:20:42.455: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname1/proxy/: tls baz (200; 11.317741ms)
Sep  6 12:20:42.456: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/https:proxy-service-mdzs6:tlsportname2/proxy/: tls qux (200; 9.701618ms)
Sep  6 12:20:42.456: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/http:proxy-service-mdzs6:portname1/proxy/: foo (200; 11.607192ms)
Sep  6 12:20:42.456: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/services/proxy-service-mdzs6:portname2/proxy/: bar (200; 9.805272ms)
Sep  6 12:20:42.456: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/https:proxy-service-mdzs6-9d5gs:443/proxy/... (200; 9.828105ms)
Sep  6 12:20:42.456: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs/proxy/rewriteme"... (200; 9.942805ms)
Sep  6 12:20:42.456: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/proxy-service-mdzs6-9d5gs:160/proxy/: foo (200; 11.828655ms)
Sep  6 12:20:42.456: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:162/proxy/: bar (200; 10.015304ms)
Sep  6 12:20:42.456: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-2wr6t/pods/http:proxy-service-mdzs6-9d5gs:1080/proxy/... (200; 12.474954ms)
STEP: deleting ReplicationController proxy-service-mdzs6 in namespace e2e-tests-proxy-2wr6t, will wait for the garbage collector to delete the pods
Sep  6 12:20:42.524: INFO: Deleting ReplicationController proxy-service-mdzs6 took: 15.11446ms
Sep  6 12:20:42.626: INFO: Terminating ReplicationController proxy-service-mdzs6 pods took: 101.853194ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:20:51.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-2wr6t" for this suite.
Sep  6 12:20:57.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:20:57.940: INFO: namespace: e2e-tests-proxy-2wr6t, resource: bindings, ignored listing per whitelist
Sep  6 12:20:58.013: INFO: namespace e2e-tests-proxy-2wr6t deletion completed in 6.181644663s

• [SLOW TEST:24.094 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:20:58.013: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-ppdjl.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-ppdjl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-ppdjl.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-ppdjl.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-ppdjl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-ppdjl.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  6 12:21:02.240: INFO: DNS probes using e2e-tests-dns-ppdjl/dns-test-c80bba46-d0a0-11e9-9cef-86a5da7a2260 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:21:02.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-ppdjl" for this suite.
Sep  6 12:21:08.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:21:08.329: INFO: namespace: e2e-tests-dns-ppdjl, resource: bindings, ignored listing per whitelist
Sep  6 12:21:08.411: INFO: namespace e2e-tests-dns-ppdjl deletion completed in 6.134411704s

• [SLOW TEST:10.398 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:21:08.411: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Sep  6 12:21:08.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:08.705: INFO: stderr: ""
Sep  6 12:21:08.705: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 12:21:08.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:08.840: INFO: stderr: ""
Sep  6 12:21:08.841: INFO: stdout: "update-demo-nautilus-khpzv update-demo-nautilus-vq8ms "
Sep  6 12:21:08.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-khpzv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:08.984: INFO: stderr: ""
Sep  6 12:21:08.984: INFO: stdout: ""
Sep  6 12:21:08.984: INFO: update-demo-nautilus-khpzv is created but not running
Sep  6 12:21:13.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:14.131: INFO: stderr: ""
Sep  6 12:21:14.131: INFO: stdout: "update-demo-nautilus-khpzv update-demo-nautilus-vq8ms "
Sep  6 12:21:14.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-khpzv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:14.238: INFO: stderr: ""
Sep  6 12:21:14.238: INFO: stdout: "true"
Sep  6 12:21:14.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-khpzv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:14.347: INFO: stderr: ""
Sep  6 12:21:14.347: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 12:21:14.347: INFO: validating pod update-demo-nautilus-khpzv
Sep  6 12:21:14.353: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 12:21:14.353: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 12:21:14.353: INFO: update-demo-nautilus-khpzv is verified up and running
Sep  6 12:21:14.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-vq8ms -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:14.461: INFO: stderr: ""
Sep  6 12:21:14.461: INFO: stdout: "true"
Sep  6 12:21:14.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-nautilus-vq8ms -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:14.633: INFO: stderr: ""
Sep  6 12:21:14.633: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  6 12:21:14.633: INFO: validating pod update-demo-nautilus-vq8ms
Sep  6 12:21:14.650: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  6 12:21:14.650: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  6 12:21:14.650: INFO: update-demo-nautilus-vq8ms is verified up and running
STEP: rolling-update to new replication controller
Sep  6 12:21:14.651: INFO: scanned /root for discovery docs: <nil>
Sep  6 12:21:14.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:37.226: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  6 12:21:37.226: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  6 12:21:37.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:37.587: INFO: stderr: ""
Sep  6 12:21:37.587: INFO: stdout: "update-demo-kitten-7l7w6 update-demo-kitten-rdhm2 "
Sep  6 12:21:37.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-kitten-7l7w6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:37.738: INFO: stderr: ""
Sep  6 12:21:37.738: INFO: stdout: "true"
Sep  6 12:21:37.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-kitten-7l7w6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:37.850: INFO: stderr: ""
Sep  6 12:21:37.850: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  6 12:21:37.850: INFO: validating pod update-demo-kitten-7l7w6
Sep  6 12:21:37.854: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  6 12:21:37.854: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  6 12:21:37.854: INFO: update-demo-kitten-7l7w6 is verified up and running
Sep  6 12:21:37.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-kitten-rdhm2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:37.956: INFO: stderr: ""
Sep  6 12:21:37.956: INFO: stdout: "true"
Sep  6 12:21:37.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods update-demo-kitten-rdhm2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xxkj5'
Sep  6 12:21:38.090: INFO: stderr: ""
Sep  6 12:21:38.090: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  6 12:21:38.090: INFO: validating pod update-demo-kitten-rdhm2
Sep  6 12:21:38.094: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  6 12:21:38.094: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  6 12:21:38.094: INFO: update-demo-kitten-rdhm2 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:21:38.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xxkj5" for this suite.
Sep  6 12:22:00.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:22:00.151: INFO: namespace: e2e-tests-kubectl-xxkj5, resource: bindings, ignored listing per whitelist
Sep  6 12:22:00.268: INFO: namespace e2e-tests-kubectl-xxkj5 deletion completed in 22.1699587s

• [SLOW TEST:51.858 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:22:00.269: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Sep  6 12:22:00.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 api-versions'
Sep  6 12:22:00.424: INFO: stderr: ""
Sep  6 12:22:00.424: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nmonitoring.coreos.com/v1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:22:00.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7z5n9" for this suite.
Sep  6 12:22:06.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:22:06.457: INFO: namespace: e2e-tests-kubectl-7z5n9, resource: bindings, ignored listing per whitelist
Sep  6 12:22:06.571: INFO: namespace e2e-tests-kubectl-7z5n9 deletion completed in 6.143962847s

• [SLOW TEST:6.302 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:22:06.571: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-f0e69ae8-d0a0-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 12:22:06.674: INFO: Waiting up to 5m0s for pod "pod-configmaps-f0e849ae-d0a0-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-configmap-t6vc5" to be "success or failure"
Sep  6 12:22:06.680: INFO: Pod "pod-configmaps-f0e849ae-d0a0-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 6.379257ms
Sep  6 12:22:08.683: INFO: Pod "pod-configmaps-f0e849ae-d0a0-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009455244s
STEP: Saw pod success
Sep  6 12:22:08.683: INFO: Pod "pod-configmaps-f0e849ae-d0a0-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:22:08.685: INFO: Trying to get logs from node metalk8s-22 pod pod-configmaps-f0e849ae-d0a0-11e9-9cef-86a5da7a2260 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 12:22:08.703: INFO: Waiting for pod pod-configmaps-f0e849ae-d0a0-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:22:08.704: INFO: Pod pod-configmaps-f0e849ae-d0a0-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:22:08.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t6vc5" for this suite.
Sep  6 12:22:14.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:22:14.840: INFO: namespace: e2e-tests-configmap-t6vc5, resource: bindings, ignored listing per whitelist
Sep  6 12:22:14.920: INFO: namespace e2e-tests-configmap-t6vc5 deletion completed in 6.213295435s

• [SLOW TEST:8.348 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:22:14.920: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-sfckk
Sep  6 12:22:17.025: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-sfckk
STEP: checking the pod's current state and verifying that restartCount is present
Sep  6 12:22:17.029: INFO: Initial restart count of pod liveness-http is 0
Sep  6 12:22:37.087: INFO: Restart count of pod e2e-tests-container-probe-sfckk/liveness-http is now 1 (20.057835805s elapsed)
Sep  6 12:22:57.141: INFO: Restart count of pod e2e-tests-container-probe-sfckk/liveness-http is now 2 (40.11148349s elapsed)
Sep  6 12:23:17.189: INFO: Restart count of pod e2e-tests-container-probe-sfckk/liveness-http is now 3 (1m0.15959421s elapsed)
Sep  6 12:23:37.224: INFO: Restart count of pod e2e-tests-container-probe-sfckk/liveness-http is now 4 (1m20.194996699s elapsed)
Sep  6 12:24:47.371: INFO: Restart count of pod e2e-tests-container-probe-sfckk/liveness-http is now 5 (2m30.342032711s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:24:47.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-sfckk" for this suite.
Sep  6 12:24:53.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:24:53.458: INFO: namespace: e2e-tests-container-probe-sfckk, resource: bindings, ignored listing per whitelist
Sep  6 12:24:53.499: INFO: namespace e2e-tests-container-probe-sfckk deletion completed in 6.11770501s

• [SLOW TEST:158.579 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:24:53.499: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  6 12:24:53.577: INFO: Waiting up to 5m0s for pod "pod-54649f04-d0a1-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-bp9vj" to be "success or failure"
Sep  6 12:24:53.584: INFO: Pod "pod-54649f04-d0a1-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 7.090284ms
Sep  6 12:24:55.589: INFO: Pod "pod-54649f04-d0a1-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011225781s
STEP: Saw pod success
Sep  6 12:24:55.589: INFO: Pod "pod-54649f04-d0a1-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:24:55.591: INFO: Trying to get logs from node metalk8s-22 pod pod-54649f04-d0a1-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 12:24:55.611: INFO: Waiting for pod pod-54649f04-d0a1-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:24:55.613: INFO: Pod pod-54649f04-d0a1-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:24:55.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bp9vj" for this suite.
Sep  6 12:25:01.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:25:01.670: INFO: namespace: e2e-tests-emptydir-bp9vj, resource: bindings, ignored listing per whitelist
Sep  6 12:25:01.731: INFO: namespace e2e-tests-emptydir-bp9vj deletion completed in 6.115238543s

• [SLOW TEST:8.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:25:01.732: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 12:25:01.826: INFO: Waiting up to 5m0s for pod "downwardapi-volume-594f0f6b-d0a1-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-fvgfw" to be "success or failure"
Sep  6 12:25:01.832: INFO: Pod "downwardapi-volume-594f0f6b-d0a1-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 6.358142ms
Sep  6 12:25:03.836: INFO: Pod "downwardapi-volume-594f0f6b-d0a1-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.009486596s
Sep  6 12:25:05.839: INFO: Pod "downwardapi-volume-594f0f6b-d0a1-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012750722s
STEP: Saw pod success
Sep  6 12:25:05.839: INFO: Pod "downwardapi-volume-594f0f6b-d0a1-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:25:05.841: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-594f0f6b-d0a1-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 12:25:05.863: INFO: Waiting for pod downwardapi-volume-594f0f6b-d0a1-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:25:05.867: INFO: Pod downwardapi-volume-594f0f6b-d0a1-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:25:05.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fvgfw" for this suite.
Sep  6 12:25:11.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:25:11.938: INFO: namespace: e2e-tests-projected-fvgfw, resource: bindings, ignored listing per whitelist
Sep  6 12:25:12.078: INFO: namespace e2e-tests-projected-fvgfw deletion completed in 6.206097453s

• [SLOW TEST:10.346 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:25:12.078: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:25:17.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-jqpg4" for this suite.
Sep  6 12:25:39.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:25:39.342: INFO: namespace: e2e-tests-replication-controller-jqpg4, resource: bindings, ignored listing per whitelist
Sep  6 12:25:39.350: INFO: namespace e2e-tests-replication-controller-jqpg4 deletion completed in 22.125246175s

• [SLOW TEST:27.273 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:25:39.351: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  6 12:25:39.474: INFO: Number of nodes with available pods: 0
Sep  6 12:25:39.474: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:40.484: INFO: Number of nodes with available pods: 0
Sep  6 12:25:40.484: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:41.482: INFO: Number of nodes with available pods: 0
Sep  6 12:25:41.482: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:42.487: INFO: Number of nodes with available pods: 1
Sep  6 12:25:42.487: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep  6 12:25:42.513: INFO: Number of nodes with available pods: 0
Sep  6 12:25:42.513: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:43.523: INFO: Number of nodes with available pods: 0
Sep  6 12:25:43.523: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:44.520: INFO: Number of nodes with available pods: 0
Sep  6 12:25:44.520: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:45.523: INFO: Number of nodes with available pods: 0
Sep  6 12:25:45.523: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:46.523: INFO: Number of nodes with available pods: 0
Sep  6 12:25:46.523: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:47.527: INFO: Number of nodes with available pods: 0
Sep  6 12:25:47.527: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:48.533: INFO: Number of nodes with available pods: 0
Sep  6 12:25:48.533: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:49.533: INFO: Number of nodes with available pods: 0
Sep  6 12:25:49.533: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:50.521: INFO: Number of nodes with available pods: 0
Sep  6 12:25:50.521: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:51.523: INFO: Number of nodes with available pods: 0
Sep  6 12:25:51.523: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:52.520: INFO: Number of nodes with available pods: 0
Sep  6 12:25:52.520: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:53.526: INFO: Number of nodes with available pods: 0
Sep  6 12:25:53.526: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:54.527: INFO: Number of nodes with available pods: 0
Sep  6 12:25:54.527: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:55.521: INFO: Number of nodes with available pods: 0
Sep  6 12:25:55.521: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:56.520: INFO: Number of nodes with available pods: 0
Sep  6 12:25:56.520: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:57.523: INFO: Number of nodes with available pods: 0
Sep  6 12:25:57.523: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:58.522: INFO: Number of nodes with available pods: 0
Sep  6 12:25:58.522: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:25:59.523: INFO: Number of nodes with available pods: 0
Sep  6 12:25:59.523: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:00.519: INFO: Number of nodes with available pods: 0
Sep  6 12:26:00.519: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:01.529: INFO: Number of nodes with available pods: 0
Sep  6 12:26:01.529: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:02.520: INFO: Number of nodes with available pods: 0
Sep  6 12:26:02.520: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:03.520: INFO: Number of nodes with available pods: 0
Sep  6 12:26:03.520: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:04.520: INFO: Number of nodes with available pods: 0
Sep  6 12:26:04.520: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:05.523: INFO: Number of nodes with available pods: 0
Sep  6 12:26:05.523: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:06.520: INFO: Number of nodes with available pods: 0
Sep  6 12:26:06.520: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:07.520: INFO: Number of nodes with available pods: 0
Sep  6 12:26:07.520: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:08.519: INFO: Number of nodes with available pods: 0
Sep  6 12:26:08.519: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:09.521: INFO: Number of nodes with available pods: 0
Sep  6 12:26:09.521: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:10.519: INFO: Number of nodes with available pods: 0
Sep  6 12:26:10.519: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:11.522: INFO: Number of nodes with available pods: 0
Sep  6 12:26:11.522: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:12.519: INFO: Number of nodes with available pods: 0
Sep  6 12:26:12.519: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:13.520: INFO: Number of nodes with available pods: 0
Sep  6 12:26:13.520: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:14.522: INFO: Number of nodes with available pods: 0
Sep  6 12:26:14.522: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:15.522: INFO: Number of nodes with available pods: 0
Sep  6 12:26:15.522: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:16.519: INFO: Number of nodes with available pods: 0
Sep  6 12:26:16.519: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:17.521: INFO: Number of nodes with available pods: 0
Sep  6 12:26:17.522: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:18.520: INFO: Number of nodes with available pods: 0
Sep  6 12:26:18.520: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:19.519: INFO: Number of nodes with available pods: 0
Sep  6 12:26:19.519: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:20.520: INFO: Number of nodes with available pods: 0
Sep  6 12:26:20.520: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:21.524: INFO: Number of nodes with available pods: 0
Sep  6 12:26:21.524: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:22.523: INFO: Number of nodes with available pods: 0
Sep  6 12:26:22.523: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:26:23.520: INFO: Number of nodes with available pods: 1
Sep  6 12:26:23.520: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-zw9zp, will wait for the garbage collector to delete the pods
Sep  6 12:26:23.584: INFO: Deleting DaemonSet.extensions daemon-set took: 6.521467ms
Sep  6 12:26:23.685: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.270742ms
Sep  6 12:27:01.796: INFO: Number of nodes with available pods: 0
Sep  6 12:27:01.796: INFO: Number of running nodes: 0, number of available pods: 0
Sep  6 12:27:01.799: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zw9zp/daemonsets","resourceVersion":"15178"},"items":null}

Sep  6 12:27:01.801: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zw9zp/pods","resourceVersion":"15178"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:27:01.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zw9zp" for this suite.
Sep  6 12:27:07.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:27:07.874: INFO: namespace: e2e-tests-daemonsets-zw9zp, resource: bindings, ignored listing per whitelist
Sep  6 12:27:07.922: INFO: namespace e2e-tests-daemonsets-zw9zp deletion completed in 6.113452509s

• [SLOW TEST:88.571 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:27:07.922: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a484d45c-d0a1-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 12:27:08.027: INFO: Waiting up to 5m0s for pod "pod-secrets-a485ee66-d0a1-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-secrets-qttck" to be "success or failure"
Sep  6 12:27:08.035: INFO: Pod "pod-secrets-a485ee66-d0a1-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 7.972811ms
Sep  6 12:27:10.040: INFO: Pod "pod-secrets-a485ee66-d0a1-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.013215523s
Sep  6 12:27:12.051: INFO: Pod "pod-secrets-a485ee66-d0a1-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023958828s
STEP: Saw pod success
Sep  6 12:27:12.051: INFO: Pod "pod-secrets-a485ee66-d0a1-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:27:12.054: INFO: Trying to get logs from node metalk8s-22 pod pod-secrets-a485ee66-d0a1-11e9-9cef-86a5da7a2260 container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 12:27:12.087: INFO: Waiting for pod pod-secrets-a485ee66-d0a1-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:27:12.091: INFO: Pod pod-secrets-a485ee66-d0a1-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:27:12.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qttck" for this suite.
Sep  6 12:27:18.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:27:18.226: INFO: namespace: e2e-tests-secrets-qttck, resource: bindings, ignored listing per whitelist
Sep  6 12:27:18.324: INFO: namespace e2e-tests-secrets-qttck deletion completed in 6.218444135s

• [SLOW TEST:10.402 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:27:18.325: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-rhw6t/secret-test-aab911a8-d0a1-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 12:27:18.423: INFO: Waiting up to 5m0s for pod "pod-configmaps-aab9cdc9-d0a1-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-secrets-rhw6t" to be "success or failure"
Sep  6 12:27:18.427: INFO: Pod "pod-configmaps-aab9cdc9-d0a1-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 3.853514ms
Sep  6 12:27:20.434: INFO: Pod "pod-configmaps-aab9cdc9-d0a1-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011172927s
STEP: Saw pod success
Sep  6 12:27:20.434: INFO: Pod "pod-configmaps-aab9cdc9-d0a1-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:27:20.437: INFO: Trying to get logs from node metalk8s-22 pod pod-configmaps-aab9cdc9-d0a1-11e9-9cef-86a5da7a2260 container env-test: <nil>
STEP: delete the pod
Sep  6 12:27:20.470: INFO: Waiting for pod pod-configmaps-aab9cdc9-d0a1-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:27:20.475: INFO: Pod pod-configmaps-aab9cdc9-d0a1-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:27:20.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rhw6t" for this suite.
Sep  6 12:27:26.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:27:26.568: INFO: namespace: e2e-tests-secrets-rhw6t, resource: bindings, ignored listing per whitelist
Sep  6 12:27:26.598: INFO: namespace e2e-tests-secrets-rhw6t deletion completed in 6.118407137s

• [SLOW TEST:8.273 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:27:26.598: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 12:27:26.688: INFO: (0) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 13.113944ms)
Sep  6 12:27:26.694: INFO: (1) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.285702ms)
Sep  6 12:27:26.702: INFO: (2) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.959334ms)
Sep  6 12:27:26.712: INFO: (3) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.384585ms)
Sep  6 12:27:26.716: INFO: (4) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.065766ms)
Sep  6 12:27:26.721: INFO: (5) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.629083ms)
Sep  6 12:27:26.731: INFO: (6) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.59912ms)
Sep  6 12:27:26.736: INFO: (7) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.856852ms)
Sep  6 12:27:26.739: INFO: (8) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.424634ms)
Sep  6 12:27:26.743: INFO: (9) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.584783ms)
Sep  6 12:27:26.749: INFO: (10) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.017635ms)
Sep  6 12:27:26.758: INFO: (11) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.328017ms)
Sep  6 12:27:26.769: INFO: (12) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.496151ms)
Sep  6 12:27:26.775: INFO: (13) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.96293ms)
Sep  6 12:27:26.783: INFO: (14) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.064974ms)
Sep  6 12:27:26.788: INFO: (15) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.883492ms)
Sep  6 12:27:26.794: INFO: (16) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.333536ms)
Sep  6 12:27:26.801: INFO: (17) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.167811ms)
Sep  6 12:27:26.812: INFO: (18) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.701238ms)
Sep  6 12:27:26.818: INFO: (19) /api/v1/nodes/metalk8s-22:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.716796ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:27:26.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-jxhk6" for this suite.
Sep  6 12:27:32.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:27:32.944: INFO: namespace: e2e-tests-proxy-jxhk6, resource: bindings, ignored listing per whitelist
Sep  6 12:27:32.964: INFO: namespace e2e-tests-proxy-jxhk6 deletion completed in 6.142438956s

• [SLOW TEST:6.366 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:27:32.964: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 12:27:33.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-pk9xq'
Sep  6 12:27:33.174: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  6 12:27:33.174: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Sep  6 12:27:35.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-pk9xq'
Sep  6 12:27:35.346: INFO: stderr: ""
Sep  6 12:27:35.346: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:27:35.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pk9xq" for this suite.
Sep  6 12:27:41.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:27:41.432: INFO: namespace: e2e-tests-kubectl-pk9xq, resource: bindings, ignored listing per whitelist
Sep  6 12:27:41.501: INFO: namespace e2e-tests-kubectl-pk9xq deletion completed in 6.150473147s

• [SLOW TEST:8.537 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:27:41.501: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Sep  6 12:27:42.118: INFO: created pod pod-service-account-defaultsa
Sep  6 12:27:42.118: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep  6 12:27:42.124: INFO: created pod pod-service-account-mountsa
Sep  6 12:27:42.124: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep  6 12:27:42.129: INFO: created pod pod-service-account-nomountsa
Sep  6 12:27:42.129: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep  6 12:27:42.136: INFO: created pod pod-service-account-defaultsa-mountspec
Sep  6 12:27:42.136: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep  6 12:27:42.147: INFO: created pod pod-service-account-mountsa-mountspec
Sep  6 12:27:42.147: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep  6 12:27:42.174: INFO: created pod pod-service-account-nomountsa-mountspec
Sep  6 12:27:42.174: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep  6 12:27:42.214: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep  6 12:27:42.214: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep  6 12:27:42.241: INFO: created pod pod-service-account-mountsa-nomountspec
Sep  6 12:27:42.241: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep  6 12:27:42.265: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep  6 12:27:42.265: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:27:42.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-l457z" for this suite.
Sep  6 12:28:06.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:28:06.363: INFO: namespace: e2e-tests-svcaccounts-l457z, resource: bindings, ignored listing per whitelist
Sep  6 12:28:06.451: INFO: namespace e2e-tests-svcaccounts-l457z deletion completed in 24.175062019s

• [SLOW TEST:24.950 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:28:06.451: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Sep  6 12:28:06.534: INFO: Waiting up to 5m0s for pod "var-expansion-c7677d39-d0a1-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-var-expansion-8pqsk" to be "success or failure"
Sep  6 12:28:06.537: INFO: Pod "var-expansion-c7677d39-d0a1-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 3.794602ms
Sep  6 12:28:08.546: INFO: Pod "var-expansion-c7677d39-d0a1-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012819982s
STEP: Saw pod success
Sep  6 12:28:08.546: INFO: Pod "var-expansion-c7677d39-d0a1-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:28:08.551: INFO: Trying to get logs from node metalk8s-22 pod var-expansion-c7677d39-d0a1-11e9-9cef-86a5da7a2260 container dapi-container: <nil>
STEP: delete the pod
Sep  6 12:28:08.579: INFO: Waiting for pod var-expansion-c7677d39-d0a1-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:28:08.593: INFO: Pod var-expansion-c7677d39-d0a1-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:28:08.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-8pqsk" for this suite.
Sep  6 12:28:14.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:28:14.692: INFO: namespace: e2e-tests-var-expansion-8pqsk, resource: bindings, ignored listing per whitelist
Sep  6 12:28:14.746: INFO: namespace e2e-tests-var-expansion-8pqsk deletion completed in 6.144767986s

• [SLOW TEST:8.295 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:28:14.746: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 12:28:14.813: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:28:16.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-z7986" for this suite.
Sep  6 12:28:54.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:28:54.936: INFO: namespace: e2e-tests-pods-z7986, resource: bindings, ignored listing per whitelist
Sep  6 12:28:54.979: INFO: namespace e2e-tests-pods-z7986 deletion completed in 38.113733375s

• [SLOW TEST:40.233 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:28:54.979: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:28:57.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-lbscn" for this suite.
Sep  6 12:29:03.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:29:03.231: INFO: namespace: e2e-tests-emptydir-wrapper-lbscn, resource: bindings, ignored listing per whitelist
Sep  6 12:29:03.253: INFO: namespace e2e-tests-emptydir-wrapper-lbscn deletion completed in 6.129395891s

• [SLOW TEST:8.274 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:29:03.254: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-6dtb
STEP: Creating a pod to test atomic-volume-subpath
Sep  6 12:29:03.355: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-6dtb" in namespace "e2e-tests-subpath-tcgct" to be "success or failure"
Sep  6 12:29:03.363: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.416748ms
Sep  6 12:29:05.375: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019712174s
Sep  6 12:29:07.379: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Running", Reason="", readiness=false. Elapsed: 4.024057223s
Sep  6 12:29:09.384: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Running", Reason="", readiness=false. Elapsed: 6.02916067s
Sep  6 12:29:11.388: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Running", Reason="", readiness=false. Elapsed: 8.032711037s
Sep  6 12:29:13.392: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Running", Reason="", readiness=false. Elapsed: 10.036904223s
Sep  6 12:29:15.397: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Running", Reason="", readiness=false. Elapsed: 12.041509547s
Sep  6 12:29:17.399: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Running", Reason="", readiness=false. Elapsed: 14.044210463s
Sep  6 12:29:19.403: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Running", Reason="", readiness=false. Elapsed: 16.04770583s
Sep  6 12:29:21.406: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Running", Reason="", readiness=false. Elapsed: 18.051045328s
Sep  6 12:29:23.410: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Running", Reason="", readiness=false. Elapsed: 20.054937049s
Sep  6 12:29:25.413: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Running", Reason="", readiness=false. Elapsed: 22.058280161s
Sep  6 12:29:27.416: INFO: Pod "pod-subpath-test-projected-6dtb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.061274425s
STEP: Saw pod success
Sep  6 12:29:27.416: INFO: Pod "pod-subpath-test-projected-6dtb" satisfied condition "success or failure"
Sep  6 12:29:27.420: INFO: Trying to get logs from node metalk8s-22 pod pod-subpath-test-projected-6dtb container test-container-subpath-projected-6dtb: <nil>
STEP: delete the pod
Sep  6 12:29:27.441: INFO: Waiting for pod pod-subpath-test-projected-6dtb to disappear
Sep  6 12:29:27.445: INFO: Pod pod-subpath-test-projected-6dtb no longer exists
STEP: Deleting pod pod-subpath-test-projected-6dtb
Sep  6 12:29:27.447: INFO: Deleting pod "pod-subpath-test-projected-6dtb" in namespace "e2e-tests-subpath-tcgct"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:29:27.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-tcgct" for this suite.
Sep  6 12:29:33.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:29:33.564: INFO: namespace: e2e-tests-subpath-tcgct, resource: bindings, ignored listing per whitelist
Sep  6 12:29:33.616: INFO: namespace e2e-tests-subpath-tcgct deletion completed in 6.159318734s

• [SLOW TEST:30.362 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:29:33.616: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-fb61db6b-d0a1-11e9-9cef-86a5da7a2260
STEP: Creating configMap with name cm-test-opt-upd-fb61dbe0-d0a1-11e9-9cef-86a5da7a2260
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fb61db6b-d0a1-11e9-9cef-86a5da7a2260
STEP: Updating configmap cm-test-opt-upd-fb61dbe0-d0a1-11e9-9cef-86a5da7a2260
STEP: Creating configMap with name cm-test-opt-create-fb61dbfb-d0a1-11e9-9cef-86a5da7a2260
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:30:52.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k4fbg" for this suite.
Sep  6 12:31:10.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:31:10.203: INFO: namespace: e2e-tests-projected-k4fbg, resource: bindings, ignored listing per whitelist
Sep  6 12:31:10.335: INFO: namespace e2e-tests-projected-k4fbg deletion completed in 18.155599643s

• [SLOW TEST:96.719 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:31:10.335: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  6 12:31:13.003: INFO: Successfully updated pod "annotationupdate350548ac-d0a2-11e9-9cef-86a5da7a2260"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:31:15.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rjxmm" for this suite.
Sep  6 12:31:37.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:31:37.113: INFO: namespace: e2e-tests-downward-api-rjxmm, resource: bindings, ignored listing per whitelist
Sep  6 12:31:37.226: INFO: namespace e2e-tests-downward-api-rjxmm deletion completed in 22.134814995s

• [SLOW TEST:26.890 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:31:37.226: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-v4bd9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  6 12:31:37.330: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  6 12:32:01.408: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.217.119:8080/dial?request=hostName&protocol=http&host=10.233.217.102&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-v4bd9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  6 12:32:01.408: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
Sep  6 12:32:01.725: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:32:01.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-v4bd9" for this suite.
Sep  6 12:32:23.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:32:23.797: INFO: namespace: e2e-tests-pod-network-test-v4bd9, resource: bindings, ignored listing per whitelist
Sep  6 12:32:23.856: INFO: namespace e2e-tests-pod-network-test-v4bd9 deletion completed in 22.127556475s

• [SLOW TEST:46.630 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:32:23.856: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  6 12:32:23.925: INFO: Waiting up to 5m0s for pod "pod-60d20332-d0a2-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-phg5p" to be "success or failure"
Sep  6 12:32:23.950: INFO: Pod "pod-60d20332-d0a2-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 25.608184ms
Sep  6 12:32:25.967: INFO: Pod "pod-60d20332-d0a2-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.041807084s
STEP: Saw pod success
Sep  6 12:32:25.967: INFO: Pod "pod-60d20332-d0a2-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:32:25.975: INFO: Trying to get logs from node metalk8s-22 pod pod-60d20332-d0a2-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 12:32:26.004: INFO: Waiting for pod pod-60d20332-d0a2-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:32:26.016: INFO: Pod pod-60d20332-d0a2-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:32:26.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-phg5p" for this suite.
Sep  6 12:32:32.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:32:32.147: INFO: namespace: e2e-tests-emptydir-phg5p, resource: bindings, ignored listing per whitelist
Sep  6 12:32:32.197: INFO: namespace e2e-tests-emptydir-phg5p deletion completed in 6.176633206s

• [SLOW TEST:8.341 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:32:32.198: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Sep  6 12:32:34.310: INFO: Pod pod-hostip-65cf134f-d0a2-11e9-9cef-86a5da7a2260 has hostIP: 10.10.0.6
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:32:34.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-k27t4" for this suite.
Sep  6 12:32:56.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:32:56.383: INFO: namespace: e2e-tests-pods-k27t4, resource: bindings, ignored listing per whitelist
Sep  6 12:32:56.417: INFO: namespace e2e-tests-pods-k27t4 deletion completed in 22.104209022s

• [SLOW TEST:24.219 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:32:56.417: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0906 12:33:06.547026      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 12:33:06.547: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:33:06.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gwp4z" for this suite.
Sep  6 12:33:12.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:33:12.631: INFO: namespace: e2e-tests-gc-gwp4z, resource: bindings, ignored listing per whitelist
Sep  6 12:33:12.720: INFO: namespace e2e-tests-gc-gwp4z deletion completed in 6.171102633s

• [SLOW TEST:16.303 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:33:12.721: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:33:12.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-pnh8k" for this suite.
Sep  6 12:33:18.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:33:19.060: INFO: namespace: e2e-tests-kubelet-test-pnh8k, resource: bindings, ignored listing per whitelist
Sep  6 12:33:19.095: INFO: namespace e2e-tests-kubelet-test-pnh8k deletion completed in 6.179830848s

• [SLOW TEST:6.374 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:33:19.095: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-81c139e5-d0a2-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 12:33:19.186: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-81c1c69f-d0a2-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-psw6j" to be "success or failure"
Sep  6 12:33:19.189: INFO: Pod "pod-projected-configmaps-81c1c69f-d0a2-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 3.235385ms
Sep  6 12:33:21.192: INFO: Pod "pod-projected-configmaps-81c1c69f-d0a2-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.006410783s
Sep  6 12:33:23.195: INFO: Pod "pod-projected-configmaps-81c1c69f-d0a2-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009189204s
STEP: Saw pod success
Sep  6 12:33:23.195: INFO: Pod "pod-projected-configmaps-81c1c69f-d0a2-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:33:23.197: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-configmaps-81c1c69f-d0a2-11e9-9cef-86a5da7a2260 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 12:33:23.217: INFO: Waiting for pod pod-projected-configmaps-81c1c69f-d0a2-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:33:23.219: INFO: Pod pod-projected-configmaps-81c1c69f-d0a2-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:33:23.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-psw6j" for this suite.
Sep  6 12:33:29.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:33:29.275: INFO: namespace: e2e-tests-projected-psw6j, resource: bindings, ignored listing per whitelist
Sep  6 12:33:29.355: INFO: namespace e2e-tests-projected-psw6j deletion completed in 6.132326372s

• [SLOW TEST:10.259 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:33:29.355: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 12:33:29.453: INFO: Waiting up to 5m0s for pod "downwardapi-volume-87e07ee8-d0a2-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-2pt4k" to be "success or failure"
Sep  6 12:33:29.460: INFO: Pod "downwardapi-volume-87e07ee8-d0a2-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 7.543457ms
Sep  6 12:33:31.465: INFO: Pod "downwardapi-volume-87e07ee8-d0a2-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012110155s
STEP: Saw pod success
Sep  6 12:33:31.465: INFO: Pod "downwardapi-volume-87e07ee8-d0a2-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:33:31.468: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-87e07ee8-d0a2-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 12:33:31.484: INFO: Waiting for pod downwardapi-volume-87e07ee8-d0a2-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:33:31.489: INFO: Pod downwardapi-volume-87e07ee8-d0a2-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:33:31.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2pt4k" for this suite.
Sep  6 12:33:37.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:33:37.566: INFO: namespace: e2e-tests-downward-api-2pt4k, resource: bindings, ignored listing per whitelist
Sep  6 12:33:37.626: INFO: namespace e2e-tests-downward-api-2pt4k deletion completed in 6.131682599s

• [SLOW TEST:8.271 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:33:37.626: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 12:33:37.691: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:33:38.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-4r7s5" for this suite.
Sep  6 12:33:44.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:33:44.785: INFO: namespace: e2e-tests-custom-resource-definition-4r7s5, resource: bindings, ignored listing per whitelist
Sep  6 12:33:44.918: INFO: namespace e2e-tests-custom-resource-definition-4r7s5 deletion completed in 6.163609523s

• [SLOW TEST:7.291 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:33:44.918: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep  6 12:33:47.071: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-91281f46-d0a2-11e9-9cef-86a5da7a2260,GenerateName:,Namespace:e2e-tests-events-z9cfw,SelfLink:/api/v1/namespaces/e2e-tests-events-z9cfw/pods/send-events-91281f46-d0a2-11e9-9cef-86a5da7a2260,UID:91298623-d0a2-11e9-baa3-fa163efa26fe,ResourceVersion:16561,Generation:0,CreationTimestamp:2019-09-06 12:33:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 11603684,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.121/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5t6xf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5t6xf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-5t6xf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ec080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ec0a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:33:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:33:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:33:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:33:45 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.121,StartTime:2019-09-06 12:33:45 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-06 12:33:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://db20530f5342f1144f69785ad1e21d86077d0f95aefa2b0e8fab71b8b8bd52b0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep  6 12:33:49.075: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep  6 12:33:51.082: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:33:51.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-z9cfw" for this suite.
Sep  6 12:34:33.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:34:33.203: INFO: namespace: e2e-tests-events-z9cfw, resource: bindings, ignored listing per whitelist
Sep  6 12:34:33.217: INFO: namespace e2e-tests-events-z9cfw deletion completed in 42.121373491s

• [SLOW TEST:48.299 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:34:33.218: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-adeeb69c-d0a2-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 12:34:33.299: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-adef56ca-d0a2-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-dwfls" to be "success or failure"
Sep  6 12:34:33.305: INFO: Pod "pod-projected-configmaps-adef56ca-d0a2-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 5.223004ms
Sep  6 12:34:35.308: INFO: Pod "pod-projected-configmaps-adef56ca-d0a2-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009065701s
STEP: Saw pod success
Sep  6 12:34:35.309: INFO: Pod "pod-projected-configmaps-adef56ca-d0a2-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:34:35.313: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-configmaps-adef56ca-d0a2-11e9-9cef-86a5da7a2260 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 12:34:35.328: INFO: Waiting for pod pod-projected-configmaps-adef56ca-d0a2-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:34:35.332: INFO: Pod pod-projected-configmaps-adef56ca-d0a2-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:34:35.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dwfls" for this suite.
Sep  6 12:34:41.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:34:41.424: INFO: namespace: e2e-tests-projected-dwfls, resource: bindings, ignored listing per whitelist
Sep  6 12:34:41.544: INFO: namespace e2e-tests-projected-dwfls deletion completed in 6.208906432s

• [SLOW TEST:8.326 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:34:41.545: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0906 12:35:21.694296      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  6 12:35:21.694: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:35:21.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-c4pwg" for this suite.
Sep  6 12:35:27.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:35:28.005: INFO: namespace: e2e-tests-gc-c4pwg, resource: bindings, ignored listing per whitelist
Sep  6 12:35:28.058: INFO: namespace e2e-tests-gc-c4pwg deletion completed in 6.359743865s

• [SLOW TEST:46.513 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:35:28.058: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  6 12:35:34.340: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 12:35:34.343: INFO: Pod pod-with-prestop-http-hook still exists
Sep  6 12:35:36.344: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 12:35:36.357: INFO: Pod pod-with-prestop-http-hook still exists
Sep  6 12:35:38.343: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 12:35:38.346: INFO: Pod pod-with-prestop-http-hook still exists
Sep  6 12:35:40.343: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 12:35:40.346: INFO: Pod pod-with-prestop-http-hook still exists
Sep  6 12:35:42.343: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  6 12:35:42.347: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:35:42.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-fl5ms" for this suite.
Sep  6 12:36:04.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:36:04.463: INFO: namespace: e2e-tests-container-lifecycle-hook-fl5ms, resource: bindings, ignored listing per whitelist
Sep  6 12:36:04.514: INFO: namespace e2e-tests-container-lifecycle-hook-fl5ms deletion completed in 22.148987654s

• [SLOW TEST:36.456 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:36:04.514: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 12:36:04.591: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e457b628-d0a2-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-v4822" to be "success or failure"
Sep  6 12:36:04.600: INFO: Pod "downwardapi-volume-e457b628-d0a2-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 8.432742ms
Sep  6 12:36:06.605: INFO: Pod "downwardapi-volume-e457b628-d0a2-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013428928s
STEP: Saw pod success
Sep  6 12:36:06.605: INFO: Pod "downwardapi-volume-e457b628-d0a2-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:36:06.612: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-e457b628-d0a2-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 12:36:06.632: INFO: Waiting for pod downwardapi-volume-e457b628-d0a2-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:36:06.636: INFO: Pod downwardapi-volume-e457b628-d0a2-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:36:06.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v4822" for this suite.
Sep  6 12:36:12.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:36:12.799: INFO: namespace: e2e-tests-projected-v4822, resource: bindings, ignored listing per whitelist
Sep  6 12:36:12.871: INFO: namespace e2e-tests-projected-v4822 deletion completed in 6.221608884s

• [SLOW TEST:8.356 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:36:12.871: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  6 12:36:17.174: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 12:36:17.179: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 12:36:19.179: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 12:36:19.182: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 12:36:21.179: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 12:36:21.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 12:36:23.179: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 12:36:23.182: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 12:36:25.182: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 12:36:25.185: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 12:36:27.179: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 12:36:27.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 12:36:29.179: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 12:36:29.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 12:36:31.179: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 12:36:31.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 12:36:33.179: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 12:36:33.183: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 12:36:35.179: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 12:36:35.184: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  6 12:36:37.179: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  6 12:36:37.183: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:36:37.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-dxbct" for this suite.
Sep  6 12:36:59.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:36:59.298: INFO: namespace: e2e-tests-container-lifecycle-hook-dxbct, resource: bindings, ignored listing per whitelist
Sep  6 12:36:59.318: INFO: namespace e2e-tests-container-lifecycle-hook-dxbct deletion completed in 22.124132213s

• [SLOW TEST:46.447 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:36:59.318: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-05079e64-d0a3-11e9-9cef-86a5da7a2260
Sep  6 12:36:59.420: INFO: Pod name my-hostname-basic-05079e64-d0a3-11e9-9cef-86a5da7a2260: Found 0 pods out of 1
Sep  6 12:37:04.435: INFO: Pod name my-hostname-basic-05079e64-d0a3-11e9-9cef-86a5da7a2260: Found 1 pods out of 1
Sep  6 12:37:04.435: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-05079e64-d0a3-11e9-9cef-86a5da7a2260" are running
Sep  6 12:37:04.439: INFO: Pod "my-hostname-basic-05079e64-d0a3-11e9-9cef-86a5da7a2260-nrblt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 12:36:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 12:37:00 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 12:37:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 12:36:59 +0000 UTC Reason: Message:}])
Sep  6 12:37:04.439: INFO: Trying to dial the pod
Sep  6 12:37:09.452: INFO: Controller my-hostname-basic-05079e64-d0a3-11e9-9cef-86a5da7a2260: Got expected result from replica 1 [my-hostname-basic-05079e64-d0a3-11e9-9cef-86a5da7a2260-nrblt]: "my-hostname-basic-05079e64-d0a3-11e9-9cef-86a5da7a2260-nrblt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:37:09.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-9mx2n" for this suite.
Sep  6 12:37:15.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:37:15.492: INFO: namespace: e2e-tests-replication-controller-9mx2n, resource: bindings, ignored listing per whitelist
Sep  6 12:37:15.555: INFO: namespace e2e-tests-replication-controller-9mx2n deletion completed in 6.098695851s

• [SLOW TEST:16.236 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:37:15.555: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  6 12:37:15.641: INFO: Number of nodes with available pods: 0
Sep  6 12:37:15.641: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:37:16.649: INFO: Number of nodes with available pods: 0
Sep  6 12:37:16.649: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:37:17.647: INFO: Number of nodes with available pods: 0
Sep  6 12:37:17.647: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:37:18.646: INFO: Number of nodes with available pods: 1
Sep  6 12:37:18.646: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep  6 12:37:18.669: INFO: Number of nodes with available pods: 0
Sep  6 12:37:18.669: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:37:19.675: INFO: Number of nodes with available pods: 0
Sep  6 12:37:19.675: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:37:20.675: INFO: Number of nodes with available pods: 1
Sep  6 12:37:20.675: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-m7p8s, will wait for the garbage collector to delete the pods
Sep  6 12:37:20.739: INFO: Deleting DaemonSet.extensions daemon-set took: 5.416203ms
Sep  6 12:37:20.840: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.244982ms
Sep  6 12:37:53.943: INFO: Number of nodes with available pods: 0
Sep  6 12:37:53.944: INFO: Number of running nodes: 0, number of available pods: 0
Sep  6 12:37:53.946: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-m7p8s/daemonsets","resourceVersion":"17465"},"items":null}

Sep  6 12:37:53.948: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-m7p8s/pods","resourceVersion":"17465"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:37:53.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-m7p8s" for this suite.
Sep  6 12:37:59.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:38:00.082: INFO: namespace: e2e-tests-daemonsets-m7p8s, resource: bindings, ignored listing per whitelist
Sep  6 12:38:00.103: INFO: namespace e2e-tests-daemonsets-m7p8s deletion completed in 6.140706296s

• [SLOW TEST:44.549 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:38:00.104: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:39:00.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-56hnf" for this suite.
Sep  6 12:39:22.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:39:22.308: INFO: namespace: e2e-tests-container-probe-56hnf, resource: bindings, ignored listing per whitelist
Sep  6 12:39:22.387: INFO: namespace e2e-tests-container-probe-56hnf deletion completed in 22.177934453s

• [SLOW TEST:82.283 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:39:22.387: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  6 12:39:22.465: INFO: PodSpec: initContainers in spec.initContainers
Sep  6 12:40:04.710: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-5a4b7f26-d0a3-11e9-9cef-86a5da7a2260", GenerateName:"", Namespace:"e2e-tests-init-container-xhb9h", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-xhb9h/pods/pod-init-5a4b7f26-d0a3-11e9-9cef-86a5da7a2260", UID:"5a4bdf28-d0a3-11e9-baa3-fa163efa26fe", ResourceVersion:"17730", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703370362, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"465467444"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.233.217.110/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-rk254", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001d92080), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rk254", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rk254", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rk254", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001eee0b8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"metalk8s-22", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00236e060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001eee140)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001eee170)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001eee178), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001eee17c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370362, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370362, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370362, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370362, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.0.6", PodIP:"10.233.217.110", StartTime:(*v1.Time)(0xc000f1c080), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0003a24d0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0003a2b60)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://6e9e485ddd41f2d20ac5c392d884e004d6e4a0637c1a3465b0c4f2d5633d49cf"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000f1c100), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000f1c0c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:40:04.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xhb9h" for this suite.
Sep  6 12:40:26.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:40:26.826: INFO: namespace: e2e-tests-init-container-xhb9h, resource: bindings, ignored listing per whitelist
Sep  6 12:40:26.847: INFO: namespace e2e-tests-init-container-xhb9h deletion completed in 22.129094989s

• [SLOW TEST:64.460 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:40:26.847: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-80b6878f-d0a3-11e9-9cef-86a5da7a2260
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-80b6878f-d0a3-11e9-9cef-86a5da7a2260
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:40:30.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mzdc8" for this suite.
Sep  6 12:40:52.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:40:53.103: INFO: namespace: e2e-tests-configmap-mzdc8, resource: bindings, ignored listing per whitelist
Sep  6 12:40:53.107: INFO: namespace e2e-tests-configmap-mzdc8 deletion completed in 22.121338664s

• [SLOW TEST:26.259 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:40:53.107: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  6 12:40:53.224: INFO: Waiting up to 5m0s for pod "downward-api-90631894-d0a3-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-hqzhn" to be "success or failure"
Sep  6 12:40:53.229: INFO: Pod "downward-api-90631894-d0a3-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 5.324469ms
Sep  6 12:40:55.246: INFO: Pod "downward-api-90631894-d0a3-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022604964s
STEP: Saw pod success
Sep  6 12:40:55.246: INFO: Pod "downward-api-90631894-d0a3-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:40:55.250: INFO: Trying to get logs from node metalk8s-22 pod downward-api-90631894-d0a3-11e9-9cef-86a5da7a2260 container dapi-container: <nil>
STEP: delete the pod
Sep  6 12:40:55.315: INFO: Waiting for pod downward-api-90631894-d0a3-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:40:55.326: INFO: Pod downward-api-90631894-d0a3-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:40:55.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hqzhn" for this suite.
Sep  6 12:41:01.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:41:01.511: INFO: namespace: e2e-tests-downward-api-hqzhn, resource: bindings, ignored listing per whitelist
Sep  6 12:41:01.541: INFO: namespace e2e-tests-downward-api-hqzhn deletion completed in 6.180773943s

• [SLOW TEST:8.434 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:41:01.541: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-95631c53-d0a3-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 12:41:01.615: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9563c256-d0a3-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-h66ss" to be "success or failure"
Sep  6 12:41:01.665: INFO: Pod "pod-projected-configmaps-9563c256-d0a3-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 50.066282ms
Sep  6 12:41:03.669: INFO: Pod "pod-projected-configmaps-9563c256-d0a3-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.05361847s
STEP: Saw pod success
Sep  6 12:41:03.669: INFO: Pod "pod-projected-configmaps-9563c256-d0a3-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:41:03.674: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-configmaps-9563c256-d0a3-11e9-9cef-86a5da7a2260 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 12:41:03.690: INFO: Waiting for pod pod-projected-configmaps-9563c256-d0a3-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:41:03.696: INFO: Pod pod-projected-configmaps-9563c256-d0a3-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:41:03.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h66ss" for this suite.
Sep  6 12:41:09.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:41:09.823: INFO: namespace: e2e-tests-projected-h66ss, resource: bindings, ignored listing per whitelist
Sep  6 12:41:09.823: INFO: namespace e2e-tests-projected-h66ss deletion completed in 6.124301326s

• [SLOW TEST:8.283 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:41:09.824: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  6 12:41:16.006: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:16.013: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:18.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:18.018: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:20.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:20.016: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:22.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:22.019: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:24.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:24.017: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:26.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:26.021: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:28.013: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:28.017: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:30.013: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:30.017: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:32.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:32.021: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:34.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:34.017: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:36.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:36.017: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:38.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:38.017: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:40.013: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:40.016: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  6 12:41:42.014: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  6 12:41:42.017: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:41:42.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-z7r6g" for this suite.
Sep  6 12:42:04.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:42:04.043: INFO: namespace: e2e-tests-container-lifecycle-hook-z7r6g, resource: bindings, ignored listing per whitelist
Sep  6 12:42:04.119: INFO: namespace e2e-tests-container-lifecycle-hook-z7r6g deletion completed in 22.098303422s

• [SLOW TEST:54.295 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:42:04.119: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep  6 12:42:04.223: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dzsq7,SelfLink:/api/v1/namespaces/e2e-tests-watch-dzsq7/configmaps/e2e-watch-test-label-changed,UID:bab20a4f-d0a3-11e9-baa3-fa163efa26fe,ResourceVersion:18066,Generation:0,CreationTimestamp:2019-09-06 12:42:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  6 12:42:04.223: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dzsq7,SelfLink:/api/v1/namespaces/e2e-tests-watch-dzsq7/configmaps/e2e-watch-test-label-changed,UID:bab20a4f-d0a3-11e9-baa3-fa163efa26fe,ResourceVersion:18067,Generation:0,CreationTimestamp:2019-09-06 12:42:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  6 12:42:04.223: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dzsq7,SelfLink:/api/v1/namespaces/e2e-tests-watch-dzsq7/configmaps/e2e-watch-test-label-changed,UID:bab20a4f-d0a3-11e9-baa3-fa163efa26fe,ResourceVersion:18068,Generation:0,CreationTimestamp:2019-09-06 12:42:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep  6 12:42:14.281: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dzsq7,SelfLink:/api/v1/namespaces/e2e-tests-watch-dzsq7/configmaps/e2e-watch-test-label-changed,UID:bab20a4f-d0a3-11e9-baa3-fa163efa26fe,ResourceVersion:18083,Generation:0,CreationTimestamp:2019-09-06 12:42:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  6 12:42:14.281: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dzsq7,SelfLink:/api/v1/namespaces/e2e-tests-watch-dzsq7/configmaps/e2e-watch-test-label-changed,UID:bab20a4f-d0a3-11e9-baa3-fa163efa26fe,ResourceVersion:18084,Generation:0,CreationTimestamp:2019-09-06 12:42:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep  6 12:42:14.284: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-dzsq7,SelfLink:/api/v1/namespaces/e2e-tests-watch-dzsq7/configmaps/e2e-watch-test-label-changed,UID:bab20a4f-d0a3-11e9-baa3-fa163efa26fe,ResourceVersion:18085,Generation:0,CreationTimestamp:2019-09-06 12:42:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:42:14.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-dzsq7" for this suite.
Sep  6 12:42:20.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:42:20.401: INFO: namespace: e2e-tests-watch-dzsq7, resource: bindings, ignored listing per whitelist
Sep  6 12:42:20.424: INFO: namespace e2e-tests-watch-dzsq7 deletion completed in 6.128529065s

• [SLOW TEST:16.305 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:42:20.424: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  6 12:42:20.512: INFO: Waiting up to 5m0s for pod "downward-api-c469e0cd-d0a3-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-88vp7" to be "success or failure"
Sep  6 12:42:20.537: INFO: Pod "downward-api-c469e0cd-d0a3-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 25.058301ms
Sep  6 12:42:22.551: INFO: Pod "downward-api-c469e0cd-d0a3-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.038510356s
Sep  6 12:42:24.555: INFO: Pod "downward-api-c469e0cd-d0a3-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042267774s
STEP: Saw pod success
Sep  6 12:42:24.555: INFO: Pod "downward-api-c469e0cd-d0a3-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:42:24.558: INFO: Trying to get logs from node metalk8s-22 pod downward-api-c469e0cd-d0a3-11e9-9cef-86a5da7a2260 container dapi-container: <nil>
STEP: delete the pod
Sep  6 12:42:24.605: INFO: Waiting for pod downward-api-c469e0cd-d0a3-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:42:24.609: INFO: Pod downward-api-c469e0cd-d0a3-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:42:24.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-88vp7" for this suite.
Sep  6 12:42:30.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:42:30.745: INFO: namespace: e2e-tests-downward-api-88vp7, resource: bindings, ignored listing per whitelist
Sep  6 12:42:30.766: INFO: namespace e2e-tests-downward-api-88vp7 deletion completed in 6.153446891s

• [SLOW TEST:10.342 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:42:30.766: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-ca9e1dae-d0a3-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 12:42:30.958: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ca9f0886-d0a3-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-5bvtc" to be "success or failure"
Sep  6 12:42:31.008: INFO: Pod "pod-projected-secrets-ca9f0886-d0a3-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 49.744736ms
Sep  6 12:42:33.016: INFO: Pod "pod-projected-secrets-ca9f0886-d0a3-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.05765921s
STEP: Saw pod success
Sep  6 12:42:33.016: INFO: Pod "pod-projected-secrets-ca9f0886-d0a3-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:42:33.020: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-secrets-ca9f0886-d0a3-11e9-9cef-86a5da7a2260 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  6 12:42:33.040: INFO: Waiting for pod pod-projected-secrets-ca9f0886-d0a3-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:42:33.052: INFO: Pod pod-projected-secrets-ca9f0886-d0a3-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:42:33.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5bvtc" for this suite.
Sep  6 12:42:39.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:42:39.176: INFO: namespace: e2e-tests-projected-5bvtc, resource: bindings, ignored listing per whitelist
Sep  6 12:42:39.186: INFO: namespace e2e-tests-projected-5bvtc deletion completed in 6.129546891s

• [SLOW TEST:8.420 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:42:39.186: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  6 12:42:39.256: INFO: Waiting up to 5m0s for pod "pod-cf964ec7-d0a3-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-lccpl" to be "success or failure"
Sep  6 12:42:39.261: INFO: Pod "pod-cf964ec7-d0a3-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 5.16145ms
Sep  6 12:42:41.265: INFO: Pod "pod-cf964ec7-d0a3-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008621886s
STEP: Saw pod success
Sep  6 12:42:41.265: INFO: Pod "pod-cf964ec7-d0a3-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:42:41.273: INFO: Trying to get logs from node metalk8s-22 pod pod-cf964ec7-d0a3-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 12:42:41.323: INFO: Waiting for pod pod-cf964ec7-d0a3-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:42:41.325: INFO: Pod pod-cf964ec7-d0a3-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:42:41.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lccpl" for this suite.
Sep  6 12:42:47.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:42:47.354: INFO: namespace: e2e-tests-emptydir-lccpl, resource: bindings, ignored listing per whitelist
Sep  6 12:42:47.455: INFO: namespace e2e-tests-emptydir-lccpl deletion completed in 6.125077292s

• [SLOW TEST:8.269 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:42:47.455: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep  6 12:42:47.852: INFO: Pod name wrapped-volume-race-d4b3d811-d0a3-11e9-9cef-86a5da7a2260: Found 0 pods out of 5
Sep  6 12:42:52.858: INFO: Pod name wrapped-volume-race-d4b3d811-d0a3-11e9-9cef-86a5da7a2260: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d4b3d811-d0a3-11e9-9cef-86a5da7a2260 in namespace e2e-tests-emptydir-wrapper-2c45k, will wait for the garbage collector to delete the pods
Sep  6 12:43:04.955: INFO: Deleting ReplicationController wrapped-volume-race-d4b3d811-d0a3-11e9-9cef-86a5da7a2260 took: 9.267163ms
Sep  6 12:43:05.055: INFO: Terminating ReplicationController wrapped-volume-race-d4b3d811-d0a3-11e9-9cef-86a5da7a2260 pods took: 100.228046ms
STEP: Creating RC which spawns configmap-volume pods
Sep  6 12:43:40.316: INFO: Pod name wrapped-volume-race-f3f32858-d0a3-11e9-9cef-86a5da7a2260: Found 0 pods out of 5
Sep  6 12:43:45.334: INFO: Pod name wrapped-volume-race-f3f32858-d0a3-11e9-9cef-86a5da7a2260: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f3f32858-d0a3-11e9-9cef-86a5da7a2260 in namespace e2e-tests-emptydir-wrapper-2c45k, will wait for the garbage collector to delete the pods
Sep  6 12:43:57.442: INFO: Deleting ReplicationController wrapped-volume-race-f3f32858-d0a3-11e9-9cef-86a5da7a2260 took: 14.967001ms
Sep  6 12:43:57.544: INFO: Terminating ReplicationController wrapped-volume-race-f3f32858-d0a3-11e9-9cef-86a5da7a2260 pods took: 101.741693ms
STEP: Creating RC which spawns configmap-volume pods
Sep  6 12:44:33.187: INFO: Pod name wrapped-volume-race-137a8bf9-d0a4-11e9-9cef-86a5da7a2260: Found 0 pods out of 5
Sep  6 12:44:38.192: INFO: Pod name wrapped-volume-race-137a8bf9-d0a4-11e9-9cef-86a5da7a2260: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-137a8bf9-d0a4-11e9-9cef-86a5da7a2260 in namespace e2e-tests-emptydir-wrapper-2c45k, will wait for the garbage collector to delete the pods
Sep  6 12:44:50.314: INFO: Deleting ReplicationController wrapped-volume-race-137a8bf9-d0a4-11e9-9cef-86a5da7a2260 took: 10.04405ms
Sep  6 12:44:50.514: INFO: Terminating ReplicationController wrapped-volume-race-137a8bf9-d0a4-11e9-9cef-86a5da7a2260 pods took: 200.420402ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:45:32.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-2c45k" for this suite.
Sep  6 12:45:38.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:45:38.394: INFO: namespace: e2e-tests-emptydir-wrapper-2c45k, resource: bindings, ignored listing per whitelist
Sep  6 12:45:38.472: INFO: namespace e2e-tests-emptydir-wrapper-2c45k deletion completed in 6.121699171s

• [SLOW TEST:171.017 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:45:38.473: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 12:45:38.530: INFO: Creating deployment "test-recreate-deployment"
Sep  6 12:45:38.535: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep  6 12:45:38.540: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Sep  6 12:45:40.550: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep  6 12:45:40.554: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep  6 12:45:40.563: INFO: Updating deployment test-recreate-deployment
Sep  6 12:45:40.563: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  6 12:45:40.660: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-8w9st,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8w9st/deployments/test-recreate-deployment,UID:3a72ad6b-d0a4-11e9-baa3-fa163efa26fe,ResourceVersion:19455,Generation:2,CreationTimestamp:2019-09-06 12:45:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-06 12:45:40 +0000 UTC 2019-09-06 12:45:40 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-06 12:45:40 +0000 UTC 2019-09-06 12:45:38 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep  6 12:45:40.666: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-8w9st,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8w9st/replicasets/test-recreate-deployment-697fbf54bf,UID:3bb2a6b3-d0a4-11e9-baa3-fa163efa26fe,ResourceVersion:19452,Generation:1,CreationTimestamp:2019-09-06 12:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 3a72ad6b-d0a4-11e9-baa3-fa163efa26fe 0xc0020a24f7 0xc0020a24f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 12:45:40.666: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep  6 12:45:40.666: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-8w9st,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8w9st/replicasets/test-recreate-deployment-5dfdcc846d,UID:3a7401fc-d0a4-11e9-baa3-fa163efa26fe,ResourceVersion:19444,Generation:2,CreationTimestamp:2019-09-06 12:45:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 3a72ad6b-d0a4-11e9-baa3-fa163efa26fe 0xc0020a2437 0xc0020a2438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 12:45:40.669: INFO: Pod "test-recreate-deployment-697fbf54bf-vqb5s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-vqb5s,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-8w9st,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8w9st/pods/test-recreate-deployment-697fbf54bf-vqb5s,UID:3bb3be84-d0a4-11e9-baa3-fa163efa26fe,ResourceVersion:19456,Generation:0,CreationTimestamp:2019-09-06 12:45:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 3bb2a6b3-d0a4-11e9-baa3-fa163efa26fe 0xc0020a3247 0xc0020a3248}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6fj7q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6fj7q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6fj7q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020a32c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020a32e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:45:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:45:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:45:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:45:40 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:,StartTime:2019-09-06 12:45:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:45:40.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8w9st" for this suite.
Sep  6 12:45:46.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:45:46.842: INFO: namespace: e2e-tests-deployment-8w9st, resource: bindings, ignored listing per whitelist
Sep  6 12:45:46.896: INFO: namespace e2e-tests-deployment-8w9st deletion completed in 6.222465869s

• [SLOW TEST:8.424 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:45:46.897: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:45:53.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-dnr6w" for this suite.
Sep  6 12:45:59.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:45:59.222: INFO: namespace: e2e-tests-namespaces-dnr6w, resource: bindings, ignored listing per whitelist
Sep  6 12:45:59.321: INFO: namespace e2e-tests-namespaces-dnr6w deletion completed in 6.133069921s
STEP: Destroying namespace "e2e-tests-nsdeletetest-jmcwk" for this suite.
Sep  6 12:45:59.324: INFO: Namespace e2e-tests-nsdeletetest-jmcwk was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-8tpzn" for this suite.
Sep  6 12:46:05.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:46:05.445: INFO: namespace: e2e-tests-nsdeletetest-8tpzn, resource: bindings, ignored listing per whitelist
Sep  6 12:46:05.497: INFO: namespace e2e-tests-nsdeletetest-8tpzn deletion completed in 6.172712826s

• [SLOW TEST:18.601 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:46:05.497: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Sep  6 12:46:05.588: INFO: namespace e2e-tests-kubectl-824tq
Sep  6 12:46:05.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-824tq'
Sep  6 12:46:06.251: INFO: stderr: ""
Sep  6 12:46:06.251: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  6 12:46:07.255: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 12:46:07.255: INFO: Found 0 / 1
Sep  6 12:46:08.256: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 12:46:08.256: INFO: Found 0 / 1
Sep  6 12:46:09.258: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 12:46:09.258: INFO: Found 1 / 1
Sep  6 12:46:09.258: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  6 12:46:09.261: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 12:46:09.261: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  6 12:46:09.262: INFO: wait on redis-master startup in e2e-tests-kubectl-824tq 
Sep  6 12:46:09.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 logs redis-master-nf2kv redis-master --namespace=e2e-tests-kubectl-824tq'
Sep  6 12:46:09.376: INFO: stderr: ""
Sep  6 12:46:09.376: INFO: stdout: "1:M 06 Sep 12:46:07.305 # You requested maxclients of 10000 requiring at least 10032 max file descriptors.\n1:M 06 Sep 12:46:07.306 # Server can't set maximum open files to 10032 because of OS error: Operation not permitted.\n1:M 06 Sep 12:46:07.306 # Current maximum open files is 4096. maxclients has been reduced to 4064 to compensate for low ulimit. If you need higher maxclients increase 'ulimit -n'.\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Sep 12:46:07.307 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Sep 12:46:07.307 # Server started, Redis version 3.2.12\n1:M 06 Sep 12:46:07.307 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Sep 12:46:07.307 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep  6 12:46:09.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-824tq'
Sep  6 12:46:09.518: INFO: stderr: ""
Sep  6 12:46:09.518: INFO: stdout: "service/rm2 exposed\n"
Sep  6 12:46:09.520: INFO: Service rm2 in namespace e2e-tests-kubectl-824tq found.
STEP: exposing service
Sep  6 12:46:11.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-824tq'
Sep  6 12:46:11.642: INFO: stderr: ""
Sep  6 12:46:11.642: INFO: stdout: "service/rm3 exposed\n"
Sep  6 12:46:11.644: INFO: Service rm3 in namespace e2e-tests-kubectl-824tq found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:46:13.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-824tq" for this suite.
Sep  6 12:46:35.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:46:35.767: INFO: namespace: e2e-tests-kubectl-824tq, resource: bindings, ignored listing per whitelist
Sep  6 12:46:35.810: INFO: namespace e2e-tests-kubectl-824tq deletion completed in 22.140519055s

• [SLOW TEST:30.313 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:46:35.810: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 12:46:35.955: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep  6 12:46:40.959: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  6 12:46:40.960: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep  6 12:46:42.972: INFO: Creating deployment "test-rollover-deployment"
Sep  6 12:46:42.998: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep  6 12:46:45.012: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep  6 12:46:45.036: INFO: Ensure that both replica sets have 1 created replica
Sep  6 12:46:45.048: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep  6 12:46:45.060: INFO: Updating deployment test-rollover-deployment
Sep  6 12:46:45.060: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep  6 12:46:47.073: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep  6 12:46:47.088: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep  6 12:46:47.098: INFO: all replica sets need to contain the pod-template-hash label
Sep  6 12:46:47.098: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370806, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 12:46:49.106: INFO: all replica sets need to contain the pod-template-hash label
Sep  6 12:46:49.106: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370806, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 12:46:51.107: INFO: all replica sets need to contain the pod-template-hash label
Sep  6 12:46:51.107: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370806, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 12:46:53.105: INFO: all replica sets need to contain the pod-template-hash label
Sep  6 12:46:53.105: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370806, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 12:46:55.108: INFO: all replica sets need to contain the pod-template-hash label
Sep  6 12:46:55.108: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370806, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703370803, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  6 12:46:57.109: INFO: 
Sep  6 12:46:57.109: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  6 12:46:57.120: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-4qm8t,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4qm8t/deployments/test-rollover-deployment,UID:60dbb5fd-d0a4-11e9-baa3-fa163efa26fe,ResourceVersion:19765,Generation:2,CreationTimestamp:2019-09-06 12:46:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-06 12:46:43 +0000 UTC 2019-09-06 12:46:43 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-06 12:46:56 +0000 UTC 2019-09-06 12:46:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  6 12:46:57.127: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-4qm8t,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4qm8t/replicasets/test-rollover-deployment-6b7f9d6597,UID:621a7ba3-d0a4-11e9-baa3-fa163efa26fe,ResourceVersion:19756,Generation:2,CreationTimestamp:2019-09-06 12:46:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 60dbb5fd-d0a4-11e9-baa3-fa163efa26fe 0xc0024338b7 0xc0024338b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  6 12:46:57.127: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep  6 12:46:57.128: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-4qm8t,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4qm8t/replicasets/test-rollover-controller,UID:5ca9f6c7-d0a4-11e9-baa3-fa163efa26fe,ResourceVersion:19764,Generation:2,CreationTimestamp:2019-09-06 12:46:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 60dbb5fd-d0a4-11e9-baa3-fa163efa26fe 0xc002433727 0xc002433728}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 12:46:57.128: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-4qm8t,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4qm8t/replicasets/test-rollover-deployment-6586df867b,UID:60e0fa0f-d0a4-11e9-baa3-fa163efa26fe,ResourceVersion:19729,Generation:2,CreationTimestamp:2019-09-06 12:46:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 60dbb5fd-d0a4-11e9-baa3-fa163efa26fe 0xc0024337e7 0xc0024337e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  6 12:46:57.134: INFO: Pod "test-rollover-deployment-6b7f9d6597-h22h5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-h22h5,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-4qm8t,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4qm8t/pods/test-rollover-deployment-6b7f9d6597-h22h5,UID:62205e83-d0a4-11e9-baa3-fa163efa26fe,ResourceVersion:19740,Generation:0,CreationTimestamp:2019-09-06 12:46:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.233.217.89/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 621a7ba3-d0a4-11e9-baa3-fa163efa26fe 0xc002864ac7 0xc002864ac8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn8c8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn8c8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-dn8c8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:metalk8s-22,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002864b40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002864b60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:46:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:46:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:46:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-06 12:46:45 +0000 UTC  }],Message:,Reason:,HostIP:10.10.0.6,PodIP:10.233.217.89,StartTime:2019-09-06 12:46:45 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-06 12:46:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://4034f31250f1cb1b6f29948ad254518d4458eacbd2c80ced367d621764baa9c1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:46:57.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4qm8t" for this suite.
Sep  6 12:47:03.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:47:03.272: INFO: namespace: e2e-tests-deployment-4qm8t, resource: bindings, ignored listing per whitelist
Sep  6 12:47:03.353: INFO: namespace e2e-tests-deployment-4qm8t deletion completed in 6.214734549s

• [SLOW TEST:27.543 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:47:03.353: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6d118e13-d0a4-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 12:47:03.477: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6d128753-d0a4-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-hc7th" to be "success or failure"
Sep  6 12:47:03.486: INFO: Pod "pod-projected-configmaps-6d128753-d0a4-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 8.722943ms
Sep  6 12:47:05.490: INFO: Pod "pod-projected-configmaps-6d128753-d0a4-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.012973835s
Sep  6 12:47:07.493: INFO: Pod "pod-projected-configmaps-6d128753-d0a4-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016006568s
STEP: Saw pod success
Sep  6 12:47:07.493: INFO: Pod "pod-projected-configmaps-6d128753-d0a4-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:47:07.499: INFO: Trying to get logs from node metalk8s-22 pod pod-projected-configmaps-6d128753-d0a4-11e9-9cef-86a5da7a2260 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 12:47:07.517: INFO: Waiting for pod pod-projected-configmaps-6d128753-d0a4-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:47:07.519: INFO: Pod pod-projected-configmaps-6d128753-d0a4-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:47:07.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hc7th" for this suite.
Sep  6 12:47:13.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:47:13.657: INFO: namespace: e2e-tests-projected-hc7th, resource: bindings, ignored listing per whitelist
Sep  6 12:47:13.696: INFO: namespace e2e-tests-projected-hc7th deletion completed in 6.173319505s

• [SLOW TEST:10.342 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:47:13.696: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  6 12:47:13.836: INFO: Waiting up to 5m0s for pod "pod-733fc048-d0a4-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-pp7tt" to be "success or failure"
Sep  6 12:47:13.845: INFO: Pod "pod-733fc048-d0a4-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 8.930322ms
Sep  6 12:47:15.849: INFO: Pod "pod-733fc048-d0a4-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012963189s
STEP: Saw pod success
Sep  6 12:47:15.849: INFO: Pod "pod-733fc048-d0a4-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:47:15.852: INFO: Trying to get logs from node metalk8s-22 pod pod-733fc048-d0a4-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 12:47:15.870: INFO: Waiting for pod pod-733fc048-d0a4-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:47:15.880: INFO: Pod pod-733fc048-d0a4-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:47:15.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pp7tt" for this suite.
Sep  6 12:47:21.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:47:21.946: INFO: namespace: e2e-tests-emptydir-pp7tt, resource: bindings, ignored listing per whitelist
Sep  6 12:47:22.028: INFO: namespace e2e-tests-emptydir-pp7tt deletion completed in 6.144915046s

• [SLOW TEST:8.332 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:47:22.029: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:47:22.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2xhrr" for this suite.
Sep  6 12:47:44.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:47:44.169: INFO: namespace: e2e-tests-pods-2xhrr, resource: bindings, ignored listing per whitelist
Sep  6 12:47:44.272: INFO: namespace e2e-tests-pods-2xhrr deletion completed in 22.140669467s

• [SLOW TEST:22.243 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:47:44.272: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 12:47:46.426: INFO: Waiting up to 5m0s for pod "client-envvars-86acba9f-d0a4-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-pods-fnczx" to be "success or failure"
Sep  6 12:47:46.443: INFO: Pod "client-envvars-86acba9f-d0a4-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 16.584908ms
Sep  6 12:47:48.448: INFO: Pod "client-envvars-86acba9f-d0a4-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021836685s
STEP: Saw pod success
Sep  6 12:47:48.448: INFO: Pod "client-envvars-86acba9f-d0a4-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:47:48.452: INFO: Trying to get logs from node metalk8s-22 pod client-envvars-86acba9f-d0a4-11e9-9cef-86a5da7a2260 container env3cont: <nil>
STEP: delete the pod
Sep  6 12:47:48.486: INFO: Waiting for pod client-envvars-86acba9f-d0a4-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:47:48.499: INFO: Pod client-envvars-86acba9f-d0a4-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:47:48.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fnczx" for this suite.
Sep  6 12:48:28.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:48:28.636: INFO: namespace: e2e-tests-pods-fnczx, resource: bindings, ignored listing per whitelist
Sep  6 12:48:28.672: INFO: namespace e2e-tests-pods-fnczx deletion completed in 40.169289597s

• [SLOW TEST:44.400 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:48:28.673: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 12:48:28.832: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ff39c67-d0a4-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-7nq2t" to be "success or failure"
Sep  6 12:48:28.838: INFO: Pod "downwardapi-volume-9ff39c67-d0a4-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 5.921244ms
Sep  6 12:48:30.843: INFO: Pod "downwardapi-volume-9ff39c67-d0a4-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010268779s
STEP: Saw pod success
Sep  6 12:48:30.843: INFO: Pod "downwardapi-volume-9ff39c67-d0a4-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:48:30.845: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-9ff39c67-d0a4-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 12:48:30.859: INFO: Waiting for pod downwardapi-volume-9ff39c67-d0a4-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:48:30.863: INFO: Pod downwardapi-volume-9ff39c67-d0a4-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:48:30.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7nq2t" for this suite.
Sep  6 12:48:36.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:48:36.888: INFO: namespace: e2e-tests-downward-api-7nq2t, resource: bindings, ignored listing per whitelist
Sep  6 12:48:37.014: INFO: namespace e2e-tests-downward-api-7nq2t deletion completed in 6.14874125s

• [SLOW TEST:8.342 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:48:37.015: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  6 12:48:37.120: INFO: Waiting up to 5m0s for pod "pod-a4e18615-d0a4-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-m7lw8" to be "success or failure"
Sep  6 12:48:37.127: INFO: Pod "pod-a4e18615-d0a4-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 6.845109ms
Sep  6 12:48:39.135: INFO: Pod "pod-a4e18615-d0a4-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014802804s
STEP: Saw pod success
Sep  6 12:48:39.135: INFO: Pod "pod-a4e18615-d0a4-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:48:39.138: INFO: Trying to get logs from node metalk8s-22 pod pod-a4e18615-d0a4-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 12:48:39.171: INFO: Waiting for pod pod-a4e18615-d0a4-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:48:39.173: INFO: Pod pod-a4e18615-d0a4-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:48:39.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-m7lw8" for this suite.
Sep  6 12:48:45.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:48:45.322: INFO: namespace: e2e-tests-emptydir-m7lw8, resource: bindings, ignored listing per whitelist
Sep  6 12:48:45.334: INFO: namespace e2e-tests-emptydir-m7lw8 deletion completed in 6.15746253s

• [SLOW TEST:8.319 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:48:45.334: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a9dbb717-d0a4-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 12:48:45.476: INFO: Waiting up to 5m0s for pod "pod-secrets-a9dcd670-d0a4-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-secrets-457fp" to be "success or failure"
Sep  6 12:48:45.483: INFO: Pod "pod-secrets-a9dcd670-d0a4-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 7.347721ms
Sep  6 12:48:47.486: INFO: Pod "pod-secrets-a9dcd670-d0a4-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010320513s
STEP: Saw pod success
Sep  6 12:48:47.486: INFO: Pod "pod-secrets-a9dcd670-d0a4-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:48:47.489: INFO: Trying to get logs from node metalk8s-22 pod pod-secrets-a9dcd670-d0a4-11e9-9cef-86a5da7a2260 container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 12:48:47.517: INFO: Waiting for pod pod-secrets-a9dcd670-d0a4-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:48:47.519: INFO: Pod pod-secrets-a9dcd670-d0a4-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:48:47.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-457fp" for this suite.
Sep  6 12:48:53.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:48:53.569: INFO: namespace: e2e-tests-secrets-457fp, resource: bindings, ignored listing per whitelist
Sep  6 12:48:53.632: INFO: namespace e2e-tests-secrets-457fp deletion completed in 6.110010661s

• [SLOW TEST:8.298 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:48:53.632: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  6 12:48:53.707: INFO: Waiting up to 5m0s for pod "pod-aec6b21c-d0a4-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-jnw9n" to be "success or failure"
Sep  6 12:48:53.715: INFO: Pod "pod-aec6b21c-d0a4-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 7.654812ms
Sep  6 12:48:55.718: INFO: Pod "pod-aec6b21c-d0a4-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010617853s
STEP: Saw pod success
Sep  6 12:48:55.718: INFO: Pod "pod-aec6b21c-d0a4-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:48:55.720: INFO: Trying to get logs from node metalk8s-22 pod pod-aec6b21c-d0a4-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 12:48:55.736: INFO: Waiting for pod pod-aec6b21c-d0a4-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:48:55.747: INFO: Pod pod-aec6b21c-d0a4-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:48:55.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jnw9n" for this suite.
Sep  6 12:49:01.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:49:01.801: INFO: namespace: e2e-tests-emptydir-jnw9n, resource: bindings, ignored listing per whitelist
Sep  6 12:49:01.866: INFO: namespace e2e-tests-emptydir-jnw9n deletion completed in 6.117009538s

• [SLOW TEST:8.234 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:49:01.866: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Sep  6 12:49:01.949: INFO: Waiting up to 5m0s for pod "client-containers-b3b08f64-d0a4-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-containers-lfcvh" to be "success or failure"
Sep  6 12:49:01.953: INFO: Pod "client-containers-b3b08f64-d0a4-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063412ms
Sep  6 12:49:03.956: INFO: Pod "client-containers-b3b08f64-d0a4-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007110487s
STEP: Saw pod success
Sep  6 12:49:03.956: INFO: Pod "client-containers-b3b08f64-d0a4-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:49:03.960: INFO: Trying to get logs from node metalk8s-22 pod client-containers-b3b08f64-d0a4-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 12:49:03.975: INFO: Waiting for pod client-containers-b3b08f64-d0a4-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:49:03.979: INFO: Pod client-containers-b3b08f64-d0a4-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:49:03.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-lfcvh" for this suite.
Sep  6 12:49:09.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:49:10.027: INFO: namespace: e2e-tests-containers-lfcvh, resource: bindings, ignored listing per whitelist
Sep  6 12:49:10.105: INFO: namespace e2e-tests-containers-lfcvh deletion completed in 6.121558681s

• [SLOW TEST:8.239 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:49:10.105: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 12:49:10.200: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep  6 12:49:10.220: INFO: Number of nodes with available pods: 0
Sep  6 12:49:10.220: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep  6 12:49:10.246: INFO: Number of nodes with available pods: 0
Sep  6 12:49:10.246: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:11.250: INFO: Number of nodes with available pods: 0
Sep  6 12:49:11.250: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:12.251: INFO: Number of nodes with available pods: 1
Sep  6 12:49:12.251: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep  6 12:49:12.268: INFO: Number of nodes with available pods: 1
Sep  6 12:49:12.268: INFO: Number of running nodes: 0, number of available pods: 1
Sep  6 12:49:13.272: INFO: Number of nodes with available pods: 0
Sep  6 12:49:13.272: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep  6 12:49:13.299: INFO: Number of nodes with available pods: 0
Sep  6 12:49:13.299: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:14.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:14.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:15.309: INFO: Number of nodes with available pods: 0
Sep  6 12:49:15.309: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:16.304: INFO: Number of nodes with available pods: 0
Sep  6 12:49:16.304: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:17.304: INFO: Number of nodes with available pods: 0
Sep  6 12:49:17.304: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:18.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:18.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:19.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:19.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:20.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:20.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:21.304: INFO: Number of nodes with available pods: 0
Sep  6 12:49:21.304: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:22.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:22.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:23.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:23.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:24.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:24.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:25.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:25.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:26.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:26.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:27.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:27.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:28.304: INFO: Number of nodes with available pods: 0
Sep  6 12:49:28.304: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:29.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:29.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:30.307: INFO: Number of nodes with available pods: 0
Sep  6 12:49:30.307: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:31.304: INFO: Number of nodes with available pods: 0
Sep  6 12:49:31.304: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:32.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:32.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:33.304: INFO: Number of nodes with available pods: 0
Sep  6 12:49:33.304: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:34.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:34.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:35.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:35.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:36.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:36.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:37.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:37.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:38.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:38.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:39.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:39.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:40.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:40.304: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:41.307: INFO: Number of nodes with available pods: 0
Sep  6 12:49:41.307: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:42.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:42.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:43.310: INFO: Number of nodes with available pods: 0
Sep  6 12:49:43.310: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:44.306: INFO: Number of nodes with available pods: 0
Sep  6 12:49:44.307: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:45.306: INFO: Number of nodes with available pods: 0
Sep  6 12:49:45.306: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:46.303: INFO: Number of nodes with available pods: 0
Sep  6 12:49:46.303: INFO: Node metalk8s-22 is running more than one daemon pod
Sep  6 12:49:47.303: INFO: Number of nodes with available pods: 1
Sep  6 12:49:47.303: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2q8r2, will wait for the garbage collector to delete the pods
Sep  6 12:49:47.365: INFO: Deleting DaemonSet.extensions daemon-set took: 6.249854ms
Sep  6 12:49:47.466: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.369442ms
Sep  6 12:50:31.775: INFO: Number of nodes with available pods: 0
Sep  6 12:50:31.775: INFO: Number of running nodes: 0, number of available pods: 0
Sep  6 12:50:31.778: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2q8r2/daemonsets","resourceVersion":"20456"},"items":null}

Sep  6 12:50:31.785: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2q8r2/pods","resourceVersion":"20456"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:50:31.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2q8r2" for this suite.
Sep  6 12:50:37.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:50:37.945: INFO: namespace: e2e-tests-daemonsets-2q8r2, resource: bindings, ignored listing per whitelist
Sep  6 12:50:37.977: INFO: namespace e2e-tests-daemonsets-2q8r2 deletion completed in 6.155136082s

• [SLOW TEST:87.871 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:50:37.978: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bxr45
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-bxr45
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-bxr45
Sep  6 12:50:38.092: INFO: Found 0 stateful pods, waiting for 1
Sep  6 12:50:48.146: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep  6 12:50:48.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 12:50:48.573: INFO: stderr: ""
Sep  6 12:50:48.573: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 12:50:48.573: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 12:50:48.577: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  6 12:50:58.581: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 12:50:58.581: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 12:50:58.599: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999507s
Sep  6 12:50:59.602: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995718813s
Sep  6 12:51:00.604: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992588637s
Sep  6 12:51:01.608: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.989945695s
Sep  6 12:51:02.615: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.986153154s
Sep  6 12:51:03.619: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.978923946s
Sep  6 12:51:04.626: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.974941321s
Sep  6 12:51:05.629: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.968731165s
Sep  6 12:51:06.632: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.965403845s
Sep  6 12:51:07.635: INFO: Verifying statefulset ss doesn't scale past 1 for another 962.546354ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-bxr45
Sep  6 12:51:08.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:51:08.938: INFO: stderr: ""
Sep  6 12:51:08.938: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 12:51:08.938: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 12:51:08.944: INFO: Found 1 stateful pods, waiting for 3
Sep  6 12:51:18.949: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 12:51:18.949: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 12:51:18.949: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep  6 12:51:18.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 12:51:19.238: INFO: stderr: ""
Sep  6 12:51:19.238: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 12:51:19.238: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 12:51:19.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 12:51:19.523: INFO: stderr: ""
Sep  6 12:51:19.523: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 12:51:19.523: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 12:51:19.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 12:51:19.754: INFO: stderr: ""
Sep  6 12:51:19.754: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 12:51:19.754: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 12:51:19.754: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 12:51:19.757: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep  6 12:51:29.765: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 12:51:29.766: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 12:51:29.766: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  6 12:51:29.784: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999607s
Sep  6 12:51:30.789: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991909751s
Sep  6 12:51:31.795: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986331681s
Sep  6 12:51:32.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.980663255s
Sep  6 12:51:33.804: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.975806132s
Sep  6 12:51:34.808: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.971935566s
Sep  6 12:51:35.812: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.968161988s
Sep  6 12:51:36.818: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.963505821s
Sep  6 12:51:37.822: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.958304594s
Sep  6 12:51:38.825: INFO: Verifying statefulset ss doesn't scale past 3 for another 954.559908ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-bxr45
Sep  6 12:51:39.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:51:40.104: INFO: stderr: ""
Sep  6 12:51:40.104: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 12:51:40.104: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 12:51:40.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:51:40.397: INFO: stderr: ""
Sep  6 12:51:40.397: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 12:51:40.397: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 12:51:40.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:51:40.774: INFO: rc: 1
Sep  6 12:51:40.775: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: failed to exec in container: failed to create exec "0d4012e4032658237e3f79032167a496ed0bb4b950e55244490ab62697d1efd3": cannot exec in a deleted state: unknown
 [] <nil> 0xc001725da0 exit status 1 <nil> <nil> true [0xc00000fdd0 0xc00000fe50 0xc00000fed0] [0xc00000fdd0 0xc00000fe50 0xc00000fed0] [0xc00000fe30 0xc00000fea8] [0x92f8e0 0x92f8e0] 0xc001b06000 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: failed to exec in container: failed to create exec "0d4012e4032658237e3f79032167a496ed0bb4b950e55244490ab62697d1efd3": cannot exec in a deleted state: unknown

error:
exit status 1

Sep  6 12:51:50.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:51:50.894: INFO: rc: 1
Sep  6 12:51:50.894: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001a8b530 exit status 1 <nil> <nil> true [0xc002af0278 0xc002af0290 0xc002af02a8] [0xc002af0278 0xc002af0290 0xc002af02a8] [0xc002af0288 0xc002af02a0] [0x92f8e0 0x92f8e0] 0xc00214f440 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Sep  6 12:52:00.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:52:01.051: INFO: rc: 1
Sep  6 12:52:01.051: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a8b920 exit status 1 <nil> <nil> true [0xc002af02b0 0xc002af02c8 0xc002af02e0] [0xc002af02b0 0xc002af02c8 0xc002af02e0] [0xc002af02c0 0xc002af02d8] [0x92f8e0 0x92f8e0] 0xc00214f740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:52:11.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:52:11.153: INFO: rc: 1
Sep  6 12:52:11.153: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001d511a0 exit status 1 <nil> <nil> true [0xc00205a268 0xc00205a280 0xc00205a298] [0xc00205a268 0xc00205a280 0xc00205a298] [0xc00205a278 0xc00205a290] [0x92f8e0 0x92f8e0] 0xc001e89980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:52:21.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:52:21.230: INFO: rc: 1
Sep  6 12:52:21.230: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0008cc4b0 exit status 1 <nil> <nil> true [0xc000380148 0xc000380250 0xc0003802c8] [0xc000380148 0xc000380250 0xc0003802c8] [0xc000380228 0xc0003802a8] [0x92f8e0 0x92f8e0] 0xc001908300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:52:31.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:52:31.334: INFO: rc: 1
Sep  6 12:52:31.335: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0008ccb40 exit status 1 <nil> <nil> true [0xc000380420 0xc0003805e0 0xc0003806c8] [0xc000380420 0xc0003805e0 0xc0003806c8] [0xc0003805c0 0xc0003806a0] [0x92f8e0 0x92f8e0] 0xc0019086c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:52:41.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:52:41.463: INFO: rc: 1
Sep  6 12:52:41.463: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0008cced0 exit status 1 <nil> <nil> true [0xc0003807a8 0xc0003808b0 0xc000380990] [0xc0003807a8 0xc0003808b0 0xc000380990] [0xc000380898 0xc000380918] [0x92f8e0 0x92f8e0] 0xc001908a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:52:51.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:52:51.564: INFO: rc: 1
Sep  6 12:52:51.564: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014f4540 exit status 1 <nil> <nil> true [0xc0001600b8 0xc000160110 0xc0001601e8] [0xc0001600b8 0xc000160110 0xc0001601e8] [0xc0001600f0 0xc0001601c0] [0x92f8e0 0x92f8e0] 0xc0023b6660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:53:01.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:53:01.681: INFO: rc: 1
Sep  6 12:53:01.682: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fee4b0 exit status 1 <nil> <nil> true [0xc00205a000 0xc00205a018 0xc00205a030] [0xc00205a000 0xc00205a018 0xc00205a030] [0xc00205a010 0xc00205a028] [0x92f8e0 0x92f8e0] 0xc0016be240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:53:11.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:53:11.775: INFO: rc: 1
Sep  6 12:53:11.775: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fee930 exit status 1 <nil> <nil> true [0xc00205a038 0xc00205a050 0xc00205a068] [0xc00205a038 0xc00205a050 0xc00205a068] [0xc00205a048 0xc00205a060] [0x92f8e0 0x92f8e0] 0xc0016be600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:53:21.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:53:21.881: INFO: rc: 1
Sep  6 12:53:21.881: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014f4930 exit status 1 <nil> <nil> true [0xc000160200 0xc0003801d8 0xc000380270] [0xc000160200 0xc0003801d8 0xc000380270] [0xc000380148 0xc000380250] [0x92f8e0 0x92f8e0] 0xc0023b7200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:53:31.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:53:31.974: INFO: rc: 1
Sep  6 12:53:31.975: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000e463f0 exit status 1 <nil> <nil> true [0xc00000e038 0xc00000e7f0 0xc00000ead8] [0xc00000e038 0xc00000e7f0 0xc00000ead8] [0xc00000e568 0xc00000ea58] [0x92f8e0 0x92f8e0] 0xc000f94360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:53:41.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:53:42.133: INFO: rc: 1
Sep  6 12:53:42.133: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000feed50 exit status 1 <nil> <nil> true [0xc00205a070 0xc00205a088 0xc00205a0a0] [0xc00205a070 0xc00205a088 0xc00205a0a0] [0xc00205a080 0xc00205a098] [0x92f8e0 0x92f8e0] 0xc0016bec60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:53:52.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:53:52.262: INFO: rc: 1
Sep  6 12:53:52.262: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fef0e0 exit status 1 <nil> <nil> true [0xc00205a0a8 0xc00205a0c0 0xc00205a0d8] [0xc00205a0a8 0xc00205a0c0 0xc00205a0d8] [0xc00205a0b8 0xc00205a0d0] [0x92f8e0 0x92f8e0] 0xc0016bf2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:54:02.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:54:02.363: INFO: rc: 1
Sep  6 12:54:02.363: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fef7d0 exit status 1 <nil> <nil> true [0xc00205a0e0 0xc00205a0f8 0xc00205a110] [0xc00205a0e0 0xc00205a0f8 0xc00205a110] [0xc00205a0f0 0xc00205a108] [0x92f8e0 0x92f8e0] 0xc0016bf8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:54:12.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:54:12.476: INFO: rc: 1
Sep  6 12:54:12.476: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000e46840 exit status 1 <nil> <nil> true [0xc00000ebe8 0xc00000efc8 0xc00000f140] [0xc00000ebe8 0xc00000efc8 0xc00000f140] [0xc00000ef50 0xc00000f0d0] [0x92f8e0 0x92f8e0] 0xc000f94720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:54:22.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:54:22.574: INFO: rc: 1
Sep  6 12:54:22.574: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000feff50 exit status 1 <nil> <nil> true [0xc00205a118 0xc00205a130 0xc00205a148] [0xc00205a118 0xc00205a130 0xc00205a148] [0xc00205a128 0xc00205a140] [0x92f8e0 0x92f8e0] 0xc001e880c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:54:32.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:54:32.727: INFO: rc: 1
Sep  6 12:54:32.727: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002382330 exit status 1 <nil> <nil> true [0xc00205a150 0xc00205a168 0xc00205a180] [0xc00205a150 0xc00205a168 0xc00205a180] [0xc00205a160 0xc00205a178] [0x92f8e0 0x92f8e0] 0xc001e88420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:54:42.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:54:42.903: INFO: rc: 1
Sep  6 12:54:42.903: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023826c0 exit status 1 <nil> <nil> true [0xc00205a188 0xc00205a1a0 0xc00205a1b8] [0xc00205a188 0xc00205a1a0 0xc00205a1b8] [0xc00205a198 0xc00205a1b0] [0x92f8e0 0x92f8e0] 0xc001e88780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:54:52.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:54:52.972: INFO: rc: 1
Sep  6 12:54:52.973: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fee480 exit status 1 <nil> <nil> true [0xc0001600b8 0xc000160110 0xc0001601e8] [0xc0001600b8 0xc000160110 0xc0001601e8] [0xc0001600f0 0xc0001601c0] [0x92f8e0 0x92f8e0] 0xc0016be240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:55:02.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:55:03.055: INFO: rc: 1
Sep  6 12:55:03.055: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fee960 exit status 1 <nil> <nil> true [0xc000160200 0xc0003801d8 0xc000380270] [0xc000160200 0xc0003801d8 0xc000380270] [0xc000380148 0xc000380250] [0x92f8e0 0x92f8e0] 0xc0016be600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:55:13.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:55:13.200: INFO: rc: 1
Sep  6 12:55:13.200: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000feedb0 exit status 1 <nil> <nil> true [0xc0003802a8 0xc0003804f0 0xc000380618] [0xc0003802a8 0xc0003804f0 0xc000380618] [0xc000380420 0xc0003805e0] [0x92f8e0 0x92f8e0] 0xc0016bec60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:55:23.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:55:23.292: INFO: rc: 1
Sep  6 12:55:23.292: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fef1a0 exit status 1 <nil> <nil> true [0xc0003806a0 0xc0003807d0 0xc000380910] [0xc0003806a0 0xc0003807d0 0xc000380910] [0xc0003807a8 0xc0003808b0] [0x92f8e0 0x92f8e0] 0xc0016bf2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:55:33.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:55:33.375: INFO: rc: 1
Sep  6 12:55:33.375: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000fef8f0 exit status 1 <nil> <nil> true [0xc000380918 0xc000380a20 0xc000380ac0] [0xc000380918 0xc000380a20 0xc000380ac0] [0xc0003809d0 0xc000380a88] [0x92f8e0 0x92f8e0] 0xc0016bf8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:55:43.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:55:43.518: INFO: rc: 1
Sep  6 12:55:43.518: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014f45a0 exit status 1 <nil> <nil> true [0xc00000e038 0xc00000e7f0 0xc00000ead8] [0xc00000e038 0xc00000e7f0 0xc00000ead8] [0xc00000e568 0xc00000ea58] [0x92f8e0 0x92f8e0] 0xc0023b6660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:55:53.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:55:53.610: INFO: rc: 1
Sep  6 12:55:53.610: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000d6e390 exit status 1 <nil> <nil> true [0xc00205a000 0xc00205a018 0xc00205a030] [0xc00205a000 0xc00205a018 0xc00205a030] [0xc00205a010 0xc00205a028] [0x92f8e0 0x92f8e0] 0xc000f94360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:56:03.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:56:03.716: INFO: rc: 1
Sep  6 12:56:03.716: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000d6e7e0 exit status 1 <nil> <nil> true [0xc00205a038 0xc00205a050 0xc00205a068] [0xc00205a038 0xc00205a050 0xc00205a068] [0xc00205a048 0xc00205a060] [0x92f8e0 0x92f8e0] 0xc000f94720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:56:13.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:56:13.840: INFO: rc: 1
Sep  6 12:56:13.840: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000e460c0 exit status 1 <nil> <nil> true [0xc000380af8 0xc000380d20 0xc000380de8] [0xc000380af8 0xc000380d20 0xc000380de8] [0xc000380bf8 0xc000380da0] [0x92f8e0 0x92f8e0] 0xc001e880c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:56:23.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:56:23.905: INFO: rc: 1
Sep  6 12:56:23.905: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014f4ae0 exit status 1 <nil> <nil> true [0xc00000ebe8 0xc00000efc8 0xc00000f140] [0xc00000ebe8 0xc00000efc8 0xc00000f140] [0xc00000ef50 0xc00000f0d0] [0x92f8e0 0x92f8e0] 0xc0023b7200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:56:33.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:56:34.003: INFO: rc: 1
Sep  6 12:56:34.003: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000e464b0 exit status 1 <nil> <nil> true [0xc000380f10 0xc000380f50 0xc000380fd8] [0xc000380f10 0xc000380f50 0xc000380fd8] [0xc000380f48 0xc000380fc0] [0x92f8e0 0x92f8e0] 0xc001e88420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  6 12:56:44.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-bxr45 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 12:56:44.133: INFO: rc: 1
Sep  6 12:56:44.133: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Sep  6 12:56:44.133: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  6 12:56:44.145: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bxr45
Sep  6 12:56:44.148: INFO: Scaling statefulset ss to 0
Sep  6 12:56:44.158: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 12:56:44.161: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:56:44.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bxr45" for this suite.
Sep  6 12:56:50.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:56:50.203: INFO: namespace: e2e-tests-statefulset-bxr45, resource: bindings, ignored listing per whitelist
Sep  6 12:56:50.283: INFO: namespace e2e-tests-statefulset-bxr45 deletion completed in 6.106249017s

• [SLOW TEST:372.305 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:56:50.283: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-cae1a4fe-d0a5-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume configMaps
Sep  6 12:56:50.360: INFO: Waiting up to 5m0s for pod "pod-configmaps-cae2bb7a-d0a5-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-configmap-xmvvk" to be "success or failure"
Sep  6 12:56:50.382: INFO: Pod "pod-configmaps-cae2bb7a-d0a5-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 22.531232ms
Sep  6 12:56:52.386: INFO: Pod "pod-configmaps-cae2bb7a-d0a5-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025973726s
STEP: Saw pod success
Sep  6 12:56:52.386: INFO: Pod "pod-configmaps-cae2bb7a-d0a5-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:56:52.389: INFO: Trying to get logs from node metalk8s-22 pod pod-configmaps-cae2bb7a-d0a5-11e9-9cef-86a5da7a2260 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  6 12:56:52.411: INFO: Waiting for pod pod-configmaps-cae2bb7a-d0a5-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:56:52.414: INFO: Pod pod-configmaps-cae2bb7a-d0a5-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:56:52.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xmvvk" for this suite.
Sep  6 12:56:58.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:56:58.556: INFO: namespace: e2e-tests-configmap-xmvvk, resource: bindings, ignored listing per whitelist
Sep  6 12:56:58.557: INFO: namespace e2e-tests-configmap-xmvvk deletion completed in 6.131934561s

• [SLOW TEST:8.274 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:56:58.557: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep  6 12:56:58.637: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-a,UID:cfd23d1c-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21241,Generation:0,CreationTimestamp:2019-09-06 12:56:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  6 12:56:58.637: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-a,UID:cfd23d1c-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21241,Generation:0,CreationTimestamp:2019-09-06 12:56:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep  6 12:57:08.645: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-a,UID:cfd23d1c-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21256,Generation:0,CreationTimestamp:2019-09-06 12:56:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  6 12:57:08.645: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-a,UID:cfd23d1c-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21256,Generation:0,CreationTimestamp:2019-09-06 12:56:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep  6 12:57:18.652: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-a,UID:cfd23d1c-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21270,Generation:0,CreationTimestamp:2019-09-06 12:56:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  6 12:57:18.652: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-a,UID:cfd23d1c-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21270,Generation:0,CreationTimestamp:2019-09-06 12:56:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep  6 12:57:28.657: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-a,UID:cfd23d1c-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21284,Generation:0,CreationTimestamp:2019-09-06 12:56:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  6 12:57:28.657: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-a,UID:cfd23d1c-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21284,Generation:0,CreationTimestamp:2019-09-06 12:56:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep  6 12:57:38.664: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-b,UID:e7ad5b1e-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21299,Generation:0,CreationTimestamp:2019-09-06 12:57:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  6 12:57:38.664: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-b,UID:e7ad5b1e-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21299,Generation:0,CreationTimestamp:2019-09-06 12:57:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep  6 12:57:48.670: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-b,UID:e7ad5b1e-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21313,Generation:0,CreationTimestamp:2019-09-06 12:57:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  6 12:57:48.670: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m556w,SelfLink:/api/v1/namespaces/e2e-tests-watch-m556w/configmaps/e2e-watch-test-configmap-b,UID:e7ad5b1e-d0a5-11e9-baa3-fa163efa26fe,ResourceVersion:21313,Generation:0,CreationTimestamp:2019-09-06 12:57:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:57:58.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-m556w" for this suite.
Sep  6 12:58:04.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:58:04.786: INFO: namespace: e2e-tests-watch-m556w, resource: bindings, ignored listing per whitelist
Sep  6 12:58:04.828: INFO: namespace e2e-tests-watch-m556w deletion completed in 6.152843411s

• [SLOW TEST:66.271 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:58:04.828: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  6 12:58:04.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-lvdgl'
Sep  6 12:58:05.514: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  6 12:58:05.514: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep  6 12:58:05.526: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Sep  6 12:58:05.559: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep  6 12:58:05.570: INFO: scanned /root for discovery docs: <nil>
Sep  6 12:58:05.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-lvdgl'
Sep  6 12:58:21.473: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  6 12:58:21.473: INFO: stdout: "Created e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966\nScaling up e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep  6 12:58:21.473: INFO: stdout: "Created e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966\nScaling up e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep  6 12:58:21.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lvdgl'
Sep  6 12:58:21.581: INFO: stderr: ""
Sep  6 12:58:21.581: INFO: stdout: "e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966-fgplp "
Sep  6 12:58:21.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966-fgplp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lvdgl'
Sep  6 12:58:21.688: INFO: stderr: ""
Sep  6 12:58:21.688: INFO: stdout: "true"
Sep  6 12:58:21.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966-fgplp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lvdgl'
Sep  6 12:58:21.832: INFO: stderr: ""
Sep  6 12:58:21.832: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep  6 12:58:21.832: INFO: e2e-test-nginx-rc-60d2018e87d6091998d82fe615f46966-fgplp is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Sep  6 12:58:21.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lvdgl'
Sep  6 12:58:21.976: INFO: stderr: ""
Sep  6 12:58:21.977: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:58:21.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lvdgl" for this suite.
Sep  6 12:58:27.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:58:28.081: INFO: namespace: e2e-tests-kubectl-lvdgl, resource: bindings, ignored listing per whitelist
Sep  6 12:58:28.123: INFO: namespace e2e-tests-kubectl-lvdgl deletion completed in 6.142913166s

• [SLOW TEST:23.295 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:58:28.123: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  6 12:58:32.795: INFO: Successfully updated pod "labelsupdate05395360-d0a6-11e9-9cef-86a5da7a2260"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:58:34.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-258vf" for this suite.
Sep  6 12:58:56.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:58:56.873: INFO: namespace: e2e-tests-projected-258vf, resource: bindings, ignored listing per whitelist
Sep  6 12:58:56.935: INFO: namespace e2e-tests-projected-258vf deletion completed in 22.118404901s

• [SLOW TEST:28.812 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:58:56.936: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-16631bad-d0a6-11e9-9cef-86a5da7a2260
STEP: Creating a pod to test consume secrets
Sep  6 12:58:57.033: INFO: Waiting up to 5m0s for pod "pod-secrets-16638dc2-d0a6-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-secrets-qn88f" to be "success or failure"
Sep  6 12:58:57.040: INFO: Pod "pod-secrets-16638dc2-d0a6-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 6.886021ms
Sep  6 12:58:59.043: INFO: Pod "pod-secrets-16638dc2-d0a6-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009821896s
STEP: Saw pod success
Sep  6 12:58:59.043: INFO: Pod "pod-secrets-16638dc2-d0a6-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 12:58:59.046: INFO: Trying to get logs from node metalk8s-22 pod pod-secrets-16638dc2-d0a6-11e9-9cef-86a5da7a2260 container secret-volume-test: <nil>
STEP: delete the pod
Sep  6 12:58:59.069: INFO: Waiting for pod pod-secrets-16638dc2-d0a6-11e9-9cef-86a5da7a2260 to disappear
Sep  6 12:58:59.072: INFO: Pod pod-secrets-16638dc2-d0a6-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 12:58:59.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qn88f" for this suite.
Sep  6 12:59:05.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 12:59:05.285: INFO: namespace: e2e-tests-secrets-qn88f, resource: bindings, ignored listing per whitelist
Sep  6 12:59:05.296: INFO: namespace e2e-tests-secrets-qn88f deletion completed in 6.218621737s

• [SLOW TEST:8.361 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 12:59:05.296: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-1b6b22ed-d0a6-11e9-9cef-86a5da7a2260
STEP: Creating secret with name s-test-opt-upd-1b6b2361-d0a6-11e9-9cef-86a5da7a2260
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1b6b22ed-d0a6-11e9-9cef-86a5da7a2260
STEP: Updating secret s-test-opt-upd-1b6b2361-d0a6-11e9-9cef-86a5da7a2260
STEP: Creating secret with name s-test-opt-create-1b6b2382-d0a6-11e9-9cef-86a5da7a2260
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 13:00:32.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tkzjw" for this suite.
Sep  6 13:00:54.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 13:00:54.696: INFO: namespace: e2e-tests-projected-tkzjw, resource: bindings, ignored listing per whitelist
Sep  6 13:00:54.746: INFO: namespace e2e-tests-projected-tkzjw deletion completed in 22.133244962s

• [SLOW TEST:109.450 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 13:00:54.747: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-k96gb
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Sep  6 13:00:54.831: INFO: Found 0 stateful pods, waiting for 3
Sep  6 13:01:04.835: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 13:01:04.835: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 13:01:04.835: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep  6 13:01:04.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-k96gb ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 13:01:05.218: INFO: stderr: ""
Sep  6 13:01:05.218: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 13:01:05.218: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  6 13:01:15.253: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep  6 13:01:25.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-k96gb ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 13:01:25.677: INFO: stderr: ""
Sep  6 13:01:25.677: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 13:01:25.677: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 13:01:45.724: INFO: Waiting for StatefulSet e2e-tests-statefulset-k96gb/ss2 to complete update
Sep  6 13:01:45.724: INFO: Waiting for Pod e2e-tests-statefulset-k96gb/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Sep  6 13:01:55.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-k96gb ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  6 13:01:56.204: INFO: stderr: ""
Sep  6 13:01:56.204: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  6 13:01:56.204: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  6 13:02:06.256: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep  6 13:02:16.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 exec --namespace=e2e-tests-statefulset-k96gb ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  6 13:02:16.635: INFO: stderr: ""
Sep  6 13:02:16.635: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  6 13:02:16.635: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  6 13:02:36.674: INFO: Waiting for StatefulSet e2e-tests-statefulset-k96gb/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  6 13:02:46.681: INFO: Deleting all statefulset in ns e2e-tests-statefulset-k96gb
Sep  6 13:02:46.684: INFO: Scaling statefulset ss2 to 0
Sep  6 13:03:06.716: INFO: Waiting for statefulset status.replicas updated to 0
Sep  6 13:03:06.721: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 13:03:06.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-k96gb" for this suite.
Sep  6 13:03:12.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 13:03:12.773: INFO: namespace: e2e-tests-statefulset-k96gb, resource: bindings, ignored listing per whitelist
Sep  6 13:03:12.900: INFO: namespace e2e-tests-statefulset-k96gb deletion completed in 6.161377585s

• [SLOW TEST:138.153 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 13:03:12.900: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  6 13:03:12.992: INFO: Creating ReplicaSet my-hostname-basic-aef49386-d0a6-11e9-9cef-86a5da7a2260
Sep  6 13:03:13.025: INFO: Pod name my-hostname-basic-aef49386-d0a6-11e9-9cef-86a5da7a2260: Found 0 pods out of 1
Sep  6 13:03:18.034: INFO: Pod name my-hostname-basic-aef49386-d0a6-11e9-9cef-86a5da7a2260: Found 1 pods out of 1
Sep  6 13:03:18.034: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-aef49386-d0a6-11e9-9cef-86a5da7a2260" is running
Sep  6 13:03:18.040: INFO: Pod "my-hostname-basic-aef49386-d0a6-11e9-9cef-86a5da7a2260-tbhfl" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 13:03:13 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 13:03:14 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 13:03:14 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-06 13:03:13 +0000 UTC Reason: Message:}])
Sep  6 13:03:18.041: INFO: Trying to dial the pod
Sep  6 13:03:23.058: INFO: Controller my-hostname-basic-aef49386-d0a6-11e9-9cef-86a5da7a2260: Got expected result from replica 1 [my-hostname-basic-aef49386-d0a6-11e9-9cef-86a5da7a2260-tbhfl]: "my-hostname-basic-aef49386-d0a6-11e9-9cef-86a5da7a2260-tbhfl", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 13:03:23.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-7kn8k" for this suite.
Sep  6 13:03:29.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 13:03:29.189: INFO: namespace: e2e-tests-replicaset-7kn8k, resource: bindings, ignored listing per whitelist
Sep  6 13:03:29.195: INFO: namespace e2e-tests-replicaset-7kn8k deletion completed in 6.133850344s

• [SLOW TEST:16.295 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 13:03:29.196: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  6 13:03:29.287: INFO: Waiting up to 5m0s for pod "downward-api-b8a952b3-d0a6-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-cv45d" to be "success or failure"
Sep  6 13:03:29.294: INFO: Pod "downward-api-b8a952b3-d0a6-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 6.953713ms
Sep  6 13:03:31.297: INFO: Pod "downward-api-b8a952b3-d0a6-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.01007761s
Sep  6 13:03:33.300: INFO: Pod "downward-api-b8a952b3-d0a6-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012998415s
STEP: Saw pod success
Sep  6 13:03:33.300: INFO: Pod "downward-api-b8a952b3-d0a6-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 13:03:33.303: INFO: Trying to get logs from node metalk8s-22 pod downward-api-b8a952b3-d0a6-11e9-9cef-86a5da7a2260 container dapi-container: <nil>
STEP: delete the pod
Sep  6 13:03:33.323: INFO: Waiting for pod downward-api-b8a952b3-d0a6-11e9-9cef-86a5da7a2260 to disappear
Sep  6 13:03:33.326: INFO: Pod downward-api-b8a952b3-d0a6-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 13:03:33.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cv45d" for this suite.
Sep  6 13:03:39.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 13:03:39.508: INFO: namespace: e2e-tests-downward-api-cv45d, resource: bindings, ignored listing per whitelist
Sep  6 13:03:39.536: INFO: namespace e2e-tests-downward-api-cv45d deletion completed in 6.20603238s

• [SLOW TEST:10.341 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 13:03:39.536: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  6 13:03:39.691: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bedce6d5-d0a6-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-projected-4kxd2" to be "success or failure"
Sep  6 13:03:39.699: INFO: Pod "downwardapi-volume-bedce6d5-d0a6-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 7.768916ms
Sep  6 13:03:41.708: INFO: Pod "downwardapi-volume-bedce6d5-d0a6-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016435766s
STEP: Saw pod success
Sep  6 13:03:41.708: INFO: Pod "downwardapi-volume-bedce6d5-d0a6-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 13:03:41.712: INFO: Trying to get logs from node metalk8s-22 pod downwardapi-volume-bedce6d5-d0a6-11e9-9cef-86a5da7a2260 container client-container: <nil>
STEP: delete the pod
Sep  6 13:03:41.739: INFO: Waiting for pod downwardapi-volume-bedce6d5-d0a6-11e9-9cef-86a5da7a2260 to disappear
Sep  6 13:03:41.742: INFO: Pod downwardapi-volume-bedce6d5-d0a6-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 13:03:41.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4kxd2" for this suite.
Sep  6 13:03:47.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 13:03:47.837: INFO: namespace: e2e-tests-projected-4kxd2, resource: bindings, ignored listing per whitelist
Sep  6 13:03:47.878: INFO: namespace e2e-tests-projected-4kxd2 deletion completed in 6.128220615s

• [SLOW TEST:8.342 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 13:03:47.878: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  6 13:03:47.944: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 13:03:51.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-nqk6n" for this suite.
Sep  6 13:03:57.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 13:03:57.645: INFO: namespace: e2e-tests-init-container-nqk6n, resource: bindings, ignored listing per whitelist
Sep  6 13:03:57.709: INFO: namespace e2e-tests-init-container-nqk6n deletion completed in 6.144804663s

• [SLOW TEST:9.831 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 13:03:57.709: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Sep  6 13:03:57.816: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep  6 13:03:57.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:03:58.077: INFO: stderr: ""
Sep  6 13:03:58.077: INFO: stdout: "service/redis-slave created\n"
Sep  6 13:03:58.077: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep  6 13:03:58.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:03:58.265: INFO: stderr: ""
Sep  6 13:03:58.266: INFO: stdout: "service/redis-master created\n"
Sep  6 13:03:58.266: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep  6 13:03:58.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:03:58.462: INFO: stderr: ""
Sep  6 13:03:58.462: INFO: stdout: "service/frontend created\n"
Sep  6 13:03:58.462: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep  6 13:03:58.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:03:58.653: INFO: stderr: ""
Sep  6 13:03:58.653: INFO: stdout: "deployment.extensions/frontend created\n"
Sep  6 13:03:58.653: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep  6 13:03:58.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:03:58.857: INFO: stderr: ""
Sep  6 13:03:58.857: INFO: stdout: "deployment.extensions/redis-master created\n"
Sep  6 13:03:58.857: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep  6 13:03:58.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:03:59.169: INFO: stderr: ""
Sep  6 13:03:59.169: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Sep  6 13:03:59.169: INFO: Waiting for all frontend pods to be Running.
Sep  6 13:04:24.221: INFO: Waiting for frontend to serve content.
Sep  6 13:04:24.239: INFO: Trying to add a new entry to the guestbook.
Sep  6 13:04:24.258: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep  6 13:04:24.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:04:24.452: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 13:04:24.452: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep  6 13:04:24.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:04:24.704: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 13:04:24.704: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  6 13:04:24.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:04:24.966: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 13:04:24.966: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  6 13:04:24.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:04:25.136: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 13:04:25.136: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  6 13:04:25.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:04:25.336: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 13:04:25.336: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  6 13:04:25.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fnlrx'
Sep  6 13:04:25.675: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 13:04:25.675: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 13:04:25.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fnlrx" for this suite.
Sep  6 13:05:05.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 13:05:05.785: INFO: namespace: e2e-tests-kubectl-fnlrx, resource: bindings, ignored listing per whitelist
Sep  6 13:05:05.897: INFO: namespace e2e-tests-kubectl-fnlrx deletion completed in 40.206893517s

• [SLOW TEST:68.188 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 13:05:05.897: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  6 13:05:05.978: INFO: Waiting up to 5m0s for pod "downward-api-f24ba7c4-d0a6-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-downward-api-bmdxp" to be "success or failure"
Sep  6 13:05:05.982: INFO: Pod "downward-api-f24ba7c4-d0a6-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 3.322045ms
Sep  6 13:05:07.985: INFO: Pod "downward-api-f24ba7c4-d0a6-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.007157407s
Sep  6 13:05:09.989: INFO: Pod "downward-api-f24ba7c4-d0a6-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011162599s
STEP: Saw pod success
Sep  6 13:05:09.990: INFO: Pod "downward-api-f24ba7c4-d0a6-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 13:05:09.993: INFO: Trying to get logs from node metalk8s-22 pod downward-api-f24ba7c4-d0a6-11e9-9cef-86a5da7a2260 container dapi-container: <nil>
STEP: delete the pod
Sep  6 13:05:10.012: INFO: Waiting for pod downward-api-f24ba7c4-d0a6-11e9-9cef-86a5da7a2260 to disappear
Sep  6 13:05:10.015: INFO: Pod downward-api-f24ba7c4-d0a6-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 13:05:10.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bmdxp" for this suite.
Sep  6 13:05:16.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 13:05:16.286: INFO: namespace: e2e-tests-downward-api-bmdxp, resource: bindings, ignored listing per whitelist
Sep  6 13:05:16.501: INFO: namespace e2e-tests-downward-api-bmdxp deletion completed in 6.483550918s

• [SLOW TEST:10.603 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 13:05:16.501: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  6 13:05:16.709: INFO: Waiting up to 5m0s for pod "pod-f8af4f84-d0a6-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-emptydir-8prnq" to be "success or failure"
Sep  6 13:05:16.715: INFO: Pod "pod-f8af4f84-d0a6-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 5.81959ms
Sep  6 13:05:18.719: INFO: Pod "pod-f8af4f84-d0a6-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.009877949s
Sep  6 13:05:20.723: INFO: Pod "pod-f8af4f84-d0a6-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013647384s
STEP: Saw pod success
Sep  6 13:05:20.723: INFO: Pod "pod-f8af4f84-d0a6-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 13:05:20.727: INFO: Trying to get logs from node metalk8s-22 pod pod-f8af4f84-d0a6-11e9-9cef-86a5da7a2260 container test-container: <nil>
STEP: delete the pod
Sep  6 13:05:20.747: INFO: Waiting for pod pod-f8af4f84-d0a6-11e9-9cef-86a5da7a2260 to disappear
Sep  6 13:05:20.750: INFO: Pod pod-f8af4f84-d0a6-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 13:05:20.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8prnq" for this suite.
Sep  6 13:05:28.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 13:05:28.231: INFO: namespace: e2e-tests-emptydir-8prnq, resource: bindings, ignored listing per whitelist
Sep  6 13:05:28.279: INFO: namespace e2e-tests-emptydir-8prnq deletion completed in 7.525392215s

• [SLOW TEST:11.779 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 13:05:28.280: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Sep  6 13:05:28.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 create -f - --namespace=e2e-tests-kubectl-ghj2c'
Sep  6 13:05:28.632: INFO: stderr: ""
Sep  6 13:05:28.632: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Sep  6 13:05:29.639: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 13:05:29.639: INFO: Found 0 / 1
Sep  6 13:05:30.635: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 13:05:30.635: INFO: Found 1 / 1
Sep  6 13:05:30.635: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  6 13:05:30.638: INFO: Selector matched 1 pods for map[app:redis]
Sep  6 13:05:30.638: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep  6 13:05:30.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 logs redis-master-ds8td redis-master --namespace=e2e-tests-kubectl-ghj2c'
Sep  6 13:05:30.735: INFO: stderr: ""
Sep  6 13:05:30.735: INFO: stdout: "1:M 06 Sep 13:05:29.795 # You requested maxclients of 10000 requiring at least 10032 max file descriptors.\n1:M 06 Sep 13:05:29.795 # Server can't set maximum open files to 10032 because of OS error: Operation not permitted.\n1:M 06 Sep 13:05:29.795 # Current maximum open files is 4096. maxclients has been reduced to 4064 to compensate for low ulimit. If you need higher maxclients increase 'ulimit -n'.\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Sep 13:05:29.797 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Sep 13:05:29.797 # Server started, Redis version 3.2.12\n1:M 06 Sep 13:05:29.797 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Sep 13:05:29.797 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep  6 13:05:30.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 log redis-master-ds8td redis-master --namespace=e2e-tests-kubectl-ghj2c --tail=1'
Sep  6 13:05:30.852: INFO: stderr: ""
Sep  6 13:05:30.852: INFO: stdout: "1:M 06 Sep 13:05:29.797 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep  6 13:05:30.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 log redis-master-ds8td redis-master --namespace=e2e-tests-kubectl-ghj2c --limit-bytes=1'
Sep  6 13:05:30.955: INFO: stderr: ""
Sep  6 13:05:30.955: INFO: stdout: "1"
STEP: exposing timestamps
Sep  6 13:05:30.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 log redis-master-ds8td redis-master --namespace=e2e-tests-kubectl-ghj2c --tail=1 --timestamps'
Sep  6 13:05:31.103: INFO: stderr: ""
Sep  6 13:05:31.103: INFO: stdout: "2019-09-06T13:05:29.797863963Z 1:M 06 Sep 13:05:29.797 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep  6 13:05:33.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 log redis-master-ds8td redis-master --namespace=e2e-tests-kubectl-ghj2c --since=1s'
Sep  6 13:05:33.723: INFO: stderr: ""
Sep  6 13:05:33.723: INFO: stdout: ""
Sep  6 13:05:33.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 log redis-master-ds8td redis-master --namespace=e2e-tests-kubectl-ghj2c --since=24h'
Sep  6 13:05:33.842: INFO: stderr: ""
Sep  6 13:05:33.842: INFO: stdout: "1:M 06 Sep 13:05:29.795 # You requested maxclients of 10000 requiring at least 10032 max file descriptors.\n1:M 06 Sep 13:05:29.795 # Server can't set maximum open files to 10032 because of OS error: Operation not permitted.\n1:M 06 Sep 13:05:29.795 # Current maximum open files is 4096. maxclients has been reduced to 4064 to compensate for low ulimit. If you need higher maxclients increase 'ulimit -n'.\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Sep 13:05:29.797 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Sep 13:05:29.797 # Server started, Redis version 3.2.12\n1:M 06 Sep 13:05:29.797 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Sep 13:05:29.797 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Sep  6 13:05:33.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ghj2c'
Sep  6 13:05:33.925: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  6 13:05:33.925: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep  6 13:05:33.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-ghj2c'
Sep  6 13:05:34.058: INFO: stderr: "No resources found.\n"
Sep  6 13:05:34.058: INFO: stdout: ""
Sep  6 13:05:34.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-878575678 get pods -l name=nginx --namespace=e2e-tests-kubectl-ghj2c -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  6 13:05:34.200: INFO: stderr: ""
Sep  6 13:05:34.200: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 13:05:34.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ghj2c" for this suite.
Sep  6 13:05:40.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 13:05:40.255: INFO: namespace: e2e-tests-kubectl-ghj2c, resource: bindings, ignored listing per whitelist
Sep  6 13:05:40.311: INFO: namespace e2e-tests-kubectl-ghj2c deletion completed in 6.106924458s

• [SLOW TEST:12.031 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  6 13:05:40.311: INFO: >>> kubeConfig: /tmp/kubeconfig-878575678
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Sep  6 13:05:40.388: INFO: Waiting up to 5m0s for pod "var-expansion-06cea2c0-d0a7-11e9-9cef-86a5da7a2260" in namespace "e2e-tests-var-expansion-84fh4" to be "success or failure"
Sep  6 13:05:40.398: INFO: Pod "var-expansion-06cea2c0-d0a7-11e9-9cef-86a5da7a2260": Phase="Pending", Reason="", readiness=false. Elapsed: 9.620288ms
Sep  6 13:05:42.401: INFO: Pod "var-expansion-06cea2c0-d0a7-11e9-9cef-86a5da7a2260": Phase="Running", Reason="", readiness=true. Elapsed: 2.012820404s
Sep  6 13:05:44.412: INFO: Pod "var-expansion-06cea2c0-d0a7-11e9-9cef-86a5da7a2260": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024041601s
STEP: Saw pod success
Sep  6 13:05:44.412: INFO: Pod "var-expansion-06cea2c0-d0a7-11e9-9cef-86a5da7a2260" satisfied condition "success or failure"
Sep  6 13:05:44.417: INFO: Trying to get logs from node metalk8s-22 pod var-expansion-06cea2c0-d0a7-11e9-9cef-86a5da7a2260 container dapi-container: <nil>
STEP: delete the pod
Sep  6 13:05:44.508: INFO: Waiting for pod var-expansion-06cea2c0-d0a7-11e9-9cef-86a5da7a2260 to disappear
Sep  6 13:05:44.515: INFO: Pod var-expansion-06cea2c0-d0a7-11e9-9cef-86a5da7a2260 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  6 13:05:44.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-84fh4" for this suite.
Sep  6 13:05:50.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  6 13:05:50.651: INFO: namespace: e2e-tests-var-expansion-84fh4, resource: bindings, ignored listing per whitelist
Sep  6 13:05:50.660: INFO: namespace e2e-tests-var-expansion-84fh4 deletion completed in 6.141590192s

• [SLOW TEST:10.349 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSep  6 13:05:50.660: INFO: Running AfterSuite actions on all nodes
Sep  6 13:05:50.661: INFO: Running AfterSuite actions on node 1
Sep  6 13:05:50.661: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5566.536 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h32m48.003905575s
Test Suite Passed
