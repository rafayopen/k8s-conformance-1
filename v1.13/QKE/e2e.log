I0715 13:21:57.932302      22 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-170914682
I0715 13:21:57.933774      22 e2e.go:224] Starting e2e run "8521c4b4-a703-11e9-afda-96f40a16177b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1563196917 - Will randomize all specs
Will run 201 of 1946 specs

Jul 15 13:21:58.374: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 13:21:58.378: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jul 15 13:21:58.391: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jul 15 13:21:58.431: INFO: 18 / 18 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jul 15 13:21:58.431: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Jul 15 13:21:58.431: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jul 15 13:21:58.444: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Jul 15 13:21:58.444: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-qingcloud-node' (0 seconds elapsed)
Jul 15 13:21:58.444: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jul 15 13:21:58.444: INFO: e2e test version: v1.13.0
Jul 15 13:21:58.445: INFO: kube-apiserver version: v1.13.5
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:21:58.446: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename replicaset
Jul 15 13:21:58.616: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jul 15 13:22:16.713: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:22:17.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-p52v6" for this suite.
Jul 15 13:22:31.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:22:31.791: INFO: namespace: e2e-tests-replicaset-p52v6, resource: bindings, ignored listing per whitelist
Jul 15 13:22:34.112: INFO: namespace e2e-tests-replicaset-p52v6 deletion completed in 16.37990542s

• [SLOW TEST:35.666 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:22:34.113: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 13:22:34.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-n78zg'
Jul 15 13:22:34.617: INFO: stderr: ""
Jul 15 13:22:34.617: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Jul 15 13:22:34.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-n78zg'
Jul 15 13:22:43.612: INFO: stderr: ""
Jul 15 13:22:43.612: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:22:43.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n78zg" for this suite.
Jul 15 13:22:49.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:22:49.672: INFO: namespace: e2e-tests-kubectl-n78zg, resource: bindings, ignored listing per whitelist
Jul 15 13:22:52.007: INFO: namespace e2e-tests-kubectl-n78zg deletion completed in 8.390388786s

• [SLOW TEST:17.894 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:22:52.008: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul 15 13:22:52.094: INFO: Waiting up to 5m0s for pod "pod-a5dbb521-a703-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-rxm4w" to be "success or failure"
Jul 15 13:22:52.096: INFO: Pod "pod-a5dbb521-a703-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.841112ms
Jul 15 13:22:56.841: INFO: Pod "pod-a5dbb521-a703-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.746856414s
Jul 15 13:22:58.844: INFO: Pod "pod-a5dbb521-a703-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.750093764s
STEP: Saw pod success
Jul 15 13:22:58.844: INFO: Pod "pod-a5dbb521-a703-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:22:58.846: INFO: Trying to get logs from node i-x8osldkx pod pod-a5dbb521-a703-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 13:22:58.869: INFO: Waiting for pod pod-a5dbb521-a703-11e9-afda-96f40a16177b to disappear
Jul 15 13:22:58.871: INFO: Pod pod-a5dbb521-a703-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:22:58.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rxm4w" for this suite.
Jul 15 13:23:04.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:23:05.005: INFO: namespace: e2e-tests-emptydir-rxm4w, resource: bindings, ignored listing per whitelist
Jul 15 13:23:07.271: INFO: namespace e2e-tests-emptydir-rxm4w deletion completed in 8.395299865s

• [SLOW TEST:15.263 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:23:07.271: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jul 15 13:23:07.378: INFO: Waiting up to 5m0s for pod "var-expansion-aef6ffb9-a703-11e9-afda-96f40a16177b" in namespace "e2e-tests-var-expansion-fnsn2" to be "success or failure"
Jul 15 13:23:07.381: INFO: Pod "var-expansion-aef6ffb9-a703-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.260851ms
Jul 15 13:23:09.384: INFO: Pod "var-expansion-aef6ffb9-a703-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006017713s
Jul 15 13:23:11.387: INFO: Pod "var-expansion-aef6ffb9-a703-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008986003s
Jul 15 13:23:13.391: INFO: Pod "var-expansion-aef6ffb9-a703-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012738095s
Jul 15 13:23:15.396: INFO: Pod "var-expansion-aef6ffb9-a703-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.017446297s
STEP: Saw pod success
Jul 15 13:23:15.396: INFO: Pod "var-expansion-aef6ffb9-a703-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:23:15.405: INFO: Trying to get logs from node i-tkuhh2hc pod var-expansion-aef6ffb9-a703-11e9-afda-96f40a16177b container dapi-container: <nil>
STEP: delete the pod
Jul 15 13:23:15.441: INFO: Waiting for pod var-expansion-aef6ffb9-a703-11e9-afda-96f40a16177b to disappear
Jul 15 13:23:15.444: INFO: Pod var-expansion-aef6ffb9-a703-11e9-afda-96f40a16177b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:23:15.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-fnsn2" for this suite.
Jul 15 13:23:21.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:23:22.431: INFO: namespace: e2e-tests-var-expansion-fnsn2, resource: bindings, ignored listing per whitelist
Jul 15 13:23:23.827: INFO: namespace e2e-tests-var-expansion-fnsn2 deletion completed in 8.377865163s

• [SLOW TEST:16.556 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:23:23.829: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0715 13:24:03.940811      22 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 13:24:03.940: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:24:03.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hnk2n" for this suite.
Jul 15 13:24:09.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:24:10.057: INFO: namespace: e2e-tests-gc-hnk2n, resource: bindings, ignored listing per whitelist
Jul 15 13:24:12.357: INFO: namespace e2e-tests-gc-hnk2n deletion completed in 8.410927281s

• [SLOW TEST:48.528 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:24:12.359: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-wmnsh
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 15 13:24:12.463: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 15 13:24:34.610: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.10.2.56 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wmnsh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 13:24:34.610: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 13:24:35.786: INFO: Found all expected endpoints: [netserver-0]
Jul 15 13:24:35.789: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.10.1.55 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wmnsh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 13:24:35.789: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 13:24:36.998: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:24:36.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-wmnsh" for this suite.
Jul 15 13:24:59.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:25:00.687: INFO: namespace: e2e-tests-pod-network-test-wmnsh, resource: bindings, ignored listing per whitelist
Jul 15 13:25:01.389: INFO: namespace e2e-tests-pod-network-test-wmnsh deletion completed in 24.386633036s

• [SLOW TEST:49.030 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:25:01.389: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lktzd
Jul 15 13:25:05.516: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lktzd
STEP: checking the pod's current state and verifying that restartCount is present
Jul 15 13:25:05.518: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:29:05.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lktzd" for this suite.
Jul 15 13:29:12.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:29:14.040: INFO: namespace: e2e-tests-container-probe-lktzd, resource: bindings, ignored listing per whitelist
Jul 15 13:29:14.390: INFO: namespace e2e-tests-container-probe-lktzd deletion completed in 8.385664575s

• [SLOW TEST:253.001 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:29:14.393: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul 15 13:29:22.551: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 13:29:22.554: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 13:29:24.554: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 13:29:24.558: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 13:29:26.558: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 13:29:26.563: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 13:29:28.554: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 13:29:28.557: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 13:29:30.554: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 13:29:30.557: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 13:29:32.554: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 13:29:32.558: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 13:29:34.554: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 13:29:34.557: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 13:29:36.556: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 13:29:36.562: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 13:29:38.554: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 13:29:38.558: INFO: Pod pod-with-poststart-exec-hook still exists
Jul 15 13:29:40.554: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul 15 13:29:40.558: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:29:40.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-zgsmb" for this suite.
Jul 15 13:30:04.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:30:06.901: INFO: namespace: e2e-tests-container-lifecycle-hook-zgsmb, resource: bindings, ignored listing per whitelist
Jul 15 13:30:06.951: INFO: namespace e2e-tests-container-lifecycle-hook-zgsmb deletion completed in 26.385756157s

• [SLOW TEST:52.559 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:30:06.953: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul 15 13:30:07.089: INFO: Waiting up to 5m0s for pod "pod-a9220cc0-a704-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-4bx56" to be "success or failure"
Jul 15 13:30:07.094: INFO: Pod "pod-a9220cc0-a704-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.451801ms
Jul 15 13:30:09.097: INFO: Pod "pod-a9220cc0-a704-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008520382s
Jul 15 13:30:11.101: INFO: Pod "pod-a9220cc0-a704-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012119069s
STEP: Saw pod success
Jul 15 13:30:11.101: INFO: Pod "pod-a9220cc0-a704-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:30:11.103: INFO: Trying to get logs from node i-tkuhh2hc pod pod-a9220cc0-a704-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 13:30:11.124: INFO: Waiting for pod pod-a9220cc0-a704-11e9-afda-96f40a16177b to disappear
Jul 15 13:30:11.129: INFO: Pod pod-a9220cc0-a704-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:30:11.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4bx56" for this suite.
Jul 15 13:30:17.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:30:17.217: INFO: namespace: e2e-tests-emptydir-4bx56, resource: bindings, ignored listing per whitelist
Jul 15 13:30:19.520: INFO: namespace e2e-tests-emptydir-4bx56 deletion completed in 8.386791922s

• [SLOW TEST:12.567 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:30:19.521: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-5t9cz
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-5t9cz
STEP: Deleting pre-stop pod
Jul 15 13:30:32.703: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:30:32.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-5t9cz" for this suite.
Jul 15 13:31:12.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:31:14.399: INFO: namespace: e2e-tests-prestop-5t9cz, resource: bindings, ignored listing per whitelist
Jul 15 13:31:15.099: INFO: namespace e2e-tests-prestop-5t9cz deletion completed in 42.383723727s

• [SLOW TEST:55.578 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:31:15.099: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jul 15 13:31:15.207: INFO: Waiting up to 5m0s for pod "client-containers-d1bc4b99-a704-11e9-afda-96f40a16177b" in namespace "e2e-tests-containers-kj9j7" to be "success or failure"
Jul 15 13:31:15.212: INFO: Pod "client-containers-d1bc4b99-a704-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.714424ms
Jul 15 13:31:17.216: INFO: Pod "client-containers-d1bc4b99-a704-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008211178s
Jul 15 13:31:19.219: INFO: Pod "client-containers-d1bc4b99-a704-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011515128s
Jul 15 13:31:21.222: INFO: Pod "client-containers-d1bc4b99-a704-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014545155s
STEP: Saw pod success
Jul 15 13:31:21.222: INFO: Pod "client-containers-d1bc4b99-a704-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:31:21.224: INFO: Trying to get logs from node i-x8osldkx pod client-containers-d1bc4b99-a704-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 13:31:21.262: INFO: Waiting for pod client-containers-d1bc4b99-a704-11e9-afda-96f40a16177b to disappear
Jul 15 13:31:21.283: INFO: Pod client-containers-d1bc4b99-a704-11e9-afda-96f40a16177b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:31:21.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-kj9j7" for this suite.
Jul 15 13:31:27.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:31:28.748: INFO: namespace: e2e-tests-containers-kj9j7, resource: bindings, ignored listing per whitelist
Jul 15 13:31:29.693: INFO: namespace e2e-tests-containers-kj9j7 deletion completed in 8.390084246s

• [SLOW TEST:14.594 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:31:29.697: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul 15 13:31:29.802: INFO: Waiting up to 5m0s for pod "pod-da6db6f4-a704-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-97jkr" to be "success or failure"
Jul 15 13:31:29.806: INFO: Pod "pod-da6db6f4-a704-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.895863ms
Jul 15 13:31:31.810: INFO: Pod "pod-da6db6f4-a704-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007313977s
Jul 15 13:31:33.813: INFO: Pod "pod-da6db6f4-a704-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010556039s
Jul 15 13:31:35.816: INFO: Pod "pod-da6db6f4-a704-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013636554s
STEP: Saw pod success
Jul 15 13:31:35.816: INFO: Pod "pod-da6db6f4-a704-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:31:35.819: INFO: Trying to get logs from node i-x8osldkx pod pod-da6db6f4-a704-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 13:31:35.837: INFO: Waiting for pod pod-da6db6f4-a704-11e9-afda-96f40a16177b to disappear
Jul 15 13:31:35.840: INFO: Pod pod-da6db6f4-a704-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:31:35.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-97jkr" for this suite.
Jul 15 13:31:41.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:31:43.633: INFO: namespace: e2e-tests-emptydir-97jkr, resource: bindings, ignored listing per whitelist
Jul 15 13:31:44.234: INFO: namespace e2e-tests-emptydir-97jkr deletion completed in 8.388403387s

• [SLOW TEST:14.537 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:31:44.234: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jul 15 13:31:44.352: INFO: PodSpec: initContainers in spec.initContainers
Jul 15 13:32:30.749: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-e31cad59-a704-11e9-afda-96f40a16177b", GenerateName:"", Namespace:"e2e-tests-init-container-x28mf", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-x28mf/pods/pod-init-e31cad59-a704-11e9-afda-96f40a16177b", UID:"e31daaed-a704-11e9-8341-525422241ab4", ResourceVersion:"40579", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63698794304, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"352796670"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.10.1.59/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-dc2sx", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0007afa00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dc2sx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dc2sx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dc2sx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001204058), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"i-tkuhh2hc", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000fe1e60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0012043a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0012043c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0012043c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0012043cc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698794304, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698794304, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698794304, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698794304, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.0.23", PodIP:"10.10.1.59", StartTime:(*v1.Time)(0xc001efa420), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001b09ea0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001b09f10)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://7b7bb921f09e6b6cc7152c01cd440e49a3817b4331792c7722871d73d3f5b2ec"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001efa460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001efa440), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:32:30.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-x28mf" for this suite.
Jul 15 13:32:52.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:32:52.798: INFO: namespace: e2e-tests-init-container-x28mf, resource: bindings, ignored listing per whitelist
Jul 15 13:32:55.140: INFO: namespace e2e-tests-init-container-x28mf deletion completed in 24.385408546s

• [SLOW TEST:70.915 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:32:55.152: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-0d5ef937-a705-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 13:32:55.263: INFO: Waiting up to 5m0s for pod "pod-configmaps-0d5f88cf-a705-11e9-afda-96f40a16177b" in namespace "e2e-tests-configmap-x222z" to be "success or failure"
Jul 15 13:32:55.266: INFO: Pod "pod-configmaps-0d5f88cf-a705-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.192249ms
Jul 15 13:32:57.272: INFO: Pod "pod-configmaps-0d5f88cf-a705-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008472878s
STEP: Saw pod success
Jul 15 13:32:57.272: INFO: Pod "pod-configmaps-0d5f88cf-a705-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:32:57.280: INFO: Trying to get logs from node i-tkuhh2hc pod pod-configmaps-0d5f88cf-a705-11e9-afda-96f40a16177b container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 13:32:57.300: INFO: Waiting for pod pod-configmaps-0d5f88cf-a705-11e9-afda-96f40a16177b to disappear
Jul 15 13:32:57.304: INFO: Pod pod-configmaps-0d5f88cf-a705-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:32:57.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x222z" for this suite.
Jul 15 13:33:03.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:33:03.386: INFO: namespace: e2e-tests-configmap-x222z, resource: bindings, ignored listing per whitelist
Jul 15 13:33:05.701: INFO: namespace e2e-tests-configmap-x222z deletion completed in 8.392669877s

• [SLOW TEST:10.549 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:33:05.702: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 13:33:05.810: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13a95feb-a705-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-wmd2w" to be "success or failure"
Jul 15 13:33:05.819: INFO: Pod "downwardapi-volume-13a95feb-a705-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.226698ms
Jul 15 13:33:07.822: INFO: Pod "downwardapi-volume-13a95feb-a705-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011361459s
Jul 15 13:33:09.826: INFO: Pod "downwardapi-volume-13a95feb-a705-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015096865s
STEP: Saw pod success
Jul 15 13:33:09.826: INFO: Pod "downwardapi-volume-13a95feb-a705-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:33:09.828: INFO: Trying to get logs from node i-x8osldkx pod downwardapi-volume-13a95feb-a705-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 13:33:09.855: INFO: Waiting for pod downwardapi-volume-13a95feb-a705-11e9-afda-96f40a16177b to disappear
Jul 15 13:33:09.860: INFO: Pod downwardapi-volume-13a95feb-a705-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:33:09.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wmd2w" for this suite.
Jul 15 13:33:15.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:33:15.930: INFO: namespace: e2e-tests-projected-wmd2w, resource: bindings, ignored listing per whitelist
Jul 15 13:33:18.253: INFO: namespace e2e-tests-projected-wmd2w deletion completed in 8.388312395s

• [SLOW TEST:12.551 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:33:18.253: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 13:33:18.368: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b2569c8-a705-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-ljc9v" to be "success or failure"
Jul 15 13:33:18.370: INFO: Pod "downwardapi-volume-1b2569c8-a705-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.951387ms
Jul 15 13:33:20.374: INFO: Pod "downwardapi-volume-1b2569c8-a705-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005465882s
STEP: Saw pod success
Jul 15 13:33:20.375: INFO: Pod "downwardapi-volume-1b2569c8-a705-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:33:20.381: INFO: Trying to get logs from node i-tkuhh2hc pod downwardapi-volume-1b2569c8-a705-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 13:33:20.412: INFO: Waiting for pod downwardapi-volume-1b2569c8-a705-11e9-afda-96f40a16177b to disappear
Jul 15 13:33:20.415: INFO: Pod downwardapi-volume-1b2569c8-a705-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:33:20.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ljc9v" for this suite.
Jul 15 13:33:26.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:33:26.475: INFO: namespace: e2e-tests-projected-ljc9v, resource: bindings, ignored listing per whitelist
Jul 15 13:33:28.799: INFO: namespace e2e-tests-projected-ljc9v deletion completed in 8.380003176s

• [SLOW TEST:10.545 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:33:28.799: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-216a9933-a705-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 13:33:28.903: INFO: Waiting up to 5m0s for pod "pod-secrets-216c3f73-a705-11e9-afda-96f40a16177b" in namespace "e2e-tests-secrets-hkkhh" to be "success or failure"
Jul 15 13:33:28.905: INFO: Pod "pod-secrets-216c3f73-a705-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.91883ms
Jul 15 13:33:30.909: INFO: Pod "pod-secrets-216c3f73-a705-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005246538s
Jul 15 13:33:32.912: INFO: Pod "pod-secrets-216c3f73-a705-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008407857s
STEP: Saw pod success
Jul 15 13:33:32.912: INFO: Pod "pod-secrets-216c3f73-a705-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:33:32.914: INFO: Trying to get logs from node i-x8osldkx pod pod-secrets-216c3f73-a705-11e9-afda-96f40a16177b container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 13:33:32.933: INFO: Waiting for pod pod-secrets-216c3f73-a705-11e9-afda-96f40a16177b to disappear
Jul 15 13:33:32.936: INFO: Pod pod-secrets-216c3f73-a705-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:33:32.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hkkhh" for this suite.
Jul 15 13:33:38.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:33:40.681: INFO: namespace: e2e-tests-secrets-hkkhh, resource: bindings, ignored listing per whitelist
Jul 15 13:33:41.331: INFO: namespace e2e-tests-secrets-hkkhh deletion completed in 8.388895936s

• [SLOW TEST:12.532 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:33:41.334: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jul 15 13:33:41.429: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nm8hq,SelfLink:/api/v1/namespaces/e2e-tests-watch-nm8hq/configmaps/e2e-watch-test-watch-closed,UID:28e3f565-a705-11e9-8341-525422241ab4,ResourceVersion:40861,Generation:0,CreationTimestamp:2019-07-15 13:33:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 15 13:33:41.430: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nm8hq,SelfLink:/api/v1/namespaces/e2e-tests-watch-nm8hq/configmaps/e2e-watch-test-watch-closed,UID:28e3f565-a705-11e9-8341-525422241ab4,ResourceVersion:40862,Generation:0,CreationTimestamp:2019-07-15 13:33:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jul 15 13:33:41.441: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nm8hq,SelfLink:/api/v1/namespaces/e2e-tests-watch-nm8hq/configmaps/e2e-watch-test-watch-closed,UID:28e3f565-a705-11e9-8341-525422241ab4,ResourceVersion:40863,Generation:0,CreationTimestamp:2019-07-15 13:33:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 15 13:33:41.442: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-nm8hq,SelfLink:/api/v1/namespaces/e2e-tests-watch-nm8hq/configmaps/e2e-watch-test-watch-closed,UID:28e3f565-a705-11e9-8341-525422241ab4,ResourceVersion:40864,Generation:0,CreationTimestamp:2019-07-15 13:33:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:33:41.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-nm8hq" for this suite.
Jul 15 13:33:47.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:33:47.612: INFO: namespace: e2e-tests-watch-nm8hq, resource: bindings, ignored listing per whitelist
Jul 15 13:33:49.901: INFO: namespace e2e-tests-watch-nm8hq deletion completed in 8.452111593s

• [SLOW TEST:8.567 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:33:49.902: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-cs7qq
Jul 15 13:33:56.035: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-cs7qq
STEP: checking the pod's current state and verifying that restartCount is present
Jul 15 13:33:56.037: INFO: Initial restart count of pod liveness-http is 0
Jul 15 13:34:14.070: INFO: Restart count of pod e2e-tests-container-probe-cs7qq/liveness-http is now 1 (18.03261113s elapsed)
Jul 15 13:34:34.111: INFO: Restart count of pod e2e-tests-container-probe-cs7qq/liveness-http is now 2 (38.073630337s elapsed)
Jul 15 13:34:54.148: INFO: Restart count of pod e2e-tests-container-probe-cs7qq/liveness-http is now 3 (58.111037699s elapsed)
Jul 15 13:35:14.195: INFO: Restart count of pod e2e-tests-container-probe-cs7qq/liveness-http is now 4 (1m18.158101578s elapsed)
Jul 15 13:36:18.321: INFO: Restart count of pod e2e-tests-container-probe-cs7qq/liveness-http is now 5 (2m22.28385007s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:36:18.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cs7qq" for this suite.
Jul 15 13:36:24.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:36:24.400: INFO: namespace: e2e-tests-container-probe-cs7qq, resource: bindings, ignored listing per whitelist
Jul 15 13:36:26.713: INFO: namespace e2e-tests-container-probe-cs7qq deletion completed in 8.378067372s

• [SLOW TEST:156.812 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:36:26.713: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 13:36:26.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-q92pt'
Jul 15 13:36:27.207: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 15 13:36:27.210: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Jul 15 13:36:27.228: INFO: scanned /root for discovery docs: <nil>
Jul 15 13:36:27.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-q92pt'
Jul 15 13:36:38.224: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jul 15 13:36:38.224: INFO: stdout: "Created e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e\nScaling up e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jul 15 13:36:38.224: INFO: stdout: "Created e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e\nScaling up e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jul 15 13:36:38.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-q92pt'
Jul 15 13:36:38.355: INFO: stderr: ""
Jul 15 13:36:38.355: INFO: stdout: "e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e-whdg8 e2e-test-nginx-rc-brzxt "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Jul 15 13:36:43.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-q92pt'
Jul 15 13:36:43.476: INFO: stderr: ""
Jul 15 13:36:43.476: INFO: stdout: "e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e-whdg8 e2e-test-nginx-rc-brzxt "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Jul 15 13:36:48.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-q92pt'
Jul 15 13:36:48.614: INFO: stderr: ""
Jul 15 13:36:48.615: INFO: stdout: "e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e-whdg8 "
Jul 15 13:36:48.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e-whdg8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-q92pt'
Jul 15 13:36:48.713: INFO: stderr: ""
Jul 15 13:36:48.713: INFO: stdout: "true"
Jul 15 13:36:48.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e-whdg8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-q92pt'
Jul 15 13:36:48.823: INFO: stderr: ""
Jul 15 13:36:48.823: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jul 15 13:36:48.823: INFO: e2e-test-nginx-rc-afc52528c34afa754260f804f7fc0d8e-whdg8 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Jul 15 13:36:48.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-q92pt'
Jul 15 13:36:48.935: INFO: stderr: ""
Jul 15 13:36:48.935: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:36:48.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q92pt" for this suite.
Jul 15 13:37:10.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:37:10.990: INFO: namespace: e2e-tests-kubectl-q92pt, resource: bindings, ignored listing per whitelist
Jul 15 13:37:13.333: INFO: namespace e2e-tests-kubectl-q92pt deletion completed in 24.393060605s

• [SLOW TEST:46.620 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:37:13.334: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jul 15 13:37:13.422: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:37:22.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-j5skx" for this suite.
Jul 15 13:37:28.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:37:28.741: INFO: namespace: e2e-tests-init-container-j5skx, resource: bindings, ignored listing per whitelist
Jul 15 13:37:31.008: INFO: namespace e2e-tests-init-container-j5skx deletion completed in 8.38571927s

• [SLOW TEST:17.674 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:37:31.008: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-9jvb
STEP: Creating a pod to test atomic-volume-subpath
Jul 15 13:37:31.152: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9jvb" in namespace "e2e-tests-subpath-4gjhw" to be "success or failure"
Jul 15 13:37:31.174: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Pending", Reason="", readiness=false. Elapsed: 21.670564ms
Jul 15 13:37:33.178: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025190825s
Jul 15 13:37:35.181: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Running", Reason="", readiness=false. Elapsed: 4.028793441s
Jul 15 13:37:37.184: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Running", Reason="", readiness=false. Elapsed: 6.032074774s
Jul 15 13:37:39.188: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Running", Reason="", readiness=false. Elapsed: 8.035793887s
Jul 15 13:37:41.192: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Running", Reason="", readiness=false. Elapsed: 10.039829629s
Jul 15 13:37:43.197: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Running", Reason="", readiness=false. Elapsed: 12.044104046s
Jul 15 13:37:45.200: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Running", Reason="", readiness=false. Elapsed: 14.047340521s
Jul 15 13:37:47.203: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Running", Reason="", readiness=false. Elapsed: 16.050567507s
Jul 15 13:37:49.206: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Running", Reason="", readiness=false. Elapsed: 18.053660901s
Jul 15 13:37:51.210: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Running", Reason="", readiness=false. Elapsed: 20.057768303s
Jul 15 13:37:53.215: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Running", Reason="", readiness=false. Elapsed: 22.062560816s
Jul 15 13:37:55.219: INFO: Pod "pod-subpath-test-secret-9jvb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.066173759s
STEP: Saw pod success
Jul 15 13:37:55.219: INFO: Pod "pod-subpath-test-secret-9jvb" satisfied condition "success or failure"
Jul 15 13:37:55.224: INFO: Trying to get logs from node i-tkuhh2hc pod pod-subpath-test-secret-9jvb container test-container-subpath-secret-9jvb: <nil>
STEP: delete the pod
Jul 15 13:37:55.247: INFO: Waiting for pod pod-subpath-test-secret-9jvb to disappear
Jul 15 13:37:55.250: INFO: Pod pod-subpath-test-secret-9jvb no longer exists
STEP: Deleting pod pod-subpath-test-secret-9jvb
Jul 15 13:37:55.250: INFO: Deleting pod "pod-subpath-test-secret-9jvb" in namespace "e2e-tests-subpath-4gjhw"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:37:55.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4gjhw" for this suite.
Jul 15 13:38:01.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:38:01.437: INFO: namespace: e2e-tests-subpath-4gjhw, resource: bindings, ignored listing per whitelist
Jul 15 13:38:03.649: INFO: namespace e2e-tests-subpath-4gjhw deletion completed in 8.392591389s

• [SLOW TEST:32.641 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:38:03.651: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jul 15 13:38:03.751: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:38:09.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zf7c2" for this suite.
Jul 15 13:38:31.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:38:31.827: INFO: namespace: e2e-tests-init-container-zf7c2, resource: bindings, ignored listing per whitelist
Jul 15 13:38:34.109: INFO: namespace e2e-tests-init-container-zf7c2 deletion completed in 24.388231132s

• [SLOW TEST:30.459 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:38:34.112: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 13:38:34.225: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d76988b8-a705-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-5jbnh" to be "success or failure"
Jul 15 13:38:34.234: INFO: Pod "downwardapi-volume-d76988b8-a705-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.33935ms
Jul 15 13:38:36.237: INFO: Pod "downwardapi-volume-d76988b8-a705-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011845167s
STEP: Saw pod success
Jul 15 13:38:36.238: INFO: Pod "downwardapi-volume-d76988b8-a705-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:38:36.241: INFO: Trying to get logs from node i-tkuhh2hc pod downwardapi-volume-d76988b8-a705-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 13:38:36.269: INFO: Waiting for pod downwardapi-volume-d76988b8-a705-11e9-afda-96f40a16177b to disappear
Jul 15 13:38:36.272: INFO: Pod downwardapi-volume-d76988b8-a705-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:38:36.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5jbnh" for this suite.
Jul 15 13:38:42.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:38:42.396: INFO: namespace: e2e-tests-downward-api-5jbnh, resource: bindings, ignored listing per whitelist
Jul 15 13:38:44.664: INFO: namespace e2e-tests-downward-api-5jbnh deletion completed in 8.386980363s

• [SLOW TEST:10.552 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:38:44.664: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 15 13:38:44.735: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 15 13:38:44.741: INFO: Waiting for terminating namespaces to be deleted...
Jul 15 13:38:44.744: INFO: 
Logging pods the kubelet thinks is on node i-tkuhh2hc before test
Jul 15 13:38:44.775: INFO: ks-devops-db-ctrl-job-nmhx5 from kubesphere-devops-system started at 2019-07-15 08:55:23 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.775: INFO: 	Container devops-db-ctrl ready: false, restart count 0
Jul 15 13:38:44.775: INFO: csi-qingcloud-node-76gtb from kube-system started at 2019-07-15 08:42:33 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.775: INFO: 	Container csi-qingcloud ready: true, restart count 0
Jul 15 13:38:44.775: INFO: 	Container driver-registrar ready: true, restart count 0
Jul 15 13:38:44.775: INFO: openpitrix-app-manager-deployment-77bf8749dc-wxxzl from openpitrix-system started at 2019-07-15 08:45:13 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.775: INFO: 	Container openpitrix-app-manager ready: true, restart count 0
Jul 15 13:38:44.775: INFO: prometheus-k8s-system-0 from kubesphere-monitoring-system started at 2019-07-15 08:46:40 +0000 UTC (3 container statuses recorded)
Jul 15 13:38:44.775: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 13:38:44.775: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 13:38:44.775: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 13:38:44.775: INFO: prometheus-k8s-1 from kubesphere-monitoring-system started at 2019-07-15 08:46:42 +0000 UTC (3 container statuses recorded)
Jul 15 13:38:44.775: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 13:38:44.776: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 13:38:44.776: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 13:38:44.776: INFO: openpitrix-db-init-job-qfxfx from openpitrix-system started at 2019-07-15 08:55:18 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container openpitrix-db-init ready: false, restart count 0
Jul 15 13:38:44.776: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-15 13:17:35 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 15 13:38:44.776: INFO: alerting-db-init-job-z7whr from kubesphere-alerting-system started at 2019-07-15 08:52:09 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container alerting-db-init ready: false, restart count 0
Jul 15 13:38:44.776: INFO: openpitrix-repo-manager-deployment-85fcf79667-wx9bf from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container openpitrix-repo-manager ready: true, restart count 0
Jul 15 13:38:44.776: INFO: uc-jenkins-update-center-598f8d6549-5898r from kubesphere-devops-system started at 2019-07-15 08:49:15 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container jenkins-update-center ready: true, restart count 0
Jul 15 13:38:44.776: INFO: istio-ingressgateway-5477b7ffd9-lt2jc from istio-system started at 2019-07-15 08:49:24 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 13:38:44.776: INFO: openpitrix-runtime-db-ctrl-job-ljjls from openpitrix-system started at 2019-07-15 08:55:17 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container openpitrix-runtime-db-ctrl ready: false, restart count 0
Jul 15 13:38:44.776: INFO: calico-node-b8m4t from kube-system started at 2019-07-15 08:42:22 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 13:38:44.776: INFO: 	Container install-cni ready: true, restart count 0
Jul 15 13:38:44.776: INFO: kube-proxy-dkcd8 from kube-system started at 2019-07-15 08:42:33 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 15 13:38:44.776: INFO: openpitrix-etcd-deployment-54bc9bb948-8qmxl from openpitrix-system started at 2019-07-15 08:45:25 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container openpitrix-etcd ready: true, restart count 0
Jul 15 13:38:44.776: INFO: fluent-bit-2xfkw from kubesphere-logging-system started at 2019-07-15 08:46:28 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container config-reloader ready: true, restart count 0
Jul 15 13:38:44.776: INFO: 	Container fluent-bit ready: true, restart count 0
Jul 15 13:38:44.776: INFO: jaeger-operator-8cb967c86-wjtqg from istio-system started at 2019-07-15 08:55:58 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container jaeger-operator ready: true, restart count 0
Jul 15 13:38:44.776: INFO: alerting-client-5bb5d87f65-6l8ng from kubesphere-alerting-system started at 2019-07-15 08:48:49 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container alerting-client ready: true, restart count 0
Jul 15 13:38:44.776: INFO: openpitrix-runtime-manager-deployment-9c4bb7d5-tsz6x from openpitrix-system started at 2019-07-15 08:45:15 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container openpitrix-runtime-manager ready: true, restart count 0
Jul 15 13:38:44.776: INFO: kubectl-admin-d784b7777-9pzv2 from kubesphere-controls-system started at 2019-07-15 08:47:08 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container kubectl ready: true, restart count 0
Jul 15 13:38:44.776: INFO: ks-sonarqube-sonarqube-7b48f4c664-6zvz7 from kubesphere-devops-system started at 2019-07-15 08:42:50 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container sonarqube ready: true, restart count 5
Jul 15 13:38:44.776: INFO: logging-fluentbit-operator-77ff6dbc78-b5w67 from kubesphere-logging-system started at 2019-07-15 08:46:24 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container fluentbit-operator ready: true, restart count 0
Jul 15 13:38:44.776: INFO: notification-deployment-6b78b697d7-r8cdn from kubesphere-alerting-system started at 2019-07-15 08:48:45 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container notification ready: true, restart count 0
Jul 15 13:38:44.776: INFO: istio-galley-689b548d98-qkcjf from istio-system started at 2019-07-15 08:49:24 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container galley ready: true, restart count 0
Jul 15 13:38:44.776: INFO: istio-pilot-9685dfc4b-n7ltn from istio-system started at 2019-07-15 08:49:39 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.776: INFO: 	Container discovery ready: true, restart count 0
Jul 15 13:38:44.776: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 13:38:44.776: INFO: sonobuoy-systemd-logs-daemon-set-3c9f017d4c504b82-9mlvz from heptio-sonobuoy started at 2019-07-15 13:17:54 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.777: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 15 13:38:44.777: INFO: 	Container systemd-logs ready: true, restart count 0
Jul 15 13:38:44.777: INFO: openpitrix-category-manager-deployment-bf4676856-6wfl6 from openpitrix-system started at 2019-07-15 08:45:13 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.777: INFO: 	Container openpitrix-category-manager ready: true, restart count 0
Jul 15 13:38:44.777: INFO: default-http-backend-96d94689d-bnkh7 from kubesphere-controls-system started at 2019-07-15 08:45:29 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.777: INFO: 	Container default-http-backend ready: true, restart count 0
Jul 15 13:38:44.777: INFO: notification-db-ctrl-job-9qrl4 from kubesphere-alerting-system started at 2019-07-15 08:55:27 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.777: INFO: 	Container notification-db-ctrl ready: false, restart count 0
Jul 15 13:38:44.777: INFO: elasticsearch-logging-data-0 from kubesphere-logging-system started at 2019-07-15 08:46:58 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.777: INFO: 	Container elasticsearch ready: true, restart count 0
Jul 15 13:38:44.777: INFO: istio-telemetry-758d9c786f-45wzg from istio-system started at 2019-07-15 08:49:24 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.778: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 13:38:44.778: INFO: 	Container mixer ready: true, restart count 2
Jul 15 13:38:44.778: INFO: istio-policy-b87497cf4-n4n9m from istio-system started at 2019-07-15 08:49:39 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.778: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 13:38:44.778: INFO: 	Container mixer ready: true, restart count 1
Jul 15 13:38:44.778: INFO: jaeger-query-7764db45bb-926v6 from istio-system started at 2019-07-15 08:56:01 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.778: INFO: 	Container jaeger-agent ready: true, restart count 0
Jul 15 13:38:44.778: INFO: 	Container jaeger-query ready: true, restart count 0
Jul 15 13:38:44.778: INFO: openpitrix-iam-service-deployment-6bc78587f-bsxsl from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.778: INFO: 	Container openpitrix-iam-service ready: true, restart count 5
Jul 15 13:38:44.778: INFO: openpitrix-cluster-db-ctrl-job-nvphh from openpitrix-system started at 2019-07-15 08:55:16 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.778: INFO: 	Container openpitrix-cluster-db-ctrl ready: false, restart count 0
Jul 15 13:38:44.778: INFO: openpitrix-repo-indexer-deployment-d975ddff6-rqd88 from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.778: INFO: 	Container openpitrix-repo-indexer ready: true, restart count 0
Jul 15 13:38:44.778: INFO: node-exporter-f75fb from kubesphere-monitoring-system started at 2019-07-15 08:46:12 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.778: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 15 13:38:44.778: INFO: 	Container node-exporter ready: true, restart count 0
Jul 15 13:38:44.778: INFO: ks-docs-77c4796dc9-npkwv from kubesphere-system started at 2019-07-15 08:46:19 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.778: INFO: 	Container ks-docs ready: true, restart count 0
Jul 15 13:38:44.778: INFO: alerting-executor-75c664c66d-29hfc from kubesphere-alerting-system started at 2019-07-15 08:48:47 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.778: INFO: 	Container alerting-adapter ready: true, restart count 0
Jul 15 13:38:44.778: INFO: 	Container alerting-executor ready: true, restart count 0
Jul 15 13:38:44.778: INFO: openpitrix-job-db-ctrl-job-qph77 from openpitrix-system started at 2019-07-15 08:55:17 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.778: INFO: 	Container openpitrix-job-db-ctrl ready: false, restart count 0
Jul 15 13:38:44.778: INFO: 
Logging pods the kubelet thinks is on node i-x8osldkx before test
Jul 15 13:38:44.811: INFO: istio-citadel-5f886dc9b4-h94c9 from istio-system started at 2019-07-15 08:49:19 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.811: INFO: 	Container citadel ready: true, restart count 0
Jul 15 13:38:44.811: INFO: openpitrix-api-gateway-deployment-585678b9b8-nhzmn from openpitrix-system started at 2019-07-15 08:45:12 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.811: INFO: 	Container openpitrix-api-gateway ready: true, restart count 0
Jul 15 13:38:44.811: INFO: openpitrix-cluster-manager-deployment-745b57798d-nhkq4 from openpitrix-system started at 2019-07-15 08:45:13 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.811: INFO: 	Container openpitrix-cluster-manager ready: true, restart count 0
Jul 15 13:38:44.811: INFO: openpitrix-job-manager-deployment-577649544c-jwgvs from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.811: INFO: 	Container openpitrix-job-manager ready: true, restart count 0
Jul 15 13:38:44.811: INFO: prometheus-operator-7d94949cf8-lzvm6 from kubesphere-monitoring-system started at 2019-07-15 08:46:11 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.811: INFO: 	Container prometheus-operator ready: true, restart count 0
Jul 15 13:38:44.811: INFO: openpitrix-task-db-ctrl-job-pf7f4 from openpitrix-system started at 2019-07-15 08:55:14 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container openpitrix-task-db-ctrl ready: false, restart count 0
Jul 15 13:38:44.812: INFO: istio-init-crd-11-gcd85 from istio-system started at 2019-07-15 08:45:27 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container istio-init-crd-11 ready: false, restart count 0
Jul 15 13:38:44.812: INFO: alerting-db-ctrl-job-jcxcm from kubesphere-alerting-system started at 2019-07-15 08:55:28 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container alerting-db-ctrl ready: false, restart count 0
Jul 15 13:38:44.812: INFO: jaeger-collector-7c567ccbbb-sl7ng from istio-system started at 2019-07-15 08:55:58 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container jaeger-collector ready: true, restart count 0
Jul 15 13:38:44.812: INFO: calico-node-ssbj9 from kube-system started at 2019-07-15 08:42:21 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container install-cni ready: true, restart count 0
Jul 15 13:38:44.812: INFO: s2ioperator-0 from kubesphere-devops-system started at 2019-07-15 08:45:53 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container manager ready: true, restart count 0
Jul 15 13:38:44.812: INFO: alerting-watcher-5d857d87db-zwvvf from kubesphere-alerting-system started at 2019-07-15 08:48:45 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container alerting-watcher ready: true, restart count 0
Jul 15 13:38:44.812: INFO: istio-galley-689b548d98-jqjbz from istio-system started at 2019-07-15 08:49:19 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container galley ready: true, restart count 0
Jul 15 13:38:44.812: INFO: istio-telemetry-758d9c786f-ppdc7 from istio-system started at 2019-07-15 08:49:35 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container mixer ready: true, restart count 1
Jul 15 13:38:44.812: INFO: istio-pilot-9685dfc4b-jdn8c from istio-system started at 2019-07-15 08:49:19 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container discovery ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 13:38:44.812: INFO: ks-devops-db-init-job-8s8ln from kubesphere-devops-system started at 2019-07-15 08:55:18 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container devops-db-init ready: false, restart count 0
Jul 15 13:38:44.812: INFO: ks-sonarqube-postgresql-5d58f5574b-2bc4v from kubesphere-devops-system started at 2019-07-15 08:43:01 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container ks-sonarqube-postgresql ready: true, restart count 0
Jul 15 13:38:44.812: INFO: istio-init-crd-10-5dzhz from istio-system started at 2019-07-15 08:45:27 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container istio-init-crd-10 ready: false, restart count 0
Jul 15 13:38:44.812: INFO: fluent-bit-h2xsj from kubesphere-logging-system started at 2019-07-15 08:46:28 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container config-reloader ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container fluent-bit ready: true, restart count 0
Jul 15 13:38:44.812: INFO: prometheus-k8s-0 from kubesphere-monitoring-system started at 2019-07-15 08:46:41 +0000 UTC (3 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 13:38:44.812: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 13:38:44.812: INFO: elasticsearch-logging-discovery-0 from kubesphere-logging-system started at 2019-07-15 08:46:44 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container elasticsearch ready: true, restart count 0
Jul 15 13:38:44.812: INFO: istio-ingressgateway-5477b7ffd9-2qgx5 from istio-system started at 2019-07-15 08:49:35 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 13:38:44.812: INFO: openpitrix-minio-deployment-84d5f9c94b-ztlsm from openpitrix-system started at 2019-07-15 08:45:35 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container openpitrix-minio ready: true, restart count 0
Jul 15 13:38:44.812: INFO: elasticsearch-logging-data-1 from kubesphere-logging-system started at 2019-07-15 08:48:34 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container elasticsearch ready: true, restart count 0
Jul 15 13:38:44.812: INFO: istio-sidecar-injector-74666b458c-tvhwg from istio-system started at 2019-07-15 08:49:19 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container sidecar-injector-webhook ready: true, restart count 0
Jul 15 13:38:44.812: INFO: node-exporter-n94q2 from kubesphere-monitoring-system started at 2019-07-15 08:46:12 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container node-exporter ready: true, restart count 0
Jul 15 13:38:44.812: INFO: openpitrix-app-db-ctrl-job-jjvlr from openpitrix-system started at 2019-07-15 08:55:11 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container openpitrix-app-db-ctrl ready: false, restart count 0
Jul 15 13:38:44.812: INFO: kube-state-metrics-7f9c44c88-f27x7 from kubesphere-monitoring-system started at 2019-07-15 08:53:01 +0000 UTC (4 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container addon-resizer ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container kube-rbac-proxy-main ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container kube-rbac-proxy-self ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jul 15 13:38:44.812: INFO: csi-qingcloud-node-fvwds from kube-system started at 2019-07-15 08:42:32 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container csi-qingcloud ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container driver-registrar ready: true, restart count 0
Jul 15 13:38:44.812: INFO: metrics-server-85d786dd4d-lgw4d from kube-system started at 2019-07-15 08:45:40 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container metrics-server ready: true, restart count 0
Jul 15 13:38:44.812: INFO: notification-db-init-job-65tz2 from kubesphere-alerting-system started at 2019-07-15 08:55:23 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container notification-db-init ready: false, restart count 0
Jul 15 13:38:44.812: INFO: alerting-executor-75c664c66d-6mzjv from kubesphere-alerting-system started at 2019-07-15 08:48:45 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container alerting-adapter ready: true, restart count 0
Jul 15 13:38:44.812: INFO: 	Container alerting-executor ready: true, restart count 0
Jul 15 13:38:44.812: INFO: openpitrix-iam-db-ctrl-job-whtxp from openpitrix-system started at 2019-07-15 08:55:12 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container openpitrix-iam-db-ctrl ready: false, restart count 0
Jul 15 13:38:44.812: INFO: openpitrix-repo-db-ctrl-job-p6xkz from openpitrix-system started at 2019-07-15 08:55:13 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.812: INFO: 	Container openpitrix-repo-db-ctrl ready: false, restart count 0
Jul 15 13:38:44.812: INFO: ks-jenkins-887ddbbbc-5mwvc from kubesphere-devops-system started at 2019-07-15 08:55:59 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.813: INFO: 	Container ks-jenkins ready: true, restart count 0
Jul 15 13:38:44.813: INFO: kube-proxy-wfgmw from kube-system started at 2019-07-15 08:42:32 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.813: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 15 13:38:44.813: INFO: openpitrix-task-manager-deployment-5f8c7cdd64-96csg from openpitrix-system started at 2019-07-15 08:45:15 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.813: INFO: 	Container openpitrix-task-manager ready: true, restart count 0
Jul 15 13:38:44.813: INFO: prometheus-k8s-system-1 from kubesphere-monitoring-system started at 2019-07-15 08:46:42 +0000 UTC (3 container statuses recorded)
Jul 15 13:38:44.813: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 13:38:44.813: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 13:38:44.813: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 13:38:44.813: INFO: alerting-manager-67c5f9c797-tcglm from kubesphere-alerting-system started at 2019-07-15 08:48:46 +0000 UTC (1 container statuses recorded)
Jul 15 13:38:44.813: INFO: 	Container alerting-manager ready: true, restart count 0
Jul 15 13:38:44.813: INFO: istio-policy-b87497cf4-r6hq4 from istio-system started at 2019-07-15 08:49:19 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.813: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 13:38:44.813: INFO: 	Container mixer ready: true, restart count 2
Jul 15 13:38:44.813: INFO: sonobuoy-systemd-logs-daemon-set-3c9f017d4c504b82-hn592 from heptio-sonobuoy started at 2019-07-15 13:17:54 +0000 UTC (2 container statuses recorded)
Jul 15 13:38:44.813: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 15 13:38:44.813: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node i-tkuhh2hc
STEP: verifying the node has the label node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod sonobuoy requesting resource cpu=0m on Node i-tkuhh2hc
Jul 15 13:38:44.916: INFO: Pod sonobuoy-systemd-logs-daemon-set-3c9f017d4c504b82-9mlvz requesting resource cpu=0m on Node i-tkuhh2hc
Jul 15 13:38:44.916: INFO: Pod sonobuoy-systemd-logs-daemon-set-3c9f017d4c504b82-hn592 requesting resource cpu=0m on Node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod istio-citadel-5f886dc9b4-h94c9 requesting resource cpu=10m on Node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod istio-galley-689b548d98-jqjbz requesting resource cpu=10m on Node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod istio-galley-689b548d98-qkcjf requesting resource cpu=10m on Node i-tkuhh2hc
Jul 15 13:38:44.916: INFO: Pod istio-ingressgateway-5477b7ffd9-2qgx5 requesting resource cpu=10m on Node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod istio-ingressgateway-5477b7ffd9-lt2jc requesting resource cpu=10m on Node i-tkuhh2hc
Jul 15 13:38:44.916: INFO: Pod istio-pilot-9685dfc4b-jdn8c requesting resource cpu=600m on Node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod istio-pilot-9685dfc4b-n7ltn requesting resource cpu=600m on Node i-tkuhh2hc
Jul 15 13:38:44.916: INFO: Pod istio-policy-b87497cf4-n4n9m requesting resource cpu=110m on Node i-tkuhh2hc
Jul 15 13:38:44.916: INFO: Pod istio-policy-b87497cf4-r6hq4 requesting resource cpu=110m on Node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod istio-sidecar-injector-74666b458c-tvhwg requesting resource cpu=10m on Node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod istio-telemetry-758d9c786f-45wzg requesting resource cpu=600m on Node i-tkuhh2hc
Jul 15 13:38:44.916: INFO: Pod istio-telemetry-758d9c786f-ppdc7 requesting resource cpu=600m on Node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod jaeger-collector-7c567ccbbb-sl7ng requesting resource cpu=0m on Node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod jaeger-operator-8cb967c86-wjtqg requesting resource cpu=0m on Node i-tkuhh2hc
Jul 15 13:38:44.916: INFO: Pod jaeger-query-7764db45bb-926v6 requesting resource cpu=0m on Node i-tkuhh2hc
Jul 15 13:38:44.916: INFO: Pod calico-node-b8m4t requesting resource cpu=250m on Node i-tkuhh2hc
Jul 15 13:38:44.916: INFO: Pod calico-node-ssbj9 requesting resource cpu=250m on Node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod csi-qingcloud-node-76gtb requesting resource cpu=0m on Node i-tkuhh2hc
Jul 15 13:38:44.916: INFO: Pod csi-qingcloud-node-fvwds requesting resource cpu=0m on Node i-x8osldkx
Jul 15 13:38:44.916: INFO: Pod kube-proxy-dkcd8 requesting resource cpu=0m on Node i-tkuhh2hc
Jul 15 13:38:44.917: INFO: Pod kube-proxy-wfgmw requesting resource cpu=0m on Node i-x8osldkx
Jul 15 13:38:44.917: INFO: Pod metrics-server-85d786dd4d-lgw4d requesting resource cpu=0m on Node i-x8osldkx
Jul 15 13:38:44.917: INFO: Pod alerting-client-5bb5d87f65-6l8ng requesting resource cpu=10m on Node i-tkuhh2hc
Jul 15 13:38:44.917: INFO: Pod alerting-executor-75c664c66d-29hfc requesting resource cpu=20m on Node i-tkuhh2hc
Jul 15 13:38:44.917: INFO: Pod alerting-executor-75c664c66d-6mzjv requesting resource cpu=20m on Node i-x8osldkx
Jul 15 13:38:44.917: INFO: Pod alerting-manager-67c5f9c797-tcglm requesting resource cpu=10m on Node i-x8osldkx
Jul 15 13:38:44.917: INFO: Pod alerting-watcher-5d857d87db-zwvvf requesting resource cpu=10m on Node i-x8osldkx
Jul 15 13:38:44.917: INFO: Pod notification-deployment-6b78b697d7-r8cdn requesting resource cpu=10m on Node i-tkuhh2hc
Jul 15 13:38:44.917: INFO: Pod default-http-backend-96d94689d-bnkh7 requesting resource cpu=10m on Node i-tkuhh2hc
Jul 15 13:38:44.917: INFO: Pod kubectl-admin-d784b7777-9pzv2 requesting resource cpu=0m on Node i-tkuhh2hc
Jul 15 13:38:44.918: INFO: Pod ks-jenkins-887ddbbbc-5mwvc requesting resource cpu=200m on Node i-x8osldkx
Jul 15 13:38:44.918: INFO: Pod ks-sonarqube-postgresql-5d58f5574b-2bc4v requesting resource cpu=100m on Node i-x8osldkx
Jul 15 13:38:44.918: INFO: Pod ks-sonarqube-sonarqube-7b48f4c664-6zvz7 requesting resource cpu=0m on Node i-tkuhh2hc
Jul 15 13:38:44.918: INFO: Pod s2ioperator-0 requesting resource cpu=100m on Node i-x8osldkx
Jul 15 13:38:44.918: INFO: Pod uc-jenkins-update-center-598f8d6549-5898r requesting resource cpu=0m on Node i-tkuhh2hc
Jul 15 13:38:44.918: INFO: Pod elasticsearch-logging-data-0 requesting resource cpu=25m on Node i-tkuhh2hc
Jul 15 13:38:44.918: INFO: Pod elasticsearch-logging-data-1 requesting resource cpu=25m on Node i-x8osldkx
Jul 15 13:38:44.918: INFO: Pod elasticsearch-logging-discovery-0 requesting resource cpu=25m on Node i-x8osldkx
Jul 15 13:38:44.918: INFO: Pod fluent-bit-2xfkw requesting resource cpu=0m on Node i-tkuhh2hc
Jul 15 13:38:44.918: INFO: Pod fluent-bit-h2xsj requesting resource cpu=0m on Node i-x8osldkx
Jul 15 13:38:44.918: INFO: Pod logging-fluentbit-operator-77ff6dbc78-b5w67 requesting resource cpu=102m on Node i-tkuhh2hc
Jul 15 13:38:44.918: INFO: Pod kube-state-metrics-7f9c44c88-f27x7 requesting resource cpu=136m on Node i-x8osldkx
Jul 15 13:38:44.918: INFO: Pod node-exporter-f75fb requesting resource cpu=112m on Node i-tkuhh2hc
Jul 15 13:38:44.918: INFO: Pod node-exporter-n94q2 requesting resource cpu=112m on Node i-x8osldkx
Jul 15 13:38:44.918: INFO: Pod prometheus-k8s-0 requesting resource cpu=475m on Node i-x8osldkx
Jul 15 13:38:44.918: INFO: Pod prometheus-k8s-1 requesting resource cpu=475m on Node i-tkuhh2hc
Jul 15 13:38:44.918: INFO: Pod prometheus-k8s-system-0 requesting resource cpu=475m on Node i-tkuhh2hc
Jul 15 13:38:44.918: INFO: Pod prometheus-k8s-system-1 requesting resource cpu=475m on Node i-x8osldkx
Jul 15 13:38:44.918: INFO: Pod prometheus-operator-7d94949cf8-lzvm6 requesting resource cpu=100m on Node i-x8osldkx
Jul 15 13:38:44.918: INFO: Pod ks-docs-77c4796dc9-npkwv requesting resource cpu=10m on Node i-tkuhh2hc
Jul 15 13:38:44.919: INFO: Pod openpitrix-api-gateway-deployment-585678b9b8-nhzmn requesting resource cpu=100m on Node i-x8osldkx
Jul 15 13:38:44.919: INFO: Pod openpitrix-app-manager-deployment-77bf8749dc-wxxzl requesting resource cpu=100m on Node i-tkuhh2hc
Jul 15 13:38:44.919: INFO: Pod openpitrix-category-manager-deployment-bf4676856-6wfl6 requesting resource cpu=100m on Node i-tkuhh2hc
Jul 15 13:38:44.919: INFO: Pod openpitrix-cluster-manager-deployment-745b57798d-nhkq4 requesting resource cpu=100m on Node i-x8osldkx
Jul 15 13:38:44.920: INFO: Pod openpitrix-etcd-deployment-54bc9bb948-8qmxl requesting resource cpu=0m on Node i-tkuhh2hc
Jul 15 13:38:44.920: INFO: Pod openpitrix-iam-service-deployment-6bc78587f-bsxsl requesting resource cpu=100m on Node i-tkuhh2hc
Jul 15 13:38:44.920: INFO: Pod openpitrix-job-manager-deployment-577649544c-jwgvs requesting resource cpu=100m on Node i-x8osldkx
Jul 15 13:38:44.920: INFO: Pod openpitrix-minio-deployment-84d5f9c94b-ztlsm requesting resource cpu=0m on Node i-x8osldkx
Jul 15 13:38:44.920: INFO: Pod openpitrix-repo-indexer-deployment-d975ddff6-rqd88 requesting resource cpu=100m on Node i-tkuhh2hc
Jul 15 13:38:44.920: INFO: Pod openpitrix-repo-manager-deployment-85fcf79667-wx9bf requesting resource cpu=100m on Node i-tkuhh2hc
Jul 15 13:38:44.920: INFO: Pod openpitrix-runtime-manager-deployment-9c4bb7d5-tsz6x requesting resource cpu=100m on Node i-tkuhh2hc
Jul 15 13:38:44.920: INFO: Pod openpitrix-task-manager-deployment-5f8c7cdd64-96csg requesting resource cpu=100m on Node i-x8osldkx
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddca4d79-a705-11e9-afda-96f40a16177b.15b1983b05aea3ad], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-62tfp/filler-pod-ddca4d79-a705-11e9-afda-96f40a16177b to i-tkuhh2hc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddca4d79-a705-11e9-afda-96f40a16177b.15b1983b3be1961a], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddca4d79-a705-11e9-afda-96f40a16177b.15b1983b6ece495a], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddca4d79-a705-11e9-afda-96f40a16177b.15b1983b72399e30], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddca4d79-a705-11e9-afda-96f40a16177b.15b1983b87541630], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddcca735-a705-11e9-afda-96f40a16177b.15b1983b064d10b4], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-62tfp/filler-pod-ddcca735-a705-11e9-afda-96f40a16177b to i-x8osldkx]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddcca735-a705-11e9-afda-96f40a16177b.15b1983b4fed9cde], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddcca735-a705-11e9-afda-96f40a16177b.15b1983b53c25156], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ddcca735-a705-11e9-afda-96f40a16177b.15b1983b6cc07deb], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15b1983bf5713b7d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node i-tkuhh2hc
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node i-x8osldkx
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:38:50.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-62tfp" for this suite.
Jul 15 13:38:56.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:38:57.476: INFO: namespace: e2e-tests-sched-pred-62tfp, resource: bindings, ignored listing per whitelist
Jul 15 13:38:58.439: INFO: namespace e2e-tests-sched-pred-62tfp deletion completed in 8.422295365s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:13.775 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:38:58.449: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 13:38:58.611: INFO: (0) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.575822ms)
Jul 15 13:38:58.621: INFO: (1) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.883252ms)
Jul 15 13:38:58.628: INFO: (2) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.937705ms)
Jul 15 13:38:58.636: INFO: (3) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.832755ms)
Jul 15 13:38:58.639: INFO: (4) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.635348ms)
Jul 15 13:38:58.642: INFO: (5) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.986094ms)
Jul 15 13:38:58.646: INFO: (6) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.265413ms)
Jul 15 13:38:58.663: INFO: (7) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 17.57432ms)
Jul 15 13:38:58.667: INFO: (8) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.745212ms)
Jul 15 13:38:58.684: INFO: (9) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.582289ms)
Jul 15 13:38:58.690: INFO: (10) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.412659ms)
Jul 15 13:38:58.695: INFO: (11) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.113088ms)
Jul 15 13:38:58.703: INFO: (12) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.840268ms)
Jul 15 13:38:58.709: INFO: (13) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.678743ms)
Jul 15 13:38:58.714: INFO: (14) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.086213ms)
Jul 15 13:38:58.724: INFO: (15) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 10.122185ms)
Jul 15 13:38:58.733: INFO: (16) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.603846ms)
Jul 15 13:38:58.747: INFO: (17) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.451012ms)
Jul 15 13:38:58.760: INFO: (18) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.224351ms)
Jul 15 13:38:58.767: INFO: (19) /api/v1/nodes/i-tkuhh2hc:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.065083ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:38:58.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-mm8ps" for this suite.
Jul 15 13:39:04.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:39:04.868: INFO: namespace: e2e-tests-proxy-mm8ps, resource: bindings, ignored listing per whitelist
Jul 15 13:39:05.157: INFO: namespace e2e-tests-proxy-mm8ps deletion completed in 6.385256748s

• [SLOW TEST:6.709 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:39:05.159: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 13:39:05.246: INFO: Creating ReplicaSet my-hostname-basic-e9e7b346-a705-11e9-afda-96f40a16177b
Jul 15 13:39:05.258: INFO: Pod name my-hostname-basic-e9e7b346-a705-11e9-afda-96f40a16177b: Found 0 pods out of 1
Jul 15 13:39:10.262: INFO: Pod name my-hostname-basic-e9e7b346-a705-11e9-afda-96f40a16177b: Found 1 pods out of 1
Jul 15 13:39:10.262: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e9e7b346-a705-11e9-afda-96f40a16177b" is running
Jul 15 13:39:10.264: INFO: Pod "my-hostname-basic-e9e7b346-a705-11e9-afda-96f40a16177b-h9jx5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 13:39:05 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 13:39:09 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 13:39:09 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 13:39:05 +0000 UTC Reason: Message:}])
Jul 15 13:39:10.264: INFO: Trying to dial the pod
Jul 15 13:39:15.278: INFO: Controller my-hostname-basic-e9e7b346-a705-11e9-afda-96f40a16177b: Got expected result from replica 1 [my-hostname-basic-e9e7b346-a705-11e9-afda-96f40a16177b-h9jx5]: "my-hostname-basic-e9e7b346-a705-11e9-afda-96f40a16177b-h9jx5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:39:15.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-2p9cd" for this suite.
Jul 15 13:39:21.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:39:23.569: INFO: namespace: e2e-tests-replicaset-2p9cd, resource: bindings, ignored listing per whitelist
Jul 15 13:39:23.668: INFO: namespace e2e-tests-replicaset-2p9cd deletion completed in 8.385839257s

• [SLOW TEST:18.510 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:39:23.669: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 13:39:23.780: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4f2a328-a705-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-p9w4b" to be "success or failure"
Jul 15 13:39:23.786: INFO: Pod "downwardapi-volume-f4f2a328-a705-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043071ms
Jul 15 13:39:25.790: INFO: Pod "downwardapi-volume-f4f2a328-a705-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009351747s
Jul 15 13:39:27.794: INFO: Pod "downwardapi-volume-f4f2a328-a705-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013391709s
STEP: Saw pod success
Jul 15 13:39:27.794: INFO: Pod "downwardapi-volume-f4f2a328-a705-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:39:27.797: INFO: Trying to get logs from node i-tkuhh2hc pod downwardapi-volume-f4f2a328-a705-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 13:39:27.821: INFO: Waiting for pod downwardapi-volume-f4f2a328-a705-11e9-afda-96f40a16177b to disappear
Jul 15 13:39:27.824: INFO: Pod downwardapi-volume-f4f2a328-a705-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:39:27.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p9w4b" for this suite.
Jul 15 13:39:33.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:39:34.523: INFO: namespace: e2e-tests-projected-p9w4b, resource: bindings, ignored listing per whitelist
Jul 15 13:39:36.224: INFO: namespace e2e-tests-projected-p9w4b deletion completed in 8.387532937s

• [SLOW TEST:12.555 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:39:36.224: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-fc6e85f0-a705-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 13:39:36.343: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fc6f521f-a705-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-clxk9" to be "success or failure"
Jul 15 13:39:36.348: INFO: Pod "pod-projected-configmaps-fc6f521f-a705-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.228079ms
Jul 15 13:39:38.351: INFO: Pod "pod-projected-configmaps-fc6f521f-a705-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008263326s
STEP: Saw pod success
Jul 15 13:39:38.351: INFO: Pod "pod-projected-configmaps-fc6f521f-a705-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:39:38.353: INFO: Trying to get logs from node i-x8osldkx pod pod-projected-configmaps-fc6f521f-a705-11e9-afda-96f40a16177b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 13:39:38.381: INFO: Waiting for pod pod-projected-configmaps-fc6f521f-a705-11e9-afda-96f40a16177b to disappear
Jul 15 13:39:38.384: INFO: Pod pod-projected-configmaps-fc6f521f-a705-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:39:38.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-clxk9" for this suite.
Jul 15 13:39:44.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:39:45.826: INFO: namespace: e2e-tests-projected-clxk9, resource: bindings, ignored listing per whitelist
Jul 15 13:39:46.773: INFO: namespace e2e-tests-projected-clxk9 deletion completed in 8.386045632s

• [SLOW TEST:10.549 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:39:46.774: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-02b75ac7-a706-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 13:39:46.887: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-02b80e5f-a706-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-hkjhn" to be "success or failure"
Jul 15 13:39:46.895: INFO: Pod "pod-projected-secrets-02b80e5f-a706-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062132ms
Jul 15 13:39:48.898: INFO: Pod "pod-projected-secrets-02b80e5f-a706-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007391381s
STEP: Saw pod success
Jul 15 13:39:48.898: INFO: Pod "pod-projected-secrets-02b80e5f-a706-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:39:48.900: INFO: Trying to get logs from node i-x8osldkx pod pod-projected-secrets-02b80e5f-a706-11e9-afda-96f40a16177b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 15 13:39:48.920: INFO: Waiting for pod pod-projected-secrets-02b80e5f-a706-11e9-afda-96f40a16177b to disappear
Jul 15 13:39:48.922: INFO: Pod pod-projected-secrets-02b80e5f-a706-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:39:48.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hkjhn" for this suite.
Jul 15 13:39:54.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:39:56.334: INFO: namespace: e2e-tests-projected-hkjhn, resource: bindings, ignored listing per whitelist
Jul 15 13:39:57.304: INFO: namespace e2e-tests-projected-hkjhn deletion completed in 8.378336285s

• [SLOW TEST:10.530 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:39:57.304: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul 15 13:40:05.465: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:05.468: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:07.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:07.472: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:09.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:09.472: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:11.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:11.473: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:13.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:13.471: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:15.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:15.472: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:17.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:17.472: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:19.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:19.474: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:21.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:21.473: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:23.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:23.474: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:25.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:25.483: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:27.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:27.473: INFO: Pod pod-with-prestop-exec-hook still exists
Jul 15 13:40:29.468: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul 15 13:40:29.474: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:40:29.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bjzcf" for this suite.
Jul 15 13:40:51.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:40:53.181: INFO: namespace: e2e-tests-container-lifecycle-hook-bjzcf, resource: bindings, ignored listing per whitelist
Jul 15 13:40:53.881: INFO: namespace e2e-tests-container-lifecycle-hook-bjzcf deletion completed in 24.388198946s

• [SLOW TEST:56.576 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:40:53.881: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jul 15 13:40:53.970: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:40:58.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-qxtvx" for this suite.
Jul 15 13:41:04.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:41:04.321: INFO: namespace: e2e-tests-init-container-qxtvx, resource: bindings, ignored listing per whitelist
Jul 15 13:41:06.422: INFO: namespace e2e-tests-init-container-qxtvx deletion completed in 8.384711988s

• [SLOW TEST:12.541 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:41:06.427: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul 15 13:41:06.567: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:06.572: INFO: Number of nodes with available pods: 0
Jul 15 13:41:06.572: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:41:07.577: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:07.579: INFO: Number of nodes with available pods: 0
Jul 15 13:41:07.579: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:41:08.577: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:08.580: INFO: Number of nodes with available pods: 0
Jul 15 13:41:08.580: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:41:09.577: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:09.581: INFO: Number of nodes with available pods: 1
Jul 15 13:41:09.581: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:10.577: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:10.582: INFO: Number of nodes with available pods: 1
Jul 15 13:41:10.584: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:11.577: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:11.580: INFO: Number of nodes with available pods: 2
Jul 15 13:41:11.581: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jul 15 13:41:11.607: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:11.610: INFO: Number of nodes with available pods: 1
Jul 15 13:41:11.610: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:12.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:12.620: INFO: Number of nodes with available pods: 1
Jul 15 13:41:12.620: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:13.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:13.618: INFO: Number of nodes with available pods: 1
Jul 15 13:41:13.618: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:14.614: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:14.617: INFO: Number of nodes with available pods: 1
Jul 15 13:41:14.617: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:15.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:15.618: INFO: Number of nodes with available pods: 1
Jul 15 13:41:15.618: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:16.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:16.617: INFO: Number of nodes with available pods: 1
Jul 15 13:41:16.617: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:17.616: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:17.620: INFO: Number of nodes with available pods: 1
Jul 15 13:41:17.620: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:18.614: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:18.617: INFO: Number of nodes with available pods: 1
Jul 15 13:41:18.617: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:19.624: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:19.628: INFO: Number of nodes with available pods: 1
Jul 15 13:41:19.628: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:20.616: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:20.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:20.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:21.630: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:21.634: INFO: Number of nodes with available pods: 1
Jul 15 13:41:21.635: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:22.616: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:22.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:22.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:23.614: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:23.617: INFO: Number of nodes with available pods: 1
Jul 15 13:41:23.617: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:24.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:24.617: INFO: Number of nodes with available pods: 1
Jul 15 13:41:24.617: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:25.617: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:25.620: INFO: Number of nodes with available pods: 1
Jul 15 13:41:25.620: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:26.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:26.618: INFO: Number of nodes with available pods: 1
Jul 15 13:41:26.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:27.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:27.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:27.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:28.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:28.618: INFO: Number of nodes with available pods: 1
Jul 15 13:41:28.618: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:29.617: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:29.624: INFO: Number of nodes with available pods: 1
Jul 15 13:41:29.624: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:30.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:30.618: INFO: Number of nodes with available pods: 1
Jul 15 13:41:30.618: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:31.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:31.617: INFO: Number of nodes with available pods: 1
Jul 15 13:41:31.617: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:32.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:32.618: INFO: Number of nodes with available pods: 1
Jul 15 13:41:32.618: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:33.616: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:33.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:33.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:34.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:34.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:34.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:35.637: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:35.642: INFO: Number of nodes with available pods: 1
Jul 15 13:41:35.643: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:36.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:36.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:36.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:37.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:37.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:37.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:38.616: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:38.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:38.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:39.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:39.618: INFO: Number of nodes with available pods: 1
Jul 15 13:41:39.618: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:40.616: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:40.623: INFO: Number of nodes with available pods: 1
Jul 15 13:41:40.623: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:41.636: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:41.640: INFO: Number of nodes with available pods: 1
Jul 15 13:41:41.640: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:42.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:42.620: INFO: Number of nodes with available pods: 1
Jul 15 13:41:42.620: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:43.634: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:43.639: INFO: Number of nodes with available pods: 1
Jul 15 13:41:43.639: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:44.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:44.617: INFO: Number of nodes with available pods: 1
Jul 15 13:41:44.618: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:45.621: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:45.627: INFO: Number of nodes with available pods: 1
Jul 15 13:41:45.628: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:46.621: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:46.624: INFO: Number of nodes with available pods: 1
Jul 15 13:41:46.624: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:47.618: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:47.621: INFO: Number of nodes with available pods: 1
Jul 15 13:41:47.621: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:48.616: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:48.620: INFO: Number of nodes with available pods: 1
Jul 15 13:41:48.620: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:49.617: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:49.620: INFO: Number of nodes with available pods: 1
Jul 15 13:41:49.620: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:50.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:50.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:50.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:51.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:51.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:51.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:52.618: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:52.621: INFO: Number of nodes with available pods: 1
Jul 15 13:41:52.621: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:53.633: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:53.637: INFO: Number of nodes with available pods: 1
Jul 15 13:41:53.637: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:54.616: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:54.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:54.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:55.615: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:55.619: INFO: Number of nodes with available pods: 1
Jul 15 13:41:55.619: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:41:56.616: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:41:56.619: INFO: Number of nodes with available pods: 2
Jul 15 13:41:56.619: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-lz2nx, will wait for the garbage collector to delete the pods
Jul 15 13:41:56.691: INFO: Deleting DaemonSet.extensions daemon-set took: 17.694966ms
Jul 15 13:41:56.807: INFO: Terminating DaemonSet.extensions daemon-set pods took: 116.402579ms
Jul 15 13:42:33.612: INFO: Number of nodes with available pods: 0
Jul 15 13:42:33.612: INFO: Number of running nodes: 0, number of available pods: 0
Jul 15 13:42:33.618: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lz2nx/daemonsets","resourceVersion":"42586"},"items":null}

Jul 15 13:42:33.623: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lz2nx/pods","resourceVersion":"42586"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:42:33.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lz2nx" for this suite.
Jul 15 13:42:39.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:42:39.698: INFO: namespace: e2e-tests-daemonsets-lz2nx, resource: bindings, ignored listing per whitelist
Jul 15 13:42:42.040: INFO: namespace e2e-tests-daemonsets-lz2nx deletion completed in 8.401514436s

• [SLOW TEST:95.613 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:42:42.041: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul 15 13:42:42.195: INFO: Waiting up to 5m0s for pod "pod-6b3597a6-a706-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-lt5cq" to be "success or failure"
Jul 15 13:42:42.199: INFO: Pod "pod-6b3597a6-a706-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.390394ms
Jul 15 13:42:44.202: INFO: Pod "pod-6b3597a6-a706-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00644678s
Jul 15 13:42:46.206: INFO: Pod "pod-6b3597a6-a706-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010380802s
STEP: Saw pod success
Jul 15 13:42:46.206: INFO: Pod "pod-6b3597a6-a706-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:42:46.209: INFO: Trying to get logs from node i-tkuhh2hc pod pod-6b3597a6-a706-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 13:42:46.237: INFO: Waiting for pod pod-6b3597a6-a706-11e9-afda-96f40a16177b to disappear
Jul 15 13:42:46.240: INFO: Pod pod-6b3597a6-a706-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:42:46.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lt5cq" for this suite.
Jul 15 13:42:52.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:42:53.274: INFO: namespace: e2e-tests-emptydir-lt5cq, resource: bindings, ignored listing per whitelist
Jul 15 13:42:54.624: INFO: namespace e2e-tests-emptydir-lt5cq deletion completed in 8.378111911s

• [SLOW TEST:12.583 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:42:54.625: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jul 15 13:42:54.725: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-a,UID:72aee5e8-a706-11e9-8341-525422241ab4,ResourceVersion:42691,Generation:0,CreationTimestamp:2019-07-15 13:42:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 15 13:42:54.726: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-a,UID:72aee5e8-a706-11e9-8341-525422241ab4,ResourceVersion:42691,Generation:0,CreationTimestamp:2019-07-15 13:42:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jul 15 13:43:04.740: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-a,UID:72aee5e8-a706-11e9-8341-525422241ab4,ResourceVersion:42712,Generation:0,CreationTimestamp:2019-07-15 13:42:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul 15 13:43:04.744: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-a,UID:72aee5e8-a706-11e9-8341-525422241ab4,ResourceVersion:42712,Generation:0,CreationTimestamp:2019-07-15 13:42:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jul 15 13:43:14.753: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-a,UID:72aee5e8-a706-11e9-8341-525422241ab4,ResourceVersion:42732,Generation:0,CreationTimestamp:2019-07-15 13:42:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 15 13:43:14.754: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-a,UID:72aee5e8-a706-11e9-8341-525422241ab4,ResourceVersion:42732,Generation:0,CreationTimestamp:2019-07-15 13:42:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jul 15 13:43:24.760: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-a,UID:72aee5e8-a706-11e9-8341-525422241ab4,ResourceVersion:42752,Generation:0,CreationTimestamp:2019-07-15 13:42:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 15 13:43:24.760: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-a,UID:72aee5e8-a706-11e9-8341-525422241ab4,ResourceVersion:42752,Generation:0,CreationTimestamp:2019-07-15 13:42:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jul 15 13:43:34.774: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-b,UID:8a8d6e50-a706-11e9-8341-525422241ab4,ResourceVersion:42774,Generation:0,CreationTimestamp:2019-07-15 13:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 15 13:43:34.774: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-b,UID:8a8d6e50-a706-11e9-8341-525422241ab4,ResourceVersion:42774,Generation:0,CreationTimestamp:2019-07-15 13:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jul 15 13:43:44.781: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-b,UID:8a8d6e50-a706-11e9-8341-525422241ab4,ResourceVersion:42795,Generation:0,CreationTimestamp:2019-07-15 13:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 15 13:43:44.781: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-hj284,SelfLink:/api/v1/namespaces/e2e-tests-watch-hj284/configmaps/e2e-watch-test-configmap-b,UID:8a8d6e50-a706-11e9-8341-525422241ab4,ResourceVersion:42795,Generation:0,CreationTimestamp:2019-07-15 13:43:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:43:54.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-hj284" for this suite.
Jul 15 13:44:00.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:44:00.873: INFO: namespace: e2e-tests-watch-hj284, resource: bindings, ignored listing per whitelist
Jul 15 13:44:03.190: INFO: namespace e2e-tests-watch-hj284 deletion completed in 8.401083619s

• [SLOW TEST:68.565 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:44:03.192: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:44:07.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-6crbh" for this suite.
Jul 15 13:44:13.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:44:13.480: INFO: namespace: e2e-tests-kubelet-test-6crbh, resource: bindings, ignored listing per whitelist
Jul 15 13:44:15.744: INFO: namespace e2e-tests-kubelet-test-6crbh deletion completed in 8.381545434s

• [SLOW TEST:12.552 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:44:15.746: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jul 15 13:44:15.830: INFO: Waiting up to 5m0s for pod "var-expansion-a3061ddb-a706-11e9-afda-96f40a16177b" in namespace "e2e-tests-var-expansion-bspgw" to be "success or failure"
Jul 15 13:44:15.834: INFO: Pod "var-expansion-a3061ddb-a706-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050513ms
Jul 15 13:44:17.838: INFO: Pod "var-expansion-a3061ddb-a706-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007695747s
STEP: Saw pod success
Jul 15 13:44:17.838: INFO: Pod "var-expansion-a3061ddb-a706-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:44:17.840: INFO: Trying to get logs from node i-tkuhh2hc pod var-expansion-a3061ddb-a706-11e9-afda-96f40a16177b container dapi-container: <nil>
STEP: delete the pod
Jul 15 13:44:17.862: INFO: Waiting for pod var-expansion-a3061ddb-a706-11e9-afda-96f40a16177b to disappear
Jul 15 13:44:17.864: INFO: Pod var-expansion-a3061ddb-a706-11e9-afda-96f40a16177b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:44:17.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-bspgw" for this suite.
Jul 15 13:44:23.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:44:23.968: INFO: namespace: e2e-tests-var-expansion-bspgw, resource: bindings, ignored listing per whitelist
Jul 15 13:44:26.264: INFO: namespace e2e-tests-var-expansion-bspgw deletion completed in 8.39306444s

• [SLOW TEST:10.518 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:44:26.264: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-a94ef9e9-a706-11e9-afda-96f40a16177b
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-a94ef9e9-a706-11e9-afda-96f40a16177b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:44:32.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-plzb2" for this suite.
Jul 15 13:44:54.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:44:54.548: INFO: namespace: e2e-tests-configmap-plzb2, resource: bindings, ignored listing per whitelist
Jul 15 13:44:56.810: INFO: namespace e2e-tests-configmap-plzb2 deletion completed in 24.389576603s

• [SLOW TEST:30.546 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:44:56.811: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
Jul 15 13:45:00.963: INFO: error from create uninitialized namespace: <nil>
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:45:23.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-l79ch" for this suite.
Jul 15 13:45:29.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:45:30.738: INFO: namespace: e2e-tests-namespaces-l79ch, resource: bindings, ignored listing per whitelist
Jul 15 13:45:31.438: INFO: namespace e2e-tests-namespaces-l79ch deletion completed in 8.412689281s
STEP: Destroying namespace "e2e-tests-nsdeletetest-xc9xx" for this suite.
Jul 15 13:45:31.441: INFO: Namespace e2e-tests-nsdeletetest-xc9xx was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-cj28s" for this suite.
Jul 15 13:45:37.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:45:39.604: INFO: namespace: e2e-tests-nsdeletetest-cj28s, resource: bindings, ignored listing per whitelist
Jul 15 13:45:39.849: INFO: namespace e2e-tests-nsdeletetest-cj28s deletion completed in 8.407473057s

• [SLOW TEST:43.038 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:45:39.853: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jul 15 13:45:39.955: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jul 15 13:45:39.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:45:40.310: INFO: stderr: ""
Jul 15 13:45:40.310: INFO: stdout: "service/redis-slave created\n"
Jul 15 13:45:40.310: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jul 15 13:45:40.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:45:40.690: INFO: stderr: ""
Jul 15 13:45:40.690: INFO: stdout: "service/redis-master created\n"
Jul 15 13:45:40.690: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jul 15 13:45:40.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:45:41.020: INFO: stderr: ""
Jul 15 13:45:41.020: INFO: stdout: "service/frontend created\n"
Jul 15 13:45:41.020: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jul 15 13:45:41.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:45:41.343: INFO: stderr: ""
Jul 15 13:45:41.343: INFO: stdout: "deployment.extensions/frontend created\n"
Jul 15 13:45:41.357: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jul 15 13:45:41.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:45:41.713: INFO: stderr: ""
Jul 15 13:45:41.713: INFO: stdout: "deployment.extensions/redis-master created\n"
Jul 15 13:45:41.713: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jul 15 13:45:41.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:45:42.066: INFO: stderr: ""
Jul 15 13:45:42.066: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jul 15 13:45:42.066: INFO: Waiting for all frontend pods to be Running.
Jul 15 13:47:37.122: INFO: Waiting for frontend to serve content.
Jul 15 13:47:38.147: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jul 15 13:47:44.203: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jul 15 13:47:50.223: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jul 15 13:47:56.260: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jul 15 13:48:03.019: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jul 15 13:48:08.041: INFO: Trying to add a new entry to the guestbook.
Jul 15 13:48:08.059: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jul 15 13:48:08.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:48:08.478: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 13:48:08.479: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jul 15 13:48:08.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:48:08.659: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 13:48:08.659: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jul 15 13:48:08.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:48:08.805: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 13:48:08.805: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul 15 13:48:08.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:48:08.973: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 13:48:08.973: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul 15 13:48:08.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:48:09.131: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 13:48:09.131: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jul 15 13:48:09.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-brchz'
Jul 15 13:48:09.255: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 13:48:09.255: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:48:09.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-brchz" for this suite.
Jul 15 13:48:49.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:48:49.311: INFO: namespace: e2e-tests-kubectl-brchz, resource: bindings, ignored listing per whitelist
Jul 15 13:48:51.650: INFO: namespace e2e-tests-kubectl-brchz deletion completed in 42.389931795s

• [SLOW TEST:191.798 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:48:51.650: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jul 15 13:48:51.747: INFO: namespace e2e-tests-kubectl-hmlzl
Jul 15 13:48:51.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-hmlzl'
Jul 15 13:48:52.083: INFO: stderr: ""
Jul 15 13:48:52.083: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 15 13:48:53.089: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 13:48:53.089: INFO: Found 0 / 1
Jul 15 13:48:54.090: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 13:48:54.090: INFO: Found 0 / 1
Jul 15 13:48:55.088: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 13:48:55.088: INFO: Found 1 / 1
Jul 15 13:48:55.088: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 15 13:48:55.090: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 13:48:55.090: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 15 13:48:55.090: INFO: wait on redis-master startup in e2e-tests-kubectl-hmlzl 
Jul 15 13:48:55.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 logs redis-master-98zdm redis-master --namespace=e2e-tests-kubectl-hmlzl'
Jul 15 13:48:55.232: INFO: stderr: ""
Jul 15 13:48:55.232: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jul 13:48:53.274 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jul 13:48:53.274 # Server started, Redis version 3.2.12\n1:M 15 Jul 13:48:53.274 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jul 13:48:53.274 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jul 15 13:48:55.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-hmlzl'
Jul 15 13:48:55.383: INFO: stderr: ""
Jul 15 13:48:55.383: INFO: stdout: "service/rm2 exposed\n"
Jul 15 13:48:55.386: INFO: Service rm2 in namespace e2e-tests-kubectl-hmlzl found.
STEP: exposing service
Jul 15 13:48:57.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-hmlzl'
Jul 15 13:48:57.546: INFO: stderr: ""
Jul 15 13:48:57.546: INFO: stdout: "service/rm3 exposed\n"
Jul 15 13:48:57.549: INFO: Service rm3 in namespace e2e-tests-kubectl-hmlzl found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:48:59.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hmlzl" for this suite.
Jul 15 13:49:21.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:49:21.654: INFO: namespace: e2e-tests-kubectl-hmlzl, resource: bindings, ignored listing per whitelist
Jul 15 13:49:23.959: INFO: namespace e2e-tests-kubectl-hmlzl deletion completed in 24.402180399s

• [SLOW TEST:32.308 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:49:23.959: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-xnqhj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 15 13:49:24.073: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 15 13:49:48.139: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.10.2.79:8080/dial?request=hostName&protocol=http&host=10.10.2.78&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xnqhj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 13:49:48.139: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 13:49:48.328: INFO: Waiting for endpoints: map[]
Jul 15 13:49:48.330: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.10.2.79:8080/dial?request=hostName&protocol=http&host=10.10.1.80&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xnqhj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 13:49:48.330: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 13:49:48.528: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:49:48.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-xnqhj" for this suite.
Jul 15 13:50:10.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:50:11.982: INFO: namespace: e2e-tests-pod-network-test-xnqhj, resource: bindings, ignored listing per whitelist
Jul 15 13:50:12.932: INFO: namespace e2e-tests-pod-network-test-xnqhj deletion completed in 24.399527315s

• [SLOW TEST:48.973 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:50:12.933: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-77f14581-a707-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 13:50:13.055: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-77f1f140-a707-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-z8cxr" to be "success or failure"
Jul 15 13:50:13.057: INFO: Pod "pod-projected-secrets-77f1f140-a707-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.999467ms
Jul 15 13:50:15.061: INFO: Pod "pod-projected-secrets-77f1f140-a707-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005560642s
Jul 15 13:50:17.064: INFO: Pod "pod-projected-secrets-77f1f140-a707-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009073353s
STEP: Saw pod success
Jul 15 13:50:17.065: INFO: Pod "pod-projected-secrets-77f1f140-a707-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:50:17.067: INFO: Trying to get logs from node i-x8osldkx pod pod-projected-secrets-77f1f140-a707-11e9-afda-96f40a16177b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 15 13:50:17.097: INFO: Waiting for pod pod-projected-secrets-77f1f140-a707-11e9-afda-96f40a16177b to disappear
Jul 15 13:50:17.100: INFO: Pod pod-projected-secrets-77f1f140-a707-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:50:17.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z8cxr" for this suite.
Jul 15 13:50:23.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:50:23.135: INFO: namespace: e2e-tests-projected-z8cxr, resource: bindings, ignored listing per whitelist
Jul 15 13:50:25.488: INFO: namespace e2e-tests-projected-z8cxr deletion completed in 8.383501621s

• [SLOW TEST:12.556 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:50:25.490: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 13:50:25.602: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f6ab969-a707-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-v24ln" to be "success or failure"
Jul 15 13:50:25.604: INFO: Pod "downwardapi-volume-7f6ab969-a707-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.724793ms
Jul 15 13:50:27.607: INFO: Pod "downwardapi-volume-7f6ab969-a707-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004736398s
Jul 15 13:50:29.611: INFO: Pod "downwardapi-volume-7f6ab969-a707-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008693421s
STEP: Saw pod success
Jul 15 13:50:29.611: INFO: Pod "downwardapi-volume-7f6ab969-a707-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:50:29.613: INFO: Trying to get logs from node i-tkuhh2hc pod downwardapi-volume-7f6ab969-a707-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 13:50:29.632: INFO: Waiting for pod downwardapi-volume-7f6ab969-a707-11e9-afda-96f40a16177b to disappear
Jul 15 13:50:29.635: INFO: Pod downwardapi-volume-7f6ab969-a707-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:50:29.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v24ln" for this suite.
Jul 15 13:50:35.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:50:36.575: INFO: namespace: e2e-tests-projected-v24ln, resource: bindings, ignored listing per whitelist
Jul 15 13:50:38.025: INFO: namespace e2e-tests-projected-v24ln deletion completed in 8.386381347s

• [SLOW TEST:12.535 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:50:38.025: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-mxvkt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 15 13:50:38.134: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 15 13:51:04.214: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.10.2.82:8080/dial?request=hostName&protocol=udp&host=10.10.2.81&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-mxvkt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 13:51:04.214: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 13:51:04.439: INFO: Waiting for endpoints: map[]
Jul 15 13:51:04.443: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.10.2.82:8080/dial?request=hostName&protocol=udp&host=10.10.1.82&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-mxvkt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 13:51:04.443: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 13:51:04.712: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:51:04.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-mxvkt" for this suite.
Jul 15 13:51:28.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:51:28.755: INFO: namespace: e2e-tests-pod-network-test-mxvkt, resource: bindings, ignored listing per whitelist
Jul 15 13:51:31.104: INFO: namespace e2e-tests-pod-network-test-mxvkt deletion completed in 26.386298957s

• [SLOW TEST:53.079 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:51:31.106: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a6869ef8-a707-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 13:51:31.224: INFO: Waiting up to 5m0s for pod "pod-secrets-a6875036-a707-11e9-afda-96f40a16177b" in namespace "e2e-tests-secrets-fqzmq" to be "success or failure"
Jul 15 13:51:31.228: INFO: Pod "pod-secrets-a6875036-a707-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.563728ms
Jul 15 13:51:33.231: INFO: Pod "pod-secrets-a6875036-a707-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007436936s
Jul 15 13:51:35.235: INFO: Pod "pod-secrets-a6875036-a707-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010547447s
STEP: Saw pod success
Jul 15 13:51:35.235: INFO: Pod "pod-secrets-a6875036-a707-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:51:35.237: INFO: Trying to get logs from node i-x8osldkx pod pod-secrets-a6875036-a707-11e9-afda-96f40a16177b container secret-env-test: <nil>
STEP: delete the pod
Jul 15 13:51:35.260: INFO: Waiting for pod pod-secrets-a6875036-a707-11e9-afda-96f40a16177b to disappear
Jul 15 13:51:35.265: INFO: Pod pod-secrets-a6875036-a707-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:51:35.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fqzmq" for this suite.
Jul 15 13:51:41.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:51:43.203: INFO: namespace: e2e-tests-secrets-fqzmq, resource: bindings, ignored listing per whitelist
Jul 15 13:51:43.654: INFO: namespace e2e-tests-secrets-fqzmq deletion completed in 8.385912066s

• [SLOW TEST:12.548 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:51:43.654: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 13:51:43.742: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:51:45.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-v22mj" for this suite.
Jul 15 13:52:29.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:52:31.626: INFO: namespace: e2e-tests-pods-v22mj, resource: bindings, ignored listing per whitelist
Jul 15 13:52:32.326: INFO: namespace e2e-tests-pods-v22mj deletion completed in 46.381359209s

• [SLOW TEST:48.672 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:52:32.330: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-bfjf
STEP: Creating a pod to test atomic-volume-subpath
Jul 15 13:52:32.474: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-bfjf" in namespace "e2e-tests-subpath-xqgwb" to be "success or failure"
Jul 15 13:52:32.482: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.522321ms
Jul 15 13:52:34.486: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007410542s
Jul 15 13:52:36.490: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Running", Reason="", readiness=false. Elapsed: 4.01109126s
Jul 15 13:52:38.493: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Running", Reason="", readiness=false. Elapsed: 6.01457636s
Jul 15 13:52:40.498: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Running", Reason="", readiness=false. Elapsed: 8.01917292s
Jul 15 13:52:42.504: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Running", Reason="", readiness=false. Elapsed: 10.025832328s
Jul 15 13:52:44.508: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Running", Reason="", readiness=false. Elapsed: 12.029867195s
Jul 15 13:52:46.511: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Running", Reason="", readiness=false. Elapsed: 14.03289068s
Jul 15 13:52:48.525: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Running", Reason="", readiness=false. Elapsed: 16.046105473s
Jul 15 13:52:50.529: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Running", Reason="", readiness=false. Elapsed: 18.050358155s
Jul 15 13:52:52.532: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Running", Reason="", readiness=false. Elapsed: 20.053941349s
Jul 15 13:52:54.536: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Running", Reason="", readiness=false. Elapsed: 22.057489737s
Jul 15 13:52:56.539: INFO: Pod "pod-subpath-test-projected-bfjf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.060914502s
STEP: Saw pod success
Jul 15 13:52:56.539: INFO: Pod "pod-subpath-test-projected-bfjf" satisfied condition "success or failure"
Jul 15 13:52:56.541: INFO: Trying to get logs from node i-x8osldkx pod pod-subpath-test-projected-bfjf container test-container-subpath-projected-bfjf: <nil>
STEP: delete the pod
Jul 15 13:52:56.567: INFO: Waiting for pod pod-subpath-test-projected-bfjf to disappear
Jul 15 13:52:56.573: INFO: Pod pod-subpath-test-projected-bfjf no longer exists
STEP: Deleting pod pod-subpath-test-projected-bfjf
Jul 15 13:52:56.573: INFO: Deleting pod "pod-subpath-test-projected-bfjf" in namespace "e2e-tests-subpath-xqgwb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:52:56.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xqgwb" for this suite.
Jul 15 13:53:02.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:53:03.023: INFO: namespace: e2e-tests-subpath-xqgwb, resource: bindings, ignored listing per whitelist
Jul 15 13:53:04.974: INFO: namespace e2e-tests-subpath-xqgwb deletion completed in 8.392489536s

• [SLOW TEST:32.644 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:53:04.975: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jul 15 13:53:05.102: INFO: Waiting up to 5m0s for pod "client-containers-de7e902a-a707-11e9-afda-96f40a16177b" in namespace "e2e-tests-containers-qbnps" to be "success or failure"
Jul 15 13:53:05.106: INFO: Pod "client-containers-de7e902a-a707-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.080243ms
Jul 15 13:53:07.109: INFO: Pod "client-containers-de7e902a-a707-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006166631s
Jul 15 13:53:09.112: INFO: Pod "client-containers-de7e902a-a707-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009669119s
STEP: Saw pod success
Jul 15 13:53:09.113: INFO: Pod "client-containers-de7e902a-a707-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:53:09.115: INFO: Trying to get logs from node i-tkuhh2hc pod client-containers-de7e902a-a707-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 13:53:09.131: INFO: Waiting for pod client-containers-de7e902a-a707-11e9-afda-96f40a16177b to disappear
Jul 15 13:53:09.134: INFO: Pod client-containers-de7e902a-a707-11e9-afda-96f40a16177b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:53:09.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-qbnps" for this suite.
Jul 15 13:53:15.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:53:15.250: INFO: namespace: e2e-tests-containers-qbnps, resource: bindings, ignored listing per whitelist
Jul 15 13:53:17.524: INFO: namespace e2e-tests-containers-qbnps deletion completed in 8.386866293s

• [SLOW TEST:12.549 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:53:17.525: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jul 15 13:53:22.139: INFO: Successfully updated pod "annotationupdatee5f3a56f-a707-11e9-afda-96f40a16177b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:53:24.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vndfs" for this suite.
Jul 15 13:53:46.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:53:46.300: INFO: namespace: e2e-tests-projected-vndfs, resource: bindings, ignored listing per whitelist
Jul 15 13:53:48.558: INFO: namespace e2e-tests-projected-vndfs deletion completed in 24.38882115s

• [SLOW TEST:31.033 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:53:48.559: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jul 15 13:53:49.149: INFO: Waiting up to 5m0s for pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-zpxmp" in namespace "e2e-tests-svcaccounts-pzrn5" to be "success or failure"
Jul 15 13:53:49.157: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-zpxmp": Phase="Pending", Reason="", readiness=false. Elapsed: 7.824754ms
Jul 15 13:53:51.161: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-zpxmp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011889034s
Jul 15 13:53:53.164: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-zpxmp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014893546s
STEP: Saw pod success
Jul 15 13:53:53.164: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-zpxmp" satisfied condition "success or failure"
Jul 15 13:53:53.166: INFO: Trying to get logs from node i-tkuhh2hc pod pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-zpxmp container token-test: <nil>
STEP: delete the pod
Jul 15 13:53:53.185: INFO: Waiting for pod pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-zpxmp to disappear
Jul 15 13:53:53.188: INFO: Pod pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-zpxmp no longer exists
STEP: Creating a pod to test consume service account root CA
Jul 15 13:53:53.205: INFO: Waiting up to 5m0s for pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-lrppd" in namespace "e2e-tests-svcaccounts-pzrn5" to be "success or failure"
Jul 15 13:53:53.207: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-lrppd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.545524ms
Jul 15 13:53:55.211: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-lrppd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006077864s
Jul 15 13:53:57.215: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-lrppd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01006363s
STEP: Saw pod success
Jul 15 13:53:57.217: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-lrppd" satisfied condition "success or failure"
Jul 15 13:53:57.219: INFO: Trying to get logs from node i-x8osldkx pod pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-lrppd container root-ca-test: <nil>
STEP: delete the pod
Jul 15 13:53:57.239: INFO: Waiting for pod pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-lrppd to disappear
Jul 15 13:53:57.241: INFO: Pod pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-lrppd no longer exists
STEP: Creating a pod to test consume service account namespace
Jul 15 13:53:57.246: INFO: Waiting up to 5m0s for pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-grfdl" in namespace "e2e-tests-svcaccounts-pzrn5" to be "success or failure"
Jul 15 13:53:57.248: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-grfdl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.726759ms
Jul 15 13:53:59.251: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-grfdl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005569686s
Jul 15 13:54:01.255: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-grfdl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009578771s
STEP: Saw pod success
Jul 15 13:54:01.255: INFO: Pod "pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-grfdl" satisfied condition "success or failure"
Jul 15 13:54:01.258: INFO: Trying to get logs from node i-tkuhh2hc pod pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-grfdl container namespace-test: <nil>
STEP: delete the pod
Jul 15 13:54:01.282: INFO: Waiting for pod pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-grfdl to disappear
Jul 15 13:54:01.286: INFO: Pod pod-service-account-f8bf457f-a707-11e9-afda-96f40a16177b-grfdl no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:54:01.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-pzrn5" for this suite.
Jul 15 13:54:07.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:54:07.408: INFO: namespace: e2e-tests-svcaccounts-pzrn5, resource: bindings, ignored listing per whitelist
Jul 15 13:54:09.686: INFO: namespace e2e-tests-svcaccounts-pzrn5 deletion completed in 8.390045008s

• [SLOW TEST:21.128 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:54:09.687: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-050cef46-a708-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 13:54:09.792: INFO: Waiting up to 5m0s for pod "pod-configmaps-050d8058-a708-11e9-afda-96f40a16177b" in namespace "e2e-tests-configmap-hvhbn" to be "success or failure"
Jul 15 13:54:09.794: INFO: Pod "pod-configmaps-050d8058-a708-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.794128ms
Jul 15 13:54:11.796: INFO: Pod "pod-configmaps-050d8058-a708-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00458292s
Jul 15 13:54:13.799: INFO: Pod "pod-configmaps-050d8058-a708-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007376108s
STEP: Saw pod success
Jul 15 13:54:13.799: INFO: Pod "pod-configmaps-050d8058-a708-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:54:13.802: INFO: Trying to get logs from node i-x8osldkx pod pod-configmaps-050d8058-a708-11e9-afda-96f40a16177b container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 13:54:13.821: INFO: Waiting for pod pod-configmaps-050d8058-a708-11e9-afda-96f40a16177b to disappear
Jul 15 13:54:13.824: INFO: Pod pod-configmaps-050d8058-a708-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:54:13.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hvhbn" for this suite.
Jul 15 13:54:19.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:54:19.896: INFO: namespace: e2e-tests-configmap-hvhbn, resource: bindings, ignored listing per whitelist
Jul 15 13:54:22.212: INFO: namespace e2e-tests-configmap-hvhbn deletion completed in 8.384428639s

• [SLOW TEST:12.525 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:54:22.213: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jul 15 13:54:22.825: INFO: created pod pod-service-account-defaultsa
Jul 15 13:54:22.825: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jul 15 13:54:22.836: INFO: created pod pod-service-account-mountsa
Jul 15 13:54:22.836: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jul 15 13:54:22.857: INFO: created pod pod-service-account-nomountsa
Jul 15 13:54:22.857: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jul 15 13:54:22.868: INFO: created pod pod-service-account-defaultsa-mountspec
Jul 15 13:54:22.868: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jul 15 13:54:22.897: INFO: created pod pod-service-account-mountsa-mountspec
Jul 15 13:54:22.897: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jul 15 13:54:22.910: INFO: created pod pod-service-account-nomountsa-mountspec
Jul 15 13:54:22.910: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jul 15 13:54:22.923: INFO: created pod pod-service-account-defaultsa-nomountspec
Jul 15 13:54:22.923: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jul 15 13:54:22.929: INFO: created pod pod-service-account-mountsa-nomountspec
Jul 15 13:54:22.929: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jul 15 13:54:22.938: INFO: created pod pod-service-account-nomountsa-nomountspec
Jul 15 13:54:22.938: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:54:22.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-hp4xn" for this suite.
Jul 15 13:54:28.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:54:30.070: INFO: namespace: e2e-tests-svcaccounts-hp4xn, resource: bindings, ignored listing per whitelist
Jul 15 13:54:31.321: INFO: namespace e2e-tests-svcaccounts-hp4xn deletion completed in 8.378015733s

• [SLOW TEST:9.108 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:54:31.322: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul 15 13:54:31.440: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:54:31.446: INFO: Number of nodes with available pods: 0
Jul 15 13:54:31.446: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:54:32.452: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:54:32.456: INFO: Number of nodes with available pods: 0
Jul 15 13:54:32.456: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:54:33.453: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:54:33.458: INFO: Number of nodes with available pods: 1
Jul 15 13:54:33.459: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 13:54:34.451: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:54:34.454: INFO: Number of nodes with available pods: 2
Jul 15 13:54:34.454: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jul 15 13:54:34.468: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 13:54:34.479: INFO: Number of nodes with available pods: 2
Jul 15 13:54:34.479: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-59qst, will wait for the garbage collector to delete the pods
Jul 15 13:54:34.573: INFO: Deleting DaemonSet.extensions daemon-set took: 5.371427ms
Jul 15 13:54:34.673: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.249593ms
Jul 15 13:55:17.978: INFO: Number of nodes with available pods: 0
Jul 15 13:55:17.978: INFO: Number of running nodes: 0, number of available pods: 0
Jul 15 13:55:17.980: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-59qst/daemonsets","resourceVersion":"45285"},"items":null}

Jul 15 13:55:17.982: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-59qst/pods","resourceVersion":"45285"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:55:17.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-59qst" for this suite.
Jul 15 13:55:24.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:55:24.779: INFO: namespace: e2e-tests-daemonsets-59qst, resource: bindings, ignored listing per whitelist
Jul 15 13:55:26.378: INFO: namespace e2e-tests-daemonsets-59qst deletion completed in 8.381059045s

• [SLOW TEST:55.057 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:55:26.380: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0715 13:55:36.548411      22 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 13:55:36.548: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:55:36.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-v8997" for this suite.
Jul 15 13:55:42.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:55:42.667: INFO: namespace: e2e-tests-gc-v8997, resource: bindings, ignored listing per whitelist
Jul 15 13:55:44.998: INFO: namespace e2e-tests-gc-v8997 deletion completed in 8.445681965s

• [SLOW TEST:18.619 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:55:44.999: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul 15 13:55:45.093: INFO: Waiting up to 5m0s for pod "pod-3ddb92f4-a708-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-44tq6" to be "success or failure"
Jul 15 13:55:45.096: INFO: Pod "pod-3ddb92f4-a708-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.455451ms
Jul 15 13:55:47.099: INFO: Pod "pod-3ddb92f4-a708-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005519073s
Jul 15 13:55:49.102: INFO: Pod "pod-3ddb92f4-a708-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00858464s
STEP: Saw pod success
Jul 15 13:55:49.102: INFO: Pod "pod-3ddb92f4-a708-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:55:49.104: INFO: Trying to get logs from node i-x8osldkx pod pod-3ddb92f4-a708-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 13:55:49.131: INFO: Waiting for pod pod-3ddb92f4-a708-11e9-afda-96f40a16177b to disappear
Jul 15 13:55:49.133: INFO: Pod pod-3ddb92f4-a708-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:55:49.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-44tq6" for this suite.
Jul 15 13:55:55.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:55:56.873: INFO: namespace: e2e-tests-emptydir-44tq6, resource: bindings, ignored listing per whitelist
Jul 15 13:55:57.524: INFO: namespace e2e-tests-emptydir-44tq6 deletion completed in 8.388083881s

• [SLOW TEST:12.525 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:55:57.524: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jul 15 13:55:57.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-sl8x9'
Jul 15 13:55:57.867: INFO: stderr: ""
Jul 15 13:55:57.867: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 13:55:57.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sl8x9'
Jul 15 13:55:57.992: INFO: stderr: ""
Jul 15 13:55:57.992: INFO: stdout: "update-demo-nautilus-djlbx update-demo-nautilus-lz6vg "
Jul 15 13:55:57.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-djlbx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sl8x9'
Jul 15 13:55:58.121: INFO: stderr: ""
Jul 15 13:55:58.121: INFO: stdout: ""
Jul 15 13:55:58.121: INFO: update-demo-nautilus-djlbx is created but not running
Jul 15 13:56:03.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sl8x9'
Jul 15 13:56:03.258: INFO: stderr: ""
Jul 15 13:56:03.258: INFO: stdout: "update-demo-nautilus-djlbx update-demo-nautilus-lz6vg "
Jul 15 13:56:03.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-djlbx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sl8x9'
Jul 15 13:56:03.367: INFO: stderr: ""
Jul 15 13:56:03.367: INFO: stdout: "true"
Jul 15 13:56:03.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-djlbx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sl8x9'
Jul 15 13:56:03.492: INFO: stderr: ""
Jul 15 13:56:03.492: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 13:56:03.492: INFO: validating pod update-demo-nautilus-djlbx
Jul 15 13:56:03.500: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 13:56:03.500: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 13:56:03.500: INFO: update-demo-nautilus-djlbx is verified up and running
Jul 15 13:56:03.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-lz6vg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sl8x9'
Jul 15 13:56:03.625: INFO: stderr: ""
Jul 15 13:56:03.625: INFO: stdout: "true"
Jul 15 13:56:03.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-lz6vg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sl8x9'
Jul 15 13:56:03.750: INFO: stderr: ""
Jul 15 13:56:03.750: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 13:56:03.750: INFO: validating pod update-demo-nautilus-lz6vg
Jul 15 13:56:03.756: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 13:56:03.756: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 13:56:03.756: INFO: update-demo-nautilus-lz6vg is verified up and running
STEP: using delete to clean up resources
Jul 15 13:56:03.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sl8x9'
Jul 15 13:56:03.877: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 13:56:03.877: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 15 13:56:03.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-sl8x9'
Jul 15 13:56:03.983: INFO: stderr: "No resources found.\n"
Jul 15 13:56:03.983: INFO: stdout: ""
Jul 15 13:56:03.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -l name=update-demo --namespace=e2e-tests-kubectl-sl8x9 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 15 13:56:04.101: INFO: stderr: ""
Jul 15 13:56:04.101: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:56:04.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sl8x9" for this suite.
Jul 15 13:56:10.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:56:11.945: INFO: namespace: e2e-tests-kubectl-sl8x9, resource: bindings, ignored listing per whitelist
Jul 15 13:56:12.507: INFO: namespace e2e-tests-kubectl-sl8x9 deletion completed in 8.401463478s

• [SLOW TEST:14.983 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:56:12.510: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:56:12.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-tp7jj" for this suite.
Jul 15 13:56:34.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:56:34.751: INFO: namespace: e2e-tests-kubelet-test-tp7jj, resource: bindings, ignored listing per whitelist
Jul 15 13:56:37.055: INFO: namespace e2e-tests-kubelet-test-tp7jj deletion completed in 24.38536352s

• [SLOW TEST:24.545 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:56:37.058: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0715 13:56:43.202044      22 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 13:56:43.202: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:56:43.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mt88p" for this suite.
Jul 15 13:56:49.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:56:49.258: INFO: namespace: e2e-tests-gc-mt88p, resource: bindings, ignored listing per whitelist
Jul 15 13:56:51.592: INFO: namespace e2e-tests-gc-mt88p deletion completed in 8.385651156s

• [SLOW TEST:14.534 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:56:51.592: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jul 15 13:56:51.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 cluster-info'
Jul 15 13:56:51.807: INFO: stderr: ""
Jul 15 13:56:51.807: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:56:51.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t8v64" for this suite.
Jul 15 13:56:57.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:56:57.848: INFO: namespace: e2e-tests-kubectl-t8v64, resource: bindings, ignored listing per whitelist
Jul 15 13:57:00.194: INFO: namespace e2e-tests-kubectl-t8v64 deletion completed in 8.382168599s

• [SLOW TEST:8.602 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:57:00.194: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-6ab140d4-a708-11e9-afda-96f40a16177b
STEP: Creating configMap with name cm-test-opt-upd-6ab1412e-a708-11e9-afda-96f40a16177b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-6ab140d4-a708-11e9-afda-96f40a16177b
STEP: Updating configmap cm-test-opt-upd-6ab1412e-a708-11e9-afda-96f40a16177b
STEP: Creating configMap with name cm-test-opt-create-6ab14158-a708-11e9-afda-96f40a16177b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:57:06.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xs8mx" for this suite.
Jul 15 13:57:28.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:57:28.608: INFO: namespace: e2e-tests-projected-xs8mx, resource: bindings, ignored listing per whitelist
Jul 15 13:57:30.875: INFO: namespace e2e-tests-projected-xs8mx deletion completed in 24.408656412s

• [SLOW TEST:30.681 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:57:30.876: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-zr4q
STEP: Creating a pod to test atomic-volume-subpath
Jul 15 13:57:31.035: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-zr4q" in namespace "e2e-tests-subpath-8kmsb" to be "success or failure"
Jul 15 13:57:31.044: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Pending", Reason="", readiness=false. Elapsed: 8.878795ms
Jul 15 13:57:33.047: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012021818s
Jul 15 13:57:35.052: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Running", Reason="", readiness=false. Elapsed: 4.017560585s
Jul 15 13:57:37.055: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Running", Reason="", readiness=false. Elapsed: 6.020061704s
Jul 15 13:57:39.058: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Running", Reason="", readiness=false. Elapsed: 8.023141646s
Jul 15 13:57:41.061: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Running", Reason="", readiness=false. Elapsed: 10.026386286s
Jul 15 13:57:43.064: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Running", Reason="", readiness=false. Elapsed: 12.029548701s
Jul 15 13:57:45.070: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Running", Reason="", readiness=false. Elapsed: 14.03511422s
Jul 15 13:57:47.074: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Running", Reason="", readiness=false. Elapsed: 16.03965353s
Jul 15 13:57:49.078: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Running", Reason="", readiness=false. Elapsed: 18.043524026s
Jul 15 13:57:51.083: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Running", Reason="", readiness=false. Elapsed: 20.04810494s
Jul 15 13:57:53.096: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Running", Reason="", readiness=false. Elapsed: 22.061021043s
Jul 15 13:57:55.100: INFO: Pod "pod-subpath-test-configmap-zr4q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.065177867s
STEP: Saw pod success
Jul 15 13:57:55.100: INFO: Pod "pod-subpath-test-configmap-zr4q" satisfied condition "success or failure"
Jul 15 13:57:55.103: INFO: Trying to get logs from node i-tkuhh2hc pod pod-subpath-test-configmap-zr4q container test-container-subpath-configmap-zr4q: <nil>
STEP: delete the pod
Jul 15 13:57:55.131: INFO: Waiting for pod pod-subpath-test-configmap-zr4q to disappear
Jul 15 13:57:55.134: INFO: Pod pod-subpath-test-configmap-zr4q no longer exists
STEP: Deleting pod pod-subpath-test-configmap-zr4q
Jul 15 13:57:55.134: INFO: Deleting pod "pod-subpath-test-configmap-zr4q" in namespace "e2e-tests-subpath-8kmsb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:57:55.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8kmsb" for this suite.
Jul 15 13:58:01.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:58:01.242: INFO: namespace: e2e-tests-subpath-8kmsb, resource: bindings, ignored listing per whitelist
Jul 15 13:58:03.557: INFO: namespace e2e-tests-subpath-8kmsb deletion completed in 8.4106404s

• [SLOW TEST:32.681 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:58:03.559: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 13:58:03.691: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jul 15 13:58:03.702: INFO: Number of nodes with available pods: 0
Jul 15 13:58:03.702: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jul 15 13:58:03.743: INFO: Number of nodes with available pods: 0
Jul 15 13:58:03.743: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:04.749: INFO: Number of nodes with available pods: 0
Jul 15 13:58:04.749: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:05.749: INFO: Number of nodes with available pods: 1
Jul 15 13:58:05.749: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jul 15 13:58:05.789: INFO: Number of nodes with available pods: 0
Jul 15 13:58:05.789: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jul 15 13:58:05.806: INFO: Number of nodes with available pods: 0
Jul 15 13:58:05.806: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:06.809: INFO: Number of nodes with available pods: 0
Jul 15 13:58:06.809: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:07.809: INFO: Number of nodes with available pods: 0
Jul 15 13:58:07.809: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:08.812: INFO: Number of nodes with available pods: 0
Jul 15 13:58:08.812: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:09.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:09.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:10.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:10.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:11.809: INFO: Number of nodes with available pods: 0
Jul 15 13:58:11.809: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:12.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:12.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:13.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:13.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:14.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:14.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:15.813: INFO: Number of nodes with available pods: 0
Jul 15 13:58:15.813: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:16.809: INFO: Number of nodes with available pods: 0
Jul 15 13:58:16.809: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:17.812: INFO: Number of nodes with available pods: 0
Jul 15 13:58:17.812: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:18.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:18.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:19.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:19.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:20.809: INFO: Number of nodes with available pods: 0
Jul 15 13:58:20.809: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:21.809: INFO: Number of nodes with available pods: 0
Jul 15 13:58:21.809: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:22.812: INFO: Number of nodes with available pods: 0
Jul 15 13:58:22.812: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:23.809: INFO: Number of nodes with available pods: 0
Jul 15 13:58:23.809: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:24.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:24.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:25.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:25.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:26.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:26.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:27.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:27.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:28.813: INFO: Number of nodes with available pods: 0
Jul 15 13:58:28.813: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:29.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:29.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:30.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:30.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:31.809: INFO: Number of nodes with available pods: 0
Jul 15 13:58:31.809: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:32.811: INFO: Number of nodes with available pods: 0
Jul 15 13:58:32.811: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:33.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:33.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:34.809: INFO: Number of nodes with available pods: 0
Jul 15 13:58:34.809: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:35.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:35.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:36.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:36.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:37.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:37.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:38.809: INFO: Number of nodes with available pods: 0
Jul 15 13:58:38.809: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:39.809: INFO: Number of nodes with available pods: 0
Jul 15 13:58:39.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:40.810: INFO: Number of nodes with available pods: 0
Jul 15 13:58:40.810: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:41.813: INFO: Number of nodes with available pods: 0
Jul 15 13:58:41.813: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 13:58:42.814: INFO: Number of nodes with available pods: 1
Jul 15 13:58:42.814: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-h6qsf, will wait for the garbage collector to delete the pods
Jul 15 13:58:42.881: INFO: Deleting DaemonSet.extensions daemon-set took: 8.014729ms
Jul 15 13:58:42.983: INFO: Terminating DaemonSet.extensions daemon-set pods took: 102.267869ms
Jul 15 13:59:27.986: INFO: Number of nodes with available pods: 0
Jul 15 13:59:27.986: INFO: Number of running nodes: 0, number of available pods: 0
Jul 15 13:59:27.988: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-h6qsf/daemonsets","resourceVersion":"46537"},"items":null}

Jul 15 13:59:27.990: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-h6qsf/pods","resourceVersion":"46537"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:59:28.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-h6qsf" for this suite.
Jul 15 13:59:34.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:59:34.089: INFO: namespace: e2e-tests-daemonsets-h6qsf, resource: bindings, ignored listing per whitelist
Jul 15 13:59:36.436: INFO: namespace e2e-tests-daemonsets-h6qsf deletion completed in 8.41389808s

• [SLOW TEST:92.877 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:59:36.437: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 13:59:36.556: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c7d0949b-a708-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-2whlq" to be "success or failure"
Jul 15 13:59:36.558: INFO: Pod "downwardapi-volume-c7d0949b-a708-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.22975ms
Jul 15 13:59:38.562: INFO: Pod "downwardapi-volume-c7d0949b-a708-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005905543s
Jul 15 13:59:40.565: INFO: Pod "downwardapi-volume-c7d0949b-a708-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009217185s
STEP: Saw pod success
Jul 15 13:59:40.565: INFO: Pod "downwardapi-volume-c7d0949b-a708-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 13:59:40.567: INFO: Trying to get logs from node i-x8osldkx pod downwardapi-volume-c7d0949b-a708-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 13:59:40.592: INFO: Waiting for pod downwardapi-volume-c7d0949b-a708-11e9-afda-96f40a16177b to disappear
Jul 15 13:59:40.594: INFO: Pod downwardapi-volume-c7d0949b-a708-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:59:40.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2whlq" for this suite.
Jul 15 13:59:46.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 13:59:47.227: INFO: namespace: e2e-tests-projected-2whlq, resource: bindings, ignored listing per whitelist
Jul 15 13:59:48.977: INFO: namespace e2e-tests-projected-2whlq deletion completed in 8.378928902s

• [SLOW TEST:12.540 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 13:59:48.978: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0715 13:59:59.071611      22 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 13:59:59.071: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 13:59:59.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-n2gn6" for this suite.
Jul 15 14:00:05.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:00:06.623: INFO: namespace: e2e-tests-gc-n2gn6, resource: bindings, ignored listing per whitelist
Jul 15 14:00:07.473: INFO: namespace e2e-tests-gc-n2gn6 deletion completed in 8.396899527s

• [SLOW TEST:18.494 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:00:07.473: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-da5368e0-a708-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 14:00:07.611: INFO: Waiting up to 5m0s for pod "pod-secrets-da53fad2-a708-11e9-afda-96f40a16177b" in namespace "e2e-tests-secrets-kkm7n" to be "success or failure"
Jul 15 14:00:07.632: INFO: Pod "pod-secrets-da53fad2-a708-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 21.271ms
Jul 15 14:00:09.640: INFO: Pod "pod-secrets-da53fad2-a708-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029306111s
STEP: Saw pod success
Jul 15 14:00:09.640: INFO: Pod "pod-secrets-da53fad2-a708-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:00:09.648: INFO: Trying to get logs from node i-tkuhh2hc pod pod-secrets-da53fad2-a708-11e9-afda-96f40a16177b container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 14:00:09.672: INFO: Waiting for pod pod-secrets-da53fad2-a708-11e9-afda-96f40a16177b to disappear
Jul 15 14:00:09.680: INFO: Pod pod-secrets-da53fad2-a708-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:00:09.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kkm7n" for this suite.
Jul 15 14:00:15.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:00:17.386: INFO: namespace: e2e-tests-secrets-kkm7n, resource: bindings, ignored listing per whitelist
Jul 15 14:00:18.082: INFO: namespace e2e-tests-secrets-kkm7n deletion completed in 8.394923931s

• [SLOW TEST:10.610 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:00:18.083: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jul 15 14:00:18.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-kjqst'
Jul 15 14:00:18.917: INFO: stderr: ""
Jul 15 14:00:18.917: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 15 14:00:19.921: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:00:19.921: INFO: Found 0 / 1
Jul 15 14:00:20.921: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:00:20.921: INFO: Found 0 / 1
Jul 15 14:00:21.920: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:00:21.920: INFO: Found 0 / 1
Jul 15 14:00:22.921: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:00:22.921: INFO: Found 0 / 1
Jul 15 14:00:23.920: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:00:23.920: INFO: Found 1 / 1
Jul 15 14:00:23.920: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jul 15 14:00:23.923: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:00:23.923: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 15 14:00:23.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 patch pod redis-master-pqd8p --namespace=e2e-tests-kubectl-kjqst -p {"metadata":{"annotations":{"x":"y"}}}'
Jul 15 14:00:24.074: INFO: stderr: ""
Jul 15 14:00:24.074: INFO: stdout: "pod/redis-master-pqd8p patched\n"
STEP: checking annotations
Jul 15 14:00:24.078: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:00:24.079: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:00:24.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kjqst" for this suite.
Jul 15 14:00:46.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:00:46.189: INFO: namespace: e2e-tests-kubectl-kjqst, resource: bindings, ignored listing per whitelist
Jul 15 14:00:48.480: INFO: namespace e2e-tests-kubectl-kjqst deletion completed in 24.383091299s

• [SLOW TEST:30.397 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:00:48.481: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jul 15 14:00:48.606: INFO: Waiting up to 5m0s for pod "client-containers-f2c3a9be-a708-11e9-afda-96f40a16177b" in namespace "e2e-tests-containers-8zj6n" to be "success or failure"
Jul 15 14:00:48.608: INFO: Pod "client-containers-f2c3a9be-a708-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.277826ms
Jul 15 14:00:50.612: INFO: Pod "client-containers-f2c3a9be-a708-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006024999s
STEP: Saw pod success
Jul 15 14:00:50.612: INFO: Pod "client-containers-f2c3a9be-a708-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:00:50.614: INFO: Trying to get logs from node i-tkuhh2hc pod client-containers-f2c3a9be-a708-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 14:00:50.634: INFO: Waiting for pod client-containers-f2c3a9be-a708-11e9-afda-96f40a16177b to disappear
Jul 15 14:00:50.637: INFO: Pod client-containers-f2c3a9be-a708-11e9-afda-96f40a16177b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:00:50.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8zj6n" for this suite.
Jul 15 14:00:56.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:00:56.720: INFO: namespace: e2e-tests-containers-8zj6n, resource: bindings, ignored listing per whitelist
Jul 15 14:00:59.037: INFO: namespace e2e-tests-containers-8zj6n deletion completed in 8.39061678s

• [SLOW TEST:10.557 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:00:59.038: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f90a8b70-a708-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 14:00:59.140: INFO: Waiting up to 5m0s for pod "pod-secrets-f90afdf2-a708-11e9-afda-96f40a16177b" in namespace "e2e-tests-secrets-rgxq5" to be "success or failure"
Jul 15 14:00:59.147: INFO: Pod "pod-secrets-f90afdf2-a708-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.291529ms
Jul 15 14:01:01.160: INFO: Pod "pod-secrets-f90afdf2-a708-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02039714s
STEP: Saw pod success
Jul 15 14:01:01.161: INFO: Pod "pod-secrets-f90afdf2-a708-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:01:01.164: INFO: Trying to get logs from node i-x8osldkx pod pod-secrets-f90afdf2-a708-11e9-afda-96f40a16177b container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 14:01:01.193: INFO: Waiting for pod pod-secrets-f90afdf2-a708-11e9-afda-96f40a16177b to disappear
Jul 15 14:01:01.197: INFO: Pod pod-secrets-f90afdf2-a708-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:01:01.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rgxq5" for this suite.
Jul 15 14:01:07.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:01:07.266: INFO: namespace: e2e-tests-secrets-rgxq5, resource: bindings, ignored listing per whitelist
Jul 15 14:01:09.605: INFO: namespace e2e-tests-secrets-rgxq5 deletion completed in 8.399314359s

• [SLOW TEST:10.568 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:01:09.609: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-ff5d31a3-a708-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 14:01:09.749: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ff5dba75-a708-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-r7b6p" to be "success or failure"
Jul 15 14:01:09.759: INFO: Pod "pod-projected-secrets-ff5dba75-a708-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.853469ms
Jul 15 14:01:11.763: INFO: Pod "pod-projected-secrets-ff5dba75-a708-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013834372s
STEP: Saw pod success
Jul 15 14:01:11.763: INFO: Pod "pod-projected-secrets-ff5dba75-a708-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:01:11.765: INFO: Trying to get logs from node i-tkuhh2hc pod pod-projected-secrets-ff5dba75-a708-11e9-afda-96f40a16177b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 15 14:01:11.783: INFO: Waiting for pod pod-projected-secrets-ff5dba75-a708-11e9-afda-96f40a16177b to disappear
Jul 15 14:01:11.786: INFO: Pod pod-projected-secrets-ff5dba75-a708-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:01:11.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r7b6p" for this suite.
Jul 15 14:01:17.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:01:17.895: INFO: namespace: e2e-tests-projected-r7b6p, resource: bindings, ignored listing per whitelist
Jul 15 14:01:20.168: INFO: namespace e2e-tests-projected-r7b6p deletion completed in 8.378337779s

• [SLOW TEST:10.564 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:01:20.177: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jul 15 14:01:24.316: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-05a56d55-a709-11e9-afda-96f40a16177b", GenerateName:"", Namespace:"e2e-tests-pods-b84v2", SelfLink:"/api/v1/namespaces/e2e-tests-pods-b84v2/pods/pod-submit-remove-05a56d55-a709-11e9-afda-96f40a16177b", UID:"05a64eef-a709-11e9-8341-525422241ab4", ResourceVersion:"47047", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63698796080, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"278261602"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.10.2.111/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-v78mk", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001f3c2c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-v78mk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002113e08), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"i-x8osldkx", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0024c4480), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002113e50)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002113e70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002113e78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002113e7c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698796080, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698796082, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698796082, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698796080, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.0.4", PodIP:"10.10.2.111", StartTime:(*v1.Time)(0xc001cf4f40), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001cf4f60), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://b78b73a1aec7d55b2bc35950e1cc97aa779b25923f1508940a12b78c4a58dde5"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:01:33.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-b84v2" for this suite.
Jul 15 14:01:39.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:01:39.670: INFO: namespace: e2e-tests-pods-b84v2, resource: bindings, ignored listing per whitelist
Jul 15 14:01:42.023: INFO: namespace e2e-tests-pods-b84v2 deletion completed in 8.406018117s

• [SLOW TEST:21.847 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:01:42.026: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-12ace4e3-a709-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 14:01:42.150: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-12ad7d95-a709-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-wr6f2" to be "success or failure"
Jul 15 14:01:42.158: INFO: Pod "pod-projected-secrets-12ad7d95-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.06556ms
Jul 15 14:01:44.163: INFO: Pod "pod-projected-secrets-12ad7d95-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012511245s
Jul 15 14:01:46.166: INFO: Pod "pod-projected-secrets-12ad7d95-a709-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016257143s
STEP: Saw pod success
Jul 15 14:01:46.167: INFO: Pod "pod-projected-secrets-12ad7d95-a709-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:01:46.170: INFO: Trying to get logs from node i-tkuhh2hc pod pod-projected-secrets-12ad7d95-a709-11e9-afda-96f40a16177b container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 14:01:46.190: INFO: Waiting for pod pod-projected-secrets-12ad7d95-a709-11e9-afda-96f40a16177b to disappear
Jul 15 14:01:46.193: INFO: Pod pod-projected-secrets-12ad7d95-a709-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:01:46.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wr6f2" for this suite.
Jul 15 14:01:52.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:01:53.574: INFO: namespace: e2e-tests-projected-wr6f2, resource: bindings, ignored listing per whitelist
Jul 15 14:01:54.572: INFO: namespace e2e-tests-projected-wr6f2 deletion completed in 8.375276993s

• [SLOW TEST:12.547 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:01:54.573: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-1a243026-a709-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 14:01:54.679: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1a24b87d-a709-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-gg4dh" to be "success or failure"
Jul 15 14:01:54.683: INFO: Pod "pod-projected-configmaps-1a24b87d-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.680581ms
Jul 15 14:01:56.688: INFO: Pod "pod-projected-configmaps-1a24b87d-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008514671s
Jul 15 14:01:58.693: INFO: Pod "pod-projected-configmaps-1a24b87d-a709-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013280858s
STEP: Saw pod success
Jul 15 14:01:58.693: INFO: Pod "pod-projected-configmaps-1a24b87d-a709-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:01:58.702: INFO: Trying to get logs from node i-x8osldkx pod pod-projected-configmaps-1a24b87d-a709-11e9-afda-96f40a16177b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 14:01:58.719: INFO: Waiting for pod pod-projected-configmaps-1a24b87d-a709-11e9-afda-96f40a16177b to disappear
Jul 15 14:01:58.721: INFO: Pod pod-projected-configmaps-1a24b87d-a709-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:01:58.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gg4dh" for this suite.
Jul 15 14:02:04.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:02:04.902: INFO: namespace: e2e-tests-projected-gg4dh, resource: bindings, ignored listing per whitelist
Jul 15 14:02:07.150: INFO: namespace e2e-tests-projected-gg4dh deletion completed in 8.426154212s

• [SLOW TEST:12.578 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:02:07.153: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:02:07.242: INFO: (0) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.168253ms)
Jul 15 14:02:07.246: INFO: (1) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.831177ms)
Jul 15 14:02:07.250: INFO: (2) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.017911ms)
Jul 15 14:02:07.253: INFO: (3) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.727889ms)
Jul 15 14:02:07.261: INFO: (4) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.570193ms)
Jul 15 14:02:07.266: INFO: (5) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.884403ms)
Jul 15 14:02:07.274: INFO: (6) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.985673ms)
Jul 15 14:02:07.278: INFO: (7) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.967224ms)
Jul 15 14:02:07.281: INFO: (8) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.391396ms)
Jul 15 14:02:07.285: INFO: (9) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.484556ms)
Jul 15 14:02:07.288: INFO: (10) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.636798ms)
Jul 15 14:02:07.291: INFO: (11) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.807033ms)
Jul 15 14:02:07.294: INFO: (12) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.98255ms)
Jul 15 14:02:07.301: INFO: (13) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.983487ms)
Jul 15 14:02:07.306: INFO: (14) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.256136ms)
Jul 15 14:02:07.311: INFO: (15) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.804253ms)
Jul 15 14:02:07.315: INFO: (16) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.42218ms)
Jul 15 14:02:07.322: INFO: (17) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.120186ms)
Jul 15 14:02:07.326: INFO: (18) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.162767ms)
Jul 15 14:02:07.331: INFO: (19) /api/v1/nodes/i-tkuhh2hc/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.498719ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:02:07.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-gv86z" for this suite.
Jul 15 14:02:13.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:02:13.499: INFO: namespace: e2e-tests-proxy-gv86z, resource: bindings, ignored listing per whitelist
Jul 15 14:02:13.609: INFO: namespace e2e-tests-proxy-gv86z deletion completed in 6.274499311s

• [SLOW TEST:6.456 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:02:13.609: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:02:13.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hfbwj" for this suite.
Jul 15 14:02:31.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:02:31.886: INFO: namespace: e2e-tests-pods-hfbwj, resource: bindings, ignored listing per whitelist
Jul 15 14:02:34.180: INFO: namespace e2e-tests-pods-hfbwj deletion completed in 20.383173572s

• [SLOW TEST:20.571 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:02:34.182: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 15 14:02:34.285: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 15 14:02:34.296: INFO: Waiting for terminating namespaces to be deleted...
Jul 15 14:02:34.302: INFO: 
Logging pods the kubelet thinks is on node i-tkuhh2hc before test
Jul 15 14:02:34.327: INFO: openpitrix-repo-manager-deployment-85fcf79667-wx9bf from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container openpitrix-repo-manager ready: true, restart count 0
Jul 15 14:02:34.327: INFO: uc-jenkins-update-center-598f8d6549-5898r from kubesphere-devops-system started at 2019-07-15 08:49:15 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container jenkins-update-center ready: true, restart count 0
Jul 15 14:02:34.327: INFO: istio-ingressgateway-5477b7ffd9-lt2jc from istio-system started at 2019-07-15 08:49:24 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:02:34.327: INFO: openpitrix-runtime-db-ctrl-job-ljjls from openpitrix-system started at 2019-07-15 08:55:17 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container openpitrix-runtime-db-ctrl ready: false, restart count 0
Jul 15 14:02:34.327: INFO: alerting-client-5bb5d87f65-6l8ng from kubesphere-alerting-system started at 2019-07-15 08:48:49 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container alerting-client ready: true, restart count 0
Jul 15 14:02:34.327: INFO: calico-node-b8m4t from kube-system started at 2019-07-15 08:42:22 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container install-cni ready: true, restart count 0
Jul 15 14:02:34.327: INFO: kube-proxy-dkcd8 from kube-system started at 2019-07-15 08:42:33 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 15 14:02:34.327: INFO: openpitrix-etcd-deployment-54bc9bb948-8qmxl from openpitrix-system started at 2019-07-15 08:45:25 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container openpitrix-etcd ready: true, restart count 0
Jul 15 14:02:34.327: INFO: fluent-bit-2xfkw from kubesphere-logging-system started at 2019-07-15 08:46:28 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container config-reloader ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container fluent-bit ready: true, restart count 0
Jul 15 14:02:34.327: INFO: jaeger-operator-8cb967c86-wjtqg from istio-system started at 2019-07-15 08:55:58 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container jaeger-operator ready: true, restart count 0
Jul 15 14:02:34.327: INFO: openpitrix-runtime-manager-deployment-9c4bb7d5-tsz6x from openpitrix-system started at 2019-07-15 08:45:15 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container openpitrix-runtime-manager ready: true, restart count 0
Jul 15 14:02:34.327: INFO: kubectl-admin-d784b7777-9pzv2 from kubesphere-controls-system started at 2019-07-15 08:47:08 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container kubectl ready: true, restart count 0
Jul 15 14:02:34.327: INFO: sonobuoy-systemd-logs-daemon-set-3c9f017d4c504b82-9mlvz from heptio-sonobuoy started at 2019-07-15 13:17:54 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container systemd-logs ready: true, restart count 0
Jul 15 14:02:34.327: INFO: ks-sonarqube-sonarqube-7b48f4c664-6zvz7 from kubesphere-devops-system started at 2019-07-15 08:42:50 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container sonarqube ready: true, restart count 5
Jul 15 14:02:34.327: INFO: logging-fluentbit-operator-77ff6dbc78-b5w67 from kubesphere-logging-system started at 2019-07-15 08:46:24 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container fluentbit-operator ready: true, restart count 0
Jul 15 14:02:34.327: INFO: notification-deployment-6b78b697d7-r8cdn from kubesphere-alerting-system started at 2019-07-15 08:48:45 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container notification ready: true, restart count 0
Jul 15 14:02:34.327: INFO: istio-galley-689b548d98-qkcjf from istio-system started at 2019-07-15 08:49:24 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container galley ready: true, restart count 0
Jul 15 14:02:34.327: INFO: istio-pilot-9685dfc4b-n7ltn from istio-system started at 2019-07-15 08:49:39 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container discovery ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:02:34.327: INFO: istio-policy-b87497cf4-n4n9m from istio-system started at 2019-07-15 08:49:39 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container mixer ready: true, restart count 1
Jul 15 14:02:34.327: INFO: jaeger-query-7764db45bb-926v6 from istio-system started at 2019-07-15 08:56:01 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container jaeger-agent ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container jaeger-query ready: true, restart count 0
Jul 15 14:02:34.327: INFO: openpitrix-category-manager-deployment-bf4676856-6wfl6 from openpitrix-system started at 2019-07-15 08:45:13 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container openpitrix-category-manager ready: true, restart count 0
Jul 15 14:02:34.327: INFO: default-http-backend-96d94689d-bnkh7 from kubesphere-controls-system started at 2019-07-15 08:45:29 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container default-http-backend ready: true, restart count 0
Jul 15 14:02:34.327: INFO: notification-db-ctrl-job-9qrl4 from kubesphere-alerting-system started at 2019-07-15 08:55:27 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container notification-db-ctrl ready: false, restart count 0
Jul 15 14:02:34.327: INFO: elasticsearch-logging-data-0 from kubesphere-logging-system started at 2019-07-15 08:46:58 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container elasticsearch ready: true, restart count 0
Jul 15 14:02:34.327: INFO: istio-telemetry-758d9c786f-45wzg from istio-system started at 2019-07-15 08:49:24 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container mixer ready: true, restart count 2
Jul 15 14:02:34.327: INFO: openpitrix-iam-service-deployment-6bc78587f-bsxsl from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container openpitrix-iam-service ready: true, restart count 5
Jul 15 14:02:34.327: INFO: openpitrix-cluster-db-ctrl-job-nvphh from openpitrix-system started at 2019-07-15 08:55:16 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container openpitrix-cluster-db-ctrl ready: false, restart count 0
Jul 15 14:02:34.327: INFO: openpitrix-job-db-ctrl-job-qph77 from openpitrix-system started at 2019-07-15 08:55:17 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container openpitrix-job-db-ctrl ready: false, restart count 0
Jul 15 14:02:34.327: INFO: openpitrix-repo-indexer-deployment-d975ddff6-rqd88 from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container openpitrix-repo-indexer ready: true, restart count 0
Jul 15 14:02:34.327: INFO: node-exporter-f75fb from kubesphere-monitoring-system started at 2019-07-15 08:46:12 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container node-exporter ready: true, restart count 0
Jul 15 14:02:34.327: INFO: ks-docs-77c4796dc9-npkwv from kubesphere-system started at 2019-07-15 08:46:19 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container ks-docs ready: true, restart count 0
Jul 15 14:02:34.327: INFO: alerting-executor-75c664c66d-29hfc from kubesphere-alerting-system started at 2019-07-15 08:48:47 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container alerting-adapter ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container alerting-executor ready: true, restart count 0
Jul 15 14:02:34.327: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-15 13:17:35 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 15 14:02:34.327: INFO: alerting-db-init-job-z7whr from kubesphere-alerting-system started at 2019-07-15 08:52:09 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container alerting-db-init ready: false, restart count 0
Jul 15 14:02:34.327: INFO: ks-devops-db-ctrl-job-nmhx5 from kubesphere-devops-system started at 2019-07-15 08:55:23 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container devops-db-ctrl ready: false, restart count 0
Jul 15 14:02:34.327: INFO: csi-qingcloud-node-76gtb from kube-system started at 2019-07-15 08:42:33 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container csi-qingcloud ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container driver-registrar ready: true, restart count 0
Jul 15 14:02:34.327: INFO: openpitrix-app-manager-deployment-77bf8749dc-wxxzl from openpitrix-system started at 2019-07-15 08:45:13 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container openpitrix-app-manager ready: true, restart count 0
Jul 15 14:02:34.327: INFO: prometheus-k8s-system-0 from kubesphere-monitoring-system started at 2019-07-15 08:46:40 +0000 UTC (3 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 14:02:34.327: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 14:02:34.327: INFO: prometheus-k8s-1 from kubesphere-monitoring-system started at 2019-07-15 08:46:42 +0000 UTC (3 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 14:02:34.327: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 14:02:34.327: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 14:02:34.327: INFO: openpitrix-db-init-job-qfxfx from openpitrix-system started at 2019-07-15 08:55:18 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.327: INFO: 	Container openpitrix-db-init ready: false, restart count 0
Jul 15 14:02:34.327: INFO: 
Logging pods the kubelet thinks is on node i-x8osldkx before test
Jul 15 14:02:34.367: INFO: elasticsearch-logging-discovery-0 from kubesphere-logging-system started at 2019-07-15 08:46:44 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.367: INFO: 	Container elasticsearch ready: true, restart count 0
Jul 15 14:02:34.367: INFO: istio-pilot-9685dfc4b-jdn8c from istio-system started at 2019-07-15 08:49:19 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.367: INFO: 	Container discovery ready: true, restart count 0
Jul 15 14:02:34.367: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:02:34.367: INFO: ks-devops-db-init-job-8s8ln from kubesphere-devops-system started at 2019-07-15 08:55:18 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.367: INFO: 	Container devops-db-init ready: false, restart count 0
Jul 15 14:02:34.368: INFO: ks-sonarqube-postgresql-5d58f5574b-2bc4v from kubesphere-devops-system started at 2019-07-15 08:43:01 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container ks-sonarqube-postgresql ready: true, restart count 0
Jul 15 14:02:34.368: INFO: istio-init-crd-10-5dzhz from istio-system started at 2019-07-15 08:45:27 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container istio-init-crd-10 ready: false, restart count 0
Jul 15 14:02:34.368: INFO: fluent-bit-h2xsj from kubesphere-logging-system started at 2019-07-15 08:46:28 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container config-reloader ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container fluent-bit ready: true, restart count 0
Jul 15 14:02:34.368: INFO: prometheus-k8s-0 from kubesphere-monitoring-system started at 2019-07-15 08:46:41 +0000 UTC (3 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 14:02:34.368: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 14:02:34.368: INFO: istio-sidecar-injector-74666b458c-tvhwg from istio-system started at 2019-07-15 08:49:19 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container sidecar-injector-webhook ready: true, restart count 0
Jul 15 14:02:34.368: INFO: istio-ingressgateway-5477b7ffd9-2qgx5 from istio-system started at 2019-07-15 08:49:35 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:02:34.368: INFO: openpitrix-minio-deployment-84d5f9c94b-ztlsm from openpitrix-system started at 2019-07-15 08:45:35 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container openpitrix-minio ready: true, restart count 0
Jul 15 14:02:34.368: INFO: elasticsearch-logging-data-1 from kubesphere-logging-system started at 2019-07-15 08:48:34 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container elasticsearch ready: true, restart count 0
Jul 15 14:02:34.368: INFO: node-exporter-n94q2 from kubesphere-monitoring-system started at 2019-07-15 08:46:12 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container node-exporter ready: true, restart count 0
Jul 15 14:02:34.368: INFO: openpitrix-app-db-ctrl-job-jjvlr from openpitrix-system started at 2019-07-15 08:55:11 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container openpitrix-app-db-ctrl ready: false, restart count 0
Jul 15 14:02:34.368: INFO: alerting-executor-75c664c66d-6mzjv from kubesphere-alerting-system started at 2019-07-15 08:48:45 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container alerting-adapter ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container alerting-executor ready: true, restart count 0
Jul 15 14:02:34.368: INFO: kube-state-metrics-7f9c44c88-f27x7 from kubesphere-monitoring-system started at 2019-07-15 08:53:01 +0000 UTC (4 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container addon-resizer ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container kube-rbac-proxy-main ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container kube-rbac-proxy-self ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jul 15 14:02:34.368: INFO: csi-qingcloud-node-fvwds from kube-system started at 2019-07-15 08:42:32 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container csi-qingcloud ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container driver-registrar ready: true, restart count 0
Jul 15 14:02:34.368: INFO: metrics-server-85d786dd4d-lgw4d from kube-system started at 2019-07-15 08:45:40 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container metrics-server ready: true, restart count 0
Jul 15 14:02:34.368: INFO: notification-db-init-job-65tz2 from kubesphere-alerting-system started at 2019-07-15 08:55:23 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container notification-db-init ready: false, restart count 0
Jul 15 14:02:34.368: INFO: istio-policy-b87497cf4-r6hq4 from istio-system started at 2019-07-15 08:49:19 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container mixer ready: true, restart count 2
Jul 15 14:02:34.368: INFO: openpitrix-iam-db-ctrl-job-whtxp from openpitrix-system started at 2019-07-15 08:55:12 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container openpitrix-iam-db-ctrl ready: false, restart count 0
Jul 15 14:02:34.368: INFO: openpitrix-repo-db-ctrl-job-p6xkz from openpitrix-system started at 2019-07-15 08:55:13 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container openpitrix-repo-db-ctrl ready: false, restart count 0
Jul 15 14:02:34.368: INFO: ks-jenkins-887ddbbbc-5mwvc from kubesphere-devops-system started at 2019-07-15 08:55:59 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container ks-jenkins ready: true, restart count 0
Jul 15 14:02:34.368: INFO: kube-proxy-wfgmw from kube-system started at 2019-07-15 08:42:32 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 15 14:02:34.368: INFO: openpitrix-task-manager-deployment-5f8c7cdd64-96csg from openpitrix-system started at 2019-07-15 08:45:15 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container openpitrix-task-manager ready: true, restart count 0
Jul 15 14:02:34.368: INFO: prometheus-k8s-system-1 from kubesphere-monitoring-system started at 2019-07-15 08:46:42 +0000 UTC (3 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 14:02:34.368: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 14:02:34.368: INFO: alerting-manager-67c5f9c797-tcglm from kubesphere-alerting-system started at 2019-07-15 08:48:46 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container alerting-manager ready: true, restart count 0
Jul 15 14:02:34.368: INFO: sonobuoy-systemd-logs-daemon-set-3c9f017d4c504b82-hn592 from heptio-sonobuoy started at 2019-07-15 13:17:54 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container systemd-logs ready: true, restart count 0
Jul 15 14:02:34.368: INFO: openpitrix-task-db-ctrl-job-pf7f4 from openpitrix-system started at 2019-07-15 08:55:14 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container openpitrix-task-db-ctrl ready: false, restart count 0
Jul 15 14:02:34.368: INFO: istio-citadel-5f886dc9b4-h94c9 from istio-system started at 2019-07-15 08:49:19 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container citadel ready: true, restart count 0
Jul 15 14:02:34.368: INFO: openpitrix-api-gateway-deployment-585678b9b8-nhzmn from openpitrix-system started at 2019-07-15 08:45:12 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container openpitrix-api-gateway ready: true, restart count 0
Jul 15 14:02:34.368: INFO: openpitrix-cluster-manager-deployment-745b57798d-nhkq4 from openpitrix-system started at 2019-07-15 08:45:13 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container openpitrix-cluster-manager ready: true, restart count 0
Jul 15 14:02:34.368: INFO: openpitrix-job-manager-deployment-577649544c-jwgvs from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container openpitrix-job-manager ready: true, restart count 0
Jul 15 14:02:34.368: INFO: prometheus-operator-7d94949cf8-lzvm6 from kubesphere-monitoring-system started at 2019-07-15 08:46:11 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container prometheus-operator ready: true, restart count 0
Jul 15 14:02:34.368: INFO: istio-init-crd-11-gcd85 from istio-system started at 2019-07-15 08:45:27 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container istio-init-crd-11 ready: false, restart count 0
Jul 15 14:02:34.368: INFO: alerting-db-ctrl-job-jcxcm from kubesphere-alerting-system started at 2019-07-15 08:55:28 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container alerting-db-ctrl ready: false, restart count 0
Jul 15 14:02:34.368: INFO: istio-telemetry-758d9c786f-ppdc7 from istio-system started at 2019-07-15 08:49:35 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container mixer ready: true, restart count 1
Jul 15 14:02:34.368: INFO: jaeger-collector-7c567ccbbb-sl7ng from istio-system started at 2019-07-15 08:55:58 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container jaeger-collector ready: true, restart count 0
Jul 15 14:02:34.368: INFO: calico-node-ssbj9 from kube-system started at 2019-07-15 08:42:21 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container install-cni ready: true, restart count 0
Jul 15 14:02:34.368: INFO: s2ioperator-0 from kubesphere-devops-system started at 2019-07-15 08:45:53 +0000 UTC (2 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 15 14:02:34.368: INFO: 	Container manager ready: true, restart count 0
Jul 15 14:02:34.368: INFO: alerting-watcher-5d857d87db-zwvvf from kubesphere-alerting-system started at 2019-07-15 08:48:45 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container alerting-watcher ready: true, restart count 0
Jul 15 14:02:34.368: INFO: istio-galley-689b548d98-jqjbz from istio-system started at 2019-07-15 08:49:19 +0000 UTC (1 container statuses recorded)
Jul 15 14:02:34.368: INFO: 	Container galley ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15b19987d8837077], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:02:35.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-b87qv" for this suite.
Jul 15 14:02:41.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:02:41.631: INFO: namespace: e2e-tests-sched-pred-b87qv, resource: bindings, ignored listing per whitelist
Jul 15 14:02:43.873: INFO: namespace e2e-tests-sched-pred-b87qv deletion completed in 8.443078893s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.690 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:02:43.873: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 14:02:43.977: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37852a57-a709-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-zv8qn" to be "success or failure"
Jul 15 14:02:43.983: INFO: Pod "downwardapi-volume-37852a57-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.549867ms
Jul 15 14:02:45.988: INFO: Pod "downwardapi-volume-37852a57-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010331598s
Jul 15 14:02:47.991: INFO: Pod "downwardapi-volume-37852a57-a709-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013772488s
STEP: Saw pod success
Jul 15 14:02:47.991: INFO: Pod "downwardapi-volume-37852a57-a709-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:02:47.993: INFO: Trying to get logs from node i-tkuhh2hc pod downwardapi-volume-37852a57-a709-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 14:02:48.026: INFO: Waiting for pod downwardapi-volume-37852a57-a709-11e9-afda-96f40a16177b to disappear
Jul 15 14:02:48.028: INFO: Pod downwardapi-volume-37852a57-a709-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:02:48.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zv8qn" for this suite.
Jul 15 14:02:54.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:02:55.466: INFO: namespace: e2e-tests-projected-zv8qn, resource: bindings, ignored listing per whitelist
Jul 15 14:02:56.416: INFO: namespace e2e-tests-projected-zv8qn deletion completed in 8.383566282s

• [SLOW TEST:12.543 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:02:56.420: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:02:56.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 version'
Jul 15 14:02:56.689: INFO: stderr: ""
Jul 15 14:02:56.689: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.5\", GitCommit:\"2166946f41b36dea2c4626f90a77706f426cdea2\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:19:22Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:02:56.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mxglm" for this suite.
Jul 15 14:03:02.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:03:03.186: INFO: namespace: e2e-tests-kubectl-mxglm, resource: bindings, ignored listing per whitelist
Jul 15 14:03:05.086: INFO: namespace e2e-tests-kubectl-mxglm deletion completed in 8.392468882s

• [SLOW TEST:8.666 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:03:05.087: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4430f497-a709-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 14:03:05.244: INFO: Waiting up to 5m0s for pod "pod-configmaps-44345da7-a709-11e9-afda-96f40a16177b" in namespace "e2e-tests-configmap-h4w2r" to be "success or failure"
Jul 15 14:03:05.249: INFO: Pod "pod-configmaps-44345da7-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.180331ms
Jul 15 14:03:07.252: INFO: Pod "pod-configmaps-44345da7-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008235248s
Jul 15 14:03:09.255: INFO: Pod "pod-configmaps-44345da7-a709-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011188515s
STEP: Saw pod success
Jul 15 14:03:09.255: INFO: Pod "pod-configmaps-44345da7-a709-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:03:09.257: INFO: Trying to get logs from node i-x8osldkx pod pod-configmaps-44345da7-a709-11e9-afda-96f40a16177b container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 14:03:09.273: INFO: Waiting for pod pod-configmaps-44345da7-a709-11e9-afda-96f40a16177b to disappear
Jul 15 14:03:09.276: INFO: Pod pod-configmaps-44345da7-a709-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:03:09.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h4w2r" for this suite.
Jul 15 14:03:15.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:03:15.352: INFO: namespace: e2e-tests-configmap-h4w2r, resource: bindings, ignored listing per whitelist
Jul 15 14:03:17.662: INFO: namespace e2e-tests-configmap-h4w2r deletion completed in 8.383334566s

• [SLOW TEST:12.575 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:03:17.664: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-4baa4b86-a709-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 14:03:17.777: INFO: Waiting up to 5m0s for pod "pod-configmaps-4baac36c-a709-11e9-afda-96f40a16177b" in namespace "e2e-tests-configmap-5zbcv" to be "success or failure"
Jul 15 14:03:17.798: INFO: Pod "pod-configmaps-4baac36c-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 21.119917ms
Jul 15 14:03:19.801: INFO: Pod "pod-configmaps-4baac36c-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024085922s
Jul 15 14:03:21.806: INFO: Pod "pod-configmaps-4baac36c-a709-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028465306s
STEP: Saw pod success
Jul 15 14:03:21.806: INFO: Pod "pod-configmaps-4baac36c-a709-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:03:21.808: INFO: Trying to get logs from node i-tkuhh2hc pod pod-configmaps-4baac36c-a709-11e9-afda-96f40a16177b container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 14:03:21.835: INFO: Waiting for pod pod-configmaps-4baac36c-a709-11e9-afda-96f40a16177b to disappear
Jul 15 14:03:21.837: INFO: Pod pod-configmaps-4baac36c-a709-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:03:21.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5zbcv" for this suite.
Jul 15 14:03:27.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:03:27.971: INFO: namespace: e2e-tests-configmap-5zbcv, resource: bindings, ignored listing per whitelist
Jul 15 14:03:30.232: INFO: namespace e2e-tests-configmap-5zbcv deletion completed in 8.389696062s

• [SLOW TEST:12.569 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:03:30.233: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:03:53.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-2drkh" for this suite.
Jul 15 14:03:59.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:04:00.213: INFO: namespace: e2e-tests-container-runtime-2drkh, resource: bindings, ignored listing per whitelist
Jul 15 14:04:02.031: INFO: namespace e2e-tests-container-runtime-2drkh deletion completed in 8.456946229s

• [SLOW TEST:31.798 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:04:02.034: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 14:04:02.229: INFO: Waiting up to 5m0s for pod "downwardapi-volume-662b3b30-a709-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-rtwm8" to be "success or failure"
Jul 15 14:04:02.233: INFO: Pod "downwardapi-volume-662b3b30-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01251ms
Jul 15 14:04:04.242: INFO: Pod "downwardapi-volume-662b3b30-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01281822s
Jul 15 14:04:06.247: INFO: Pod "downwardapi-volume-662b3b30-a709-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01763296s
STEP: Saw pod success
Jul 15 14:04:06.247: INFO: Pod "downwardapi-volume-662b3b30-a709-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:04:06.254: INFO: Trying to get logs from node i-tkuhh2hc pod downwardapi-volume-662b3b30-a709-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 14:04:06.311: INFO: Waiting for pod downwardapi-volume-662b3b30-a709-11e9-afda-96f40a16177b to disappear
Jul 15 14:04:06.316: INFO: Pod downwardapi-volume-662b3b30-a709-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:04:06.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rtwm8" for this suite.
Jul 15 14:04:12.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:04:12.469: INFO: namespace: e2e-tests-downward-api-rtwm8, resource: bindings, ignored listing per whitelist
Jul 15 14:04:14.733: INFO: namespace e2e-tests-downward-api-rtwm8 deletion completed in 8.408307064s

• [SLOW TEST:12.699 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:04:14.734: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2gb54
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-2gb54
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-2gb54
Jul 15 14:04:14.869: INFO: Found 0 stateful pods, waiting for 1
Jul 15 14:04:24.873: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jul 15 14:04:24.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-2gb54 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 14:04:25.375: INFO: stderr: ""
Jul 15 14:04:25.375: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 14:04:25.375: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 14:04:25.381: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul 15 14:04:35.384: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 14:04:35.384: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 14:04:35.397: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999593s
Jul 15 14:04:36.401: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996877662s
Jul 15 14:04:37.408: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989819167s
Jul 15 14:04:38.411: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.985404321s
Jul 15 14:04:39.414: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982265931s
Jul 15 14:04:40.418: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.979253198s
Jul 15 14:04:41.421: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.97511841s
Jul 15 14:04:42.427: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.972060512s
Jul 15 14:04:43.439: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.958603958s
Jul 15 14:04:44.442: INFO: Verifying statefulset ss doesn't scale past 1 for another 954.406242ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-2gb54
Jul 15 14:04:45.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-2gb54 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 14:04:45.834: INFO: stderr: ""
Jul 15 14:04:45.834: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 14:04:45.834: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 14:04:45.838: INFO: Found 1 stateful pods, waiting for 3
Jul 15 14:04:55.841: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 14:04:55.841: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 14:04:55.841: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jul 15 14:04:55.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-2gb54 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 14:04:56.161: INFO: stderr: ""
Jul 15 14:04:56.161: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 14:04:56.161: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 14:04:56.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-2gb54 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 14:04:56.466: INFO: stderr: ""
Jul 15 14:04:56.466: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 14:04:56.466: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 14:04:56.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-2gb54 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 14:04:56.828: INFO: stderr: ""
Jul 15 14:04:56.828: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 14:04:56.829: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 14:04:56.829: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 14:04:56.831: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jul 15 14:05:06.838: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 14:05:06.838: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 14:05:06.838: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 14:05:06.852: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999211s
Jul 15 14:05:07.857: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993012132s
Jul 15 14:05:08.861: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988467309s
Jul 15 14:05:09.865: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984267856s
Jul 15 14:05:10.869: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980252985s
Jul 15 14:05:11.873: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976513739s
Jul 15 14:05:12.890: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972491202s
Jul 15 14:05:13.896: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.95560419s
Jul 15 14:05:14.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.949609565s
Jul 15 14:05:15.903: INFO: Verifying statefulset ss doesn't scale past 3 for another 946.199562ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-2gb54
Jul 15 14:05:16.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-2gb54 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 14:05:17.300: INFO: stderr: ""
Jul 15 14:05:17.300: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 14:05:17.300: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 14:05:17.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-2gb54 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 14:05:17.639: INFO: stderr: ""
Jul 15 14:05:17.639: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 14:05:17.639: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 14:05:17.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-2gb54 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 14:05:18.044: INFO: stderr: ""
Jul 15 14:05:18.044: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 14:05:18.044: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 14:05:18.044: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 15 14:05:38.058: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2gb54
Jul 15 14:05:38.060: INFO: Scaling statefulset ss to 0
Jul 15 14:05:38.068: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 14:05:38.070: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:05:38.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2gb54" for this suite.
Jul 15 14:05:44.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:05:44.156: INFO: namespace: e2e-tests-statefulset-2gb54, resource: bindings, ignored listing per whitelist
Jul 15 14:05:46.474: INFO: namespace e2e-tests-statefulset-2gb54 deletion completed in 8.387734916s

• [SLOW TEST:91.741 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:05:46.475: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-a465f388-a709-11e9-afda-96f40a16177b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-a465f388-a709-11e9-afda-96f40a16177b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:06:55.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n6qfc" for this suite.
Jul 15 14:07:19.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:07:19.145: INFO: namespace: e2e-tests-projected-n6qfc, resource: bindings, ignored listing per whitelist
Jul 15 14:07:21.423: INFO: namespace e2e-tests-projected-n6qfc deletion completed in 26.380379524s

• [SLOW TEST:94.948 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:07:21.423: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:07:21.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-bdtlq" for this suite.
Jul 15 14:07:27.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:07:27.604: INFO: namespace: e2e-tests-services-bdtlq, resource: bindings, ignored listing per whitelist
Jul 15 14:07:29.922: INFO: namespace e2e-tests-services-bdtlq deletion completed in 8.394152352s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:8.499 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:07:29.922: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-e2122a42-a709-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 14:07:30.116: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e212ed82-a709-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-2sjzv" to be "success or failure"
Jul 15 14:07:30.118: INFO: Pod "pod-projected-secrets-e212ed82-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009356ms
Jul 15 14:07:32.122: INFO: Pod "pod-projected-secrets-e212ed82-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00537359s
Jul 15 14:07:34.126: INFO: Pod "pod-projected-secrets-e212ed82-a709-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009056348s
STEP: Saw pod success
Jul 15 14:07:34.126: INFO: Pod "pod-projected-secrets-e212ed82-a709-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:07:34.129: INFO: Trying to get logs from node i-x8osldkx pod pod-projected-secrets-e212ed82-a709-11e9-afda-96f40a16177b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 15 14:07:34.158: INFO: Waiting for pod pod-projected-secrets-e212ed82-a709-11e9-afda-96f40a16177b to disappear
Jul 15 14:07:34.160: INFO: Pod pod-projected-secrets-e212ed82-a709-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:07:34.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2sjzv" for this suite.
Jul 15 14:07:40.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:07:40.309: INFO: namespace: e2e-tests-projected-2sjzv, resource: bindings, ignored listing per whitelist
Jul 15 14:07:42.567: INFO: namespace e2e-tests-projected-2sjzv deletion completed in 8.401383893s

• [SLOW TEST:12.645 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:07:42.567: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jul 15 14:07:42.730: INFO: Waiting up to 5m0s for pod "var-expansion-e99852b0-a709-11e9-afda-96f40a16177b" in namespace "e2e-tests-var-expansion-j2pqg" to be "success or failure"
Jul 15 14:07:42.748: INFO: Pod "var-expansion-e99852b0-a709-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 17.792133ms
Jul 15 14:07:44.751: INFO: Pod "var-expansion-e99852b0-a709-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020632359s
STEP: Saw pod success
Jul 15 14:07:44.751: INFO: Pod "var-expansion-e99852b0-a709-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:07:44.753: INFO: Trying to get logs from node i-tkuhh2hc pod var-expansion-e99852b0-a709-11e9-afda-96f40a16177b container dapi-container: <nil>
STEP: delete the pod
Jul 15 14:07:44.781: INFO: Waiting for pod var-expansion-e99852b0-a709-11e9-afda-96f40a16177b to disappear
Jul 15 14:07:44.784: INFO: Pod var-expansion-e99852b0-a709-11e9-afda-96f40a16177b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:07:44.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-j2pqg" for this suite.
Jul 15 14:07:50.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:07:50.862: INFO: namespace: e2e-tests-var-expansion-j2pqg, resource: bindings, ignored listing per whitelist
Jul 15 14:07:53.215: INFO: namespace e2e-tests-var-expansion-j2pqg deletion completed in 8.422081365s

• [SLOW TEST:10.648 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:07:53.215: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:07:53.301: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:07:53.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-ngrfl" for this suite.
Jul 15 14:07:59.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:07:59.883: INFO: namespace: e2e-tests-custom-resource-definition-ngrfl, resource: bindings, ignored listing per whitelist
Jul 15 14:08:02.226: INFO: namespace e2e-tests-custom-resource-definition-ngrfl deletion completed in 8.389615842s

• [SLOW TEST:9.010 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:08:02.227: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-d9k5
STEP: Creating a pod to test atomic-volume-subpath
Jul 15 14:08:02.468: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-d9k5" in namespace "e2e-tests-subpath-jdst7" to be "success or failure"
Jul 15 14:08:02.487: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.345897ms
Jul 15 14:08:04.494: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025981499s
Jul 15 14:08:06.507: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Running", Reason="", readiness=false. Elapsed: 4.038293284s
Jul 15 14:08:08.517: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Running", Reason="", readiness=false. Elapsed: 6.049061631s
Jul 15 14:08:10.521: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Running", Reason="", readiness=false. Elapsed: 8.052565431s
Jul 15 14:08:12.524: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Running", Reason="", readiness=false. Elapsed: 10.056021187s
Jul 15 14:08:14.528: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Running", Reason="", readiness=false. Elapsed: 12.059633659s
Jul 15 14:08:16.531: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Running", Reason="", readiness=false. Elapsed: 14.062656766s
Jul 15 14:08:18.535: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Running", Reason="", readiness=false. Elapsed: 16.066314446s
Jul 15 14:08:20.538: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Running", Reason="", readiness=false. Elapsed: 18.070017713s
Jul 15 14:08:22.542: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Running", Reason="", readiness=false. Elapsed: 20.073256668s
Jul 15 14:08:24.545: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Running", Reason="", readiness=false. Elapsed: 22.076671027s
Jul 15 14:08:26.552: INFO: Pod "pod-subpath-test-configmap-d9k5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.083822037s
STEP: Saw pod success
Jul 15 14:08:26.552: INFO: Pod "pod-subpath-test-configmap-d9k5" satisfied condition "success or failure"
Jul 15 14:08:26.555: INFO: Trying to get logs from node i-x8osldkx pod pod-subpath-test-configmap-d9k5 container test-container-subpath-configmap-d9k5: <nil>
STEP: delete the pod
Jul 15 14:08:26.604: INFO: Waiting for pod pod-subpath-test-configmap-d9k5 to disappear
Jul 15 14:08:26.606: INFO: Pod pod-subpath-test-configmap-d9k5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-d9k5
Jul 15 14:08:26.606: INFO: Deleting pod "pod-subpath-test-configmap-d9k5" in namespace "e2e-tests-subpath-jdst7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:08:26.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jdst7" for this suite.
Jul 15 14:08:32.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:08:32.855: INFO: namespace: e2e-tests-subpath-jdst7, resource: bindings, ignored listing per whitelist
Jul 15 14:08:35.005: INFO: namespace e2e-tests-subpath-jdst7 deletion completed in 8.389678336s

• [SLOW TEST:32.778 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:08:35.006: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-hx9gf
Jul 15 14:08:37.121: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-hx9gf
STEP: checking the pod's current state and verifying that restartCount is present
Jul 15 14:08:37.123: INFO: Initial restart count of pod liveness-exec is 0
Jul 15 14:09:27.249: INFO: Restart count of pod e2e-tests-container-probe-hx9gf/liveness-exec is now 1 (50.125202827s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:09:27.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hx9gf" for this suite.
Jul 15 14:09:33.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:09:33.383: INFO: namespace: e2e-tests-container-probe-hx9gf, resource: bindings, ignored listing per whitelist
Jul 15 14:09:35.646: INFO: namespace e2e-tests-container-probe-hx9gf deletion completed in 8.38053317s

• [SLOW TEST:60.641 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:09:35.647: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:09:35.762: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jul 15 14:09:35.778: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:35.780: INFO: Number of nodes with available pods: 0
Jul 15 14:09:35.780: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 14:09:36.799: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:36.803: INFO: Number of nodes with available pods: 0
Jul 15 14:09:36.803: INFO: Node i-tkuhh2hc is running more than one daemon pod
Jul 15 14:09:37.787: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:37.791: INFO: Number of nodes with available pods: 2
Jul 15 14:09:37.791: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jul 15 14:09:37.820: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:37.820: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:37.826: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:38.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:38.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:38.833: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:39.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:39.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:39.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:40.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:40.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:40.833: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:41.831: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:41.831: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:41.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:42.834: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:42.834: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:42.838: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:43.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:43.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:43.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:44.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:44.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:44.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:45.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:45.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:45.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:46.831: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:46.831: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:46.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:47.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:47.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:47.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:48.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:48.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:48.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:49.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:49.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:49.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:50.831: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:50.831: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:50.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:51.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:51.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:51.836: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:52.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:52.831: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:52.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:53.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:53.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:53.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:54.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:54.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:54.843: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:55.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:55.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:55.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:56.836: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:56.836: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:56.845: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:57.832: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:57.832: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:57.840: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:58.831: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:58.831: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:58.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:09:59.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:59.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:09:59.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:00.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:00.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:00.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:01.831: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:01.831: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:01.837: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:02.831: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:02.832: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:02.839: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:03.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:03.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:03.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:04.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:04.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:04.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:05.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:05.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:05.837: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:06.829: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:06.829: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:06.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:07.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:07.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:07.832: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:08.832: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:08.832: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:08.836: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:09.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:09.831: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:09.836: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:10.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:10.831: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:10.831: INFO: Pod daemon-set-wxcs7 is not available
Jul 15 14:10:10.836: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:11.839: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:11.839: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:11.840: INFO: Pod daemon-set-wxcs7 is not available
Jul 15 14:10:11.851: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:12.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:12.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:12.830: INFO: Pod daemon-set-wxcs7 is not available
Jul 15 14:10:12.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:13.831: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:13.831: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:13.831: INFO: Pod daemon-set-wxcs7 is not available
Jul 15 14:10:13.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:14.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:14.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:14.830: INFO: Pod daemon-set-wxcs7 is not available
Jul 15 14:10:14.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:15.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:15.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:15.830: INFO: Pod daemon-set-wxcs7 is not available
Jul 15 14:10:15.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:16.832: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:16.832: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:16.832: INFO: Pod daemon-set-wxcs7 is not available
Jul 15 14:10:16.836: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:17.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:17.830: INFO: Wrong image for pod: daemon-set-wxcs7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:17.831: INFO: Pod daemon-set-wxcs7 is not available
Jul 15 14:10:17.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:18.830: INFO: Pod daemon-set-8prqh is not available
Jul 15 14:10:18.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:18.833: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:19.832: INFO: Pod daemon-set-8prqh is not available
Jul 15 14:10:19.832: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:19.854: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:20.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:20.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:21.833: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:21.838: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:22.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:22.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:23.936: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:23.945: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:24.831: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:24.836: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:25.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:25.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:26.832: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:26.836: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:27.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:27.836: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:28.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:28.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:29.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:29.833: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:30.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:30.833: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:31.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:31.846: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:32.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:32.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:33.831: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:33.850: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:34.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:34.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:35.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:35.837: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:36.846: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:36.851: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:37.831: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:37.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:38.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:38.833: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:39.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:39.833: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:40.832: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:40.837: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:41.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:41.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:42.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:42.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:43.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:43.832: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:44.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:44.834: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:45.835: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:45.840: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:46.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:46.833: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:47.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:47.832: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:48.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:48.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:49.832: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:49.836: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:50.837: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:50.853: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:51.830: INFO: Wrong image for pod: daemon-set-pmnmg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jul 15 14:10:51.830: INFO: Pod daemon-set-pmnmg is not available
Jul 15 14:10:51.835: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:52.836: INFO: Pod daemon-set-svjg2 is not available
Jul 15 14:10:52.843: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jul 15 14:10:52.850: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:52.855: INFO: Number of nodes with available pods: 1
Jul 15 14:10:52.855: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 14:10:53.859: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:53.863: INFO: Number of nodes with available pods: 1
Jul 15 14:10:53.863: INFO: Node i-x8osldkx is running more than one daemon pod
Jul 15 14:10:54.863: INFO: DaemonSet pods can't tolerate node i-lvlwru2e with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul 15 14:10:54.869: INFO: Number of nodes with available pods: 2
Jul 15 14:10:54.869: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-cnnjp, will wait for the garbage collector to delete the pods
Jul 15 14:10:54.943: INFO: Deleting DaemonSet.extensions daemon-set took: 5.408868ms
Jul 15 14:10:55.043: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.216184ms
Jul 15 14:11:08.048: INFO: Number of nodes with available pods: 0
Jul 15 14:11:08.048: INFO: Number of running nodes: 0, number of available pods: 0
Jul 15 14:11:08.051: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cnnjp/daemonsets","resourceVersion":"49046"},"items":null}

Jul 15 14:11:08.053: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cnnjp/pods","resourceVersion":"49046"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:11:08.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cnnjp" for this suite.
Jul 15 14:11:14.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:11:16.057: INFO: namespace: e2e-tests-daemonsets-cnnjp, resource: bindings, ignored listing per whitelist
Jul 15 14:11:16.456: INFO: namespace e2e-tests-daemonsets-cnnjp deletion completed in 8.390857935s

• [SLOW TEST:100.810 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:11:16.456: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul 15 14:11:21.127: INFO: Successfully updated pod "pod-update-6912506c-a70a-11e9-afda-96f40a16177b"
STEP: verifying the updated pod is in kubernetes
Jul 15 14:11:21.135: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:11:21.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xpxtm" for this suite.
Jul 15 14:11:43.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:11:43.206: INFO: namespace: e2e-tests-pods-xpxtm, resource: bindings, ignored listing per whitelist
Jul 15 14:11:45.524: INFO: namespace e2e-tests-pods-xpxtm deletion completed in 24.38375078s

• [SLOW TEST:29.068 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:11:45.525: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9pz5h A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9pz5h;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9pz5h A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9pz5h;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9pz5h.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9pz5h.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9pz5h.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9pz5h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9pz5h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-9pz5h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9pz5h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-9pz5h.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9pz5h.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 43.95.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.95.43_udp@PTR;check="$$(dig +tcp +noall +answer +search 43.95.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.95.43_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9pz5h A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9pz5h;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9pz5h A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9pz5h.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9pz5h.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9pz5h.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9pz5h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-9pz5h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9pz5h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-9pz5h.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9pz5h.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 43.95.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.95.43_udp@PTR;check="$$(dig +tcp +noall +answer +search 43.95.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.95.43_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 15 14:12:33.758: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:33.763: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:33.796: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:33.799: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:33.802: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9pz5h from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:33.808: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:33.813: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:33.821: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:33.827: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:33.831: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:33.871: INFO: Lookups using e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b failed for: [wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-9pz5h jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h jessie_udp@dns-test-service.e2e-tests-dns-9pz5h.svc jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc]

Jul 15 14:12:38.899: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:38.902: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:38.922: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:38.925: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:38.927: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9pz5h from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:38.930: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:38.954: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:38.957: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:38.959: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:38.961: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:38.985: INFO: Lookups using e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b failed for: [wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-9pz5h jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h jessie_udp@dns-test-service.e2e-tests-dns-9pz5h.svc jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc]

Jul 15 14:12:43.891: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:43.895: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:43.925: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:43.929: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:43.932: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9pz5h from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:43.935: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:43.937: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:43.941: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:43.944: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:43.948: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:43.969: INFO: Lookups using e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b failed for: [wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-9pz5h jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h jessie_udp@dns-test-service.e2e-tests-dns-9pz5h.svc jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc]

Jul 15 14:12:48.890: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:48.893: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:48.911: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:48.914: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:48.917: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9pz5h from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:48.919: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:48.921: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:48.924: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:48.928: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:48.930: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc from pod e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b: the server could not find the requested resource (get pods dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b)
Jul 15 14:12:48.944: INFO: Lookups using e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b failed for: [wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-9pz5h jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h jessie_udp@dns-test-service.e2e-tests-dns-9pz5h.svc jessie_tcp@dns-test-service.e2e-tests-dns-9pz5h.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9pz5h.svc]

Jul 15 14:12:53.981: INFO: DNS probes using e2e-tests-dns-9pz5h/dns-test-7a66c38b-a70a-11e9-afda-96f40a16177b succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:12:54.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-9pz5h" for this suite.
Jul 15 14:13:00.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:13:00.270: INFO: namespace: e2e-tests-dns-9pz5h, resource: bindings, ignored listing per whitelist
Jul 15 14:13:02.420: INFO: namespace e2e-tests-dns-9pz5h deletion completed in 8.392951999s

• [SLOW TEST:76.896 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:13:02.427: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-a8420758-a70a-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 14:13:02.617: INFO: Waiting up to 5m0s for pod "pod-secrets-a8448228-a70a-11e9-afda-96f40a16177b" in namespace "e2e-tests-secrets-np6h2" to be "success or failure"
Jul 15 14:13:02.629: INFO: Pod "pod-secrets-a8448228-a70a-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.474564ms
Jul 15 14:13:04.632: INFO: Pod "pod-secrets-a8448228-a70a-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013769342s
Jul 15 14:13:06.636: INFO: Pod "pod-secrets-a8448228-a70a-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017108745s
STEP: Saw pod success
Jul 15 14:13:06.636: INFO: Pod "pod-secrets-a8448228-a70a-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:13:06.640: INFO: Trying to get logs from node i-x8osldkx pod pod-secrets-a8448228-a70a-11e9-afda-96f40a16177b container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 14:13:06.664: INFO: Waiting for pod pod-secrets-a8448228-a70a-11e9-afda-96f40a16177b to disappear
Jul 15 14:13:06.668: INFO: Pod pod-secrets-a8448228-a70a-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:13:06.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-np6h2" for this suite.
Jul 15 14:13:12.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:13:12.834: INFO: namespace: e2e-tests-secrets-np6h2, resource: bindings, ignored listing per whitelist
Jul 15 14:13:15.124: INFO: namespace e2e-tests-secrets-np6h2 deletion completed in 8.452831075s

• [SLOW TEST:12.697 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:13:15.125: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:13:19.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-47dn8" for this suite.
Jul 15 14:14:13.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:14:13.339: INFO: namespace: e2e-tests-kubelet-test-47dn8, resource: bindings, ignored listing per whitelist
Jul 15 14:14:15.635: INFO: namespace e2e-tests-kubelet-test-47dn8 deletion completed in 56.377988176s

• [SLOW TEST:60.510 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:14:15.635: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Jul 15 14:14:15.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-nbrhq'
Jul 15 14:14:16.471: INFO: stderr: ""
Jul 15 14:14:16.471: INFO: stdout: "pod/pause created\n"
Jul 15 14:14:16.472: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jul 15 14:14:16.472: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-nbrhq" to be "running and ready"
Jul 15 14:14:16.476: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.585851ms
Jul 15 14:14:18.480: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007759001s
Jul 15 14:14:20.483: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.011085775s
Jul 15 14:14:20.483: INFO: Pod "pause" satisfied condition "running and ready"
Jul 15 14:14:20.483: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jul 15 14:14:20.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-nbrhq'
Jul 15 14:14:20.645: INFO: stderr: ""
Jul 15 14:14:20.645: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jul 15 14:14:20.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pod pause -L testing-label --namespace=e2e-tests-kubectl-nbrhq'
Jul 15 14:14:20.750: INFO: stderr: ""
Jul 15 14:14:20.750: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jul 15 14:14:20.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 label pods pause testing-label- --namespace=e2e-tests-kubectl-nbrhq'
Jul 15 14:14:20.875: INFO: stderr: ""
Jul 15 14:14:20.875: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jul 15 14:14:20.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pod pause -L testing-label --namespace=e2e-tests-kubectl-nbrhq'
Jul 15 14:14:20.987: INFO: stderr: ""
Jul 15 14:14:20.987: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Jul 15 14:14:20.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-nbrhq'
Jul 15 14:14:21.109: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 14:14:21.109: INFO: stdout: "pod \"pause\" force deleted\n"
Jul 15 14:14:21.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-nbrhq'
Jul 15 14:14:21.214: INFO: stderr: "No resources found.\n"
Jul 15 14:14:21.214: INFO: stdout: ""
Jul 15 14:14:21.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -l name=pause --namespace=e2e-tests-kubectl-nbrhq -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 15 14:14:21.327: INFO: stderr: ""
Jul 15 14:14:21.327: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:14:21.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nbrhq" for this suite.
Jul 15 14:14:27.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:14:27.822: INFO: namespace: e2e-tests-kubectl-nbrhq, resource: bindings, ignored listing per whitelist
Jul 15 14:14:29.722: INFO: namespace e2e-tests-kubectl-nbrhq deletion completed in 8.390973666s

• [SLOW TEST:14.087 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:14:29.723: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:14:29.817: INFO: Creating deployment "nginx-deployment"
Jul 15 14:14:29.822: INFO: Waiting for observed generation 1
Jul 15 14:14:31.838: INFO: Waiting for all required pods to come up
Jul 15 14:14:31.842: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jul 15 14:14:35.855: INFO: Waiting for deployment "nginx-deployment" to complete
Jul 15 14:14:35.862: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jul 15 14:14:35.870: INFO: Updating deployment nginx-deployment
Jul 15 14:14:35.870: INFO: Waiting for observed generation 2
Jul 15 14:14:37.901: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jul 15 14:14:37.902: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jul 15 14:14:37.904: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul 15 14:14:37.911: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jul 15 14:14:37.911: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jul 15 14:14:37.913: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jul 15 14:14:37.915: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jul 15 14:14:37.915: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jul 15 14:14:37.920: INFO: Updating deployment nginx-deployment
Jul 15 14:14:37.921: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jul 15 14:14:37.938: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jul 15 14:14:39.944: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 15 14:14:39.949: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xdm8f/deployments/nginx-deployment,UID:dc3fd285-a70a-11e9-8341-525422241ab4,ResourceVersion:49938,Generation:3,CreationTimestamp:2019-07-15 14:14:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-07-15 14:14:37 +0000 UTC 2019-07-15 14:14:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-07-15 14:14:38 +0000 UTC 2019-07-15 14:14:29 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jul 15 14:14:39.952: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xdm8f/replicasets/nginx-deployment-65bbdb5f8,UID:dfdb8618-a70a-11e9-8341-525422241ab4,ResourceVersion:49933,Generation:3,CreationTimestamp:2019-07-15 14:14:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment dc3fd285-a70a-11e9-8341-525422241ab4 0xc001466aa7 0xc001466aa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 14:14:39.952: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jul 15 14:14:39.952: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xdm8f/replicasets/nginx-deployment-555b55d965,UID:dc41adb7-a70a-11e9-8341-525422241ab4,ResourceVersion:49926,Generation:3,CreationTimestamp:2019-07-15 14:14:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment dc3fd285-a70a-11e9-8341-525422241ab4 0xc0014669e7 0xc0014669e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jul 15 14:14:39.959: INFO: Pod "nginx-deployment-555b55d965-4mzdj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4mzdj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-4mzdj,UID:e118ae7c-a70a-11e9-8341-525422241ab4,ResourceVersion:49927,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc0014673c7 0xc0014673c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001467440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001467460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.959: INFO: Pod "nginx-deployment-555b55d965-6kj9x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6kj9x,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-6kj9x,UID:dc447e28-a70a-11e9-8341-525422241ab4,ResourceVersion:49791,Generation:0,CreationTimestamp:2019-07-15 14:14:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.126/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc0014674e0 0xc0014674e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001467550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001467570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:10.10.1.126,StartTime:2019-07-15 14:14:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 14:14:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://15eff3b9bfa83110d495cd232e8f7d074ec90ab896033dbdf0cb6c815508a3ac}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.960: INFO: Pod "nginx-deployment-555b55d965-7k5fc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7k5fc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-7k5fc,UID:dc452052-a70a-11e9-8341-525422241ab4,ResourceVersion:49777,Generation:0,CreationTimestamp:2019-07-15 14:14:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.2.125/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc001467640 0xc001467641}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014676b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014676d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.4,PodIP:10.10.2.125,StartTime:2019-07-15 14:14:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 14:14:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://3eb0052b648f9b18460ef7d240de0938176051b2acfcb2ebd8d55b975ed9c8af}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.960: INFO: Pod "nginx-deployment-555b55d965-8hkrj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8hkrj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-8hkrj,UID:dc4542cc-a70a-11e9-8341-525422241ab4,ResourceVersion:49754,Generation:0,CreationTimestamp:2019-07-15 14:14:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.125/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc0014677a0 0xc0014677a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001467810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001467830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:10.10.1.125,StartTime:2019-07-15 14:14:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 14:14:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://258336adaa9c72a43ec4c5c9db6ad6d56e23bc21dfa204f9d940131ec4e11ec9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.960: INFO: Pod "nginx-deployment-555b55d965-9j5bz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9j5bz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-9j5bz,UID:e11896ca-a70a-11e9-8341-525422241ab4,ResourceVersion:49928,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc0014678f0 0xc0014678f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001467960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001467980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.960: INFO: Pod "nginx-deployment-555b55d965-cxtnd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cxtnd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-cxtnd,UID:e11a16e9-a70a-11e9-8341-525422241ab4,ResourceVersion:49925,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc0014679f0 0xc0014679f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001467a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001467a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.961: INFO: Pod "nginx-deployment-555b55d965-dxg5w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dxg5w,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-dxg5w,UID:e1154656-a70a-11e9-8341-525422241ab4,ResourceVersion:49961,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc001467af0 0xc001467af1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001467b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001467b80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.4,PodIP:,StartTime:2019-07-15 14:14:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.961: INFO: Pod "nginx-deployment-555b55d965-gd54v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gd54v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-gd54v,UID:e118b11a-a70a-11e9-8341-525422241ab4,ResourceVersion:49959,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc001467c30 0xc001467c31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001467ca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001467cc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:,StartTime:2019-07-15 14:14:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.961: INFO: Pod "nginx-deployment-555b55d965-h4zrd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-h4zrd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-h4zrd,UID:e11a8dce-a70a-11e9-8341-525422241ab4,ResourceVersion:49982,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc001467d77 0xc001467d78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001467df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001467e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:,StartTime:2019-07-15 14:14:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.962: INFO: Pod "nginx-deployment-555b55d965-hf77c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hf77c,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-hf77c,UID:e1173f2b-a70a-11e9-8341-525422241ab4,ResourceVersion:49904,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc001467ec7 0xc001467ec8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001467f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001467f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.962: INFO: Pod "nginx-deployment-555b55d965-jft4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jft4v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-jft4v,UID:e11a7a06-a70a-11e9-8341-525422241ab4,ResourceVersion:49921,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc001467fd0 0xc001467fd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c86040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c86060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.962: INFO: Pod "nginx-deployment-555b55d965-nvm59" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nvm59,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-nvm59,UID:e11a3ee4-a70a-11e9-8341-525422241ab4,ResourceVersion:49932,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc002c860d0 0xc002c860d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c86140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c86160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.963: INFO: Pod "nginx-deployment-555b55d965-pbqw2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pbqw2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-pbqw2,UID:dc47c355-a70a-11e9-8341-525422241ab4,ResourceVersion:49785,Generation:0,CreationTimestamp:2019-07-15 14:14:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.127/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc002c861e0 0xc002c861e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c86250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c86270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:10.10.1.127,StartTime:2019-07-15 14:14:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 14:14:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e3dd6ba5fc934a05f8dbbdfe2e5865d637f4ceef4126d13c5abf0906c2662637}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.963: INFO: Pod "nginx-deployment-555b55d965-rp9cf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rp9cf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-rp9cf,UID:dc47ddc0-a70a-11e9-8341-525422241ab4,ResourceVersion:49788,Generation:0,CreationTimestamp:2019-07-15 14:14:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.128/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc002c86340 0xc002c86341}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c863b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c863d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:10.10.1.128,StartTime:2019-07-15 14:14:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 14:14:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://98e545ab1f0838e8bd970dbca093a60e45d911c312ca8fbee42bd8c0481fab74}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.963: INFO: Pod "nginx-deployment-555b55d965-vbhnn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vbhnn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-vbhnn,UID:e116df99-a70a-11e9-8341-525422241ab4,ResourceVersion:49994,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.2.133/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc002c864a0 0xc002c864a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c86510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c86530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.4,PodIP:,StartTime:2019-07-15 14:14:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.964: INFO: Pod "nginx-deployment-555b55d965-vm5j2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vm5j2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-vm5j2,UID:dc4a3b12-a70a-11e9-8341-525422241ab4,ResourceVersion:49807,Generation:0,CreationTimestamp:2019-07-15 14:14:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.129/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc002c865f0 0xc002c865f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c86660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c86680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:10.10.1.129,StartTime:2019-07-15 14:14:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 14:14:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d98f05aaa18b0a82da6c3247238064ac0fd2b08848e228e4751ec8a76110bffb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.964: INFO: Pod "nginx-deployment-555b55d965-vnfph" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vnfph,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-vnfph,UID:e11a2a0c-a70a-11e9-8341-525422241ab4,ResourceVersion:49924,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc002c86740 0xc002c86741}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c867b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c867d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.976: INFO: Pod "nginx-deployment-555b55d965-vxbhn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vxbhn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-vxbhn,UID:e118db94-a70a-11e9-8341-525422241ab4,ResourceVersion:49986,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.133/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc002c86850 0xc002c86851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c868c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c868e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:,StartTime:2019-07-15 14:14:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.977: INFO: Pod "nginx-deployment-555b55d965-zjd6n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zjd6n,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-zjd6n,UID:dc4798b8-a70a-11e9-8341-525422241ab4,ResourceVersion:49780,Generation:0,CreationTimestamp:2019-07-15 14:14:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.2.126/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc002c869a7 0xc002c869a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c86a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c86a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.4,PodIP:10.10.2.126,StartTime:2019-07-15 14:14:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 14:14:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://463480c1e9b5831f8d816d98a21c74b13ac26a377aca98590db040cd5be94753}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.977: INFO: Pod "nginx-deployment-555b55d965-zxn68" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zxn68,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-555b55d965-zxn68,UID:dc47d454-a70a-11e9-8341-525422241ab4,ResourceVersion:49796,Generation:0,CreationTimestamp:2019-07-15 14:14:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.2.129/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 dc41adb7-a70a-11e9-8341-525422241ab4 0xc002c86b10 0xc002c86b11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c86b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c86ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:29 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.4,PodIP:10.10.2.129,StartTime:2019-07-15 14:14:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-07-15 14:14:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a3f64ed06c7482784d8388be4d25ea3828f504c9e2100836f63ae4ff22be2c22}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.977: INFO: Pod "nginx-deployment-65bbdb5f8-2srtl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2srtl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-2srtl,UID:e11db5b3-a70a-11e9-8341-525422241ab4,ResourceVersion:49930,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c86c60 0xc002c86c61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c86ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c86d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.978: INFO: Pod "nginx-deployment-65bbdb5f8-2wbhv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2wbhv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-2wbhv,UID:e11fb1fc-a70a-11e9-8341-525422241ab4,ResourceVersion:49931,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c86d70 0xc002c86d71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c86df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c86e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.978: INFO: Pod "nginx-deployment-65bbdb5f8-65462" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-65462,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-65462,UID:e1184c02-a70a-11e9-8341-525422241ab4,ResourceVersion:49984,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.2.134/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c86e90 0xc002c86e91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c86f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c86f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.978: INFO: Pod "nginx-deployment-65bbdb5f8-brcm6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-brcm6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-brcm6,UID:e11714e3-a70a-11e9-8341-525422241ab4,ResourceVersion:49980,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.132/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c86fb0 0xc002c86fb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c87030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c87050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:,StartTime:2019-07-15 14:14:37 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.978: INFO: Pod "nginx-deployment-65bbdb5f8-bvb2s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bvb2s,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-bvb2s,UID:dfe5b39a-a70a-11e9-8341-525422241ab4,ResourceVersion:49965,Generation:0,CreationTimestamp:2019-07-15 14:14:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.2.132/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c87120 0xc002c87121}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c871a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c871c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.4,PodIP:,StartTime:2019-07-15 14:14:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.979: INFO: Pod "nginx-deployment-65bbdb5f8-f2bpp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-f2bpp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-f2bpp,UID:e119f2b8-a70a-11e9-8341-525422241ab4,ResourceVersion:49920,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c87280 0xc002c87281}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c87300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c87320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.979: INFO: Pod "nginx-deployment-65bbdb5f8-kq46t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-kq46t,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-kq46t,UID:e118639e-a70a-11e9-8341-525422241ab4,ResourceVersion:49958,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c87390 0xc002c87391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c87410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c87430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:,StartTime:2019-07-15 14:14:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.979: INFO: Pod "nginx-deployment-65bbdb5f8-qcbnh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qcbnh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-qcbnh,UID:dfdcfe67-a70a-11e9-8341-525422241ab4,ResourceVersion:49866,Generation:0,CreationTimestamp:2019-07-15 14:14:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.130/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c87500 0xc002c87501}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c87580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c875a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:,StartTime:2019-07-15 14:14:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.981: INFO: Pod "nginx-deployment-65bbdb5f8-qwzhk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qwzhk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-qwzhk,UID:e11b3a0d-a70a-11e9-8341-525422241ab4,ResourceVersion:49916,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c87660 0xc002c87661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c876e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c87700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.981: INFO: Pod "nginx-deployment-65bbdb5f8-s646p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-s646p,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-s646p,UID:dfdea5ca-a70a-11e9-8341-525422241ab4,ResourceVersion:49870,Generation:0,CreationTimestamp:2019-07-15 14:14:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.131/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c87780 0xc002c87781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c87800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c87820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:,StartTime:2019-07-15 14:14:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.983: INFO: Pod "nginx-deployment-65bbdb5f8-txqkr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-txqkr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-txqkr,UID:dfe66744-a70a-11e9-8341-525422241ab4,ResourceVersion:49934,Generation:0,CreationTimestamp:2019-07-15 14:14:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.2.131/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c878f0 0xc002c878f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c87970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c87990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.4,PodIP:,StartTime:2019-07-15 14:14:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.984: INFO: Pod "nginx-deployment-65bbdb5f8-x6rx4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x6rx4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-x6rx4,UID:dfde8fc6-a70a-11e9-8341-525422241ab4,ResourceVersion:49872,Generation:0,CreationTimestamp:2019-07-15 14:14:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.2.130/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c87a60 0xc002c87a61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c87ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c87b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.4,PodIP:,StartTime:2019-07-15 14:14:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jul 15 14:14:39.984: INFO: Pod "nginx-deployment-65bbdb5f8-z9qdj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z9qdj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xdm8f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xdm8f/pods/nginx-deployment-65bbdb5f8-z9qdj,UID:e11a0a54-a70a-11e9-8341-525422241ab4,ResourceVersion:49917,Generation:0,CreationTimestamp:2019-07-15 14:14:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 dfdb8618-a70a-11e9-8341-525422241ab4 0xc002c87bc0 0xc002c87bc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dcftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dcftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dcftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c87c40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c87c60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:14:38 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:14:39.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xdm8f" for this suite.
Jul 15 14:14:48.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:14:48.053: INFO: namespace: e2e-tests-deployment-xdm8f, resource: bindings, ignored listing per whitelist
Jul 15 14:14:50.371: INFO: namespace e2e-tests-deployment-xdm8f deletion completed in 10.381540788s

• [SLOW TEST:20.647 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:14:50.371: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jul 15 14:14:58.493: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dk57v PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:14:58.493: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:14:58.701: INFO: Exec stderr: ""
Jul 15 14:14:58.701: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dk57v PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:14:58.701: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:14:58.944: INFO: Exec stderr: ""
Jul 15 14:14:58.944: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dk57v PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:14:58.944: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:14:59.159: INFO: Exec stderr: ""
Jul 15 14:14:59.159: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dk57v PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:14:59.160: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:14:59.430: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jul 15 14:14:59.430: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dk57v PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:14:59.430: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:14:59.719: INFO: Exec stderr: ""
Jul 15 14:14:59.720: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dk57v PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:14:59.720: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:14:59.932: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jul 15 14:14:59.933: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dk57v PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:14:59.933: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:15:00.123: INFO: Exec stderr: ""
Jul 15 14:15:00.123: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dk57v PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:15:00.124: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:15:00.375: INFO: Exec stderr: ""
Jul 15 14:15:00.375: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dk57v PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:15:00.375: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:15:00.609: INFO: Exec stderr: ""
Jul 15 14:15:00.609: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dk57v PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:15:00.609: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:15:00.851: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:15:00.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-dk57v" for this suite.
Jul 15 14:15:48.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:15:48.903: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-dk57v, resource: bindings, ignored listing per whitelist
Jul 15 14:15:51.234: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-dk57v deletion completed in 50.379461025s

• [SLOW TEST:60.863 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:15:51.237: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jul 15 14:15:51.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:15:51.726: INFO: stderr: ""
Jul 15 14:15:51.726: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 14:15:51.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:15:51.849: INFO: stderr: ""
Jul 15 14:15:51.849: INFO: stdout: "update-demo-nautilus-5xrzz update-demo-nautilus-fsqhp "
Jul 15 14:15:51.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-5xrzz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:15:51.970: INFO: stderr: ""
Jul 15 14:15:51.970: INFO: stdout: ""
Jul 15 14:15:51.970: INFO: update-demo-nautilus-5xrzz is created but not running
Jul 15 14:15:56.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:15:57.081: INFO: stderr: ""
Jul 15 14:15:57.081: INFO: stdout: "update-demo-nautilus-5xrzz update-demo-nautilus-fsqhp "
Jul 15 14:15:57.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-5xrzz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:15:57.197: INFO: stderr: ""
Jul 15 14:15:57.198: INFO: stdout: "true"
Jul 15 14:15:57.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-5xrzz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:15:57.334: INFO: stderr: ""
Jul 15 14:15:57.334: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 14:15:57.334: INFO: validating pod update-demo-nautilus-5xrzz
Jul 15 14:15:57.340: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 14:15:57.340: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 14:15:57.341: INFO: update-demo-nautilus-5xrzz is verified up and running
Jul 15 14:15:57.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-fsqhp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:15:57.451: INFO: stderr: ""
Jul 15 14:15:57.451: INFO: stdout: "true"
Jul 15 14:15:57.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-fsqhp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:15:57.578: INFO: stderr: ""
Jul 15 14:15:57.578: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 14:15:57.578: INFO: validating pod update-demo-nautilus-fsqhp
Jul 15 14:15:57.584: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 14:15:57.584: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 14:15:57.584: INFO: update-demo-nautilus-fsqhp is verified up and running
STEP: scaling down the replication controller
Jul 15 14:15:57.589: INFO: scanned /root for discovery docs: <nil>
Jul 15 14:15:57.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:15:58.730: INFO: stderr: ""
Jul 15 14:15:58.730: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 14:15:58.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:15:58.825: INFO: stderr: ""
Jul 15 14:15:58.825: INFO: stdout: "update-demo-nautilus-5xrzz update-demo-nautilus-fsqhp "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jul 15 14:16:03.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:03.939: INFO: stderr: ""
Jul 15 14:16:03.939: INFO: stdout: "update-demo-nautilus-5xrzz update-demo-nautilus-fsqhp "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jul 15 14:16:08.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:09.050: INFO: stderr: ""
Jul 15 14:16:09.050: INFO: stdout: "update-demo-nautilus-5xrzz "
Jul 15 14:16:09.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-5xrzz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:09.176: INFO: stderr: ""
Jul 15 14:16:09.176: INFO: stdout: "true"
Jul 15 14:16:09.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-5xrzz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:09.272: INFO: stderr: ""
Jul 15 14:16:09.272: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 14:16:09.272: INFO: validating pod update-demo-nautilus-5xrzz
Jul 15 14:16:09.282: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 14:16:09.282: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 14:16:09.282: INFO: update-demo-nautilus-5xrzz is verified up and running
STEP: scaling up the replication controller
Jul 15 14:16:09.287: INFO: scanned /root for discovery docs: <nil>
Jul 15 14:16:09.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:09.451: INFO: stderr: ""
Jul 15 14:16:09.451: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 14:16:09.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:09.627: INFO: stderr: ""
Jul 15 14:16:09.627: INFO: stdout: "update-demo-nautilus-5xrzz update-demo-nautilus-zdhg2 "
Jul 15 14:16:09.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-5xrzz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:09.779: INFO: stderr: ""
Jul 15 14:16:09.779: INFO: stdout: "true"
Jul 15 14:16:09.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-5xrzz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:09.887: INFO: stderr: ""
Jul 15 14:16:09.887: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 14:16:09.887: INFO: validating pod update-demo-nautilus-5xrzz
Jul 15 14:16:09.891: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 14:16:09.891: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 14:16:09.891: INFO: update-demo-nautilus-5xrzz is verified up and running
Jul 15 14:16:09.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-zdhg2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:09.997: INFO: stderr: ""
Jul 15 14:16:09.997: INFO: stdout: ""
Jul 15 14:16:09.997: INFO: update-demo-nautilus-zdhg2 is created but not running
Jul 15 14:16:14.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:15.126: INFO: stderr: ""
Jul 15 14:16:15.126: INFO: stdout: "update-demo-nautilus-5xrzz update-demo-nautilus-zdhg2 "
Jul 15 14:16:15.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-5xrzz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:15.250: INFO: stderr: ""
Jul 15 14:16:15.250: INFO: stdout: "true"
Jul 15 14:16:15.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-5xrzz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:15.374: INFO: stderr: ""
Jul 15 14:16:15.374: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 14:16:15.374: INFO: validating pod update-demo-nautilus-5xrzz
Jul 15 14:16:15.378: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 14:16:15.378: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 14:16:15.378: INFO: update-demo-nautilus-5xrzz is verified up and running
Jul 15 14:16:15.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-zdhg2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:15.499: INFO: stderr: ""
Jul 15 14:16:15.499: INFO: stdout: "true"
Jul 15 14:16:15.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-zdhg2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:15.631: INFO: stderr: ""
Jul 15 14:16:15.631: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 14:16:15.631: INFO: validating pod update-demo-nautilus-zdhg2
Jul 15 14:16:15.636: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 14:16:15.636: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 14:16:15.636: INFO: update-demo-nautilus-zdhg2 is verified up and running
STEP: using delete to clean up resources
Jul 15 14:16:15.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:15.752: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 14:16:15.752: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul 15 14:16:15.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-f9t9p'
Jul 15 14:16:15.859: INFO: stderr: "No resources found.\n"
Jul 15 14:16:15.859: INFO: stdout: ""
Jul 15 14:16:15.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -l name=update-demo --namespace=e2e-tests-kubectl-f9t9p -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 15 14:16:15.971: INFO: stderr: ""
Jul 15 14:16:15.971: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:16:15.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f9t9p" for this suite.
Jul 15 14:16:37.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:16:38.510: INFO: namespace: e2e-tests-kubectl-f9t9p, resource: bindings, ignored listing per whitelist
Jul 15 14:16:40.360: INFO: namespace e2e-tests-kubectl-f9t9p deletion completed in 24.383258557s

• [SLOW TEST:49.124 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:16:40.363: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul 15 14:16:45.158: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2a380919-a70b-11e9-afda-96f40a16177b"
Jul 15 14:16:45.158: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2a380919-a70b-11e9-afda-96f40a16177b" in namespace "e2e-tests-pods-9kscs" to be "terminated due to deadline exceeded"
Jul 15 14:16:45.164: INFO: Pod "pod-update-activedeadlineseconds-2a380919-a70b-11e9-afda-96f40a16177b": Phase="Running", Reason="", readiness=true. Elapsed: 5.696226ms
Jul 15 14:16:47.167: INFO: Pod "pod-update-activedeadlineseconds-2a380919-a70b-11e9-afda-96f40a16177b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.008925328s
Jul 15 14:16:47.167: INFO: Pod "pod-update-activedeadlineseconds-2a380919-a70b-11e9-afda-96f40a16177b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:16:47.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9kscs" for this suite.
Jul 15 14:16:53.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:16:53.207: INFO: namespace: e2e-tests-pods-9kscs, resource: bindings, ignored listing per whitelist
Jul 15 14:16:55.561: INFO: namespace e2e-tests-pods-9kscs deletion completed in 8.388031256s

• [SLOW TEST:15.198 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:16:55.562: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 14:16:55.667: INFO: Waiting up to 5m0s for pod "downwardapi-volume-332c7fbe-a70b-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-4dzzd" to be "success or failure"
Jul 15 14:16:55.669: INFO: Pod "downwardapi-volume-332c7fbe-a70b-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.325001ms
Jul 15 14:16:57.673: INFO: Pod "downwardapi-volume-332c7fbe-a70b-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005822034s
STEP: Saw pod success
Jul 15 14:16:57.673: INFO: Pod "downwardapi-volume-332c7fbe-a70b-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:16:57.676: INFO: Trying to get logs from node i-x8osldkx pod downwardapi-volume-332c7fbe-a70b-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 14:16:57.704: INFO: Waiting for pod downwardapi-volume-332c7fbe-a70b-11e9-afda-96f40a16177b to disappear
Jul 15 14:16:57.707: INFO: Pod downwardapi-volume-332c7fbe-a70b-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:16:57.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4dzzd" for this suite.
Jul 15 14:17:03.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:17:03.801: INFO: namespace: e2e-tests-downward-api-4dzzd, resource: bindings, ignored listing per whitelist
Jul 15 14:17:06.095: INFO: namespace e2e-tests-downward-api-4dzzd deletion completed in 8.38372979s

• [SLOW TEST:10.533 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:17:06.095: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-lsgnt
I0715 14:17:06.215222      22 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-lsgnt, replica count: 1
I0715 14:17:07.265812      22 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0715 14:17:08.266106      22 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 15 14:17:08.377: INFO: Created: latency-svc-ngbkf
Jul 15 14:17:08.383: INFO: Got endpoints: latency-svc-ngbkf [16.625635ms]
Jul 15 14:17:08.402: INFO: Created: latency-svc-9gnxj
Jul 15 14:17:08.433: INFO: Created: latency-svc-rzsfp
Jul 15 14:17:08.435: INFO: Created: latency-svc-8rhxp
Jul 15 14:17:08.436: INFO: Got endpoints: latency-svc-9gnxj [53.015659ms]
Jul 15 14:17:08.452: INFO: Got endpoints: latency-svc-rzsfp [69.114531ms]
Jul 15 14:17:08.454: INFO: Got endpoints: latency-svc-8rhxp [69.472198ms]
Jul 15 14:17:08.455: INFO: Created: latency-svc-pfdlj
Jul 15 14:17:08.455: INFO: Got endpoints: latency-svc-pfdlj [71.179771ms]
Jul 15 14:17:08.456: INFO: Created: latency-svc-vjxsg
Jul 15 14:17:08.463: INFO: Got endpoints: latency-svc-vjxsg [79.791353ms]
Jul 15 14:17:08.472: INFO: Created: latency-svc-vq7dp
Jul 15 14:17:08.472: INFO: Created: latency-svc-lx85n
Jul 15 14:17:08.472: INFO: Created: latency-svc-rs6nz
Jul 15 14:17:08.473: INFO: Created: latency-svc-x9qzl
Jul 15 14:17:08.473: INFO: Created: latency-svc-8cbj8
Jul 15 14:17:08.473: INFO: Created: latency-svc-lncmc
Jul 15 14:17:08.479: INFO: Created: latency-svc-jc6n9
Jul 15 14:17:08.481: INFO: Created: latency-svc-lrqrc
Jul 15 14:17:08.481: INFO: Got endpoints: latency-svc-x9qzl [97.29887ms]
Jul 15 14:17:08.483: INFO: Got endpoints: latency-svc-rs6nz [100.410996ms]
Jul 15 14:17:08.484: INFO: Got endpoints: latency-svc-lrqrc [99.720593ms]
Jul 15 14:17:08.484: INFO: Got endpoints: latency-svc-lx85n [100.698089ms]
Jul 15 14:17:08.484: INFO: Got endpoints: latency-svc-8cbj8 [100.168476ms]
Jul 15 14:17:08.484: INFO: Got endpoints: latency-svc-vq7dp [100.317264ms]
Jul 15 14:17:08.486: INFO: Got endpoints: latency-svc-lncmc [102.276399ms]
Jul 15 14:17:08.487: INFO: Created: latency-svc-szmfg
Jul 15 14:17:08.488: INFO: Got endpoints: latency-svc-jc6n9 [52.508976ms]
Jul 15 14:17:08.496: INFO: Created: latency-svc-s76wh
Jul 15 14:17:08.496: INFO: Got endpoints: latency-svc-szmfg [112.408347ms]
Jul 15 14:17:08.498: INFO: Got endpoints: latency-svc-s76wh [114.829374ms]
Jul 15 14:17:08.500: INFO: Created: latency-svc-xfrq6
Jul 15 14:17:08.504: INFO: Got endpoints: latency-svc-xfrq6 [50.437149ms]
Jul 15 14:17:08.534: INFO: Created: latency-svc-xr6cj
Jul 15 14:17:08.534: INFO: Got endpoints: latency-svc-xr6cj [81.685047ms]
Jul 15 14:17:08.535: INFO: Created: latency-svc-5pswn
Jul 15 14:17:08.543: INFO: Got endpoints: latency-svc-5pswn [87.453992ms]
Jul 15 14:17:08.551: INFO: Created: latency-svc-9qbvp
Jul 15 14:17:08.558: INFO: Got endpoints: latency-svc-9qbvp [95.191245ms]
Jul 15 14:17:08.564: INFO: Created: latency-svc-9dlc2
Jul 15 14:17:08.564: INFO: Created: latency-svc-j5wxf
Jul 15 14:17:08.572: INFO: Got endpoints: latency-svc-j5wxf [188.385872ms]
Jul 15 14:17:08.572: INFO: Got endpoints: latency-svc-9dlc2 [90.824109ms]
Jul 15 14:17:08.572: INFO: Created: latency-svc-ggxvx
Jul 15 14:17:08.577: INFO: Created: latency-svc-pdvh5
Jul 15 14:17:08.578: INFO: Got endpoints: latency-svc-ggxvx [94.308078ms]
Jul 15 14:17:08.583: INFO: Got endpoints: latency-svc-pdvh5 [94.232043ms]
Jul 15 14:17:08.583: INFO: Created: latency-svc-lfbhk
Jul 15 14:17:08.587: INFO: Got endpoints: latency-svc-lfbhk [102.535237ms]
Jul 15 14:17:08.588: INFO: Created: latency-svc-zgdjn
Jul 15 14:17:08.594: INFO: Got endpoints: latency-svc-zgdjn [109.968895ms]
Jul 15 14:17:08.596: INFO: Created: latency-svc-wtk99
Jul 15 14:17:08.605: INFO: Created: latency-svc-97gw5
Jul 15 14:17:08.605: INFO: Created: latency-svc-d5rvw
Jul 15 14:17:08.606: INFO: Got endpoints: latency-svc-wtk99 [121.547744ms]
Jul 15 14:17:08.607: INFO: Created: latency-svc-2w899
Jul 15 14:17:08.610: INFO: Created: latency-svc-kng95
Jul 15 14:17:08.611: INFO: Got endpoints: latency-svc-kng95 [125.039496ms]
Jul 15 14:17:08.615: INFO: Got endpoints: latency-svc-2w899 [131.172218ms]
Jul 15 14:17:08.616: INFO: Got endpoints: latency-svc-d5rvw [119.291925ms]
Jul 15 14:17:08.616: INFO: Got endpoints: latency-svc-97gw5 [118.167319ms]
Jul 15 14:17:08.618: INFO: Created: latency-svc-h2gpf
Jul 15 14:17:08.619: INFO: Created: latency-svc-d8lk5
Jul 15 14:17:08.637: INFO: Created: latency-svc-gzrt8
Jul 15 14:17:08.637: INFO: Created: latency-svc-8fmwm
Jul 15 14:17:08.637: INFO: Created: latency-svc-5sqmh
Jul 15 14:17:08.637: INFO: Created: latency-svc-6m7qn
Jul 15 14:17:08.637: INFO: Created: latency-svc-rbgwl
Jul 15 14:17:08.637: INFO: Got endpoints: latency-svc-5sqmh [78.982383ms]
Jul 15 14:17:08.638: INFO: Got endpoints: latency-svc-h2gpf [133.517974ms]
Jul 15 14:17:08.641: INFO: Got endpoints: latency-svc-d8lk5 [98.482399ms]
Jul 15 14:17:08.644: INFO: Got endpoints: latency-svc-8fmwm [109.4401ms]
Jul 15 14:17:08.645: INFO: Created: latency-svc-cks7c
Jul 15 14:17:08.645: INFO: Created: latency-svc-x2ptp
Jul 15 14:17:08.652: INFO: Created: latency-svc-mwqgp
Jul 15 14:17:08.657: INFO: Created: latency-svc-2rsdh
Jul 15 14:17:08.660: INFO: Created: latency-svc-xn4qd
Jul 15 14:17:08.666: INFO: Created: latency-svc-87jwk
Jul 15 14:17:08.669: INFO: Created: latency-svc-brz98
Jul 15 14:17:08.670: INFO: Created: latency-svc-km4zz
Jul 15 14:17:08.675: INFO: Created: latency-svc-n98nj
Jul 15 14:17:08.675: INFO: Created: latency-svc-n6pnn
Jul 15 14:17:08.689: INFO: Created: latency-svc-tqr54
Jul 15 14:17:08.689: INFO: Got endpoints: latency-svc-6m7qn [117.443283ms]
Jul 15 14:17:08.689: INFO: Created: latency-svc-428vr
Jul 15 14:17:08.696: INFO: Created: latency-svc-db7nf
Jul 15 14:17:08.732: INFO: Got endpoints: latency-svc-rbgwl [160.118397ms]
Jul 15 14:17:08.741: INFO: Created: latency-svc-vlbl8
Jul 15 14:17:08.800: INFO: Got endpoints: latency-svc-gzrt8 [217.112093ms]
Jul 15 14:17:08.809: INFO: Created: latency-svc-46lwb
Jul 15 14:17:08.830: INFO: Got endpoints: latency-svc-x2ptp [251.792179ms]
Jul 15 14:17:08.839: INFO: Created: latency-svc-kn4ft
Jul 15 14:17:08.879: INFO: Got endpoints: latency-svc-cks7c [292.710487ms]
Jul 15 14:17:08.886: INFO: Created: latency-svc-vhqpf
Jul 15 14:17:08.930: INFO: Got endpoints: latency-svc-mwqgp [336.548236ms]
Jul 15 14:17:08.941: INFO: Created: latency-svc-lxz8l
Jul 15 14:17:08.980: INFO: Got endpoints: latency-svc-2rsdh [374.543578ms]
Jul 15 14:17:08.997: INFO: Created: latency-svc-vbdg8
Jul 15 14:17:09.029: INFO: Got endpoints: latency-svc-xn4qd [413.363159ms]
Jul 15 14:17:09.037: INFO: Created: latency-svc-qv7ls
Jul 15 14:17:09.079: INFO: Got endpoints: latency-svc-87jwk [463.284888ms]
Jul 15 14:17:09.087: INFO: Created: latency-svc-btcwq
Jul 15 14:17:09.129: INFO: Got endpoints: latency-svc-brz98 [513.203924ms]
Jul 15 14:17:09.138: INFO: Created: latency-svc-24wvp
Jul 15 14:17:09.179: INFO: Got endpoints: latency-svc-km4zz [568.186009ms]
Jul 15 14:17:09.189: INFO: Created: latency-svc-vwb2t
Jul 15 14:17:09.229: INFO: Got endpoints: latency-svc-n6pnn [591.753684ms]
Jul 15 14:17:09.236: INFO: Created: latency-svc-sd47s
Jul 15 14:17:09.279: INFO: Got endpoints: latency-svc-n98nj [637.337868ms]
Jul 15 14:17:09.286: INFO: Created: latency-svc-45ldq
Jul 15 14:17:09.328: INFO: Got endpoints: latency-svc-tqr54 [690.831208ms]
Jul 15 14:17:09.337: INFO: Created: latency-svc-dwx5c
Jul 15 14:17:09.379: INFO: Got endpoints: latency-svc-428vr [735.115935ms]
Jul 15 14:17:09.386: INFO: Created: latency-svc-ptqh5
Jul 15 14:17:09.429: INFO: Got endpoints: latency-svc-db7nf [739.58909ms]
Jul 15 14:17:09.440: INFO: Created: latency-svc-8m66m
Jul 15 14:17:09.482: INFO: Got endpoints: latency-svc-vlbl8 [749.890413ms]
Jul 15 14:17:09.490: INFO: Created: latency-svc-nf2nk
Jul 15 14:17:09.529: INFO: Got endpoints: latency-svc-46lwb [729.675353ms]
Jul 15 14:17:09.540: INFO: Created: latency-svc-8hwwp
Jul 15 14:17:09.584: INFO: Got endpoints: latency-svc-kn4ft [754.481504ms]
Jul 15 14:17:09.596: INFO: Created: latency-svc-zf5d2
Jul 15 14:17:09.633: INFO: Got endpoints: latency-svc-vhqpf [753.765121ms]
Jul 15 14:17:09.649: INFO: Created: latency-svc-fx8tn
Jul 15 14:17:09.680: INFO: Got endpoints: latency-svc-lxz8l [749.163852ms]
Jul 15 14:17:09.689: INFO: Created: latency-svc-qrd2l
Jul 15 14:17:09.735: INFO: Got endpoints: latency-svc-vbdg8 [754.476248ms]
Jul 15 14:17:09.744: INFO: Created: latency-svc-z92dt
Jul 15 14:17:09.780: INFO: Got endpoints: latency-svc-qv7ls [751.715967ms]
Jul 15 14:17:09.793: INFO: Created: latency-svc-j88hz
Jul 15 14:17:09.831: INFO: Got endpoints: latency-svc-btcwq [751.803045ms]
Jul 15 14:17:09.841: INFO: Created: latency-svc-89rnd
Jul 15 14:17:09.880: INFO: Got endpoints: latency-svc-24wvp [750.594866ms]
Jul 15 14:17:09.889: INFO: Created: latency-svc-bz2qg
Jul 15 14:17:09.930: INFO: Got endpoints: latency-svc-vwb2t [750.745568ms]
Jul 15 14:17:09.937: INFO: Created: latency-svc-zrsrp
Jul 15 14:17:09.983: INFO: Got endpoints: latency-svc-sd47s [754.184125ms]
Jul 15 14:17:09.993: INFO: Created: latency-svc-nrljx
Jul 15 14:17:10.031: INFO: Got endpoints: latency-svc-45ldq [752.13898ms]
Jul 15 14:17:10.043: INFO: Created: latency-svc-bfplp
Jul 15 14:17:10.078: INFO: Got endpoints: latency-svc-dwx5c [749.78123ms]
Jul 15 14:17:10.089: INFO: Created: latency-svc-k5qsz
Jul 15 14:17:10.131: INFO: Got endpoints: latency-svc-ptqh5 [751.95097ms]
Jul 15 14:17:10.147: INFO: Created: latency-svc-8hlcj
Jul 15 14:17:10.187: INFO: Got endpoints: latency-svc-8m66m [758.302967ms]
Jul 15 14:17:10.195: INFO: Created: latency-svc-ghqhn
Jul 15 14:17:10.229: INFO: Got endpoints: latency-svc-nf2nk [747.011166ms]
Jul 15 14:17:10.238: INFO: Created: latency-svc-rf9sv
Jul 15 14:17:10.284: INFO: Got endpoints: latency-svc-8hwwp [754.573204ms]
Jul 15 14:17:10.297: INFO: Created: latency-svc-mpqsv
Jul 15 14:17:10.329: INFO: Got endpoints: latency-svc-zf5d2 [743.387544ms]
Jul 15 14:17:10.336: INFO: Created: latency-svc-cwqfb
Jul 15 14:17:10.381: INFO: Got endpoints: latency-svc-fx8tn [747.072511ms]
Jul 15 14:17:10.395: INFO: Created: latency-svc-4hbvq
Jul 15 14:17:10.429: INFO: Got endpoints: latency-svc-qrd2l [749.386137ms]
Jul 15 14:17:10.439: INFO: Created: latency-svc-9vfqq
Jul 15 14:17:10.480: INFO: Got endpoints: latency-svc-z92dt [744.852381ms]
Jul 15 14:17:10.505: INFO: Created: latency-svc-r8n9t
Jul 15 14:17:10.530: INFO: Got endpoints: latency-svc-j88hz [749.688795ms]
Jul 15 14:17:10.545: INFO: Created: latency-svc-f6ctm
Jul 15 14:17:10.587: INFO: Got endpoints: latency-svc-89rnd [756.059388ms]
Jul 15 14:17:10.600: INFO: Created: latency-svc-vstjn
Jul 15 14:17:10.632: INFO: Got endpoints: latency-svc-bz2qg [751.861279ms]
Jul 15 14:17:10.644: INFO: Created: latency-svc-99958
Jul 15 14:17:10.679: INFO: Got endpoints: latency-svc-zrsrp [749.236905ms]
Jul 15 14:17:10.690: INFO: Created: latency-svc-4clsx
Jul 15 14:17:10.734: INFO: Got endpoints: latency-svc-nrljx [749.725846ms]
Jul 15 14:17:10.748: INFO: Created: latency-svc-c8fr5
Jul 15 14:17:10.780: INFO: Got endpoints: latency-svc-bfplp [748.757476ms]
Jul 15 14:17:10.792: INFO: Created: latency-svc-ps4nm
Jul 15 14:17:10.831: INFO: Got endpoints: latency-svc-k5qsz [752.606986ms]
Jul 15 14:17:10.846: INFO: Created: latency-svc-67xkd
Jul 15 14:17:10.881: INFO: Got endpoints: latency-svc-8hlcj [749.314011ms]
Jul 15 14:17:10.895: INFO: Created: latency-svc-lmpwz
Jul 15 14:17:10.931: INFO: Got endpoints: latency-svc-ghqhn [743.864397ms]
Jul 15 14:17:10.945: INFO: Created: latency-svc-824nq
Jul 15 14:17:10.982: INFO: Got endpoints: latency-svc-rf9sv [752.612238ms]
Jul 15 14:17:10.994: INFO: Created: latency-svc-bt96x
Jul 15 14:17:11.030: INFO: Got endpoints: latency-svc-mpqsv [746.02907ms]
Jul 15 14:17:11.037: INFO: Created: latency-svc-wjrcq
Jul 15 14:17:11.080: INFO: Got endpoints: latency-svc-cwqfb [751.831209ms]
Jul 15 14:17:11.091: INFO: Created: latency-svc-rxcjh
Jul 15 14:17:11.130: INFO: Got endpoints: latency-svc-4hbvq [748.928189ms]
Jul 15 14:17:11.141: INFO: Created: latency-svc-6tp8q
Jul 15 14:17:11.179: INFO: Got endpoints: latency-svc-9vfqq [749.826981ms]
Jul 15 14:17:11.188: INFO: Created: latency-svc-l25qr
Jul 15 14:17:11.231: INFO: Got endpoints: latency-svc-r8n9t [750.36875ms]
Jul 15 14:17:11.241: INFO: Created: latency-svc-knpzj
Jul 15 14:17:11.280: INFO: Got endpoints: latency-svc-f6ctm [749.667169ms]
Jul 15 14:17:11.290: INFO: Created: latency-svc-zt2cz
Jul 15 14:17:11.331: INFO: Got endpoints: latency-svc-vstjn [743.767779ms]
Jul 15 14:17:11.342: INFO: Created: latency-svc-qzm7g
Jul 15 14:17:11.380: INFO: Got endpoints: latency-svc-99958 [747.568869ms]
Jul 15 14:17:11.391: INFO: Created: latency-svc-wbrf6
Jul 15 14:17:11.429: INFO: Got endpoints: latency-svc-4clsx [749.223745ms]
Jul 15 14:17:11.438: INFO: Created: latency-svc-dsr9w
Jul 15 14:17:11.481: INFO: Got endpoints: latency-svc-c8fr5 [747.046774ms]
Jul 15 14:17:11.492: INFO: Created: latency-svc-c9qpz
Jul 15 14:17:11.529: INFO: Got endpoints: latency-svc-ps4nm [749.231301ms]
Jul 15 14:17:11.539: INFO: Created: latency-svc-zwg2s
Jul 15 14:17:11.580: INFO: Got endpoints: latency-svc-67xkd [748.258234ms]
Jul 15 14:17:11.587: INFO: Created: latency-svc-brxxz
Jul 15 14:17:11.629: INFO: Got endpoints: latency-svc-lmpwz [748.516875ms]
Jul 15 14:17:11.638: INFO: Created: latency-svc-vzjql
Jul 15 14:17:11.679: INFO: Got endpoints: latency-svc-824nq [747.0632ms]
Jul 15 14:17:11.686: INFO: Created: latency-svc-h22ls
Jul 15 14:17:11.729: INFO: Got endpoints: latency-svc-bt96x [746.648605ms]
Jul 15 14:17:11.736: INFO: Created: latency-svc-5lzw2
Jul 15 14:17:11.779: INFO: Got endpoints: latency-svc-wjrcq [748.584119ms]
Jul 15 14:17:11.788: INFO: Created: latency-svc-lrmpr
Jul 15 14:17:11.829: INFO: Got endpoints: latency-svc-rxcjh [747.796648ms]
Jul 15 14:17:11.837: INFO: Created: latency-svc-rdngx
Jul 15 14:17:11.879: INFO: Got endpoints: latency-svc-6tp8q [749.521426ms]
Jul 15 14:17:11.889: INFO: Created: latency-svc-j7xqt
Jul 15 14:17:11.930: INFO: Got endpoints: latency-svc-l25qr [750.982685ms]
Jul 15 14:17:11.937: INFO: Created: latency-svc-fmjzw
Jul 15 14:17:11.980: INFO: Got endpoints: latency-svc-knpzj [748.918055ms]
Jul 15 14:17:11.989: INFO: Created: latency-svc-9kn2v
Jul 15 14:17:12.029: INFO: Got endpoints: latency-svc-zt2cz [748.703416ms]
Jul 15 14:17:12.057: INFO: Created: latency-svc-prx4c
Jul 15 14:17:12.078: INFO: Got endpoints: latency-svc-qzm7g [747.232627ms]
Jul 15 14:17:12.096: INFO: Created: latency-svc-78llp
Jul 15 14:17:12.128: INFO: Got endpoints: latency-svc-wbrf6 [748.637137ms]
Jul 15 14:17:12.138: INFO: Created: latency-svc-fkdwf
Jul 15 14:17:12.180: INFO: Got endpoints: latency-svc-dsr9w [751.074397ms]
Jul 15 14:17:12.189: INFO: Created: latency-svc-xgkmf
Jul 15 14:17:12.229: INFO: Got endpoints: latency-svc-c9qpz [747.9214ms]
Jul 15 14:17:12.235: INFO: Created: latency-svc-9nxxg
Jul 15 14:17:12.280: INFO: Got endpoints: latency-svc-zwg2s [750.592436ms]
Jul 15 14:17:12.289: INFO: Created: latency-svc-tqppd
Jul 15 14:17:12.330: INFO: Got endpoints: latency-svc-brxxz [750.374102ms]
Jul 15 14:17:12.343: INFO: Created: latency-svc-tl4c8
Jul 15 14:17:12.381: INFO: Got endpoints: latency-svc-vzjql [751.084544ms]
Jul 15 14:17:12.390: INFO: Created: latency-svc-g585w
Jul 15 14:17:12.427: INFO: Got endpoints: latency-svc-h22ls [747.915539ms]
Jul 15 14:17:12.434: INFO: Created: latency-svc-8sxjd
Jul 15 14:17:12.481: INFO: Got endpoints: latency-svc-5lzw2 [751.81213ms]
Jul 15 14:17:12.491: INFO: Created: latency-svc-njwvz
Jul 15 14:17:12.529: INFO: Got endpoints: latency-svc-lrmpr [750.219037ms]
Jul 15 14:17:12.538: INFO: Created: latency-svc-gzngh
Jul 15 14:17:12.579: INFO: Got endpoints: latency-svc-rdngx [750.564656ms]
Jul 15 14:17:12.591: INFO: Created: latency-svc-s6sw2
Jul 15 14:17:12.633: INFO: Got endpoints: latency-svc-j7xqt [753.449631ms]
Jul 15 14:17:12.645: INFO: Created: latency-svc-46xvc
Jul 15 14:17:12.678: INFO: Got endpoints: latency-svc-fmjzw [747.774116ms]
Jul 15 14:17:12.686: INFO: Created: latency-svc-sqst6
Jul 15 14:17:12.731: INFO: Got endpoints: latency-svc-9kn2v [750.75249ms]
Jul 15 14:17:12.740: INFO: Created: latency-svc-68cdh
Jul 15 14:17:12.779: INFO: Got endpoints: latency-svc-prx4c [750.313351ms]
Jul 15 14:17:12.785: INFO: Created: latency-svc-fxpd5
Jul 15 14:17:12.829: INFO: Got endpoints: latency-svc-78llp [750.271133ms]
Jul 15 14:17:12.836: INFO: Created: latency-svc-k4d64
Jul 15 14:17:12.882: INFO: Got endpoints: latency-svc-fkdwf [753.566409ms]
Jul 15 14:17:12.890: INFO: Created: latency-svc-pqn6q
Jul 15 14:17:12.931: INFO: Got endpoints: latency-svc-xgkmf [750.513508ms]
Jul 15 14:17:12.939: INFO: Created: latency-svc-wmv6s
Jul 15 14:17:12.979: INFO: Got endpoints: latency-svc-9nxxg [749.794951ms]
Jul 15 14:17:12.986: INFO: Created: latency-svc-r5jst
Jul 15 14:17:13.030: INFO: Got endpoints: latency-svc-tqppd [749.554551ms]
Jul 15 14:17:13.038: INFO: Created: latency-svc-vv5pf
Jul 15 14:17:13.079: INFO: Got endpoints: latency-svc-tl4c8 [748.347515ms]
Jul 15 14:17:13.086: INFO: Created: latency-svc-b2g72
Jul 15 14:17:13.129: INFO: Got endpoints: latency-svc-g585w [747.719436ms]
Jul 15 14:17:13.135: INFO: Created: latency-svc-cdjff
Jul 15 14:17:13.178: INFO: Got endpoints: latency-svc-8sxjd [751.329449ms]
Jul 15 14:17:13.187: INFO: Created: latency-svc-vvkv6
Jul 15 14:17:13.230: INFO: Got endpoints: latency-svc-njwvz [749.471432ms]
Jul 15 14:17:13.238: INFO: Created: latency-svc-4sn64
Jul 15 14:17:13.278: INFO: Got endpoints: latency-svc-gzngh [748.782479ms]
Jul 15 14:17:13.287: INFO: Created: latency-svc-cwhqr
Jul 15 14:17:13.329: INFO: Got endpoints: latency-svc-s6sw2 [750.182547ms]
Jul 15 14:17:13.341: INFO: Created: latency-svc-wmr6t
Jul 15 14:17:13.381: INFO: Got endpoints: latency-svc-46xvc [747.854874ms]
Jul 15 14:17:13.392: INFO: Created: latency-svc-tqwlw
Jul 15 14:17:13.431: INFO: Got endpoints: latency-svc-sqst6 [752.681411ms]
Jul 15 14:17:13.439: INFO: Created: latency-svc-lvn7n
Jul 15 14:17:13.479: INFO: Got endpoints: latency-svc-68cdh [748.317569ms]
Jul 15 14:17:13.485: INFO: Created: latency-svc-zz7bg
Jul 15 14:17:13.528: INFO: Got endpoints: latency-svc-fxpd5 [748.732883ms]
Jul 15 14:17:13.535: INFO: Created: latency-svc-qq4xw
Jul 15 14:17:13.579: INFO: Got endpoints: latency-svc-k4d64 [750.369161ms]
Jul 15 14:17:13.584: INFO: Created: latency-svc-4kbrq
Jul 15 14:17:13.630: INFO: Got endpoints: latency-svc-pqn6q [747.712734ms]
Jul 15 14:17:13.641: INFO: Created: latency-svc-9tq6l
Jul 15 14:17:13.679: INFO: Got endpoints: latency-svc-wmv6s [747.907882ms]
Jul 15 14:17:13.684: INFO: Created: latency-svc-bb92f
Jul 15 14:17:13.729: INFO: Got endpoints: latency-svc-r5jst [750.557616ms]
Jul 15 14:17:13.742: INFO: Created: latency-svc-hpdd2
Jul 15 14:17:13.781: INFO: Got endpoints: latency-svc-vv5pf [750.607845ms]
Jul 15 14:17:13.790: INFO: Created: latency-svc-s7ckc
Jul 15 14:17:13.830: INFO: Got endpoints: latency-svc-b2g72 [751.307399ms]
Jul 15 14:17:13.838: INFO: Created: latency-svc-6rzj9
Jul 15 14:17:13.879: INFO: Got endpoints: latency-svc-cdjff [749.941775ms]
Jul 15 14:17:13.888: INFO: Created: latency-svc-zcjqf
Jul 15 14:17:13.929: INFO: Got endpoints: latency-svc-vvkv6 [750.09129ms]
Jul 15 14:17:13.939: INFO: Created: latency-svc-6q4mf
Jul 15 14:17:13.979: INFO: Got endpoints: latency-svc-4sn64 [748.059073ms]
Jul 15 14:17:13.986: INFO: Created: latency-svc-6sqtx
Jul 15 14:17:14.029: INFO: Got endpoints: latency-svc-cwhqr [749.924624ms]
Jul 15 14:17:14.040: INFO: Created: latency-svc-7v49n
Jul 15 14:17:14.081: INFO: Got endpoints: latency-svc-wmr6t [751.654638ms]
Jul 15 14:17:14.090: INFO: Created: latency-svc-wcvgt
Jul 15 14:17:14.128: INFO: Got endpoints: latency-svc-tqwlw [747.609789ms]
Jul 15 14:17:14.137: INFO: Created: latency-svc-bgl56
Jul 15 14:17:14.178: INFO: Got endpoints: latency-svc-lvn7n [747.37647ms]
Jul 15 14:17:14.187: INFO: Created: latency-svc-gqrn4
Jul 15 14:17:14.234: INFO: Got endpoints: latency-svc-zz7bg [754.727391ms]
Jul 15 14:17:14.242: INFO: Created: latency-svc-2nclx
Jul 15 14:17:14.280: INFO: Got endpoints: latency-svc-qq4xw [752.252494ms]
Jul 15 14:17:14.289: INFO: Created: latency-svc-sk4fk
Jul 15 14:17:14.328: INFO: Got endpoints: latency-svc-4kbrq [749.067796ms]
Jul 15 14:17:14.336: INFO: Created: latency-svc-f8c4r
Jul 15 14:17:14.379: INFO: Got endpoints: latency-svc-9tq6l [748.490082ms]
Jul 15 14:17:14.386: INFO: Created: latency-svc-8fggp
Jul 15 14:17:14.433: INFO: Got endpoints: latency-svc-bb92f [754.691084ms]
Jul 15 14:17:14.443: INFO: Created: latency-svc-8jm4x
Jul 15 14:17:14.479: INFO: Got endpoints: latency-svc-hpdd2 [749.102325ms]
Jul 15 14:17:14.486: INFO: Created: latency-svc-cjd5j
Jul 15 14:17:14.529: INFO: Got endpoints: latency-svc-s7ckc [748.353462ms]
Jul 15 14:17:14.544: INFO: Created: latency-svc-tpbq4
Jul 15 14:17:14.587: INFO: Got endpoints: latency-svc-6rzj9 [756.73674ms]
Jul 15 14:17:14.601: INFO: Created: latency-svc-dxv2w
Jul 15 14:17:14.629: INFO: Got endpoints: latency-svc-zcjqf [750.035679ms]
Jul 15 14:17:14.639: INFO: Created: latency-svc-hp8bg
Jul 15 14:17:14.684: INFO: Got endpoints: latency-svc-6q4mf [755.493144ms]
Jul 15 14:17:14.697: INFO: Created: latency-svc-c7czp
Jul 15 14:17:14.730: INFO: Got endpoints: latency-svc-6sqtx [750.872067ms]
Jul 15 14:17:14.744: INFO: Created: latency-svc-842z5
Jul 15 14:17:14.778: INFO: Got endpoints: latency-svc-7v49n [748.558917ms]
Jul 15 14:17:14.785: INFO: Created: latency-svc-rdwh5
Jul 15 14:17:14.829: INFO: Got endpoints: latency-svc-wcvgt [748.114481ms]
Jul 15 14:17:14.838: INFO: Created: latency-svc-c5rqf
Jul 15 14:17:14.881: INFO: Got endpoints: latency-svc-bgl56 [752.148319ms]
Jul 15 14:17:14.892: INFO: Created: latency-svc-9vgwh
Jul 15 14:17:14.931: INFO: Got endpoints: latency-svc-gqrn4 [752.56224ms]
Jul 15 14:17:14.942: INFO: Created: latency-svc-sqdm2
Jul 15 14:17:14.980: INFO: Got endpoints: latency-svc-2nclx [746.302914ms]
Jul 15 14:17:14.988: INFO: Created: latency-svc-wkmmj
Jul 15 14:17:15.028: INFO: Got endpoints: latency-svc-sk4fk [748.281573ms]
Jul 15 14:17:15.034: INFO: Created: latency-svc-jgdx7
Jul 15 14:17:15.080: INFO: Got endpoints: latency-svc-f8c4r [751.552215ms]
Jul 15 14:17:15.096: INFO: Created: latency-svc-kqchh
Jul 15 14:17:15.131: INFO: Got endpoints: latency-svc-8fggp [752.031445ms]
Jul 15 14:17:15.142: INFO: Created: latency-svc-dmg44
Jul 15 14:17:15.179: INFO: Got endpoints: latency-svc-8jm4x [744.49211ms]
Jul 15 14:17:15.188: INFO: Created: latency-svc-t7442
Jul 15 14:17:15.228: INFO: Got endpoints: latency-svc-cjd5j [749.460285ms]
Jul 15 14:17:15.241: INFO: Created: latency-svc-6lzp5
Jul 15 14:17:15.281: INFO: Got endpoints: latency-svc-tpbq4 [752.300317ms]
Jul 15 14:17:15.290: INFO: Created: latency-svc-r4b29
Jul 15 14:17:15.329: INFO: Got endpoints: latency-svc-dxv2w [742.084425ms]
Jul 15 14:17:15.336: INFO: Created: latency-svc-xz775
Jul 15 14:17:15.381: INFO: Got endpoints: latency-svc-hp8bg [751.745492ms]
Jul 15 14:17:15.392: INFO: Created: latency-svc-mpj54
Jul 15 14:17:15.429: INFO: Got endpoints: latency-svc-c7czp [744.555056ms]
Jul 15 14:17:15.437: INFO: Created: latency-svc-l7zsb
Jul 15 14:17:15.481: INFO: Got endpoints: latency-svc-842z5 [751.425991ms]
Jul 15 14:17:15.494: INFO: Created: latency-svc-llkcw
Jul 15 14:17:15.532: INFO: Got endpoints: latency-svc-rdwh5 [753.690565ms]
Jul 15 14:17:15.544: INFO: Created: latency-svc-fkl5h
Jul 15 14:17:15.578: INFO: Got endpoints: latency-svc-c5rqf [748.925328ms]
Jul 15 14:17:15.587: INFO: Created: latency-svc-g6tc8
Jul 15 14:17:15.630: INFO: Got endpoints: latency-svc-9vgwh [748.996025ms]
Jul 15 14:17:15.638: INFO: Created: latency-svc-8tvr2
Jul 15 14:17:15.681: INFO: Got endpoints: latency-svc-sqdm2 [750.428308ms]
Jul 15 14:17:15.690: INFO: Created: latency-svc-ntcs4
Jul 15 14:17:15.731: INFO: Got endpoints: latency-svc-wkmmj [750.592751ms]
Jul 15 14:17:15.745: INFO: Created: latency-svc-bf8xq
Jul 15 14:17:15.781: INFO: Got endpoints: latency-svc-jgdx7 [752.408098ms]
Jul 15 14:17:15.790: INFO: Created: latency-svc-fphcb
Jul 15 14:17:15.828: INFO: Got endpoints: latency-svc-kqchh [746.700661ms]
Jul 15 14:17:15.837: INFO: Created: latency-svc-b6hsx
Jul 15 14:17:15.878: INFO: Got endpoints: latency-svc-dmg44 [747.716551ms]
Jul 15 14:17:15.891: INFO: Created: latency-svc-ljg4n
Jul 15 14:17:15.929: INFO: Got endpoints: latency-svc-t7442 [749.63862ms]
Jul 15 14:17:15.935: INFO: Created: latency-svc-7vwbf
Jul 15 14:17:15.979: INFO: Got endpoints: latency-svc-6lzp5 [749.346764ms]
Jul 15 14:17:15.986: INFO: Created: latency-svc-br99n
Jul 15 14:17:16.029: INFO: Got endpoints: latency-svc-r4b29 [748.09761ms]
Jul 15 14:17:16.037: INFO: Created: latency-svc-c85bb
Jul 15 14:17:16.080: INFO: Got endpoints: latency-svc-xz775 [750.602268ms]
Jul 15 14:17:16.087: INFO: Created: latency-svc-9bchw
Jul 15 14:17:16.129: INFO: Got endpoints: latency-svc-mpj54 [747.434931ms]
Jul 15 14:17:16.136: INFO: Created: latency-svc-vzdg8
Jul 15 14:17:16.179: INFO: Got endpoints: latency-svc-l7zsb [749.64826ms]
Jul 15 14:17:16.187: INFO: Created: latency-svc-7f55z
Jul 15 14:17:16.229: INFO: Got endpoints: latency-svc-llkcw [747.187095ms]
Jul 15 14:17:16.279: INFO: Got endpoints: latency-svc-fkl5h [746.870172ms]
Jul 15 14:17:16.329: INFO: Got endpoints: latency-svc-g6tc8 [750.462505ms]
Jul 15 14:17:16.379: INFO: Got endpoints: latency-svc-8tvr2 [749.145756ms]
Jul 15 14:17:16.429: INFO: Got endpoints: latency-svc-ntcs4 [746.981302ms]
Jul 15 14:17:16.487: INFO: Got endpoints: latency-svc-bf8xq [755.753059ms]
Jul 15 14:17:16.529: INFO: Got endpoints: latency-svc-fphcb [747.943929ms]
Jul 15 14:17:16.580: INFO: Got endpoints: latency-svc-b6hsx [747.864749ms]
Jul 15 14:17:16.641: INFO: Got endpoints: latency-svc-ljg4n [762.314302ms]
Jul 15 14:17:16.679: INFO: Got endpoints: latency-svc-7vwbf [750.006808ms]
Jul 15 14:17:16.728: INFO: Got endpoints: latency-svc-br99n [749.172179ms]
Jul 15 14:17:16.780: INFO: Got endpoints: latency-svc-c85bb [750.289874ms]
Jul 15 14:17:16.828: INFO: Got endpoints: latency-svc-9bchw [747.851978ms]
Jul 15 14:17:16.880: INFO: Got endpoints: latency-svc-vzdg8 [751.195295ms]
Jul 15 14:17:16.928: INFO: Got endpoints: latency-svc-7f55z [749.243477ms]
Jul 15 14:17:16.928: INFO: Latencies: [50.437149ms 52.508976ms 53.015659ms 69.114531ms 69.472198ms 71.179771ms 78.982383ms 79.791353ms 81.685047ms 87.453992ms 90.824109ms 94.232043ms 94.308078ms 95.191245ms 97.29887ms 98.482399ms 99.720593ms 100.168476ms 100.317264ms 100.410996ms 100.698089ms 102.276399ms 102.535237ms 109.4401ms 109.968895ms 112.408347ms 114.829374ms 117.443283ms 118.167319ms 119.291925ms 121.547744ms 125.039496ms 131.172218ms 133.517974ms 160.118397ms 188.385872ms 217.112093ms 251.792179ms 292.710487ms 336.548236ms 374.543578ms 413.363159ms 463.284888ms 513.203924ms 568.186009ms 591.753684ms 637.337868ms 690.831208ms 729.675353ms 735.115935ms 739.58909ms 742.084425ms 743.387544ms 743.767779ms 743.864397ms 744.49211ms 744.555056ms 744.852381ms 746.02907ms 746.302914ms 746.648605ms 746.700661ms 746.870172ms 746.981302ms 747.011166ms 747.046774ms 747.0632ms 747.072511ms 747.187095ms 747.232627ms 747.37647ms 747.434931ms 747.568869ms 747.609789ms 747.712734ms 747.716551ms 747.719436ms 747.774116ms 747.796648ms 747.851978ms 747.854874ms 747.864749ms 747.907882ms 747.915539ms 747.9214ms 747.943929ms 748.059073ms 748.09761ms 748.114481ms 748.258234ms 748.281573ms 748.317569ms 748.347515ms 748.353462ms 748.490082ms 748.516875ms 748.558917ms 748.584119ms 748.637137ms 748.703416ms 748.732883ms 748.757476ms 748.782479ms 748.918055ms 748.925328ms 748.928189ms 748.996025ms 749.067796ms 749.102325ms 749.145756ms 749.163852ms 749.172179ms 749.223745ms 749.231301ms 749.236905ms 749.243477ms 749.314011ms 749.346764ms 749.386137ms 749.460285ms 749.471432ms 749.521426ms 749.554551ms 749.63862ms 749.64826ms 749.667169ms 749.688795ms 749.725846ms 749.78123ms 749.794951ms 749.826981ms 749.890413ms 749.924624ms 749.941775ms 750.006808ms 750.035679ms 750.09129ms 750.182547ms 750.219037ms 750.271133ms 750.289874ms 750.313351ms 750.36875ms 750.369161ms 750.374102ms 750.428308ms 750.462505ms 750.513508ms 750.557616ms 750.564656ms 750.592436ms 750.592751ms 750.594866ms 750.602268ms 750.607845ms 750.745568ms 750.75249ms 750.872067ms 750.982685ms 751.074397ms 751.084544ms 751.195295ms 751.307399ms 751.329449ms 751.425991ms 751.552215ms 751.654638ms 751.715967ms 751.745492ms 751.803045ms 751.81213ms 751.831209ms 751.861279ms 751.95097ms 752.031445ms 752.13898ms 752.148319ms 752.252494ms 752.300317ms 752.408098ms 752.56224ms 752.606986ms 752.612238ms 752.681411ms 753.449631ms 753.566409ms 753.690565ms 753.765121ms 754.184125ms 754.476248ms 754.481504ms 754.573204ms 754.691084ms 754.727391ms 755.493144ms 755.753059ms 756.059388ms 756.73674ms 758.302967ms 762.314302ms]
Jul 15 14:17:16.929: INFO: 50 %ile: 748.732883ms
Jul 15 14:17:16.929: INFO: 90 %ile: 752.56224ms
Jul 15 14:17:16.929: INFO: 99 %ile: 758.302967ms
Jul 15 14:17:16.929: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:17:16.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-lsgnt" for this suite.
Jul 15 14:17:40.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:17:41.015: INFO: namespace: e2e-tests-svc-latency-lsgnt, resource: bindings, ignored listing per whitelist
Jul 15 14:17:43.348: INFO: namespace e2e-tests-svc-latency-lsgnt deletion completed in 26.413795665s

• [SLOW TEST:37.253 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:17:43.348: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jul 15 14:17:43.427: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-170914682 proxy --unix-socket=/tmp/kubectl-proxy-unix731207825/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:17:43.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cmxk8" for this suite.
Jul 15 14:17:49.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:17:49.565: INFO: namespace: e2e-tests-kubectl-cmxk8, resource: bindings, ignored listing per whitelist
Jul 15 14:17:51.928: INFO: namespace e2e-tests-kubectl-cmxk8 deletion completed in 8.419149231s

• [SLOW TEST:8.580 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:17:51.929: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-54d415fb-a70b-11e9-afda-96f40a16177b
STEP: Creating configMap with name cm-test-opt-upd-54d41648-a70b-11e9-afda-96f40a16177b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-54d415fb-a70b-11e9-afda-96f40a16177b
STEP: Updating configmap cm-test-opt-upd-54d41648-a70b-11e9-afda-96f40a16177b
STEP: Creating configMap with name cm-test-opt-create-54d4165f-a70b-11e9-afda-96f40a16177b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:17:58.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x8vr5" for this suite.
Jul 15 14:18:20.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:18:22.120: INFO: namespace: e2e-tests-configmap-x8vr5, resource: bindings, ignored listing per whitelist
Jul 15 14:18:22.620: INFO: namespace e2e-tests-configmap-x8vr5 deletion completed in 24.379952336s

• [SLOW TEST:30.692 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:18:22.623: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:18:22.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 version --client'
Jul 15 14:18:22.806: INFO: stderr: ""
Jul 15 14:18:22.806: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jul 15 14:18:22.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-scjf9'
Jul 15 14:18:23.110: INFO: stderr: ""
Jul 15 14:18:23.110: INFO: stdout: "replicationcontroller/redis-master created\n"
Jul 15 14:18:23.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-scjf9'
Jul 15 14:18:23.457: INFO: stderr: ""
Jul 15 14:18:23.457: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jul 15 14:18:24.461: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:18:24.461: INFO: Found 0 / 1
Jul 15 14:18:25.461: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:18:25.461: INFO: Found 1 / 1
Jul 15 14:18:25.461: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 15 14:18:25.465: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:18:25.465: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul 15 14:18:25.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 describe pod redis-master-vkm4n --namespace=e2e-tests-kubectl-scjf9'
Jul 15 14:18:25.600: INFO: stderr: ""
Jul 15 14:18:25.600: INFO: stdout: "Name:               redis-master-vkm4n\nNamespace:          e2e-tests-kubectl-scjf9\nPriority:           0\nPriorityClassName:  <none>\nNode:               i-tkuhh2hc/192.168.0.23\nStart Time:         Mon, 15 Jul 2019 14:18:23 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.10.1.146/32\nStatus:             Running\nIP:                 10.10.1.146\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://2010b7afabcc62f730a865953dd070b7cbcfa52320f27908b9b66d4d540c81aa\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 15 Jul 2019 14:18:24 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-hhj2w (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-hhj2w:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-hhj2w\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                 Message\n  ----    ------     ----  ----                 -------\n  Normal  Scheduled  2s    default-scheduler    Successfully assigned e2e-tests-kubectl-scjf9/redis-master-vkm4n to i-tkuhh2hc\n  Normal  Pulled     1s    kubelet, i-tkuhh2hc  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, i-tkuhh2hc  Created container\n  Normal  Started    1s    kubelet, i-tkuhh2hc  Started container\n"
Jul 15 14:18:25.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 describe rc redis-master --namespace=e2e-tests-kubectl-scjf9'
Jul 15 14:18:25.736: INFO: stderr: ""
Jul 15 14:18:25.736: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-scjf9\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-vkm4n\n"
Jul 15 14:18:25.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 describe service redis-master --namespace=e2e-tests-kubectl-scjf9'
Jul 15 14:18:25.837: INFO: stderr: ""
Jul 15 14:18:25.837: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-scjf9\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.96.98.134\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.10.1.146:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jul 15 14:18:25.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 describe node i-lvlwru2e'
Jul 15 14:18:26.003: INFO: stderr: ""
Jul 15 14:18:26.003: INFO: stdout: "Name:               i-lvlwru2e\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=i-lvlwru2e\n                    node-role.kubernetes.io/master=\n                    role=master\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"csi-qingcloud\":\"i-lvlwru2e\"}\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 192.168.0.2/24\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 15 Jul 2019 08:40:44 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 15 Jul 2019 14:18:24 +0000   Mon, 15 Jul 2019 08:40:36 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 15 Jul 2019 14:18:24 +0000   Mon, 15 Jul 2019 08:40:36 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 15 Jul 2019 14:18:24 +0000   Mon, 15 Jul 2019 08:40:36 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 15 Jul 2019 14:18:24 +0000   Mon, 15 Jul 2019 08:41:23 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.0.2\n  Hostname:    i-lvlwru2e\nCapacity:\n cpu:                4\n ephemeral-storage:  82438832Ki\n hugepages-2Mi:      0\n memory:             8174676Ki\n pods:               120\nAllocatable:\n cpu:                4\n ephemeral-storage:  75975627446\n hugepages-2Mi:      0\n memory:             8072276Ki\n pods:               120\nSystem Info:\n Machine ID:                    76d20bc173e005d7696d4a565d2c3b02\n System UUID:                   70CBB3AE-7220-34D1-9691-022BAF76B846\n Boot ID:                       1d370fca-5ded-457a-8fc2-06a966a0b045\n Kernel Version:                4.4.0-148-generic\n OS Image:                      Ubuntu 16.04.6 LTS\n Operating System:              linux\n Architecture:                  amd64\n Container Runtime Version:     docker://18.6.2\n Kubelet Version:               v1.13.5\n Kube-Proxy Version:            v1.13.5\nPodCIDR:                        10.10.0.0/24\nNon-terminated Pods:            (24 in total)\n  Namespace                     Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                     ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy               sonobuoy-e2e-job-b5317c9a3e2d40cf                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         60m\n  heptio-sonobuoy               sonobuoy-systemd-logs-daemon-set-3c9f017d4c504b82-2wv65    0 (0%)        0 (0%)      0 (0%)           0 (0%)         60m\n  kube-system                   calico-node-8gbjd                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)         5h37m\n  kube-system                   cloud-controller-manager-75464fc6cb-x22xl                  100m (2%)     200m (5%)   50Mi (0%)        100Mi (1%)     5h35m\n  kube-system                   coredns-545f6ffc78-cf2cp                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     5h37m\n  kube-system                   coredns-545f6ffc78-j4tzn                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     5h37m\n  kube-system                   csi-qingcloud-controller-0                                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h37m\n  kube-system                   csi-qingcloud-node-sf4pr                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h36m\n  kube-system                   kube-apiserver-i-lvlwru2e                                  250m (6%)     0 (0%)      0 (0%)           0 (0%)         5h37m\n  kube-system                   kube-controller-manager-i-lvlwru2e                         200m (5%)     0 (0%)      0 (0%)           0 (0%)         5h37m\n  kube-system                   kube-proxy-6xrx4                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h36m\n  kube-system                   kube-scheduler-i-lvlwru2e                                  100m (2%)     0 (0%)      0 (0%)           0 (0%)         5h37m\n  kube-system                   tiller-deploy-565697f9fd-bsk9z                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h37m\n  kubesphere-logging-system     fluent-bit-mqrsn                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h32m\n  kubesphere-monitoring-system  node-exporter-p48ns                                        112m (2%)     270m (6%)   200Mi (2%)       220Mi (2%)     5h32m\n  kubesphere-system             ks-account-7f9d74f78f-j8h79                                50m (1%)      1 (25%)     200Mi (2%)       500Mi (6%)     5h26m\n  kubesphere-system             ks-apigateway-6b5cb7f5f8-rbmkn                             50m (1%)      1 (25%)     200Mi (2%)       500Mi (6%)     5h25m\n  kubesphere-system             ks-apiserver-7d8db56987-njv7m                              50m (1%)      1 (25%)     200Mi (2%)       1Gi (12%)      5h22m\n  kubesphere-system             ks-console-57744c949b-jjfmd                                50m (1%)      1 (25%)     100Mi (1%)       512Mi (6%)     5h25m\n  kubesphere-system             ks-console-57744c949b-rjzwd                                50m (1%)      1 (25%)     100Mi (1%)       512Mi (6%)     5h25m\n  kubesphere-system             ks-controller-manager-6447cf7cf-j7vv8                      50m (1%)      500m (12%)  50Mi (0%)        500Mi (6%)     5h32m\n  kubesphere-system             openldap-748984454-8d5mq                                   100m (2%)     1 (25%)     900Mi (11%)      1500Mi (19%)   5h33m\n  kubesphere-system             redis-7569768957-wnrdx                                     100m (2%)     1 (25%)     100Mi (1%)       1000Mi (12%)   5h33m\n  openpitrix-system             openpitrix-db-deployment-6864df4f99-lr5sl                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h33m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests      Limits\n  --------           --------      ------\n  cpu                1712m (42%)   7970m (199%)\n  memory             2240Mi (28%)  6708Mi (85%)\n  ephemeral-storage  0 (0%)        0 (0%)\nEvents:              <none>\n"
Jul 15 14:18:26.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 describe namespace e2e-tests-kubectl-scjf9'
Jul 15 14:18:26.166: INFO: stderr: ""
Jul 15 14:18:26.166: INFO: stdout: "Name:         e2e-tests-kubectl-scjf9\nLabels:       e2e-framework=kubectl\n              e2e-run=8521c4b4-a703-11e9-afda-96f40a16177b\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:18:26.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-scjf9" for this suite.
Jul 15 14:18:48.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:18:48.236: INFO: namespace: e2e-tests-kubectl-scjf9, resource: bindings, ignored listing per whitelist
Jul 15 14:18:50.575: INFO: namespace e2e-tests-kubectl-scjf9 deletion completed in 24.4056286s

• [SLOW TEST:27.952 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:18:50.576: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0715 14:19:21.208491      22 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 14:19:21.208: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:19:21.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ntx2q" for this suite.
Jul 15 14:19:27.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:19:28.395: INFO: namespace: e2e-tests-gc-ntx2q, resource: bindings, ignored listing per whitelist
Jul 15 14:19:29.607: INFO: namespace e2e-tests-gc-ntx2q deletion completed in 8.395128044s

• [SLOW TEST:39.040 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:19:29.630: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul 15 14:19:29.742: INFO: Waiting up to 5m0s for pod "pod-8f03d21f-a70b-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-t5pz2" to be "success or failure"
Jul 15 14:19:29.749: INFO: Pod "pod-8f03d21f-a70b-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.053025ms
Jul 15 14:19:31.752: INFO: Pod "pod-8f03d21f-a70b-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010340897s
Jul 15 14:19:33.757: INFO: Pod "pod-8f03d21f-a70b-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015406445s
Jul 15 14:19:35.761: INFO: Pod "pod-8f03d21f-a70b-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018993183s
STEP: Saw pod success
Jul 15 14:19:35.761: INFO: Pod "pod-8f03d21f-a70b-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:19:35.764: INFO: Trying to get logs from node i-tkuhh2hc pod pod-8f03d21f-a70b-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 14:19:35.784: INFO: Waiting for pod pod-8f03d21f-a70b-11e9-afda-96f40a16177b to disappear
Jul 15 14:19:35.786: INFO: Pod pod-8f03d21f-a70b-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:19:35.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t5pz2" for this suite.
Jul 15 14:19:41.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:19:41.875: INFO: namespace: e2e-tests-emptydir-t5pz2, resource: bindings, ignored listing per whitelist
Jul 15 14:19:44.179: INFO: namespace e2e-tests-emptydir-t5pz2 deletion completed in 8.388534337s

• [SLOW TEST:14.550 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:19:44.182: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:19:48.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-mjv75" for this suite.
Jul 15 14:19:54.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:19:54.569: INFO: namespace: e2e-tests-emptydir-wrapper-mjv75, resource: bindings, ignored listing per whitelist
Jul 15 14:19:56.719: INFO: namespace e2e-tests-emptydir-wrapper-mjv75 deletion completed in 8.379021808s

• [SLOW TEST:12.538 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:19:56.720: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 14:19:56.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-q8qtn'
Jul 15 14:19:57.002: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 15 14:19:57.003: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Jul 15 14:19:57.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-q8qtn'
Jul 15 14:19:57.167: INFO: stderr: ""
Jul 15 14:19:57.167: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:19:57.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q8qtn" for this suite.
Jul 15 14:20:03.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:20:03.302: INFO: namespace: e2e-tests-kubectl-q8qtn, resource: bindings, ignored listing per whitelist
Jul 15 14:20:05.572: INFO: namespace e2e-tests-kubectl-q8qtn deletion completed in 8.400359863s

• [SLOW TEST:8.853 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:20:05.573: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a46e7b16-a70b-11e9-afda-96f40a16177b
STEP: Creating secret with name s-test-opt-upd-a46e7b70-a70b-11e9-afda-96f40a16177b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a46e7b16-a70b-11e9-afda-96f40a16177b
STEP: Updating secret s-test-opt-upd-a46e7b70-a70b-11e9-afda-96f40a16177b
STEP: Creating secret with name s-test-opt-create-a46e7b89-a70b-11e9-afda-96f40a16177b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:20:11.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n9mj5" for this suite.
Jul 15 14:20:33.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:20:35.711: INFO: namespace: e2e-tests-secrets-n9mj5, resource: bindings, ignored listing per whitelist
Jul 15 14:20:36.262: INFO: namespace e2e-tests-secrets-n9mj5 deletion completed in 24.468650823s

• [SLOW TEST:30.689 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:20:36.263: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 14:20:36.364: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b6b76e7b-a70b-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-nrklj" to be "success or failure"
Jul 15 14:20:36.366: INFO: Pod "downwardapi-volume-b6b76e7b-a70b-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.902893ms
Jul 15 14:20:38.369: INFO: Pod "downwardapi-volume-b6b76e7b-a70b-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005374812s
STEP: Saw pod success
Jul 15 14:20:38.369: INFO: Pod "downwardapi-volume-b6b76e7b-a70b-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:20:38.371: INFO: Trying to get logs from node i-tkuhh2hc pod downwardapi-volume-b6b76e7b-a70b-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 14:20:38.391: INFO: Waiting for pod downwardapi-volume-b6b76e7b-a70b-11e9-afda-96f40a16177b to disappear
Jul 15 14:20:38.393: INFO: Pod downwardapi-volume-b6b76e7b-a70b-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:20:38.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nrklj" for this suite.
Jul 15 14:20:44.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:20:46.733: INFO: namespace: e2e-tests-downward-api-nrklj, resource: bindings, ignored listing per whitelist
Jul 15 14:20:46.783: INFO: namespace e2e-tests-downward-api-nrklj deletion completed in 8.385714181s

• [SLOW TEST:10.520 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:20:46.788: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 14:20:46.881: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bcfde3aa-a70b-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-8n9vn" to be "success or failure"
Jul 15 14:20:46.887: INFO: Pod "downwardapi-volume-bcfde3aa-a70b-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.331558ms
Jul 15 14:20:48.890: INFO: Pod "downwardapi-volume-bcfde3aa-a70b-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008605838s
STEP: Saw pod success
Jul 15 14:20:48.890: INFO: Pod "downwardapi-volume-bcfde3aa-a70b-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:20:48.892: INFO: Trying to get logs from node i-tkuhh2hc pod downwardapi-volume-bcfde3aa-a70b-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 14:20:48.909: INFO: Waiting for pod downwardapi-volume-bcfde3aa-a70b-11e9-afda-96f40a16177b to disappear
Jul 15 14:20:48.911: INFO: Pod downwardapi-volume-bcfde3aa-a70b-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:20:48.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8n9vn" for this suite.
Jul 15 14:20:54.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:20:54.961: INFO: namespace: e2e-tests-downward-api-8n9vn, resource: bindings, ignored listing per whitelist
Jul 15 14:20:57.301: INFO: namespace e2e-tests-downward-api-8n9vn deletion completed in 8.387521655s

• [SLOW TEST:10.514 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:20:57.302: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jul 15 14:20:57.404: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-170914682 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:20:57.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q2jfc" for this suite.
Jul 15 14:21:03.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:21:03.605: INFO: namespace: e2e-tests-kubectl-q2jfc, resource: bindings, ignored listing per whitelist
Jul 15 14:21:05.899: INFO: namespace e2e-tests-kubectl-q2jfc deletion completed in 8.386861404s

• [SLOW TEST:8.597 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:21:05.900: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jul 15 14:21:06.215: INFO: Pod name wrapped-volume-race-c882cf66-a70b-11e9-afda-96f40a16177b: Found 0 pods out of 5
Jul 15 14:21:11.223: INFO: Pod name wrapped-volume-race-c882cf66-a70b-11e9-afda-96f40a16177b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c882cf66-a70b-11e9-afda-96f40a16177b in namespace e2e-tests-emptydir-wrapper-jw29n, will wait for the garbage collector to delete the pods
Jul 15 14:23:47.342: INFO: Deleting ReplicationController wrapped-volume-race-c882cf66-a70b-11e9-afda-96f40a16177b took: 7.497866ms
Jul 15 14:23:47.442: INFO: Terminating ReplicationController wrapped-volume-race-c882cf66-a70b-11e9-afda-96f40a16177b pods took: 100.304369ms
STEP: Creating RC which spawns configmap-volume pods
Jul 15 14:24:26.500: INFO: Pod name wrapped-volume-race-3fbeefc9-a70c-11e9-afda-96f40a16177b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3fbeefc9-a70c-11e9-afda-96f40a16177b in namespace e2e-tests-emptydir-wrapper-jw29n, will wait for the garbage collector to delete the pods
Jul 15 14:27:46.610: INFO: Deleting ReplicationController wrapped-volume-race-3fbeefc9-a70c-11e9-afda-96f40a16177b took: 12.83013ms
Jul 15 14:27:46.710: INFO: Terminating ReplicationController wrapped-volume-race-3fbeefc9-a70c-11e9-afda-96f40a16177b pods took: 100.360007ms
STEP: Creating RC which spawns configmap-volume pods
Jul 15 14:28:29.033: INFO: Pod name wrapped-volume-race-d0725bc4-a70c-11e9-afda-96f40a16177b: Found 0 pods out of 5
Jul 15 14:28:34.046: INFO: Pod name wrapped-volume-race-d0725bc4-a70c-11e9-afda-96f40a16177b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d0725bc4-a70c-11e9-afda-96f40a16177b in namespace e2e-tests-emptydir-wrapper-jw29n, will wait for the garbage collector to delete the pods
Jul 15 14:31:28.167: INFO: Deleting ReplicationController wrapped-volume-race-d0725bc4-a70c-11e9-afda-96f40a16177b took: 8.61464ms
Jul 15 14:31:28.267: INFO: Terminating ReplicationController wrapped-volume-race-d0725bc4-a70c-11e9-afda-96f40a16177b pods took: 100.268765ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:32:08.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-jw29n" for this suite.
Jul 15 14:32:14.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:32:14.738: INFO: namespace: e2e-tests-emptydir-wrapper-jw29n, resource: bindings, ignored listing per whitelist
Jul 15 14:32:17.025: INFO: namespace e2e-tests-emptydir-wrapper-jw29n deletion completed in 8.381988252s

• [SLOW TEST:671.125 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:32:17.025: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul 15 14:32:17.126: INFO: Waiting up to 5m0s for pod "pod-58682a70-a70d-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-db95w" to be "success or failure"
Jul 15 14:32:17.132: INFO: Pod "pod-58682a70-a70d-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.640752ms
Jul 15 14:32:19.135: INFO: Pod "pod-58682a70-a70d-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007025369s
STEP: Saw pod success
Jul 15 14:32:19.136: INFO: Pod "pod-58682a70-a70d-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:32:19.139: INFO: Trying to get logs from node i-x8osldkx pod pod-58682a70-a70d-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 14:32:19.160: INFO: Waiting for pod pod-58682a70-a70d-11e9-afda-96f40a16177b to disappear
Jul 15 14:32:19.163: INFO: Pod pod-58682a70-a70d-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:32:19.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-db95w" for this suite.
Jul 15 14:32:25.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:32:26.356: INFO: namespace: e2e-tests-emptydir-db95w, resource: bindings, ignored listing per whitelist
Jul 15 14:32:27.551: INFO: namespace e2e-tests-emptydir-db95w deletion completed in 8.382989071s

• [SLOW TEST:10.526 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:32:27.551: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-plww
STEP: Creating a pod to test atomic-volume-subpath
Jul 15 14:32:27.669: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-plww" in namespace "e2e-tests-subpath-bhmlp" to be "success or failure"
Jul 15 14:32:27.674: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Pending", Reason="", readiness=false. Elapsed: 4.419969ms
Jul 15 14:32:29.679: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009812412s
Jul 15 14:32:31.682: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Running", Reason="", readiness=false. Elapsed: 4.013163255s
Jul 15 14:32:33.686: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Running", Reason="", readiness=false. Elapsed: 6.017172601s
Jul 15 14:32:35.690: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Running", Reason="", readiness=false. Elapsed: 8.020849724s
Jul 15 14:32:37.694: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Running", Reason="", readiness=false. Elapsed: 10.024685247s
Jul 15 14:32:39.697: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Running", Reason="", readiness=false. Elapsed: 12.027714277s
Jul 15 14:32:41.701: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Running", Reason="", readiness=false. Elapsed: 14.03166151s
Jul 15 14:32:43.707: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Running", Reason="", readiness=false. Elapsed: 16.03795542s
Jul 15 14:32:45.711: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Running", Reason="", readiness=false. Elapsed: 18.041385958s
Jul 15 14:32:47.714: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Running", Reason="", readiness=false. Elapsed: 20.044452374s
Jul 15 14:32:49.716: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Running", Reason="", readiness=false. Elapsed: 22.047150524s
Jul 15 14:32:51.720: INFO: Pod "pod-subpath-test-downwardapi-plww": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.050640831s
STEP: Saw pod success
Jul 15 14:32:51.720: INFO: Pod "pod-subpath-test-downwardapi-plww" satisfied condition "success or failure"
Jul 15 14:32:51.723: INFO: Trying to get logs from node i-tkuhh2hc pod pod-subpath-test-downwardapi-plww container test-container-subpath-downwardapi-plww: <nil>
STEP: delete the pod
Jul 15 14:32:51.754: INFO: Waiting for pod pod-subpath-test-downwardapi-plww to disappear
Jul 15 14:32:51.757: INFO: Pod pod-subpath-test-downwardapi-plww no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-plww
Jul 15 14:32:51.757: INFO: Deleting pod "pod-subpath-test-downwardapi-plww" in namespace "e2e-tests-subpath-bhmlp"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:32:51.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-bhmlp" for this suite.
Jul 15 14:32:57.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:32:57.905: INFO: namespace: e2e-tests-subpath-bhmlp, resource: bindings, ignored listing per whitelist
Jul 15 14:33:00.155: INFO: namespace e2e-tests-subpath-bhmlp deletion completed in 8.390827364s

• [SLOW TEST:32.604 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:33:00.157: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 14:33:00.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-pk5br'
Jul 15 14:33:01.095: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 15 14:33:01.095: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Jul 15 14:33:03.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-pk5br'
Jul 15 14:33:03.284: INFO: stderr: ""
Jul 15 14:33:03.284: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:33:03.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pk5br" for this suite.
Jul 15 14:33:25.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:33:25.889: INFO: namespace: e2e-tests-kubectl-pk5br, resource: bindings, ignored listing per whitelist
Jul 15 14:33:27.689: INFO: namespace e2e-tests-kubectl-pk5br deletion completed in 24.39273954s

• [SLOW TEST:27.533 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:33:27.690: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jul 15 14:33:27.790: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul 15 14:33:27.802: INFO: Waiting for terminating namespaces to be deleted...
Jul 15 14:33:27.805: INFO: 
Logging pods the kubelet thinks is on node i-tkuhh2hc before test
Jul 15 14:33:27.827: INFO: ks-sonarqube-sonarqube-7b48f4c664-6zvz7 from kubesphere-devops-system started at 2019-07-15 08:42:50 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.827: INFO: 	Container sonarqube ready: true, restart count 5
Jul 15 14:33:27.827: INFO: logging-fluentbit-operator-77ff6dbc78-b5w67 from kubesphere-logging-system started at 2019-07-15 08:46:24 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.827: INFO: 	Container fluentbit-operator ready: true, restart count 0
Jul 15 14:33:27.827: INFO: istio-galley-689b548d98-qkcjf from istio-system started at 2019-07-15 08:49:24 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.827: INFO: 	Container galley ready: true, restart count 0
Jul 15 14:33:27.827: INFO: istio-pilot-9685dfc4b-n7ltn from istio-system started at 2019-07-15 08:49:39 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.827: INFO: 	Container discovery ready: true, restart count 0
Jul 15 14:33:27.827: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:33:27.827: INFO: default-http-backend-96d94689d-bnkh7 from kubesphere-controls-system started at 2019-07-15 08:45:29 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.827: INFO: 	Container default-http-backend ready: true, restart count 0
Jul 15 14:33:27.827: INFO: elasticsearch-logging-data-0 from kubesphere-logging-system started at 2019-07-15 08:46:58 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.827: INFO: 	Container elasticsearch ready: true, restart count 0
Jul 15 14:33:27.827: INFO: istio-telemetry-758d9c786f-45wzg from istio-system started at 2019-07-15 08:49:24 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.827: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:33:27.827: INFO: 	Container mixer ready: true, restart count 2
Jul 15 14:33:27.827: INFO: jaeger-query-7764db45bb-926v6 from istio-system started at 2019-07-15 08:56:01 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.827: INFO: 	Container jaeger-agent ready: true, restart count 0
Jul 15 14:33:27.827: INFO: 	Container jaeger-query ready: true, restart count 0
Jul 15 14:33:27.827: INFO: openpitrix-cluster-db-ctrl-job-nvphh from openpitrix-system started at 2019-07-15 08:55:16 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.827: INFO: 	Container openpitrix-cluster-db-ctrl ready: false, restart count 0
Jul 15 14:33:27.828: INFO: openpitrix-job-db-ctrl-job-qph77 from openpitrix-system started at 2019-07-15 08:55:17 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container openpitrix-job-db-ctrl ready: false, restart count 0
Jul 15 14:33:27.828: INFO: openpitrix-repo-indexer-deployment-d975ddff6-rqd88 from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container openpitrix-repo-indexer ready: true, restart count 0
Jul 15 14:33:27.828: INFO: ks-docs-77c4796dc9-npkwv from kubesphere-system started at 2019-07-15 08:46:19 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container ks-docs ready: true, restart count 0
Jul 15 14:33:27.828: INFO: alerting-executor-75c664c66d-29hfc from kubesphere-alerting-system started at 2019-07-15 08:48:47 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container alerting-adapter ready: true, restart count 0
Jul 15 14:33:27.828: INFO: 	Container alerting-executor ready: true, restart count 0
Jul 15 14:33:27.828: INFO: csi-qingcloud-node-76gtb from kube-system started at 2019-07-15 08:42:33 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container csi-qingcloud ready: true, restart count 0
Jul 15 14:33:27.828: INFO: 	Container driver-registrar ready: true, restart count 0
Jul 15 14:33:27.828: INFO: prometheus-k8s-system-0 from kubesphere-monitoring-system started at 2019-07-15 08:46:40 +0000 UTC (3 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 14:33:27.828: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 14:33:27.828: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 14:33:27.828: INFO: sonobuoy from heptio-sonobuoy started at 2019-07-15 13:17:35 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul 15 14:33:27.828: INFO: openpitrix-repo-manager-deployment-85fcf79667-wx9bf from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container openpitrix-repo-manager ready: true, restart count 0
Jul 15 14:33:27.828: INFO: istio-ingressgateway-5477b7ffd9-lt2jc from istio-system started at 2019-07-15 08:49:24 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:33:27.828: INFO: calico-node-b8m4t from kube-system started at 2019-07-15 08:42:22 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 14:33:27.828: INFO: 	Container install-cni ready: true, restart count 0
Jul 15 14:33:27.828: INFO: alerting-client-5bb5d87f65-6l8ng from kubesphere-alerting-system started at 2019-07-15 08:48:49 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container alerting-client ready: true, restart count 0
Jul 15 14:33:27.828: INFO: kubectl-admin-d784b7777-9pzv2 from kubesphere-controls-system started at 2019-07-15 08:47:08 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container kubectl ready: true, restart count 0
Jul 15 14:33:27.828: INFO: notification-deployment-6b78b697d7-r8cdn from kubesphere-alerting-system started at 2019-07-15 08:48:45 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container notification ready: true, restart count 0
Jul 15 14:33:27.828: INFO: sonobuoy-systemd-logs-daemon-set-3c9f017d4c504b82-9mlvz from heptio-sonobuoy started at 2019-07-15 13:17:54 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 15 14:33:27.828: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 15 14:33:27.828: INFO: openpitrix-category-manager-deployment-bf4676856-6wfl6 from openpitrix-system started at 2019-07-15 08:45:13 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container openpitrix-category-manager ready: true, restart count 0
Jul 15 14:33:27.828: INFO: notification-db-ctrl-job-9qrl4 from kubesphere-alerting-system started at 2019-07-15 08:55:27 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container notification-db-ctrl ready: false, restart count 0
Jul 15 14:33:27.828: INFO: istio-policy-b87497cf4-n4n9m from istio-system started at 2019-07-15 08:49:39 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:33:27.828: INFO: 	Container mixer ready: true, restart count 1
Jul 15 14:33:27.828: INFO: openpitrix-iam-service-deployment-6bc78587f-bsxsl from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container openpitrix-iam-service ready: true, restart count 5
Jul 15 14:33:27.828: INFO: node-exporter-f75fb from kubesphere-monitoring-system started at 2019-07-15 08:46:12 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 15 14:33:27.828: INFO: 	Container node-exporter ready: true, restart count 0
Jul 15 14:33:27.828: INFO: ks-devops-db-ctrl-job-nmhx5 from kubesphere-devops-system started at 2019-07-15 08:55:23 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container devops-db-ctrl ready: false, restart count 0
Jul 15 14:33:27.828: INFO: openpitrix-app-manager-deployment-77bf8749dc-wxxzl from openpitrix-system started at 2019-07-15 08:45:13 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container openpitrix-app-manager ready: true, restart count 0
Jul 15 14:33:27.828: INFO: prometheus-k8s-1 from kubesphere-monitoring-system started at 2019-07-15 08:46:42 +0000 UTC (3 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 14:33:27.828: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 14:33:27.828: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 14:33:27.828: INFO: openpitrix-db-init-job-qfxfx from openpitrix-system started at 2019-07-15 08:55:18 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container openpitrix-db-init ready: false, restart count 0
Jul 15 14:33:27.828: INFO: alerting-db-init-job-z7whr from kubesphere-alerting-system started at 2019-07-15 08:52:09 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container alerting-db-init ready: false, restart count 0
Jul 15 14:33:27.828: INFO: uc-jenkins-update-center-598f8d6549-5898r from kubesphere-devops-system started at 2019-07-15 08:49:15 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container jenkins-update-center ready: true, restart count 0
Jul 15 14:33:27.828: INFO: openpitrix-runtime-db-ctrl-job-ljjls from openpitrix-system started at 2019-07-15 08:55:17 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container openpitrix-runtime-db-ctrl ready: false, restart count 0
Jul 15 14:33:27.828: INFO: kube-proxy-dkcd8 from kube-system started at 2019-07-15 08:42:33 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 15 14:33:27.828: INFO: openpitrix-etcd-deployment-54bc9bb948-8qmxl from openpitrix-system started at 2019-07-15 08:45:25 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container openpitrix-etcd ready: true, restart count 0
Jul 15 14:33:27.828: INFO: fluent-bit-2xfkw from kubesphere-logging-system started at 2019-07-15 08:46:28 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container config-reloader ready: true, restart count 0
Jul 15 14:33:27.828: INFO: 	Container fluent-bit ready: true, restart count 0
Jul 15 14:33:27.828: INFO: jaeger-operator-8cb967c86-wjtqg from istio-system started at 2019-07-15 08:55:58 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container jaeger-operator ready: true, restart count 0
Jul 15 14:33:27.828: INFO: openpitrix-runtime-manager-deployment-9c4bb7d5-tsz6x from openpitrix-system started at 2019-07-15 08:45:15 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.828: INFO: 	Container openpitrix-runtime-manager ready: true, restart count 0
Jul 15 14:33:27.828: INFO: 
Logging pods the kubelet thinks is on node i-x8osldkx before test
Jul 15 14:33:27.852: INFO: istio-init-crd-11-gcd85 from istio-system started at 2019-07-15 08:45:27 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.852: INFO: 	Container istio-init-crd-11 ready: false, restart count 0
Jul 15 14:33:27.852: INFO: alerting-watcher-5d857d87db-zwvvf from kubesphere-alerting-system started at 2019-07-15 08:48:45 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.852: INFO: 	Container alerting-watcher ready: true, restart count 0
Jul 15 14:33:27.852: INFO: jaeger-collector-7c567ccbbb-sl7ng from istio-system started at 2019-07-15 08:55:58 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.852: INFO: 	Container jaeger-collector ready: true, restart count 0
Jul 15 14:33:27.852: INFO: ks-sonarqube-postgresql-5d58f5574b-2bc4v from kubesphere-devops-system started at 2019-07-15 08:43:01 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.852: INFO: 	Container ks-sonarqube-postgresql ready: true, restart count 0
Jul 15 14:33:27.852: INFO: istio-init-crd-10-5dzhz from istio-system started at 2019-07-15 08:45:27 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.852: INFO: 	Container istio-init-crd-10 ready: false, restart count 0
Jul 15 14:33:27.852: INFO: elasticsearch-logging-discovery-0 from kubesphere-logging-system started at 2019-07-15 08:46:44 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.852: INFO: 	Container elasticsearch ready: true, restart count 0
Jul 15 14:33:27.852: INFO: ks-devops-db-init-job-8s8ln from kubesphere-devops-system started at 2019-07-15 08:55:18 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.852: INFO: 	Container devops-db-init ready: false, restart count 0
Jul 15 14:33:27.853: INFO: elasticsearch-logging-data-1 from kubesphere-logging-system started at 2019-07-15 08:48:34 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container elasticsearch ready: true, restart count 0
Jul 15 14:33:27.853: INFO: istio-ingressgateway-5477b7ffd9-2qgx5 from istio-system started at 2019-07-15 08:49:35 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:33:27.853: INFO: openpitrix-app-db-ctrl-job-jjvlr from openpitrix-system started at 2019-07-15 08:55:11 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container openpitrix-app-db-ctrl ready: false, restart count 0
Jul 15 14:33:27.853: INFO: csi-qingcloud-node-fvwds from kube-system started at 2019-07-15 08:42:32 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container csi-qingcloud ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container driver-registrar ready: true, restart count 0
Jul 15 14:33:27.853: INFO: metrics-server-85d786dd4d-lgw4d from kube-system started at 2019-07-15 08:45:40 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container metrics-server ready: true, restart count 0
Jul 15 14:33:27.853: INFO: alerting-executor-75c664c66d-6mzjv from kubesphere-alerting-system started at 2019-07-15 08:48:45 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container alerting-adapter ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container alerting-executor ready: true, restart count 0
Jul 15 14:33:27.853: INFO: openpitrix-task-manager-deployment-5f8c7cdd64-96csg from openpitrix-system started at 2019-07-15 08:45:15 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container openpitrix-task-manager ready: true, restart count 0
Jul 15 14:33:27.853: INFO: prometheus-k8s-system-1 from kubesphere-monitoring-system started at 2019-07-15 08:46:42 +0000 UTC (3 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 14:33:27.853: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 14:33:27.853: INFO: ks-jenkins-887ddbbbc-5mwvc from kubesphere-devops-system started at 2019-07-15 08:55:59 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container ks-jenkins ready: true, restart count 0
Jul 15 14:33:27.853: INFO: sonobuoy-systemd-logs-daemon-set-3c9f017d4c504b82-hn592 from heptio-sonobuoy started at 2019-07-15 13:17:54 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jul 15 14:33:27.853: INFO: 	Container systemd-logs ready: true, restart count 1
Jul 15 14:33:27.853: INFO: openpitrix-cluster-manager-deployment-745b57798d-nhkq4 from openpitrix-system started at 2019-07-15 08:45:13 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container openpitrix-cluster-manager ready: true, restart count 0
Jul 15 14:33:27.853: INFO: prometheus-operator-7d94949cf8-lzvm6 from kubesphere-monitoring-system started at 2019-07-15 08:46:11 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container prometheus-operator ready: true, restart count 0
Jul 15 14:33:27.853: INFO: alerting-db-ctrl-job-jcxcm from kubesphere-alerting-system started at 2019-07-15 08:55:28 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container alerting-db-ctrl ready: false, restart count 0
Jul 15 14:33:27.853: INFO: calico-node-ssbj9 from kube-system started at 2019-07-15 08:42:21 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container calico-node ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container install-cni ready: true, restart count 0
Jul 15 14:33:27.853: INFO: s2ioperator-0 from kubesphere-devops-system started at 2019-07-15 08:45:53 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container manager ready: true, restart count 0
Jul 15 14:33:27.853: INFO: istio-galley-689b548d98-jqjbz from istio-system started at 2019-07-15 08:49:19 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container galley ready: true, restart count 0
Jul 15 14:33:27.853: INFO: istio-telemetry-758d9c786f-ppdc7 from istio-system started at 2019-07-15 08:49:35 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container mixer ready: true, restart count 1
Jul 15 14:33:27.853: INFO: fluent-bit-h2xsj from kubesphere-logging-system started at 2019-07-15 08:46:28 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container config-reloader ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container fluent-bit ready: true, restart count 0
Jul 15 14:33:27.853: INFO: prometheus-k8s-0 from kubesphere-monitoring-system started at 2019-07-15 08:46:41 +0000 UTC (3 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container prometheus ready: true, restart count 1
Jul 15 14:33:27.853: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Jul 15 14:33:27.853: INFO: istio-pilot-9685dfc4b-jdn8c from istio-system started at 2019-07-15 08:49:19 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container discovery ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:33:27.853: INFO: openpitrix-minio-deployment-84d5f9c94b-ztlsm from openpitrix-system started at 2019-07-15 08:45:35 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container openpitrix-minio ready: true, restart count 0
Jul 15 14:33:27.853: INFO: istio-sidecar-injector-74666b458c-tvhwg from istio-system started at 2019-07-15 08:49:19 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container sidecar-injector-webhook ready: true, restart count 0
Jul 15 14:33:27.853: INFO: node-exporter-n94q2 from kubesphere-monitoring-system started at 2019-07-15 08:46:12 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container node-exporter ready: true, restart count 0
Jul 15 14:33:27.853: INFO: notification-db-init-job-65tz2 from kubesphere-alerting-system started at 2019-07-15 08:55:23 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container notification-db-init ready: false, restart count 0
Jul 15 14:33:27.853: INFO: kube-state-metrics-7f9c44c88-f27x7 from kubesphere-monitoring-system started at 2019-07-15 08:53:01 +0000 UTC (4 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container addon-resizer ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container kube-rbac-proxy-main ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container kube-rbac-proxy-self ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jul 15 14:33:27.853: INFO: kube-proxy-wfgmw from kube-system started at 2019-07-15 08:42:32 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container kube-proxy ready: true, restart count 0
Jul 15 14:33:27.853: INFO: alerting-manager-67c5f9c797-tcglm from kubesphere-alerting-system started at 2019-07-15 08:48:46 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container alerting-manager ready: true, restart count 0
Jul 15 14:33:27.853: INFO: istio-policy-b87497cf4-r6hq4 from istio-system started at 2019-07-15 08:49:19 +0000 UTC (2 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container istio-proxy ready: true, restart count 0
Jul 15 14:33:27.853: INFO: 	Container mixer ready: true, restart count 2
Jul 15 14:33:27.853: INFO: openpitrix-iam-db-ctrl-job-whtxp from openpitrix-system started at 2019-07-15 08:55:12 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container openpitrix-iam-db-ctrl ready: false, restart count 0
Jul 15 14:33:27.853: INFO: openpitrix-repo-db-ctrl-job-p6xkz from openpitrix-system started at 2019-07-15 08:55:13 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container openpitrix-repo-db-ctrl ready: false, restart count 0
Jul 15 14:33:27.853: INFO: openpitrix-api-gateway-deployment-585678b9b8-nhzmn from openpitrix-system started at 2019-07-15 08:45:12 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container openpitrix-api-gateway ready: true, restart count 0
Jul 15 14:33:27.853: INFO: openpitrix-job-manager-deployment-577649544c-jwgvs from openpitrix-system started at 2019-07-15 08:45:14 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container openpitrix-job-manager ready: true, restart count 0
Jul 15 14:33:27.853: INFO: openpitrix-task-db-ctrl-job-pf7f4 from openpitrix-system started at 2019-07-15 08:55:14 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container openpitrix-task-db-ctrl ready: false, restart count 0
Jul 15 14:33:27.853: INFO: istio-citadel-5f886dc9b4-h94c9 from istio-system started at 2019-07-15 08:49:19 +0000 UTC (1 container statuses recorded)
Jul 15 14:33:27.853: INFO: 	Container citadel ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-84f92cd0-a70d-11e9-afda-96f40a16177b 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-84f92cd0-a70d-11e9-afda-96f40a16177b off the node i-tkuhh2hc
STEP: verifying the node doesn't have the label kubernetes.io/e2e-84f92cd0-a70d-11e9-afda-96f40a16177b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:33:33.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-d88x6" for this suite.
Jul 15 14:33:41.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:33:43.888: INFO: namespace: e2e-tests-sched-pred-d88x6, resource: bindings, ignored listing per whitelist
Jul 15 14:33:44.337: INFO: namespace e2e-tests-sched-pred-d88x6 deletion completed in 10.38945293s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.648 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:33:44.340: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8c7582e4-a70d-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 14:33:44.457: INFO: Waiting up to 5m0s for pod "pod-configmaps-8c76601b-a70d-11e9-afda-96f40a16177b" in namespace "e2e-tests-configmap-sgxp9" to be "success or failure"
Jul 15 14:33:44.465: INFO: Pod "pod-configmaps-8c76601b-a70d-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.240755ms
Jul 15 14:33:46.471: INFO: Pod "pod-configmaps-8c76601b-a70d-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013722334s
Jul 15 14:33:48.479: INFO: Pod "pod-configmaps-8c76601b-a70d-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021442357s
STEP: Saw pod success
Jul 15 14:33:48.479: INFO: Pod "pod-configmaps-8c76601b-a70d-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:33:48.483: INFO: Trying to get logs from node i-x8osldkx pod pod-configmaps-8c76601b-a70d-11e9-afda-96f40a16177b container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 14:33:48.509: INFO: Waiting for pod pod-configmaps-8c76601b-a70d-11e9-afda-96f40a16177b to disappear
Jul 15 14:33:48.524: INFO: Pod pod-configmaps-8c76601b-a70d-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:33:48.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sgxp9" for this suite.
Jul 15 14:33:54.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:33:54.570: INFO: namespace: e2e-tests-configmap-sgxp9, resource: bindings, ignored listing per whitelist
Jul 15 14:33:56.919: INFO: namespace e2e-tests-configmap-sgxp9 deletion completed in 8.387895629s

• [SLOW TEST:12.580 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:33:56.920: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 14:33:57.025: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93f34fd2-a70d-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-q82fb" to be "success or failure"
Jul 15 14:33:57.032: INFO: Pod "downwardapi-volume-93f34fd2-a70d-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.481035ms
Jul 15 14:33:59.035: INFO: Pod "downwardapi-volume-93f34fd2-a70d-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010223386s
STEP: Saw pod success
Jul 15 14:33:59.035: INFO: Pod "downwardapi-volume-93f34fd2-a70d-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:33:59.037: INFO: Trying to get logs from node i-tkuhh2hc pod downwardapi-volume-93f34fd2-a70d-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 14:33:59.058: INFO: Waiting for pod downwardapi-volume-93f34fd2-a70d-11e9-afda-96f40a16177b to disappear
Jul 15 14:33:59.059: INFO: Pod downwardapi-volume-93f34fd2-a70d-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:33:59.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q82fb" for this suite.
Jul 15 14:34:05.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:34:05.859: INFO: namespace: e2e-tests-projected-q82fb, resource: bindings, ignored listing per whitelist
Jul 15 14:34:07.457: INFO: namespace e2e-tests-projected-q82fb deletion completed in 8.394921496s

• [SLOW TEST:10.538 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:34:07.459: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jul 15 14:34:07.552: INFO: Waiting up to 5m0s for pod "downward-api-9a3ac997-a70d-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-9j4ft" to be "success or failure"
Jul 15 14:34:07.556: INFO: Pod "downward-api-9a3ac997-a70d-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074115ms
Jul 15 14:34:09.558: INFO: Pod "downward-api-9a3ac997-a70d-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006685222s
STEP: Saw pod success
Jul 15 14:34:09.558: INFO: Pod "downward-api-9a3ac997-a70d-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:34:09.560: INFO: Trying to get logs from node i-tkuhh2hc pod downward-api-9a3ac997-a70d-11e9-afda-96f40a16177b container dapi-container: <nil>
STEP: delete the pod
Jul 15 14:34:09.588: INFO: Waiting for pod downward-api-9a3ac997-a70d-11e9-afda-96f40a16177b to disappear
Jul 15 14:34:09.595: INFO: Pod downward-api-9a3ac997-a70d-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:34:09.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9j4ft" for this suite.
Jul 15 14:34:15.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:34:15.662: INFO: namespace: e2e-tests-downward-api-9j4ft, resource: bindings, ignored listing per whitelist
Jul 15 14:34:17.981: INFO: namespace e2e-tests-downward-api-9j4ft deletion completed in 8.382318922s

• [SLOW TEST:10.522 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:34:17.982: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-bfrxv/configmap-test-a083567d-a70d-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 14:34:18.100: INFO: Waiting up to 5m0s for pod "pod-configmaps-a0842f93-a70d-11e9-afda-96f40a16177b" in namespace "e2e-tests-configmap-bfrxv" to be "success or failure"
Jul 15 14:34:18.103: INFO: Pod "pod-configmaps-a0842f93-a70d-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.187226ms
Jul 15 14:34:20.107: INFO: Pod "pod-configmaps-a0842f93-a70d-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006555591s
STEP: Saw pod success
Jul 15 14:34:20.107: INFO: Pod "pod-configmaps-a0842f93-a70d-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:34:20.109: INFO: Trying to get logs from node i-tkuhh2hc pod pod-configmaps-a0842f93-a70d-11e9-afda-96f40a16177b container env-test: <nil>
STEP: delete the pod
Jul 15 14:34:20.127: INFO: Waiting for pod pod-configmaps-a0842f93-a70d-11e9-afda-96f40a16177b to disappear
Jul 15 14:34:20.129: INFO: Pod pod-configmaps-a0842f93-a70d-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:34:20.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bfrxv" for this suite.
Jul 15 14:34:26.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:34:26.368: INFO: namespace: e2e-tests-configmap-bfrxv, resource: bindings, ignored listing per whitelist
Jul 15 14:34:28.526: INFO: namespace e2e-tests-configmap-bfrxv deletion completed in 8.392533443s

• [SLOW TEST:10.544 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:34:28.536: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-a6cad0b9-a70d-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 14:34:28.637: INFO: Waiting up to 5m0s for pod "pod-secrets-a6cb9956-a70d-11e9-afda-96f40a16177b" in namespace "e2e-tests-secrets-ljpvn" to be "success or failure"
Jul 15 14:34:28.639: INFO: Pod "pod-secrets-a6cb9956-a70d-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.713143ms
Jul 15 14:34:30.646: INFO: Pod "pod-secrets-a6cb9956-a70d-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008386134s
Jul 15 14:34:32.652: INFO: Pod "pod-secrets-a6cb9956-a70d-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015160101s
STEP: Saw pod success
Jul 15 14:34:32.652: INFO: Pod "pod-secrets-a6cb9956-a70d-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:34:32.657: INFO: Trying to get logs from node i-x8osldkx pod pod-secrets-a6cb9956-a70d-11e9-afda-96f40a16177b container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 14:34:32.680: INFO: Waiting for pod pod-secrets-a6cb9956-a70d-11e9-afda-96f40a16177b to disappear
Jul 15 14:34:32.683: INFO: Pod pod-secrets-a6cb9956-a70d-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:34:32.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ljpvn" for this suite.
Jul 15 14:34:38.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:34:39.987: INFO: namespace: e2e-tests-secrets-ljpvn, resource: bindings, ignored listing per whitelist
Jul 15 14:34:41.087: INFO: namespace e2e-tests-secrets-ljpvn deletion completed in 8.397449539s

• [SLOW TEST:12.551 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:34:41.088: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-ae49c2a8-a70d-11e9-afda-96f40a16177b
STEP: Creating secret with name secret-projected-all-test-volume-ae49c0eb-a70d-11e9-afda-96f40a16177b
STEP: Creating a pod to test Check all projections for projected volume plugin
Jul 15 14:34:41.217: INFO: Waiting up to 5m0s for pod "projected-volume-ae49c09e-a70d-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-dfc5j" to be "success or failure"
Jul 15 14:34:41.222: INFO: Pod "projected-volume-ae49c09e-a70d-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.296338ms
Jul 15 14:34:43.226: INFO: Pod "projected-volume-ae49c09e-a70d-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008540436s
STEP: Saw pod success
Jul 15 14:34:43.226: INFO: Pod "projected-volume-ae49c09e-a70d-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:34:43.228: INFO: Trying to get logs from node i-tkuhh2hc pod projected-volume-ae49c09e-a70d-11e9-afda-96f40a16177b container projected-all-volume-test: <nil>
STEP: delete the pod
Jul 15 14:34:43.249: INFO: Waiting for pod projected-volume-ae49c09e-a70d-11e9-afda-96f40a16177b to disappear
Jul 15 14:34:43.253: INFO: Pod projected-volume-ae49c09e-a70d-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:34:43.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dfc5j" for this suite.
Jul 15 14:34:49.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:34:49.399: INFO: namespace: e2e-tests-projected-dfc5j, resource: bindings, ignored listing per whitelist
Jul 15 14:34:51.659: INFO: namespace e2e-tests-projected-dfc5j deletion completed in 8.396837845s

• [SLOW TEST:10.571 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:34:51.660: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b493d2ce-a70d-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 14:34:51.775: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b4946dd1-a70d-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-7llhl" to be "success or failure"
Jul 15 14:34:51.778: INFO: Pod "pod-projected-configmaps-b4946dd1-a70d-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.024504ms
Jul 15 14:34:53.781: INFO: Pod "pod-projected-configmaps-b4946dd1-a70d-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006327328s
STEP: Saw pod success
Jul 15 14:34:53.781: INFO: Pod "pod-projected-configmaps-b4946dd1-a70d-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:34:53.784: INFO: Trying to get logs from node i-tkuhh2hc pod pod-projected-configmaps-b4946dd1-a70d-11e9-afda-96f40a16177b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 14:34:53.802: INFO: Waiting for pod pod-projected-configmaps-b4946dd1-a70d-11e9-afda-96f40a16177b to disappear
Jul 15 14:34:53.805: INFO: Pod pod-projected-configmaps-b4946dd1-a70d-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:34:53.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7llhl" for this suite.
Jul 15 14:34:59.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:34:59.854: INFO: namespace: e2e-tests-projected-7llhl, resource: bindings, ignored listing per whitelist
Jul 15 14:35:02.189: INFO: namespace e2e-tests-projected-7llhl deletion completed in 8.379645003s

• [SLOW TEST:10.529 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:35:02.189: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:35:02.456: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"baf1d27c-a70d-11e9-8341-525422241ab4", Controller:(*bool)(0xc00164be9e), BlockOwnerDeletion:(*bool)(0xc00164be9f)}}
Jul 15 14:35:02.472: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"baef3181-a70d-11e9-8341-525422241ab4", Controller:(*bool)(0xc000fea7d2), BlockOwnerDeletion:(*bool)(0xc000fea7d3)}}
Jul 15 14:35:02.517: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"baf0457a-a70d-11e9-8341-525422241ab4", Controller:(*bool)(0xc0019425be), BlockOwnerDeletion:(*bool)(0xc0019425bf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:35:07.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ps942" for this suite.
Jul 15 14:35:13.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:35:13.597: INFO: namespace: e2e-tests-gc-ps942, resource: bindings, ignored listing per whitelist
Jul 15 14:35:15.922: INFO: namespace e2e-tests-gc-ps942 deletion completed in 8.386188882s

• [SLOW TEST:13.733 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:35:15.924: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-c30ada37-a70d-11e9-afda-96f40a16177b
STEP: Creating secret with name s-test-opt-upd-c30ada89-a70d-11e9-afda-96f40a16177b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c30ada37-a70d-11e9-afda-96f40a16177b
STEP: Updating secret s-test-opt-upd-c30ada89-a70d-11e9-afda-96f40a16177b
STEP: Creating secret with name s-test-opt-create-c30adaa3-a70d-11e9-afda-96f40a16177b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:36:30.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wrkjg" for this suite.
Jul 15 14:36:52.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:36:53.787: INFO: namespace: e2e-tests-projected-wrkjg, resource: bindings, ignored listing per whitelist
Jul 15 14:36:55.037: INFO: namespace e2e-tests-projected-wrkjg deletion completed in 24.380155221s

• [SLOW TEST:99.114 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:36:55.038: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Jul 15 14:36:55.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-5mbxn'
Jul 15 14:36:55.548: INFO: stderr: ""
Jul 15 14:36:55.548: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jul 15 14:36:56.551: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:36:56.551: INFO: Found 0 / 1
Jul 15 14:36:57.607: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:36:57.607: INFO: Found 1 / 1
Jul 15 14:36:57.607: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul 15 14:36:57.610: INFO: Selector matched 1 pods for map[app:redis]
Jul 15 14:36:57.610: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jul 15 14:36:57.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 logs redis-master-zm2vj redis-master --namespace=e2e-tests-kubectl-5mbxn'
Jul 15 14:36:57.803: INFO: stderr: ""
Jul 15 14:36:57.803: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jul 14:36:56.738 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jul 14:36:56.738 # Server started, Redis version 3.2.12\n1:M 15 Jul 14:36:56.738 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jul 14:36:56.738 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jul 15 14:36:57.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 log redis-master-zm2vj redis-master --namespace=e2e-tests-kubectl-5mbxn --tail=1'
Jul 15 14:36:57.926: INFO: stderr: ""
Jul 15 14:36:57.926: INFO: stdout: "1:M 15 Jul 14:36:56.738 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jul 15 14:36:57.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 log redis-master-zm2vj redis-master --namespace=e2e-tests-kubectl-5mbxn --limit-bytes=1'
Jul 15 14:36:58.074: INFO: stderr: ""
Jul 15 14:36:58.074: INFO: stdout: " "
STEP: exposing timestamps
Jul 15 14:36:58.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 log redis-master-zm2vj redis-master --namespace=e2e-tests-kubectl-5mbxn --tail=1 --timestamps'
Jul 15 14:36:58.212: INFO: stderr: ""
Jul 15 14:36:58.212: INFO: stdout: "2019-07-15T14:36:56.740444532Z 1:M 15 Jul 14:36:56.738 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jul 15 14:37:00.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 log redis-master-zm2vj redis-master --namespace=e2e-tests-kubectl-5mbxn --since=1s'
Jul 15 14:37:00.869: INFO: stderr: ""
Jul 15 14:37:00.869: INFO: stdout: ""
Jul 15 14:37:00.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 log redis-master-zm2vj redis-master --namespace=e2e-tests-kubectl-5mbxn --since=24h'
Jul 15 14:37:01.023: INFO: stderr: ""
Jul 15 14:37:01.023: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jul 14:36:56.738 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jul 14:36:56.738 # Server started, Redis version 3.2.12\n1:M 15 Jul 14:36:56.738 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jul 14:36:56.738 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Jul 15 14:37:01.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5mbxn'
Jul 15 14:37:01.157: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul 15 14:37:01.157: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jul 15 14:37:01.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-5mbxn'
Jul 15 14:37:01.287: INFO: stderr: "No resources found.\n"
Jul 15 14:37:01.287: INFO: stdout: ""
Jul 15 14:37:01.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -l name=nginx --namespace=e2e-tests-kubectl-5mbxn -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul 15 14:37:01.410: INFO: stderr: ""
Jul 15 14:37:01.410: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:37:01.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5mbxn" for this suite.
Jul 15 14:37:23.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:37:23.651: INFO: namespace: e2e-tests-kubectl-5mbxn, resource: bindings, ignored listing per whitelist
Jul 15 14:37:25.801: INFO: namespace e2e-tests-kubectl-5mbxn deletion completed in 24.385842244s

• [SLOW TEST:30.763 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:37:25.801: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jul 15 14:37:25.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 create -f - --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:26.316: INFO: stderr: ""
Jul 15 14:37:26.316: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 14:37:26.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:26.491: INFO: stderr: ""
Jul 15 14:37:26.491: INFO: stdout: "update-demo-nautilus-gqbc4 update-demo-nautilus-tn8qh "
Jul 15 14:37:26.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-gqbc4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:26.637: INFO: stderr: ""
Jul 15 14:37:26.638: INFO: stdout: ""
Jul 15 14:37:26.638: INFO: update-demo-nautilus-gqbc4 is created but not running
Jul 15 14:37:31.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:31.760: INFO: stderr: ""
Jul 15 14:37:31.760: INFO: stdout: "update-demo-nautilus-gqbc4 update-demo-nautilus-tn8qh "
Jul 15 14:37:31.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-gqbc4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:31.870: INFO: stderr: ""
Jul 15 14:37:31.870: INFO: stdout: "true"
Jul 15 14:37:31.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-gqbc4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:32.005: INFO: stderr: ""
Jul 15 14:37:32.006: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 14:37:32.006: INFO: validating pod update-demo-nautilus-gqbc4
Jul 15 14:37:32.011: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 14:37:32.011: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 14:37:32.011: INFO: update-demo-nautilus-gqbc4 is verified up and running
Jul 15 14:37:32.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-tn8qh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:32.129: INFO: stderr: ""
Jul 15 14:37:32.129: INFO: stdout: "true"
Jul 15 14:37:32.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-nautilus-tn8qh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:32.248: INFO: stderr: ""
Jul 15 14:37:32.248: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jul 15 14:37:32.248: INFO: validating pod update-demo-nautilus-tn8qh
Jul 15 14:37:32.254: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul 15 14:37:32.254: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul 15 14:37:32.254: INFO: update-demo-nautilus-tn8qh is verified up and running
STEP: rolling-update to new replication controller
Jul 15 14:37:32.261: INFO: scanned /root for discovery docs: <nil>
Jul 15 14:37:32.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:55.904: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jul 15 14:37:55.904: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul 15 14:37:55.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:56.033: INFO: stderr: ""
Jul 15 14:37:56.033: INFO: stdout: "update-demo-kitten-6vhl5 update-demo-kitten-flp8k "
Jul 15 14:37:56.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-kitten-6vhl5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:56.157: INFO: stderr: ""
Jul 15 14:37:56.157: INFO: stdout: "true"
Jul 15 14:37:56.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-kitten-6vhl5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:56.302: INFO: stderr: ""
Jul 15 14:37:56.302: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jul 15 14:37:56.302: INFO: validating pod update-demo-kitten-6vhl5
Jul 15 14:37:56.335: INFO: got data: {
  "image": "kitten.jpg"
}

Jul 15 14:37:56.335: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jul 15 14:37:56.335: INFO: update-demo-kitten-6vhl5 is verified up and running
Jul 15 14:37:56.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-kitten-flp8k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:56.467: INFO: stderr: ""
Jul 15 14:37:56.467: INFO: stdout: "true"
Jul 15 14:37:56.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pods update-demo-kitten-flp8k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6cjx6'
Jul 15 14:37:56.612: INFO: stderr: ""
Jul 15 14:37:56.612: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jul 15 14:37:56.612: INFO: validating pod update-demo-kitten-flp8k
Jul 15 14:37:56.624: INFO: got data: {
  "image": "kitten.jpg"
}

Jul 15 14:37:56.624: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jul 15 14:37:56.624: INFO: update-demo-kitten-flp8k is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:37:56.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6cjx6" for this suite.
Jul 15 14:38:20.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:38:20.681: INFO: namespace: e2e-tests-kubectl-6cjx6, resource: bindings, ignored listing per whitelist
Jul 15 14:38:23.011: INFO: namespace e2e-tests-kubectl-6cjx6 deletion completed in 26.380988311s

• [SLOW TEST:57.210 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:38:23.013: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-328cdec1-a70e-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 14:38:23.110: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-328dc782-a70e-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-hfhb5" to be "success or failure"
Jul 15 14:38:23.120: INFO: Pod "pod-projected-configmaps-328dc782-a70e-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.758967ms
Jul 15 14:38:25.123: INFO: Pod "pod-projected-configmaps-328dc782-a70e-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012778794s
Jul 15 14:38:27.126: INFO: Pod "pod-projected-configmaps-328dc782-a70e-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016678594s
STEP: Saw pod success
Jul 15 14:38:27.127: INFO: Pod "pod-projected-configmaps-328dc782-a70e-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:38:27.130: INFO: Trying to get logs from node i-x8osldkx pod pod-projected-configmaps-328dc782-a70e-11e9-afda-96f40a16177b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 14:38:27.158: INFO: Waiting for pod pod-projected-configmaps-328dc782-a70e-11e9-afda-96f40a16177b to disappear
Jul 15 14:38:27.161: INFO: Pod pod-projected-configmaps-328dc782-a70e-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:38:27.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hfhb5" for this suite.
Jul 15 14:38:33.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:38:33.255: INFO: namespace: e2e-tests-projected-hfhb5, resource: bindings, ignored listing per whitelist
Jul 15 14:38:35.579: INFO: namespace e2e-tests-projected-hfhb5 deletion completed in 8.413153261s

• [SLOW TEST:12.566 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:38:35.579: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jul 15 14:38:39.728: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 14:38:39.730: INFO: Pod pod-with-prestop-http-hook still exists
Jul 15 14:38:41.731: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 14:38:41.733: INFO: Pod pod-with-prestop-http-hook still exists
Jul 15 14:38:43.731: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 14:38:43.734: INFO: Pod pod-with-prestop-http-hook still exists
Jul 15 14:38:45.731: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 14:38:45.734: INFO: Pod pod-with-prestop-http-hook still exists
Jul 15 14:38:47.731: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 14:38:47.734: INFO: Pod pod-with-prestop-http-hook still exists
Jul 15 14:38:49.731: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 14:38:49.735: INFO: Pod pod-with-prestop-http-hook still exists
Jul 15 14:38:51.731: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 14:38:51.734: INFO: Pod pod-with-prestop-http-hook still exists
Jul 15 14:38:53.731: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul 15 14:38:53.735: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:38:53.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-lqnpg" for this suite.
Jul 15 14:39:15.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:39:15.812: INFO: namespace: e2e-tests-container-lifecycle-hook-lqnpg, resource: bindings, ignored listing per whitelist
Jul 15 14:39:18.137: INFO: namespace e2e-tests-container-lifecycle-hook-lqnpg deletion completed in 24.390616025s

• [SLOW TEST:42.558 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:39:18.140: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:39:42.267: INFO: Container started at 2019-07-15 14:39:19 +0000 UTC, pod became ready at 2019-07-15 14:39:40 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:39:42.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9xdgt" for this suite.
Jul 15 14:40:04.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:40:04.335: INFO: namespace: e2e-tests-container-probe-9xdgt, resource: bindings, ignored listing per whitelist
Jul 15 14:40:06.669: INFO: namespace e2e-tests-container-probe-9xdgt deletion completed in 24.395202146s

• [SLOW TEST:48.529 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:40:06.671: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 14:40:06.809: INFO: Waiting up to 5m0s for pod "downwardapi-volume-705ca4a0-a70e-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-mn6jj" to be "success or failure"
Jul 15 14:40:06.819: INFO: Pod "downwardapi-volume-705ca4a0-a70e-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.560563ms
Jul 15 14:40:08.829: INFO: Pod "downwardapi-volume-705ca4a0-a70e-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01979655s
Jul 15 14:40:10.835: INFO: Pod "downwardapi-volume-705ca4a0-a70e-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025398559s
STEP: Saw pod success
Jul 15 14:40:10.835: INFO: Pod "downwardapi-volume-705ca4a0-a70e-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:40:10.837: INFO: Trying to get logs from node i-x8osldkx pod downwardapi-volume-705ca4a0-a70e-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 14:40:10.869: INFO: Waiting for pod downwardapi-volume-705ca4a0-a70e-11e9-afda-96f40a16177b to disappear
Jul 15 14:40:10.873: INFO: Pod downwardapi-volume-705ca4a0-a70e-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:40:10.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mn6jj" for this suite.
Jul 15 14:40:16.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:40:16.917: INFO: namespace: e2e-tests-downward-api-mn6jj, resource: bindings, ignored listing per whitelist
Jul 15 14:40:19.268: INFO: namespace e2e-tests-downward-api-mn6jj deletion completed in 8.391394995s

• [SLOW TEST:12.598 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:40:19.269: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-6hzh9
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-6hzh9 to expose endpoints map[]
Jul 15 14:40:19.391: INFO: Get endpoints failed (3.051297ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jul 15 14:40:20.394: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-6hzh9 exposes endpoints map[] (1.005944614s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-6hzh9
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-6hzh9 to expose endpoints map[pod1:[100]]
Jul 15 14:40:22.424: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-6hzh9 exposes endpoints map[pod1:[100]] (2.024671104s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-6hzh9
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-6hzh9 to expose endpoints map[pod1:[100] pod2:[101]]
Jul 15 14:40:24.452: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-6hzh9 exposes endpoints map[pod1:[100] pod2:[101]] (2.024063316s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-6hzh9
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-6hzh9 to expose endpoints map[pod2:[101]]
Jul 15 14:40:24.478: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-6hzh9 exposes endpoints map[pod2:[101]] (15.493635ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-6hzh9
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-6hzh9 to expose endpoints map[]
Jul 15 14:40:25.492: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-6hzh9 exposes endpoints map[] (1.00613896s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:40:25.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-6hzh9" for this suite.
Jul 15 14:40:31.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:40:33.032: INFO: namespace: e2e-tests-services-6hzh9, resource: bindings, ignored listing per whitelist
Jul 15 14:40:33.882: INFO: namespace e2e-tests-services-6hzh9 deletion completed in 8.37658992s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:14.613 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:40:33.883: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-js4l6/configmap-test-808d8917-a70e-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 14:40:33.978: INFO: Waiting up to 5m0s for pod "pod-configmaps-808e2882-a70e-11e9-afda-96f40a16177b" in namespace "e2e-tests-configmap-js4l6" to be "success or failure"
Jul 15 14:40:33.981: INFO: Pod "pod-configmaps-808e2882-a70e-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.186662ms
Jul 15 14:40:35.984: INFO: Pod "pod-configmaps-808e2882-a70e-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006662127s
STEP: Saw pod success
Jul 15 14:40:35.984: INFO: Pod "pod-configmaps-808e2882-a70e-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:40:35.987: INFO: Trying to get logs from node i-tkuhh2hc pod pod-configmaps-808e2882-a70e-11e9-afda-96f40a16177b container env-test: <nil>
STEP: delete the pod
Jul 15 14:40:36.013: INFO: Waiting for pod pod-configmaps-808e2882-a70e-11e9-afda-96f40a16177b to disappear
Jul 15 14:40:36.016: INFO: Pod pod-configmaps-808e2882-a70e-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:40:36.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-js4l6" for this suite.
Jul 15 14:40:42.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:40:42.109: INFO: namespace: e2e-tests-configmap-js4l6, resource: bindings, ignored listing per whitelist
Jul 15 14:40:44.409: INFO: namespace e2e-tests-configmap-js4l6 deletion completed in 8.388794065s

• [SLOW TEST:10.526 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:40:44.409: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jul 15 14:40:49.026: INFO: Successfully updated pod "labelsupdate86d31631-a70e-11e9-afda-96f40a16177b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:40:51.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s92xw" for this suite.
Jul 15 14:41:13.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:41:13.225: INFO: namespace: e2e-tests-downward-api-s92xw, resource: bindings, ignored listing per whitelist
Jul 15 14:41:15.486: INFO: namespace e2e-tests-downward-api-s92xw deletion completed in 24.404025288s

• [SLOW TEST:31.078 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:41:15.490: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-qvdth
Jul 15 14:41:21.668: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-qvdth
STEP: checking the pod's current state and verifying that restartCount is present
Jul 15 14:41:21.670: INFO: Initial restart count of pod liveness-http is 0
Jul 15 14:41:45.729: INFO: Restart count of pod e2e-tests-container-probe-qvdth/liveness-http is now 1 (24.058696503s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:41:45.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qvdth" for this suite.
Jul 15 14:41:51.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:41:51.790: INFO: namespace: e2e-tests-container-probe-qvdth, resource: bindings, ignored listing per whitelist
Jul 15 14:41:54.135: INFO: namespace e2e-tests-container-probe-qvdth deletion completed in 8.38832576s

• [SLOW TEST:38.645 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:41:54.136: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 14:41:54.232: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0648036-a70e-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-t4qwh" to be "success or failure"
Jul 15 14:41:54.235: INFO: Pod "downwardapi-volume-b0648036-a70e-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.613082ms
Jul 15 14:41:56.239: INFO: Pod "downwardapi-volume-b0648036-a70e-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006276061s
STEP: Saw pod success
Jul 15 14:41:56.239: INFO: Pod "downwardapi-volume-b0648036-a70e-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:41:56.241: INFO: Trying to get logs from node i-x8osldkx pod downwardapi-volume-b0648036-a70e-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 14:41:56.269: INFO: Waiting for pod downwardapi-volume-b0648036-a70e-11e9-afda-96f40a16177b to disappear
Jul 15 14:41:56.274: INFO: Pod downwardapi-volume-b0648036-a70e-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:41:56.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t4qwh" for this suite.
Jul 15 14:42:02.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:42:04.236: INFO: namespace: e2e-tests-projected-t4qwh, resource: bindings, ignored listing per whitelist
Jul 15 14:42:04.686: INFO: namespace e2e-tests-projected-t4qwh deletion completed in 8.404849858s

• [SLOW TEST:10.551 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:42:04.687: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jul 15 14:42:04.822: INFO: Waiting up to 5m0s for pod "pod-b6b38f0f-a70e-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-9ltvg" to be "success or failure"
Jul 15 14:42:04.829: INFO: Pod "pod-b6b38f0f-a70e-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.59207ms
Jul 15 14:42:06.835: INFO: Pod "pod-b6b38f0f-a70e-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012329569s
Jul 15 14:42:08.838: INFO: Pod "pod-b6b38f0f-a70e-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01530955s
STEP: Saw pod success
Jul 15 14:42:08.838: INFO: Pod "pod-b6b38f0f-a70e-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:42:08.840: INFO: Trying to get logs from node i-tkuhh2hc pod pod-b6b38f0f-a70e-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 14:42:08.861: INFO: Waiting for pod pod-b6b38f0f-a70e-11e9-afda-96f40a16177b to disappear
Jul 15 14:42:08.863: INFO: Pod pod-b6b38f0f-a70e-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:42:08.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9ltvg" for this suite.
Jul 15 14:42:14.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:42:14.937: INFO: namespace: e2e-tests-emptydir-9ltvg, resource: bindings, ignored listing per whitelist
Jul 15 14:42:17.263: INFO: namespace e2e-tests-emptydir-9ltvg deletion completed in 8.389405735s

• [SLOW TEST:12.576 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:42:17.263: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-l4psm.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-l4psm.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-l4psm.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-l4psm.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-l4psm.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-l4psm.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul 15 14:42:21.444: INFO: DNS probes using e2e-tests-dns-l4psm/dns-test-be2dc00b-a70e-11e9-afda-96f40a16177b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:42:21.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-l4psm" for this suite.
Jul 15 14:42:27.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:42:27.494: INFO: namespace: e2e-tests-dns-l4psm, resource: bindings, ignored listing per whitelist
Jul 15 14:42:29.847: INFO: namespace e2e-tests-dns-l4psm deletion completed in 8.381302554s

• [SLOW TEST:12.583 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:42:29.847: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul 15 14:42:29.969: INFO: Waiting up to 5m0s for pod "pod-c5b084f2-a70e-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-5jtpz" to be "success or failure"
Jul 15 14:42:29.978: INFO: Pod "pod-c5b084f2-a70e-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.390444ms
Jul 15 14:42:31.981: INFO: Pod "pod-c5b084f2-a70e-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01142324s
STEP: Saw pod success
Jul 15 14:42:31.982: INFO: Pod "pod-c5b084f2-a70e-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:42:31.986: INFO: Trying to get logs from node i-tkuhh2hc pod pod-c5b084f2-a70e-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 14:42:32.020: INFO: Waiting for pod pod-c5b084f2-a70e-11e9-afda-96f40a16177b to disappear
Jul 15 14:42:32.026: INFO: Pod pod-c5b084f2-a70e-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:42:32.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5jtpz" for this suite.
Jul 15 14:42:38.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:42:39.322: INFO: namespace: e2e-tests-emptydir-5jtpz, resource: bindings, ignored listing per whitelist
Jul 15 14:42:40.421: INFO: namespace e2e-tests-emptydir-5jtpz deletion completed in 8.383737996s

• [SLOW TEST:10.574 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:42:40.421: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:42:40.550: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Jul 15 14:42:40.557: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-tdz47/daemonsets","resourceVersion":"56970"},"items":null}

Jul 15 14:42:40.560: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-tdz47/pods","resourceVersion":"56970"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:42:40.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-tdz47" for this suite.
Jul 15 14:42:46.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:42:46.953: INFO: namespace: e2e-tests-daemonsets-tdz47, resource: bindings, ignored listing per whitelist
Jul 15 14:42:48.952: INFO: namespace e2e-tests-daemonsets-tdz47 deletion completed in 8.38072907s

S [SKIPPING] [8.531 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jul 15 14:42:40.550: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:42:48.954: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jul 15 14:42:51.112: INFO: Pod pod-hostip-d117ee08-a70e-11e9-afda-96f40a16177b has hostIP: 192.168.0.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:42:51.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rspmd" for this suite.
Jul 15 14:43:13.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:43:13.145: INFO: namespace: e2e-tests-pods-rspmd, resource: bindings, ignored listing per whitelist
Jul 15 14:43:15.498: INFO: namespace e2e-tests-pods-rspmd deletion completed in 24.381026241s

• [SLOW TEST:26.545 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:43:15.498: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:44:15.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nbgjx" for this suite.
Jul 15 14:44:37.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:44:37.732: INFO: namespace: e2e-tests-container-probe-nbgjx, resource: bindings, ignored listing per whitelist
Jul 15 14:44:40.014: INFO: namespace e2e-tests-container-probe-nbgjx deletion completed in 24.397229971s

• [SLOW TEST:84.516 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:44:40.016: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-1345b9d1-a70f-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 14:44:40.140: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-134665a4-a70f-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-fbdnx" to be "success or failure"
Jul 15 14:44:40.147: INFO: Pod "pod-projected-secrets-134665a4-a70f-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.994094ms
Jul 15 14:44:42.150: INFO: Pod "pod-projected-secrets-134665a4-a70f-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010369658s
STEP: Saw pod success
Jul 15 14:44:42.150: INFO: Pod "pod-projected-secrets-134665a4-a70f-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:44:42.155: INFO: Trying to get logs from node i-x8osldkx pod pod-projected-secrets-134665a4-a70f-11e9-afda-96f40a16177b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul 15 14:44:42.186: INFO: Waiting for pod pod-projected-secrets-134665a4-a70f-11e9-afda-96f40a16177b to disappear
Jul 15 14:44:42.190: INFO: Pod pod-projected-secrets-134665a4-a70f-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:44:42.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fbdnx" for this suite.
Jul 15 14:44:48.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:44:48.238: INFO: namespace: e2e-tests-projected-fbdnx, resource: bindings, ignored listing per whitelist
Jul 15 14:44:50.585: INFO: namespace e2e-tests-projected-fbdnx deletion completed in 8.390865503s

• [SLOW TEST:10.569 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:44:50.585: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-phzmd/secret-test-199294aa-a70f-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 14:44:50.710: INFO: Waiting up to 5m0s for pod "pod-configmaps-1993821e-a70f-11e9-afda-96f40a16177b" in namespace "e2e-tests-secrets-phzmd" to be "success or failure"
Jul 15 14:44:50.714: INFO: Pod "pod-configmaps-1993821e-a70f-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.424105ms
Jul 15 14:44:52.718: INFO: Pod "pod-configmaps-1993821e-a70f-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005657995s
Jul 15 14:44:54.721: INFO: Pod "pod-configmaps-1993821e-a70f-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009560116s
STEP: Saw pod success
Jul 15 14:44:54.721: INFO: Pod "pod-configmaps-1993821e-a70f-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:44:54.724: INFO: Trying to get logs from node i-tkuhh2hc pod pod-configmaps-1993821e-a70f-11e9-afda-96f40a16177b container env-test: <nil>
STEP: delete the pod
Jul 15 14:44:54.748: INFO: Waiting for pod pod-configmaps-1993821e-a70f-11e9-afda-96f40a16177b to disappear
Jul 15 14:44:54.751: INFO: Pod pod-configmaps-1993821e-a70f-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:44:54.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-phzmd" for this suite.
Jul 15 14:45:00.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:45:00.817: INFO: namespace: e2e-tests-secrets-phzmd, resource: bindings, ignored listing per whitelist
Jul 15 14:45:03.149: INFO: namespace e2e-tests-secrets-phzmd deletion completed in 8.39360857s

• [SLOW TEST:12.564 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:45:03.149: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bq4jv
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jul 15 14:45:03.294: INFO: Found 0 stateful pods, waiting for 3
Jul 15 14:45:13.300: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 14:45:13.300: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 14:45:13.300: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul 15 14:45:13.328: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jul 15 14:45:23.369: INFO: Updating stateful set ss2
Jul 15 14:45:23.378: INFO: Waiting for Pod e2e-tests-statefulset-bq4jv/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 15 14:45:33.395: INFO: Waiting for Pod e2e-tests-statefulset-bq4jv/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jul 15 14:45:43.496: INFO: Found 2 stateful pods, waiting for 3
Jul 15 14:45:53.501: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 14:45:53.501: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 14:45:53.501: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jul 15 14:45:53.524: INFO: Updating stateful set ss2
Jul 15 14:45:53.550: INFO: Waiting for Pod e2e-tests-statefulset-bq4jv/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 15 14:46:03.559: INFO: Waiting for Pod e2e-tests-statefulset-bq4jv/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 15 14:46:13.577: INFO: Updating stateful set ss2
Jul 15 14:46:13.585: INFO: Waiting for StatefulSet e2e-tests-statefulset-bq4jv/ss2 to complete update
Jul 15 14:46:13.585: INFO: Waiting for Pod e2e-tests-statefulset-bq4jv/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jul 15 14:46:23.590: INFO: Waiting for StatefulSet e2e-tests-statefulset-bq4jv/ss2 to complete update
Jul 15 14:46:23.591: INFO: Waiting for Pod e2e-tests-statefulset-bq4jv/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 15 14:46:33.595: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bq4jv
Jul 15 14:46:33.598: INFO: Scaling statefulset ss2 to 0
Jul 15 14:46:43.652: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 14:46:43.656: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:46:43.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bq4jv" for this suite.
Jul 15 14:46:49.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:46:52.059: INFO: namespace: e2e-tests-statefulset-bq4jv, resource: bindings, ignored listing per whitelist
Jul 15 14:46:52.059: INFO: namespace e2e-tests-statefulset-bq4jv deletion completed in 8.387649693s

• [SLOW TEST:108.910 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:46:52.060: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:46:52.155: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jul 15 14:46:57.158: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 15 14:46:57.163: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 15 14:46:59.200: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-2r2xk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2r2xk/deployments/test-cleanup-deployment,UID:64f67913-a70f-11e9-8341-525422241ab4,ResourceVersion:57937,Generation:1,CreationTimestamp:2019-07-15 14:46:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-15 14:46:57 +0000 UTC 2019-07-15 14:46:57 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-15 14:46:59 +0000 UTC 2019-07-15 14:46:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-7dbbfcf846" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 15 14:46:59.203: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-2r2xk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2r2xk/replicasets/test-cleanup-deployment-7dbbfcf846,UID:64f8c1c6-a70f-11e9-8341-525422241ab4,ResourceVersion:57928,Generation:1,CreationTimestamp:2019-07-15 14:46:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 64f67913-a70f-11e9-8341-525422241ab4 0xc000f507e7 0xc000f507e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 15 14:46:59.206: INFO: Pod "test-cleanup-deployment-7dbbfcf846-cvh8h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-cvh8h,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-2r2xk,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r2xk/pods/test-cleanup-deployment-7dbbfcf846-cvh8h,UID:64f9864a-a70f-11e9-8341-525422241ab4,ResourceVersion:57927,Generation:0,CreationTimestamp:2019-07-15 14:46:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.2.170/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 64f8c1c6-a70f-11e9-8341-525422241ab4 0xc0011eba17 0xc0011eba18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hkvcq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hkvcq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hkvcq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011ebaa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0011ebac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:46:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:46:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:46:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:46:57 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.4,PodIP:10.10.2.170,StartTime:2019-07-15 14:46:57 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-15 14:46:58 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://489784a6724e276c34c919cb1a3d687b770594b7f415f286544cf65d53454181}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:46:59.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2r2xk" for this suite.
Jul 15 14:47:05.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:47:05.344: INFO: namespace: e2e-tests-deployment-2r2xk, resource: bindings, ignored listing per whitelist
Jul 15 14:47:07.606: INFO: namespace e2e-tests-deployment-2r2xk deletion completed in 8.395270607s

• [SLOW TEST:15.546 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:47:07.607: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 14:47:07.698: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6b3aa0ca-a70f-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-zz64l" to be "success or failure"
Jul 15 14:47:07.705: INFO: Pod "downwardapi-volume-6b3aa0ca-a70f-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.144241ms
Jul 15 14:47:09.709: INFO: Pod "downwardapi-volume-6b3aa0ca-a70f-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011005281s
Jul 15 14:47:11.714: INFO: Pod "downwardapi-volume-6b3aa0ca-a70f-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015643456s
STEP: Saw pod success
Jul 15 14:47:11.714: INFO: Pod "downwardapi-volume-6b3aa0ca-a70f-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:47:11.716: INFO: Trying to get logs from node i-x8osldkx pod downwardapi-volume-6b3aa0ca-a70f-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 14:47:11.736: INFO: Waiting for pod downwardapi-volume-6b3aa0ca-a70f-11e9-afda-96f40a16177b to disappear
Jul 15 14:47:11.739: INFO: Pod downwardapi-volume-6b3aa0ca-a70f-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:47:11.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zz64l" for this suite.
Jul 15 14:47:17.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:47:19.531: INFO: namespace: e2e-tests-downward-api-zz64l, resource: bindings, ignored listing per whitelist
Jul 15 14:47:20.132: INFO: namespace e2e-tests-downward-api-zz64l deletion completed in 8.389083091s

• [SLOW TEST:12.525 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:47:20.132: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9mw4p
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-9mw4p
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-9mw4p
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-9mw4p
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-9mw4p
Jul 15 14:47:24.303: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9mw4p, name: ss-0, uid: 74f7bd2e-a70f-11e9-8341-525422241ab4, status phase: Pending. Waiting for statefulset controller to delete.
Jul 15 14:47:24.813: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9mw4p, name: ss-0, uid: 74f7bd2e-a70f-11e9-8341-525422241ab4, status phase: Failed. Waiting for statefulset controller to delete.
Jul 15 14:47:24.835: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9mw4p, name: ss-0, uid: 74f7bd2e-a70f-11e9-8341-525422241ab4, status phase: Failed. Waiting for statefulset controller to delete.
Jul 15 14:47:24.835: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-9mw4p
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-9mw4p
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-9mw4p and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 15 14:47:30.861: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9mw4p
Jul 15 14:47:30.864: INFO: Scaling statefulset ss to 0
Jul 15 14:47:40.876: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 14:47:40.878: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:47:40.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9mw4p" for this suite.
Jul 15 14:47:46.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:47:47.042: INFO: namespace: e2e-tests-statefulset-9mw4p, resource: bindings, ignored listing per whitelist
Jul 15 14:47:49.297: INFO: namespace e2e-tests-statefulset-9mw4p deletion completed in 8.402772007s

• [SLOW TEST:29.165 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:47:49.300: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:47:49.394: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jul 15 14:47:54.398: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 15 14:47:54.399: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jul 15 14:47:56.402: INFO: Creating deployment "test-rollover-deployment"
Jul 15 14:47:56.412: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jul 15 14:47:58.419: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jul 15 14:47:58.422: INFO: Ensure that both replica sets have 1 created replica
Jul 15 14:47:58.431: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jul 15 14:47:58.440: INFO: Updating deployment test-rollover-deployment
Jul 15 14:47:58.440: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jul 15 14:48:00.449: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jul 15 14:48:00.461: INFO: Make sure deployment "test-rollover-deployment" is complete
Jul 15 14:48:00.471: INFO: all replica sets need to contain the pod-template-hash label
Jul 15 14:48:00.473: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798878, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 14:48:02.487: INFO: all replica sets need to contain the pod-template-hash label
Jul 15 14:48:02.493: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798880, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 14:48:04.478: INFO: all replica sets need to contain the pod-template-hash label
Jul 15 14:48:04.479: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798880, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 14:48:06.478: INFO: all replica sets need to contain the pod-template-hash label
Jul 15 14:48:06.479: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798880, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 14:48:08.491: INFO: all replica sets need to contain the pod-template-hash label
Jul 15 14:48:08.491: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798880, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 14:48:10.481: INFO: all replica sets need to contain the pod-template-hash label
Jul 15 14:48:10.482: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798880, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698798876, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 14:48:12.478: INFO: 
Jul 15 14:48:12.478: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 15 14:48:12.484: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-9mfgt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9mfgt/deployments/test-rollover-deployment,UID:88447827-a70f-11e9-8341-525422241ab4,ResourceVersion:58362,Generation:2,CreationTimestamp:2019-07-15 14:47:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-15 14:47:56 +0000 UTC 2019-07-15 14:47:56 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-15 14:48:10 +0000 UTC 2019-07-15 14:47:56 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 15 14:48:12.486: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-9mfgt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9mfgt/replicasets/test-rollover-deployment-6b7f9d6597,UID:897b24cc-a70f-11e9-8341-525422241ab4,ResourceVersion:58353,Generation:2,CreationTimestamp:2019-07-15 14:47:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 88447827-a70f-11e9-8341-525422241ab4 0xc002e56307 0xc002e56308}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 15 14:48:12.486: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jul 15 14:48:12.486: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-9mfgt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9mfgt/replicasets/test-rollover-controller,UID:8415c5df-a70f-11e9-8341-525422241ab4,ResourceVersion:58361,Generation:2,CreationTimestamp:2019-07-15 14:47:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 88447827-a70f-11e9-8341-525422241ab4 0xc002e56177 0xc002e56178}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 14:48:12.487: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-9mfgt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9mfgt/replicasets/test-rollover-deployment-6586df867b,UID:884716c4-a70f-11e9-8341-525422241ab4,ResourceVersion:58314,Generation:2,CreationTimestamp:2019-07-15 14:47:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 88447827-a70f-11e9-8341-525422241ab4 0xc002e56237 0xc002e56238}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 14:48:12.489: INFO: Pod "test-rollover-deployment-6b7f9d6597-98xdq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-98xdq,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-9mfgt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9mfgt/pods/test-rollover-deployment-6b7f9d6597-98xdq,UID:897e8aa2-a70f-11e9-8341-525422241ab4,ResourceVersion:58327,Generation:0,CreationTimestamp:2019-07-15 14:47:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.195/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 897b24cc-a70f-11e9-8341-525422241ab4 0xc002e56e47 0xc002e56e48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gnpkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gnpkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-gnpkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e56ec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e56ee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:47:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:48:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:48:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:47:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:10.10.1.195,StartTime:2019-07-15 14:47:58 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-15 14:47:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://05d1d167c18599f6567aaed84df599e5d0a40ab649c1a22923b334ba819238ef}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:48:12.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9mfgt" for this suite.
Jul 15 14:48:18.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:48:18.621: INFO: namespace: e2e-tests-deployment-9mfgt, resource: bindings, ignored listing per whitelist
Jul 15 14:48:20.928: INFO: namespace e2e-tests-deployment-9mfgt deletion completed in 8.436227835s

• [SLOW TEST:31.629 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:48:20.929: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 14:48:21.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jg4q2'
Jul 15 14:48:21.503: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 15 14:48:21.504: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Jul 15 14:48:21.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-jg4q2'
Jul 15 14:48:21.629: INFO: stderr: ""
Jul 15 14:48:21.629: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:48:21.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jg4q2" for this suite.
Jul 15 14:48:27.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:48:27.682: INFO: namespace: e2e-tests-kubectl-jg4q2, resource: bindings, ignored listing per whitelist
Jul 15 14:48:30.021: INFO: namespace e2e-tests-kubectl-jg4q2 deletion completed in 8.382499517s

• [SLOW TEST:9.092 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:48:30.021: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rtm8m
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul 15 14:48:30.146: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jul 15 14:48:50.223: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.10.2.173:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rtm8m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:48:50.223: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:48:50.529: INFO: Found all expected endpoints: [netserver-0]
Jul 15 14:48:50.536: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.10.1.197:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rtm8m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jul 15 14:48:50.536: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
Jul 15 14:48:50.770: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:48:50.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rtm8m" for this suite.
Jul 15 14:49:14.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:49:15.869: INFO: namespace: e2e-tests-pod-network-test-rtm8m, resource: bindings, ignored listing per whitelist
Jul 15 14:49:17.170: INFO: namespace e2e-tests-pod-network-test-rtm8m deletion completed in 26.391376368s

• [SLOW TEST:47.149 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:49:17.171: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:49:19.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-6fv69" for this suite.
Jul 15 14:50:05.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:50:06.055: INFO: namespace: e2e-tests-kubelet-test-6fv69, resource: bindings, ignored listing per whitelist
Jul 15 14:50:07.703: INFO: namespace e2e-tests-kubelet-test-6fv69 deletion completed in 48.383719993s

• [SLOW TEST:50.533 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:50:07.707: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 14:50:07.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gpwns'
Jul 15 14:50:07.949: INFO: stderr: ""
Jul 15 14:50:07.949: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jul 15 14:50:13.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gpwns -o json'
Jul 15 14:50:13.155: INFO: stderr: ""
Jul 15 14:50:13.155: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.10.2.175/32\"\n        },\n        \"creationTimestamp\": \"2019-07-15T14:50:07Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-gpwns\",\n        \"resourceVersion\": \"58793\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-gpwns/pods/e2e-test-nginx-pod\",\n        \"uid\": \"d6a6a74c-a70f-11e9-8341-525422241ab4\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-kj5tn\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"i-x8osldkx\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-kj5tn\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-kj5tn\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-15T14:50:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-15T14:50:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-15T14:50:10Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-07-15T14:50:07Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f52a1863b59255fe178a6976503786eb53d74d678d3916ebd74956bc8a618e84\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-07-15T14:50:09Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.0.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.10.2.175\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-07-15T14:50:07Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jul 15 14:50:13.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 replace -f - --namespace=e2e-tests-kubectl-gpwns'
Jul 15 14:50:13.429: INFO: stderr: ""
Jul 15 14:50:13.429: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Jul 15 14:50:13.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gpwns'
Jul 15 14:50:15.666: INFO: stderr: ""
Jul 15 14:50:15.666: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:50:15.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gpwns" for this suite.
Jul 15 14:50:21.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:50:21.760: INFO: namespace: e2e-tests-kubectl-gpwns, resource: bindings, ignored listing per whitelist
Jul 15 14:50:24.065: INFO: namespace e2e-tests-kubectl-gpwns deletion completed in 8.394342841s

• [SLOW TEST:16.359 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:50:24.065: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 14:50:24.157: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0549567-a70f-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-mnf5b" to be "success or failure"
Jul 15 14:50:24.161: INFO: Pod "downwardapi-volume-e0549567-a70f-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.646299ms
Jul 15 14:50:26.165: INFO: Pod "downwardapi-volume-e0549567-a70f-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007234679s
STEP: Saw pod success
Jul 15 14:50:26.165: INFO: Pod "downwardapi-volume-e0549567-a70f-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:50:26.169: INFO: Trying to get logs from node i-tkuhh2hc pod downwardapi-volume-e0549567-a70f-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 14:50:26.192: INFO: Waiting for pod downwardapi-volume-e0549567-a70f-11e9-afda-96f40a16177b to disappear
Jul 15 14:50:26.195: INFO: Pod downwardapi-volume-e0549567-a70f-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:50:26.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mnf5b" for this suite.
Jul 15 14:50:32.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:50:32.265: INFO: namespace: e2e-tests-projected-mnf5b, resource: bindings, ignored listing per whitelist
Jul 15 14:50:34.578: INFO: namespace e2e-tests-projected-mnf5b deletion completed in 8.379676636s

• [SLOW TEST:10.513 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:50:34.578: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:50:34.661: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:50:36.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-j6v5t" for this suite.
Jul 15 14:51:16.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:51:16.774: INFO: namespace: e2e-tests-pods-j6v5t, resource: bindings, ignored listing per whitelist
Jul 15 14:51:19.080: INFO: namespace e2e-tests-pods-j6v5t deletion completed in 42.38331615s

• [SLOW TEST:44.502 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:51:19.081: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jul 15 14:51:19.174: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-ktz8d" to be "success or failure"
Jul 15 14:51:19.180: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.700545ms
Jul 15 14:51:21.184: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009560257s
Jul 15 14:51:23.187: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013085113s
STEP: Saw pod success
Jul 15 14:51:23.187: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jul 15 14:51:23.190: INFO: Trying to get logs from node i-tkuhh2hc pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jul 15 14:51:23.214: INFO: Waiting for pod pod-host-path-test to disappear
Jul 15 14:51:23.217: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:51:23.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-ktz8d" for this suite.
Jul 15 14:51:29.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:51:31.065: INFO: namespace: e2e-tests-hostpath-ktz8d, resource: bindings, ignored listing per whitelist
Jul 15 14:51:31.614: INFO: namespace e2e-tests-hostpath-ktz8d deletion completed in 8.389291575s

• [SLOW TEST:12.533 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:51:31.615: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:51:31.687: INFO: Creating deployment "test-recreate-deployment"
Jul 15 14:51:31.695: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jul 15 14:51:31.712: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jul 15 14:51:33.717: INFO: Waiting deployment "test-recreate-deployment" to complete
Jul 15 14:51:33.720: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jul 15 14:51:33.727: INFO: Updating deployment test-recreate-deployment
Jul 15 14:51:33.727: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 15 14:51:33.781: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-j76sl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j76sl/deployments/test-recreate-deployment,UID:0896313b-a710-11e9-8341-525422241ab4,ResourceVersion:59113,Generation:2,CreationTimestamp:2019-07-15 14:51:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-07-15 14:51:33 +0000 UTC 2019-07-15 14:51:33 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-07-15 14:51:33 +0000 UTC 2019-07-15 14:51:31 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jul 15 14:51:33.784: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-j76sl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j76sl/replicasets/test-recreate-deployment-697fbf54bf,UID:09d0f713-a710-11e9-8341-525422241ab4,ResourceVersion:59112,Generation:1,CreationTimestamp:2019-07-15 14:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0896313b-a710-11e9-8341-525422241ab4 0xc002af62d7 0xc002af62d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 14:51:33.784: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jul 15 14:51:33.788: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-j76sl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j76sl/replicasets/test-recreate-deployment-5dfdcc846d,UID:089777ce-a710-11e9-8341-525422241ab4,ResourceVersion:59102,Generation:2,CreationTimestamp:2019-07-15 14:51:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0896313b-a710-11e9-8341-525422241ab4 0xc002af6217 0xc002af6218}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 14:51:33.793: INFO: Pod "test-recreate-deployment-697fbf54bf-mbh2c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-mbh2c,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-j76sl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j76sl/pods/test-recreate-deployment-697fbf54bf-mbh2c,UID:09d1b9f4-a710-11e9-8341-525422241ab4,ResourceVersion:59114,Generation:0,CreationTimestamp:2019-07-15 14:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 09d0f713-a710-11e9-8341-525422241ab4 0xc002af6a47 0xc002af6a48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bs7sd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bs7sd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bs7sd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-x8osldkx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002af6ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002af6ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:51:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:51:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:51:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:51:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.4,PodIP:,StartTime:2019-07-15 14:51:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:51:33.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-j76sl" for this suite.
Jul 15 14:51:39.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:51:40.375: INFO: namespace: e2e-tests-deployment-j76sl, resource: bindings, ignored listing per whitelist
Jul 15 14:51:42.175: INFO: namespace e2e-tests-deployment-j76sl deletion completed in 8.377929813s

• [SLOW TEST:10.560 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:51:42.175: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0ee4792e-a710-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 14:51:42.328: INFO: Waiting up to 5m0s for pod "pod-secrets-0eebc69b-a710-11e9-afda-96f40a16177b" in namespace "e2e-tests-secrets-2dj87" to be "success or failure"
Jul 15 14:51:42.330: INFO: Pod "pod-secrets-0eebc69b-a710-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047538ms
Jul 15 14:51:44.333: INFO: Pod "pod-secrets-0eebc69b-a710-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005226391s
STEP: Saw pod success
Jul 15 14:51:44.333: INFO: Pod "pod-secrets-0eebc69b-a710-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:51:44.335: INFO: Trying to get logs from node i-tkuhh2hc pod pod-secrets-0eebc69b-a710-11e9-afda-96f40a16177b container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 14:51:44.358: INFO: Waiting for pod pod-secrets-0eebc69b-a710-11e9-afda-96f40a16177b to disappear
Jul 15 14:51:44.360: INFO: Pod pod-secrets-0eebc69b-a710-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:51:44.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2dj87" for this suite.
Jul 15 14:51:50.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:51:50.482: INFO: namespace: e2e-tests-secrets-2dj87, resource: bindings, ignored listing per whitelist
Jul 15 14:51:52.751: INFO: namespace e2e-tests-secrets-2dj87 deletion completed in 8.386897345s
STEP: Destroying namespace "e2e-tests-secret-namespace-cslkc" for this suite.
Jul 15 14:51:58.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:51:58.847: INFO: namespace: e2e-tests-secret-namespace-cslkc, resource: bindings, ignored listing per whitelist
Jul 15 14:52:01.138: INFO: namespace e2e-tests-secret-namespace-cslkc deletion completed in 8.386331586s

• [SLOW TEST:18.962 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:52:01.141: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0715 14:52:02.346946      22 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jul 15 14:52:02.347: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:52:02.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qbcvk" for this suite.
Jul 15 14:52:08.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:52:08.475: INFO: namespace: e2e-tests-gc-qbcvk, resource: bindings, ignored listing per whitelist
Jul 15 14:52:10.764: INFO: namespace e2e-tests-gc-qbcvk deletion completed in 8.411406347s

• [SLOW TEST:9.624 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:52:10.766: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul 15 14:52:10.884: INFO: Waiting up to 5m0s for pod "pod-1ff079c9-a710-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-k6vjp" to be "success or failure"
Jul 15 14:52:10.887: INFO: Pod "pod-1ff079c9-a710-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.074985ms
Jul 15 14:52:12.894: INFO: Pod "pod-1ff079c9-a710-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01036981s
STEP: Saw pod success
Jul 15 14:52:12.894: INFO: Pod "pod-1ff079c9-a710-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:52:12.897: INFO: Trying to get logs from node i-x8osldkx pod pod-1ff079c9-a710-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 14:52:12.935: INFO: Waiting for pod pod-1ff079c9-a710-11e9-afda-96f40a16177b to disappear
Jul 15 14:52:12.938: INFO: Pod pod-1ff079c9-a710-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:52:12.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-k6vjp" for this suite.
Jul 15 14:52:18.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:52:20.533: INFO: namespace: e2e-tests-emptydir-k6vjp, resource: bindings, ignored listing per whitelist
Jul 15 14:52:21.333: INFO: namespace e2e-tests-emptydir-k6vjp deletion completed in 8.390846161s

• [SLOW TEST:10.567 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:52:21.341: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-w72xc in namespace e2e-tests-proxy-5vwfb
I0715 14:52:21.444496      22 runners.go:184] Created replication controller with name: proxy-service-w72xc, namespace: e2e-tests-proxy-5vwfb, replica count: 1
I0715 14:52:22.494907      22 runners.go:184] proxy-service-w72xc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0715 14:52:23.495139      22 runners.go:184] proxy-service-w72xc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0715 14:52:24.496015      22 runners.go:184] proxy-service-w72xc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0715 14:52:25.496938      22 runners.go:184] proxy-service-w72xc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0715 14:52:26.500368      22 runners.go:184] proxy-service-w72xc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0715 14:52:27.500607      22 runners.go:184] proxy-service-w72xc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0715 14:52:28.500946      22 runners.go:184] proxy-service-w72xc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul 15 14:52:28.503: INFO: setup took 7.078662029s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jul 15 14:52:28.531: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 27.533984ms)
Jul 15 14:52:28.531: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 26.477685ms)
Jul 15 14:52:28.531: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 27.47771ms)
Jul 15 14:52:28.532: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 27.574079ms)
Jul 15 14:52:28.532: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 27.787935ms)
Jul 15 14:52:28.532: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 27.925728ms)
Jul 15 14:52:28.532: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 28.35565ms)
Jul 15 14:52:28.532: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 29.001451ms)
Jul 15 14:52:28.546: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 42.310378ms)
Jul 15 14:52:28.547: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 42.244202ms)
Jul 15 14:52:28.547: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 41.879446ms)
Jul 15 14:52:28.547: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 42.000342ms)
Jul 15 14:52:28.547: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 42.866459ms)
Jul 15 14:52:28.551: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 46.021854ms)
Jul 15 14:52:28.551: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 46.13547ms)
Jul 15 14:52:28.551: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 47.345848ms)
Jul 15 14:52:28.563: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 11.986307ms)
Jul 15 14:52:28.584: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 30.854697ms)
Jul 15 14:52:28.584: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 31.697978ms)
Jul 15 14:52:28.585: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 31.549194ms)
Jul 15 14:52:28.585: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 32.183258ms)
Jul 15 14:52:28.585: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 31.808307ms)
Jul 15 14:52:28.585: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 31.874122ms)
Jul 15 14:52:28.585: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 32.172293ms)
Jul 15 14:52:28.586: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 32.458611ms)
Jul 15 14:52:28.586: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 32.553233ms)
Jul 15 14:52:28.586: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 32.68078ms)
Jul 15 14:52:28.586: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 32.908046ms)
Jul 15 14:52:28.586: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 33.097501ms)
Jul 15 14:52:28.587: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 33.359397ms)
Jul 15 14:52:28.587: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 33.371215ms)
Jul 15 14:52:28.591: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 37.061329ms)
Jul 15 14:52:28.602: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 6.733782ms)
Jul 15 14:52:28.602: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 11.375211ms)
Jul 15 14:52:28.602: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 11.138965ms)
Jul 15 14:52:28.602: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 11.009368ms)
Jul 15 14:52:28.603: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 11.366594ms)
Jul 15 14:52:28.603: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 11.936599ms)
Jul 15 14:52:28.603: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 11.325312ms)
Jul 15 14:52:28.603: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 10.67049ms)
Jul 15 14:52:28.603: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 11.260766ms)
Jul 15 14:52:28.603: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 6.795491ms)
Jul 15 14:52:28.603: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 7.535643ms)
Jul 15 14:52:28.603: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 4.876755ms)
Jul 15 14:52:28.603: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 5.276161ms)
Jul 15 14:52:28.603: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 5.156073ms)
Jul 15 14:52:28.603: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 5.040297ms)
Jul 15 14:52:28.604: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 3.421977ms)
Jul 15 14:52:28.612: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 6.673078ms)
Jul 15 14:52:28.612: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 8.772815ms)
Jul 15 14:52:28.612: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 7.275804ms)
Jul 15 14:52:28.612: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 7.44929ms)
Jul 15 14:52:28.612: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 7.418201ms)
Jul 15 14:52:28.612: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 7.289075ms)
Jul 15 14:52:28.613: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 8.040399ms)
Jul 15 14:52:28.615: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 9.474101ms)
Jul 15 14:52:28.615: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 10.211119ms)
Jul 15 14:52:28.616: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 10.403194ms)
Jul 15 14:52:28.616: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 10.889612ms)
Jul 15 14:52:28.616: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 11.011073ms)
Jul 15 14:52:28.617: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 11.078255ms)
Jul 15 14:52:28.617: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 11.747491ms)
Jul 15 14:52:28.617: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 11.877964ms)
Jul 15 14:52:28.617: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 11.941458ms)
Jul 15 14:52:28.626: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 8.401632ms)
Jul 15 14:52:28.626: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 8.323935ms)
Jul 15 14:52:28.626: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 8.581731ms)
Jul 15 14:52:28.626: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 8.331184ms)
Jul 15 14:52:28.626: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 8.579624ms)
Jul 15 14:52:28.626: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 8.637458ms)
Jul 15 14:52:28.626: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 8.603089ms)
Jul 15 14:52:28.626: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 8.672205ms)
Jul 15 14:52:28.627: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 8.81511ms)
Jul 15 14:52:28.627: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 8.882192ms)
Jul 15 14:52:28.626: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 8.266707ms)
Jul 15 14:52:28.627: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 9.326328ms)
Jul 15 14:52:28.628: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 9.989661ms)
Jul 15 14:52:28.628: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 9.927536ms)
Jul 15 14:52:28.628: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 9.872695ms)
Jul 15 14:52:28.628: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 9.478235ms)
Jul 15 14:52:28.643: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 13.653054ms)
Jul 15 14:52:28.643: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 4.659132ms)
Jul 15 14:52:28.643: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 14.366814ms)
Jul 15 14:52:28.643: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 14.602339ms)
Jul 15 14:52:28.644: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 14.651822ms)
Jul 15 14:52:28.644: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 14.980737ms)
Jul 15 14:52:28.644: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 15.72927ms)
Jul 15 14:52:28.644: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 15.278528ms)
Jul 15 14:52:28.644: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 15.175547ms)
Jul 15 14:52:28.644: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 15.247147ms)
Jul 15 14:52:28.644: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 15.261276ms)
Jul 15 14:52:28.645: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 15.537445ms)
Jul 15 14:52:28.645: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 15.75755ms)
Jul 15 14:52:28.645: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 15.842523ms)
Jul 15 14:52:28.645: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 16.568598ms)
Jul 15 14:52:28.646: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 16.658558ms)
Jul 15 14:52:28.665: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 2.942389ms)
Jul 15 14:52:28.665: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 19.476437ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 18.776436ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 18.906897ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 18.560889ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 18.490219ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 8.816334ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 13.656603ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 15.317987ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 11.819493ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 7.378148ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 11.05996ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 8.76681ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 6.698068ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 18.842744ms)
Jul 15 14:52:28.666: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 18.539483ms)
Jul 15 14:52:28.679: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 12.022073ms)
Jul 15 14:52:28.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 12.640404ms)
Jul 15 14:52:28.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 12.678363ms)
Jul 15 14:52:28.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 12.883175ms)
Jul 15 14:52:28.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 12.996707ms)
Jul 15 14:52:28.680: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 13.243604ms)
Jul 15 14:52:28.681: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 13.165511ms)
Jul 15 14:52:28.681: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 13.368065ms)
Jul 15 14:52:28.681: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 13.404286ms)
Jul 15 14:52:28.681: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 13.685895ms)
Jul 15 14:52:28.681: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 13.72677ms)
Jul 15 14:52:28.681: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 14.198375ms)
Jul 15 14:52:28.682: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 14.255803ms)
Jul 15 14:52:28.684: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 16.189273ms)
Jul 15 14:52:28.685: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 17.798928ms)
Jul 15 14:52:28.685: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 17.338052ms)
Jul 15 14:52:28.688: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 3.007027ms)
Jul 15 14:52:28.689: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 3.992236ms)
Jul 15 14:52:28.690: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 5.540313ms)
Jul 15 14:52:28.696: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 8.324729ms)
Jul 15 14:52:28.697: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 9.530066ms)
Jul 15 14:52:28.697: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 9.940634ms)
Jul 15 14:52:28.697: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 9.992089ms)
Jul 15 14:52:28.698: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 10.296606ms)
Jul 15 14:52:28.698: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 10.583992ms)
Jul 15 14:52:28.700: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 12.426116ms)
Jul 15 14:52:28.702: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 14.308978ms)
Jul 15 14:52:28.702: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 14.586173ms)
Jul 15 14:52:28.702: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 14.674103ms)
Jul 15 14:52:28.702: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 14.724825ms)
Jul 15 14:52:28.703: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 14.938279ms)
Jul 15 14:52:28.703: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 15.440827ms)
Jul 15 14:52:28.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 5.998236ms)
Jul 15 14:52:28.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 11.823113ms)
Jul 15 14:52:28.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 9.625006ms)
Jul 15 14:52:28.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 9.564701ms)
Jul 15 14:52:28.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 9.438016ms)
Jul 15 14:52:28.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 6.962388ms)
Jul 15 14:52:28.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 5.960965ms)
Jul 15 14:52:28.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 6.35301ms)
Jul 15 14:52:28.715: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 5.957889ms)
Jul 15 14:52:28.716: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 4.705484ms)
Jul 15 14:52:28.717: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 5.828652ms)
Jul 15 14:52:28.717: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 6.464869ms)
Jul 15 14:52:28.717: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 5.911688ms)
Jul 15 14:52:28.718: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 6.928721ms)
Jul 15 14:52:28.718: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 6.456061ms)
Jul 15 14:52:28.718: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 6.574591ms)
Jul 15 14:52:28.723: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 4.836184ms)
Jul 15 14:52:28.723: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 4.825608ms)
Jul 15 14:52:28.729: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 6.823689ms)
Jul 15 14:52:28.729: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 10.646645ms)
Jul 15 14:52:28.729: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 7.206204ms)
Jul 15 14:52:28.730: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 8.908438ms)
Jul 15 14:52:28.730: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 8.291592ms)
Jul 15 14:52:28.730: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 8.184112ms)
Jul 15 14:52:28.730: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 7.119678ms)
Jul 15 14:52:28.730: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 8.554077ms)
Jul 15 14:52:28.730: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 8.318483ms)
Jul 15 14:52:28.730: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 8.439633ms)
Jul 15 14:52:28.730: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 8.835417ms)
Jul 15 14:52:28.730: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 7.348583ms)
Jul 15 14:52:28.730: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 7.374045ms)
Jul 15 14:52:28.730: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 7.265903ms)
Jul 15 14:52:28.741: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 10.807905ms)
Jul 15 14:52:28.741: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 10.678655ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 10.858347ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 10.648924ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 11.111842ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 10.807195ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 11.313983ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 11.465845ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 11.362047ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 11.129672ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 11.246548ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 11.626591ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 11.669807ms)
Jul 15 14:52:28.742: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 11.712332ms)
Jul 15 14:52:28.743: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 11.847921ms)
Jul 15 14:52:28.744: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 13.206355ms)
Jul 15 14:52:28.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 2.703ms)
Jul 15 14:52:28.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 2.789238ms)
Jul 15 14:52:28.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 2.598569ms)
Jul 15 14:52:28.747: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 2.810769ms)
Jul 15 14:52:28.752: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 6.530448ms)
Jul 15 14:52:28.752: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 7.832565ms)
Jul 15 14:52:28.753: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 7.975289ms)
Jul 15 14:52:28.753: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 7.959086ms)
Jul 15 14:52:28.753: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 7.343021ms)
Jul 15 14:52:28.753: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 7.319381ms)
Jul 15 14:52:28.753: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 8.126692ms)
Jul 15 14:52:28.753: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 7.267538ms)
Jul 15 14:52:28.753: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 7.347852ms)
Jul 15 14:52:28.754: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 9.023736ms)
Jul 15 14:52:28.754: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 8.136533ms)
Jul 15 14:52:28.754: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 9.500318ms)
Jul 15 14:52:28.760: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 5.377559ms)
Jul 15 14:52:28.760: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 6.196869ms)
Jul 15 14:52:28.760: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 6.209584ms)
Jul 15 14:52:28.760: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 5.906658ms)
Jul 15 14:52:28.760: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 6.158739ms)
Jul 15 14:52:28.760: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 5.798922ms)
Jul 15 14:52:28.760: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 6.255254ms)
Jul 15 14:52:28.760: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 6.24703ms)
Jul 15 14:52:28.762: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 6.747758ms)
Jul 15 14:52:28.762: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 7.062319ms)
Jul 15 14:52:28.762: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 6.930081ms)
Jul 15 14:52:28.764: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 9.367865ms)
Jul 15 14:52:28.764: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 9.585639ms)
Jul 15 14:52:28.765: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 9.500768ms)
Jul 15 14:52:28.764: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 9.28792ms)
Jul 15 14:52:28.765: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 9.982723ms)
Jul 15 14:52:28.768: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 3.024212ms)
Jul 15 14:52:28.768: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 3.291827ms)
Jul 15 14:52:28.768: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 3.352143ms)
Jul 15 14:52:28.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 6.814499ms)
Jul 15 14:52:28.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 6.763841ms)
Jul 15 14:52:28.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 6.865538ms)
Jul 15 14:52:28.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 6.935499ms)
Jul 15 14:52:28.772: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 6.565062ms)
Jul 15 14:52:28.776: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 10.649195ms)
Jul 15 14:52:28.776: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 10.866495ms)
Jul 15 14:52:28.776: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 10.774078ms)
Jul 15 14:52:28.776: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 10.941195ms)
Jul 15 14:52:28.776: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 10.978452ms)
Jul 15 14:52:28.778: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 12.63442ms)
Jul 15 14:52:28.784: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 18.216026ms)
Jul 15 14:52:28.784: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 18.625389ms)
Jul 15 14:52:28.795: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 10.566293ms)
Jul 15 14:52:28.795: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 10.850504ms)
Jul 15 14:52:28.795: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 11.087576ms)
Jul 15 14:52:28.795: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 10.965437ms)
Jul 15 14:52:28.795: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 11.115692ms)
Jul 15 14:52:28.796: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 11.307909ms)
Jul 15 14:52:28.796: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 11.306335ms)
Jul 15 14:52:28.796: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 11.109502ms)
Jul 15 14:52:28.796: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 11.292317ms)
Jul 15 14:52:28.796: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 11.373855ms)
Jul 15 14:52:28.796: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 11.564227ms)
Jul 15 14:52:28.796: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 11.475575ms)
Jul 15 14:52:28.796: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 11.513388ms)
Jul 15 14:52:28.796: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 11.719882ms)
Jul 15 14:52:28.796: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 11.876548ms)
Jul 15 14:52:28.796: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 12.140195ms)
Jul 15 14:52:28.808: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 11.854833ms)
Jul 15 14:52:28.808: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 11.896743ms)
Jul 15 14:52:28.809: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 12.292595ms)
Jul 15 14:52:28.809: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 12.598965ms)
Jul 15 14:52:28.809: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 12.761065ms)
Jul 15 14:52:28.809: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 12.572345ms)
Jul 15 14:52:28.809: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 12.939638ms)
Jul 15 14:52:28.809: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 12.812248ms)
Jul 15 14:52:28.809: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 13.069712ms)
Jul 15 14:52:28.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 13.227215ms)
Jul 15 14:52:28.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 13.524153ms)
Jul 15 14:52:28.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 13.221158ms)
Jul 15 14:52:28.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 13.24831ms)
Jul 15 14:52:28.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 13.662028ms)
Jul 15 14:52:28.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 13.698033ms)
Jul 15 14:52:28.810: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 13.841242ms)
Jul 15 14:52:28.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 10.325396ms)
Jul 15 14:52:28.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 10.134784ms)
Jul 15 14:52:28.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 10.107547ms)
Jul 15 14:52:28.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 10.171107ms)
Jul 15 14:52:28.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 10.67273ms)
Jul 15 14:52:28.823: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 11.303131ms)
Jul 15 14:52:28.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 12.511946ms)
Jul 15 14:52:28.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 12.445062ms)
Jul 15 14:52:28.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 11.891985ms)
Jul 15 14:52:28.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 12.797771ms)
Jul 15 14:52:28.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 12.309985ms)
Jul 15 14:52:28.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 12.901184ms)
Jul 15 14:52:28.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 13.220347ms)
Jul 15 14:52:28.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 12.511022ms)
Jul 15 14:52:28.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 13.641446ms)
Jul 15 14:52:28.825: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 12.844579ms)
Jul 15 14:52:28.831: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 5.543624ms)
Jul 15 14:52:28.832: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 5.889365ms)
Jul 15 14:52:28.832: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 5.876694ms)
Jul 15 14:52:28.832: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 5.703381ms)
Jul 15 14:52:28.833: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 6.869456ms)
Jul 15 14:52:28.835: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 9.342746ms)
Jul 15 14:52:28.836: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 10.390947ms)
Jul 15 14:52:28.838: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 11.854823ms)
Jul 15 14:52:28.838: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 12.321344ms)
Jul 15 14:52:28.839: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 13.069812ms)
Jul 15 14:52:28.845: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 19.16563ms)
Jul 15 14:52:28.845: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 19.306374ms)
Jul 15 14:52:28.845: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 19.27751ms)
Jul 15 14:52:28.845: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 19.346899ms)
Jul 15 14:52:28.845: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 19.620393ms)
Jul 15 14:52:28.846: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 19.507337ms)
Jul 15 14:52:28.856: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 10.368293ms)
Jul 15 14:52:28.856: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:1080/proxy/rewri... (200; 10.364004ms)
Jul 15 14:52:28.856: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname1/proxy/: foo (200; 10.51034ms)
Jul 15 14:52:28.856: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:1080/proxy/... (200; 10.730902ms)
Jul 15 14:52:28.856: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/proxy-service-w72xc:portname2/proxy/: bar (200; 10.668107ms)
Jul 15 14:52:28.857: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:460/proxy/: tls baz (200; 10.679676ms)
Jul 15 14:52:28.857: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname1/proxy/: tls baz (200; 11.238149ms)
Jul 15 14:52:28.858: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:160/proxy/: foo (200; 11.519467ms)
Jul 15 14:52:28.858: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/https:proxy-service-w72xc:tlsportname2/proxy/: tls qux (200; 12.442119ms)
Jul 15 14:52:28.859: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 12.578646ms)
Jul 15 14:52:28.859: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname1/proxy/: foo (200; 13.092981ms)
Jul 15 14:52:28.859: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:462/proxy/: tls qux (200; 12.874919ms)
Jul 15 14:52:28.859: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/proxy-service-w72xc-nvqjg/proxy/rewriteme"... (200; 12.897672ms)
Jul 15 14:52:28.859: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/services/http:proxy-service-w72xc:portname2/proxy/: bar (200; 12.897201ms)
Jul 15 14:52:28.860: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/http:proxy-service-w72xc-nvqjg:162/proxy/: bar (200; 13.383119ms)
Jul 15 14:52:28.862: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-5vwfb/pods/https:proxy-service-w72xc-nvqjg:443/proxy/... (200; 16.120588ms)
STEP: deleting ReplicationController proxy-service-w72xc in namespace e2e-tests-proxy-5vwfb, will wait for the garbage collector to delete the pods
Jul 15 14:52:28.920: INFO: Deleting ReplicationController proxy-service-w72xc took: 5.617744ms
Jul 15 14:52:29.020: INFO: Terminating ReplicationController proxy-service-w72xc pods took: 100.317776ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:52:32.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5vwfb" for this suite.
Jul 15 14:52:38.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:52:38.601: INFO: namespace: e2e-tests-proxy-5vwfb, resource: bindings, ignored listing per whitelist
Jul 15 14:52:38.657: INFO: namespace e2e-tests-proxy-5vwfb deletion completed in 6.232250741s

• [SLOW TEST:17.316 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:52:38.659: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-30918607-a710-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 14:52:38.786: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-30926213-a710-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-9qkr8" to be "success or failure"
Jul 15 14:52:38.793: INFO: Pod "pod-projected-configmaps-30926213-a710-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.276382ms
Jul 15 14:52:40.802: INFO: Pod "pod-projected-configmaps-30926213-a710-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016001876s
STEP: Saw pod success
Jul 15 14:52:40.802: INFO: Pod "pod-projected-configmaps-30926213-a710-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:52:40.805: INFO: Trying to get logs from node i-x8osldkx pod pod-projected-configmaps-30926213-a710-11e9-afda-96f40a16177b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 14:52:40.841: INFO: Waiting for pod pod-projected-configmaps-30926213-a710-11e9-afda-96f40a16177b to disappear
Jul 15 14:52:40.844: INFO: Pod pod-projected-configmaps-30926213-a710-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:52:40.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9qkr8" for this suite.
Jul 15 14:52:46.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:52:46.957: INFO: namespace: e2e-tests-projected-9qkr8, resource: bindings, ignored listing per whitelist
Jul 15 14:52:49.236: INFO: namespace e2e-tests-projected-9qkr8 deletion completed in 8.388066824s

• [SLOW TEST:10.577 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:52:49.237: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jul 15 14:52:49.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 api-versions'
Jul 15 14:52:49.438: INFO: stderr: ""
Jul 15 14:52:49.438: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napp.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.istio.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\nconfig.istio.io/v1alpha2\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndevops.kubesphere.io/v1alpha1\nevents.k8s.io/v1beta1\nextensions/v1beta1\njaegertracing.io/v1\nlogging.kubesphere.io/v1alpha1\nmetrics.k8s.io/v1beta1\nmonitoring.coreos.com/v1\nnetworking.istio.io/v1alpha3\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nrbac.istio.io/v1alpha1\nscheduling.k8s.io/v1beta1\nservicemesh.kubesphere.io/v1alpha2\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\ntenant.kubesphere.io/v1alpha1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:52:49.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m769b" for this suite.
Jul 15 14:52:55.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:52:55.517: INFO: namespace: e2e-tests-kubectl-m769b, resource: bindings, ignored listing per whitelist
Jul 15 14:52:57.841: INFO: namespace e2e-tests-kubectl-m769b deletion completed in 8.397635218s

• [SLOW TEST:8.604 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:52:57.842: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3bfb1535-a710-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 14:52:57.921: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3bfb89b1-a710-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-zlbg9" to be "success or failure"
Jul 15 14:52:57.924: INFO: Pod "pod-projected-configmaps-3bfb89b1-a710-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.699852ms
Jul 15 14:52:59.927: INFO: Pod "pod-projected-configmaps-3bfb89b1-a710-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005832688s
STEP: Saw pod success
Jul 15 14:52:59.927: INFO: Pod "pod-projected-configmaps-3bfb89b1-a710-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:52:59.929: INFO: Trying to get logs from node i-tkuhh2hc pod pod-projected-configmaps-3bfb89b1-a710-11e9-afda-96f40a16177b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 14:52:59.951: INFO: Waiting for pod pod-projected-configmaps-3bfb89b1-a710-11e9-afda-96f40a16177b to disappear
Jul 15 14:52:59.954: INFO: Pod pod-projected-configmaps-3bfb89b1-a710-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:52:59.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zlbg9" for this suite.
Jul 15 14:53:05.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:53:06.060: INFO: namespace: e2e-tests-projected-zlbg9, resource: bindings, ignored listing per whitelist
Jul 15 14:53:08.358: INFO: namespace e2e-tests-projected-zlbg9 deletion completed in 8.40062783s

• [SLOW TEST:10.516 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:53:08.358: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jul 15 14:53:08.508: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-pfchw,SelfLink:/api/v1/namespaces/e2e-tests-watch-pfchw/configmaps/e2e-watch-test-resource-version,UID:4245c9c3-a710-11e9-8341-525422241ab4,ResourceVersion:59579,Generation:0,CreationTimestamp:2019-07-15 14:53:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 15 14:53:08.509: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-pfchw,SelfLink:/api/v1/namespaces/e2e-tests-watch-pfchw/configmaps/e2e-watch-test-resource-version,UID:4245c9c3-a710-11e9-8341-525422241ab4,ResourceVersion:59580,Generation:0,CreationTimestamp:2019-07-15 14:53:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:53:08.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-pfchw" for this suite.
Jul 15 14:53:14.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:53:16.511: INFO: namespace: e2e-tests-watch-pfchw, resource: bindings, ignored listing per whitelist
Jul 15 14:53:16.910: INFO: namespace e2e-tests-watch-pfchw deletion completed in 8.396934562s

• [SLOW TEST:8.552 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:53:16.910: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul 15 14:53:17.000: INFO: Waiting up to 5m0s for pod "pod-475aa221-a710-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-dkxnx" to be "success or failure"
Jul 15 14:53:17.003: INFO: Pod "pod-475aa221-a710-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.701113ms
Jul 15 14:53:19.007: INFO: Pod "pod-475aa221-a710-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007601747s
STEP: Saw pod success
Jul 15 14:53:19.007: INFO: Pod "pod-475aa221-a710-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:53:19.010: INFO: Trying to get logs from node i-x8osldkx pod pod-475aa221-a710-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 14:53:19.051: INFO: Waiting for pod pod-475aa221-a710-11e9-afda-96f40a16177b to disappear
Jul 15 14:53:19.054: INFO: Pod pod-475aa221-a710-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:53:19.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dkxnx" for this suite.
Jul 15 14:53:25.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:53:25.168: INFO: namespace: e2e-tests-emptydir-dkxnx, resource: bindings, ignored listing per whitelist
Jul 15 14:53:27.462: INFO: namespace e2e-tests-emptydir-dkxnx deletion completed in 8.403172072s

• [SLOW TEST:10.552 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:53:27.465: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jul 15 14:53:29.583: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-4da6fef0-a710-11e9-afda-96f40a16177b,GenerateName:,Namespace:e2e-tests-events-dkdhz,SelfLink:/api/v1/namespaces/e2e-tests-events-dkdhz/pods/send-events-4da6fef0-a710-11e9-afda-96f40a16177b,UID:4da7832b-a710-11e9-8341-525422241ab4,ResourceVersion:59669,Generation:0,CreationTimestamp:2019-07-15 14:53:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 561606762,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.206/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-97dck {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-97dck,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-97dck true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019ce6b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019ce6d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:53:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:53:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:53:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:53:27 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:10.10.1.206,StartTime:2019-07-15 14:53:27 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-07-15 14:53:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://435b22643f20baeddb047703192a2ac540a6c2520cce98d6831c69a4748c65ed}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jul 15 14:53:31.587: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jul 15 14:53:33.590: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:53:33.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-dkdhz" for this suite.
Jul 15 14:54:13.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:54:14.251: INFO: namespace: e2e-tests-events-dkdhz, resource: bindings, ignored listing per whitelist
Jul 15 14:54:15.998: INFO: namespace e2e-tests-events-dkdhz deletion completed in 42.395695723s

• [SLOW TEST:48.534 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:54:15.999: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:54:16.102: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jul 15 14:54:16.109: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul 15 14:54:21.114: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul 15 14:54:21.114: INFO: Creating deployment "test-rolling-update-deployment"
Jul 15 14:54:21.119: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jul 15 14:54:21.125: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jul 15 14:54:23.133: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jul 15 14:54:23.135: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698799261, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698799261, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63698799261, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63698799261, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul 15 14:54:25.140: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jul 15 14:54:25.158: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-2rckk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2rckk/deployments/test-rolling-update-deployment,UID:6d92c18d-a710-11e9-8341-525422241ab4,ResourceVersion:59847,Generation:1,CreationTimestamp:2019-07-15 14:54:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-07-15 14:54:21 +0000 UTC 2019-07-15 14:54:21 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-07-15 14:54:23 +0000 UTC 2019-07-15 14:54:21 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jul 15 14:54:25.169: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-2rckk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2rckk/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:6d94e6d3-a710-11e9-8341-525422241ab4,ResourceVersion:59838,Generation:1,CreationTimestamp:2019-07-15 14:54:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 6d92c18d-a710-11e9-8341-525422241ab4 0xc002a993c7 0xc002a993c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jul 15 14:54:25.169: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jul 15 14:54:25.169: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-2rckk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2rckk/replicasets/test-rolling-update-controller,UID:6a95d547-a710-11e9-8341-525422241ab4,ResourceVersion:59846,Generation:2,CreationTimestamp:2019-07-15 14:54:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 6d92c18d-a710-11e9-8341-525422241ab4 0xc002a99307 0xc002a99308}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jul 15 14:54:25.176: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-qgqwj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-qgqwj,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-2rckk,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2rckk/pods/test-rolling-update-deployment-68b55d7bc6-qgqwj,UID:6d959553-a710-11e9-8341-525422241ab4,ResourceVersion:59837,Generation:0,CreationTimestamp:2019-07-15 14:54:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.10.1.207/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 6d94e6d3-a710-11e9-8341-525422241ab4 0xc002b076f7 0xc002b076f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8qnqn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8qnqn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-8qnqn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:i-tkuhh2hc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b07810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b07830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:54:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:54:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:54:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 14:54:21 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.23,PodIP:10.10.1.207,StartTime:2019-07-15 14:54:21 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-07-15 14:54:22 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://39350138e02e30d861942c97056a5a678e6011a417549a69f281eeddba7c5922}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:54:25.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2rckk" for this suite.
Jul 15 14:54:31.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:54:31.291: INFO: namespace: e2e-tests-deployment-2rckk, resource: bindings, ignored listing per whitelist
Jul 15 14:54:33.572: INFO: namespace e2e-tests-deployment-2rckk deletion completed in 8.390288198s

• [SLOW TEST:17.573 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:54:33.572: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jul 15 14:54:33.682: INFO: Pod name pod-release: Found 0 pods out of 1
Jul 15 14:54:38.689: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:54:39.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-p2z6r" for this suite.
Jul 15 14:54:45.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:54:45.775: INFO: namespace: e2e-tests-replication-controller-p2z6r, resource: bindings, ignored listing per whitelist
Jul 15 14:54:48.091: INFO: namespace e2e-tests-replication-controller-p2z6r deletion completed in 8.384133239s

• [SLOW TEST:14.519 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:54:48.092: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jul 15 14:54:52.230: INFO: Waiting up to 5m0s for pod "client-envvars-801d05c6-a710-11e9-afda-96f40a16177b" in namespace "e2e-tests-pods-9mgjh" to be "success or failure"
Jul 15 14:54:52.238: INFO: Pod "client-envvars-801d05c6-a710-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.979927ms
Jul 15 14:54:54.240: INFO: Pod "client-envvars-801d05c6-a710-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009921011s
Jul 15 14:54:56.244: INFO: Pod "client-envvars-801d05c6-a710-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013443725s
STEP: Saw pod success
Jul 15 14:54:56.244: INFO: Pod "client-envvars-801d05c6-a710-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:54:56.246: INFO: Trying to get logs from node i-tkuhh2hc pod client-envvars-801d05c6-a710-11e9-afda-96f40a16177b container env3cont: <nil>
STEP: delete the pod
Jul 15 14:54:56.267: INFO: Waiting for pod client-envvars-801d05c6-a710-11e9-afda-96f40a16177b to disappear
Jul 15 14:54:56.269: INFO: Pod client-envvars-801d05c6-a710-11e9-afda-96f40a16177b no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:54:56.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9mgjh" for this suite.
Jul 15 14:55:36.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:55:38.008: INFO: namespace: e2e-tests-pods-9mgjh, resource: bindings, ignored listing per whitelist
Jul 15 14:55:38.658: INFO: namespace e2e-tests-pods-9mgjh deletion completed in 42.385346374s

• [SLOW TEST:50.566 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:55:38.658: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:55:47.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-kpd94" for this suite.
Jul 15 14:56:09.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:56:10.617: INFO: namespace: e2e-tests-replication-controller-kpd94, resource: bindings, ignored listing per whitelist
Jul 15 14:56:12.167: INFO: namespace e2e-tests-replication-controller-kpd94 deletion completed in 24.387456069s

• [SLOW TEST:33.509 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:56:12.170: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jul 15 14:56:12.278: INFO: Waiting up to 5m0s for pod "pod-afd394c0-a710-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-vgwvl" to be "success or failure"
Jul 15 14:56:12.281: INFO: Pod "pod-afd394c0-a710-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.43533ms
Jul 15 14:56:14.290: INFO: Pod "pod-afd394c0-a710-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011513554s
STEP: Saw pod success
Jul 15 14:56:14.290: INFO: Pod "pod-afd394c0-a710-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:56:14.292: INFO: Trying to get logs from node i-tkuhh2hc pod pod-afd394c0-a710-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 14:56:14.321: INFO: Waiting for pod pod-afd394c0-a710-11e9-afda-96f40a16177b to disappear
Jul 15 14:56:14.324: INFO: Pod pod-afd394c0-a710-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:56:14.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vgwvl" for this suite.
Jul 15 14:56:20.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:56:22.407: INFO: namespace: e2e-tests-emptydir-vgwvl, resource: bindings, ignored listing per whitelist
Jul 15 14:56:22.707: INFO: namespace e2e-tests-emptydir-vgwvl deletion completed in 8.379992136s

• [SLOW TEST:10.538 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:56:22.708: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jul 15 14:56:25.348: INFO: Successfully updated pod "labelsupdateb61a7e86-a710-11e9-afda-96f40a16177b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:56:29.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d2qsf" for this suite.
Jul 15 14:56:51.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:56:51.412: INFO: namespace: e2e-tests-projected-d2qsf, resource: bindings, ignored listing per whitelist
Jul 15 14:56:53.762: INFO: namespace e2e-tests-projected-d2qsf deletion completed in 24.378317956s

• [SLOW TEST:31.054 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:56:53.762: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-c89bf5eb-a710-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 14:56:53.864: INFO: Waiting up to 5m0s for pod "pod-configmaps-c89d4e54-a710-11e9-afda-96f40a16177b" in namespace "e2e-tests-configmap-8dgqm" to be "success or failure"
Jul 15 14:56:53.869: INFO: Pod "pod-configmaps-c89d4e54-a710-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.710775ms
Jul 15 14:56:55.875: INFO: Pod "pod-configmaps-c89d4e54-a710-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010352917s
STEP: Saw pod success
Jul 15 14:56:55.875: INFO: Pod "pod-configmaps-c89d4e54-a710-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 14:56:55.882: INFO: Trying to get logs from node i-tkuhh2hc pod pod-configmaps-c89d4e54-a710-11e9-afda-96f40a16177b container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 14:56:55.898: INFO: Waiting for pod pod-configmaps-c89d4e54-a710-11e9-afda-96f40a16177b to disappear
Jul 15 14:56:55.901: INFO: Pod pod-configmaps-c89d4e54-a710-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:56:55.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8dgqm" for this suite.
Jul 15 14:57:01.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:57:03.840: INFO: namespace: e2e-tests-configmap-8dgqm, resource: bindings, ignored listing per whitelist
Jul 15 14:57:04.340: INFO: namespace e2e-tests-configmap-8dgqm deletion completed in 8.435204892s

• [SLOW TEST:10.578 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:57:04.340: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-ceefaabc-a710-11e9-afda-96f40a16177b
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:57:08.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lwtqt" for this suite.
Jul 15 14:57:30.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:57:30.614: INFO: namespace: e2e-tests-configmap-lwtqt, resource: bindings, ignored listing per whitelist
Jul 15 14:57:32.938: INFO: namespace e2e-tests-configmap-lwtqt deletion completed in 24.427032819s

• [SLOW TEST:28.598 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:57:32.939: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jul 15 14:57:33.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-vhxv6'
Jul 15 14:57:33.241: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jul 15 14:57:33.241: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jul 15 14:57:33.256: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-cxqjk]
Jul 15 14:57:33.257: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-cxqjk" in namespace "e2e-tests-kubectl-vhxv6" to be "running and ready"
Jul 15 14:57:33.259: INFO: Pod "e2e-test-nginx-rc-cxqjk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.393732ms
Jul 15 14:57:35.268: INFO: Pod "e2e-test-nginx-rc-cxqjk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011372536s
Jul 15 14:57:37.314: INFO: Pod "e2e-test-nginx-rc-cxqjk": Phase="Running", Reason="", readiness=true. Elapsed: 4.057053763s
Jul 15 14:57:37.314: INFO: Pod "e2e-test-nginx-rc-cxqjk" satisfied condition "running and ready"
Jul 15 14:57:37.314: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-cxqjk]
Jul 15 14:57:37.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-vhxv6'
Jul 15 14:57:37.495: INFO: stderr: ""
Jul 15 14:57:37.495: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Jul 15 14:57:37.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-vhxv6'
Jul 15 14:57:37.642: INFO: stderr: ""
Jul 15 14:57:37.642: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 14:57:37.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vhxv6" for this suite.
Jul 15 14:57:59.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 14:58:00.437: INFO: namespace: e2e-tests-kubectl-vhxv6, resource: bindings, ignored listing per whitelist
Jul 15 14:58:02.039: INFO: namespace e2e-tests-kubectl-vhxv6 deletion completed in 24.391825528s

• [SLOW TEST:29.100 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 14:58:02.039: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-6b5hb
Jul 15 14:58:06.212: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-6b5hb
STEP: checking the pod's current state and verifying that restartCount is present
Jul 15 14:58:06.214: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:02:06.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6b5hb" for this suite.
Jul 15 15:02:12.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:02:12.784: INFO: namespace: e2e-tests-container-probe-6b5hb, resource: bindings, ignored listing per whitelist
Jul 15 15:02:15.130: INFO: namespace e2e-tests-container-probe-6b5hb deletion completed in 8.382486158s

• [SLOW TEST:253.091 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:02:15.131: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul 15 15:02:19.300: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 15:02:19.306: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 15:02:21.307: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 15:02:21.311: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 15:02:23.307: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 15:02:23.312: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 15:02:25.307: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 15:02:25.311: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 15:02:27.308: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 15:02:27.311: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 15:02:29.307: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 15:02:29.309: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 15:02:31.307: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 15:02:31.310: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 15:02:33.307: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 15:02:33.310: INFO: Pod pod-with-poststart-http-hook still exists
Jul 15 15:02:35.307: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul 15 15:02:35.311: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:02:35.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9dqbt" for this suite.
Jul 15 15:02:57.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:02:57.409: INFO: namespace: e2e-tests-container-lifecycle-hook-9dqbt, resource: bindings, ignored listing per whitelist
Jul 15 15:02:59.700: INFO: namespace e2e-tests-container-lifecycle-hook-9dqbt deletion completed in 24.384549986s

• [SLOW TEST:44.570 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:02:59.702: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-a2c3c031-a711-11e9-afda-96f40a16177b
Jul 15 15:02:59.859: INFO: Pod name my-hostname-basic-a2c3c031-a711-11e9-afda-96f40a16177b: Found 0 pods out of 1
Jul 15 15:03:04.864: INFO: Pod name my-hostname-basic-a2c3c031-a711-11e9-afda-96f40a16177b: Found 1 pods out of 1
Jul 15 15:03:04.864: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-a2c3c031-a711-11e9-afda-96f40a16177b" are running
Jul 15 15:03:04.868: INFO: Pod "my-hostname-basic-a2c3c031-a711-11e9-afda-96f40a16177b-vvxjc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 15:02:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 15:03:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 15:03:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-07-15 15:02:59 +0000 UTC Reason: Message:}])
Jul 15 15:03:04.868: INFO: Trying to dial the pod
Jul 15 15:03:09.883: INFO: Controller my-hostname-basic-a2c3c031-a711-11e9-afda-96f40a16177b: Got expected result from replica 1 [my-hostname-basic-a2c3c031-a711-11e9-afda-96f40a16177b-vvxjc]: "my-hostname-basic-a2c3c031-a711-11e9-afda-96f40a16177b-vvxjc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:03:09.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-qnckc" for this suite.
Jul 15 15:03:15.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:03:15.932: INFO: namespace: e2e-tests-replication-controller-qnckc, resource: bindings, ignored listing per whitelist
Jul 15 15:03:18.277: INFO: namespace e2e-tests-replication-controller-qnckc deletion completed in 8.390696026s

• [SLOW TEST:18.576 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:03:18.278: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:03:20.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-7f272" for this suite.
Jul 15 15:04:00.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:04:01.192: INFO: namespace: e2e-tests-kubelet-test-7f272, resource: bindings, ignored listing per whitelist
Jul 15 15:04:02.842: INFO: namespace e2e-tests-kubelet-test-7f272 deletion completed in 42.441775519s

• [SLOW TEST:44.564 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:04:02.843: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zbzbx
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jul 15 15:04:02.985: INFO: Found 0 stateful pods, waiting for 3
Jul 15 15:04:12.989: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 15:04:12.989: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 15:04:12.989: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 15:04:12.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-zbzbx ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 15:04:13.400: INFO: stderr: ""
Jul 15 15:04:13.401: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 15:04:13.401: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jul 15 15:04:23.430: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jul 15 15:04:33.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-zbzbx ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 15:04:33.944: INFO: stderr: ""
Jul 15 15:04:33.944: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 15:04:33.944: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Jul 15 15:04:53.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-zbzbx ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 15:04:54.324: INFO: stderr: ""
Jul 15 15:04:54.324: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 15:04:54.324: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 15:05:04.353: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jul 15 15:05:14.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-zbzbx ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 15:05:14.723: INFO: stderr: ""
Jul 15 15:05:14.723: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 15:05:14.723: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 15:05:24.740: INFO: Waiting for StatefulSet e2e-tests-statefulset-zbzbx/ss2 to complete update
Jul 15 15:05:24.740: INFO: Waiting for Pod e2e-tests-statefulset-zbzbx/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul 15 15:05:24.740: INFO: Waiting for Pod e2e-tests-statefulset-zbzbx/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul 15 15:05:34.748: INFO: Waiting for StatefulSet e2e-tests-statefulset-zbzbx/ss2 to complete update
Jul 15 15:05:34.748: INFO: Waiting for Pod e2e-tests-statefulset-zbzbx/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul 15 15:05:34.748: INFO: Waiting for Pod e2e-tests-statefulset-zbzbx/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul 15 15:05:44.746: INFO: Waiting for StatefulSet e2e-tests-statefulset-zbzbx/ss2 to complete update
Jul 15 15:05:44.746: INFO: Waiting for Pod e2e-tests-statefulset-zbzbx/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jul 15 15:05:54.746: INFO: Waiting for StatefulSet e2e-tests-statefulset-zbzbx/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 15 15:06:04.746: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zbzbx
Jul 15 15:06:04.749: INFO: Scaling statefulset ss2 to 0
Jul 15 15:06:34.767: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 15:06:34.769: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:06:34.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zbzbx" for this suite.
Jul 15 15:06:40.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:06:41.962: INFO: namespace: e2e-tests-statefulset-zbzbx, resource: bindings, ignored listing per whitelist
Jul 15 15:06:43.220: INFO: namespace e2e-tests-statefulset-zbzbx deletion completed in 8.42539857s

• [SLOW TEST:160.378 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:06:43.221: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jul 15 15:06:43.363: INFO: Waiting up to 5m0s for pod "downward-api-27fb95ae-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-xsdps" to be "success or failure"
Jul 15 15:06:43.370: INFO: Pod "downward-api-27fb95ae-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.591045ms
Jul 15 15:06:45.373: INFO: Pod "downward-api-27fb95ae-a712-11e9-afda-96f40a16177b": Phase="Running", Reason="", readiness=true. Elapsed: 2.010200502s
Jul 15 15:06:47.376: INFO: Pod "downward-api-27fb95ae-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013248671s
STEP: Saw pod success
Jul 15 15:06:47.377: INFO: Pod "downward-api-27fb95ae-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:06:47.380: INFO: Trying to get logs from node i-tkuhh2hc pod downward-api-27fb95ae-a712-11e9-afda-96f40a16177b container dapi-container: <nil>
STEP: delete the pod
Jul 15 15:06:47.412: INFO: Waiting for pod downward-api-27fb95ae-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:06:47.417: INFO: Pod downward-api-27fb95ae-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:06:47.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xsdps" for this suite.
Jul 15 15:06:53.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:06:53.532: INFO: namespace: e2e-tests-downward-api-xsdps, resource: bindings, ignored listing per whitelist
Jul 15 15:06:55.814: INFO: namespace e2e-tests-downward-api-xsdps deletion completed in 8.393480514s

• [SLOW TEST:12.593 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:06:55.815: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-2f782019-a712-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 15:06:55.941: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2f78f6f6-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-projected-974xb" to be "success or failure"
Jul 15 15:06:55.945: INFO: Pod "pod-projected-configmaps-2f78f6f6-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.579429ms
Jul 15 15:06:57.948: INFO: Pod "pod-projected-configmaps-2f78f6f6-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005997432s
Jul 15 15:06:59.952: INFO: Pod "pod-projected-configmaps-2f78f6f6-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009602338s
STEP: Saw pod success
Jul 15 15:06:59.952: INFO: Pod "pod-projected-configmaps-2f78f6f6-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:06:59.955: INFO: Trying to get logs from node i-x8osldkx pod pod-projected-configmaps-2f78f6f6-a712-11e9-afda-96f40a16177b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 15:06:59.976: INFO: Waiting for pod pod-projected-configmaps-2f78f6f6-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:06:59.980: INFO: Pod pod-projected-configmaps-2f78f6f6-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:06:59.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-974xb" for this suite.
Jul 15 15:07:06.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:07:06.141: INFO: namespace: e2e-tests-projected-974xb, resource: bindings, ignored listing per whitelist
Jul 15 15:07:08.397: INFO: namespace e2e-tests-projected-974xb deletion completed in 8.412693293s

• [SLOW TEST:12.582 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:07:08.397: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jul 15 15:07:08.574: INFO: Waiting up to 5m0s for pod "downward-api-3701d651-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-hd7t6" to be "success or failure"
Jul 15 15:07:08.579: INFO: Pod "downward-api-3701d651-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.790236ms
Jul 15 15:07:10.584: INFO: Pod "downward-api-3701d651-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009841077s
Jul 15 15:07:12.588: INFO: Pod "downward-api-3701d651-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01405328s
STEP: Saw pod success
Jul 15 15:07:12.588: INFO: Pod "downward-api-3701d651-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:07:12.591: INFO: Trying to get logs from node i-tkuhh2hc pod downward-api-3701d651-a712-11e9-afda-96f40a16177b container dapi-container: <nil>
STEP: delete the pod
Jul 15 15:07:12.627: INFO: Waiting for pod downward-api-3701d651-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:07:12.629: INFO: Pod downward-api-3701d651-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:07:12.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hd7t6" for this suite.
Jul 15 15:07:18.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:07:19.507: INFO: namespace: e2e-tests-downward-api-hd7t6, resource: bindings, ignored listing per whitelist
Jul 15 15:07:21.011: INFO: namespace e2e-tests-downward-api-hd7t6 deletion completed in 8.378839387s

• [SLOW TEST:12.614 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:07:21.012: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jul 15 15:07:21.108: INFO: Waiting up to 5m0s for pod "client-containers-3e7b560b-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-containers-cr6vl" to be "success or failure"
Jul 15 15:07:21.117: INFO: Pod "client-containers-3e7b560b-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.892571ms
Jul 15 15:07:23.121: INFO: Pod "client-containers-3e7b560b-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012825152s
STEP: Saw pod success
Jul 15 15:07:23.121: INFO: Pod "client-containers-3e7b560b-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:07:23.123: INFO: Trying to get logs from node i-tkuhh2hc pod client-containers-3e7b560b-a712-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 15:07:23.148: INFO: Waiting for pod client-containers-3e7b560b-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:07:23.155: INFO: Pod client-containers-3e7b560b-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:07:23.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-cr6vl" for this suite.
Jul 15 15:07:29.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:07:31.129: INFO: namespace: e2e-tests-containers-cr6vl, resource: bindings, ignored listing per whitelist
Jul 15 15:07:31.579: INFO: namespace e2e-tests-containers-cr6vl deletion completed in 8.419646048s

• [SLOW TEST:10.567 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:07:31.583: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jul 15 15:07:36.221: INFO: Successfully updated pod "annotationupdate44c8e963-a712-11e9-afda-96f40a16177b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:07:38.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fcxk6" for this suite.
Jul 15 15:08:00.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:08:00.377: INFO: namespace: e2e-tests-downward-api-fcxk6, resource: bindings, ignored listing per whitelist
Jul 15 15:08:02.651: INFO: namespace e2e-tests-downward-api-fcxk6 deletion completed in 24.400866645s

• [SLOW TEST:31.068 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:08:02.651: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 15:08:02.821: INFO: Waiting up to 5m0s for pod "downwardapi-volume-57572d23-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-n9ldt" to be "success or failure"
Jul 15 15:08:02.826: INFO: Pod "downwardapi-volume-57572d23-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.812304ms
Jul 15 15:08:04.833: INFO: Pod "downwardapi-volume-57572d23-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011220282s
STEP: Saw pod success
Jul 15 15:08:04.833: INFO: Pod "downwardapi-volume-57572d23-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:08:04.836: INFO: Trying to get logs from node i-tkuhh2hc pod downwardapi-volume-57572d23-a712-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 15:08:04.867: INFO: Waiting for pod downwardapi-volume-57572d23-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:08:04.871: INFO: Pod downwardapi-volume-57572d23-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:08:04.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n9ldt" for this suite.
Jul 15 15:08:10.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:08:12.764: INFO: namespace: e2e-tests-downward-api-n9ldt, resource: bindings, ignored listing per whitelist
Jul 15 15:08:13.264: INFO: namespace e2e-tests-downward-api-n9ldt deletion completed in 8.387880777s

• [SLOW TEST:10.613 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:08:13.264: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:08:19.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-69cc8" for this suite.
Jul 15 15:08:25.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:08:27.555: INFO: namespace: e2e-tests-namespaces-69cc8, resource: bindings, ignored listing per whitelist
Jul 15 15:08:27.855: INFO: namespace e2e-tests-namespaces-69cc8 deletion completed in 8.396143202s
STEP: Destroying namespace "e2e-tests-nsdeletetest-plpqj" for this suite.
Jul 15 15:08:27.857: INFO: Namespace e2e-tests-nsdeletetest-plpqj was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-s7j6n" for this suite.
Jul 15 15:08:33.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:08:35.493: INFO: namespace: e2e-tests-nsdeletetest-s7j6n, resource: bindings, ignored listing per whitelist
Jul 15 15:08:36.243: INFO: namespace e2e-tests-nsdeletetest-s7j6n deletion completed in 8.385680785s

• [SLOW TEST:22.979 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:08:36.245: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jul 15 15:08:36.356: INFO: Waiting up to 5m0s for pod "downward-api-6b54d06c-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-dq6qb" to be "success or failure"
Jul 15 15:08:36.359: INFO: Pod "downward-api-6b54d06c-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.137808ms
Jul 15 15:08:38.363: INFO: Pod "downward-api-6b54d06c-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007126712s
STEP: Saw pod success
Jul 15 15:08:38.363: INFO: Pod "downward-api-6b54d06c-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:08:38.367: INFO: Trying to get logs from node i-tkuhh2hc pod downward-api-6b54d06c-a712-11e9-afda-96f40a16177b container dapi-container: <nil>
STEP: delete the pod
Jul 15 15:08:38.391: INFO: Waiting for pod downward-api-6b54d06c-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:08:38.399: INFO: Pod downward-api-6b54d06c-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:08:38.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dq6qb" for this suite.
Jul 15 15:08:44.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:08:44.987: INFO: namespace: e2e-tests-downward-api-dq6qb, resource: bindings, ignored listing per whitelist
Jul 15 15:08:46.786: INFO: namespace e2e-tests-downward-api-dq6qb deletion completed in 8.381423572s

• [SLOW TEST:10.542 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:08:46.789: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jul 15 15:08:46.890: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-khhzv,SelfLink:/api/v1/namespaces/e2e-tests-watch-khhzv/configmaps/e2e-watch-test-label-changed,UID:719b08d3-a712-11e9-8341-525422241ab4,ResourceVersion:62637,Generation:0,CreationTimestamp:2019-07-15 15:08:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jul 15 15:08:46.890: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-khhzv,SelfLink:/api/v1/namespaces/e2e-tests-watch-khhzv/configmaps/e2e-watch-test-label-changed,UID:719b08d3-a712-11e9-8341-525422241ab4,ResourceVersion:62638,Generation:0,CreationTimestamp:2019-07-15 15:08:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jul 15 15:08:46.891: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-khhzv,SelfLink:/api/v1/namespaces/e2e-tests-watch-khhzv/configmaps/e2e-watch-test-label-changed,UID:719b08d3-a712-11e9-8341-525422241ab4,ResourceVersion:62639,Generation:0,CreationTimestamp:2019-07-15 15:08:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jul 15 15:08:56.924: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-khhzv,SelfLink:/api/v1/namespaces/e2e-tests-watch-khhzv/configmaps/e2e-watch-test-label-changed,UID:719b08d3-a712-11e9-8341-525422241ab4,ResourceVersion:62662,Generation:0,CreationTimestamp:2019-07-15 15:08:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jul 15 15:08:56.924: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-khhzv,SelfLink:/api/v1/namespaces/e2e-tests-watch-khhzv/configmaps/e2e-watch-test-label-changed,UID:719b08d3-a712-11e9-8341-525422241ab4,ResourceVersion:62663,Generation:0,CreationTimestamp:2019-07-15 15:08:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jul 15 15:08:56.924: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-khhzv,SelfLink:/api/v1/namespaces/e2e-tests-watch-khhzv/configmaps/e2e-watch-test-label-changed,UID:719b08d3-a712-11e9-8341-525422241ab4,ResourceVersion:62664,Generation:0,CreationTimestamp:2019-07-15 15:08:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:08:56.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-khhzv" for this suite.
Jul 15 15:09:02.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:09:02.986: INFO: namespace: e2e-tests-watch-khhzv, resource: bindings, ignored listing per whitelist
Jul 15 15:09:05.315: INFO: namespace e2e-tests-watch-khhzv deletion completed in 8.38545886s

• [SLOW TEST:18.526 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:09:05.317: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul 15 15:09:05.452: INFO: Waiting up to 5m0s for pod "pod-7cab3946-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-cvqkw" to be "success or failure"
Jul 15 15:09:05.464: INFO: Pod "pod-7cab3946-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.837981ms
Jul 15 15:09:07.473: INFO: Pod "pod-7cab3946-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020272364s
Jul 15 15:09:09.476: INFO: Pod "pod-7cab3946-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023403065s
STEP: Saw pod success
Jul 15 15:09:09.476: INFO: Pod "pod-7cab3946-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:09:09.478: INFO: Trying to get logs from node i-tkuhh2hc pod pod-7cab3946-a712-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 15:09:09.526: INFO: Waiting for pod pod-7cab3946-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:09:09.528: INFO: Pod pod-7cab3946-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:09:09.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cvqkw" for this suite.
Jul 15 15:09:15.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:09:17.415: INFO: namespace: e2e-tests-emptydir-cvqkw, resource: bindings, ignored listing per whitelist
Jul 15 15:09:17.915: INFO: namespace e2e-tests-emptydir-cvqkw deletion completed in 8.383243035s

• [SLOW TEST:12.598 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:09:17.916: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-82lk4
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-82lk4 to expose endpoints map[]
Jul 15 15:09:18.041: INFO: Get endpoints failed (3.570134ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jul 15 15:09:19.044: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-82lk4 exposes endpoints map[] (1.006385625s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-82lk4
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-82lk4 to expose endpoints map[pod1:[80]]
Jul 15 15:09:22.066: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-82lk4 exposes endpoints map[pod1:[80]] (3.016938559s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-82lk4
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-82lk4 to expose endpoints map[pod1:[80] pod2:[80]]
Jul 15 15:09:25.109: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-82lk4 exposes endpoints map[pod2:[80] pod1:[80]] (3.038168006s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-82lk4
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-82lk4 to expose endpoints map[pod2:[80]]
Jul 15 15:09:26.141: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-82lk4 exposes endpoints map[pod2:[80]] (1.024840167s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-82lk4
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-82lk4 to expose endpoints map[]
Jul 15 15:09:26.164: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-82lk4 exposes endpoints map[] (7.41486ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:09:26.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-82lk4" for this suite.
Jul 15 15:09:48.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:09:48.290: INFO: namespace: e2e-tests-services-82lk4, resource: bindings, ignored listing per whitelist
Jul 15 15:09:50.576: INFO: namespace e2e-tests-services-82lk4 deletion completed in 24.394724027s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:32.660 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:09:50.576: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul 15 15:09:50.696: INFO: Waiting up to 5m0s for pod "pod-97a40690-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-emptydir-lrqzm" to be "success or failure"
Jul 15 15:09:50.701: INFO: Pod "pod-97a40690-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.843454ms
Jul 15 15:09:52.704: INFO: Pod "pod-97a40690-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007490333s
Jul 15 15:09:54.708: INFO: Pod "pod-97a40690-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011265509s
STEP: Saw pod success
Jul 15 15:09:54.708: INFO: Pod "pod-97a40690-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:09:54.713: INFO: Trying to get logs from node i-x8osldkx pod pod-97a40690-a712-11e9-afda-96f40a16177b container test-container: <nil>
STEP: delete the pod
Jul 15 15:09:54.730: INFO: Waiting for pod pod-97a40690-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:09:54.733: INFO: Pod pod-97a40690-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:09:54.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lrqzm" for this suite.
Jul 15 15:10:00.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:10:01.017: INFO: namespace: e2e-tests-emptydir-lrqzm, resource: bindings, ignored listing per whitelist
Jul 15 15:10:03.118: INFO: namespace e2e-tests-emptydir-lrqzm deletion completed in 8.380161496s

• [SLOW TEST:12.541 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:10:03.122: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jul 15 15:10:03.243: INFO: Waiting up to 5m0s for pod "downward-api-9f1e8e80-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-lvhfg" to be "success or failure"
Jul 15 15:10:03.253: INFO: Pod "downward-api-9f1e8e80-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.605814ms
Jul 15 15:10:05.255: INFO: Pod "downward-api-9f1e8e80-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012220544s
STEP: Saw pod success
Jul 15 15:10:05.256: INFO: Pod "downward-api-9f1e8e80-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:10:05.258: INFO: Trying to get logs from node i-tkuhh2hc pod downward-api-9f1e8e80-a712-11e9-afda-96f40a16177b container dapi-container: <nil>
STEP: delete the pod
Jul 15 15:10:05.277: INFO: Waiting for pod downward-api-9f1e8e80-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:10:05.287: INFO: Pod downward-api-9f1e8e80-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:10:05.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lvhfg" for this suite.
Jul 15 15:10:11.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:10:11.379: INFO: namespace: e2e-tests-downward-api-lvhfg, resource: bindings, ignored listing per whitelist
Jul 15 15:10:13.682: INFO: namespace e2e-tests-downward-api-lvhfg deletion completed in 8.391217077s

• [SLOW TEST:10.560 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:10:13.682: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-5mjqs
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-5mjqs
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-5mjqs
Jul 15 15:10:13.787: INFO: Found 0 stateful pods, waiting for 1
Jul 15 15:10:23.791: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jul 15 15:10:23.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-5mjqs ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 15:10:24.103: INFO: stderr: ""
Jul 15 15:10:24.103: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 15:10:24.103: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 15:10:24.107: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul 15 15:10:34.111: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 15:10:34.111: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 15:10:34.148: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999920268s
Jul 15 15:10:35.154: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.978674699s
Jul 15 15:10:36.158: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.973508484s
Jul 15 15:10:37.162: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.969274768s
Jul 15 15:10:38.167: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965365214s
Jul 15 15:10:39.171: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.960422627s
Jul 15 15:10:40.176: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.956092404s
Jul 15 15:10:41.180: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.951169549s
Jul 15 15:10:42.185: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.947178582s
Jul 15 15:10:43.190: INFO: Verifying statefulset ss doesn't scale past 3 for another 941.7127ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-5mjqs
Jul 15 15:10:44.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-5mjqs ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 15:10:44.537: INFO: stderr: ""
Jul 15 15:10:44.537: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 15:10:44.537: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 15:10:44.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-5mjqs ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 15:10:44.873: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jul 15 15:10:44.873: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 15:10:44.873: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 15:10:44.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-5mjqs ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jul 15 15:10:45.299: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jul 15 15:10:45.299: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jul 15 15:10:45.299: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jul 15 15:10:45.304: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jul 15 15:10:55.313: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 15:10:55.313: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul 15 15:10:55.313: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jul 15 15:10:55.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-5mjqs ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 15:10:55.695: INFO: stderr: ""
Jul 15 15:10:55.695: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 15:10:55.695: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 15:10:55.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-5mjqs ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 15:10:55.999: INFO: stderr: ""
Jul 15 15:10:56.000: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 15:10:56.000: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 15:10:56.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 exec --namespace=e2e-tests-statefulset-5mjqs ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jul 15 15:10:56.414: INFO: stderr: ""
Jul 15 15:10:56.414: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jul 15 15:10:56.414: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jul 15 15:10:56.414: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 15:10:56.417: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jul 15 15:11:06.423: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 15:11:06.423: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 15:11:06.423: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul 15 15:11:06.433: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Jul 15 15:11:06.433: INFO: ss-0  i-x8osldkx  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  }]
Jul 15 15:11:06.434: INFO: ss-1  i-tkuhh2hc  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  }]
Jul 15 15:11:06.434: INFO: ss-2  i-x8osldkx  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  }]
Jul 15 15:11:06.434: INFO: 
Jul 15 15:11:06.434: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 15 15:11:07.439: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Jul 15 15:11:07.439: INFO: ss-0  i-x8osldkx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  }]
Jul 15 15:11:07.439: INFO: ss-1  i-tkuhh2hc  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  }]
Jul 15 15:11:07.439: INFO: ss-2  i-x8osldkx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  }]
Jul 15 15:11:07.439: INFO: 
Jul 15 15:11:07.439: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 15 15:11:08.443: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Jul 15 15:11:08.443: INFO: ss-0  i-x8osldkx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  }]
Jul 15 15:11:08.443: INFO: ss-1  i-tkuhh2hc  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  }]
Jul 15 15:11:08.443: INFO: ss-2  i-x8osldkx  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  }]
Jul 15 15:11:08.443: INFO: 
Jul 15 15:11:08.443: INFO: StatefulSet ss has not reached scale 0, at 3
Jul 15 15:11:09.447: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Jul 15 15:11:09.447: INFO: ss-0  i-x8osldkx  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  }]
Jul 15 15:11:09.447: INFO: ss-2  i-x8osldkx  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  }]
Jul 15 15:11:09.447: INFO: 
Jul 15 15:11:09.447: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 15 15:11:10.454: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Jul 15 15:11:10.454: INFO: ss-0  i-x8osldkx  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  }]
Jul 15 15:11:10.454: INFO: ss-2  i-x8osldkx  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  }]
Jul 15 15:11:10.454: INFO: 
Jul 15 15:11:10.454: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 15 15:11:11.458: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Jul 15 15:11:11.458: INFO: ss-0  i-x8osldkx  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  }]
Jul 15 15:11:11.458: INFO: ss-2  i-x8osldkx  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  }]
Jul 15 15:11:11.458: INFO: 
Jul 15 15:11:11.458: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 15 15:11:12.462: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Jul 15 15:11:12.462: INFO: ss-0  i-x8osldkx  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  }]
Jul 15 15:11:12.462: INFO: ss-2  i-x8osldkx  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  }]
Jul 15 15:11:12.462: INFO: 
Jul 15 15:11:12.462: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 15 15:11:13.466: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Jul 15 15:11:13.466: INFO: ss-0  i-x8osldkx  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:13 +0000 UTC  }]
Jul 15 15:11:13.466: INFO: ss-2  i-x8osldkx  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-07-15 15:10:34 +0000 UTC  }]
Jul 15 15:11:13.466: INFO: 
Jul 15 15:11:13.466: INFO: StatefulSet ss has not reached scale 0, at 2
Jul 15 15:11:14.469: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.962608674s
Jul 15 15:11:15.474: INFO: Verifying statefulset ss doesn't scale past 0 for another 959.094426ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-5mjqs
Jul 15 15:11:16.477: INFO: Scaling statefulset ss to 0
Jul 15 15:11:16.486: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jul 15 15:11:16.489: INFO: Deleting all statefulset in ns e2e-tests-statefulset-5mjqs
Jul 15 15:11:16.492: INFO: Scaling statefulset ss to 0
Jul 15 15:11:16.505: INFO: Waiting for statefulset status.replicas updated to 0
Jul 15 15:11:16.506: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:11:16.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-5mjqs" for this suite.
Jul 15 15:11:22.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:11:24.334: INFO: namespace: e2e-tests-statefulset-5mjqs, resource: bindings, ignored listing per whitelist
Jul 15 15:11:24.985: INFO: namespace e2e-tests-statefulset-5mjqs deletion completed in 8.405499644s

• [SLOW TEST:71.303 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:11:24.986: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jul 15 15:11:25.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-170914682 --namespace=e2e-tests-kubectl-j2zdh run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jul 15 15:11:27.749: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jul 15 15:11:27.749: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:11:29.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j2zdh" for this suite.
Jul 15 15:11:39.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:11:39.808: INFO: namespace: e2e-tests-kubectl-j2zdh, resource: bindings, ignored listing per whitelist
Jul 15 15:11:42.141: INFO: namespace e2e-tests-kubectl-j2zdh deletion completed in 12.384289453s

• [SLOW TEST:17.156 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:11:42.142: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jul 15 15:11:42.255: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da23258a-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-downward-api-7v8qq" to be "success or failure"
Jul 15 15:11:42.258: INFO: Pod "downwardapi-volume-da23258a-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.559759ms
Jul 15 15:11:44.261: INFO: Pod "downwardapi-volume-da23258a-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005425073s
STEP: Saw pod success
Jul 15 15:11:44.261: INFO: Pod "downwardapi-volume-da23258a-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:11:44.262: INFO: Trying to get logs from node i-x8osldkx pod downwardapi-volume-da23258a-a712-11e9-afda-96f40a16177b container client-container: <nil>
STEP: delete the pod
Jul 15 15:11:44.281: INFO: Waiting for pod downwardapi-volume-da23258a-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:11:44.283: INFO: Pod downwardapi-volume-da23258a-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:11:44.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7v8qq" for this suite.
Jul 15 15:11:50.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:11:50.351: INFO: namespace: e2e-tests-downward-api-7v8qq, resource: bindings, ignored listing per whitelist
Jul 15 15:11:52.673: INFO: namespace e2e-tests-downward-api-7v8qq deletion completed in 8.385770587s

• [SLOW TEST:10.531 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:11:52.678: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e0680619-a712-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume secrets
Jul 15 15:11:52.790: INFO: Waiting up to 5m0s for pod "pod-secrets-e06885f6-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-secrets-kjqcg" to be "success or failure"
Jul 15 15:11:52.802: INFO: Pod "pod-secrets-e06885f6-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.534475ms
Jul 15 15:11:54.806: INFO: Pod "pod-secrets-e06885f6-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015150972s
STEP: Saw pod success
Jul 15 15:11:54.806: INFO: Pod "pod-secrets-e06885f6-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:11:54.809: INFO: Trying to get logs from node i-tkuhh2hc pod pod-secrets-e06885f6-a712-11e9-afda-96f40a16177b container secret-volume-test: <nil>
STEP: delete the pod
Jul 15 15:11:54.846: INFO: Waiting for pod pod-secrets-e06885f6-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:11:54.847: INFO: Pod pod-secrets-e06885f6-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:11:54.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kjqcg" for this suite.
Jul 15 15:12:00.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:12:02.091: INFO: namespace: e2e-tests-secrets-kjqcg, resource: bindings, ignored listing per whitelist
Jul 15 15:12:03.240: INFO: namespace e2e-tests-secrets-kjqcg deletion completed in 8.385551576s

• [SLOW TEST:10.563 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jul 15 15:12:03.241: INFO: >>> kubeConfig: /tmp/kubeconfig-170914682
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-e6b45fe3-a712-11e9-afda-96f40a16177b
STEP: Creating a pod to test consume configMaps
Jul 15 15:12:03.345: INFO: Waiting up to 5m0s for pod "pod-configmaps-e6b50113-a712-11e9-afda-96f40a16177b" in namespace "e2e-tests-configmap-5d8wx" to be "success or failure"
Jul 15 15:12:03.347: INFO: Pod "pod-configmaps-e6b50113-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.868177ms
Jul 15 15:12:05.350: INFO: Pod "pod-configmaps-e6b50113-a712-11e9-afda-96f40a16177b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004846177s
Jul 15 15:12:07.353: INFO: Pod "pod-configmaps-e6b50113-a712-11e9-afda-96f40a16177b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008061783s
STEP: Saw pod success
Jul 15 15:12:07.353: INFO: Pod "pod-configmaps-e6b50113-a712-11e9-afda-96f40a16177b" satisfied condition "success or failure"
Jul 15 15:12:07.356: INFO: Trying to get logs from node i-x8osldkx pod pod-configmaps-e6b50113-a712-11e9-afda-96f40a16177b container configmap-volume-test: <nil>
STEP: delete the pod
Jul 15 15:12:07.383: INFO: Waiting for pod pod-configmaps-e6b50113-a712-11e9-afda-96f40a16177b to disappear
Jul 15 15:12:07.390: INFO: Pod pod-configmaps-e6b50113-a712-11e9-afda-96f40a16177b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jul 15 15:12:07.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5d8wx" for this suite.
Jul 15 15:12:13.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jul 15 15:12:13.440: INFO: namespace: e2e-tests-configmap-5d8wx, resource: bindings, ignored listing per whitelist
Jul 15 15:12:15.782: INFO: namespace e2e-tests-configmap-5d8wx deletion completed in 8.388126972s

• [SLOW TEST:12.542 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSJul 15 15:12:15.783: INFO: Running AfterSuite actions on all nodes
Jul 15 15:12:15.785: INFO: Running AfterSuite actions on node 1
Jul 15 15:12:15.785: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6617.412 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h50m18.775318752s
Test Suite Passed
