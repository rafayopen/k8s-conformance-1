I0114 05:48:49.293252      13 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-949281363
I0114 05:48:49.293327      13 e2e.go:224] Starting e2e run "102c12cd-17c0-11e9-912e-6a405af5e95c" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1547444928 - Will randomize all specs
Will run 201 of 1946 specs

Jan 14 05:48:49.533: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 05:48:49.536: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 14 05:48:49.554: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 14 05:48:49.590: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 14 05:48:49.590: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Jan 14 05:48:49.590: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 14 05:48:49.599: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'fluentd-v1.1.0' (0 seconds elapsed)
Jan 14 05:48:49.599: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jan 14 05:48:49.599: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'nginx-ingress-controller' (0 seconds elapsed)
Jan 14 05:48:49.599: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
Jan 14 05:48:49.599: INFO: e2e test version: v1.13.0
Jan 14 05:48:49.600: INFO: kube-apiserver version: v1.13.1
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:48:49.601: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename deployment
Jan 14 05:48:49.740: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 05:48:49.742: INFO: Creating deployment "test-recreate-deployment"
Jan 14 05:48:49.747: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 14 05:48:49.753: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Jan 14 05:48:51.759: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 14 05:48:51.775: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 14 05:48:51.782: INFO: Updating deployment test-recreate-deployment
Jan 14 05:48:51.782: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 14 05:48:51.901: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-h8c4j,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h8c4j/deployments/test-recreate-deployment,UID:10c4f99d-17c0-11e9-b726-525400ada096,ResourceVersion:50790,Generation:2,CreationTimestamp:2019-01-14 05:48:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-14 05:48:51 +0000 UTC 2019-01-14 05:48:51 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-14 05:48:51 +0000 UTC 2019-01-14 05:48:49 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan 14 05:48:51.905: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-h8c4j,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h8c4j/replicasets/test-recreate-deployment-697fbf54bf,UID:12026668-17c0-11e9-b726-525400ada096,ResourceVersion:50789,Generation:1,CreationTimestamp:2019-01-14 05:48:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 10c4f99d-17c0-11e9-b726-525400ada096 0xc000dce027 0xc000dce028}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 14 05:48:51.905: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 14 05:48:51.905: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-h8c4j,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h8c4j/replicasets/test-recreate-deployment-5dfdcc846d,UID:10c6a33a-17c0-11e9-b726-525400ada096,ResourceVersion:50778,Generation:2,CreationTimestamp:2019-01-14 05:48:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 10c4f99d-17c0-11e9-b726-525400ada096 0xc000783f67 0xc000783f68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 14 05:48:51.909: INFO: Pod "test-recreate-deployment-697fbf54bf-w4tnd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-w4tnd,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-h8c4j,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h8c4j/pods/test-recreate-deployment-697fbf54bf-w4tnd,UID:1204c133-17c0-11e9-b726-525400ada096,ResourceVersion:50791,Generation:0,CreationTimestamp:2019-01-14 05:48:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 12026668-17c0-11e9-b726-525400ada096 0xc000dce8a7 0xc000dce8a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wkqgv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wkqgv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wkqgv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dce920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dce940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 05:48:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 05:48:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 05:48:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 05:48:51 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 05:48:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:48:51.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-h8c4j" for this suite.
Jan 14 05:48:57.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:48:58.084: INFO: namespace: e2e-tests-deployment-h8c4j, resource: bindings, ignored listing per whitelist
Jan 14 05:48:58.110: INFO: namespace e2e-tests-deployment-h8c4j deletion completed in 6.197049707s

• [SLOW TEST:8.510 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:48:58.111: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 14 05:48:58.182: INFO: Waiting up to 5m0s for pod "downward-api-15ffb8b7-17c0-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-mfb62" to be "success or failure"
Jan 14 05:48:58.192: INFO: Pod "downward-api-15ffb8b7-17c0-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.36427ms
Jan 14 05:49:00.195: INFO: Pod "downward-api-15ffb8b7-17c0-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013103103s
STEP: Saw pod success
Jan 14 05:49:00.195: INFO: Pod "downward-api-15ffb8b7-17c0-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 05:49:00.197: INFO: Trying to get logs from node paaswkr2 pod downward-api-15ffb8b7-17c0-11e9-912e-6a405af5e95c container dapi-container: <nil>
STEP: delete the pod
Jan 14 05:49:00.222: INFO: Waiting for pod downward-api-15ffb8b7-17c0-11e9-912e-6a405af5e95c to disappear
Jan 14 05:49:00.230: INFO: Pod downward-api-15ffb8b7-17c0-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:49:00.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mfb62" for this suite.
Jan 14 05:49:06.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:49:06.314: INFO: namespace: e2e-tests-downward-api-mfb62, resource: bindings, ignored listing per whitelist
Jan 14 05:49:06.340: INFO: namespace e2e-tests-downward-api-mfb62 deletion completed in 6.107136448s

• [SLOW TEST:8.230 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:49:06.340: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 14 05:49:06.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-k6wjs'
Jan 14 05:49:06.652: INFO: stderr: ""
Jan 14 05:49:06.652: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan 14 05:49:11.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-k6wjs -o json'
Jan 14 05:49:11.794: INFO: stderr: ""
Jan 14 05:49:11.794: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-01-14T05:49:06Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-k6wjs\",\n        \"resourceVersion\": \"50877\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-k6wjs/pods/e2e-test-nginx-pod\",\n        \"uid\": \"1ad55538-17c0-11e9-b726-525400ada096\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-5kqrz\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"paaswkr2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-5kqrz\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-5kqrz\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-14T05:49:06Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-14T05:49:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-14T05:49:07Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-14T05:49:06Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://a59c891e8efc2436c02407b25c8b35cc03643d8f39fe192d0f8c1e0e004fafbe\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-14T05:49:07Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.10.105\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.64.9\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-14T05:49:06Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan 14 05:49:11.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 replace -f - --namespace=e2e-tests-kubectl-k6wjs'
Jan 14 05:49:12.044: INFO: stderr: ""
Jan 14 05:49:12.044: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Jan 14 05:49:12.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-k6wjs'
Jan 14 05:49:16.447: INFO: stderr: ""
Jan 14 05:49:16.447: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:49:16.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k6wjs" for this suite.
Jan 14 05:49:22.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:49:22.556: INFO: namespace: e2e-tests-kubectl-k6wjs, resource: bindings, ignored listing per whitelist
Jan 14 05:49:22.595: INFO: namespace e2e-tests-kubectl-k6wjs deletion completed in 6.141422082s

• [SLOW TEST:16.255 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:49:22.595: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Jan 14 05:49:22.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-jkltk'
Jan 14 05:49:22.932: INFO: stderr: ""
Jan 14 05:49:22.932: INFO: stdout: "pod/pause created\n"
Jan 14 05:49:22.932: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 14 05:49:22.932: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-jkltk" to be "running and ready"
Jan 14 05:49:22.953: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 20.917085ms
Jan 14 05:49:24.956: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.023928974s
Jan 14 05:49:24.956: INFO: Pod "pause" satisfied condition "running and ready"
Jan 14 05:49:24.956: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan 14 05:49:24.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-jkltk'
Jan 14 05:49:25.067: INFO: stderr: ""
Jan 14 05:49:25.067: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan 14 05:49:25.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pod pause -L testing-label --namespace=e2e-tests-kubectl-jkltk'
Jan 14 05:49:25.162: INFO: stderr: ""
Jan 14 05:49:25.162: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan 14 05:49:25.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 label pods pause testing-label- --namespace=e2e-tests-kubectl-jkltk'
Jan 14 05:49:25.269: INFO: stderr: ""
Jan 14 05:49:25.269: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan 14 05:49:25.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pod pause -L testing-label --namespace=e2e-tests-kubectl-jkltk'
Jan 14 05:49:25.350: INFO: stderr: ""
Jan 14 05:49:25.350: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Jan 14 05:49:25.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jkltk'
Jan 14 05:49:25.449: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 14 05:49:25.449: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 14 05:49:25.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-jkltk'
Jan 14 05:49:25.662: INFO: stderr: "No resources found.\n"
Jan 14 05:49:25.662: INFO: stdout: ""
Jan 14 05:49:25.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -l name=pause --namespace=e2e-tests-kubectl-jkltk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 14 05:49:25.818: INFO: stderr: ""
Jan 14 05:49:25.818: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:49:25.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jkltk" for this suite.
Jan 14 05:49:31.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:49:31.975: INFO: namespace: e2e-tests-kubectl-jkltk, resource: bindings, ignored listing per whitelist
Jan 14 05:49:31.988: INFO: namespace e2e-tests-kubectl-jkltk deletion completed in 6.163004113s

• [SLOW TEST:9.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:49:31.988: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 14 05:49:34.603: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2a32e907-17c0-11e9-912e-6a405af5e95c"
Jan 14 05:49:34.603: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2a32e907-17c0-11e9-912e-6a405af5e95c" in namespace "e2e-tests-pods-hdp8k" to be "terminated due to deadline exceeded"
Jan 14 05:49:34.608: INFO: Pod "pod-update-activedeadlineseconds-2a32e907-17c0-11e9-912e-6a405af5e95c": Phase="Running", Reason="", readiness=true. Elapsed: 5.277696ms
Jan 14 05:49:36.612: INFO: Pod "pod-update-activedeadlineseconds-2a32e907-17c0-11e9-912e-6a405af5e95c": Phase="Running", Reason="", readiness=true. Elapsed: 2.008468624s
Jan 14 05:49:38.615: INFO: Pod "pod-update-activedeadlineseconds-2a32e907-17c0-11e9-912e-6a405af5e95c": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.011724975s
Jan 14 05:49:38.615: INFO: Pod "pod-update-activedeadlineseconds-2a32e907-17c0-11e9-912e-6a405af5e95c" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:49:38.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hdp8k" for this suite.
Jan 14 05:49:44.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:49:44.667: INFO: namespace: e2e-tests-pods-hdp8k, resource: bindings, ignored listing per whitelist
Jan 14 05:49:44.717: INFO: namespace e2e-tests-pods-hdp8k deletion completed in 6.098013411s

• [SLOW TEST:12.729 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:49:44.717: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 05:49:44.805: INFO: Waiting up to 5m0s for pod "downwardapi-volume-31c90cbd-17c0-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-p76cs" to be "success or failure"
Jan 14 05:49:44.814: INFO: Pod "downwardapi-volume-31c90cbd-17c0-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.931786ms
Jan 14 05:49:46.818: INFO: Pod "downwardapi-volume-31c90cbd-17c0-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013569625s
STEP: Saw pod success
Jan 14 05:49:46.818: INFO: Pod "downwardapi-volume-31c90cbd-17c0-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 05:49:46.823: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-31c90cbd-17c0-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 05:49:46.859: INFO: Waiting for pod downwardapi-volume-31c90cbd-17c0-11e9-912e-6a405af5e95c to disappear
Jan 14 05:49:46.863: INFO: Pod downwardapi-volume-31c90cbd-17c0-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:49:46.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p76cs" for this suite.
Jan 14 05:49:52.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:49:52.935: INFO: namespace: e2e-tests-downward-api-p76cs, resource: bindings, ignored listing per whitelist
Jan 14 05:49:52.960: INFO: namespace e2e-tests-downward-api-p76cs deletion completed in 6.090952108s

• [SLOW TEST:8.243 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:49:52.960: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-36b198d1-17c0-11e9-912e-6a405af5e95c
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-36b198d1-17c0-11e9-912e-6a405af5e95c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:49:57.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-45x29" for this suite.
Jan 14 05:50:19.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:50:19.139: INFO: namespace: e2e-tests-projected-45x29, resource: bindings, ignored listing per whitelist
Jan 14 05:50:19.190: INFO: namespace e2e-tests-projected-45x29 deletion completed in 22.114341568s

• [SLOW TEST:26.230 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:50:19.190: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 05:50:19.312: INFO: Waiting up to 5m0s for pod "downwardapi-volume-465b309b-17c0-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-4bq7z" to be "success or failure"
Jan 14 05:50:19.321: INFO: Pod "downwardapi-volume-465b309b-17c0-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.075269ms
Jan 14 05:50:21.325: INFO: Pod "downwardapi-volume-465b309b-17c0-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012636415s
STEP: Saw pod success
Jan 14 05:50:21.325: INFO: Pod "downwardapi-volume-465b309b-17c0-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 05:50:21.328: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-465b309b-17c0-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 05:50:21.349: INFO: Waiting for pod downwardapi-volume-465b309b-17c0-11e9-912e-6a405af5e95c to disappear
Jan 14 05:50:21.354: INFO: Pod downwardapi-volume-465b309b-17c0-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:50:21.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4bq7z" for this suite.
Jan 14 05:50:27.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:50:27.423: INFO: namespace: e2e-tests-projected-4bq7z, resource: bindings, ignored listing per whitelist
Jan 14 05:50:27.492: INFO: namespace e2e-tests-projected-4bq7z deletion completed in 6.132611608s

• [SLOW TEST:8.302 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:50:27.492: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 14 05:50:27.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-ddptv'
Jan 14 05:50:27.718: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 14 05:50:27.718: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan 14 05:50:27.731: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jan 14 05:50:27.757: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan 14 05:50:27.772: INFO: scanned /root for discovery docs: <nil>
Jan 14 05:50:27.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-ddptv'
Jan 14 05:50:43.553: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 14 05:50:43.553: INFO: stdout: "Created e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79\nScaling up e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan 14 05:50:43.553: INFO: stdout: "Created e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79\nScaling up e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan 14 05:50:43.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ddptv'
Jan 14 05:50:43.644: INFO: stderr: ""
Jan 14 05:50:43.644: INFO: stdout: "e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79-2c2qx e2e-test-nginx-rc-p4mqv "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Jan 14 05:50:48.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ddptv'
Jan 14 05:50:48.724: INFO: stderr: ""
Jan 14 05:50:48.724: INFO: stdout: "e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79-2c2qx "
Jan 14 05:50:48.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79-2c2qx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ddptv'
Jan 14 05:50:48.798: INFO: stderr: ""
Jan 14 05:50:48.798: INFO: stdout: "true"
Jan 14 05:50:48.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79-2c2qx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ddptv'
Jan 14 05:50:48.954: INFO: stderr: ""
Jan 14 05:50:48.954: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jan 14 05:50:48.954: INFO: e2e-test-nginx-rc-89d3db729b3dcf181b97b4c865b36f79-2c2qx is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Jan 14 05:50:48.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ddptv'
Jan 14 05:50:49.042: INFO: stderr: ""
Jan 14 05:50:49.042: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:50:49.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ddptv" for this suite.
Jan 14 05:50:55.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:50:55.164: INFO: namespace: e2e-tests-kubectl-ddptv, resource: bindings, ignored listing per whitelist
Jan 14 05:50:55.185: INFO: namespace e2e-tests-kubectl-ddptv deletion completed in 6.138856897s

• [SLOW TEST:27.693 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:50:55.185: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5bca68c8-17c0-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 05:50:55.283: INFO: Waiting up to 5m0s for pod "pod-secrets-5bcb2829-17c0-11e9-912e-6a405af5e95c" in namespace "e2e-tests-secrets-v7q4r" to be "success or failure"
Jan 14 05:50:55.295: INFO: Pod "pod-secrets-5bcb2829-17c0-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.573729ms
Jan 14 05:50:57.297: INFO: Pod "pod-secrets-5bcb2829-17c0-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013949587s
STEP: Saw pod success
Jan 14 05:50:57.297: INFO: Pod "pod-secrets-5bcb2829-17c0-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 05:50:57.301: INFO: Trying to get logs from node paaswkr2 pod pod-secrets-5bcb2829-17c0-11e9-912e-6a405af5e95c container secret-volume-test: <nil>
STEP: delete the pod
Jan 14 05:50:57.321: INFO: Waiting for pod pod-secrets-5bcb2829-17c0-11e9-912e-6a405af5e95c to disappear
Jan 14 05:50:57.323: INFO: Pod pod-secrets-5bcb2829-17c0-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:50:57.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v7q4r" for this suite.
Jan 14 05:51:03.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:51:03.390: INFO: namespace: e2e-tests-secrets-v7q4r, resource: bindings, ignored listing per whitelist
Jan 14 05:51:03.431: INFO: namespace e2e-tests-secrets-v7q4r deletion completed in 6.101068412s

• [SLOW TEST:8.246 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:51:03.431: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 05:51:03.517: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 14 05:51:08.521: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 14 05:51:08.521: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 14 05:51:10.526: INFO: Creating deployment "test-rollover-deployment"
Jan 14 05:51:10.533: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 14 05:51:12.539: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 14 05:51:12.550: INFO: Ensure that both replica sets have 1 created replica
Jan 14 05:51:12.568: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 14 05:51:12.578: INFO: Updating deployment test-rollover-deployment
Jan 14 05:51:12.579: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 14 05:51:14.599: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 14 05:51:14.608: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 14 05:51:14.615: INFO: all replica sets need to contain the pod-template-hash label
Jan 14 05:51:14.615: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041873, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 14 05:51:16.645: INFO: all replica sets need to contain the pod-template-hash label
Jan 14 05:51:16.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041873, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 14 05:51:18.620: INFO: all replica sets need to contain the pod-template-hash label
Jan 14 05:51:18.620: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041873, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 14 05:51:20.621: INFO: all replica sets need to contain the pod-template-hash label
Jan 14 05:51:20.621: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041873, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 14 05:51:22.623: INFO: all replica sets need to contain the pod-template-hash label
Jan 14 05:51:22.623: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041873, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 14 05:51:24.623: INFO: all replica sets need to contain the pod-template-hash label
Jan 14 05:51:24.623: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041873, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 14 05:51:26.622: INFO: all replica sets need to contain the pod-template-hash label
Jan 14 05:51:26.622: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041873, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 14 05:51:28.622: INFO: all replica sets need to contain the pod-template-hash label
Jan 14 05:51:28.622: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041873, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 14 05:51:30.620: INFO: all replica sets need to contain the pod-template-hash label
Jan 14 05:51:30.620: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041873, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 14 05:51:32.620: INFO: all replica sets need to contain the pod-template-hash label
Jan 14 05:51:32.620: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041873, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683041870, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 14 05:51:34.626: INFO: 
Jan 14 05:51:34.626: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 14 05:51:34.637: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-5dd4d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5dd4d/deployments/test-rollover-deployment,UID:64aed13c-17c0-11e9-b726-525400ada096,ResourceVersion:51444,Generation:2,CreationTimestamp:2019-01-14 05:51:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-14 05:51:10 +0000 UTC 2019-01-14 05:51:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-14 05:51:34 +0000 UTC 2019-01-14 05:51:10 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 14 05:51:34.640: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-5dd4d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5dd4d/replicasets/test-rollover-deployment-6b7f9d6597,UID:65e8274a-17c0-11e9-b726-525400ada096,ResourceVersion:51435,Generation:2,CreationTimestamp:2019-01-14 05:51:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 64aed13c-17c0-11e9-b726-525400ada096 0xc000c2f737 0xc000c2f738}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 14 05:51:34.640: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 14 05:51:34.640: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-5dd4d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5dd4d/replicasets/test-rollover-controller,UID:607fd330-17c0-11e9-b726-525400ada096,ResourceVersion:51443,Generation:2,CreationTimestamp:2019-01-14 05:51:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 64aed13c-17c0-11e9-b726-525400ada096 0xc000c2f547 0xc000c2f548}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 14 05:51:34.640: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-5dd4d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5dd4d/replicasets/test-rollover-deployment-6586df867b,UID:64b195c3-17c0-11e9-b726-525400ada096,ResourceVersion:51391,Generation:2,CreationTimestamp:2019-01-14 05:51:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 64aed13c-17c0-11e9-b726-525400ada096 0xc000c2f607 0xc000c2f608}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 14 05:51:34.643: INFO: Pod "test-rollover-deployment-6b7f9d6597-5tzjn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-5tzjn,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-5dd4d,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5dd4d/pods/test-rollover-deployment-6b7f9d6597-5tzjn,UID:65fd2f3f-17c0-11e9-b726-525400ada096,ResourceVersion:51402,Generation:0,CreationTimestamp:2019-01-14 05:51:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 65e8274a-17c0-11e9-b726-525400ada096 0xc000b9a2f7 0xc000b9a2f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fv22g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fv22g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fv22g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b9a370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b9a390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 05:51:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 05:51:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 05:51:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 05:51:12 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:10.244.64.10,StartTime:2019-01-14 05:51:12 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-14 05:51:13 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://807183864cc5ea944cea14b0c4aecc1c910f5b9ad60460ae026f931ea7c1661b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:51:34.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5dd4d" for this suite.
Jan 14 05:51:40.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:51:40.713: INFO: namespace: e2e-tests-deployment-5dd4d, resource: bindings, ignored listing per whitelist
Jan 14 05:51:40.759: INFO: namespace e2e-tests-deployment-5dd4d deletion completed in 6.111534503s

• [SLOW TEST:37.328 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:51:40.759: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 05:52:06.889: INFO: Container started at 2019-01-14 05:51:41 +0000 UTC, pod became ready at 2019-01-14 05:52:05 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:52:06.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2f8c2" for this suite.
Jan 14 05:52:18.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:52:18.968: INFO: namespace: e2e-tests-container-probe-2f8c2, resource: bindings, ignored listing per whitelist
Jan 14 05:52:18.991: INFO: namespace e2e-tests-container-probe-2f8c2 deletion completed in 12.094037384s

• [SLOW TEST:38.232 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:52:18.992: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan 14 05:52:19.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:19.261: INFO: stderr: ""
Jan 14 05:52:19.261: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 14 05:52:19.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:19.372: INFO: stderr: ""
Jan 14 05:52:19.372: INFO: stdout: "update-demo-nautilus-hnsl9 update-demo-nautilus-zngvz "
Jan 14 05:52:19.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-hnsl9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:19.465: INFO: stderr: ""
Jan 14 05:52:19.465: INFO: stdout: ""
Jan 14 05:52:19.465: INFO: update-demo-nautilus-hnsl9 is created but not running
Jan 14 05:52:24.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:24.552: INFO: stderr: ""
Jan 14 05:52:24.553: INFO: stdout: "update-demo-nautilus-hnsl9 update-demo-nautilus-zngvz "
Jan 14 05:52:24.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-hnsl9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:24.634: INFO: stderr: ""
Jan 14 05:52:24.634: INFO: stdout: "true"
Jan 14 05:52:24.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-hnsl9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:24.716: INFO: stderr: ""
Jan 14 05:52:24.716: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 14 05:52:24.716: INFO: validating pod update-demo-nautilus-hnsl9
Jan 14 05:52:24.725: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 14 05:52:24.725: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 14 05:52:24.725: INFO: update-demo-nautilus-hnsl9 is verified up and running
Jan 14 05:52:24.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-zngvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:24.807: INFO: stderr: ""
Jan 14 05:52:24.807: INFO: stdout: "true"
Jan 14 05:52:24.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-zngvz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:24.887: INFO: stderr: ""
Jan 14 05:52:24.887: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 14 05:52:24.887: INFO: validating pod update-demo-nautilus-zngvz
Jan 14 05:52:24.893: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 14 05:52:24.893: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 14 05:52:24.893: INFO: update-demo-nautilus-zngvz is verified up and running
STEP: rolling-update to new replication controller
Jan 14 05:52:24.893: INFO: scanned /root for discovery docs: <nil>
Jan 14 05:52:24.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:47.271: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 14 05:52:47.271: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 14 05:52:47.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:47.366: INFO: stderr: ""
Jan 14 05:52:47.366: INFO: stdout: "update-demo-kitten-n7mbf update-demo-kitten-nb42k "
Jan 14 05:52:47.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-kitten-n7mbf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:47.444: INFO: stderr: ""
Jan 14 05:52:47.444: INFO: stdout: "true"
Jan 14 05:52:47.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-kitten-n7mbf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:47.542: INFO: stderr: ""
Jan 14 05:52:47.542: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 14 05:52:47.542: INFO: validating pod update-demo-kitten-n7mbf
Jan 14 05:52:47.548: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 14 05:52:47.548: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 14 05:52:47.549: INFO: update-demo-kitten-n7mbf is verified up and running
Jan 14 05:52:47.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-kitten-nb42k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:47.630: INFO: stderr: ""
Jan 14 05:52:47.630: INFO: stdout: "true"
Jan 14 05:52:47.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-kitten-nb42k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-79s78'
Jan 14 05:52:47.706: INFO: stderr: ""
Jan 14 05:52:47.706: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 14 05:52:47.706: INFO: validating pod update-demo-kitten-nb42k
Jan 14 05:52:47.724: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 14 05:52:47.724: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 14 05:52:47.724: INFO: update-demo-kitten-nb42k is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:52:47.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-79s78" for this suite.
Jan 14 05:53:09.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:53:09.779: INFO: namespace: e2e-tests-kubectl-79s78, resource: bindings, ignored listing per whitelist
Jan 14 05:53:09.857: INFO: namespace e2e-tests-kubectl-79s78 deletion completed in 22.127518879s

• [SLOW TEST:50.865 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:53:09.857: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan 14 05:53:09.972: INFO: Waiting up to 5m0s for pod "pod-ac1381df-17c0-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-bb2ds" to be "success or failure"
Jan 14 05:53:09.983: INFO: Pod "pod-ac1381df-17c0-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.332049ms
Jan 14 05:53:11.986: INFO: Pod "pod-ac1381df-17c0-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013398829s
STEP: Saw pod success
Jan 14 05:53:11.986: INFO: Pod "pod-ac1381df-17c0-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 05:53:11.990: INFO: Trying to get logs from node paaswkr2 pod pod-ac1381df-17c0-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 05:53:12.021: INFO: Waiting for pod pod-ac1381df-17c0-11e9-912e-6a405af5e95c to disappear
Jan 14 05:53:12.031: INFO: Pod pod-ac1381df-17c0-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:53:12.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bb2ds" for this suite.
Jan 14 05:53:18.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:53:18.095: INFO: namespace: e2e-tests-emptydir-bb2ds, resource: bindings, ignored listing per whitelist
Jan 14 05:53:18.150: INFO: namespace e2e-tests-emptydir-bb2ds deletion completed in 6.111447089s

• [SLOW TEST:8.293 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:53:18.150: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-smpr
STEP: Creating a pod to test atomic-volume-subpath
Jan 14 05:53:18.253: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-smpr" in namespace "e2e-tests-subpath-rtf5r" to be "success or failure"
Jan 14 05:53:18.259: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Pending", Reason="", readiness=false. Elapsed: 5.439427ms
Jan 14 05:53:20.262: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008566616s
Jan 14 05:53:22.265: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Running", Reason="", readiness=false. Elapsed: 4.011563255s
Jan 14 05:53:24.267: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Running", Reason="", readiness=false. Elapsed: 6.01441249s
Jan 14 05:53:26.271: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Running", Reason="", readiness=false. Elapsed: 8.017704723s
Jan 14 05:53:28.274: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Running", Reason="", readiness=false. Elapsed: 10.020467854s
Jan 14 05:53:30.276: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Running", Reason="", readiness=false. Elapsed: 12.023320985s
Jan 14 05:53:32.280: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Running", Reason="", readiness=false. Elapsed: 14.026856389s
Jan 14 05:53:34.283: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Running", Reason="", readiness=false. Elapsed: 16.029861186s
Jan 14 05:53:36.286: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Running", Reason="", readiness=false. Elapsed: 18.032641839s
Jan 14 05:53:38.289: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Running", Reason="", readiness=false. Elapsed: 20.035876054s
Jan 14 05:53:40.294: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Running", Reason="", readiness=false. Elapsed: 22.040891379s
Jan 14 05:53:42.297: INFO: Pod "pod-subpath-test-configmap-smpr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.044371115s
STEP: Saw pod success
Jan 14 05:53:42.297: INFO: Pod "pod-subpath-test-configmap-smpr" satisfied condition "success or failure"
Jan 14 05:53:42.301: INFO: Trying to get logs from node paaswkr2 pod pod-subpath-test-configmap-smpr container test-container-subpath-configmap-smpr: <nil>
STEP: delete the pod
Jan 14 05:53:42.327: INFO: Waiting for pod pod-subpath-test-configmap-smpr to disappear
Jan 14 05:53:42.330: INFO: Pod pod-subpath-test-configmap-smpr no longer exists
STEP: Deleting pod pod-subpath-test-configmap-smpr
Jan 14 05:53:42.330: INFO: Deleting pod "pod-subpath-test-configmap-smpr" in namespace "e2e-tests-subpath-rtf5r"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:53:42.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rtf5r" for this suite.
Jan 14 05:53:48.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:53:48.385: INFO: namespace: e2e-tests-subpath-rtf5r, resource: bindings, ignored listing per whitelist
Jan 14 05:53:48.450: INFO: namespace e2e-tests-subpath-rtf5r deletion completed in 6.110246947s

• [SLOW TEST:30.300 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:53:48.450: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c30fcaa1-17c0-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 05:53:48.540: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c3105f5f-17c0-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-w8rj8" to be "success or failure"
Jan 14 05:53:48.551: INFO: Pod "pod-projected-configmaps-c3105f5f-17c0-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.069415ms
Jan 14 05:53:50.554: INFO: Pod "pod-projected-configmaps-c3105f5f-17c0-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013610496s
STEP: Saw pod success
Jan 14 05:53:50.554: INFO: Pod "pod-projected-configmaps-c3105f5f-17c0-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 05:53:50.557: INFO: Trying to get logs from node paaswkr2 pod pod-projected-configmaps-c3105f5f-17c0-11e9-912e-6a405af5e95c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 05:53:50.577: INFO: Waiting for pod pod-projected-configmaps-c3105f5f-17c0-11e9-912e-6a405af5e95c to disappear
Jan 14 05:53:50.581: INFO: Pod pod-projected-configmaps-c3105f5f-17c0-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:53:50.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w8rj8" for this suite.
Jan 14 05:53:56.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:53:56.633: INFO: namespace: e2e-tests-projected-w8rj8, resource: bindings, ignored listing per whitelist
Jan 14 05:53:56.720: INFO: namespace e2e-tests-projected-w8rj8 deletion completed in 6.130985511s

• [SLOW TEST:8.271 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:53:56.720: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:53:58.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-d6snm" for this suite.
Jan 14 05:54:04.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:54:04.964: INFO: namespace: e2e-tests-emptydir-wrapper-d6snm, resource: bindings, ignored listing per whitelist
Jan 14 05:54:05.041: INFO: namespace e2e-tests-emptydir-wrapper-d6snm deletion completed in 6.162507171s

• [SLOW TEST:8.320 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:54:05.041: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-l8nvm
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan 14 05:54:05.206: INFO: Found 0 stateful pods, waiting for 3
Jan 14 05:54:15.209: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 14 05:54:15.209: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 14 05:54:15.209: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 14 05:54:15.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-l8nvm ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 14 05:54:15.732: INFO: stderr: ""
Jan 14 05:54:15.732: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 14 05:54:15.732: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 14 05:54:15.767: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan 14 05:54:25.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-l8nvm ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 14 05:54:26.010: INFO: stderr: ""
Jan 14 05:54:26.010: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 14 05:54:26.010: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Jan 14 05:54:46.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-l8nvm ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 14 05:54:46.484: INFO: stderr: ""
Jan 14 05:54:46.484: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 14 05:54:46.484: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 14 05:54:56.517: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan 14 05:55:06.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-l8nvm ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 14 05:55:06.945: INFO: stderr: ""
Jan 14 05:55:06.945: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 14 05:55:06.945: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 14 05:55:07.035: INFO: Waiting for StatefulSet e2e-tests-statefulset-l8nvm/ss2 to complete update
Jan 14 05:55:07.035: INFO: Waiting for Pod e2e-tests-statefulset-l8nvm/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 14 05:55:07.035: INFO: Waiting for Pod e2e-tests-statefulset-l8nvm/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 14 05:55:07.035: INFO: Waiting for Pod e2e-tests-statefulset-l8nvm/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 14 05:55:17.041: INFO: Waiting for StatefulSet e2e-tests-statefulset-l8nvm/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 14 05:55:27.044: INFO: Deleting all statefulset in ns e2e-tests-statefulset-l8nvm
Jan 14 05:55:27.049: INFO: Scaling statefulset ss2 to 0
Jan 14 05:55:37.077: INFO: Waiting for statefulset status.replicas updated to 0
Jan 14 05:55:37.081: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:55:37.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-l8nvm" for this suite.
Jan 14 05:55:43.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:55:43.249: INFO: namespace: e2e-tests-statefulset-l8nvm, resource: bindings, ignored listing per whitelist
Jan 14 05:55:43.276: INFO: namespace e2e-tests-statefulset-l8nvm deletion completed in 6.168472482s

• [SLOW TEST:98.236 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:55:43.277: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 14 05:55:43.409: INFO: PodSpec: initContainers in spec.initContainers
Jan 14 05:56:29.409: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-07898b8b-17c1-11e9-912e-6a405af5e95c", GenerateName:"", Namespace:"e2e-tests-init-container-r5hzl", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-r5hzl/pods/pod-init-07898b8b-17c1-11e9-912e-6a405af5e95c", UID:"0756898d-17c1-11e9-b726-525400ada096", ResourceVersion:"52561", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683042143, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"409254115"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-m4hz7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001456240), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m4hz7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m4hz7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-m4hz7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0007823f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"paaswkr2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0016d4060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000782480)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0007824a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0007824a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0007824ac)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683042143, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683042143, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683042143, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683042143, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.10.105", PodIP:"10.244.64.9", StartTime:(*v1.Time)(0xc001212180), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00040e620)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00040e850)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://813fec498719c538bb2b6edb3eda6bd9de61a118fa6fe0f33ae41908fe3d2357"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0012121c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0012121a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:56:29.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-r5hzl" for this suite.
Jan 14 05:56:51.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:56:51.472: INFO: namespace: e2e-tests-init-container-r5hzl, resource: bindings, ignored listing per whitelist
Jan 14 05:56:51.552: INFO: namespace e2e-tests-init-container-r5hzl deletion completed in 22.128453064s

• [SLOW TEST:68.275 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:56:51.552: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan 14 05:56:51.663: INFO: Waiting up to 5m0s for pod "var-expansion-3036ffeb-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-var-expansion-6ktmj" to be "success or failure"
Jan 14 05:56:51.671: INFO: Pod "var-expansion-3036ffeb-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.034471ms
Jan 14 05:56:53.674: INFO: Pod "var-expansion-3036ffeb-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011559397s
STEP: Saw pod success
Jan 14 05:56:53.674: INFO: Pod "var-expansion-3036ffeb-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 05:56:53.678: INFO: Trying to get logs from node paaswkr2 pod var-expansion-3036ffeb-17c1-11e9-912e-6a405af5e95c container dapi-container: <nil>
STEP: delete the pod
Jan 14 05:56:53.701: INFO: Waiting for pod var-expansion-3036ffeb-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 05:56:53.707: INFO: Pod var-expansion-3036ffeb-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:56:53.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6ktmj" for this suite.
Jan 14 05:56:59.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:56:59.793: INFO: namespace: e2e-tests-var-expansion-6ktmj, resource: bindings, ignored listing per whitelist
Jan 14 05:56:59.807: INFO: namespace e2e-tests-var-expansion-6ktmj deletion completed in 6.094612527s

• [SLOW TEST:8.255 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:56:59.807: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 14 05:56:59.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-lgp7x'
Jan 14 05:57:00.086: INFO: stderr: ""
Jan 14 05:57:00.086: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 14 05:57:00.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lgp7x'
Jan 14 05:57:00.212: INFO: stderr: ""
Jan 14 05:57:00.212: INFO: stdout: "update-demo-nautilus-6qcll update-demo-nautilus-tzkqz "
Jan 14 05:57:00.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-6qcll -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lgp7x'
Jan 14 05:57:00.292: INFO: stderr: ""
Jan 14 05:57:00.292: INFO: stdout: ""
Jan 14 05:57:00.292: INFO: update-demo-nautilus-6qcll is created but not running
Jan 14 05:57:05.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lgp7x'
Jan 14 05:57:05.372: INFO: stderr: ""
Jan 14 05:57:05.372: INFO: stdout: "update-demo-nautilus-6qcll update-demo-nautilus-tzkqz "
Jan 14 05:57:05.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-6qcll -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lgp7x'
Jan 14 05:57:05.457: INFO: stderr: ""
Jan 14 05:57:05.457: INFO: stdout: "true"
Jan 14 05:57:05.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-6qcll -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lgp7x'
Jan 14 05:57:05.536: INFO: stderr: ""
Jan 14 05:57:05.536: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 14 05:57:05.536: INFO: validating pod update-demo-nautilus-6qcll
Jan 14 05:57:05.543: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 14 05:57:05.543: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 14 05:57:05.543: INFO: update-demo-nautilus-6qcll is verified up and running
Jan 14 05:57:05.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-tzkqz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lgp7x'
Jan 14 05:57:05.623: INFO: stderr: ""
Jan 14 05:57:05.623: INFO: stdout: "true"
Jan 14 05:57:05.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-tzkqz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lgp7x'
Jan 14 05:57:05.704: INFO: stderr: ""
Jan 14 05:57:05.704: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 14 05:57:05.704: INFO: validating pod update-demo-nautilus-tzkqz
Jan 14 05:57:05.714: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 14 05:57:05.714: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 14 05:57:05.714: INFO: update-demo-nautilus-tzkqz is verified up and running
STEP: using delete to clean up resources
Jan 14 05:57:05.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lgp7x'
Jan 14 05:57:05.797: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 14 05:57:05.797: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 14 05:57:05.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-lgp7x'
Jan 14 05:57:05.986: INFO: stderr: "No resources found.\n"
Jan 14 05:57:05.986: INFO: stdout: ""
Jan 14 05:57:05.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -l name=update-demo --namespace=e2e-tests-kubectl-lgp7x -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 14 05:57:06.228: INFO: stderr: ""
Jan 14 05:57:06.228: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:57:06.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lgp7x" for this suite.
Jan 14 05:57:20.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:57:20.286: INFO: namespace: e2e-tests-kubectl-lgp7x, resource: bindings, ignored listing per whitelist
Jan 14 05:57:20.362: INFO: namespace e2e-tests-kubectl-lgp7x deletion completed in 14.118445896s

• [SLOW TEST:20.555 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:57:20.363: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-41629b21-17c1-11e9-912e-6a405af5e95c
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-41629b21-17c1-11e9-912e-6a405af5e95c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:57:24.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hvp5j" for this suite.
Jan 14 05:57:46.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:57:46.552: INFO: namespace: e2e-tests-configmap-hvp5j, resource: bindings, ignored listing per whitelist
Jan 14 05:57:46.617: INFO: namespace e2e-tests-configmap-hvp5j deletion completed in 22.093232861s

• [SLOW TEST:26.255 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:57:46.617: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 14 05:57:46.709: INFO: Waiting up to 5m0s for pod "pod-51064d23-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-ctv6l" to be "success or failure"
Jan 14 05:57:46.722: INFO: Pod "pod-51064d23-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.410259ms
Jan 14 05:57:48.725: INFO: Pod "pod-51064d23-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015554375s
STEP: Saw pod success
Jan 14 05:57:48.725: INFO: Pod "pod-51064d23-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 05:57:48.728: INFO: Trying to get logs from node paaswkr2 pod pod-51064d23-17c1-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 05:57:48.751: INFO: Waiting for pod pod-51064d23-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 05:57:48.758: INFO: Pod pod-51064d23-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:57:48.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ctv6l" for this suite.
Jan 14 05:57:54.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:57:54.817: INFO: namespace: e2e-tests-emptydir-ctv6l, resource: bindings, ignored listing per whitelist
Jan 14 05:57:54.862: INFO: namespace e2e-tests-emptydir-ctv6l deletion completed in 6.098630533s

• [SLOW TEST:8.245 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:57:54.862: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-55f03923-17c1-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 05:57:54.954: INFO: Waiting up to 5m0s for pod "pod-secrets-55f0db2e-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-secrets-5mqc7" to be "success or failure"
Jan 14 05:57:54.959: INFO: Pod "pod-secrets-55f0db2e-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.579551ms
Jan 14 05:57:56.963: INFO: Pod "pod-secrets-55f0db2e-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008582807s
STEP: Saw pod success
Jan 14 05:57:56.963: INFO: Pod "pod-secrets-55f0db2e-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 05:57:56.967: INFO: Trying to get logs from node paaswkr2 pod pod-secrets-55f0db2e-17c1-11e9-912e-6a405af5e95c container secret-env-test: <nil>
STEP: delete the pod
Jan 14 05:57:56.992: INFO: Waiting for pod pod-secrets-55f0db2e-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 05:57:56.997: INFO: Pod pod-secrets-55f0db2e-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:57:56.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5mqc7" for this suite.
Jan 14 05:58:03.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:58:03.086: INFO: namespace: e2e-tests-secrets-5mqc7, resource: bindings, ignored listing per whitelist
Jan 14 05:58:03.112: INFO: namespace e2e-tests-secrets-5mqc7 deletion completed in 6.104522882s

• [SLOW TEST:8.250 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:58:03.112: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 14 05:58:07.253: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 14 05:58:07.273: INFO: Pod pod-with-prestop-http-hook still exists
Jan 14 05:58:09.274: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 14 05:58:09.306: INFO: Pod pod-with-prestop-http-hook still exists
Jan 14 05:58:11.274: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 14 05:58:11.278: INFO: Pod pod-with-prestop-http-hook still exists
Jan 14 05:58:13.274: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 14 05:58:13.278: INFO: Pod pod-with-prestop-http-hook still exists
Jan 14 05:58:15.274: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 14 05:58:15.282: INFO: Pod pod-with-prestop-http-hook still exists
Jan 14 05:58:17.274: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 14 05:58:17.278: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:58:17.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-q97hw" for this suite.
Jan 14 05:58:39.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:58:39.434: INFO: namespace: e2e-tests-container-lifecycle-hook-q97hw, resource: bindings, ignored listing per whitelist
Jan 14 05:58:39.467: INFO: namespace e2e-tests-container-lifecycle-hook-q97hw deletion completed in 22.123318779s

• [SLOW TEST:36.355 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:58:39.467: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 14 05:58:42.117: INFO: Successfully updated pod "annotationupdate70867cd2-17c1-11e9-912e-6a405af5e95c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:58:46.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v64dr" for this suite.
Jan 14 05:59:08.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:59:08.206: INFO: namespace: e2e-tests-projected-v64dr, resource: bindings, ignored listing per whitelist
Jan 14 05:59:08.257: INFO: namespace e2e-tests-projected-v64dr deletion completed in 22.115807845s

• [SLOW TEST:28.790 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:59:08.258: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 14 05:59:08.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5rwfs'
Jan 14 05:59:08.614: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 14 05:59:08.614: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Jan 14 05:59:08.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-5rwfs'
Jan 14 05:59:08.759: INFO: stderr: ""
Jan 14 05:59:08.759: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:59:08.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5rwfs" for this suite.
Jan 14 05:59:30.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:59:30.808: INFO: namespace: e2e-tests-kubectl-5rwfs, resource: bindings, ignored listing per whitelist
Jan 14 05:59:30.872: INFO: namespace e2e-tests-kubectl-5rwfs deletion completed in 22.100902107s

• [SLOW TEST:22.614 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:59:30.872: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8f2be88e-17c1-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 05:59:30.979: INFO: Waiting up to 5m0s for pod "pod-secrets-8f2c791f-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-secrets-bx6z6" to be "success or failure"
Jan 14 05:59:30.992: INFO: Pod "pod-secrets-8f2c791f-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.947887ms
Jan 14 05:59:32.996: INFO: Pod "pod-secrets-8f2c791f-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0169753s
STEP: Saw pod success
Jan 14 05:59:32.996: INFO: Pod "pod-secrets-8f2c791f-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 05:59:32.999: INFO: Trying to get logs from node paaswkr2 pod pod-secrets-8f2c791f-17c1-11e9-912e-6a405af5e95c container secret-volume-test: <nil>
STEP: delete the pod
Jan 14 05:59:33.016: INFO: Waiting for pod pod-secrets-8f2c791f-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 05:59:33.020: INFO: Pod pod-secrets-8f2c791f-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:59:33.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bx6z6" for this suite.
Jan 14 05:59:39.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 05:59:39.068: INFO: namespace: e2e-tests-secrets-bx6z6, resource: bindings, ignored listing per whitelist
Jan 14 05:59:39.130: INFO: namespace e2e-tests-secrets-bx6z6 deletion completed in 6.098965898s

• [SLOW TEST:8.258 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 05:59:39.130: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 14 05:59:39.210: INFO: namespace e2e-tests-kubectl-g6tbl
Jan 14 05:59:39.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-g6tbl'
Jan 14 05:59:39.360: INFO: stderr: ""
Jan 14 05:59:39.360: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 14 05:59:40.364: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 05:59:40.364: INFO: Found 0 / 1
Jan 14 05:59:41.363: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 05:59:41.363: INFO: Found 1 / 1
Jan 14 05:59:41.363: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 14 05:59:41.366: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 05:59:41.366: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 14 05:59:41.366: INFO: wait on redis-master startup in e2e-tests-kubectl-g6tbl 
Jan 14 05:59:41.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 logs redis-master-cb7zg redis-master --namespace=e2e-tests-kubectl-g6tbl'
Jan 14 05:59:41.451: INFO: stderr: ""
Jan 14 05:59:41.451: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Jan 05:59:40.039 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Jan 05:59:40.039 # Server started, Redis version 3.2.12\n1:M 14 Jan 05:59:40.039 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Jan 05:59:40.039 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan 14 05:59:41.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-g6tbl'
Jan 14 05:59:41.555: INFO: stderr: ""
Jan 14 05:59:41.555: INFO: stdout: "service/rm2 exposed\n"
Jan 14 05:59:41.563: INFO: Service rm2 in namespace e2e-tests-kubectl-g6tbl found.
STEP: exposing service
Jan 14 05:59:43.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-g6tbl'
Jan 14 05:59:43.663: INFO: stderr: ""
Jan 14 05:59:43.663: INFO: stdout: "service/rm3 exposed\n"
Jan 14 05:59:43.671: INFO: Service rm3 in namespace e2e-tests-kubectl-g6tbl found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 05:59:45.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g6tbl" for this suite.
Jan 14 06:00:07.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:00:07.708: INFO: namespace: e2e-tests-kubectl-g6tbl, resource: bindings, ignored listing per whitelist
Jan 14 06:00:07.779: INFO: namespace e2e-tests-kubectl-g6tbl deletion completed in 22.09928138s

• [SLOW TEST:28.650 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:00:07.780: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-8j2mg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 14 06:00:07.862: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 14 06:00:23.939: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.64.10:8080/dial?request=hostName&protocol=udp&host=10.244.192.19&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-8j2mg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 06:00:23.939: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 06:00:24.352: INFO: Waiting for endpoints: map[]
Jan 14 06:00:24.356: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.64.10:8080/dial?request=hostName&protocol=udp&host=10.244.64.9&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-8j2mg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 06:00:24.356: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 06:00:24.630: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:00:24.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-8j2mg" for this suite.
Jan 14 06:00:46.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:00:46.738: INFO: namespace: e2e-tests-pod-network-test-8j2mg, resource: bindings, ignored listing per whitelist
Jan 14 06:00:46.754: INFO: namespace e2e-tests-pod-network-test-8j2mg deletion completed in 22.118804293s

• [SLOW TEST:38.974 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:00:46.754: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-bc668217-17c1-11e9-912e-6a405af5e95c
Jan 14 06:00:46.857: INFO: Pod name my-hostname-basic-bc668217-17c1-11e9-912e-6a405af5e95c: Found 0 pods out of 1
Jan 14 06:00:51.860: INFO: Pod name my-hostname-basic-bc668217-17c1-11e9-912e-6a405af5e95c: Found 1 pods out of 1
Jan 14 06:00:51.860: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-bc668217-17c1-11e9-912e-6a405af5e95c" are running
Jan 14 06:00:51.863: INFO: Pod "my-hostname-basic-bc668217-17c1-11e9-912e-6a405af5e95c-lr94l" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-14 06:00:46 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-14 06:00:48 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-14 06:00:48 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-14 06:00:46 +0000 UTC Reason: Message:}])
Jan 14 06:00:51.863: INFO: Trying to dial the pod
Jan 14 06:00:56.900: INFO: Controller my-hostname-basic-bc668217-17c1-11e9-912e-6a405af5e95c: Got expected result from replica 1 [my-hostname-basic-bc668217-17c1-11e9-912e-6a405af5e95c-lr94l]: "my-hostname-basic-bc668217-17c1-11e9-912e-6a405af5e95c-lr94l", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:00:56.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-dwlt6" for this suite.
Jan 14 06:01:02.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:01:02.999: INFO: namespace: e2e-tests-replication-controller-dwlt6, resource: bindings, ignored listing per whitelist
Jan 14 06:01:03.028: INFO: namespace e2e-tests-replication-controller-dwlt6 deletion completed in 6.121900782s

• [SLOW TEST:16.275 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:01:03.028: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 14 06:01:03.109: INFO: Waiting up to 5m0s for pod "pod-c616c318-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-fb58w" to be "success or failure"
Jan 14 06:01:03.115: INFO: Pod "pod-c616c318-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.071716ms
Jan 14 06:01:05.118: INFO: Pod "pod-c616c318-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009189508s
STEP: Saw pod success
Jan 14 06:01:05.118: INFO: Pod "pod-c616c318-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:01:05.121: INFO: Trying to get logs from node paaswkr2 pod pod-c616c318-17c1-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 06:01:05.141: INFO: Waiting for pod pod-c616c318-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 06:01:05.149: INFO: Pod pod-c616c318-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:01:05.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fb58w" for this suite.
Jan 14 06:01:11.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:01:11.215: INFO: namespace: e2e-tests-emptydir-fb58w, resource: bindings, ignored listing per whitelist
Jan 14 06:01:11.327: INFO: namespace e2e-tests-emptydir-fb58w deletion completed in 6.170757552s

• [SLOW TEST:8.299 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:01:11.327: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-cb095e33-17c1-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 06:01:11.433: INFO: Waiting up to 5m0s for pod "pod-secrets-cb0aadc3-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-secrets-nb8hb" to be "success or failure"
Jan 14 06:01:11.463: INFO: Pod "pod-secrets-cb0aadc3-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 29.760716ms
Jan 14 06:01:13.466: INFO: Pod "pod-secrets-cb0aadc3-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033122459s
STEP: Saw pod success
Jan 14 06:01:13.466: INFO: Pod "pod-secrets-cb0aadc3-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:01:13.469: INFO: Trying to get logs from node paaswkr2 pod pod-secrets-cb0aadc3-17c1-11e9-912e-6a405af5e95c container secret-volume-test: <nil>
STEP: delete the pod
Jan 14 06:01:13.492: INFO: Waiting for pod pod-secrets-cb0aadc3-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 06:01:13.496: INFO: Pod pod-secrets-cb0aadc3-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:01:13.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nb8hb" for this suite.
Jan 14 06:01:19.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:01:19.538: INFO: namespace: e2e-tests-secrets-nb8hb, resource: bindings, ignored listing per whitelist
Jan 14 06:01:19.600: INFO: namespace e2e-tests-secrets-nb8hb deletion completed in 6.098272326s

• [SLOW TEST:8.273 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:01:19.600: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 14 06:01:19.684: INFO: Waiting up to 5m0s for pod "pod-cff76a9a-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-cbwwc" to be "success or failure"
Jan 14 06:01:19.701: INFO: Pod "pod-cff76a9a-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.630242ms
Jan 14 06:01:21.705: INFO: Pod "pod-cff76a9a-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021704937s
STEP: Saw pod success
Jan 14 06:01:21.705: INFO: Pod "pod-cff76a9a-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:01:21.709: INFO: Trying to get logs from node paaswkr2 pod pod-cff76a9a-17c1-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 06:01:21.731: INFO: Waiting for pod pod-cff76a9a-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 06:01:21.736: INFO: Pod pod-cff76a9a-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:01:21.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cbwwc" for this suite.
Jan 14 06:01:27.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:01:27.857: INFO: namespace: e2e-tests-emptydir-cbwwc, resource: bindings, ignored listing per whitelist
Jan 14 06:01:27.862: INFO: namespace e2e-tests-emptydir-cbwwc deletion completed in 6.120693244s

• [SLOW TEST:8.262 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:01:27.862: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 06:01:27.939: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4e39610-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-lrpks" to be "success or failure"
Jan 14 06:01:27.950: INFO: Pod "downwardapi-volume-d4e39610-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.04497ms
Jan 14 06:01:29.953: INFO: Pod "downwardapi-volume-d4e39610-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013942023s
STEP: Saw pod success
Jan 14 06:01:29.953: INFO: Pod "downwardapi-volume-d4e39610-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:01:29.957: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-d4e39610-17c1-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 06:01:29.978: INFO: Waiting for pod downwardapi-volume-d4e39610-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 06:01:29.984: INFO: Pod downwardapi-volume-d4e39610-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:01:29.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lrpks" for this suite.
Jan 14 06:01:36.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:01:36.077: INFO: namespace: e2e-tests-projected-lrpks, resource: bindings, ignored listing per whitelist
Jan 14 06:01:36.130: INFO: namespace e2e-tests-projected-lrpks deletion completed in 6.141388497s

• [SLOW TEST:8.268 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:01:36.131: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 14 06:01:36.253: INFO: Waiting up to 5m0s for pod "downward-api-d9d7dc0b-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-hvc48" to be "success or failure"
Jan 14 06:01:36.260: INFO: Pod "downward-api-d9d7dc0b-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.6639ms
Jan 14 06:01:38.263: INFO: Pod "downward-api-d9d7dc0b-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010844716s
STEP: Saw pod success
Jan 14 06:01:38.263: INFO: Pod "downward-api-d9d7dc0b-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:01:38.267: INFO: Trying to get logs from node paaswkr2 pod downward-api-d9d7dc0b-17c1-11e9-912e-6a405af5e95c container dapi-container: <nil>
STEP: delete the pod
Jan 14 06:01:38.285: INFO: Waiting for pod downward-api-d9d7dc0b-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 06:01:38.293: INFO: Pod downward-api-d9d7dc0b-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:01:38.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hvc48" for this suite.
Jan 14 06:01:44.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:01:44.322: INFO: namespace: e2e-tests-downward-api-hvc48, resource: bindings, ignored listing per whitelist
Jan 14 06:01:44.390: INFO: namespace e2e-tests-downward-api-hvc48 deletion completed in 6.090728113s

• [SLOW TEST:8.260 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:01:44.390: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-dec75743-17c1-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:01:44.824: INFO: Waiting up to 5m0s for pod "pod-configmaps-def40464-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-configmap-4q94b" to be "success or failure"
Jan 14 06:01:44.829: INFO: Pod "pod-configmaps-def40464-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.408027ms
Jan 14 06:01:46.833: INFO: Pod "pod-configmaps-def40464-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008754174s
STEP: Saw pod success
Jan 14 06:01:46.833: INFO: Pod "pod-configmaps-def40464-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:01:46.836: INFO: Trying to get logs from node paaswkr2 pod pod-configmaps-def40464-17c1-11e9-912e-6a405af5e95c container configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 06:01:46.855: INFO: Waiting for pod pod-configmaps-def40464-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 06:01:46.860: INFO: Pod pod-configmaps-def40464-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:01:46.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4q94b" for this suite.
Jan 14 06:01:52.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:01:52.917: INFO: namespace: e2e-tests-configmap-4q94b, resource: bindings, ignored listing per whitelist
Jan 14 06:01:52.985: INFO: namespace e2e-tests-configmap-4q94b deletion completed in 6.11778701s

• [SLOW TEST:8.594 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:01:52.985: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 06:01:53.084: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e3e047b1-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-wlt8w" to be "success or failure"
Jan 14 06:01:53.090: INFO: Pod "downwardapi-volume-e3e047b1-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.507631ms
Jan 14 06:01:55.094: INFO: Pod "downwardapi-volume-e3e047b1-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009714534s
STEP: Saw pod success
Jan 14 06:01:55.094: INFO: Pod "downwardapi-volume-e3e047b1-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:01:55.097: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-e3e047b1-17c1-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 06:01:55.116: INFO: Waiting for pod downwardapi-volume-e3e047b1-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 06:01:55.123: INFO: Pod downwardapi-volume-e3e047b1-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:01:55.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wlt8w" for this suite.
Jan 14 06:02:01.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:02:01.293: INFO: namespace: e2e-tests-projected-wlt8w, resource: bindings, ignored listing per whitelist
Jan 14 06:02:01.350: INFO: namespace e2e-tests-projected-wlt8w deletion completed in 6.222138155s

• [SLOW TEST:8.366 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:02:01.351: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 06:02:01.489: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8e07249-17c1-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-zc6q5" to be "success or failure"
Jan 14 06:02:01.506: INFO: Pod "downwardapi-volume-e8e07249-17c1-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.077568ms
Jan 14 06:02:03.510: INFO: Pod "downwardapi-volume-e8e07249-17c1-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021607318s
STEP: Saw pod success
Jan 14 06:02:03.510: INFO: Pod "downwardapi-volume-e8e07249-17c1-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:02:03.514: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-e8e07249-17c1-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 06:02:03.538: INFO: Waiting for pod downwardapi-volume-e8e07249-17c1-11e9-912e-6a405af5e95c to disappear
Jan 14 06:02:03.548: INFO: Pod downwardapi-volume-e8e07249-17c1-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:02:03.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zc6q5" for this suite.
Jan 14 06:02:09.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:02:09.624: INFO: namespace: e2e-tests-downward-api-zc6q5, resource: bindings, ignored listing per whitelist
Jan 14 06:02:09.669: INFO: namespace e2e-tests-downward-api-zc6q5 deletion completed in 6.112989838s

• [SLOW TEST:8.318 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:02:09.669: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-fmk4s
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-fmk4s
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-fmk4s
Jan 14 06:02:09.810: INFO: Found 0 stateful pods, waiting for 1
Jan 14 06:02:19.813: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan 14 06:02:19.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-fmk4s ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 14 06:02:20.049: INFO: stderr: ""
Jan 14 06:02:20.049: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 14 06:02:20.049: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 14 06:02:20.053: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 14 06:02:30.057: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 14 06:02:30.057: INFO: Waiting for statefulset status.replicas updated to 0
Jan 14 06:02:30.073: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999002s
Jan 14 06:02:31.076: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994529607s
Jan 14 06:02:32.079: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991442796s
Jan 14 06:02:33.083: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987769108s
Jan 14 06:02:34.087: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.98361952s
Jan 14 06:02:35.090: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.980549182s
Jan 14 06:02:36.093: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.977725908s
Jan 14 06:02:37.098: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.974322946s
Jan 14 06:02:38.107: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.966227714s
Jan 14 06:02:39.110: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.016308ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-fmk4s
Jan 14 06:02:40.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-fmk4s ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 14 06:02:40.323: INFO: stderr: ""
Jan 14 06:02:40.323: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 14 06:02:40.323: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 14 06:02:40.327: INFO: Found 1 stateful pods, waiting for 3
Jan 14 06:02:50.331: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 14 06:02:50.331: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 14 06:02:50.331: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan 14 06:02:50.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-fmk4s ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 14 06:02:50.691: INFO: stderr: ""
Jan 14 06:02:50.691: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 14 06:02:50.691: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 14 06:02:50.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-fmk4s ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 14 06:02:51.581: INFO: stderr: ""
Jan 14 06:02:51.581: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 14 06:02:51.581: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 14 06:02:51.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-fmk4s ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 14 06:02:51.769: INFO: stderr: ""
Jan 14 06:02:51.769: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 14 06:02:51.769: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 14 06:02:51.769: INFO: Waiting for statefulset status.replicas updated to 0
Jan 14 06:02:51.773: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan 14 06:03:01.787: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 14 06:03:01.787: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 14 06:03:01.787: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 14 06:03:01.858: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999961s
Jan 14 06:03:02.862: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996128434s
Jan 14 06:03:03.866: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991592035s
Jan 14 06:03:04.869: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98849614s
Jan 14 06:03:05.872: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985360727s
Jan 14 06:03:06.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.981684409s
Jan 14 06:03:07.880: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977085024s
Jan 14 06:03:08.884: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.973998643s
Jan 14 06:03:09.887: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.969897223s
Jan 14 06:03:10.891: INFO: Verifying statefulset ss doesn't scale past 3 for another 966.230234ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-fmk4s
Jan 14 06:03:11.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-fmk4s ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 14 06:03:12.096: INFO: stderr: ""
Jan 14 06:03:12.096: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 14 06:03:12.096: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 14 06:03:12.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-fmk4s ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 14 06:03:12.469: INFO: stderr: ""
Jan 14 06:03:12.469: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 14 06:03:12.469: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 14 06:03:12.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-fmk4s ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 14 06:03:12.683: INFO: stderr: ""
Jan 14 06:03:12.683: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 14 06:03:12.683: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 14 06:03:12.683: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 14 06:03:32.705: INFO: Deleting all statefulset in ns e2e-tests-statefulset-fmk4s
Jan 14 06:03:32.708: INFO: Scaling statefulset ss to 0
Jan 14 06:03:32.718: INFO: Waiting for statefulset status.replicas updated to 0
Jan 14 06:03:32.722: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:03:32.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-fmk4s" for this suite.
Jan 14 06:03:38.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:03:38.798: INFO: namespace: e2e-tests-statefulset-fmk4s, resource: bindings, ignored listing per whitelist
Jan 14 06:03:38.883: INFO: namespace e2e-tests-statefulset-fmk4s deletion completed in 6.138146855s

• [SLOW TEST:89.214 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:03:38.883: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:03:39.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-77z2t" for this suite.
Jan 14 06:04:01.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:04:01.103: INFO: namespace: e2e-tests-pods-77z2t, resource: bindings, ignored listing per whitelist
Jan 14 06:04:01.118: INFO: namespace e2e-tests-pods-77z2t deletion completed in 22.094636148s

• [SLOW TEST:22.235 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:04:01.118: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan 14 06:04:03.223: INFO: Pod pod-hostip-303cea4a-17c2-11e9-912e-6a405af5e95c has hostIP: 192.168.10.105
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:04:03.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-chkz2" for this suite.
Jan 14 06:04:25.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:04:25.314: INFO: namespace: e2e-tests-pods-chkz2, resource: bindings, ignored listing per whitelist
Jan 14 06:04:25.321: INFO: namespace e2e-tests-pods-chkz2 deletion completed in 22.088601192s

• [SLOW TEST:24.203 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:04:25.321: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 14 06:04:25.394: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:04:27.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-gvxlb" for this suite.
Jan 14 06:04:33.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:04:34.017: INFO: namespace: e2e-tests-init-container-gvxlb, resource: bindings, ignored listing per whitelist
Jan 14 06:04:34.074: INFO: namespace e2e-tests-init-container-gvxlb deletion completed in 6.102191468s

• [SLOW TEST:8.753 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:04:34.074: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jan 14 06:04:34.376: INFO: Pod name wrapped-volume-race-43fe51c2-17c2-11e9-912e-6a405af5e95c: Found 0 pods out of 5
Jan 14 06:04:39.384: INFO: Pod name wrapped-volume-race-43fe51c2-17c2-11e9-912e-6a405af5e95c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-43fe51c2-17c2-11e9-912e-6a405af5e95c in namespace e2e-tests-emptydir-wrapper-wttls, will wait for the garbage collector to delete the pods
Jan 14 06:06:07.472: INFO: Deleting ReplicationController wrapped-volume-race-43fe51c2-17c2-11e9-912e-6a405af5e95c took: 12.554887ms
Jan 14 06:06:07.573: INFO: Terminating ReplicationController wrapped-volume-race-43fe51c2-17c2-11e9-912e-6a405af5e95c pods took: 100.999706ms
STEP: Creating RC which spawns configmap-volume pods
Jan 14 06:06:49.328: INFO: Pod name wrapped-volume-race-946c680b-17c2-11e9-912e-6a405af5e95c: Found 0 pods out of 5
Jan 14 06:06:54.336: INFO: Pod name wrapped-volume-race-946c680b-17c2-11e9-912e-6a405af5e95c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-946c680b-17c2-11e9-912e-6a405af5e95c in namespace e2e-tests-emptydir-wrapper-wttls, will wait for the garbage collector to delete the pods
Jan 14 06:07:14.420: INFO: Deleting ReplicationController wrapped-volume-race-946c680b-17c2-11e9-912e-6a405af5e95c took: 6.913464ms
Jan 14 06:07:14.521: INFO: Terminating ReplicationController wrapped-volume-race-946c680b-17c2-11e9-912e-6a405af5e95c pods took: 100.970765ms
STEP: Creating RC which spawns configmap-volume pods
Jan 14 06:07:58.739: INFO: Pod name wrapped-volume-race-bdd17429-17c2-11e9-912e-6a405af5e95c: Found 0 pods out of 5
Jan 14 06:08:03.757: INFO: Pod name wrapped-volume-race-bdd17429-17c2-11e9-912e-6a405af5e95c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-bdd17429-17c2-11e9-912e-6a405af5e95c in namespace e2e-tests-emptydir-wrapper-wttls, will wait for the garbage collector to delete the pods
Jan 14 06:08:41.836: INFO: Deleting ReplicationController wrapped-volume-race-bdd17429-17c2-11e9-912e-6a405af5e95c took: 6.779627ms
Jan 14 06:08:41.936: INFO: Terminating ReplicationController wrapped-volume-race-bdd17429-17c2-11e9-912e-6a405af5e95c pods took: 100.473774ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:09:28.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-wttls" for this suite.
Jan 14 06:09:34.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:09:34.735: INFO: namespace: e2e-tests-emptydir-wrapper-wttls, resource: bindings, ignored listing per whitelist
Jan 14 06:09:34.817: INFO: namespace e2e-tests-emptydir-wrapper-wttls deletion completed in 6.133259165s

• [SLOW TEST:300.743 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:09:34.817: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 06:09:34.897: INFO: Creating ReplicaSet my-hostname-basic-f72490b3-17c2-11e9-912e-6a405af5e95c
Jan 14 06:09:34.905: INFO: Pod name my-hostname-basic-f72490b3-17c2-11e9-912e-6a405af5e95c: Found 0 pods out of 1
Jan 14 06:09:39.909: INFO: Pod name my-hostname-basic-f72490b3-17c2-11e9-912e-6a405af5e95c: Found 1 pods out of 1
Jan 14 06:09:39.909: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f72490b3-17c2-11e9-912e-6a405af5e95c" is running
Jan 14 06:09:39.912: INFO: Pod "my-hostname-basic-f72490b3-17c2-11e9-912e-6a405af5e95c-7j88p" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-14 06:09:34 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-14 06:09:36 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-14 06:09:36 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-14 06:09:34 +0000 UTC Reason: Message:}])
Jan 14 06:09:39.912: INFO: Trying to dial the pod
Jan 14 06:09:44.924: INFO: Controller my-hostname-basic-f72490b3-17c2-11e9-912e-6a405af5e95c: Got expected result from replica 1 [my-hostname-basic-f72490b3-17c2-11e9-912e-6a405af5e95c-7j88p]: "my-hostname-basic-f72490b3-17c2-11e9-912e-6a405af5e95c-7j88p", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:09:44.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-zm6zb" for this suite.
Jan 14 06:09:50.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:09:50.988: INFO: namespace: e2e-tests-replicaset-zm6zb, resource: bindings, ignored listing per whitelist
Jan 14 06:09:51.028: INFO: namespace e2e-tests-replicaset-zm6zb deletion completed in 6.099823577s

• [SLOW TEST:16.210 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:09:51.028: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 06:09:51.130: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00cfa06d-17c3-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-7qvrj" to be "success or failure"
Jan 14 06:09:51.140: INFO: Pod "downwardapi-volume-00cfa06d-17c3-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.043273ms
Jan 14 06:09:53.144: INFO: Pod "downwardapi-volume-00cfa06d-17c3-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013363441s
STEP: Saw pod success
Jan 14 06:09:53.144: INFO: Pod "downwardapi-volume-00cfa06d-17c3-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:09:53.158: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-00cfa06d-17c3-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 06:09:53.184: INFO: Waiting for pod downwardapi-volume-00cfa06d-17c3-11e9-912e-6a405af5e95c to disappear
Jan 14 06:09:53.190: INFO: Pod downwardapi-volume-00cfa06d-17c3-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:09:53.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7qvrj" for this suite.
Jan 14 06:09:59.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:09:59.222: INFO: namespace: e2e-tests-downward-api-7qvrj, resource: bindings, ignored listing per whitelist
Jan 14 06:09:59.281: INFO: namespace e2e-tests-downward-api-7qvrj deletion completed in 6.087277388s

• [SLOW TEST:8.253 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:09:59.281: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-05b98969-17c3-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 06:09:59.374: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-05ba57ce-17c3-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-9ct8w" to be "success or failure"
Jan 14 06:09:59.382: INFO: Pod "pod-projected-secrets-05ba57ce-17c3-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.388956ms
Jan 14 06:10:01.385: INFO: Pod "pod-projected-secrets-05ba57ce-17c3-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011026621s
STEP: Saw pod success
Jan 14 06:10:01.385: INFO: Pod "pod-projected-secrets-05ba57ce-17c3-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:10:01.389: INFO: Trying to get logs from node paaswkr2 pod pod-projected-secrets-05ba57ce-17c3-11e9-912e-6a405af5e95c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 14 06:10:01.408: INFO: Waiting for pod pod-projected-secrets-05ba57ce-17c3-11e9-912e-6a405af5e95c to disappear
Jan 14 06:10:01.411: INFO: Pod pod-projected-secrets-05ba57ce-17c3-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:10:01.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9ct8w" for this suite.
Jan 14 06:10:07.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:10:07.506: INFO: namespace: e2e-tests-projected-9ct8w, resource: bindings, ignored listing per whitelist
Jan 14 06:10:07.512: INFO: namespace e2e-tests-projected-9ct8w deletion completed in 6.096904908s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:10:07.512: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 14 06:10:07.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-npvtz'
Jan 14 06:10:07.838: INFO: stderr: ""
Jan 14 06:10:07.838: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 14 06:10:08.842: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 06:10:08.842: INFO: Found 0 / 1
Jan 14 06:10:09.842: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 06:10:09.842: INFO: Found 1 / 1
Jan 14 06:10:09.842: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan 14 06:10:09.845: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 06:10:09.845: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 14 06:10:09.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 patch pod redis-master-bzl7l --namespace=e2e-tests-kubectl-npvtz -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 14 06:10:09.927: INFO: stderr: ""
Jan 14 06:10:09.927: INFO: stdout: "pod/redis-master-bzl7l patched\n"
STEP: checking annotations
Jan 14 06:10:09.931: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 06:10:09.931: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:10:09.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-npvtz" for this suite.
Jan 14 06:10:31.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:10:31.986: INFO: namespace: e2e-tests-kubectl-npvtz, resource: bindings, ignored listing per whitelist
Jan 14 06:10:32.046: INFO: namespace e2e-tests-kubectl-npvtz deletion completed in 22.11014573s

• [SLOW TEST:24.534 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:10:32.046: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Jan 14 06:10:32.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-vgv74'
Jan 14 06:10:32.279: INFO: stderr: ""
Jan 14 06:10:32.279: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan 14 06:10:33.282: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 06:10:33.282: INFO: Found 0 / 1
Jan 14 06:10:34.282: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 06:10:34.282: INFO: Found 1 / 1
Jan 14 06:10:34.282: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 14 06:10:34.286: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 06:10:34.286: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan 14 06:10:34.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 logs redis-master-xksjr redis-master --namespace=e2e-tests-kubectl-vgv74'
Jan 14 06:10:34.381: INFO: stderr: ""
Jan 14 06:10:34.381: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Jan 06:10:33.035 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Jan 06:10:33.035 # Server started, Redis version 3.2.12\n1:M 14 Jan 06:10:33.035 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Jan 06:10:33.035 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan 14 06:10:34.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 log redis-master-xksjr redis-master --namespace=e2e-tests-kubectl-vgv74 --tail=1'
Jan 14 06:10:34.524: INFO: stderr: ""
Jan 14 06:10:34.524: INFO: stdout: "1:M 14 Jan 06:10:33.035 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan 14 06:10:34.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 log redis-master-xksjr redis-master --namespace=e2e-tests-kubectl-vgv74 --limit-bytes=1'
Jan 14 06:10:34.620: INFO: stderr: ""
Jan 14 06:10:34.620: INFO: stdout: " "
STEP: exposing timestamps
Jan 14 06:10:34.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 log redis-master-xksjr redis-master --namespace=e2e-tests-kubectl-vgv74 --tail=1 --timestamps'
Jan 14 06:10:34.706: INFO: stderr: ""
Jan 14 06:10:34.706: INFO: stdout: "2019-01-14T06:10:33.036168711Z 1:M 14 Jan 06:10:33.035 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan 14 06:10:37.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 log redis-master-xksjr redis-master --namespace=e2e-tests-kubectl-vgv74 --since=1s'
Jan 14 06:10:37.291: INFO: stderr: ""
Jan 14 06:10:37.291: INFO: stdout: ""
Jan 14 06:10:37.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 log redis-master-xksjr redis-master --namespace=e2e-tests-kubectl-vgv74 --since=24h'
Jan 14 06:10:37.390: INFO: stderr: ""
Jan 14 06:10:37.391: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Jan 06:10:33.035 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Jan 06:10:33.035 # Server started, Redis version 3.2.12\n1:M 14 Jan 06:10:33.035 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Jan 06:10:33.035 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Jan 14 06:10:37.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vgv74'
Jan 14 06:10:37.466: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 14 06:10:37.466: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan 14 06:10:37.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-vgv74'
Jan 14 06:10:37.626: INFO: stderr: "No resources found.\n"
Jan 14 06:10:37.626: INFO: stdout: ""
Jan 14 06:10:37.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -l name=nginx --namespace=e2e-tests-kubectl-vgv74 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 14 06:10:37.787: INFO: stderr: ""
Jan 14 06:10:37.787: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:10:37.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vgv74" for this suite.
Jan 14 06:10:59.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:10:59.862: INFO: namespace: e2e-tests-kubectl-vgv74, resource: bindings, ignored listing per whitelist
Jan 14 06:10:59.880: INFO: namespace e2e-tests-kubectl-vgv74 deletion completed in 22.08564189s

• [SLOW TEST:27.834 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:10:59.880: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-mzsv
STEP: Creating a pod to test atomic-volume-subpath
Jan 14 06:10:59.967: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-mzsv" in namespace "e2e-tests-subpath-drnn7" to be "success or failure"
Jan 14 06:10:59.976: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.481481ms
Jan 14 06:11:01.984: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016797886s
Jan 14 06:11:03.987: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Running", Reason="", readiness=false. Elapsed: 4.019824929s
Jan 14 06:11:05.990: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Running", Reason="", readiness=false. Elapsed: 6.02248201s
Jan 14 06:11:07.994: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Running", Reason="", readiness=false. Elapsed: 8.026113608s
Jan 14 06:11:09.997: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Running", Reason="", readiness=false. Elapsed: 10.029586449s
Jan 14 06:11:12.000: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Running", Reason="", readiness=false. Elapsed: 12.032844094s
Jan 14 06:11:14.004: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Running", Reason="", readiness=false. Elapsed: 14.036784282s
Jan 14 06:11:16.008: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Running", Reason="", readiness=false. Elapsed: 16.040428988s
Jan 14 06:11:18.013: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Running", Reason="", readiness=false. Elapsed: 18.045292315s
Jan 14 06:11:20.016: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Running", Reason="", readiness=false. Elapsed: 20.048864799s
Jan 14 06:11:22.020: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Running", Reason="", readiness=false. Elapsed: 22.052846413s
Jan 14 06:11:24.026: INFO: Pod "pod-subpath-test-downwardapi-mzsv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057986225s
STEP: Saw pod success
Jan 14 06:11:24.026: INFO: Pod "pod-subpath-test-downwardapi-mzsv" satisfied condition "success or failure"
Jan 14 06:11:24.029: INFO: Trying to get logs from node paaswkr2 pod pod-subpath-test-downwardapi-mzsv container test-container-subpath-downwardapi-mzsv: <nil>
STEP: delete the pod
Jan 14 06:11:24.047: INFO: Waiting for pod pod-subpath-test-downwardapi-mzsv to disappear
Jan 14 06:11:24.050: INFO: Pod pod-subpath-test-downwardapi-mzsv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-mzsv
Jan 14 06:11:24.050: INFO: Deleting pod "pod-subpath-test-downwardapi-mzsv" in namespace "e2e-tests-subpath-drnn7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:11:24.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-drnn7" for this suite.
Jan 14 06:11:30.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:11:30.104: INFO: namespace: e2e-tests-subpath-drnn7, resource: bindings, ignored listing per whitelist
Jan 14 06:11:30.172: INFO: namespace e2e-tests-subpath-drnn7 deletion completed in 6.106865388s

• [SLOW TEST:30.292 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:11:30.172: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:11:36.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-f5gbs" for this suite.
Jan 14 06:11:42.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:11:42.426: INFO: namespace: e2e-tests-namespaces-f5gbs, resource: bindings, ignored listing per whitelist
Jan 14 06:11:42.452: INFO: namespace e2e-tests-namespaces-f5gbs deletion completed in 6.098801396s
STEP: Destroying namespace "e2e-tests-nsdeletetest-nqtj6" for this suite.
Jan 14 06:11:42.454: INFO: Namespace e2e-tests-nsdeletetest-nqtj6 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-8qgml" for this suite.
Jan 14 06:11:48.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:11:48.517: INFO: namespace: e2e-tests-nsdeletetest-8qgml, resource: bindings, ignored listing per whitelist
Jan 14 06:11:48.556: INFO: namespace e2e-tests-nsdeletetest-8qgml deletion completed in 6.101245072s

• [SLOW TEST:18.384 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:11:48.556: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 14 06:11:48.662: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:11:48.665: INFO: Number of nodes with available pods: 0
Jan 14 06:11:48.665: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:11:49.670: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:11:49.674: INFO: Number of nodes with available pods: 0
Jan 14 06:11:49.674: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:11:50.678: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:11:50.685: INFO: Number of nodes with available pods: 1
Jan 14 06:11:50.685: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:11:51.672: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:11:51.675: INFO: Number of nodes with available pods: 2
Jan 14 06:11:51.675: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan 14 06:11:51.694: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:11:51.702: INFO: Number of nodes with available pods: 1
Jan 14 06:11:51.702: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:11:52.706: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:11:52.711: INFO: Number of nodes with available pods: 1
Jan 14 06:11:52.711: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:11:53.710: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:11:53.714: INFO: Number of nodes with available pods: 2
Jan 14 06:11:53.714: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-gf5nc, will wait for the garbage collector to delete the pods
Jan 14 06:11:53.785: INFO: Deleting DaemonSet.extensions daemon-set took: 10.519398ms
Jan 14 06:11:53.885: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.518157ms
Jan 14 06:12:38.288: INFO: Number of nodes with available pods: 0
Jan 14 06:12:38.288: INFO: Number of running nodes: 0, number of available pods: 0
Jan 14 06:12:38.293: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gf5nc/daemonsets","resourceVersion":"56199"},"items":null}

Jan 14 06:12:38.298: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gf5nc/pods","resourceVersion":"56199"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:12:38.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gf5nc" for this suite.
Jan 14 06:12:44.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:12:44.415: INFO: namespace: e2e-tests-daemonsets-gf5nc, resource: bindings, ignored listing per whitelist
Jan 14 06:12:44.434: INFO: namespace e2e-tests-daemonsets-gf5nc deletion completed in 6.119368517s

• [SLOW TEST:55.878 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:12:44.434: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-xqkx4
I0114 06:12:44.509903      13 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-xqkx4, replica count: 1
I0114 06:12:45.561601      13 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0114 06:12:46.562324      13 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0114 06:12:47.562427      13 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 14 06:12:47.688: INFO: Created: latency-svc-8sqxn
Jan 14 06:12:47.704: INFO: Got endpoints: latency-svc-8sqxn [41.682109ms]
Jan 14 06:12:47.731: INFO: Created: latency-svc-hlwcc
Jan 14 06:12:47.738: INFO: Got endpoints: latency-svc-hlwcc [33.501103ms]
Jan 14 06:12:47.746: INFO: Created: latency-svc-hkvcp
Jan 14 06:12:47.752: INFO: Got endpoints: latency-svc-hkvcp [47.45587ms]
Jan 14 06:12:47.760: INFO: Created: latency-svc-jmznd
Jan 14 06:12:47.769: INFO: Got endpoints: latency-svc-jmznd [63.603738ms]
Jan 14 06:12:47.782: INFO: Created: latency-svc-zgthh
Jan 14 06:12:47.789: INFO: Got endpoints: latency-svc-zgthh [81.695863ms]
Jan 14 06:12:47.800: INFO: Created: latency-svc-2q4c7
Jan 14 06:12:47.806: INFO: Got endpoints: latency-svc-2q4c7 [98.962953ms]
Jan 14 06:12:47.818: INFO: Created: latency-svc-nnbhn
Jan 14 06:12:47.829: INFO: Got endpoints: latency-svc-nnbhn [121.633121ms]
Jan 14 06:12:47.837: INFO: Created: latency-svc-rlbjz
Jan 14 06:12:47.844: INFO: Got endpoints: latency-svc-rlbjz [135.936857ms]
Jan 14 06:12:47.864: INFO: Created: latency-svc-whkzk
Jan 14 06:12:47.870: INFO: Got endpoints: latency-svc-whkzk [154.726633ms]
Jan 14 06:12:47.877: INFO: Created: latency-svc-lngq6
Jan 14 06:12:47.884: INFO: Got endpoints: latency-svc-lngq6 [168.034338ms]
Jan 14 06:12:47.906: INFO: Created: latency-svc-rkwql
Jan 14 06:12:47.906: INFO: Got endpoints: latency-svc-rkwql [190.025555ms]
Jan 14 06:12:47.924: INFO: Created: latency-svc-b76b4
Jan 14 06:12:47.940: INFO: Got endpoints: latency-svc-b76b4 [224.355196ms]
Jan 14 06:12:47.970: INFO: Created: latency-svc-sp94h
Jan 14 06:12:47.976: INFO: Got endpoints: latency-svc-sp94h [260.427502ms]
Jan 14 06:12:47.993: INFO: Created: latency-svc-lr7f8
Jan 14 06:12:47.993: INFO: Got endpoints: latency-svc-lr7f8 [274.116223ms]
Jan 14 06:12:48.006: INFO: Created: latency-svc-495qb
Jan 14 06:12:48.022: INFO: Got endpoints: latency-svc-495qb [304.080357ms]
Jan 14 06:12:48.023: INFO: Created: latency-svc-gjjm6
Jan 14 06:12:48.032: INFO: Created: latency-svc-j5hz6
Jan 14 06:12:48.034: INFO: Got endpoints: latency-svc-gjjm6 [314.392037ms]
Jan 14 06:12:48.047: INFO: Got endpoints: latency-svc-j5hz6 [308.916376ms]
Jan 14 06:12:48.086: INFO: Created: latency-svc-mz8zb
Jan 14 06:12:48.086: INFO: Got endpoints: latency-svc-mz8zb [333.295018ms]
Jan 14 06:12:48.096: INFO: Created: latency-svc-wvdjc
Jan 14 06:12:48.104: INFO: Got endpoints: latency-svc-wvdjc [334.943964ms]
Jan 14 06:12:48.111: INFO: Created: latency-svc-728bm
Jan 14 06:12:48.117: INFO: Got endpoints: latency-svc-728bm [327.449452ms]
Jan 14 06:12:48.130: INFO: Created: latency-svc-9wvcm
Jan 14 06:12:48.139: INFO: Got endpoints: latency-svc-9wvcm [332.75785ms]
Jan 14 06:12:48.149: INFO: Created: latency-svc-6qktr
Jan 14 06:12:48.154: INFO: Got endpoints: latency-svc-6qktr [324.396898ms]
Jan 14 06:12:48.172: INFO: Created: latency-svc-n7wcg
Jan 14 06:12:48.188: INFO: Created: latency-svc-pl5sf
Jan 14 06:12:48.188: INFO: Got endpoints: latency-svc-pl5sf [318.351762ms]
Jan 14 06:12:48.189: INFO: Got endpoints: latency-svc-n7wcg [344.629396ms]
Jan 14 06:12:48.197: INFO: Created: latency-svc-g4lx2
Jan 14 06:12:48.210: INFO: Got endpoints: latency-svc-g4lx2 [325.901571ms]
Jan 14 06:12:48.219: INFO: Created: latency-svc-wdqwf
Jan 14 06:12:48.223: INFO: Got endpoints: latency-svc-wdqwf [316.780266ms]
Jan 14 06:12:48.244: INFO: Created: latency-svc-7g4zc
Jan 14 06:12:48.246: INFO: Got endpoints: latency-svc-7g4zc [306.346386ms]
Jan 14 06:12:48.257: INFO: Created: latency-svc-57sz9
Jan 14 06:12:48.266: INFO: Got endpoints: latency-svc-57sz9 [289.505076ms]
Jan 14 06:12:48.273: INFO: Created: latency-svc-4cfsk
Jan 14 06:12:48.282: INFO: Got endpoints: latency-svc-4cfsk [289.419777ms]
Jan 14 06:12:48.289: INFO: Created: latency-svc-fnstl
Jan 14 06:12:48.296: INFO: Got endpoints: latency-svc-fnstl [273.634499ms]
Jan 14 06:12:48.307: INFO: Created: latency-svc-jjml5
Jan 14 06:12:48.312: INFO: Got endpoints: latency-svc-jjml5 [277.768618ms]
Jan 14 06:12:48.316: INFO: Created: latency-svc-xfrpc
Jan 14 06:12:48.329: INFO: Got endpoints: latency-svc-xfrpc [282.145258ms]
Jan 14 06:12:48.340: INFO: Created: latency-svc-fx66k
Jan 14 06:12:48.348: INFO: Got endpoints: latency-svc-fx66k [262.057631ms]
Jan 14 06:12:48.356: INFO: Created: latency-svc-gr589
Jan 14 06:12:48.362: INFO: Got endpoints: latency-svc-gr589 [258.148739ms]
Jan 14 06:12:48.394: INFO: Created: latency-svc-vz2h7
Jan 14 06:12:48.404: INFO: Got endpoints: latency-svc-vz2h7 [287.265164ms]
Jan 14 06:12:48.413: INFO: Created: latency-svc-vzmbr
Jan 14 06:12:48.418: INFO: Created: latency-svc-gcxmd
Jan 14 06:12:48.418: INFO: Got endpoints: latency-svc-vzmbr [278.979015ms]
Jan 14 06:12:48.427: INFO: Got endpoints: latency-svc-gcxmd [272.840557ms]
Jan 14 06:12:48.447: INFO: Created: latency-svc-7zsbf
Jan 14 06:12:48.467: INFO: Got endpoints: latency-svc-7zsbf [279.252511ms]
Jan 14 06:12:48.479: INFO: Created: latency-svc-9lmxh
Jan 14 06:12:48.486: INFO: Got endpoints: latency-svc-9lmxh [296.88905ms]
Jan 14 06:12:48.496: INFO: Created: latency-svc-lgn6t
Jan 14 06:12:48.503: INFO: Got endpoints: latency-svc-lgn6t [293.044028ms]
Jan 14 06:12:48.516: INFO: Created: latency-svc-x5smc
Jan 14 06:12:48.524: INFO: Created: latency-svc-t6t2p
Jan 14 06:12:48.524: INFO: Got endpoints: latency-svc-x5smc [301.227985ms]
Jan 14 06:12:48.547: INFO: Got endpoints: latency-svc-t6t2p [301.008339ms]
Jan 14 06:12:48.556: INFO: Created: latency-svc-876dc
Jan 14 06:12:48.564: INFO: Got endpoints: latency-svc-876dc [297.511381ms]
Jan 14 06:12:48.573: INFO: Created: latency-svc-z7hkl
Jan 14 06:12:48.583: INFO: Got endpoints: latency-svc-z7hkl [300.278945ms]
Jan 14 06:12:48.593: INFO: Created: latency-svc-l7482
Jan 14 06:12:48.601: INFO: Got endpoints: latency-svc-l7482 [304.34949ms]
Jan 14 06:12:48.604: INFO: Created: latency-svc-mrxf7
Jan 14 06:12:48.612: INFO: Got endpoints: latency-svc-mrxf7 [300.222765ms]
Jan 14 06:12:48.618: INFO: Created: latency-svc-pxw96
Jan 14 06:12:48.633: INFO: Got endpoints: latency-svc-pxw96 [304.016906ms]
Jan 14 06:12:48.645: INFO: Created: latency-svc-ll24f
Jan 14 06:12:48.655: INFO: Got endpoints: latency-svc-ll24f [306.932632ms]
Jan 14 06:12:48.667: INFO: Created: latency-svc-xq8nn
Jan 14 06:12:48.675: INFO: Got endpoints: latency-svc-xq8nn [312.635691ms]
Jan 14 06:12:48.682: INFO: Created: latency-svc-8zfsv
Jan 14 06:12:48.697: INFO: Got endpoints: latency-svc-8zfsv [293.543772ms]
Jan 14 06:12:48.698: INFO: Created: latency-svc-bxn72
Jan 14 06:12:48.721: INFO: Created: latency-svc-tg6dj
Jan 14 06:12:48.833: INFO: Got endpoints: latency-svc-bxn72 [415.423856ms]
Jan 14 06:12:48.840: INFO: Got endpoints: latency-svc-tg6dj [413.492394ms]
Jan 14 06:12:48.847: INFO: Created: latency-svc-9ts4s
Jan 14 06:12:48.856: INFO: Got endpoints: latency-svc-9ts4s [383.618345ms]
Jan 14 06:12:48.869: INFO: Created: latency-svc-vtl9p
Jan 14 06:12:48.881: INFO: Created: latency-svc-xvp6w
Jan 14 06:12:48.893: INFO: Got endpoints: latency-svc-vtl9p [407.649142ms]
Jan 14 06:12:48.894: INFO: Created: latency-svc-hmgjl
Jan 14 06:12:48.905: INFO: Created: latency-svc-lzfth
Jan 14 06:12:48.913: INFO: Created: latency-svc-m85s4
Jan 14 06:12:48.929: INFO: Created: latency-svc-xzf8m
Jan 14 06:12:48.949: INFO: Got endpoints: latency-svc-xvp6w [446.228145ms]
Jan 14 06:12:48.956: INFO: Created: latency-svc-8pmmh
Jan 14 06:12:48.964: INFO: Created: latency-svc-84j84
Jan 14 06:12:48.982: INFO: Created: latency-svc-9j5vd
Jan 14 06:12:48.999: INFO: Got endpoints: latency-svc-hmgjl [475.152596ms]
Jan 14 06:12:49.000: INFO: Created: latency-svc-69fc8
Jan 14 06:12:49.008: INFO: Created: latency-svc-llml4
Jan 14 06:12:49.022: INFO: Created: latency-svc-mvlvc
Jan 14 06:12:49.033: INFO: Created: latency-svc-rd245
Jan 14 06:12:49.042: INFO: Got endpoints: latency-svc-lzfth [494.931684ms]
Jan 14 06:12:49.080: INFO: Created: latency-svc-z758w
Jan 14 06:12:49.090: INFO: Created: latency-svc-d96xj
Jan 14 06:12:49.102: INFO: Got endpoints: latency-svc-m85s4 [538.427785ms]
Jan 14 06:12:49.111: INFO: Created: latency-svc-s7wd7
Jan 14 06:12:49.118: INFO: Created: latency-svc-gfsmf
Jan 14 06:12:49.139: INFO: Created: latency-svc-wnz95
Jan 14 06:12:49.139: INFO: Created: latency-svc-7cgkx
Jan 14 06:12:49.150: INFO: Got endpoints: latency-svc-xzf8m [567.649153ms]
Jan 14 06:12:49.151: INFO: Created: latency-svc-tgkbk
Jan 14 06:12:49.199: INFO: Got endpoints: latency-svc-8pmmh [598.416551ms]
Jan 14 06:12:49.200: INFO: Created: latency-svc-gblcm
Jan 14 06:12:49.214: INFO: Created: latency-svc-72bxx
Jan 14 06:12:49.240: INFO: Got endpoints: latency-svc-84j84 [628.267254ms]
Jan 14 06:12:49.255: INFO: Created: latency-svc-gwdwz
Jan 14 06:12:49.296: INFO: Got endpoints: latency-svc-9j5vd [662.889588ms]
Jan 14 06:12:49.308: INFO: Created: latency-svc-nhw6b
Jan 14 06:12:49.349: INFO: Got endpoints: latency-svc-69fc8 [694.225743ms]
Jan 14 06:12:49.364: INFO: Created: latency-svc-bfvmg
Jan 14 06:12:49.393: INFO: Got endpoints: latency-svc-llml4 [718.137134ms]
Jan 14 06:12:49.416: INFO: Created: latency-svc-9v85t
Jan 14 06:12:49.446: INFO: Got endpoints: latency-svc-mvlvc [748.869641ms]
Jan 14 06:12:49.472: INFO: Created: latency-svc-r9x57
Jan 14 06:12:49.490: INFO: Got endpoints: latency-svc-rd245 [657.03675ms]
Jan 14 06:12:49.517: INFO: Created: latency-svc-fxz57
Jan 14 06:12:49.545: INFO: Got endpoints: latency-svc-z758w [704.604462ms]
Jan 14 06:12:49.570: INFO: Created: latency-svc-w8glq
Jan 14 06:12:49.595: INFO: Got endpoints: latency-svc-d96xj [739.019702ms]
Jan 14 06:12:49.617: INFO: Created: latency-svc-g8x5s
Jan 14 06:12:49.643: INFO: Got endpoints: latency-svc-s7wd7 [749.494334ms]
Jan 14 06:12:49.658: INFO: Created: latency-svc-r6x86
Jan 14 06:12:49.691: INFO: Got endpoints: latency-svc-gfsmf [742.290087ms]
Jan 14 06:12:49.716: INFO: Created: latency-svc-q9mf5
Jan 14 06:12:49.740: INFO: Got endpoints: latency-svc-7cgkx [741.1838ms]
Jan 14 06:12:49.755: INFO: Created: latency-svc-5dlbz
Jan 14 06:12:49.791: INFO: Got endpoints: latency-svc-wnz95 [748.603228ms]
Jan 14 06:12:49.804: INFO: Created: latency-svc-gts88
Jan 14 06:12:49.842: INFO: Got endpoints: latency-svc-tgkbk [739.753412ms]
Jan 14 06:12:49.855: INFO: Created: latency-svc-llfw7
Jan 14 06:12:49.891: INFO: Got endpoints: latency-svc-gblcm [740.602374ms]
Jan 14 06:12:49.902: INFO: Created: latency-svc-g6lxv
Jan 14 06:12:49.941: INFO: Got endpoints: latency-svc-72bxx [741.98511ms]
Jan 14 06:12:49.965: INFO: Created: latency-svc-76p5b
Jan 14 06:12:49.990: INFO: Got endpoints: latency-svc-gwdwz [750.041335ms]
Jan 14 06:12:50.009: INFO: Created: latency-svc-xfdkb
Jan 14 06:12:50.042: INFO: Got endpoints: latency-svc-nhw6b [745.573179ms]
Jan 14 06:12:50.056: INFO: Created: latency-svc-xw4wt
Jan 14 06:12:50.092: INFO: Got endpoints: latency-svc-bfvmg [743.318084ms]
Jan 14 06:12:50.107: INFO: Created: latency-svc-5fjl5
Jan 14 06:12:50.140: INFO: Got endpoints: latency-svc-9v85t [747.668674ms]
Jan 14 06:12:50.166: INFO: Created: latency-svc-x59n6
Jan 14 06:12:50.190: INFO: Got endpoints: latency-svc-r9x57 [743.378611ms]
Jan 14 06:12:50.208: INFO: Created: latency-svc-x2gsf
Jan 14 06:12:50.239: INFO: Got endpoints: latency-svc-fxz57 [749.007071ms]
Jan 14 06:12:50.260: INFO: Created: latency-svc-bx87b
Jan 14 06:12:50.293: INFO: Got endpoints: latency-svc-w8glq [747.976661ms]
Jan 14 06:12:50.303: INFO: Created: latency-svc-g9cfg
Jan 14 06:12:50.343: INFO: Got endpoints: latency-svc-g8x5s [748.466556ms]
Jan 14 06:12:50.361: INFO: Created: latency-svc-dqdwr
Jan 14 06:12:50.392: INFO: Got endpoints: latency-svc-r6x86 [749.130681ms]
Jan 14 06:12:50.413: INFO: Created: latency-svc-x8th6
Jan 14 06:12:50.444: INFO: Got endpoints: latency-svc-q9mf5 [753.015307ms]
Jan 14 06:12:50.508: INFO: Created: latency-svc-57wjd
Jan 14 06:12:50.508: INFO: Got endpoints: latency-svc-5dlbz [767.383316ms]
Jan 14 06:12:50.519: INFO: Created: latency-svc-vj46x
Jan 14 06:12:50.542: INFO: Got endpoints: latency-svc-gts88 [751.502612ms]
Jan 14 06:12:50.562: INFO: Created: latency-svc-4gc8z
Jan 14 06:12:50.592: INFO: Got endpoints: latency-svc-llfw7 [749.976839ms]
Jan 14 06:12:50.612: INFO: Created: latency-svc-brsgc
Jan 14 06:12:50.644: INFO: Got endpoints: latency-svc-g6lxv [753.324647ms]
Jan 14 06:12:50.662: INFO: Created: latency-svc-phmhf
Jan 14 06:12:50.691: INFO: Got endpoints: latency-svc-76p5b [750.163952ms]
Jan 14 06:12:50.706: INFO: Created: latency-svc-krlrn
Jan 14 06:12:50.742: INFO: Got endpoints: latency-svc-xfdkb [751.625375ms]
Jan 14 06:12:50.757: INFO: Created: latency-svc-mzdbl
Jan 14 06:12:50.790: INFO: Got endpoints: latency-svc-xw4wt [748.20594ms]
Jan 14 06:12:50.807: INFO: Created: latency-svc-klp8l
Jan 14 06:12:50.847: INFO: Got endpoints: latency-svc-5fjl5 [754.575585ms]
Jan 14 06:12:50.869: INFO: Created: latency-svc-t2qbj
Jan 14 06:12:50.890: INFO: Got endpoints: latency-svc-x59n6 [749.852574ms]
Jan 14 06:12:50.902: INFO: Created: latency-svc-6q6bc
Jan 14 06:12:50.941: INFO: Got endpoints: latency-svc-x2gsf [751.470504ms]
Jan 14 06:12:50.959: INFO: Created: latency-svc-687d9
Jan 14 06:12:50.991: INFO: Got endpoints: latency-svc-bx87b [751.717968ms]
Jan 14 06:12:51.006: INFO: Created: latency-svc-9h7p4
Jan 14 06:12:51.040: INFO: Got endpoints: latency-svc-g9cfg [746.963693ms]
Jan 14 06:12:51.056: INFO: Created: latency-svc-mtftr
Jan 14 06:12:51.090: INFO: Got endpoints: latency-svc-dqdwr [747.005323ms]
Jan 14 06:12:51.106: INFO: Created: latency-svc-fq46d
Jan 14 06:12:51.139: INFO: Got endpoints: latency-svc-x8th6 [747.242779ms]
Jan 14 06:12:51.154: INFO: Created: latency-svc-gszm9
Jan 14 06:12:51.191: INFO: Got endpoints: latency-svc-57wjd [747.198632ms]
Jan 14 06:12:51.224: INFO: Created: latency-svc-w5bwv
Jan 14 06:12:51.243: INFO: Got endpoints: latency-svc-vj46x [735.361982ms]
Jan 14 06:12:51.261: INFO: Created: latency-svc-rxbm2
Jan 14 06:12:51.291: INFO: Got endpoints: latency-svc-4gc8z [749.319947ms]
Jan 14 06:12:51.307: INFO: Created: latency-svc-jb5zl
Jan 14 06:12:51.341: INFO: Got endpoints: latency-svc-brsgc [748.699337ms]
Jan 14 06:12:51.358: INFO: Created: latency-svc-s5q2b
Jan 14 06:12:51.392: INFO: Got endpoints: latency-svc-phmhf [747.053581ms]
Jan 14 06:12:51.409: INFO: Created: latency-svc-55jt9
Jan 14 06:12:51.443: INFO: Got endpoints: latency-svc-krlrn [751.598488ms]
Jan 14 06:12:51.460: INFO: Created: latency-svc-m77d8
Jan 14 06:12:51.492: INFO: Got endpoints: latency-svc-mzdbl [750.355732ms]
Jan 14 06:12:51.509: INFO: Created: latency-svc-hpmkl
Jan 14 06:12:51.541: INFO: Got endpoints: latency-svc-klp8l [751.011466ms]
Jan 14 06:12:51.555: INFO: Created: latency-svc-dfrd4
Jan 14 06:12:51.598: INFO: Got endpoints: latency-svc-t2qbj [751.338697ms]
Jan 14 06:12:51.612: INFO: Created: latency-svc-r5ztc
Jan 14 06:12:51.646: INFO: Got endpoints: latency-svc-6q6bc [755.208604ms]
Jan 14 06:12:51.664: INFO: Created: latency-svc-jgztd
Jan 14 06:12:51.691: INFO: Got endpoints: latency-svc-687d9 [749.743072ms]
Jan 14 06:12:51.706: INFO: Created: latency-svc-8b557
Jan 14 06:12:51.744: INFO: Got endpoints: latency-svc-9h7p4 [752.570846ms]
Jan 14 06:12:51.796: INFO: Got endpoints: latency-svc-mtftr [756.111261ms]
Jan 14 06:12:51.836: INFO: Created: latency-svc-mnzdd
Jan 14 06:12:51.860: INFO: Got endpoints: latency-svc-fq46d [769.520017ms]
Jan 14 06:12:51.886: INFO: Created: latency-svc-rqbn5
Jan 14 06:12:51.946: INFO: Got endpoints: latency-svc-gszm9 [806.500201ms]
Jan 14 06:12:51.962: INFO: Got endpoints: latency-svc-w5bwv [770.046579ms]
Jan 14 06:12:51.971: INFO: Created: latency-svc-vwm78
Jan 14 06:12:51.980: INFO: Created: latency-svc-592cb
Jan 14 06:12:51.986: INFO: Created: latency-svc-8fbvr
Jan 14 06:12:51.993: INFO: Got endpoints: latency-svc-rxbm2 [749.459962ms]
Jan 14 06:12:52.007: INFO: Created: latency-svc-pw9tz
Jan 14 06:12:52.041: INFO: Got endpoints: latency-svc-jb5zl [749.712031ms]
Jan 14 06:12:52.063: INFO: Created: latency-svc-zpqpn
Jan 14 06:12:52.091: INFO: Got endpoints: latency-svc-s5q2b [750.610364ms]
Jan 14 06:12:52.112: INFO: Created: latency-svc-2rqvp
Jan 14 06:12:52.142: INFO: Got endpoints: latency-svc-55jt9 [749.991833ms]
Jan 14 06:12:52.158: INFO: Created: latency-svc-z8ztw
Jan 14 06:12:52.191: INFO: Got endpoints: latency-svc-m77d8 [748.231162ms]
Jan 14 06:12:52.211: INFO: Created: latency-svc-2swb8
Jan 14 06:12:52.242: INFO: Got endpoints: latency-svc-hpmkl [749.582232ms]
Jan 14 06:12:52.262: INFO: Created: latency-svc-jk6kd
Jan 14 06:12:52.291: INFO: Got endpoints: latency-svc-dfrd4 [749.788328ms]
Jan 14 06:12:52.309: INFO: Created: latency-svc-s7p26
Jan 14 06:12:52.342: INFO: Got endpoints: latency-svc-r5ztc [743.25345ms]
Jan 14 06:12:52.375: INFO: Created: latency-svc-skqnc
Jan 14 06:12:52.391: INFO: Got endpoints: latency-svc-jgztd [745.387626ms]
Jan 14 06:12:52.412: INFO: Created: latency-svc-jlj26
Jan 14 06:12:52.440: INFO: Got endpoints: latency-svc-8b557 [749.352471ms]
Jan 14 06:12:52.456: INFO: Created: latency-svc-jmjpt
Jan 14 06:12:52.492: INFO: Got endpoints: latency-svc-mnzdd [747.91624ms]
Jan 14 06:12:52.507: INFO: Created: latency-svc-cq6gl
Jan 14 06:12:52.542: INFO: Got endpoints: latency-svc-rqbn5 [745.594683ms]
Jan 14 06:12:52.557: INFO: Created: latency-svc-8rhlh
Jan 14 06:12:52.590: INFO: Got endpoints: latency-svc-vwm78 [730.027675ms]
Jan 14 06:12:52.604: INFO: Created: latency-svc-kr5bw
Jan 14 06:12:52.641: INFO: Got endpoints: latency-svc-592cb [695.572419ms]
Jan 14 06:12:52.657: INFO: Created: latency-svc-z9c67
Jan 14 06:12:52.694: INFO: Got endpoints: latency-svc-8fbvr [732.302244ms]
Jan 14 06:12:52.708: INFO: Created: latency-svc-c5kt5
Jan 14 06:12:52.750: INFO: Got endpoints: latency-svc-pw9tz [757.584146ms]
Jan 14 06:12:52.765: INFO: Created: latency-svc-d794v
Jan 14 06:12:52.795: INFO: Got endpoints: latency-svc-zpqpn [753.234242ms]
Jan 14 06:12:52.811: INFO: Created: latency-svc-ngpfk
Jan 14 06:12:52.841: INFO: Got endpoints: latency-svc-2rqvp [747.535386ms]
Jan 14 06:12:52.860: INFO: Created: latency-svc-nv48m
Jan 14 06:12:52.889: INFO: Got endpoints: latency-svc-z8ztw [747.572747ms]
Jan 14 06:12:52.908: INFO: Created: latency-svc-hl8km
Jan 14 06:12:52.944: INFO: Got endpoints: latency-svc-2swb8 [752.695919ms]
Jan 14 06:12:52.959: INFO: Created: latency-svc-z4stc
Jan 14 06:12:52.990: INFO: Got endpoints: latency-svc-jk6kd [747.834394ms]
Jan 14 06:12:53.003: INFO: Created: latency-svc-9vr89
Jan 14 06:12:53.040: INFO: Got endpoints: latency-svc-s7p26 [749.342854ms]
Jan 14 06:12:53.063: INFO: Created: latency-svc-xnhvj
Jan 14 06:12:53.094: INFO: Got endpoints: latency-svc-skqnc [751.868031ms]
Jan 14 06:12:53.116: INFO: Created: latency-svc-lj258
Jan 14 06:12:53.140: INFO: Got endpoints: latency-svc-jlj26 [748.642546ms]
Jan 14 06:12:53.152: INFO: Created: latency-svc-n7wcc
Jan 14 06:12:53.191: INFO: Got endpoints: latency-svc-jmjpt [750.783666ms]
Jan 14 06:12:53.206: INFO: Created: latency-svc-s76s7
Jan 14 06:12:53.240: INFO: Got endpoints: latency-svc-cq6gl [748.704297ms]
Jan 14 06:12:53.254: INFO: Created: latency-svc-wqrfv
Jan 14 06:12:53.293: INFO: Got endpoints: latency-svc-8rhlh [751.103618ms]
Jan 14 06:12:53.307: INFO: Created: latency-svc-l64tc
Jan 14 06:12:53.342: INFO: Got endpoints: latency-svc-kr5bw [752.215471ms]
Jan 14 06:12:53.361: INFO: Created: latency-svc-5wwz4
Jan 14 06:12:53.393: INFO: Got endpoints: latency-svc-z9c67 [751.169199ms]
Jan 14 06:12:53.411: INFO: Created: latency-svc-st2l9
Jan 14 06:12:53.449: INFO: Got endpoints: latency-svc-c5kt5 [754.611807ms]
Jan 14 06:12:53.472: INFO: Created: latency-svc-97d46
Jan 14 06:12:53.491: INFO: Got endpoints: latency-svc-d794v [740.397163ms]
Jan 14 06:12:53.511: INFO: Created: latency-svc-vn6s2
Jan 14 06:12:53.543: INFO: Got endpoints: latency-svc-ngpfk [748.045155ms]
Jan 14 06:12:53.562: INFO: Created: latency-svc-4h87n
Jan 14 06:12:53.591: INFO: Got endpoints: latency-svc-nv48m [750.12411ms]
Jan 14 06:12:53.611: INFO: Created: latency-svc-82z5c
Jan 14 06:12:53.640: INFO: Got endpoints: latency-svc-hl8km [750.568871ms]
Jan 14 06:12:53.657: INFO: Created: latency-svc-cflsk
Jan 14 06:12:53.691: INFO: Got endpoints: latency-svc-z4stc [746.632364ms]
Jan 14 06:12:53.703: INFO: Created: latency-svc-4tnqt
Jan 14 06:12:53.741: INFO: Got endpoints: latency-svc-9vr89 [751.078523ms]
Jan 14 06:12:53.761: INFO: Created: latency-svc-4z827
Jan 14 06:12:53.796: INFO: Got endpoints: latency-svc-xnhvj [755.162199ms]
Jan 14 06:12:53.812: INFO: Created: latency-svc-97pmg
Jan 14 06:12:53.840: INFO: Got endpoints: latency-svc-lj258 [746.3486ms]
Jan 14 06:12:53.857: INFO: Created: latency-svc-vxwmz
Jan 14 06:12:53.891: INFO: Got endpoints: latency-svc-n7wcc [751.216376ms]
Jan 14 06:12:53.910: INFO: Created: latency-svc-498tj
Jan 14 06:12:53.944: INFO: Got endpoints: latency-svc-s76s7 [752.946559ms]
Jan 14 06:12:53.966: INFO: Created: latency-svc-92r2c
Jan 14 06:12:53.997: INFO: Got endpoints: latency-svc-wqrfv [756.362672ms]
Jan 14 06:12:54.014: INFO: Created: latency-svc-r6pw7
Jan 14 06:12:54.041: INFO: Got endpoints: latency-svc-l64tc [748.286038ms]
Jan 14 06:12:54.067: INFO: Created: latency-svc-bmztz
Jan 14 06:12:54.095: INFO: Got endpoints: latency-svc-5wwz4 [752.715075ms]
Jan 14 06:12:54.116: INFO: Created: latency-svc-pfs4f
Jan 14 06:12:54.144: INFO: Got endpoints: latency-svc-st2l9 [751.01421ms]
Jan 14 06:12:54.162: INFO: Created: latency-svc-rhm5q
Jan 14 06:12:54.192: INFO: Got endpoints: latency-svc-97d46 [743.629319ms]
Jan 14 06:12:54.209: INFO: Created: latency-svc-dqjxb
Jan 14 06:12:54.243: INFO: Got endpoints: latency-svc-vn6s2 [752.331823ms]
Jan 14 06:12:54.258: INFO: Created: latency-svc-99v4c
Jan 14 06:12:54.293: INFO: Got endpoints: latency-svc-4h87n [750.209896ms]
Jan 14 06:12:54.311: INFO: Created: latency-svc-gfjjz
Jan 14 06:12:54.340: INFO: Got endpoints: latency-svc-82z5c [748.876976ms]
Jan 14 06:12:54.353: INFO: Created: latency-svc-6c679
Jan 14 06:12:54.390: INFO: Got endpoints: latency-svc-cflsk [750.271575ms]
Jan 14 06:12:54.403: INFO: Created: latency-svc-djgdp
Jan 14 06:12:54.441: INFO: Got endpoints: latency-svc-4tnqt [750.844317ms]
Jan 14 06:12:54.459: INFO: Created: latency-svc-zd86f
Jan 14 06:12:54.493: INFO: Got endpoints: latency-svc-4z827 [751.716385ms]
Jan 14 06:12:54.506: INFO: Created: latency-svc-24cnw
Jan 14 06:12:54.540: INFO: Got endpoints: latency-svc-97pmg [744.439271ms]
Jan 14 06:12:54.554: INFO: Created: latency-svc-w8fvc
Jan 14 06:12:54.590: INFO: Got endpoints: latency-svc-vxwmz [749.856423ms]
Jan 14 06:12:54.606: INFO: Created: latency-svc-5q8qx
Jan 14 06:12:54.642: INFO: Got endpoints: latency-svc-498tj [750.617565ms]
Jan 14 06:12:54.655: INFO: Created: latency-svc-jqb5s
Jan 14 06:12:54.691: INFO: Got endpoints: latency-svc-92r2c [746.244027ms]
Jan 14 06:12:54.706: INFO: Created: latency-svc-9lj7z
Jan 14 06:12:54.743: INFO: Got endpoints: latency-svc-r6pw7 [745.951557ms]
Jan 14 06:12:54.754: INFO: Created: latency-svc-ss7j9
Jan 14 06:12:54.792: INFO: Got endpoints: latency-svc-bmztz [750.687756ms]
Jan 14 06:12:54.806: INFO: Created: latency-svc-xcsh2
Jan 14 06:12:54.841: INFO: Got endpoints: latency-svc-pfs4f [746.514268ms]
Jan 14 06:12:54.869: INFO: Created: latency-svc-qmn54
Jan 14 06:12:54.890: INFO: Got endpoints: latency-svc-rhm5q [746.264786ms]
Jan 14 06:12:54.906: INFO: Created: latency-svc-z84f7
Jan 14 06:12:54.942: INFO: Got endpoints: latency-svc-dqjxb [749.435967ms]
Jan 14 06:12:54.959: INFO: Created: latency-svc-nkhpv
Jan 14 06:12:54.991: INFO: Got endpoints: latency-svc-99v4c [748.199613ms]
Jan 14 06:12:55.009: INFO: Created: latency-svc-7lv6k
Jan 14 06:12:55.046: INFO: Got endpoints: latency-svc-gfjjz [753.472501ms]
Jan 14 06:12:55.062: INFO: Created: latency-svc-n9742
Jan 14 06:12:55.093: INFO: Got endpoints: latency-svc-6c679 [752.87868ms]
Jan 14 06:12:55.124: INFO: Created: latency-svc-6wvg2
Jan 14 06:12:55.142: INFO: Got endpoints: latency-svc-djgdp [751.61274ms]
Jan 14 06:12:55.164: INFO: Created: latency-svc-jtwcm
Jan 14 06:12:55.194: INFO: Got endpoints: latency-svc-zd86f [752.741789ms]
Jan 14 06:12:55.213: INFO: Created: latency-svc-qc7g6
Jan 14 06:12:55.243: INFO: Got endpoints: latency-svc-24cnw [750.077697ms]
Jan 14 06:12:55.259: INFO: Created: latency-svc-mhdvj
Jan 14 06:12:55.295: INFO: Got endpoints: latency-svc-w8fvc [755.268632ms]
Jan 14 06:12:55.313: INFO: Created: latency-svc-ddwmt
Jan 14 06:12:55.343: INFO: Got endpoints: latency-svc-5q8qx [752.844749ms]
Jan 14 06:12:55.358: INFO: Created: latency-svc-4zkfz
Jan 14 06:12:55.391: INFO: Got endpoints: latency-svc-jqb5s [749.678773ms]
Jan 14 06:12:55.408: INFO: Created: latency-svc-h5sbx
Jan 14 06:12:55.456: INFO: Got endpoints: latency-svc-9lj7z [765.374242ms]
Jan 14 06:12:55.475: INFO: Created: latency-svc-lsvbc
Jan 14 06:12:55.493: INFO: Got endpoints: latency-svc-ss7j9 [750.415351ms]
Jan 14 06:12:55.511: INFO: Created: latency-svc-hd9s5
Jan 14 06:12:55.560: INFO: Got endpoints: latency-svc-xcsh2 [768.5612ms]
Jan 14 06:12:55.644: INFO: Got endpoints: latency-svc-qmn54 [802.801167ms]
Jan 14 06:12:55.655: INFO: Got endpoints: latency-svc-z84f7 [765.194359ms]
Jan 14 06:12:55.692: INFO: Got endpoints: latency-svc-nkhpv [750.324705ms]
Jan 14 06:12:55.742: INFO: Got endpoints: latency-svc-7lv6k [750.284873ms]
Jan 14 06:12:55.793: INFO: Got endpoints: latency-svc-n9742 [746.90852ms]
Jan 14 06:12:55.842: INFO: Got endpoints: latency-svc-6wvg2 [748.646558ms]
Jan 14 06:12:55.893: INFO: Got endpoints: latency-svc-jtwcm [751.662454ms]
Jan 14 06:12:55.941: INFO: Got endpoints: latency-svc-qc7g6 [747.157292ms]
Jan 14 06:12:55.991: INFO: Got endpoints: latency-svc-mhdvj [747.855991ms]
Jan 14 06:12:56.039: INFO: Got endpoints: latency-svc-ddwmt [743.869361ms]
Jan 14 06:12:56.092: INFO: Got endpoints: latency-svc-4zkfz [749.071845ms]
Jan 14 06:12:56.142: INFO: Got endpoints: latency-svc-h5sbx [750.529485ms]
Jan 14 06:12:56.192: INFO: Got endpoints: latency-svc-lsvbc [735.613841ms]
Jan 14 06:12:56.242: INFO: Got endpoints: latency-svc-hd9s5 [748.481229ms]
Jan 14 06:12:56.242: INFO: Latencies: [33.501103ms 47.45587ms 63.603738ms 81.695863ms 98.962953ms 121.633121ms 135.936857ms 154.726633ms 168.034338ms 190.025555ms 224.355196ms 258.148739ms 260.427502ms 262.057631ms 272.840557ms 273.634499ms 274.116223ms 277.768618ms 278.979015ms 279.252511ms 282.145258ms 287.265164ms 289.419777ms 289.505076ms 293.044028ms 293.543772ms 296.88905ms 297.511381ms 300.222765ms 300.278945ms 301.008339ms 301.227985ms 304.016906ms 304.080357ms 304.34949ms 306.346386ms 306.932632ms 308.916376ms 312.635691ms 314.392037ms 316.780266ms 318.351762ms 324.396898ms 325.901571ms 327.449452ms 332.75785ms 333.295018ms 334.943964ms 344.629396ms 383.618345ms 407.649142ms 413.492394ms 415.423856ms 446.228145ms 475.152596ms 494.931684ms 538.427785ms 567.649153ms 598.416551ms 628.267254ms 657.03675ms 662.889588ms 694.225743ms 695.572419ms 704.604462ms 718.137134ms 730.027675ms 732.302244ms 735.361982ms 735.613841ms 739.019702ms 739.753412ms 740.397163ms 740.602374ms 741.1838ms 741.98511ms 742.290087ms 743.25345ms 743.318084ms 743.378611ms 743.629319ms 743.869361ms 744.439271ms 745.387626ms 745.573179ms 745.594683ms 745.951557ms 746.244027ms 746.264786ms 746.3486ms 746.514268ms 746.632364ms 746.90852ms 746.963693ms 747.005323ms 747.053581ms 747.157292ms 747.198632ms 747.242779ms 747.535386ms 747.572747ms 747.668674ms 747.834394ms 747.855991ms 747.91624ms 747.976661ms 748.045155ms 748.199613ms 748.20594ms 748.231162ms 748.286038ms 748.466556ms 748.481229ms 748.603228ms 748.642546ms 748.646558ms 748.699337ms 748.704297ms 748.869641ms 748.876976ms 749.007071ms 749.071845ms 749.130681ms 749.319947ms 749.342854ms 749.352471ms 749.435967ms 749.459962ms 749.494334ms 749.582232ms 749.678773ms 749.712031ms 749.743072ms 749.788328ms 749.852574ms 749.856423ms 749.976839ms 749.991833ms 750.041335ms 750.077697ms 750.12411ms 750.163952ms 750.209896ms 750.271575ms 750.284873ms 750.324705ms 750.355732ms 750.415351ms 750.529485ms 750.568871ms 750.610364ms 750.617565ms 750.687756ms 750.783666ms 750.844317ms 751.011466ms 751.01421ms 751.078523ms 751.103618ms 751.169199ms 751.216376ms 751.338697ms 751.470504ms 751.502612ms 751.598488ms 751.61274ms 751.625375ms 751.662454ms 751.716385ms 751.717968ms 751.868031ms 752.215471ms 752.331823ms 752.570846ms 752.695919ms 752.715075ms 752.741789ms 752.844749ms 752.87868ms 752.946559ms 753.015307ms 753.234242ms 753.324647ms 753.472501ms 754.575585ms 754.611807ms 755.162199ms 755.208604ms 755.268632ms 756.111261ms 756.362672ms 757.584146ms 765.194359ms 765.374242ms 767.383316ms 768.5612ms 769.520017ms 770.046579ms 802.801167ms 806.500201ms]
Jan 14 06:12:56.242: INFO: 50 %ile: 747.572747ms
Jan 14 06:12:56.242: INFO: 90 %ile: 753.015307ms
Jan 14 06:12:56.242: INFO: 99 %ile: 802.801167ms
Jan 14 06:12:56.242: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:12:56.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-xqkx4" for this suite.
Jan 14 06:13:08.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:13:08.450: INFO: namespace: e2e-tests-svc-latency-xqkx4, resource: bindings, ignored listing per whitelist
Jan 14 06:13:08.458: INFO: namespace e2e-tests-svc-latency-xqkx4 deletion completed in 12.204625878s

• [SLOW TEST:24.024 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:13:08.459: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-767fa591-17c3-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 06:13:08.578: INFO: Waiting up to 5m0s for pod "pod-secrets-76808f99-17c3-11e9-912e-6a405af5e95c" in namespace "e2e-tests-secrets-lzd68" to be "success or failure"
Jan 14 06:13:08.583: INFO: Pod "pod-secrets-76808f99-17c3-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.143494ms
Jan 14 06:13:10.586: INFO: Pod "pod-secrets-76808f99-17c3-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007678283s
STEP: Saw pod success
Jan 14 06:13:10.586: INFO: Pod "pod-secrets-76808f99-17c3-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:13:10.589: INFO: Trying to get logs from node paaswkr2 pod pod-secrets-76808f99-17c3-11e9-912e-6a405af5e95c container secret-volume-test: <nil>
STEP: delete the pod
Jan 14 06:13:10.610: INFO: Waiting for pod pod-secrets-76808f99-17c3-11e9-912e-6a405af5e95c to disappear
Jan 14 06:13:10.614: INFO: Pod pod-secrets-76808f99-17c3-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:13:10.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lzd68" for this suite.
Jan 14 06:13:16.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:13:16.711: INFO: namespace: e2e-tests-secrets-lzd68, resource: bindings, ignored listing per whitelist
Jan 14 06:13:16.727: INFO: namespace e2e-tests-secrets-lzd68 deletion completed in 6.106483085s

• [SLOW TEST:8.269 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:13:16.727: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-7b70496e-17c3-11e9-912e-6a405af5e95c
STEP: Creating configMap with name cm-test-opt-upd-7b70499f-17c3-11e9-912e-6a405af5e95c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-7b70496e-17c3-11e9-912e-6a405af5e95c
STEP: Updating configmap cm-test-opt-upd-7b70499f-17c3-11e9-912e-6a405af5e95c
STEP: Creating configMap with name cm-test-opt-create-7b7049ae-17c3-11e9-912e-6a405af5e95c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:14:49.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5njbh" for this suite.
Jan 14 06:15:11.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:15:11.501: INFO: namespace: e2e-tests-projected-5njbh, resource: bindings, ignored listing per whitelist
Jan 14 06:15:11.609: INFO: namespace e2e-tests-projected-5njbh deletion completed in 22.138052365s

• [SLOW TEST:114.881 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:15:11.609: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-bfe2b65b-17c3-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:15:11.701: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bfe3471d-17c3-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-pnsvg" to be "success or failure"
Jan 14 06:15:11.709: INFO: Pod "pod-projected-configmaps-bfe3471d-17c3-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.915875ms
Jan 14 06:15:13.712: INFO: Pod "pod-projected-configmaps-bfe3471d-17c3-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011025047s
STEP: Saw pod success
Jan 14 06:15:13.712: INFO: Pod "pod-projected-configmaps-bfe3471d-17c3-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:15:13.716: INFO: Trying to get logs from node paaswkr2 pod pod-projected-configmaps-bfe3471d-17c3-11e9-912e-6a405af5e95c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 06:15:13.739: INFO: Waiting for pod pod-projected-configmaps-bfe3471d-17c3-11e9-912e-6a405af5e95c to disappear
Jan 14 06:15:13.743: INFO: Pod pod-projected-configmaps-bfe3471d-17c3-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:15:13.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pnsvg" for this suite.
Jan 14 06:15:19.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:15:19.828: INFO: namespace: e2e-tests-projected-pnsvg, resource: bindings, ignored listing per whitelist
Jan 14 06:15:19.838: INFO: namespace e2e-tests-projected-pnsvg deletion completed in 6.0897029s

• [SLOW TEST:8.230 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:15:19.838: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan 14 06:15:19.911: INFO: Waiting up to 5m0s for pod "client-containers-c4c84c71-17c3-11e9-912e-6a405af5e95c" in namespace "e2e-tests-containers-wxfsj" to be "success or failure"
Jan 14 06:15:19.916: INFO: Pod "client-containers-c4c84c71-17c3-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.651798ms
Jan 14 06:15:21.919: INFO: Pod "client-containers-c4c84c71-17c3-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008025527s
STEP: Saw pod success
Jan 14 06:15:21.919: INFO: Pod "client-containers-c4c84c71-17c3-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:15:21.923: INFO: Trying to get logs from node paaswkr2 pod client-containers-c4c84c71-17c3-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 06:15:21.940: INFO: Waiting for pod client-containers-c4c84c71-17c3-11e9-912e-6a405af5e95c to disappear
Jan 14 06:15:21.944: INFO: Pod client-containers-c4c84c71-17c3-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:15:21.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-wxfsj" for this suite.
Jan 14 06:15:27.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:15:28.001: INFO: namespace: e2e-tests-containers-wxfsj, resource: bindings, ignored listing per whitelist
Jan 14 06:15:28.054: INFO: namespace e2e-tests-containers-wxfsj deletion completed in 6.098950949s

• [SLOW TEST:8.216 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:15:28.054: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 14 06:15:28.132: INFO: Waiting up to 5m0s for pod "pod-c9aedb3d-17c3-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-88lxr" to be "success or failure"
Jan 14 06:15:28.136: INFO: Pod "pod-c9aedb3d-17c3-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.799983ms
Jan 14 06:15:30.139: INFO: Pod "pod-c9aedb3d-17c3-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006958337s
STEP: Saw pod success
Jan 14 06:15:30.139: INFO: Pod "pod-c9aedb3d-17c3-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:15:30.143: INFO: Trying to get logs from node paaswkr2 pod pod-c9aedb3d-17c3-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 06:15:30.163: INFO: Waiting for pod pod-c9aedb3d-17c3-11e9-912e-6a405af5e95c to disappear
Jan 14 06:15:30.168: INFO: Pod pod-c9aedb3d-17c3-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:15:30.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-88lxr" for this suite.
Jan 14 06:15:36.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:15:36.238: INFO: namespace: e2e-tests-emptydir-88lxr, resource: bindings, ignored listing per whitelist
Jan 14 06:15:36.284: INFO: namespace e2e-tests-emptydir-88lxr deletion completed in 6.110520345s

• [SLOW TEST:8.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:15:36.284: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-w7frg
Jan 14 06:15:38.365: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-w7frg
STEP: checking the pod's current state and verifying that restartCount is present
Jan 14 06:15:38.368: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:19:38.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-w7frg" for this suite.
Jan 14 06:19:44.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:19:44.835: INFO: namespace: e2e-tests-container-probe-w7frg, resource: bindings, ignored listing per whitelist
Jan 14 06:19:44.908: INFO: namespace e2e-tests-container-probe-w7frg deletion completed in 6.099068351s

• [SLOW TEST:248.624 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:19:44.908: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan 14 06:19:45.005: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-a,UID:6296cff5-17c4-11e9-b726-525400ada096,ResourceVersion:58382,Generation:0,CreationTimestamp:2019-01-14 06:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 14 06:19:45.005: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-a,UID:6296cff5-17c4-11e9-b726-525400ada096,ResourceVersion:58382,Generation:0,CreationTimestamp:2019-01-14 06:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 14 06:19:55.012: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-a,UID:6296cff5-17c4-11e9-b726-525400ada096,ResourceVersion:58399,Generation:0,CreationTimestamp:2019-01-14 06:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 14 06:19:55.012: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-a,UID:6296cff5-17c4-11e9-b726-525400ada096,ResourceVersion:58399,Generation:0,CreationTimestamp:2019-01-14 06:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 14 06:20:05.020: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-a,UID:6296cff5-17c4-11e9-b726-525400ada096,ResourceVersion:58415,Generation:0,CreationTimestamp:2019-01-14 06:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 14 06:20:05.021: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-a,UID:6296cff5-17c4-11e9-b726-525400ada096,ResourceVersion:58415,Generation:0,CreationTimestamp:2019-01-14 06:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 14 06:20:15.026: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-a,UID:6296cff5-17c4-11e9-b726-525400ada096,ResourceVersion:58431,Generation:0,CreationTimestamp:2019-01-14 06:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 14 06:20:15.026: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-a,UID:6296cff5-17c4-11e9-b726-525400ada096,ResourceVersion:58431,Generation:0,CreationTimestamp:2019-01-14 06:19:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 14 06:20:25.033: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-b,UID:7a7250ef-17c4-11e9-b726-525400ada096,ResourceVersion:58448,Generation:0,CreationTimestamp:2019-01-14 06:20:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 14 06:20:25.033: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-b,UID:7a7250ef-17c4-11e9-b726-525400ada096,ResourceVersion:58448,Generation:0,CreationTimestamp:2019-01-14 06:20:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 14 06:20:35.041: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-b,UID:7a7250ef-17c4-11e9-b726-525400ada096,ResourceVersion:58464,Generation:0,CreationTimestamp:2019-01-14 06:20:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 14 06:20:35.041: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-262cm,SelfLink:/api/v1/namespaces/e2e-tests-watch-262cm/configmaps/e2e-watch-test-configmap-b,UID:7a7250ef-17c4-11e9-b726-525400ada096,ResourceVersion:58464,Generation:0,CreationTimestamp:2019-01-14 06:20:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:20:45.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-262cm" for this suite.
Jan 14 06:20:51.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:20:51.148: INFO: namespace: e2e-tests-watch-262cm, resource: bindings, ignored listing per whitelist
Jan 14 06:20:51.154: INFO: namespace e2e-tests-watch-262cm deletion completed in 6.107940013s

• [SLOW TEST:66.246 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:20:51.154: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 06:20:51.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 version --client'
Jan 14 06:20:51.287: INFO: stderr: ""
Jan 14 06:20:51.287: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan 14 06:20:51.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-5qkr4'
Jan 14 06:20:51.523: INFO: stderr: ""
Jan 14 06:20:51.523: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan 14 06:20:51.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-5qkr4'
Jan 14 06:20:51.718: INFO: stderr: ""
Jan 14 06:20:51.718: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 14 06:20:52.721: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 06:20:52.721: INFO: Found 0 / 1
Jan 14 06:20:53.721: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 06:20:53.721: INFO: Found 1 / 1
Jan 14 06:20:53.721: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 14 06:20:53.724: INFO: Selector matched 1 pods for map[app:redis]
Jan 14 06:20:53.724: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 14 06:20:53.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 describe pod redis-master-82d59 --namespace=e2e-tests-kubectl-5qkr4'
Jan 14 06:20:53.814: INFO: stderr: ""
Jan 14 06:20:53.814: INFO: stdout: "Name:               redis-master-82d59\nNamespace:          e2e-tests-kubectl-5qkr4\nPriority:           0\nPriorityClassName:  <none>\nNode:               paaswkr2/192.168.10.105\nStart Time:         Mon, 14 Jan 2019 06:20:51 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.64.9\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://73ac2c1049eeec74af426eb9d7982c28697d38b852feae88d08af012f1b80185\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 14 Jan 2019 06:20:52 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9btqb (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-9btqb:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-9btqb\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned e2e-tests-kubectl-5qkr4/redis-master-82d59 to paaswkr2\n  Normal  Pulled     1s    kubelet, paaswkr2  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, paaswkr2  Created container\n  Normal  Started    1s    kubelet, paaswkr2  Started container\n"
Jan 14 06:20:53.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 describe rc redis-master --namespace=e2e-tests-kubectl-5qkr4'
Jan 14 06:20:53.908: INFO: stderr: ""
Jan 14 06:20:53.908: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-5qkr4\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-82d59\n"
Jan 14 06:20:53.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 describe service redis-master --namespace=e2e-tests-kubectl-5qkr4'
Jan 14 06:20:53.992: INFO: stderr: ""
Jan 14 06:20:53.992: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-5qkr4\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.107.131.195\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.64.9:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan 14 06:20:53.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 describe node paasmst1'
Jan 14 06:20:54.103: INFO: stderr: ""
Jan 14 06:20:54.103: INFO: stdout: "Name:               paasmst1\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=paasmst1\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 14 Jan 2019 00:42:14 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 14 Jan 2019 00:48:12 +0000   Mon, 14 Jan 2019 00:48:12 +0000   WeaveIsUp                    Weave pod has set this\n  MemoryPressure       False   Mon, 14 Jan 2019 06:20:44 +0000   Mon, 14 Jan 2019 00:42:06 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 14 Jan 2019 06:20:44 +0000   Mon, 14 Jan 2019 00:42:06 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 14 Jan 2019 06:20:44 +0000   Mon, 14 Jan 2019 00:42:06 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 14 Jan 2019 06:20:44 +0000   Mon, 14 Jan 2019 00:42:44 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.10.101\n  Hostname:    paasmst1\nCapacity:\n cpu:                2\n ephemeral-storage:  39269648Ki\n hugepages-2Mi:      0\n memory:             1882688Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  36190907537\n hugepages-2Mi:      0\n memory:             1780288Ki\n pods:               110\nSystem Info:\n Machine ID:                 b755acb54ef1481eb2dbd1979a4412f3\n System UUID:                B755ACB5-4EF1-481E-B2DB-D1979A4412F3\n Boot ID:                    e5f2f3c5-179d-4337-9d99-8dd1a56b1aa3\n Kernel Version:             3.10.0-862.3.2.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.1\n Kube-Proxy Version:         v1.13.1\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                ------------  ----------  ---------------  -------------  ---\n  kube-system                etcd-paasmst1                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h37m\n  kube-system                fluentd-v1.1.0-vvcsc                100m (5%)     0 (0%)      200Mi (11%)      500Mi (28%)    78m\n  kube-system                kube-apiserver-paasmst1             250m (12%)    0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                kube-controller-manager-paasmst1    200m (10%)    0 (0%)      0 (0%)           0 (0%)         5h37m\n  kube-system                kube-proxy-srfkv                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h38m\n  kube-system                kube-scheduler-paasmst1             100m (5%)     0 (0%)      0 (0%)           0 (0%)         5h37m\n  kube-system                weave-net-lxxzh                     20m (1%)      0 (0%)      0 (0%)           0 (0%)         5h38m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                670m (33%)   0 (0%)\n  memory             200Mi (11%)  500Mi (28%)\n  ephemeral-storage  0 (0%)       0 (0%)\nEvents:\n  Type    Reason                   Age                From               Message\n  ----    ------                   ----               ----               -------\n  Normal  Starting                 34m                kubelet, paasmst1  Starting kubelet.\n  Normal  NodeHasSufficientMemory  34m (x8 over 34m)  kubelet, paasmst1  Node paasmst1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    34m (x8 over 34m)  kubelet, paasmst1  Node paasmst1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     34m (x7 over 34m)  kubelet, paasmst1  Node paasmst1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  34m                kubelet, paasmst1  Updated Node Allocatable limit across pods\n"
Jan 14 06:20:54.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 describe namespace e2e-tests-kubectl-5qkr4'
Jan 14 06:20:54.192: INFO: stderr: ""
Jan 14 06:20:54.192: INFO: stdout: "Name:         e2e-tests-kubectl-5qkr4\nLabels:       e2e-framework=kubectl\n              e2e-run=102c12cd-17c0-11e9-912e-6a405af5e95c\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:20:54.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5qkr4" for this suite.
Jan 14 06:21:16.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:21:16.286: INFO: namespace: e2e-tests-kubectl-5qkr4, resource: bindings, ignored listing per whitelist
Jan 14 06:21:16.319: INFO: namespace e2e-tests-kubectl-5qkr4 deletion completed in 22.123599183s

• [SLOW TEST:25.165 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:21:16.319: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jan 14 06:21:23.481: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:21:23.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-dwr8s" for this suite.
Jan 14 06:21:45.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:21:45.568: INFO: namespace: e2e-tests-replicaset-dwr8s, resource: bindings, ignored listing per whitelist
Jan 14 06:21:45.640: INFO: namespace e2e-tests-replicaset-dwr8s deletion completed in 22.115773378s

• [SLOW TEST:29.321 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:21:45.641: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-aac15900-17c4-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:21:45.747: INFO: Waiting up to 5m0s for pod "pod-configmaps-aac246ea-17c4-11e9-912e-6a405af5e95c" in namespace "e2e-tests-configmap-c7j47" to be "success or failure"
Jan 14 06:21:45.755: INFO: Pod "pod-configmaps-aac246ea-17c4-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.079303ms
Jan 14 06:21:47.758: INFO: Pod "pod-configmaps-aac246ea-17c4-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01087074s
STEP: Saw pod success
Jan 14 06:21:47.758: INFO: Pod "pod-configmaps-aac246ea-17c4-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:21:47.763: INFO: Trying to get logs from node paaswkr2 pod pod-configmaps-aac246ea-17c4-11e9-912e-6a405af5e95c container configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 06:21:47.805: INFO: Waiting for pod pod-configmaps-aac246ea-17c4-11e9-912e-6a405af5e95c to disappear
Jan 14 06:21:47.828: INFO: Pod pod-configmaps-aac246ea-17c4-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:21:47.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-c7j47" for this suite.
Jan 14 06:21:53.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:21:53.910: INFO: namespace: e2e-tests-configmap-c7j47, resource: bindings, ignored listing per whitelist
Jan 14 06:21:53.992: INFO: namespace e2e-tests-configmap-c7j47 deletion completed in 6.138152985s

• [SLOW TEST:8.352 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:21:53.992: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan 14 06:21:54.083: INFO: Waiting up to 5m0s for pod "var-expansion-afb9bc5a-17c4-11e9-912e-6a405af5e95c" in namespace "e2e-tests-var-expansion-7s7gn" to be "success or failure"
Jan 14 06:21:54.093: INFO: Pod "var-expansion-afb9bc5a-17c4-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.278288ms
Jan 14 06:21:56.100: INFO: Pod "var-expansion-afb9bc5a-17c4-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016408399s
STEP: Saw pod success
Jan 14 06:21:56.100: INFO: Pod "var-expansion-afb9bc5a-17c4-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:21:56.108: INFO: Trying to get logs from node paaswkr2 pod var-expansion-afb9bc5a-17c4-11e9-912e-6a405af5e95c container dapi-container: <nil>
STEP: delete the pod
Jan 14 06:21:56.132: INFO: Waiting for pod var-expansion-afb9bc5a-17c4-11e9-912e-6a405af5e95c to disappear
Jan 14 06:21:56.142: INFO: Pod var-expansion-afb9bc5a-17c4-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:21:56.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-7s7gn" for this suite.
Jan 14 06:22:02.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:22:02.248: INFO: namespace: e2e-tests-var-expansion-7s7gn, resource: bindings, ignored listing per whitelist
Jan 14 06:22:02.278: INFO: namespace e2e-tests-var-expansion-7s7gn deletion completed in 6.128128026s

• [SLOW TEST:8.286 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:22:02.278: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0114 06:22:08.441691      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 14 06:22:08.441: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:22:08.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bjgdc" for this suite.
Jan 14 06:24:08.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:24:08.639: INFO: namespace: e2e-tests-gc-bjgdc, resource: bindings, ignored listing per whitelist
Jan 14 06:24:08.686: INFO: namespace e2e-tests-gc-bjgdc deletion completed in 2m0.236569838s

• [SLOW TEST:126.408 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:24:08.687: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 14 06:24:12.873: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 14 06:24:12.879: INFO: Pod pod-with-poststart-http-hook still exists
Jan 14 06:24:14.880: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 14 06:24:14.884: INFO: Pod pod-with-poststart-http-hook still exists
Jan 14 06:24:16.880: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 14 06:24:16.884: INFO: Pod pod-with-poststart-http-hook still exists
Jan 14 06:24:18.880: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 14 06:24:18.884: INFO: Pod pod-with-poststart-http-hook still exists
Jan 14 06:24:20.880: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 14 06:24:20.883: INFO: Pod pod-with-poststart-http-hook still exists
Jan 14 06:24:22.880: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 14 06:24:22.883: INFO: Pod pod-with-poststart-http-hook still exists
Jan 14 06:24:24.880: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 14 06:24:24.891: INFO: Pod pod-with-poststart-http-hook still exists
Jan 14 06:24:26.880: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 14 06:24:26.883: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:24:26.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-vrdp7" for this suite.
Jan 14 06:24:48.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:24:49.016: INFO: namespace: e2e-tests-container-lifecycle-hook-vrdp7, resource: bindings, ignored listing per whitelist
Jan 14 06:24:49.022: INFO: namespace e2e-tests-container-lifecycle-hook-vrdp7 deletion completed in 22.13414276s

• [SLOW TEST:40.336 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:24:49.022: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-180d784d-17c5-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:24:49.122: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-180e412b-17c5-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-ljxrq" to be "success or failure"
Jan 14 06:24:49.131: INFO: Pod "pod-projected-configmaps-180e412b-17c5-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.890712ms
Jan 14 06:24:51.134: INFO: Pod "pod-projected-configmaps-180e412b-17c5-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01257052s
STEP: Saw pod success
Jan 14 06:24:51.134: INFO: Pod "pod-projected-configmaps-180e412b-17c5-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:24:51.139: INFO: Trying to get logs from node paaswkr2 pod pod-projected-configmaps-180e412b-17c5-11e9-912e-6a405af5e95c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 06:24:51.172: INFO: Waiting for pod pod-projected-configmaps-180e412b-17c5-11e9-912e-6a405af5e95c to disappear
Jan 14 06:24:51.176: INFO: Pod pod-projected-configmaps-180e412b-17c5-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:24:51.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ljxrq" for this suite.
Jan 14 06:24:57.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:24:57.357: INFO: namespace: e2e-tests-projected-ljxrq, resource: bindings, ignored listing per whitelist
Jan 14 06:24:57.372: INFO: namespace e2e-tests-projected-ljxrq deletion completed in 6.182907509s

• [SLOW TEST:8.349 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:24:57.372: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0114 06:25:07.507511      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 14 06:25:07.507: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:25:07.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-h88pp" for this suite.
Jan 14 06:25:13.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:25:13.633: INFO: namespace: e2e-tests-gc-h88pp, resource: bindings, ignored listing per whitelist
Jan 14 06:25:13.633: INFO: namespace e2e-tests-gc-h88pp deletion completed in 6.116996014s

• [SLOW TEST:16.261 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:25:13.633: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-gcmvd/configmap-test-26b8b045-17c5-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:25:13.731: INFO: Waiting up to 5m0s for pod "pod-configmaps-26b9b1ae-17c5-11e9-912e-6a405af5e95c" in namespace "e2e-tests-configmap-gcmvd" to be "success or failure"
Jan 14 06:25:13.743: INFO: Pod "pod-configmaps-26b9b1ae-17c5-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.619012ms
Jan 14 06:25:15.747: INFO: Pod "pod-configmaps-26b9b1ae-17c5-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0159928s
STEP: Saw pod success
Jan 14 06:25:15.747: INFO: Pod "pod-configmaps-26b9b1ae-17c5-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:25:15.750: INFO: Trying to get logs from node paaswkr2 pod pod-configmaps-26b9b1ae-17c5-11e9-912e-6a405af5e95c container env-test: <nil>
STEP: delete the pod
Jan 14 06:25:15.776: INFO: Waiting for pod pod-configmaps-26b9b1ae-17c5-11e9-912e-6a405af5e95c to disappear
Jan 14 06:25:15.779: INFO: Pod pod-configmaps-26b9b1ae-17c5-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:25:15.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gcmvd" for this suite.
Jan 14 06:25:21.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:25:21.895: INFO: namespace: e2e-tests-configmap-gcmvd, resource: bindings, ignored listing per whitelist
Jan 14 06:25:21.899: INFO: namespace e2e-tests-configmap-gcmvd deletion completed in 6.113585209s

• [SLOW TEST:8.266 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:25:21.899: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2ba502ab-17c5-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 06:25:22.019: INFO: Waiting up to 5m0s for pod "pod-secrets-2baad48c-17c5-11e9-912e-6a405af5e95c" in namespace "e2e-tests-secrets-9zwxt" to be "success or failure"
Jan 14 06:25:22.030: INFO: Pod "pod-secrets-2baad48c-17c5-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.376322ms
Jan 14 06:25:24.033: INFO: Pod "pod-secrets-2baad48c-17c5-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013947964s
STEP: Saw pod success
Jan 14 06:25:24.033: INFO: Pod "pod-secrets-2baad48c-17c5-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:25:24.038: INFO: Trying to get logs from node paaswkr2 pod pod-secrets-2baad48c-17c5-11e9-912e-6a405af5e95c container secret-volume-test: <nil>
STEP: delete the pod
Jan 14 06:25:24.062: INFO: Waiting for pod pod-secrets-2baad48c-17c5-11e9-912e-6a405af5e95c to disappear
Jan 14 06:25:24.071: INFO: Pod pod-secrets-2baad48c-17c5-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:25:24.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9zwxt" for this suite.
Jan 14 06:25:30.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:25:30.178: INFO: namespace: e2e-tests-secrets-9zwxt, resource: bindings, ignored listing per whitelist
Jan 14 06:25:30.199: INFO: namespace e2e-tests-secrets-9zwxt deletion completed in 6.121435305s
STEP: Destroying namespace "e2e-tests-secret-namespace-2pvt9" for this suite.
Jan 14 06:25:36.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:25:36.293: INFO: namespace: e2e-tests-secret-namespace-2pvt9, resource: bindings, ignored listing per whitelist
Jan 14 06:25:36.306: INFO: namespace e2e-tests-secret-namespace-2pvt9 deletion completed in 6.106300219s

• [SLOW TEST:14.407 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:25:36.306: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:25:43.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-7x75n" for this suite.
Jan 14 06:26:05.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:26:05.540: INFO: namespace: e2e-tests-replication-controller-7x75n, resource: bindings, ignored listing per whitelist
Jan 14 06:26:05.598: INFO: namespace e2e-tests-replication-controller-7x75n deletion completed in 22.119679215s

• [SLOW TEST:29.292 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:26:05.598: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 14 06:26:05.673: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:26:09.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-m96ck" for this suite.
Jan 14 06:26:31.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:26:31.086: INFO: namespace: e2e-tests-init-container-m96ck, resource: bindings, ignored listing per whitelist
Jan 14 06:26:31.215: INFO: namespace e2e-tests-init-container-m96ck deletion completed in 22.161281082s

• [SLOW TEST:25.617 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:26:31.215: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-54f7a26a-17c5-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:26:31.317: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-54f834c2-17c5-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-c8mcq" to be "success or failure"
Jan 14 06:26:31.320: INFO: Pod "pod-projected-configmaps-54f834c2-17c5-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.785358ms
Jan 14 06:26:33.323: INFO: Pod "pod-projected-configmaps-54f834c2-17c5-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00659683s
STEP: Saw pod success
Jan 14 06:26:33.323: INFO: Pod "pod-projected-configmaps-54f834c2-17c5-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:26:33.327: INFO: Trying to get logs from node paaswkr2 pod pod-projected-configmaps-54f834c2-17c5-11e9-912e-6a405af5e95c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 06:26:33.348: INFO: Waiting for pod pod-projected-configmaps-54f834c2-17c5-11e9-912e-6a405af5e95c to disappear
Jan 14 06:26:33.354: INFO: Pod pod-projected-configmaps-54f834c2-17c5-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:26:33.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c8mcq" for this suite.
Jan 14 06:26:39.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:26:39.390: INFO: namespace: e2e-tests-projected-c8mcq, resource: bindings, ignored listing per whitelist
Jan 14 06:26:39.460: INFO: namespace e2e-tests-projected-c8mcq deletion completed in 6.09943157s

• [SLOW TEST:8.245 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:26:39.460: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-qk9n4 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-qk9n4;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-qk9n4 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-qk9n4;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-qk9n4.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-qk9n4.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-qk9n4.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-qk9n4.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qk9n4.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 71.228.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.228.71_udp@PTR;check="$$(dig +tcp +noall +answer +search 71.228.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.228.71_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-qk9n4 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-qk9n4;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-qk9n4 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-qk9n4;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-qk9n4.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-qk9n4.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-qk9n4.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-qk9n4.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-qk9n4.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 71.228.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.228.71_udp@PTR;check="$$(dig +tcp +noall +answer +search 71.228.98.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.98.228.71_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 14 06:26:43.662: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.666: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.669: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-qk9n4 from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.673: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-qk9n4 from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.681: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.686: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.692: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.696: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.701: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.705: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.711: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.718: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.722: INFO: Unable to read 10.98.228.71_udp@PTR from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.727: INFO: Unable to read 10.98.228.71_tcp@PTR from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.734: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.738: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.744: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-qk9n4 from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.750: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-qk9n4 from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.755: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.761: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.770: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.775: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.780: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.787: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.793: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.801: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.810: INFO: Unable to read 10.98.228.71_udp@PTR from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.814: INFO: Unable to read 10.98.228.71_tcp@PTR from pod e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c)
Jan 14 06:26:43.814: INFO: Lookups using e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-qk9n4 wheezy_tcp@dns-test-service.e2e-tests-dns-qk9n4 wheezy_udp@dns-test-service.e2e-tests-dns-qk9n4.svc wheezy_tcp@dns-test-service.e2e-tests-dns-qk9n4.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord 10.98.228.71_udp@PTR 10.98.228.71_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-qk9n4 jessie_tcp@dns-test-service.e2e-tests-dns-qk9n4 jessie_udp@dns-test-service.e2e-tests-dns-qk9n4.svc jessie_tcp@dns-test-service.e2e-tests-dns-qk9n4.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-qk9n4.svc jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-qk9n4.svc jessie_udp@PodARecord jessie_tcp@PodARecord 10.98.228.71_udp@PTR 10.98.228.71_tcp@PTR]

Jan 14 06:26:48.906: INFO: DNS probes using e2e-tests-dns-qk9n4/dns-test-59e8075a-17c5-11e9-912e-6a405af5e95c succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:26:49.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-qk9n4" for this suite.
Jan 14 06:26:55.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:26:55.139: INFO: namespace: e2e-tests-dns-qk9n4, resource: bindings, ignored listing per whitelist
Jan 14 06:26:55.189: INFO: namespace e2e-tests-dns-qk9n4 deletion completed in 6.176800008s

• [SLOW TEST:15.729 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:26:55.189: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:26:57.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-6z6f5" for this suite.
Jan 14 06:27:35.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:27:35.338: INFO: namespace: e2e-tests-kubelet-test-6z6f5, resource: bindings, ignored listing per whitelist
Jan 14 06:27:35.415: INFO: namespace e2e-tests-kubelet-test-6z6f5 deletion completed in 38.117105204s

• [SLOW TEST:40.226 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:27:35.415: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-8dnhf/configmap-test-7b3b5a06-17c5-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:27:35.509: INFO: Waiting up to 5m0s for pod "pod-configmaps-7b3be26a-17c5-11e9-912e-6a405af5e95c" in namespace "e2e-tests-configmap-8dnhf" to be "success or failure"
Jan 14 06:27:35.516: INFO: Pod "pod-configmaps-7b3be26a-17c5-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.466392ms
Jan 14 06:27:37.519: INFO: Pod "pod-configmaps-7b3be26a-17c5-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009790549s
STEP: Saw pod success
Jan 14 06:27:37.519: INFO: Pod "pod-configmaps-7b3be26a-17c5-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:27:37.522: INFO: Trying to get logs from node paaswkr2 pod pod-configmaps-7b3be26a-17c5-11e9-912e-6a405af5e95c container env-test: <nil>
STEP: delete the pod
Jan 14 06:27:37.540: INFO: Waiting for pod pod-configmaps-7b3be26a-17c5-11e9-912e-6a405af5e95c to disappear
Jan 14 06:27:37.548: INFO: Pod pod-configmaps-7b3be26a-17c5-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:27:37.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8dnhf" for this suite.
Jan 14 06:27:43.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:27:43.634: INFO: namespace: e2e-tests-configmap-8dnhf, resource: bindings, ignored listing per whitelist
Jan 14 06:27:43.647: INFO: namespace e2e-tests-configmap-8dnhf deletion completed in 6.091773326s

• [SLOW TEST:8.232 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:27:43.647: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:27:43.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-phtsb" for this suite.
Jan 14 06:27:49.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:27:49.786: INFO: namespace: e2e-tests-services-phtsb, resource: bindings, ignored listing per whitelist
Jan 14 06:27:49.813: INFO: namespace e2e-tests-services-phtsb deletion completed in 6.090408189s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.166 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:27:49.813: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-83cf1f2f-17c5-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 06:27:49.899: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-83cfb146-17c5-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-pvwr2" to be "success or failure"
Jan 14 06:27:49.905: INFO: Pod "pod-projected-secrets-83cfb146-17c5-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.354652ms
Jan 14 06:27:51.907: INFO: Pod "pod-projected-secrets-83cfb146-17c5-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007860273s
STEP: Saw pod success
Jan 14 06:27:51.907: INFO: Pod "pod-projected-secrets-83cfb146-17c5-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:27:51.911: INFO: Trying to get logs from node paaswkr2 pod pod-projected-secrets-83cfb146-17c5-11e9-912e-6a405af5e95c container secret-volume-test: <nil>
STEP: delete the pod
Jan 14 06:27:51.931: INFO: Waiting for pod pod-projected-secrets-83cfb146-17c5-11e9-912e-6a405af5e95c to disappear
Jan 14 06:27:51.941: INFO: Pod pod-projected-secrets-83cfb146-17c5-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:27:51.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pvwr2" for this suite.
Jan 14 06:27:57.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:27:58.033: INFO: namespace: e2e-tests-projected-pvwr2, resource: bindings, ignored listing per whitelist
Jan 14 06:27:58.046: INFO: namespace e2e-tests-projected-pvwr2 deletion completed in 6.10016151s

• [SLOW TEST:8.233 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:27:58.046: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan 14 06:27:58.111: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-949281363 proxy --unix-socket=/tmp/kubectl-proxy-unix660356502/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:27:58.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5x7wk" for this suite.
Jan 14 06:28:04.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:28:04.312: INFO: namespace: e2e-tests-kubectl-5x7wk, resource: bindings, ignored listing per whitelist
Jan 14 06:28:04.367: INFO: namespace e2e-tests-kubectl-5x7wk deletion completed in 6.131296668s

• [SLOW TEST:6.321 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:28:04.367: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 14 06:28:04.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:04.690: INFO: stderr: ""
Jan 14 06:28:04.690: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 14 06:28:04.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:04.827: INFO: stderr: ""
Jan 14 06:28:04.827: INFO: stdout: "update-demo-nautilus-6xmzs update-demo-nautilus-9cd6q "
Jan 14 06:28:04.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-6xmzs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:04.940: INFO: stderr: ""
Jan 14 06:28:04.940: INFO: stdout: ""
Jan 14 06:28:04.940: INFO: update-demo-nautilus-6xmzs is created but not running
Jan 14 06:28:09.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:10.018: INFO: stderr: ""
Jan 14 06:28:10.018: INFO: stdout: "update-demo-nautilus-6xmzs update-demo-nautilus-9cd6q "
Jan 14 06:28:10.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-6xmzs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:10.093: INFO: stderr: ""
Jan 14 06:28:10.093: INFO: stdout: "true"
Jan 14 06:28:10.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-6xmzs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:10.190: INFO: stderr: ""
Jan 14 06:28:10.190: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 14 06:28:10.190: INFO: validating pod update-demo-nautilus-6xmzs
Jan 14 06:28:10.196: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 14 06:28:10.196: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 14 06:28:10.196: INFO: update-demo-nautilus-6xmzs is verified up and running
Jan 14 06:28:10.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-9cd6q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:10.293: INFO: stderr: ""
Jan 14 06:28:10.293: INFO: stdout: "true"
Jan 14 06:28:10.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-9cd6q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:10.425: INFO: stderr: ""
Jan 14 06:28:10.425: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 14 06:28:10.425: INFO: validating pod update-demo-nautilus-9cd6q
Jan 14 06:28:13.446: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 14 06:28:13.446: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 14 06:28:13.446: INFO: update-demo-nautilus-9cd6q is verified up and running
STEP: scaling down the replication controller
Jan 14 06:28:13.447: INFO: scanned /root for discovery docs: <nil>
Jan 14 06:28:13.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:14.624: INFO: stderr: ""
Jan 14 06:28:14.624: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 14 06:28:14.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:14.703: INFO: stderr: ""
Jan 14 06:28:14.703: INFO: stdout: "update-demo-nautilus-6xmzs update-demo-nautilus-9cd6q "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 14 06:28:19.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:19.797: INFO: stderr: ""
Jan 14 06:28:19.797: INFO: stdout: "update-demo-nautilus-6xmzs "
Jan 14 06:28:19.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-6xmzs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:19.880: INFO: stderr: ""
Jan 14 06:28:19.880: INFO: stdout: "true"
Jan 14 06:28:19.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-6xmzs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:19.977: INFO: stderr: ""
Jan 14 06:28:19.977: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 14 06:28:19.977: INFO: validating pod update-demo-nautilus-6xmzs
Jan 14 06:28:19.983: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 14 06:28:19.983: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 14 06:28:19.983: INFO: update-demo-nautilus-6xmzs is verified up and running
STEP: scaling up the replication controller
Jan 14 06:28:19.984: INFO: scanned /root for discovery docs: <nil>
Jan 14 06:28:19.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:21.113: INFO: stderr: ""
Jan 14 06:28:21.113: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 14 06:28:21.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:21.201: INFO: stderr: ""
Jan 14 06:28:21.201: INFO: stdout: "update-demo-nautilus-69v2z update-demo-nautilus-6xmzs "
Jan 14 06:28:21.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-69v2z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:21.281: INFO: stderr: ""
Jan 14 06:28:21.281: INFO: stdout: ""
Jan 14 06:28:21.281: INFO: update-demo-nautilus-69v2z is created but not running
Jan 14 06:28:26.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:26.358: INFO: stderr: ""
Jan 14 06:28:26.358: INFO: stdout: "update-demo-nautilus-69v2z update-demo-nautilus-6xmzs "
Jan 14 06:28:26.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-69v2z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:26.439: INFO: stderr: ""
Jan 14 06:28:26.439: INFO: stdout: "true"
Jan 14 06:28:26.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-69v2z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:28:26.514: INFO: stderr: ""
Jan 14 06:28:26.514: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 14 06:28:26.514: INFO: validating pod update-demo-nautilus-69v2z
Jan 14 06:28:56.518: INFO: update-demo-nautilus-69v2z is running right image but validator function failed: the server is currently unable to handle the request (get pods update-demo-nautilus-69v2z)
Jan 14 06:29:01.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:29:01.596: INFO: stderr: ""
Jan 14 06:29:01.596: INFO: stdout: "update-demo-nautilus-69v2z update-demo-nautilus-6xmzs "
Jan 14 06:29:01.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-69v2z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:29:01.674: INFO: stderr: ""
Jan 14 06:29:01.674: INFO: stdout: "true"
Jan 14 06:29:01.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-69v2z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:29:01.754: INFO: stderr: ""
Jan 14 06:29:01.754: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 14 06:29:01.754: INFO: validating pod update-demo-nautilus-69v2z
Jan 14 06:29:04.785: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 14 06:29:04.785: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 14 06:29:04.785: INFO: update-demo-nautilus-69v2z is verified up and running
Jan 14 06:29:04.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-6xmzs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:29:04.880: INFO: stderr: ""
Jan 14 06:29:04.880: INFO: stdout: "true"
Jan 14 06:29:04.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods update-demo-nautilus-6xmzs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:29:05.043: INFO: stderr: ""
Jan 14 06:29:05.043: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 14 06:29:05.043: INFO: validating pod update-demo-nautilus-6xmzs
Jan 14 06:29:05.052: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 14 06:29:05.052: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 14 06:29:05.052: INFO: update-demo-nautilus-6xmzs is verified up and running
STEP: using delete to clean up resources
Jan 14 06:29:05.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:29:05.266: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 14 06:29:05.266: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 14 06:29:05.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-jtmnr'
Jan 14 06:29:05.681: INFO: stderr: "No resources found.\n"
Jan 14 06:29:05.681: INFO: stdout: ""
Jan 14 06:29:05.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 get pods -l name=update-demo --namespace=e2e-tests-kubectl-jtmnr -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 14 06:29:05.982: INFO: stderr: ""
Jan 14 06:29:05.982: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:29:05.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jtmnr" for this suite.
Jan 14 06:29:28.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:29:28.098: INFO: namespace: e2e-tests-kubectl-jtmnr, resource: bindings, ignored listing per whitelist
Jan 14 06:29:28.113: INFO: namespace e2e-tests-kubectl-jtmnr deletion completed in 22.119941168s

• [SLOW TEST:83.745 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:29:28.113: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan 14 06:29:28.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 api-versions'
Jan 14 06:29:28.379: INFO: stderr: ""
Jan 14 06:29:28.379: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:29:28.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6qpj6" for this suite.
Jan 14 06:29:34.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:29:34.458: INFO: namespace: e2e-tests-kubectl-6qpj6, resource: bindings, ignored listing per whitelist
Jan 14 06:29:34.488: INFO: namespace e2e-tests-kubectl-6qpj6 deletion completed in 6.102381792s

• [SLOW TEST:6.375 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:29:34.488: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan 14 06:29:35.144: INFO: created pod pod-service-account-defaultsa
Jan 14 06:29:35.144: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 14 06:29:35.151: INFO: created pod pod-service-account-mountsa
Jan 14 06:29:35.151: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 14 06:29:35.167: INFO: created pod pod-service-account-nomountsa
Jan 14 06:29:35.167: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 14 06:29:35.179: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 14 06:29:35.179: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 14 06:29:35.193: INFO: created pod pod-service-account-mountsa-mountspec
Jan 14 06:29:35.193: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 14 06:29:35.210: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 14 06:29:35.210: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 14 06:29:35.233: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 14 06:29:35.233: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 14 06:29:35.257: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 14 06:29:35.257: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 14 06:29:35.272: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 14 06:29:35.272: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:29:35.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-4297b" for this suite.
Jan 14 06:30:55.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:30:55.364: INFO: namespace: e2e-tests-svcaccounts-4297b, resource: bindings, ignored listing per whitelist
Jan 14 06:30:55.417: INFO: namespace e2e-tests-svcaccounts-4297b deletion completed in 1m20.128107833s

• [SLOW TEST:80.929 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:30:55.417: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-f2729d44-17c5-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:30:55.522: INFO: Waiting up to 5m0s for pod "pod-configmaps-f2733c89-17c5-11e9-912e-6a405af5e95c" in namespace "e2e-tests-configmap-4f2pr" to be "success or failure"
Jan 14 06:30:55.526: INFO: Pod "pod-configmaps-f2733c89-17c5-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.95786ms
Jan 14 06:30:57.528: INFO: Pod "pod-configmaps-f2733c89-17c5-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006784198s
STEP: Saw pod success
Jan 14 06:30:57.528: INFO: Pod "pod-configmaps-f2733c89-17c5-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:30:57.532: INFO: Trying to get logs from node paaswkr2 pod pod-configmaps-f2733c89-17c5-11e9-912e-6a405af5e95c container configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 06:30:57.550: INFO: Waiting for pod pod-configmaps-f2733c89-17c5-11e9-912e-6a405af5e95c to disappear
Jan 14 06:30:57.561: INFO: Pod pod-configmaps-f2733c89-17c5-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:30:57.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4f2pr" for this suite.
Jan 14 06:31:03.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:31:03.607: INFO: namespace: e2e-tests-configmap-4f2pr, resource: bindings, ignored listing per whitelist
Jan 14 06:31:03.675: INFO: namespace e2e-tests-configmap-4f2pr deletion completed in 6.106254811s

• [SLOW TEST:8.258 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:31:03.675: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan 14 06:31:03.742: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan 14 06:31:03.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:03.994: INFO: stderr: ""
Jan 14 06:31:03.994: INFO: stdout: "service/redis-slave created\n"
Jan 14 06:31:03.994: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan 14 06:31:03.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:04.226: INFO: stderr: ""
Jan 14 06:31:04.226: INFO: stdout: "service/redis-master created\n"
Jan 14 06:31:04.226: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 14 06:31:04.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:04.435: INFO: stderr: ""
Jan 14 06:31:04.435: INFO: stdout: "service/frontend created\n"
Jan 14 06:31:04.445: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan 14 06:31:04.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:04.673: INFO: stderr: ""
Jan 14 06:31:04.673: INFO: stdout: "deployment.extensions/frontend created\n"
Jan 14 06:31:04.673: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 14 06:31:04.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:04.912: INFO: stderr: ""
Jan 14 06:31:04.912: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan 14 06:31:04.912: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan 14 06:31:04.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 create -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:05.110: INFO: stderr: ""
Jan 14 06:31:05.110: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan 14 06:31:05.110: INFO: Waiting for all frontend pods to be Running.
Jan 14 06:31:10.161: INFO: Waiting for frontend to serve content.
Jan 14 06:31:13.402: INFO: Trying to add a new entry to the guestbook.
Jan 14 06:31:13.448: INFO: Verifying that added entry can be retrieved.
Jan 14 06:31:13.504: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Jan 14 06:31:18.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:18.677: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 14 06:31:18.677: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan 14 06:31:18.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:18.916: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 14 06:31:18.916: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 14 06:31:18.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:19.024: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 14 06:31:19.024: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 14 06:31:19.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:19.138: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 14 06:31:19.138: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 14 06:31:19.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:19.312: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 14 06:31:19.312: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 14 06:31:19.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zkhsf'
Jan 14 06:31:19.541: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 14 06:31:19.541: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:31:19.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zkhsf" for this suite.
Jan 14 06:31:57.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:31:57.743: INFO: namespace: e2e-tests-kubectl-zkhsf, resource: bindings, ignored listing per whitelist
Jan 14 06:31:57.751: INFO: namespace e2e-tests-kubectl-zkhsf deletion completed in 38.189617006s

• [SLOW TEST:54.075 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:31:57.751: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 06:31:57.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 version'
Jan 14 06:31:57.900: INFO: stderr: ""
Jan 14 06:31:57.900: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.1\", GitCommit:\"eec55b9ba98609a46fee712359c7b5b365bdd920\", GitTreeState:\"clean\", BuildDate:\"2018-12-13T10:31:33Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:31:57.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5s7ph" for this suite.
Jan 14 06:32:03.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:32:03.974: INFO: namespace: e2e-tests-kubectl-5s7ph, resource: bindings, ignored listing per whitelist
Jan 14 06:32:03.997: INFO: namespace e2e-tests-kubectl-5s7ph deletion completed in 6.090456597s

• [SLOW TEST:6.246 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:32:03.997: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan 14 06:32:04.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 cluster-info'
Jan 14 06:32:04.170: INFO: stderr: ""
Jan 14 06:32:04.170: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mdefault-http-backend\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/default-http-backend/proxy\x1b[0m\n\x1b[0;32mgraylog\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/graylog:web/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\x1b[0;32mmongodb\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/mongodb/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:32:04.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q9td7" for this suite.
Jan 14 06:32:10.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:32:10.237: INFO: namespace: e2e-tests-kubectl-q9td7, resource: bindings, ignored listing per whitelist
Jan 14 06:32:10.265: INFO: namespace e2e-tests-kubectl-q9td7 deletion completed in 6.090803019s

• [SLOW TEST:6.269 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:32:10.266: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 06:32:10.554: INFO: (0) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 158.820548ms)
Jan 14 06:32:10.573: INFO: (1) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 18.903987ms)
Jan 14 06:32:10.583: INFO: (2) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.807536ms)
Jan 14 06:32:10.594: INFO: (3) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.919619ms)
Jan 14 06:32:10.601: INFO: (4) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.354448ms)
Jan 14 06:32:10.622: INFO: (5) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 20.771674ms)
Jan 14 06:32:10.638: INFO: (6) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 15.387734ms)
Jan 14 06:32:10.654: INFO: (7) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 16.38883ms)
Jan 14 06:32:10.677: INFO: (8) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 22.972856ms)
Jan 14 06:32:10.717: INFO: (9) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 39.255127ms)
Jan 14 06:32:10.723: INFO: (10) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.46884ms)
Jan 14 06:32:10.730: INFO: (11) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.932215ms)
Jan 14 06:32:10.736: INFO: (12) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.059977ms)
Jan 14 06:32:10.742: INFO: (13) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.812276ms)
Jan 14 06:32:10.750: INFO: (14) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.712572ms)
Jan 14 06:32:10.757: INFO: (15) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.746672ms)
Jan 14 06:32:10.766: INFO: (16) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.972397ms)
Jan 14 06:32:10.773: INFO: (17) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.297664ms)
Jan 14 06:32:10.782: INFO: (18) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.910914ms)
Jan 14 06:32:10.790: INFO: (19) /api/v1/nodes/paassys1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.924472ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:32:10.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-jcbtw" for this suite.
Jan 14 06:32:16.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:32:16.848: INFO: namespace: e2e-tests-proxy-jcbtw, resource: bindings, ignored listing per whitelist
Jan 14 06:32:16.952: INFO: namespace e2e-tests-proxy-jcbtw deletion completed in 6.148144245s

• [SLOW TEST:6.686 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:32:16.952: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0114 06:32:57.100516      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 14 06:32:57.100: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:32:57.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7jzl2" for this suite.
Jan 14 06:33:03.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:33:03.172: INFO: namespace: e2e-tests-gc-7jzl2, resource: bindings, ignored listing per whitelist
Jan 14 06:33:03.298: INFO: namespace e2e-tests-gc-7jzl2 deletion completed in 6.192682517s

• [SLOW TEST:46.347 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:33:03.299: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan 14 06:33:03.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 --namespace=e2e-tests-kubectl-dts8x run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan 14 06:33:06.052: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan 14 06:33:06.052: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:33:08.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dts8x" for this suite.
Jan 14 06:33:18.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:33:18.202: INFO: namespace: e2e-tests-kubectl-dts8x, resource: bindings, ignored listing per whitelist
Jan 14 06:33:18.235: INFO: namespace e2e-tests-kubectl-dts8x deletion completed in 10.13539789s

• [SLOW TEST:14.936 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:33:18.235: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 14 06:33:18.349: INFO: Waiting up to 5m0s for pod "downward-api-4794ea4d-17c6-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-54zln" to be "success or failure"
Jan 14 06:33:18.356: INFO: Pod "downward-api-4794ea4d-17c6-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.976476ms
Jan 14 06:33:20.360: INFO: Pod "downward-api-4794ea4d-17c6-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011680501s
STEP: Saw pod success
Jan 14 06:33:20.360: INFO: Pod "downward-api-4794ea4d-17c6-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:33:20.367: INFO: Trying to get logs from node paaswkr2 pod downward-api-4794ea4d-17c6-11e9-912e-6a405af5e95c container dapi-container: <nil>
STEP: delete the pod
Jan 14 06:33:20.413: INFO: Waiting for pod downward-api-4794ea4d-17c6-11e9-912e-6a405af5e95c to disappear
Jan 14 06:33:20.425: INFO: Pod downward-api-4794ea4d-17c6-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:33:20.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-54zln" for this suite.
Jan 14 06:33:26.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:33:26.655: INFO: namespace: e2e-tests-downward-api-54zln, resource: bindings, ignored listing per whitelist
Jan 14 06:33:26.655: INFO: namespace e2e-tests-downward-api-54zln deletion completed in 6.219180377s

• [SLOW TEST:8.420 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:33:26.655: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 06:33:26.811: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c9d1bf9-17c6-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-khhhl" to be "success or failure"
Jan 14 06:33:26.821: INFO: Pod "downwardapi-volume-4c9d1bf9-17c6-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.962717ms
Jan 14 06:33:28.824: INFO: Pod "downwardapi-volume-4c9d1bf9-17c6-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013323031s
STEP: Saw pod success
Jan 14 06:33:28.824: INFO: Pod "downwardapi-volume-4c9d1bf9-17c6-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:33:28.827: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-4c9d1bf9-17c6-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 06:33:28.849: INFO: Waiting for pod downwardapi-volume-4c9d1bf9-17c6-11e9-912e-6a405af5e95c to disappear
Jan 14 06:33:28.855: INFO: Pod downwardapi-volume-4c9d1bf9-17c6-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:33:28.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-khhhl" for this suite.
Jan 14 06:33:34.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:33:34.976: INFO: namespace: e2e-tests-downward-api-khhhl, resource: bindings, ignored listing per whitelist
Jan 14 06:33:35.045: INFO: namespace e2e-tests-downward-api-khhhl deletion completed in 6.184850469s

• [SLOW TEST:8.391 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:33:35.045: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan 14 06:33:35.218: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zsnbz,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsnbz/configmaps/e2e-watch-test-label-changed,UID:516b725f-17c6-11e9-b726-525400ada096,ResourceVersion:61294,Generation:0,CreationTimestamp:2019-01-14 06:33:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 14 06:33:35.218: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zsnbz,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsnbz/configmaps/e2e-watch-test-label-changed,UID:516b725f-17c6-11e9-b726-525400ada096,ResourceVersion:61295,Generation:0,CreationTimestamp:2019-01-14 06:33:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 14 06:33:35.218: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zsnbz,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsnbz/configmaps/e2e-watch-test-label-changed,UID:516b725f-17c6-11e9-b726-525400ada096,ResourceVersion:61296,Generation:0,CreationTimestamp:2019-01-14 06:33:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan 14 06:33:45.287: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zsnbz,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsnbz/configmaps/e2e-watch-test-label-changed,UID:516b725f-17c6-11e9-b726-525400ada096,ResourceVersion:61313,Generation:0,CreationTimestamp:2019-01-14 06:33:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 14 06:33:45.287: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zsnbz,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsnbz/configmaps/e2e-watch-test-label-changed,UID:516b725f-17c6-11e9-b726-525400ada096,ResourceVersion:61314,Generation:0,CreationTimestamp:2019-01-14 06:33:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan 14 06:33:45.287: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zsnbz,SelfLink:/api/v1/namespaces/e2e-tests-watch-zsnbz/configmaps/e2e-watch-test-label-changed,UID:516b725f-17c6-11e9-b726-525400ada096,ResourceVersion:61315,Generation:0,CreationTimestamp:2019-01-14 06:33:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:33:45.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zsnbz" for this suite.
Jan 14 06:33:51.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:33:51.377: INFO: namespace: e2e-tests-watch-zsnbz, resource: bindings, ignored listing per whitelist
Jan 14 06:33:51.421: INFO: namespace e2e-tests-watch-zsnbz deletion completed in 6.127219061s

• [SLOW TEST:16.376 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:33:51.421: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 14 06:33:51.517: INFO: Waiting up to 5m0s for pod "pod-5b59e89b-17c6-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-7xhqj" to be "success or failure"
Jan 14 06:33:51.526: INFO: Pod "pod-5b59e89b-17c6-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.134549ms
Jan 14 06:33:53.529: INFO: Pod "pod-5b59e89b-17c6-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012206867s
STEP: Saw pod success
Jan 14 06:33:53.530: INFO: Pod "pod-5b59e89b-17c6-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:33:53.533: INFO: Trying to get logs from node paaswkr2 pod pod-5b59e89b-17c6-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 06:33:53.554: INFO: Waiting for pod pod-5b59e89b-17c6-11e9-912e-6a405af5e95c to disappear
Jan 14 06:33:53.557: INFO: Pod pod-5b59e89b-17c6-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:33:53.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7xhqj" for this suite.
Jan 14 06:33:59.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:33:59.618: INFO: namespace: e2e-tests-emptydir-7xhqj, resource: bindings, ignored listing per whitelist
Jan 14 06:33:59.680: INFO: namespace e2e-tests-emptydir-7xhqj deletion completed in 6.106258613s

• [SLOW TEST:8.259 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:33:59.680: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:34:59.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2pfpr" for this suite.
Jan 14 06:35:21.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:35:21.822: INFO: namespace: e2e-tests-container-probe-2pfpr, resource: bindings, ignored listing per whitelist
Jan 14 06:35:21.868: INFO: namespace e2e-tests-container-probe-2pfpr deletion completed in 22.102900822s

• [SLOW TEST:82.188 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:35:21.868: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-kv7rt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kv7rt to expose endpoints map[]
Jan 14 06:35:21.964: INFO: Get endpoints failed (8.544316ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan 14 06:35:22.967: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kv7rt exposes endpoints map[] (1.012327497s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-kv7rt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kv7rt to expose endpoints map[pod1:[80]]
Jan 14 06:35:24.998: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kv7rt exposes endpoints map[pod1:[80]] (2.022707099s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-kv7rt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kv7rt to expose endpoints map[pod1:[80] pod2:[80]]
Jan 14 06:35:28.055: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kv7rt exposes endpoints map[pod1:[80] pod2:[80]] (3.047557886s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-kv7rt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kv7rt to expose endpoints map[pod2:[80]]
Jan 14 06:35:28.083: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kv7rt exposes endpoints map[pod2:[80]] (16.931065ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-kv7rt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kv7rt to expose endpoints map[]
Jan 14 06:35:28.104: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kv7rt exposes endpoints map[] (7.413633ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:35:28.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-kv7rt" for this suite.
Jan 14 06:35:50.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:35:50.182: INFO: namespace: e2e-tests-services-kv7rt, resource: bindings, ignored listing per whitelist
Jan 14 06:35:50.262: INFO: namespace e2e-tests-services-kv7rt deletion completed in 22.118133634s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.394 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:35:50.262: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-728dv.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-728dv.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-728dv.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-728dv.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-728dv.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-728dv.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 14 06:35:55.387: INFO: Unable to read wheezy_udp@kubernetes.default from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.390: INFO: Unable to read wheezy_tcp@kubernetes.default from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.394: INFO: Unable to read wheezy_udp@kubernetes.default.svc from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.397: INFO: Unable to read wheezy_tcp@kubernetes.default.svc from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.400: INFO: Unable to read wheezy_udp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.404: INFO: Unable to read wheezy_tcp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.407: INFO: Unable to read wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-728dv.svc.cluster.local from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.410: INFO: Unable to read wheezy_hosts@dns-querier-1 from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.414: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.435: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.445: INFO: Unable to read jessie_udp@kubernetes.default from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.452: INFO: Unable to read jessie_tcp@kubernetes.default from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.461: INFO: Unable to read jessie_udp@kubernetes.default.svc from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.469: INFO: Unable to read jessie_tcp@kubernetes.default.svc from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.474: INFO: Unable to read jessie_udp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.477: INFO: Unable to read jessie_tcp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.482: INFO: Unable to read jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-728dv.svc.cluster.local from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.487: INFO: Unable to read jessie_hosts@dns-querier-1 from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.491: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.494: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:35:55.494: INFO: Lookups using e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c failed for: [wheezy_udp@kubernetes.default wheezy_tcp@kubernetes.default wheezy_udp@kubernetes.default.svc wheezy_tcp@kubernetes.default.svc wheezy_udp@kubernetes.default.svc.cluster.local wheezy_tcp@kubernetes.default.svc.cluster.local wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-728dv.svc.cluster.local wheezy_hosts@dns-querier-1 wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@kubernetes.default jessie_tcp@kubernetes.default jessie_udp@kubernetes.default.svc jessie_tcp@kubernetes.default.svc jessie_udp@kubernetes.default.svc.cluster.local jessie_tcp@kubernetes.default.svc.cluster.local jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-728dv.svc.cluster.local jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Jan 14 06:36:00.566: INFO: Unable to read jessie_hosts@dns-querier-1 from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:36:00.570: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:36:00.573: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:36:00.573: INFO: Lookups using e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c failed for: [jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Jan 14 06:36:05.568: INFO: Unable to read jessie_hosts@dns-querier-1 from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:36:05.571: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:36:05.575: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c: the server could not find the requested resource (get pods dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c)
Jan 14 06:36:05.575: INFO: Lookups using e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c failed for: [jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Jan 14 06:36:10.613: INFO: DNS probes using e2e-tests-dns-728dv/dns-test-a22d67ac-17c6-11e9-912e-6a405af5e95c succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:36:10.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-728dv" for this suite.
Jan 14 06:36:16.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:36:16.751: INFO: namespace: e2e-tests-dns-728dv, resource: bindings, ignored listing per whitelist
Jan 14 06:36:16.775: INFO: namespace e2e-tests-dns-728dv deletion completed in 6.123136291s

• [SLOW TEST:26.513 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:36:16.775: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 14 06:36:19.396: INFO: Successfully updated pod "labelsupdateb1fc5681-17c6-11e9-912e-6a405af5e95c"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:36:23.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sf9ht" for this suite.
Jan 14 06:36:45.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:36:45.517: INFO: namespace: e2e-tests-projected-sf9ht, resource: bindings, ignored listing per whitelist
Jan 14 06:36:45.517: INFO: namespace e2e-tests-projected-sf9ht deletion completed in 22.09522228s

• [SLOW TEST:28.742 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:36:45.517: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c31c8c77-17c6-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:36:45.609: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c31d99ea-17c6-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-8hb6c" to be "success or failure"
Jan 14 06:36:45.617: INFO: Pod "pod-projected-configmaps-c31d99ea-17c6-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.610091ms
Jan 14 06:36:47.619: INFO: Pod "pod-projected-configmaps-c31d99ea-17c6-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009239471s
STEP: Saw pod success
Jan 14 06:36:47.619: INFO: Pod "pod-projected-configmaps-c31d99ea-17c6-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:36:47.624: INFO: Trying to get logs from node paaswkr2 pod pod-projected-configmaps-c31d99ea-17c6-11e9-912e-6a405af5e95c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 06:36:47.652: INFO: Waiting for pod pod-projected-configmaps-c31d99ea-17c6-11e9-912e-6a405af5e95c to disappear
Jan 14 06:36:47.656: INFO: Pod pod-projected-configmaps-c31d99ea-17c6-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:36:47.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8hb6c" for this suite.
Jan 14 06:36:53.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:36:53.729: INFO: namespace: e2e-tests-projected-8hb6c, resource: bindings, ignored listing per whitelist
Jan 14 06:36:53.768: INFO: namespace e2e-tests-projected-8hb6c deletion completed in 6.104448339s

• [SLOW TEST:8.251 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:36:53.768: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-4t7s
STEP: Creating a pod to test atomic-volume-subpath
Jan 14 06:36:53.877: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-4t7s" in namespace "e2e-tests-subpath-l2xpk" to be "success or failure"
Jan 14 06:36:53.882: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Pending", Reason="", readiness=false. Elapsed: 4.629414ms
Jan 14 06:36:55.886: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008307492s
Jan 14 06:36:57.889: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Running", Reason="", readiness=false. Elapsed: 4.011338385s
Jan 14 06:36:59.892: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Running", Reason="", readiness=false. Elapsed: 6.014356051s
Jan 14 06:37:01.895: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Running", Reason="", readiness=false. Elapsed: 8.017658753s
Jan 14 06:37:03.898: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Running", Reason="", readiness=false. Elapsed: 10.020806543s
Jan 14 06:37:05.901: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Running", Reason="", readiness=false. Elapsed: 12.024248112s
Jan 14 06:37:07.904: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Running", Reason="", readiness=false. Elapsed: 14.027200521s
Jan 14 06:37:09.908: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Running", Reason="", readiness=false. Elapsed: 16.030395814s
Jan 14 06:37:11.911: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Running", Reason="", readiness=false. Elapsed: 18.033283178s
Jan 14 06:37:13.914: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Running", Reason="", readiness=false. Elapsed: 20.03630173s
Jan 14 06:37:15.917: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Running", Reason="", readiness=false. Elapsed: 22.039628194s
Jan 14 06:37:17.920: INFO: Pod "pod-subpath-test-secret-4t7s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.04266635s
STEP: Saw pod success
Jan 14 06:37:17.920: INFO: Pod "pod-subpath-test-secret-4t7s" satisfied condition "success or failure"
Jan 14 06:37:17.924: INFO: Trying to get logs from node paaswkr2 pod pod-subpath-test-secret-4t7s container test-container-subpath-secret-4t7s: <nil>
STEP: delete the pod
Jan 14 06:37:17.974: INFO: Waiting for pod pod-subpath-test-secret-4t7s to disappear
Jan 14 06:37:17.979: INFO: Pod pod-subpath-test-secret-4t7s no longer exists
STEP: Deleting pod pod-subpath-test-secret-4t7s
Jan 14 06:37:17.979: INFO: Deleting pod "pod-subpath-test-secret-4t7s" in namespace "e2e-tests-subpath-l2xpk"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:37:17.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-l2xpk" for this suite.
Jan 14 06:37:24.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:37:24.047: INFO: namespace: e2e-tests-subpath-l2xpk, resource: bindings, ignored listing per whitelist
Jan 14 06:37:24.092: INFO: namespace e2e-tests-subpath-l2xpk deletion completed in 6.101432536s

• [SLOW TEST:30.324 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:37:24.092: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 14 06:37:24.180: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 14 06:37:24.189: INFO: Waiting for terminating namespaces to be deleted...
Jan 14 06:37:24.195: INFO: 
Logging pods the kubelet thinks is on node paassys1 before test
Jan 14 06:37:24.223: INFO: fluentd-v1.1.0-vs2vp from kube-system started at 2019-01-14 05:02:11 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.224: INFO: 	Container fluentd ready: true, restart count 1
Jan 14 06:37:24.224: INFO: weave-net-xlbzd from kube-system started at 2019-01-14 00:43:08 +0000 UTC (2 container statuses recorded)
Jan 14 06:37:24.224: INFO: 	Container weave ready: true, restart count 10
Jan 14 06:37:24.224: INFO: 	Container weave-npc ready: true, restart count 9
Jan 14 06:37:24.224: INFO: metrics-server-87d5db7fc-5pgrw from kube-system started at 2019-01-14 05:00:40 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.224: INFO: 	Container metrics-server ready: true, restart count 1
Jan 14 06:37:24.224: INFO: graylog-cd85c9657-ld27h from kube-system started at 2019-01-14 05:12:48 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.224: INFO: 	Container graylog ready: true, restart count 10
Jan 14 06:37:24.224: INFO: mongodb-69879b9b6b-nnwpq from kube-system started at 2019-01-14 05:02:20 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.224: INFO: 	Container mongodb ready: true, restart count 1
Jan 14 06:37:24.224: INFO: default-http-backend-68b78b5998-t82lt from kube-system started at 2019-01-14 05:07:38 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.224: INFO: 	Container default-http-backend ready: true, restart count 1
Jan 14 06:37:24.224: INFO: nginx-ingress-controller-gj8fr from kube-system started at 2019-01-14 05:07:38 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.224: INFO: 	Container nginx-ingress-controller ready: true, restart count 5
Jan 14 06:37:24.224: INFO: kube-proxy-s86sw from kube-system started at 2019-01-14 00:43:08 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.224: INFO: 	Container kube-proxy ready: true, restart count 9
Jan 14 06:37:24.224: INFO: coredns-657dc6d946-hpfkl from kube-system started at 2019-01-14 05:24:40 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.224: INFO: 	Container coredns ready: true, restart count 4
Jan 14 06:37:24.224: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-14 05:48:44 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.224: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 14 06:37:24.224: INFO: 
Logging pods the kubelet thinks is on node paaswkr2 before test
Jan 14 06:37:24.234: INFO: kube-proxy-z7hbv from kube-system started at 2019-01-14 00:44:12 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.234: INFO: 	Container kube-proxy ready: true, restart count 11
Jan 14 06:37:24.234: INFO: coredns-657dc6d946-8pj4m from kube-system started at 2019-01-14 05:24:33 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.234: INFO: 	Container coredns ready: true, restart count 1
Jan 14 06:37:24.234: INFO: sonobuoy-e2e-job-aac769ef79af4018 from heptio-sonobuoy started at 2019-01-14 05:48:47 +0000 UTC (2 container statuses recorded)
Jan 14 06:37:24.234: INFO: 	Container e2e ready: true, restart count 0
Jan 14 06:37:24.234: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 14 06:37:24.234: INFO: weave-net-2vnzc from kube-system started at 2019-01-14 00:44:12 +0000 UTC (2 container statuses recorded)
Jan 14 06:37:24.234: INFO: 	Container weave ready: true, restart count 12
Jan 14 06:37:24.234: INFO: 	Container weave-npc ready: true, restart count 10
Jan 14 06:37:24.234: INFO: fluentd-v1.1.0-hq6w7 from kube-system started at 2019-01-14 05:02:10 +0000 UTC (1 container statuses recorded)
Jan 14 06:37:24.234: INFO: 	Container fluentd ready: true, restart count 2
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node paassys1
STEP: verifying the node has the label node paaswkr2
Jan 14 06:37:24.302: INFO: Pod sonobuoy requesting resource cpu=0m on Node paassys1
Jan 14 06:37:24.302: INFO: Pod sonobuoy-e2e-job-aac769ef79af4018 requesting resource cpu=0m on Node paaswkr2
Jan 14 06:37:24.302: INFO: Pod coredns-657dc6d946-8pj4m requesting resource cpu=100m on Node paaswkr2
Jan 14 06:37:24.302: INFO: Pod coredns-657dc6d946-hpfkl requesting resource cpu=100m on Node paassys1
Jan 14 06:37:24.302: INFO: Pod default-http-backend-68b78b5998-t82lt requesting resource cpu=10m on Node paassys1
Jan 14 06:37:24.302: INFO: Pod fluentd-v1.1.0-hq6w7 requesting resource cpu=100m on Node paaswkr2
Jan 14 06:37:24.302: INFO: Pod fluentd-v1.1.0-vs2vp requesting resource cpu=100m on Node paassys1
Jan 14 06:37:24.302: INFO: Pod graylog-cd85c9657-ld27h requesting resource cpu=0m on Node paassys1
Jan 14 06:37:24.302: INFO: Pod kube-proxy-s86sw requesting resource cpu=0m on Node paassys1
Jan 14 06:37:24.302: INFO: Pod kube-proxy-z7hbv requesting resource cpu=0m on Node paaswkr2
Jan 14 06:37:24.302: INFO: Pod metrics-server-87d5db7fc-5pgrw requesting resource cpu=0m on Node paassys1
Jan 14 06:37:24.302: INFO: Pod mongodb-69879b9b6b-nnwpq requesting resource cpu=0m on Node paassys1
Jan 14 06:37:24.302: INFO: Pod nginx-ingress-controller-gj8fr requesting resource cpu=0m on Node paassys1
Jan 14 06:37:24.302: INFO: Pod weave-net-2vnzc requesting resource cpu=20m on Node paaswkr2
Jan 14 06:37:24.302: INFO: Pod weave-net-xlbzd requesting resource cpu=20m on Node paassys1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-da2f8c07-17c6-11e9-912e-6a405af5e95c.1579a39d890b9b67], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-9jm46/filler-pod-da2f8c07-17c6-11e9-912e-6a405af5e95c to paassys1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-da2f8c07-17c6-11e9-912e-6a405af5e95c.1579a39dfddace17], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-da2f8c07-17c6-11e9-912e-6a405af5e95c.1579a39e0250921b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-da2f8c07-17c6-11e9-912e-6a405af5e95c.1579a39e0d57ed04], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-da31e006-17c6-11e9-912e-6a405af5e95c.1579a39d8a01d921], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-9jm46/filler-pod-da31e006-17c6-11e9-912e-6a405af5e95c to paaswkr2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-da31e006-17c6-11e9-912e-6a405af5e95c.1579a39dc10fe19f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-da31e006-17c6-11e9-912e-6a405af5e95c.1579a39dc23ea2e3], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-da31e006-17c6-11e9-912e-6a405af5e95c.1579a39dc90caf1f], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1579a39e7cdb7f78], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node paaswkr2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node paassys1
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:37:29.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-9jm46" for this suite.
Jan 14 06:37:35.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:37:35.534: INFO: namespace: e2e-tests-sched-pred-9jm46, resource: bindings, ignored listing per whitelist
Jan 14 06:37:35.575: INFO: namespace e2e-tests-sched-pred-9jm46 deletion completed in 6.152356067s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.483 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:37:35.575: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Jan 14 06:37:37.706: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:38:01.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-bg9mv" for this suite.
Jan 14 06:38:07.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:38:07.854: INFO: namespace: e2e-tests-namespaces-bg9mv, resource: bindings, ignored listing per whitelist
Jan 14 06:38:07.912: INFO: namespace e2e-tests-namespaces-bg9mv deletion completed in 6.103571734s
STEP: Destroying namespace "e2e-tests-nsdeletetest-85nvq" for this suite.
Jan 14 06:38:07.915: INFO: Namespace e2e-tests-nsdeletetest-85nvq was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-xb249" for this suite.
Jan 14 06:38:13.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:38:13.954: INFO: namespace: e2e-tests-nsdeletetest-xb249, resource: bindings, ignored listing per whitelist
Jan 14 06:38:14.060: INFO: namespace e2e-tests-nsdeletetest-xb249 deletion completed in 6.144511017s

• [SLOW TEST:38.485 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:38:14.060: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-7qmcn
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 14 06:38:14.155: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 14 06:38:36.252: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.64.9 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7qmcn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 06:38:36.252: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 06:38:37.383: INFO: Found all expected endpoints: [netserver-0]
Jan 14 06:38:37.387: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.192.19 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-7qmcn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 06:38:37.387: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 06:38:38.524: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:38:38.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-7qmcn" for this suite.
Jan 14 06:39:00.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:39:00.588: INFO: namespace: e2e-tests-pod-network-test-7qmcn, resource: bindings, ignored listing per whitelist
Jan 14 06:39:00.661: INFO: namespace e2e-tests-pod-network-test-7qmcn deletion completed in 22.130520925s

• [SLOW TEST:46.601 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:39:00.661: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 06:39:00.735: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:39:02.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2w79n" for this suite.
Jan 14 06:39:46.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:39:46.929: INFO: namespace: e2e-tests-pods-2w79n, resource: bindings, ignored listing per whitelist
Jan 14 06:39:47.015: INFO: namespace e2e-tests-pods-2w79n deletion completed in 44.130247119s

• [SLOW TEST:46.354 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:39:47.015: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-2f4f6121-17c7-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 06:39:47.131: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2f500b6f-17c7-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-sspvx" to be "success or failure"
Jan 14 06:39:47.150: INFO: Pod "pod-projected-secrets-2f500b6f-17c7-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.862619ms
Jan 14 06:39:49.156: INFO: Pod "pod-projected-secrets-2f500b6f-17c7-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025774001s
STEP: Saw pod success
Jan 14 06:39:49.156: INFO: Pod "pod-projected-secrets-2f500b6f-17c7-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:39:49.160: INFO: Trying to get logs from node paaswkr2 pod pod-projected-secrets-2f500b6f-17c7-11e9-912e-6a405af5e95c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 14 06:39:49.177: INFO: Waiting for pod pod-projected-secrets-2f500b6f-17c7-11e9-912e-6a405af5e95c to disappear
Jan 14 06:39:49.183: INFO: Pod pod-projected-secrets-2f500b6f-17c7-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:39:49.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sspvx" for this suite.
Jan 14 06:39:55.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:39:55.266: INFO: namespace: e2e-tests-projected-sspvx, resource: bindings, ignored listing per whitelist
Jan 14 06:39:55.300: INFO: namespace e2e-tests-projected-sspvx deletion completed in 6.106272225s

• [SLOW TEST:8.285 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:39:55.300: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-343aadd8-17c7-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 06:39:55.382: INFO: Waiting up to 5m0s for pod "pod-secrets-343b434c-17c7-11e9-912e-6a405af5e95c" in namespace "e2e-tests-secrets-kkrwl" to be "success or failure"
Jan 14 06:39:55.391: INFO: Pod "pod-secrets-343b434c-17c7-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.579616ms
Jan 14 06:39:57.394: INFO: Pod "pod-secrets-343b434c-17c7-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011833967s
STEP: Saw pod success
Jan 14 06:39:57.394: INFO: Pod "pod-secrets-343b434c-17c7-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:39:57.398: INFO: Trying to get logs from node paaswkr2 pod pod-secrets-343b434c-17c7-11e9-912e-6a405af5e95c container secret-volume-test: <nil>
STEP: delete the pod
Jan 14 06:39:57.423: INFO: Waiting for pod pod-secrets-343b434c-17c7-11e9-912e-6a405af5e95c to disappear
Jan 14 06:39:57.432: INFO: Pod pod-secrets-343b434c-17c7-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:39:57.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kkrwl" for this suite.
Jan 14 06:40:03.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:40:03.543: INFO: namespace: e2e-tests-secrets-kkrwl, resource: bindings, ignored listing per whitelist
Jan 14 06:40:03.552: INFO: namespace e2e-tests-secrets-kkrwl deletion completed in 6.115045373s

• [SLOW TEST:8.252 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:40:03.552: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-gjfbw
Jan 14 06:40:05.647: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-gjfbw
STEP: checking the pod's current state and verifying that restartCount is present
Jan 14 06:40:05.651: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:44:06.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gjfbw" for this suite.
Jan 14 06:44:12.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:44:12.167: INFO: namespace: e2e-tests-container-probe-gjfbw, resource: bindings, ignored listing per whitelist
Jan 14 06:44:12.180: INFO: namespace e2e-tests-container-probe-gjfbw deletion completed in 6.100766467s

• [SLOW TEST:248.628 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:44:12.180: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 06:44:12.269: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cd58e469-17c7-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-9vv5s" to be "success or failure"
Jan 14 06:44:12.275: INFO: Pod "downwardapi-volume-cd58e469-17c7-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.962486ms
Jan 14 06:44:14.279: INFO: Pod "downwardapi-volume-cd58e469-17c7-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009687934s
STEP: Saw pod success
Jan 14 06:44:14.279: INFO: Pod "downwardapi-volume-cd58e469-17c7-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:44:14.284: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-cd58e469-17c7-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 06:44:14.311: INFO: Waiting for pod downwardapi-volume-cd58e469-17c7-11e9-912e-6a405af5e95c to disappear
Jan 14 06:44:14.314: INFO: Pod downwardapi-volume-cd58e469-17c7-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:44:14.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9vv5s" for this suite.
Jan 14 06:44:20.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:44:20.369: INFO: namespace: e2e-tests-downward-api-9vv5s, resource: bindings, ignored listing per whitelist
Jan 14 06:44:20.419: INFO: namespace e2e-tests-downward-api-9vv5s deletion completed in 6.09961118s

• [SLOW TEST:8.238 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:44:20.419: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:44:22.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-l8tz9" for this suite.
Jan 14 06:45:00.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:45:00.577: INFO: namespace: e2e-tests-kubelet-test-l8tz9, resource: bindings, ignored listing per whitelist
Jan 14 06:45:00.610: INFO: namespace e2e-tests-kubelet-test-l8tz9 deletion completed in 38.096188462s

• [SLOW TEST:40.191 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:45:00.610: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 14 06:45:00.684: INFO: Waiting up to 5m0s for pod "downward-api-ea34d559-17c7-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-bpb57" to be "success or failure"
Jan 14 06:45:00.692: INFO: Pod "downward-api-ea34d559-17c7-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.684132ms
Jan 14 06:45:02.695: INFO: Pod "downward-api-ea34d559-17c7-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010948537s
STEP: Saw pod success
Jan 14 06:45:02.695: INFO: Pod "downward-api-ea34d559-17c7-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:45:02.699: INFO: Trying to get logs from node paaswkr2 pod downward-api-ea34d559-17c7-11e9-912e-6a405af5e95c container dapi-container: <nil>
STEP: delete the pod
Jan 14 06:45:02.714: INFO: Waiting for pod downward-api-ea34d559-17c7-11e9-912e-6a405af5e95c to disappear
Jan 14 06:45:02.721: INFO: Pod downward-api-ea34d559-17c7-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:45:02.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bpb57" for this suite.
Jan 14 06:45:08.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:45:08.787: INFO: namespace: e2e-tests-downward-api-bpb57, resource: bindings, ignored listing per whitelist
Jan 14 06:45:08.814: INFO: namespace e2e-tests-downward-api-bpb57 deletion completed in 6.085311253s

• [SLOW TEST:8.204 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:45:08.814: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 06:45:08.884: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ef1846c5-17c7-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-w2sr8" to be "success or failure"
Jan 14 06:45:08.902: INFO: Pod "downwardapi-volume-ef1846c5-17c7-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.632975ms
Jan 14 06:45:10.905: INFO: Pod "downwardapi-volume-ef1846c5-17c7-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020735742s
STEP: Saw pod success
Jan 14 06:45:10.905: INFO: Pod "downwardapi-volume-ef1846c5-17c7-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:45:10.908: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-ef1846c5-17c7-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 06:45:10.929: INFO: Waiting for pod downwardapi-volume-ef1846c5-17c7-11e9-912e-6a405af5e95c to disappear
Jan 14 06:45:10.932: INFO: Pod downwardapi-volume-ef1846c5-17c7-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:45:10.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w2sr8" for this suite.
Jan 14 06:45:16.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:45:17.046: INFO: namespace: e2e-tests-projected-w2sr8, resource: bindings, ignored listing per whitelist
Jan 14 06:45:17.093: INFO: namespace e2e-tests-projected-w2sr8 deletion completed in 6.156115138s

• [SLOW TEST:8.279 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:45:17.093: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jan 14 06:45:17.234: INFO: Pod name pod-release: Found 0 pods out of 1
Jan 14 06:45:22.249: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:45:23.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-nwzq2" for this suite.
Jan 14 06:45:29.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:45:29.398: INFO: namespace: e2e-tests-replication-controller-nwzq2, resource: bindings, ignored listing per whitelist
Jan 14 06:45:29.398: INFO: namespace e2e-tests-replication-controller-nwzq2 deletion completed in 6.104713309s

• [SLOW TEST:12.305 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:45:29.398: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan 14 06:45:29.508: INFO: Waiting up to 5m0s for pod "client-containers-fb626195-17c7-11e9-912e-6a405af5e95c" in namespace "e2e-tests-containers-srq9h" to be "success or failure"
Jan 14 06:45:29.516: INFO: Pod "client-containers-fb626195-17c7-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.854656ms
Jan 14 06:45:31.519: INFO: Pod "client-containers-fb626195-17c7-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011219188s
STEP: Saw pod success
Jan 14 06:45:31.519: INFO: Pod "client-containers-fb626195-17c7-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:45:31.523: INFO: Trying to get logs from node paaswkr2 pod client-containers-fb626195-17c7-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 06:45:31.546: INFO: Waiting for pod client-containers-fb626195-17c7-11e9-912e-6a405af5e95c to disappear
Jan 14 06:45:31.551: INFO: Pod client-containers-fb626195-17c7-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:45:31.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-srq9h" for this suite.
Jan 14 06:45:37.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:45:37.619: INFO: namespace: e2e-tests-containers-srq9h, resource: bindings, ignored listing per whitelist
Jan 14 06:45:37.655: INFO: namespace e2e-tests-containers-srq9h deletion completed in 6.096506022s

• [SLOW TEST:8.257 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:45:37.655: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-004ab8af-17c8-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:45:37.740: INFO: Waiting up to 5m0s for pod "pod-configmaps-004b722b-17c8-11e9-912e-6a405af5e95c" in namespace "e2e-tests-configmap-tswts" to be "success or failure"
Jan 14 06:45:37.746: INFO: Pod "pod-configmaps-004b722b-17c8-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.698875ms
Jan 14 06:45:39.749: INFO: Pod "pod-configmaps-004b722b-17c8-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008809731s
STEP: Saw pod success
Jan 14 06:45:39.749: INFO: Pod "pod-configmaps-004b722b-17c8-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:45:39.752: INFO: Trying to get logs from node paaswkr2 pod pod-configmaps-004b722b-17c8-11e9-912e-6a405af5e95c container configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 06:45:39.774: INFO: Waiting for pod pod-configmaps-004b722b-17c8-11e9-912e-6a405af5e95c to disappear
Jan 14 06:45:39.788: INFO: Pod pod-configmaps-004b722b-17c8-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:45:39.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tswts" for this suite.
Jan 14 06:45:45.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:45:45.825: INFO: namespace: e2e-tests-configmap-tswts, resource: bindings, ignored listing per whitelist
Jan 14 06:45:45.896: INFO: namespace e2e-tests-configmap-tswts deletion completed in 6.0984281s

• [SLOW TEST:8.241 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:45:45.896: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 14 06:45:46.025: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:46.031: INFO: Number of nodes with available pods: 0
Jan 14 06:45:46.031: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:45:47.041: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:47.047: INFO: Number of nodes with available pods: 1
Jan 14 06:45:47.047: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:45:48.035: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:48.038: INFO: Number of nodes with available pods: 1
Jan 14 06:45:48.038: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:45:49.039: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:49.042: INFO: Number of nodes with available pods: 2
Jan 14 06:45:49.042: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan 14 06:45:49.068: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:49.073: INFO: Number of nodes with available pods: 1
Jan 14 06:45:49.073: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:45:50.079: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:50.082: INFO: Number of nodes with available pods: 1
Jan 14 06:45:50.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:45:51.077: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:51.083: INFO: Number of nodes with available pods: 1
Jan 14 06:45:51.083: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:45:52.078: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:52.082: INFO: Number of nodes with available pods: 1
Jan 14 06:45:52.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:45:53.079: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:53.083: INFO: Number of nodes with available pods: 1
Jan 14 06:45:53.083: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:45:54.077: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:54.082: INFO: Number of nodes with available pods: 1
Jan 14 06:45:54.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:45:55.080: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:55.084: INFO: Number of nodes with available pods: 1
Jan 14 06:45:55.084: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:45:56.078: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:56.081: INFO: Number of nodes with available pods: 1
Jan 14 06:45:56.081: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:45:57.085: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:57.091: INFO: Number of nodes with available pods: 1
Jan 14 06:45:57.091: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:45:58.077: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:58.080: INFO: Number of nodes with available pods: 1
Jan 14 06:45:58.080: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:45:59.078: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:45:59.081: INFO: Number of nodes with available pods: 1
Jan 14 06:45:59.081: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:00.077: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:00.080: INFO: Number of nodes with available pods: 1
Jan 14 06:46:00.080: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:01.079: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:01.083: INFO: Number of nodes with available pods: 1
Jan 14 06:46:01.083: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:02.078: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:02.082: INFO: Number of nodes with available pods: 1
Jan 14 06:46:02.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:03.076: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:03.080: INFO: Number of nodes with available pods: 1
Jan 14 06:46:03.080: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:04.077: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:04.082: INFO: Number of nodes with available pods: 1
Jan 14 06:46:04.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:05.078: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:05.082: INFO: Number of nodes with available pods: 1
Jan 14 06:46:05.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:06.077: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:06.080: INFO: Number of nodes with available pods: 1
Jan 14 06:46:06.080: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:07.080: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:07.083: INFO: Number of nodes with available pods: 1
Jan 14 06:46:07.083: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:08.080: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:08.083: INFO: Number of nodes with available pods: 1
Jan 14 06:46:08.083: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:09.085: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:09.090: INFO: Number of nodes with available pods: 1
Jan 14 06:46:09.090: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:10.078: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:10.082: INFO: Number of nodes with available pods: 1
Jan 14 06:46:10.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:11.076: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:11.080: INFO: Number of nodes with available pods: 1
Jan 14 06:46:11.080: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:12.078: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:12.082: INFO: Number of nodes with available pods: 1
Jan 14 06:46:12.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:13.084: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:13.087: INFO: Number of nodes with available pods: 1
Jan 14 06:46:13.087: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:14.079: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:14.082: INFO: Number of nodes with available pods: 1
Jan 14 06:46:14.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:15.079: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:15.083: INFO: Number of nodes with available pods: 1
Jan 14 06:46:15.083: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:16.078: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:16.082: INFO: Number of nodes with available pods: 1
Jan 14 06:46:16.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:17.082: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:17.095: INFO: Number of nodes with available pods: 1
Jan 14 06:46:17.095: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:18.079: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:18.082: INFO: Number of nodes with available pods: 1
Jan 14 06:46:18.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:19.077: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:19.080: INFO: Number of nodes with available pods: 1
Jan 14 06:46:19.080: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:20.077: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:20.080: INFO: Number of nodes with available pods: 1
Jan 14 06:46:20.080: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:21.077: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:21.080: INFO: Number of nodes with available pods: 1
Jan 14 06:46:21.080: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:22.078: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:22.082: INFO: Number of nodes with available pods: 1
Jan 14 06:46:22.082: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:46:23.079: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:46:23.083: INFO: Number of nodes with available pods: 2
Jan 14 06:46:23.083: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-cgnw8, will wait for the garbage collector to delete the pods
Jan 14 06:46:23.146: INFO: Deleting DaemonSet.extensions daemon-set took: 4.963906ms
Jan 14 06:46:23.246: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.148595ms
Jan 14 06:46:56.649: INFO: Number of nodes with available pods: 0
Jan 14 06:46:56.649: INFO: Number of running nodes: 0, number of available pods: 0
Jan 14 06:46:56.654: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cgnw8/daemonsets","resourceVersion":"63302"},"items":null}

Jan 14 06:46:56.657: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cgnw8/pods","resourceVersion":"63302"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:46:56.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cgnw8" for this suite.
Jan 14 06:47:02.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:47:02.796: INFO: namespace: e2e-tests-daemonsets-cgnw8, resource: bindings, ignored listing per whitelist
Jan 14 06:47:02.820: INFO: namespace e2e-tests-daemonsets-cgnw8 deletion completed in 6.148158563s

• [SLOW TEST:76.923 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:47:02.820: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan 14 06:47:03.413: INFO: Waiting up to 5m0s for pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-kgpvh" in namespace "e2e-tests-svcaccounts-r8z67" to be "success or failure"
Jan 14 06:47:03.418: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-kgpvh": Phase="Pending", Reason="", readiness=false. Elapsed: 4.09332ms
Jan 14 06:47:05.421: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-kgpvh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007248564s
Jan 14 06:47:07.424: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-kgpvh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010405793s
STEP: Saw pod success
Jan 14 06:47:07.424: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-kgpvh" satisfied condition "success or failure"
Jan 14 06:47:07.428: INFO: Trying to get logs from node paassys1 pod pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-kgpvh container token-test: <nil>
STEP: delete the pod
Jan 14 06:47:07.662: INFO: Waiting for pod pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-kgpvh to disappear
Jan 14 06:47:07.666: INFO: Pod pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-kgpvh no longer exists
STEP: Creating a pod to test consume service account root CA
Jan 14 06:47:07.673: INFO: Waiting up to 5m0s for pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-gtlvn" in namespace "e2e-tests-svcaccounts-r8z67" to be "success or failure"
Jan 14 06:47:07.682: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-gtlvn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.859117ms
Jan 14 06:47:09.685: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-gtlvn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012251497s
Jan 14 06:47:11.688: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-gtlvn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014776074s
STEP: Saw pod success
Jan 14 06:47:11.688: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-gtlvn" satisfied condition "success or failure"
Jan 14 06:47:11.691: INFO: Trying to get logs from node paaswkr2 pod pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-gtlvn container root-ca-test: <nil>
STEP: delete the pod
Jan 14 06:47:11.710: INFO: Waiting for pod pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-gtlvn to disappear
Jan 14 06:47:11.714: INFO: Pod pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-gtlvn no longer exists
STEP: Creating a pod to test consume service account namespace
Jan 14 06:47:11.721: INFO: Waiting up to 5m0s for pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-wbqgz" in namespace "e2e-tests-svcaccounts-r8z67" to be "success or failure"
Jan 14 06:47:11.727: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-wbqgz": Phase="Pending", Reason="", readiness=false. Elapsed: 5.845798ms
Jan 14 06:47:13.731: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-wbqgz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009600531s
Jan 14 06:47:15.734: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-wbqgz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012312912s
STEP: Saw pod success
Jan 14 06:47:15.734: INFO: Pod "pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-wbqgz" satisfied condition "success or failure"
Jan 14 06:47:15.737: INFO: Trying to get logs from node paassys1 pod pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-wbqgz container namespace-test: <nil>
STEP: delete the pod
Jan 14 06:47:15.778: INFO: Waiting for pod pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-wbqgz to disappear
Jan 14 06:47:15.783: INFO: Pod pod-service-account-335be2a9-17c8-11e9-912e-6a405af5e95c-wbqgz no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:47:15.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-r8z67" for this suite.
Jan 14 06:47:21.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:47:21.923: INFO: namespace: e2e-tests-svcaccounts-r8z67, resource: bindings, ignored listing per whitelist
Jan 14 06:47:21.928: INFO: namespace e2e-tests-svcaccounts-r8z67 deletion completed in 6.139205353s

• [SLOW TEST:19.108 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:47:21.928: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan 14 06:47:24.035: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-3e726116-17c8-11e9-912e-6a405af5e95c", GenerateName:"", Namespace:"e2e-tests-pods-9blhl", SelfLink:"/api/v1/namespaces/e2e-tests-pods-9blhl/pods/pod-submit-remove-3e726116-17c8-11e9-912e-6a405af5e95c", UID:"3e3f0400-17c8-11e9-b726-525400ada096", ResourceVersion:"63466", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683045241, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"9222175"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-xzt9p", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001960f80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xzt9p", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001709a38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"paaswkr2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0023fd200), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001709a90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001709de0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001709de8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001709dec)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683045242, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683045242, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683045242, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683045241, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.10.105", PodIP:"10.244.64.9", StartTime:(*v1.Time)(0xc0012436a0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0012436c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://123bdcdbb26456d983078853a3f059bb9773943328d5bfaa368cdb41f128bf03"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jan 14 06:47:29.049: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:47:29.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9blhl" for this suite.
Jan 14 06:47:35.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:47:35.104: INFO: namespace: e2e-tests-pods-9blhl, resource: bindings, ignored listing per whitelist
Jan 14 06:47:35.145: INFO: namespace e2e-tests-pods-9blhl deletion completed in 6.089399303s

• [SLOW TEST:13.217 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:47:35.146: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 06:47:35.226: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46519e0f-17c8-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-9z679" to be "success or failure"
Jan 14 06:47:35.237: INFO: Pod "downwardapi-volume-46519e0f-17c8-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.4685ms
Jan 14 06:47:37.255: INFO: Pod "downwardapi-volume-46519e0f-17c8-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029119764s
STEP: Saw pod success
Jan 14 06:47:37.255: INFO: Pod "downwardapi-volume-46519e0f-17c8-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:47:37.259: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-46519e0f-17c8-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 06:47:37.285: INFO: Waiting for pod downwardapi-volume-46519e0f-17c8-11e9-912e-6a405af5e95c to disappear
Jan 14 06:47:37.290: INFO: Pod downwardapi-volume-46519e0f-17c8-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:47:37.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9z679" for this suite.
Jan 14 06:47:43.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:47:43.335: INFO: namespace: e2e-tests-projected-9z679, resource: bindings, ignored listing per whitelist
Jan 14 06:47:43.407: INFO: namespace e2e-tests-projected-9z679 deletion completed in 6.109158002s

• [SLOW TEST:8.262 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:47:43.407: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-59dpv/secret-test-4b405286-17c8-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 06:47:43.503: INFO: Waiting up to 5m0s for pod "pod-configmaps-4b41073a-17c8-11e9-912e-6a405af5e95c" in namespace "e2e-tests-secrets-59dpv" to be "success or failure"
Jan 14 06:47:43.507: INFO: Pod "pod-configmaps-4b41073a-17c8-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.889134ms
Jan 14 06:47:45.510: INFO: Pod "pod-configmaps-4b41073a-17c8-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006773881s
STEP: Saw pod success
Jan 14 06:47:45.510: INFO: Pod "pod-configmaps-4b41073a-17c8-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:47:45.513: INFO: Trying to get logs from node paaswkr2 pod pod-configmaps-4b41073a-17c8-11e9-912e-6a405af5e95c container env-test: <nil>
STEP: delete the pod
Jan 14 06:47:45.534: INFO: Waiting for pod pod-configmaps-4b41073a-17c8-11e9-912e-6a405af5e95c to disappear
Jan 14 06:47:45.538: INFO: Pod pod-configmaps-4b41073a-17c8-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:47:45.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-59dpv" for this suite.
Jan 14 06:47:51.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:47:51.643: INFO: namespace: e2e-tests-secrets-59dpv, resource: bindings, ignored listing per whitelist
Jan 14 06:47:51.693: INFO: namespace e2e-tests-secrets-59dpv deletion completed in 6.149598091s

• [SLOW TEST:8.286 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:47:51.693: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-5033759f-17c8-11e9-912e-6a405af5e95c
STEP: Creating secret with name secret-projected-all-test-volume-50337586-17c8-11e9-912e-6a405af5e95c
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan 14 06:47:51.817: INFO: Waiting up to 5m0s for pod "projected-volume-50337549-17c8-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-dxf8h" to be "success or failure"
Jan 14 06:47:51.822: INFO: Pod "projected-volume-50337549-17c8-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.082259ms
Jan 14 06:47:53.825: INFO: Pod "projected-volume-50337549-17c8-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00711698s
STEP: Saw pod success
Jan 14 06:47:53.825: INFO: Pod "projected-volume-50337549-17c8-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:47:53.828: INFO: Trying to get logs from node paaswkr2 pod projected-volume-50337549-17c8-11e9-912e-6a405af5e95c container projected-all-volume-test: <nil>
STEP: delete the pod
Jan 14 06:47:53.848: INFO: Waiting for pod projected-volume-50337549-17c8-11e9-912e-6a405af5e95c to disappear
Jan 14 06:47:53.852: INFO: Pod projected-volume-50337549-17c8-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:47:53.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dxf8h" for this suite.
Jan 14 06:47:59.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:47:59.925: INFO: namespace: e2e-tests-projected-dxf8h, resource: bindings, ignored listing per whitelist
Jan 14 06:47:59.964: INFO: namespace e2e-tests-projected-dxf8h deletion completed in 6.106620112s

• [SLOW TEST:8.272 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:47:59.965: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0114 06:48:30.627687      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 14 06:48:30.627: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:48:30.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nfdpj" for this suite.
Jan 14 06:48:36.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:48:36.935: INFO: namespace: e2e-tests-gc-nfdpj, resource: bindings, ignored listing per whitelist
Jan 14 06:48:36.959: INFO: namespace e2e-tests-gc-nfdpj deletion completed in 6.327370312s

• [SLOW TEST:36.995 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:48:36.959: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0114 06:48:38.158790      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 14 06:48:38.158: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:48:38.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-84272" for this suite.
Jan 14 06:48:44.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:48:44.272: INFO: namespace: e2e-tests-gc-84272, resource: bindings, ignored listing per whitelist
Jan 14 06:48:44.286: INFO: namespace e2e-tests-gc-84272 deletion completed in 6.117513716s

• [SLOW TEST:7.327 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:48:44.286: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 14 06:48:44.363: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 14 06:48:44.379: INFO: Waiting for terminating namespaces to be deleted...
Jan 14 06:48:44.382: INFO: 
Logging pods the kubelet thinks is on node paassys1 before test
Jan 14 06:48:44.414: INFO: nginx-ingress-controller-gj8fr from kube-system started at 2019-01-14 05:07:38 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.414: INFO: 	Container nginx-ingress-controller ready: true, restart count 5
Jan 14 06:48:44.414: INFO: kube-proxy-s86sw from kube-system started at 2019-01-14 00:43:08 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.414: INFO: 	Container kube-proxy ready: true, restart count 9
Jan 14 06:48:44.414: INFO: coredns-657dc6d946-hpfkl from kube-system started at 2019-01-14 05:24:40 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.414: INFO: 	Container coredns ready: true, restart count 4
Jan 14 06:48:44.414: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-14 05:48:44 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.414: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 14 06:48:44.414: INFO: graylog-cd85c9657-ld27h from kube-system started at 2019-01-14 05:12:48 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.414: INFO: 	Container graylog ready: true, restart count 10
Jan 14 06:48:44.414: INFO: fluentd-v1.1.0-vs2vp from kube-system started at 2019-01-14 05:02:11 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.414: INFO: 	Container fluentd ready: true, restart count 1
Jan 14 06:48:44.414: INFO: weave-net-xlbzd from kube-system started at 2019-01-14 00:43:08 +0000 UTC (2 container statuses recorded)
Jan 14 06:48:44.414: INFO: 	Container weave ready: true, restart count 10
Jan 14 06:48:44.414: INFO: 	Container weave-npc ready: true, restart count 9
Jan 14 06:48:44.414: INFO: metrics-server-87d5db7fc-5pgrw from kube-system started at 2019-01-14 05:00:40 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.414: INFO: 	Container metrics-server ready: true, restart count 1
Jan 14 06:48:44.414: INFO: mongodb-69879b9b6b-nnwpq from kube-system started at 2019-01-14 05:02:20 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.414: INFO: 	Container mongodb ready: true, restart count 1
Jan 14 06:48:44.414: INFO: default-http-backend-68b78b5998-t82lt from kube-system started at 2019-01-14 05:07:38 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.414: INFO: 	Container default-http-backend ready: true, restart count 1
Jan 14 06:48:44.414: INFO: 
Logging pods the kubelet thinks is on node paaswkr2 before test
Jan 14 06:48:44.422: INFO: coredns-657dc6d946-8pj4m from kube-system started at 2019-01-14 05:24:33 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.422: INFO: 	Container coredns ready: true, restart count 1
Jan 14 06:48:44.422: INFO: sonobuoy-e2e-job-aac769ef79af4018 from heptio-sonobuoy started at 2019-01-14 05:48:47 +0000 UTC (2 container statuses recorded)
Jan 14 06:48:44.422: INFO: 	Container e2e ready: true, restart count 0
Jan 14 06:48:44.422: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 14 06:48:44.422: INFO: weave-net-2vnzc from kube-system started at 2019-01-14 00:44:12 +0000 UTC (2 container statuses recorded)
Jan 14 06:48:44.422: INFO: 	Container weave ready: true, restart count 12
Jan 14 06:48:44.422: INFO: 	Container weave-npc ready: true, restart count 10
Jan 14 06:48:44.422: INFO: fluentd-v1.1.0-hq6w7 from kube-system started at 2019-01-14 05:02:10 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.422: INFO: 	Container fluentd ready: true, restart count 2
Jan 14 06:48:44.422: INFO: kube-proxy-z7hbv from kube-system started at 2019-01-14 00:44:12 +0000 UTC (1 container statuses recorded)
Jan 14 06:48:44.422: INFO: 	Container kube-proxy ready: true, restart count 11
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1579a43be2e5b777], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:48:45.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-95b92" for this suite.
Jan 14 06:48:51.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:48:51.473: INFO: namespace: e2e-tests-sched-pred-95b92, resource: bindings, ignored listing per whitelist
Jan 14 06:48:51.570: INFO: namespace e2e-tests-sched-pred-95b92 deletion completed in 6.123202935s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.284 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:48:51.571: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 14 06:48:54.189: INFO: Successfully updated pod "annotationupdate73dfd053-17c8-11e9-912e-6a405af5e95c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:48:58.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7kwfn" for this suite.
Jan 14 06:49:20.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:49:20.241: INFO: namespace: e2e-tests-downward-api-7kwfn, resource: bindings, ignored listing per whitelist
Jan 14 06:49:20.318: INFO: namespace e2e-tests-downward-api-7kwfn deletion completed in 22.101663551s

• [SLOW TEST:28.748 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:49:20.318: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 14 06:49:20.395: INFO: Waiting up to 5m0s for pod "pod-8501795a-17c8-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-zc2w4" to be "success or failure"
Jan 14 06:49:20.408: INFO: Pod "pod-8501795a-17c8-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.642534ms
Jan 14 06:49:22.415: INFO: Pod "pod-8501795a-17c8-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019756267s
STEP: Saw pod success
Jan 14 06:49:22.415: INFO: Pod "pod-8501795a-17c8-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:49:22.419: INFO: Trying to get logs from node paaswkr2 pod pod-8501795a-17c8-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 06:49:22.436: INFO: Waiting for pod pod-8501795a-17c8-11e9-912e-6a405af5e95c to disappear
Jan 14 06:49:22.445: INFO: Pod pod-8501795a-17c8-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:49:22.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zc2w4" for this suite.
Jan 14 06:49:28.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:49:28.496: INFO: namespace: e2e-tests-emptydir-zc2w4, resource: bindings, ignored listing per whitelist
Jan 14 06:49:28.568: INFO: namespace e2e-tests-emptydir-zc2w4 deletion completed in 6.117649392s

• [SLOW TEST:8.250 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:49:28.568: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-jf2r4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 14 06:49:28.638: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 14 06:49:54.722: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.64.10:8080/dial?request=hostName&protocol=http&host=10.244.64.9&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-jf2r4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 06:49:54.722: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 06:49:55.372: INFO: Waiting for endpoints: map[]
Jan 14 06:49:55.377: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.64.10:8080/dial?request=hostName&protocol=http&host=10.244.192.19&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-jf2r4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 06:49:55.377: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 06:49:55.576: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:49:55.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-jf2r4" for this suite.
Jan 14 06:50:17.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:50:17.664: INFO: namespace: e2e-tests-pod-network-test-jf2r4, resource: bindings, ignored listing per whitelist
Jan 14 06:50:17.681: INFO: namespace e2e-tests-pod-network-test-jf2r4 deletion completed in 22.098191236s

• [SLOW TEST:49.113 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:50:17.681: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 14 06:50:17.768: INFO: Waiting up to 5m0s for pod "downward-api-a7334355-17c8-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-sv6ps" to be "success or failure"
Jan 14 06:50:17.795: INFO: Pod "downward-api-a7334355-17c8-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 27.034897ms
Jan 14 06:50:19.799: INFO: Pod "downward-api-a7334355-17c8-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030162691s
STEP: Saw pod success
Jan 14 06:50:19.799: INFO: Pod "downward-api-a7334355-17c8-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:50:19.802: INFO: Trying to get logs from node paaswkr2 pod downward-api-a7334355-17c8-11e9-912e-6a405af5e95c container dapi-container: <nil>
STEP: delete the pod
Jan 14 06:50:19.830: INFO: Waiting for pod downward-api-a7334355-17c8-11e9-912e-6a405af5e95c to disappear
Jan 14 06:50:19.834: INFO: Pod downward-api-a7334355-17c8-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:50:19.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sv6ps" for this suite.
Jan 14 06:50:25.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:50:25.926: INFO: namespace: e2e-tests-downward-api-sv6ps, resource: bindings, ignored listing per whitelist
Jan 14 06:50:25.936: INFO: namespace e2e-tests-downward-api-sv6ps deletion completed in 6.096444155s

• [SLOW TEST:8.254 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:50:25.936: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 14 06:50:26.013: INFO: Waiting up to 5m0s for pod "pod-ac1dc116-17c8-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-mfkgw" to be "success or failure"
Jan 14 06:50:26.020: INFO: Pod "pod-ac1dc116-17c8-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.594729ms
Jan 14 06:50:28.023: INFO: Pod "pod-ac1dc116-17c8-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00985435s
STEP: Saw pod success
Jan 14 06:50:28.023: INFO: Pod "pod-ac1dc116-17c8-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:50:28.026: INFO: Trying to get logs from node paaswkr2 pod pod-ac1dc116-17c8-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 06:50:28.076: INFO: Waiting for pod pod-ac1dc116-17c8-11e9-912e-6a405af5e95c to disappear
Jan 14 06:50:28.080: INFO: Pod pod-ac1dc116-17c8-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:50:28.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mfkgw" for this suite.
Jan 14 06:50:34.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:50:34.165: INFO: namespace: e2e-tests-emptydir-mfkgw, resource: bindings, ignored listing per whitelist
Jan 14 06:50:34.192: INFO: namespace e2e-tests-emptydir-mfkgw deletion completed in 6.098079405s

• [SLOW TEST:8.256 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:50:34.192: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-tbb87
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 14 06:50:34.280: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 14 06:50:56.352: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.192.19:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-tbb87 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 06:50:56.352: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 06:50:56.683: INFO: Found all expected endpoints: [netserver-0]
Jan 14 06:50:56.691: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.64.9:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-tbb87 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 06:50:56.691: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 06:50:56.854: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:50:56.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-tbb87" for this suite.
Jan 14 06:51:18.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:51:18.980: INFO: namespace: e2e-tests-pod-network-test-tbb87, resource: bindings, ignored listing per whitelist
Jan 14 06:51:18.994: INFO: namespace e2e-tests-pod-network-test-tbb87 deletion completed in 22.136248528s

• [SLOW TEST:44.802 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:51:18.995: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 06:51:19.097: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan 14 06:51:19.105: INFO: Number of nodes with available pods: 0
Jan 14 06:51:19.105: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan 14 06:51:19.128: INFO: Number of nodes with available pods: 0
Jan 14 06:51:19.128: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:20.133: INFO: Number of nodes with available pods: 0
Jan 14 06:51:20.133: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:21.132: INFO: Number of nodes with available pods: 0
Jan 14 06:51:21.132: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:22.134: INFO: Number of nodes with available pods: 1
Jan 14 06:51:22.134: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan 14 06:51:22.160: INFO: Number of nodes with available pods: 1
Jan 14 06:51:22.160: INFO: Number of running nodes: 0, number of available pods: 1
Jan 14 06:51:23.163: INFO: Number of nodes with available pods: 0
Jan 14 06:51:23.163: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan 14 06:51:23.173: INFO: Number of nodes with available pods: 0
Jan 14 06:51:23.173: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:24.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:24.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:25.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:25.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:26.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:26.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:27.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:27.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:28.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:28.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:29.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:29.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:30.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:30.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:31.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:31.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:32.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:32.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:33.178: INFO: Number of nodes with available pods: 0
Jan 14 06:51:33.178: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:34.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:34.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:35.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:35.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:36.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:36.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:37.179: INFO: Number of nodes with available pods: 0
Jan 14 06:51:37.179: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:38.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:38.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:39.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:39.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:40.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:40.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:41.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:41.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:42.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:42.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:43.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:43.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:44.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:44.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:45.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:45.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:46.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:46.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:47.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:47.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:48.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:48.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:49.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:49.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:50.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:50.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:51.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:51.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:52.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:52.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:53.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:53.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:54.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:54.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:55.184: INFO: Number of nodes with available pods: 0
Jan 14 06:51:55.184: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:56.177: INFO: Number of nodes with available pods: 0
Jan 14 06:51:56.177: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:57.179: INFO: Number of nodes with available pods: 0
Jan 14 06:51:57.179: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:58.182: INFO: Number of nodes with available pods: 0
Jan 14 06:51:58.182: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:51:59.176: INFO: Number of nodes with available pods: 0
Jan 14 06:51:59.176: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:52:00.176: INFO: Number of nodes with available pods: 1
Jan 14 06:52:00.176: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2gfbn, will wait for the garbage collector to delete the pods
Jan 14 06:52:00.242: INFO: Deleting DaemonSet.extensions daemon-set took: 5.491515ms
Jan 14 06:52:00.342: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.468617ms
Jan 14 06:52:38.252: INFO: Number of nodes with available pods: 0
Jan 14 06:52:38.252: INFO: Number of running nodes: 0, number of available pods: 0
Jan 14 06:52:38.255: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2gfbn/daemonsets","resourceVersion":"64447"},"items":null}

Jan 14 06:52:38.258: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2gfbn/pods","resourceVersion":"64447"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:52:38.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2gfbn" for this suite.
Jan 14 06:52:44.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:52:44.324: INFO: namespace: e2e-tests-daemonsets-2gfbn, resource: bindings, ignored listing per whitelist
Jan 14 06:52:44.427: INFO: namespace e2e-tests-daemonsets-2gfbn deletion completed in 6.145382722s

• [SLOW TEST:85.433 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:52:44.428: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 14 06:52:44.507: INFO: Waiting up to 5m0s for pod "pod-feaa2d10-17c8-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-ntj9x" to be "success or failure"
Jan 14 06:52:44.512: INFO: Pod "pod-feaa2d10-17c8-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.050007ms
Jan 14 06:52:46.515: INFO: Pod "pod-feaa2d10-17c8-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008195154s
STEP: Saw pod success
Jan 14 06:52:46.515: INFO: Pod "pod-feaa2d10-17c8-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:52:46.518: INFO: Trying to get logs from node paaswkr2 pod pod-feaa2d10-17c8-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 06:52:46.536: INFO: Waiting for pod pod-feaa2d10-17c8-11e9-912e-6a405af5e95c to disappear
Jan 14 06:52:46.541: INFO: Pod pod-feaa2d10-17c8-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:52:46.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ntj9x" for this suite.
Jan 14 06:52:52.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:52:52.610: INFO: namespace: e2e-tests-emptydir-ntj9x, resource: bindings, ignored listing per whitelist
Jan 14 06:52:52.653: INFO: namespace e2e-tests-emptydir-ntj9x deletion completed in 6.10224455s

• [SLOW TEST:8.225 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:52:52.653: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 14 06:52:52.723: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:52:55.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-7bnvp" for this suite.
Jan 14 06:53:01.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:53:02.003: INFO: namespace: e2e-tests-init-container-7bnvp, resource: bindings, ignored listing per whitelist
Jan 14 06:53:02.025: INFO: namespace e2e-tests-init-container-7bnvp deletion completed in 6.107469142s

• [SLOW TEST:9.372 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:53:02.025: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan 14 06:53:02.113: INFO: Waiting up to 5m0s for pod "var-expansion-0928f38e-17c9-11e9-912e-6a405af5e95c" in namespace "e2e-tests-var-expansion-ggj9s" to be "success or failure"
Jan 14 06:53:02.120: INFO: Pod "var-expansion-0928f38e-17c9-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.323018ms
Jan 14 06:53:04.122: INFO: Pod "var-expansion-0928f38e-17c9-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008828151s
STEP: Saw pod success
Jan 14 06:53:04.122: INFO: Pod "var-expansion-0928f38e-17c9-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:53:04.126: INFO: Trying to get logs from node paaswkr2 pod var-expansion-0928f38e-17c9-11e9-912e-6a405af5e95c container dapi-container: <nil>
STEP: delete the pod
Jan 14 06:53:04.144: INFO: Waiting for pod var-expansion-0928f38e-17c9-11e9-912e-6a405af5e95c to disappear
Jan 14 06:53:04.148: INFO: Pod var-expansion-0928f38e-17c9-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:53:04.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-ggj9s" for this suite.
Jan 14 06:53:10.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:53:10.176: INFO: namespace: e2e-tests-var-expansion-ggj9s, resource: bindings, ignored listing per whitelist
Jan 14 06:53:10.252: INFO: namespace e2e-tests-var-expansion-ggj9s deletion completed in 6.099794313s

• [SLOW TEST:8.227 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:53:10.252: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 06:53:10.335: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan 14 06:53:10.348: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:10.353: INFO: Number of nodes with available pods: 0
Jan 14 06:53:10.353: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:53:11.358: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:11.362: INFO: Number of nodes with available pods: 0
Jan 14 06:53:11.362: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:53:12.357: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:12.361: INFO: Number of nodes with available pods: 1
Jan 14 06:53:12.361: INFO: Node paassys1 is running more than one daemon pod
Jan 14 06:53:13.358: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:13.361: INFO: Number of nodes with available pods: 2
Jan 14 06:53:13.361: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan 14 06:53:13.395: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:13.395: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:13.401: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:14.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:14.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:14.415: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:15.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:15.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:15.410: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:16.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:16.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:16.416: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:17.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:17.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:17.411: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:18.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:18.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:18.416: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:19.414: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:19.414: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:19.419: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:20.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:20.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:20.416: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:21.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:21.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:21.409: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:22.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:22.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:22.417: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:23.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:23.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:23.408: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:24.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:24.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:24.414: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:25.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:25.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:25.410: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:26.415: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:26.415: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:26.419: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:27.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:27.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:27.417: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:28.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:28.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:28.413: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:29.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:29.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:29.408: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:30.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:30.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:30.417: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:31.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:31.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:31.408: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:32.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:32.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:32.420: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:33.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:33.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:33.409: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:34.412: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:34.412: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:34.416: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:35.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:35.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:35.408: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:36.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:36.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:36.420: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:37.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:37.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:37.410: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:38.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:38.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:38.415: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:39.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:39.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:39.409: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:40.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:40.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:40.416: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:41.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:41.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:41.409: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:42.413: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:42.413: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:42.418: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:43.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:43.405: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:43.410: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:44.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:44.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:44.419: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:45.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:45.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:45.410: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:46.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:46.404: INFO: Wrong image for pod: daemon-set-d9562. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:46.404: INFO: Pod daemon-set-d9562 is not available
Jan 14 06:53:46.417: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:47.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:47.405: INFO: Pod daemon-set-rdvql is not available
Jan 14 06:53:47.409: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:48.415: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:48.415: INFO: Pod daemon-set-rdvql is not available
Jan 14 06:53:48.430: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:49.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:49.410: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:50.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:50.413: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:51.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:51.410: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:52.414: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:52.418: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:53.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:53.412: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:54.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:54.416: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:55.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:55.411: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:56.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:56.421: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:57.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:57.410: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:58.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:58.415: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:53:59.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:53:59.409: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:00.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:00.413: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:01.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:01.408: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:02.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:02.415: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:03.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:03.408: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:04.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:04.417: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:05.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:05.409: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:06.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:06.418: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:07.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:07.411: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:08.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:08.417: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:09.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:09.408: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:10.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:10.417: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:11.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:11.412: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:12.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:12.416: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:13.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:13.409: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:14.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:14.421: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:15.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:15.408: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:16.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:16.413: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:17.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:17.409: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:18.404: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:18.417: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:19.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:19.410: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:20.405: INFO: Wrong image for pod: daemon-set-4s7lz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 14 06:54:20.405: INFO: Pod daemon-set-4s7lz is not available
Jan 14 06:54:20.420: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:21.404: INFO: Pod daemon-set-nx7bd is not available
Jan 14 06:54:21.409: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jan 14 06:54:21.415: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:21.419: INFO: Number of nodes with available pods: 1
Jan 14 06:54:21.419: INFO: Node paaswkr2 is running more than one daemon pod
Jan 14 06:54:22.423: INFO: DaemonSet pods can't tolerate node paasmst1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 14 06:54:22.427: INFO: Number of nodes with available pods: 2
Jan 14 06:54:22.427: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-nh9tl, will wait for the garbage collector to delete the pods
Jan 14 06:54:22.500: INFO: Deleting DaemonSet.extensions daemon-set took: 4.673275ms
Jan 14 06:54:22.600: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.258431ms
Jan 14 06:54:36.504: INFO: Number of nodes with available pods: 0
Jan 14 06:54:36.504: INFO: Number of running nodes: 0, number of available pods: 0
Jan 14 06:54:36.508: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nh9tl/daemonsets","resourceVersion":"64812"},"items":null}

Jan 14 06:54:36.512: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nh9tl/pods","resourceVersion":"64812"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:54:36.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nh9tl" for this suite.
Jan 14 06:54:42.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:54:42.608: INFO: namespace: e2e-tests-daemonsets-nh9tl, resource: bindings, ignored listing per whitelist
Jan 14 06:54:42.661: INFO: namespace e2e-tests-daemonsets-nh9tl deletion completed in 6.1337582s

• [SLOW TEST:92.409 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:54:42.661: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 14 06:54:42.741: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 14 06:54:42.751: INFO: Waiting for terminating namespaces to be deleted...
Jan 14 06:54:42.754: INFO: 
Logging pods the kubelet thinks is on node paassys1 before test
Jan 14 06:54:42.784: INFO: mongodb-69879b9b6b-nnwpq from kube-system started at 2019-01-14 05:02:20 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.784: INFO: 	Container mongodb ready: true, restart count 1
Jan 14 06:54:42.784: INFO: default-http-backend-68b78b5998-t82lt from kube-system started at 2019-01-14 05:07:38 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.784: INFO: 	Container default-http-backend ready: true, restart count 1
Jan 14 06:54:42.784: INFO: kube-proxy-s86sw from kube-system started at 2019-01-14 00:43:08 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.784: INFO: 	Container kube-proxy ready: true, restart count 9
Jan 14 06:54:42.784: INFO: coredns-657dc6d946-hpfkl from kube-system started at 2019-01-14 05:24:40 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.784: INFO: 	Container coredns ready: true, restart count 4
Jan 14 06:54:42.784: INFO: nginx-ingress-controller-gj8fr from kube-system started at 2019-01-14 05:07:38 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.784: INFO: 	Container nginx-ingress-controller ready: true, restart count 5
Jan 14 06:54:42.784: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-14 05:48:44 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.784: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 14 06:54:42.784: INFO: weave-net-xlbzd from kube-system started at 2019-01-14 00:43:08 +0000 UTC (2 container statuses recorded)
Jan 14 06:54:42.784: INFO: 	Container weave ready: true, restart count 10
Jan 14 06:54:42.784: INFO: 	Container weave-npc ready: true, restart count 9
Jan 14 06:54:42.784: INFO: metrics-server-87d5db7fc-5pgrw from kube-system started at 2019-01-14 05:00:40 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.784: INFO: 	Container metrics-server ready: true, restart count 1
Jan 14 06:54:42.784: INFO: graylog-cd85c9657-ld27h from kube-system started at 2019-01-14 05:12:48 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.784: INFO: 	Container graylog ready: true, restart count 10
Jan 14 06:54:42.784: INFO: fluentd-v1.1.0-vs2vp from kube-system started at 2019-01-14 05:02:11 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.784: INFO: 	Container fluentd ready: true, restart count 1
Jan 14 06:54:42.784: INFO: 
Logging pods the kubelet thinks is on node paaswkr2 before test
Jan 14 06:54:42.794: INFO: kube-proxy-z7hbv from kube-system started at 2019-01-14 00:44:12 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.794: INFO: 	Container kube-proxy ready: true, restart count 11
Jan 14 06:54:42.794: INFO: coredns-657dc6d946-8pj4m from kube-system started at 2019-01-14 05:24:33 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.794: INFO: 	Container coredns ready: true, restart count 1
Jan 14 06:54:42.794: INFO: sonobuoy-e2e-job-aac769ef79af4018 from heptio-sonobuoy started at 2019-01-14 05:48:47 +0000 UTC (2 container statuses recorded)
Jan 14 06:54:42.794: INFO: 	Container e2e ready: true, restart count 0
Jan 14 06:54:42.794: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 14 06:54:42.794: INFO: weave-net-2vnzc from kube-system started at 2019-01-14 00:44:12 +0000 UTC (2 container statuses recorded)
Jan 14 06:54:42.794: INFO: 	Container weave ready: true, restart count 12
Jan 14 06:54:42.794: INFO: 	Container weave-npc ready: true, restart count 10
Jan 14 06:54:42.794: INFO: fluentd-v1.1.0-hq6w7 from kube-system started at 2019-01-14 05:02:10 +0000 UTC (1 container statuses recorded)
Jan 14 06:54:42.794: INFO: 	Container fluentd ready: true, restart count 2
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-4662bad2-17c9-11e9-912e-6a405af5e95c 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-4662bad2-17c9-11e9-912e-6a405af5e95c off the node paaswkr2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4662bad2-17c9-11e9-912e-6a405af5e95c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:54:46.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-46b8c" for this suite.
Jan 14 06:54:58.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:54:58.905: INFO: namespace: e2e-tests-sched-pred-46b8c, resource: bindings, ignored listing per whitelist
Jan 14 06:54:58.968: INFO: namespace e2e-tests-sched-pred-46b8c deletion completed in 12.094067727s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.307 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:54:58.968: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 14 06:55:01.565: INFO: Successfully updated pod "pod-update-4edb5790-17c9-11e9-912e-6a405af5e95c"
STEP: verifying the updated pod is in kubernetes
Jan 14 06:55:01.571: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:55:01.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bmtj9" for this suite.
Jan 14 06:55:23.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:55:23.627: INFO: namespace: e2e-tests-pods-bmtj9, resource: bindings, ignored listing per whitelist
Jan 14 06:55:23.671: INFO: namespace e2e-tests-pods-bmtj9 deletion completed in 22.094972351s

• [SLOW TEST:24.703 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:55:23.671: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5d96a61f-17c9-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:55:23.766: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5d975aff-17c9-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-rjwhg" to be "success or failure"
Jan 14 06:55:23.774: INFO: Pod "pod-projected-configmaps-5d975aff-17c9-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.41161ms
Jan 14 06:55:25.777: INFO: Pod "pod-projected-configmaps-5d975aff-17c9-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01016107s
STEP: Saw pod success
Jan 14 06:55:25.777: INFO: Pod "pod-projected-configmaps-5d975aff-17c9-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:55:25.780: INFO: Trying to get logs from node paaswkr2 pod pod-projected-configmaps-5d975aff-17c9-11e9-912e-6a405af5e95c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 06:55:25.798: INFO: Waiting for pod pod-projected-configmaps-5d975aff-17c9-11e9-912e-6a405af5e95c to disappear
Jan 14 06:55:25.803: INFO: Pod pod-projected-configmaps-5d975aff-17c9-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:55:25.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rjwhg" for this suite.
Jan 14 06:55:31.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:55:31.849: INFO: namespace: e2e-tests-projected-rjwhg, resource: bindings, ignored listing per whitelist
Jan 14 06:55:31.910: INFO: namespace e2e-tests-projected-rjwhg deletion completed in 6.100699344s

• [SLOW TEST:8.239 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:55:31.910: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan 14 06:55:31.974: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-949281363 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:55:32.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-frdk9" for this suite.
Jan 14 06:55:38.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:55:38.126: INFO: namespace: e2e-tests-kubectl-frdk9, resource: bindings, ignored listing per whitelist
Jan 14 06:55:38.140: INFO: namespace e2e-tests-kubectl-frdk9 deletion completed in 6.090867065s

• [SLOW TEST:6.230 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:55:38.140: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 14 06:55:38.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-wx777'
Jan 14 06:55:38.397: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 14 06:55:38.397: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan 14 06:55:38.410: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-zfkfs]
Jan 14 06:55:38.410: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-zfkfs" in namespace "e2e-tests-kubectl-wx777" to be "running and ready"
Jan 14 06:55:38.418: INFO: Pod "e2e-test-nginx-rc-zfkfs": Phase="Pending", Reason="", readiness=false. Elapsed: 7.300131ms
Jan 14 06:55:40.421: INFO: Pod "e2e-test-nginx-rc-zfkfs": Phase="Running", Reason="", readiness=true. Elapsed: 2.010167316s
Jan 14 06:55:40.421: INFO: Pod "e2e-test-nginx-rc-zfkfs" satisfied condition "running and ready"
Jan 14 06:55:40.421: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-zfkfs]
Jan 14 06:55:40.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-wx777'
Jan 14 06:55:40.512: INFO: stderr: ""
Jan 14 06:55:40.512: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Jan 14 06:55:40.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-wx777'
Jan 14 06:55:40.607: INFO: stderr: ""
Jan 14 06:55:40.607: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:55:40.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wx777" for this suite.
Jan 14 06:56:02.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:56:02.659: INFO: namespace: e2e-tests-kubectl-wx777, resource: bindings, ignored listing per whitelist
Jan 14 06:56:02.708: INFO: namespace e2e-tests-kubectl-wx777 deletion completed in 22.095665844s

• [SLOW TEST:24.568 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:56:02.708: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:56:04.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qk28d" for this suite.
Jan 14 06:56:48.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:56:48.895: INFO: namespace: e2e-tests-kubelet-test-qk28d, resource: bindings, ignored listing per whitelist
Jan 14 06:56:48.926: INFO: namespace e2e-tests-kubelet-test-qk28d deletion completed in 44.110099108s

• [SLOW TEST:46.218 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:56:48.926: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 06:56:49.092: INFO: (0) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 75.290491ms)
Jan 14 06:56:49.103: INFO: (1) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.852433ms)
Jan 14 06:56:49.107: INFO: (2) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.689113ms)
Jan 14 06:56:49.111: INFO: (3) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.839016ms)
Jan 14 06:56:49.118: INFO: (4) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.214023ms)
Jan 14 06:56:49.123: INFO: (5) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.837777ms)
Jan 14 06:56:49.133: INFO: (6) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.611608ms)
Jan 14 06:56:49.140: INFO: (7) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.856259ms)
Jan 14 06:56:49.150: INFO: (8) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.872678ms)
Jan 14 06:56:49.158: INFO: (9) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.961344ms)
Jan 14 06:56:49.165: INFO: (10) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.222082ms)
Jan 14 06:56:49.178: INFO: (11) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.774265ms)
Jan 14 06:56:49.186: INFO: (12) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.947597ms)
Jan 14 06:56:49.193: INFO: (13) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.989297ms)
Jan 14 06:56:49.197: INFO: (14) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.980471ms)
Jan 14 06:56:49.203: INFO: (15) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.90235ms)
Jan 14 06:56:49.210: INFO: (16) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.955069ms)
Jan 14 06:56:49.216: INFO: (17) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.556378ms)
Jan 14 06:56:49.225: INFO: (18) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.560032ms)
Jan 14 06:56:49.229: INFO: (19) /api/v1/nodes/paassys1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.539923ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:56:49.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-nljqh" for this suite.
Jan 14 06:56:55.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:56:55.363: INFO: namespace: e2e-tests-proxy-nljqh, resource: bindings, ignored listing per whitelist
Jan 14 06:56:55.375: INFO: namespace e2e-tests-proxy-nljqh deletion completed in 6.140171509s

• [SLOW TEST:6.449 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:56:55.375: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 06:56:55.449: INFO: Waiting up to 5m0s for pod "downwardapi-volume-943c9850-17c9-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-vcflk" to be "success or failure"
Jan 14 06:56:55.461: INFO: Pod "downwardapi-volume-943c9850-17c9-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.377632ms
Jan 14 06:56:57.467: INFO: Pod "downwardapi-volume-943c9850-17c9-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017485379s
STEP: Saw pod success
Jan 14 06:56:57.467: INFO: Pod "downwardapi-volume-943c9850-17c9-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:56:57.470: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-943c9850-17c9-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 06:56:57.490: INFO: Waiting for pod downwardapi-volume-943c9850-17c9-11e9-912e-6a405af5e95c to disappear
Jan 14 06:56:57.493: INFO: Pod downwardapi-volume-943c9850-17c9-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:56:57.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vcflk" for this suite.
Jan 14 06:57:03.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:57:03.583: INFO: namespace: e2e-tests-downward-api-vcflk, resource: bindings, ignored listing per whitelist
Jan 14 06:57:03.595: INFO: namespace e2e-tests-downward-api-vcflk deletion completed in 6.097485558s

• [SLOW TEST:8.220 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:57:03.595: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 06:57:03.682: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:57:04.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-sh9lj" for this suite.
Jan 14 06:57:10.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:57:10.862: INFO: namespace: e2e-tests-custom-resource-definition-sh9lj, resource: bindings, ignored listing per whitelist
Jan 14 06:57:10.930: INFO: namespace e2e-tests-custom-resource-definition-sh9lj deletion completed in 6.123243618s

• [SLOW TEST:7.335 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:57:10.930: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 06:57:11.014: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Jan 14 06:57:11.019: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-54z2l/daemonsets","resourceVersion":"65304"},"items":null}

Jan 14 06:57:11.024: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-54z2l/pods","resourceVersion":"65304"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:57:11.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-54z2l" for this suite.
Jan 14 06:57:17.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:57:17.108: INFO: namespace: e2e-tests-daemonsets-54z2l, resource: bindings, ignored listing per whitelist
Jan 14 06:57:17.167: INFO: namespace e2e-tests-daemonsets-54z2l deletion completed in 6.124979154s

S [SKIPPING] [6.238 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan 14 06:57:11.014: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:57:17.167: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan 14 06:57:17.305: INFO: Waiting up to 5m0s for pod "pod-a143bff7-17c9-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-j7tmg" to be "success or failure"
Jan 14 06:57:17.312: INFO: Pod "pod-a143bff7-17c9-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.133618ms
Jan 14 06:57:19.315: INFO: Pod "pod-a143bff7-17c9-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009832549s
STEP: Saw pod success
Jan 14 06:57:19.315: INFO: Pod "pod-a143bff7-17c9-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:57:19.318: INFO: Trying to get logs from node paaswkr2 pod pod-a143bff7-17c9-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 06:57:19.341: INFO: Waiting for pod pod-a143bff7-17c9-11e9-912e-6a405af5e95c to disappear
Jan 14 06:57:19.345: INFO: Pod pod-a143bff7-17c9-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:57:19.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j7tmg" for this suite.
Jan 14 06:57:25.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:57:25.422: INFO: namespace: e2e-tests-emptydir-j7tmg, resource: bindings, ignored listing per whitelist
Jan 14 06:57:25.457: INFO: namespace e2e-tests-emptydir-j7tmg deletion completed in 6.099790274s

• [SLOW TEST:8.290 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:57:25.457: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a62c27cf-17c9-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 06:57:25.540: INFO: Waiting up to 5m0s for pod "pod-configmaps-a62ca8d4-17c9-11e9-912e-6a405af5e95c" in namespace "e2e-tests-configmap-vbqxs" to be "success or failure"
Jan 14 06:57:25.547: INFO: Pod "pod-configmaps-a62ca8d4-17c9-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.45821ms
Jan 14 06:57:27.550: INFO: Pod "pod-configmaps-a62ca8d4-17c9-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010289266s
STEP: Saw pod success
Jan 14 06:57:27.550: INFO: Pod "pod-configmaps-a62ca8d4-17c9-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:57:27.553: INFO: Trying to get logs from node paaswkr2 pod pod-configmaps-a62ca8d4-17c9-11e9-912e-6a405af5e95c container configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 06:57:27.572: INFO: Waiting for pod pod-configmaps-a62ca8d4-17c9-11e9-912e-6a405af5e95c to disappear
Jan 14 06:57:27.577: INFO: Pod pod-configmaps-a62ca8d4-17c9-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:57:27.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vbqxs" for this suite.
Jan 14 06:57:33.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:57:33.646: INFO: namespace: e2e-tests-configmap-vbqxs, resource: bindings, ignored listing per whitelist
Jan 14 06:57:33.700: INFO: namespace e2e-tests-configmap-vbqxs deletion completed in 6.115397719s

• [SLOW TEST:8.242 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:57:33.700: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-rsr8
STEP: Creating a pod to test atomic-volume-subpath
Jan 14 06:57:33.789: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-rsr8" in namespace "e2e-tests-subpath-s68f5" to be "success or failure"
Jan 14 06:57:33.793: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.424345ms
Jan 14 06:57:35.797: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007669765s
Jan 14 06:57:37.800: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Running", Reason="", readiness=false. Elapsed: 4.010869846s
Jan 14 06:57:39.802: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Running", Reason="", readiness=false. Elapsed: 6.01345204s
Jan 14 06:57:41.806: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Running", Reason="", readiness=false. Elapsed: 8.016693735s
Jan 14 06:57:43.809: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Running", Reason="", readiness=false. Elapsed: 10.020208589s
Jan 14 06:57:45.812: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Running", Reason="", readiness=false. Elapsed: 12.023444976s
Jan 14 06:57:47.815: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Running", Reason="", readiness=false. Elapsed: 14.026447881s
Jan 14 06:57:49.818: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Running", Reason="", readiness=false. Elapsed: 16.029193463s
Jan 14 06:57:51.822: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Running", Reason="", readiness=false. Elapsed: 18.032586165s
Jan 14 06:57:53.825: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Running", Reason="", readiness=false. Elapsed: 20.035823774s
Jan 14 06:57:55.828: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Running", Reason="", readiness=false. Elapsed: 22.038786652s
Jan 14 06:57:57.831: INFO: Pod "pod-subpath-test-projected-rsr8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.041731813s
STEP: Saw pod success
Jan 14 06:57:57.831: INFO: Pod "pod-subpath-test-projected-rsr8" satisfied condition "success or failure"
Jan 14 06:57:57.834: INFO: Trying to get logs from node paaswkr2 pod pod-subpath-test-projected-rsr8 container test-container-subpath-projected-rsr8: <nil>
STEP: delete the pod
Jan 14 06:57:57.853: INFO: Waiting for pod pod-subpath-test-projected-rsr8 to disappear
Jan 14 06:57:57.860: INFO: Pod pod-subpath-test-projected-rsr8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-rsr8
Jan 14 06:57:57.860: INFO: Deleting pod "pod-subpath-test-projected-rsr8" in namespace "e2e-tests-subpath-s68f5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:57:57.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-s68f5" for this suite.
Jan 14 06:58:03.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:58:03.915: INFO: namespace: e2e-tests-subpath-s68f5, resource: bindings, ignored listing per whitelist
Jan 14 06:58:03.961: INFO: namespace e2e-tests-subpath-s68f5 deletion completed in 6.093137006s

• [SLOW TEST:30.262 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:58:03.962: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-bd1f4884-17c9-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 06:58:04.058: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bd214f2e-17c9-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-cgm8s" to be "success or failure"
Jan 14 06:58:04.069: INFO: Pod "pod-projected-secrets-bd214f2e-17c9-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.671634ms
Jan 14 06:58:06.072: INFO: Pod "pod-projected-secrets-bd214f2e-17c9-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014257339s
STEP: Saw pod success
Jan 14 06:58:06.072: INFO: Pod "pod-projected-secrets-bd214f2e-17c9-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:58:06.075: INFO: Trying to get logs from node paaswkr2 pod pod-projected-secrets-bd214f2e-17c9-11e9-912e-6a405af5e95c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 14 06:58:06.098: INFO: Waiting for pod pod-projected-secrets-bd214f2e-17c9-11e9-912e-6a405af5e95c to disappear
Jan 14 06:58:06.102: INFO: Pod pod-projected-secrets-bd214f2e-17c9-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:58:06.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cgm8s" for this suite.
Jan 14 06:58:12.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:58:12.197: INFO: namespace: e2e-tests-projected-cgm8s, resource: bindings, ignored listing per whitelist
Jan 14 06:58:12.200: INFO: namespace e2e-tests-projected-cgm8s deletion completed in 6.091573414s

• [SLOW TEST:8.238 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:58:12.200: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 06:58:12.319: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c20ec134-17c9-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-gqlkz" to be "success or failure"
Jan 14 06:58:12.324: INFO: Pod "downwardapi-volume-c20ec134-17c9-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.341273ms
Jan 14 06:58:14.328: INFO: Pod "downwardapi-volume-c20ec134-17c9-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008469796s
STEP: Saw pod success
Jan 14 06:58:14.328: INFO: Pod "downwardapi-volume-c20ec134-17c9-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 06:58:14.331: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-c20ec134-17c9-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 06:58:14.348: INFO: Waiting for pod downwardapi-volume-c20ec134-17c9-11e9-912e-6a405af5e95c to disappear
Jan 14 06:58:14.353: INFO: Pod downwardapi-volume-c20ec134-17c9-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:58:14.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gqlkz" for this suite.
Jan 14 06:58:20.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:58:20.398: INFO: namespace: e2e-tests-downward-api-gqlkz, resource: bindings, ignored listing per whitelist
Jan 14 06:58:20.465: INFO: namespace e2e-tests-downward-api-gqlkz deletion completed in 6.105020986s

• [SLOW TEST:8.265 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:58:20.465: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2kp5n
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-2kp5n
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-2kp5n
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-2kp5n
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-2kp5n
Jan 14 06:58:24.624: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2kp5n, name: ss-0, uid: c6fe9fb6-17c9-11e9-b726-525400ada096, status phase: Pending. Waiting for statefulset controller to delete.
Jan 14 06:58:28.223: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2kp5n, name: ss-0, uid: c6fe9fb6-17c9-11e9-b726-525400ada096, status phase: Failed. Waiting for statefulset controller to delete.
Jan 14 06:58:28.235: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2kp5n, name: ss-0, uid: c6fe9fb6-17c9-11e9-b726-525400ada096, status phase: Failed. Waiting for statefulset controller to delete.
Jan 14 06:58:28.240: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-2kp5n
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-2kp5n
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-2kp5n and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 14 06:58:38.301: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2kp5n
Jan 14 06:58:38.306: INFO: Scaling statefulset ss to 0
Jan 14 06:58:48.323: INFO: Waiting for statefulset status.replicas updated to 0
Jan 14 06:58:48.327: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:58:48.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2kp5n" for this suite.
Jan 14 06:58:54.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:58:54.437: INFO: namespace: e2e-tests-statefulset-2kp5n, resource: bindings, ignored listing per whitelist
Jan 14 06:58:54.461: INFO: namespace e2e-tests-statefulset-2kp5n deletion completed in 6.117182941s

• [SLOW TEST:33.996 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:58:54.461: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan 14 06:58:54.544: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wj626,SelfLink:/api/v1/namespaces/e2e-tests-watch-wj626/configmaps/e2e-watch-test-watch-closed,UID:db044f7a-17c9-11e9-b726-525400ada096,ResourceVersion:65712,Generation:0,CreationTimestamp:2019-01-14 06:58:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 14 06:58:54.544: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wj626,SelfLink:/api/v1/namespaces/e2e-tests-watch-wj626/configmaps/e2e-watch-test-watch-closed,UID:db044f7a-17c9-11e9-b726-525400ada096,ResourceVersion:65713,Generation:0,CreationTimestamp:2019-01-14 06:58:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan 14 06:58:54.562: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wj626,SelfLink:/api/v1/namespaces/e2e-tests-watch-wj626/configmaps/e2e-watch-test-watch-closed,UID:db044f7a-17c9-11e9-b726-525400ada096,ResourceVersion:65714,Generation:0,CreationTimestamp:2019-01-14 06:58:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 14 06:58:54.562: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-wj626,SelfLink:/api/v1/namespaces/e2e-tests-watch-wj626/configmaps/e2e-watch-test-watch-closed,UID:db044f7a-17c9-11e9-b726-525400ada096,ResourceVersion:65715,Generation:0,CreationTimestamp:2019-01-14 06:58:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 06:58:54.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wj626" for this suite.
Jan 14 06:59:00.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 06:59:00.658: INFO: namespace: e2e-tests-watch-wj626, resource: bindings, ignored listing per whitelist
Jan 14 06:59:00.670: INFO: namespace e2e-tests-watch-wj626 deletion completed in 6.096778649s

• [SLOW TEST:6.209 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 06:59:00.670: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-def41da8-17c9-11e9-912e-6a405af5e95c
STEP: Creating configMap with name cm-test-opt-upd-def41de0-17c9-11e9-912e-6a405af5e95c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-def41da8-17c9-11e9-912e-6a405af5e95c
STEP: Updating configmap cm-test-opt-upd-def41de0-17c9-11e9-912e-6a405af5e95c
STEP: Creating configMap with name cm-test-opt-create-def41df0-17c9-11e9-912e-6a405af5e95c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:00:23.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2bm8k" for this suite.
Jan 14 07:00:45.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:00:45.258: INFO: namespace: e2e-tests-configmap-2bm8k, resource: bindings, ignored listing per whitelist
Jan 14 07:00:45.324: INFO: namespace e2e-tests-configmap-2bm8k deletion completed in 22.113218786s

• [SLOW TEST:104.653 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:00:45.324: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-r5qrm
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan 14 07:00:45.407: INFO: Found 0 stateful pods, waiting for 3
Jan 14 07:00:55.410: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 14 07:00:55.410: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 14 07:00:55.410: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 14 07:00:55.435: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 14 07:01:05.480: INFO: Updating stateful set ss2
Jan 14 07:01:05.488: INFO: Waiting for Pod e2e-tests-statefulset-r5qrm/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 14 07:01:15.494: INFO: Waiting for Pod e2e-tests-statefulset-r5qrm/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan 14 07:01:25.567: INFO: Found 2 stateful pods, waiting for 3
Jan 14 07:01:35.583: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 14 07:01:35.583: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 14 07:01:35.583: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 14 07:01:35.606: INFO: Updating stateful set ss2
Jan 14 07:01:35.617: INFO: Waiting for Pod e2e-tests-statefulset-r5qrm/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 14 07:01:45.622: INFO: Waiting for Pod e2e-tests-statefulset-r5qrm/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 14 07:01:55.644: INFO: Updating stateful set ss2
Jan 14 07:01:55.659: INFO: Waiting for StatefulSet e2e-tests-statefulset-r5qrm/ss2 to complete update
Jan 14 07:01:55.659: INFO: Waiting for Pod e2e-tests-statefulset-r5qrm/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 14 07:02:05.664: INFO: Waiting for StatefulSet e2e-tests-statefulset-r5qrm/ss2 to complete update
Jan 14 07:02:05.664: INFO: Waiting for Pod e2e-tests-statefulset-r5qrm/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 14 07:02:15.664: INFO: Deleting all statefulset in ns e2e-tests-statefulset-r5qrm
Jan 14 07:02:15.667: INFO: Scaling statefulset ss2 to 0
Jan 14 07:02:35.682: INFO: Waiting for statefulset status.replicas updated to 0
Jan 14 07:02:35.685: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:02:35.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-r5qrm" for this suite.
Jan 14 07:02:41.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:02:41.830: INFO: namespace: e2e-tests-statefulset-r5qrm, resource: bindings, ignored listing per whitelist
Jan 14 07:02:41.848: INFO: namespace e2e-tests-statefulset-r5qrm deletion completed in 6.1454696s

• [SLOW TEST:116.524 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:02:41.848: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 07:02:41.928: INFO: Waiting up to 5m0s for pod "downwardapi-volume-62c11010-17ca-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-h7lxg" to be "success or failure"
Jan 14 07:02:41.943: INFO: Pod "downwardapi-volume-62c11010-17ca-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.087073ms
Jan 14 07:02:43.946: INFO: Pod "downwardapi-volume-62c11010-17ca-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017178984s
STEP: Saw pod success
Jan 14 07:02:43.946: INFO: Pod "downwardapi-volume-62c11010-17ca-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:02:43.950: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-62c11010-17ca-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 07:02:43.974: INFO: Waiting for pod downwardapi-volume-62c11010-17ca-11e9-912e-6a405af5e95c to disappear
Jan 14 07:02:43.979: INFO: Pod downwardapi-volume-62c11010-17ca-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:02:43.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h7lxg" for this suite.
Jan 14 07:02:49.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:02:50.036: INFO: namespace: e2e-tests-projected-h7lxg, resource: bindings, ignored listing per whitelist
Jan 14 07:02:50.084: INFO: namespace e2e-tests-projected-h7lxg deletion completed in 6.099985385s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:02:50.084: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-67a9dab3-17ca-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 07:02:50.169: INFO: Waiting up to 5m0s for pod "pod-configmaps-67ab6a52-17ca-11e9-912e-6a405af5e95c" in namespace "e2e-tests-configmap-dzfmr" to be "success or failure"
Jan 14 07:02:50.178: INFO: Pod "pod-configmaps-67ab6a52-17ca-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.671743ms
Jan 14 07:02:52.182: INFO: Pod "pod-configmaps-67ab6a52-17ca-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01337746s
STEP: Saw pod success
Jan 14 07:02:52.182: INFO: Pod "pod-configmaps-67ab6a52-17ca-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:02:52.189: INFO: Trying to get logs from node paaswkr2 pod pod-configmaps-67ab6a52-17ca-11e9-912e-6a405af5e95c container configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 07:02:52.205: INFO: Waiting for pod pod-configmaps-67ab6a52-17ca-11e9-912e-6a405af5e95c to disappear
Jan 14 07:02:52.209: INFO: Pod pod-configmaps-67ab6a52-17ca-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:02:52.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dzfmr" for this suite.
Jan 14 07:02:58.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:02:58.301: INFO: namespace: e2e-tests-configmap-dzfmr, resource: bindings, ignored listing per whitelist
Jan 14 07:02:58.320: INFO: namespace e2e-tests-configmap-dzfmr deletion completed in 6.097640406s

• [SLOW TEST:8.235 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:02:58.320: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 07:03:00.431: INFO: Waiting up to 5m0s for pod "client-envvars-6dc9548d-17ca-11e9-912e-6a405af5e95c" in namespace "e2e-tests-pods-7ccw6" to be "success or failure"
Jan 14 07:03:00.442: INFO: Pod "client-envvars-6dc9548d-17ca-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.322299ms
Jan 14 07:03:02.444: INFO: Pod "client-envvars-6dc9548d-17ca-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013075652s
STEP: Saw pod success
Jan 14 07:03:02.444: INFO: Pod "client-envvars-6dc9548d-17ca-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:03:02.448: INFO: Trying to get logs from node paaswkr2 pod client-envvars-6dc9548d-17ca-11e9-912e-6a405af5e95c container env3cont: <nil>
STEP: delete the pod
Jan 14 07:03:02.469: INFO: Waiting for pod client-envvars-6dc9548d-17ca-11e9-912e-6a405af5e95c to disappear
Jan 14 07:03:02.472: INFO: Pod client-envvars-6dc9548d-17ca-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:03:02.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7ccw6" for this suite.
Jan 14 07:03:40.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:03:40.557: INFO: namespace: e2e-tests-pods-7ccw6, resource: bindings, ignored listing per whitelist
Jan 14 07:03:40.599: INFO: namespace e2e-tests-pods-7ccw6 deletion completed in 38.122431216s

• [SLOW TEST:42.280 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:03:40.600: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-85c59d93-17ca-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 07:03:40.677: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-85c63eee-17ca-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-vxgdq" to be "success or failure"
Jan 14 07:03:40.683: INFO: Pod "pod-projected-secrets-85c63eee-17ca-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.327839ms
Jan 14 07:03:42.687: INFO: Pod "pod-projected-secrets-85c63eee-17ca-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009493624s
STEP: Saw pod success
Jan 14 07:03:42.687: INFO: Pod "pod-projected-secrets-85c63eee-17ca-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:03:42.692: INFO: Trying to get logs from node paaswkr2 pod pod-projected-secrets-85c63eee-17ca-11e9-912e-6a405af5e95c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 14 07:03:42.714: INFO: Waiting for pod pod-projected-secrets-85c63eee-17ca-11e9-912e-6a405af5e95c to disappear
Jan 14 07:03:42.720: INFO: Pod pod-projected-secrets-85c63eee-17ca-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:03:42.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vxgdq" for this suite.
Jan 14 07:03:48.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:03:48.750: INFO: namespace: e2e-tests-projected-vxgdq, resource: bindings, ignored listing per whitelist
Jan 14 07:03:48.824: INFO: namespace e2e-tests-projected-vxgdq deletion completed in 6.098317454s

• [SLOW TEST:8.224 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:03:48.824: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 14 07:03:48.938: INFO: Waiting up to 5m0s for pod "pod-8ab2e28d-17ca-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-jmrzw" to be "success or failure"
Jan 14 07:03:48.946: INFO: Pod "pod-8ab2e28d-17ca-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.297667ms
Jan 14 07:03:50.949: INFO: Pod "pod-8ab2e28d-17ca-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010043676s
STEP: Saw pod success
Jan 14 07:03:50.949: INFO: Pod "pod-8ab2e28d-17ca-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:03:50.952: INFO: Trying to get logs from node paaswkr2 pod pod-8ab2e28d-17ca-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 07:03:50.970: INFO: Waiting for pod pod-8ab2e28d-17ca-11e9-912e-6a405af5e95c to disappear
Jan 14 07:03:50.975: INFO: Pod pod-8ab2e28d-17ca-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:03:50.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jmrzw" for this suite.
Jan 14 07:03:56.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:03:57.056: INFO: namespace: e2e-tests-emptydir-jmrzw, resource: bindings, ignored listing per whitelist
Jan 14 07:03:57.094: INFO: namespace e2e-tests-emptydir-jmrzw deletion completed in 6.112405705s

• [SLOW TEST:8.270 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:03:57.094: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 07:03:57.213: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 14 07:04:02.217: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 14 07:04:02.217: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 14 07:04:02.248: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-6pwwn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6pwwn/deployments/test-cleanup-deployment,UID:926ac6e3-17ca-11e9-b726-525400ada096,ResourceVersion:66652,Generation:1,CreationTimestamp:2019-01-14 07:04:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan 14 07:04:02.251: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Jan 14 07:04:02.251: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan 14 07:04:02.252: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-6pwwn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6pwwn/replicasets/test-cleanup-controller,UID:8f6bb217-17ca-11e9-b726-525400ada096,ResourceVersion:66653,Generation:1,CreationTimestamp:2019-01-14 07:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 926ac6e3-17ca-11e9-b726-525400ada096 0xc00251a527 0xc00251a528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 14 07:04:02.255: INFO: Pod "test-cleanup-controller-jdjmz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-jdjmz,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-6pwwn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6pwwn/pods/test-cleanup-controller-jdjmz,UID:8f6f0155-17ca-11e9-b726-525400ada096,ResourceVersion:66643,Generation:0,CreationTimestamp:2019-01-14 07:03:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 8f6bb217-17ca-11e9-b726-525400ada096 0xc001d50097 0xc001d50098}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-n8ftb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-n8ftb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-n8ftb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d50110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d50130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:03:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:03:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:03:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:03:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:10.244.64.9,StartTime:2019-01-14 07:03:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-14 07:03:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://7cd78b84758ffc13899494bcd48d876b6f674c9ba86093d357f458ba5778c0e9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:04:02.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-6pwwn" for this suite.
Jan 14 07:04:08.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:04:08.334: INFO: namespace: e2e-tests-deployment-6pwwn, resource: bindings, ignored listing per whitelist
Jan 14 07:04:08.381: INFO: namespace e2e-tests-deployment-6pwwn deletion completed in 6.113361939s

• [SLOW TEST:11.287 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:04:08.381: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan 14 07:04:10.486: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-96574df8-17ca-11e9-912e-6a405af5e95c,GenerateName:,Namespace:e2e-tests-events-dc5f6,SelfLink:/api/v1/namespaces/e2e-tests-events-dc5f6/pods/send-events-96574df8-17ca-11e9-912e-6a405af5e95c,UID:96235597-17ca-11e9-b726-525400ada096,ResourceVersion:66718,Generation:0,CreationTimestamp:2019-01-14 07:04:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 464746910,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zz6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zz6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-4zz6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f35c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f35cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:04:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:04:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:04:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:04:08 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:10.244.64.9,StartTime:2019-01-14 07:04:08 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-14 07:04:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://f1a8ba0d875fddafc1c823db3a4d2b41535268ecdfab90c8044ce473e38d8c15}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan 14 07:04:12.489: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan 14 07:04:14.492: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:04:14.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-dc5f6" for this suite.
Jan 14 07:04:58.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:04:58.592: INFO: namespace: e2e-tests-events-dc5f6, resource: bindings, ignored listing per whitelist
Jan 14 07:04:58.626: INFO: namespace e2e-tests-events-dc5f6 deletion completed in 44.112916456s

• [SLOW TEST:50.245 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:04:58.626: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 07:04:58.693: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 14 07:04:58.702: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 14 07:05:03.705: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 14 07:05:03.705: INFO: Creating deployment "test-rolling-update-deployment"
Jan 14 07:05:03.710: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 14 07:05:03.717: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 14 07:05:05.723: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 14 07:05:05.726: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 14 07:05:05.736: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-hzhh7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hzhh7/deployments/test-rolling-update-deployment,UID:b70ff6db-17ca-11e9-b726-525400ada096,ResourceVersion:66858,Generation:1,CreationTimestamp:2019-01-14 07:05:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-14 07:05:03 +0000 UTC 2019-01-14 07:05:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-14 07:05:04 +0000 UTC 2019-01-14 07:05:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 14 07:05:05.739: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-hzhh7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hzhh7/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:b7129deb-17ca-11e9-b726-525400ada096,ResourceVersion:66849,Generation:1,CreationTimestamp:2019-01-14 07:05:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment b70ff6db-17ca-11e9-b726-525400ada096 0xc0009e51e7 0xc0009e51e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 14 07:05:05.739: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 14 07:05:05.739: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-hzhh7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hzhh7/replicasets/test-rolling-update-controller,UID:b41338ea-17ca-11e9-b726-525400ada096,ResourceVersion:66857,Generation:2,CreationTimestamp:2019-01-14 07:04:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment b70ff6db-17ca-11e9-b726-525400ada096 0xc0009e50f7 0xc0009e50f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 14 07:05:05.743: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-9zpnc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-9zpnc,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-hzhh7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hzhh7/pods/test-rolling-update-deployment-68b55d7bc6-9zpnc,UID:b7134c7d-17ca-11e9-b726-525400ada096,ResourceVersion:66848,Generation:0,CreationTimestamp:2019-01-14 07:05:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 b7129deb-17ca-11e9-b726-525400ada096 0xc001df4197 0xc001df4198}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7wrkp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7wrkp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7wrkp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001df43a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001df4560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:03 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:10.244.64.10,StartTime:2019-01-14 07:05:03 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-14 07:05:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://64e1d27b379ea8f90980fd6378f9f1f637f6c298ee96cf73d9e56d0ceb95e07e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:05:05.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-hzhh7" for this suite.
Jan 14 07:05:11.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:05:11.807: INFO: namespace: e2e-tests-deployment-hzhh7, resource: bindings, ignored listing per whitelist
Jan 14 07:05:11.851: INFO: namespace e2e-tests-deployment-hzhh7 deletion completed in 6.102734646s

• [SLOW TEST:13.225 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:05:11.851: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan 14 07:05:11.933: INFO: Waiting up to 5m0s for pod "client-containers-bc2ac9da-17ca-11e9-912e-6a405af5e95c" in namespace "e2e-tests-containers-xglls" to be "success or failure"
Jan 14 07:05:11.937: INFO: Pod "client-containers-bc2ac9da-17ca-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.636532ms
Jan 14 07:05:13.941: INFO: Pod "client-containers-bc2ac9da-17ca-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008135995s
STEP: Saw pod success
Jan 14 07:05:13.941: INFO: Pod "client-containers-bc2ac9da-17ca-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:05:13.944: INFO: Trying to get logs from node paaswkr2 pod client-containers-bc2ac9da-17ca-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 07:05:13.962: INFO: Waiting for pod client-containers-bc2ac9da-17ca-11e9-912e-6a405af5e95c to disappear
Jan 14 07:05:13.973: INFO: Pod client-containers-bc2ac9da-17ca-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:05:13.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-xglls" for this suite.
Jan 14 07:05:20.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:05:20.056: INFO: namespace: e2e-tests-containers-xglls, resource: bindings, ignored listing per whitelist
Jan 14 07:05:20.080: INFO: namespace e2e-tests-containers-xglls deletion completed in 6.097436739s

• [SLOW TEST:8.229 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:05:20.080: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mwdz4
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-mwdz4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-mwdz4
Jan 14 07:05:20.203: INFO: Found 0 stateful pods, waiting for 1
Jan 14 07:05:30.207: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan 14 07:05:30.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-mwdz4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 14 07:05:30.396: INFO: stderr: ""
Jan 14 07:05:30.396: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 14 07:05:30.396: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 14 07:05:30.401: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 14 07:05:40.405: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 14 07:05:40.405: INFO: Waiting for statefulset status.replicas updated to 0
Jan 14 07:05:40.435: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 14 07:05:40.435: INFO: ss-0  paaswkr2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:19 +0000 UTC  }]
Jan 14 07:05:40.435: INFO: ss-1            Pending         []
Jan 14 07:05:40.435: INFO: 
Jan 14 07:05:40.435: INFO: StatefulSet ss has not reached scale 3, at 2
Jan 14 07:05:41.440: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98959791s
Jan 14 07:05:42.444: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.983456976s
Jan 14 07:05:43.447: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.980338745s
Jan 14 07:05:44.450: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977170129s
Jan 14 07:05:45.455: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974092048s
Jan 14 07:05:46.458: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.969473568s
Jan 14 07:05:47.461: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966336161s
Jan 14 07:05:48.465: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962750858s
Jan 14 07:05:49.472: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.080309ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-mwdz4
Jan 14 07:05:50.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-mwdz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 14 07:05:50.864: INFO: stderr: ""
Jan 14 07:05:50.864: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 14 07:05:50.864: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 14 07:05:50.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-mwdz4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 14 07:05:51.653: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 14 07:05:51.653: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 14 07:05:51.653: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 14 07:05:51.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-mwdz4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 14 07:05:51.856: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 14 07:05:51.856: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 14 07:05:51.856: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 14 07:05:51.860: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 14 07:05:51.860: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 14 07:05:51.860: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan 14 07:05:51.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-mwdz4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 14 07:05:52.078: INFO: stderr: ""
Jan 14 07:05:52.078: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 14 07:05:52.078: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 14 07:05:52.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-mwdz4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 14 07:05:52.589: INFO: stderr: ""
Jan 14 07:05:52.589: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 14 07:05:52.589: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 14 07:05:52.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 exec --namespace=e2e-tests-statefulset-mwdz4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 14 07:05:52.790: INFO: stderr: ""
Jan 14 07:05:52.790: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 14 07:05:52.790: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 14 07:05:52.790: INFO: Waiting for statefulset status.replicas updated to 0
Jan 14 07:05:52.795: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan 14 07:06:02.800: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 14 07:06:02.800: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 14 07:06:02.800: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 14 07:06:02.813: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 14 07:06:02.813: INFO: ss-0  paaswkr2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:19 +0000 UTC  }]
Jan 14 07:06:02.813: INFO: ss-1  paassys1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  }]
Jan 14 07:06:02.813: INFO: ss-2  paaswkr2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  }]
Jan 14 07:06:02.813: INFO: 
Jan 14 07:06:02.813: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 14 07:06:03.816: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 14 07:06:03.816: INFO: ss-0  paaswkr2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:19 +0000 UTC  }]
Jan 14 07:06:03.816: INFO: ss-1  paassys1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  }]
Jan 14 07:06:03.816: INFO: ss-2  paaswkr2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  }]
Jan 14 07:06:03.816: INFO: 
Jan 14 07:06:03.816: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 14 07:06:04.820: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 14 07:06:04.820: INFO: ss-1  paassys1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  }]
Jan 14 07:06:04.820: INFO: 
Jan 14 07:06:04.820: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 14 07:06:05.824: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 14 07:06:05.824: INFO: ss-1  paassys1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  }]
Jan 14 07:06:05.824: INFO: 
Jan 14 07:06:05.824: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 14 07:06:06.830: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 14 07:06:06.830: INFO: ss-1  paassys1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  }]
Jan 14 07:06:06.830: INFO: 
Jan 14 07:06:06.830: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 14 07:06:07.833: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Jan 14 07:06:07.833: INFO: ss-1  paassys1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:05:40 +0000 UTC  }]
Jan 14 07:06:07.833: INFO: 
Jan 14 07:06:07.833: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 14 07:06:08.835: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.974684742s
Jan 14 07:06:09.839: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.971576842s
Jan 14 07:06:10.843: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.967648613s
Jan 14 07:06:11.859: INFO: Verifying statefulset ss doesn't scale past 0 for another 964.257758ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-mwdz4
Jan 14 07:06:12.863: INFO: Scaling statefulset ss to 0
Jan 14 07:06:12.873: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 14 07:06:12.878: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mwdz4
Jan 14 07:06:12.882: INFO: Scaling statefulset ss to 0
Jan 14 07:06:12.892: INFO: Waiting for statefulset status.replicas updated to 0
Jan 14 07:06:12.897: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:06:12.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mwdz4" for this suite.
Jan 14 07:06:19.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:06:19.033: INFO: namespace: e2e-tests-statefulset-mwdz4, resource: bindings, ignored listing per whitelist
Jan 14 07:06:19.135: INFO: namespace e2e-tests-statefulset-mwdz4 deletion completed in 6.146038726s

• [SLOW TEST:59.054 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:06:19.135: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:06:19.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-x47gg" for this suite.
Jan 14 07:06:41.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:06:41.309: INFO: namespace: e2e-tests-kubelet-test-x47gg, resource: bindings, ignored listing per whitelist
Jan 14 07:06:41.364: INFO: namespace e2e-tests-kubelet-test-x47gg deletion completed in 22.102704341s

• [SLOW TEST:22.229 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:06:41.364: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-f18512b1-17ca-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 07:06:41.461: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f186f074-17ca-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-m5m9q" to be "success or failure"
Jan 14 07:06:41.473: INFO: Pod "pod-projected-configmaps-f186f074-17ca-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014641ms
Jan 14 07:06:43.476: INFO: Pod "pod-projected-configmaps-f186f074-17ca-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015230132s
STEP: Saw pod success
Jan 14 07:06:43.476: INFO: Pod "pod-projected-configmaps-f186f074-17ca-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:06:43.479: INFO: Trying to get logs from node paaswkr2 pod pod-projected-configmaps-f186f074-17ca-11e9-912e-6a405af5e95c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 07:06:43.495: INFO: Waiting for pod pod-projected-configmaps-f186f074-17ca-11e9-912e-6a405af5e95c to disappear
Jan 14 07:06:43.503: INFO: Pod pod-projected-configmaps-f186f074-17ca-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:06:43.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m5m9q" for this suite.
Jan 14 07:06:49.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:06:49.569: INFO: namespace: e2e-tests-projected-m5m9q, resource: bindings, ignored listing per whitelist
Jan 14 07:06:49.633: INFO: namespace e2e-tests-projected-m5m9q deletion completed in 6.122661147s

• [SLOW TEST:8.269 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:06:49.633: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 07:06:49.722: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:06:51.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ps47c" for this suite.
Jan 14 07:07:37.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:07:37.833: INFO: namespace: e2e-tests-pods-ps47c, resource: bindings, ignored listing per whitelist
Jan 14 07:07:37.900: INFO: namespace e2e-tests-pods-ps47c deletion completed in 46.10533011s

• [SLOW TEST:48.266 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:07:37.900: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-qvt4g
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qvt4g to expose endpoints map[]
Jan 14 07:07:37.997: INFO: Get endpoints failed (7.072577ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jan 14 07:07:39.001: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qvt4g exposes endpoints map[] (1.010196948s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-qvt4g
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qvt4g to expose endpoints map[pod1:[100]]
Jan 14 07:07:41.029: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qvt4g exposes endpoints map[pod1:[100]] (2.022697743s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-qvt4g
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qvt4g to expose endpoints map[pod1:[100] pod2:[101]]
Jan 14 07:07:44.065: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qvt4g exposes endpoints map[pod1:[100] pod2:[101]] (3.03126113s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-qvt4g
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qvt4g to expose endpoints map[pod2:[101]]
Jan 14 07:07:45.087: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qvt4g exposes endpoints map[pod2:[101]] (1.016901796s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-qvt4g
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qvt4g to expose endpoints map[]
Jan 14 07:07:45.096: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qvt4g exposes endpoints map[] (4.265761ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:07:45.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-qvt4g" for this suite.
Jan 14 07:08:07.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:08:07.242: INFO: namespace: e2e-tests-services-qvt4g, resource: bindings, ignored listing per whitelist
Jan 14 07:08:07.312: INFO: namespace e2e-tests-services-qvt4g deletion completed in 22.1728098s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.412 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:08:07.312: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 07:08:07.400: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24c07016-17cb-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-p4xlw" to be "success or failure"
Jan 14 07:08:07.409: INFO: Pod "downwardapi-volume-24c07016-17cb-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.737157ms
Jan 14 07:08:09.413: INFO: Pod "downwardapi-volume-24c07016-17cb-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012636003s
STEP: Saw pod success
Jan 14 07:08:09.413: INFO: Pod "downwardapi-volume-24c07016-17cb-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:08:09.416: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-24c07016-17cb-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 07:08:09.444: INFO: Waiting for pod downwardapi-volume-24c07016-17cb-11e9-912e-6a405af5e95c to disappear
Jan 14 07:08:09.447: INFO: Pod downwardapi-volume-24c07016-17cb-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:08:09.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p4xlw" for this suite.
Jan 14 07:08:15.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:08:15.493: INFO: namespace: e2e-tests-projected-p4xlw, resource: bindings, ignored listing per whitelist
Jan 14 07:08:15.548: INFO: namespace e2e-tests-projected-p4xlw deletion completed in 6.094760675s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:08:15.548: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-xrhn
STEP: Creating a pod to test atomic-volume-subpath
Jan 14 07:08:15.633: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xrhn" in namespace "e2e-tests-subpath-269hj" to be "success or failure"
Jan 14 07:08:15.653: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Pending", Reason="", readiness=false. Elapsed: 19.883649ms
Jan 14 07:08:17.656: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02279735s
Jan 14 07:08:19.660: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Running", Reason="", readiness=false. Elapsed: 4.027169802s
Jan 14 07:08:21.663: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Running", Reason="", readiness=false. Elapsed: 6.029750137s
Jan 14 07:08:23.666: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Running", Reason="", readiness=false. Elapsed: 8.03264469s
Jan 14 07:08:25.668: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Running", Reason="", readiness=false. Elapsed: 10.035439995s
Jan 14 07:08:27.672: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Running", Reason="", readiness=false. Elapsed: 12.038605641s
Jan 14 07:08:29.675: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Running", Reason="", readiness=false. Elapsed: 14.04232573s
Jan 14 07:08:31.679: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Running", Reason="", readiness=false. Elapsed: 16.045564894s
Jan 14 07:08:33.682: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Running", Reason="", readiness=false. Elapsed: 18.048692585s
Jan 14 07:08:35.685: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Running", Reason="", readiness=false. Elapsed: 20.051771932s
Jan 14 07:08:37.688: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Running", Reason="", readiness=false. Elapsed: 22.054864186s
Jan 14 07:08:39.691: INFO: Pod "pod-subpath-test-configmap-xrhn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057985863s
STEP: Saw pod success
Jan 14 07:08:39.691: INFO: Pod "pod-subpath-test-configmap-xrhn" satisfied condition "success or failure"
Jan 14 07:08:39.694: INFO: Trying to get logs from node paaswkr2 pod pod-subpath-test-configmap-xrhn container test-container-subpath-configmap-xrhn: <nil>
STEP: delete the pod
Jan 14 07:08:39.737: INFO: Waiting for pod pod-subpath-test-configmap-xrhn to disappear
Jan 14 07:08:39.741: INFO: Pod pod-subpath-test-configmap-xrhn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xrhn
Jan 14 07:08:39.741: INFO: Deleting pod "pod-subpath-test-configmap-xrhn" in namespace "e2e-tests-subpath-269hj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:08:39.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-269hj" for this suite.
Jan 14 07:08:45.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:08:45.782: INFO: namespace: e2e-tests-subpath-269hj, resource: bindings, ignored listing per whitelist
Jan 14 07:08:45.839: INFO: namespace e2e-tests-subpath-269hj deletion completed in 6.089056959s

• [SLOW TEST:30.291 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:08:45.839: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 07:08:46.065: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"3b95f093-17cb-11e9-b726-525400ada096", Controller:(*bool)(0xc003713506), BlockOwnerDeletion:(*bool)(0xc003713507)}}
Jan 14 07:08:46.076: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3b94828c-17cb-11e9-b726-525400ada096", Controller:(*bool)(0xc0037138c6), BlockOwnerDeletion:(*bool)(0xc0037138c7)}}
Jan 14 07:08:46.090: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"3b9524fd-17cb-11e9-b726-525400ada096", Controller:(*bool)(0xc003713b5e), BlockOwnerDeletion:(*bool)(0xc003713b5f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:08:51.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7z2dw" for this suite.
Jan 14 07:08:57.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:08:57.216: INFO: namespace: e2e-tests-gc-7z2dw, resource: bindings, ignored listing per whitelist
Jan 14 07:08:57.261: INFO: namespace e2e-tests-gc-7z2dw deletion completed in 6.151856935s

• [SLOW TEST:11.422 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:08:57.261: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan 14 07:08:57.369: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-bxx2s" to be "success or failure"
Jan 14 07:08:57.377: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.446695ms
Jan 14 07:08:59.381: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011779884s
STEP: Saw pod success
Jan 14 07:08:59.381: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan 14 07:08:59.384: INFO: Trying to get logs from node paaswkr2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan 14 07:08:59.415: INFO: Waiting for pod pod-host-path-test to disappear
Jan 14 07:08:59.420: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:08:59.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-bxx2s" for this suite.
Jan 14 07:09:05.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:09:05.581: INFO: namespace: e2e-tests-hostpath-bxx2s, resource: bindings, ignored listing per whitelist
Jan 14 07:09:05.612: INFO: namespace e2e-tests-hostpath-bxx2s deletion completed in 6.182539151s

• [SLOW TEST:8.351 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:09:05.612: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-4782cbd0-17cb-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 07:09:05.730: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4784328f-17cb-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-dbpv7" to be "success or failure"
Jan 14 07:09:05.744: INFO: Pod "pod-projected-secrets-4784328f-17cb-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.47173ms
Jan 14 07:09:07.747: INFO: Pod "pod-projected-secrets-4784328f-17cb-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016952586s
STEP: Saw pod success
Jan 14 07:09:07.747: INFO: Pod "pod-projected-secrets-4784328f-17cb-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:09:07.750: INFO: Trying to get logs from node paaswkr2 pod pod-projected-secrets-4784328f-17cb-11e9-912e-6a405af5e95c container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 14 07:09:07.773: INFO: Waiting for pod pod-projected-secrets-4784328f-17cb-11e9-912e-6a405af5e95c to disappear
Jan 14 07:09:07.777: INFO: Pod pod-projected-secrets-4784328f-17cb-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:09:07.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dbpv7" for this suite.
Jan 14 07:09:13.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:09:13.883: INFO: namespace: e2e-tests-projected-dbpv7, resource: bindings, ignored listing per whitelist
Jan 14 07:09:13.886: INFO: namespace e2e-tests-projected-dbpv7 deletion completed in 6.101025801s

• [SLOW TEST:8.274 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:09:13.886: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-bz94z
Jan 14 07:09:15.989: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-bz94z
STEP: checking the pod's current state and verifying that restartCount is present
Jan 14 07:09:15.995: INFO: Initial restart count of pod liveness-exec is 0
Jan 14 07:10:06.100: INFO: Restart count of pod e2e-tests-container-probe-bz94z/liveness-exec is now 1 (50.104725468s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:10:06.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bz94z" for this suite.
Jan 14 07:10:12.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:10:12.188: INFO: namespace: e2e-tests-container-probe-bz94z, resource: bindings, ignored listing per whitelist
Jan 14 07:10:12.216: INFO: namespace e2e-tests-container-probe-bz94z deletion completed in 6.092718019s

• [SLOW TEST:58.330 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:10:12.216: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 07:10:12.303: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f33b5f7-17cb-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-lpd44" to be "success or failure"
Jan 14 07:10:12.312: INFO: Pod "downwardapi-volume-6f33b5f7-17cb-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.121712ms
Jan 14 07:10:14.316: INFO: Pod "downwardapi-volume-6f33b5f7-17cb-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013434283s
STEP: Saw pod success
Jan 14 07:10:14.316: INFO: Pod "downwardapi-volume-6f33b5f7-17cb-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:10:14.321: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-6f33b5f7-17cb-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 07:10:14.344: INFO: Waiting for pod downwardapi-volume-6f33b5f7-17cb-11e9-912e-6a405af5e95c to disappear
Jan 14 07:10:14.354: INFO: Pod downwardapi-volume-6f33b5f7-17cb-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:10:14.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lpd44" for this suite.
Jan 14 07:10:20.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:10:20.423: INFO: namespace: e2e-tests-downward-api-lpd44, resource: bindings, ignored listing per whitelist
Jan 14 07:10:20.484: INFO: namespace e2e-tests-downward-api-lpd44 deletion completed in 6.123810756s

• [SLOW TEST:8.267 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:10:20.484: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:10:42.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-r7gw6" for this suite.
Jan 14 07:10:48.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:10:48.875: INFO: namespace: e2e-tests-container-runtime-r7gw6, resource: bindings, ignored listing per whitelist
Jan 14 07:10:48.900: INFO: namespace e2e-tests-container-runtime-r7gw6 deletion completed in 6.109147203s

• [SLOW TEST:28.416 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:10:48.900: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 14 07:10:48.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-krsqv'
Jan 14 07:10:49.177: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 14 07:10:49.177: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Jan 14 07:10:53.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-krsqv'
Jan 14 07:10:53.284: INFO: stderr: ""
Jan 14 07:10:53.284: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:10:53.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-krsqv" for this suite.
Jan 14 07:10:59.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:10:59.405: INFO: namespace: e2e-tests-kubectl-krsqv, resource: bindings, ignored listing per whitelist
Jan 14 07:10:59.428: INFO: namespace e2e-tests-kubectl-krsqv deletion completed in 6.103129054s

• [SLOW TEST:10.529 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:10:59.428: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 14 07:10:59.516: INFO: Waiting up to 5m0s for pod "pod-8b579b37-17cb-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-6cbns" to be "success or failure"
Jan 14 07:10:59.522: INFO: Pod "pod-8b579b37-17cb-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.091067ms
Jan 14 07:11:01.527: INFO: Pod "pod-8b579b37-17cb-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011049499s
STEP: Saw pod success
Jan 14 07:11:01.527: INFO: Pod "pod-8b579b37-17cb-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:11:01.531: INFO: Trying to get logs from node paaswkr2 pod pod-8b579b37-17cb-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 07:11:01.556: INFO: Waiting for pod pod-8b579b37-17cb-11e9-912e-6a405af5e95c to disappear
Jan 14 07:11:01.560: INFO: Pod pod-8b579b37-17cb-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:11:01.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6cbns" for this suite.
Jan 14 07:11:07.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:11:07.598: INFO: namespace: e2e-tests-emptydir-6cbns, resource: bindings, ignored listing per whitelist
Jan 14 07:11:07.658: INFO: namespace e2e-tests-emptydir-6cbns deletion completed in 6.093014806s

• [SLOW TEST:8.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:11:07.658: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 07:11:07.733: INFO: Waiting up to 5m0s for pod "downwardapi-volume-903d5ac9-17cb-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-c27np" to be "success or failure"
Jan 14 07:11:07.737: INFO: Pod "downwardapi-volume-903d5ac9-17cb-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.705888ms
Jan 14 07:11:09.746: INFO: Pod "downwardapi-volume-903d5ac9-17cb-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012962566s
STEP: Saw pod success
Jan 14 07:11:09.746: INFO: Pod "downwardapi-volume-903d5ac9-17cb-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:11:09.750: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-903d5ac9-17cb-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 07:11:09.785: INFO: Waiting for pod downwardapi-volume-903d5ac9-17cb-11e9-912e-6a405af5e95c to disappear
Jan 14 07:11:09.787: INFO: Pod downwardapi-volume-903d5ac9-17cb-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:11:09.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c27np" for this suite.
Jan 14 07:11:15.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:11:15.877: INFO: namespace: e2e-tests-projected-c27np, resource: bindings, ignored listing per whitelist
Jan 14 07:11:15.880: INFO: namespace e2e-tests-projected-c27np deletion completed in 6.088315377s

• [SLOW TEST:8.222 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:11:15.881: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-9523c1b3-17cb-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume configMaps
Jan 14 07:11:15.963: INFO: Waiting up to 5m0s for pod "pod-configmaps-9524903e-17cb-11e9-912e-6a405af5e95c" in namespace "e2e-tests-configmap-skkqt" to be "success or failure"
Jan 14 07:11:15.969: INFO: Pod "pod-configmaps-9524903e-17cb-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.793664ms
Jan 14 07:11:17.974: INFO: Pod "pod-configmaps-9524903e-17cb-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011758401s
STEP: Saw pod success
Jan 14 07:11:17.975: INFO: Pod "pod-configmaps-9524903e-17cb-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:11:17.979: INFO: Trying to get logs from node paaswkr2 pod pod-configmaps-9524903e-17cb-11e9-912e-6a405af5e95c container configmap-volume-test: <nil>
STEP: delete the pod
Jan 14 07:11:18.017: INFO: Waiting for pod pod-configmaps-9524903e-17cb-11e9-912e-6a405af5e95c to disappear
Jan 14 07:11:18.022: INFO: Pod pod-configmaps-9524903e-17cb-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:11:18.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-skkqt" for this suite.
Jan 14 07:11:24.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:11:24.113: INFO: namespace: e2e-tests-configmap-skkqt, resource: bindings, ignored listing per whitelist
Jan 14 07:11:24.118: INFO: namespace e2e-tests-configmap-skkqt deletion completed in 6.09031089s

• [SLOW TEST:8.237 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:11:24.118: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-wf2p8
Jan 14 07:11:26.204: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-wf2p8
STEP: checking the pod's current state and verifying that restartCount is present
Jan 14 07:11:26.208: INFO: Initial restart count of pod liveness-http is 0
Jan 14 07:11:48.252: INFO: Restart count of pod e2e-tests-container-probe-wf2p8/liveness-http is now 1 (22.043620827s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:11:48.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wf2p8" for this suite.
Jan 14 07:11:54.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:11:54.419: INFO: namespace: e2e-tests-container-probe-wf2p8, resource: bindings, ignored listing per whitelist
Jan 14 07:11:54.440: INFO: namespace e2e-tests-container-probe-wf2p8 deletion completed in 6.160165334s

• [SLOW TEST:30.322 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:11:54.440: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-lf2f2 in namespace e2e-tests-proxy-l6mc5
I0114 07:11:54.561465      13 runners.go:184] Created replication controller with name: proxy-service-lf2f2, namespace: e2e-tests-proxy-l6mc5, replica count: 1
I0114 07:11:55.615625      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0114 07:11:56.616787      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0114 07:11:57.617464      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0114 07:11:58.618050      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0114 07:11:59.618177      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0114 07:12:00.618747      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0114 07:12:01.618872      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0114 07:12:02.619494      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0114 07:12:03.619587      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0114 07:12:04.620281      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0114 07:12:05.620865      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0114 07:12:06.621008      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0114 07:12:07.621587      13 runners.go:184] proxy-service-lf2f2 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 14 07:12:07.626: INFO: setup took 13.085868745s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan 14 07:12:07.646: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 20.754781ms)
Jan 14 07:12:07.668: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 41.991086ms)
Jan 14 07:12:07.668: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 42.574052ms)
Jan 14 07:12:07.668: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 42.494317ms)
Jan 14 07:12:07.676: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 49.70921ms)
Jan 14 07:12:07.680: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 53.59133ms)
Jan 14 07:12:07.680: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 53.815269ms)
Jan 14 07:12:07.698: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 70.957357ms)
Jan 14 07:12:07.702: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 75.801963ms)
Jan 14 07:12:07.702: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 75.71361ms)
Jan 14 07:12:07.702: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 75.02125ms)
Jan 14 07:12:07.711: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 83.605679ms)
Jan 14 07:12:07.711: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 83.966288ms)
Jan 14 07:12:07.712: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 85.498475ms)
Jan 14 07:12:07.713: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 86.127756ms)
Jan 14 07:12:07.713: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 85.55625ms)
Jan 14 07:12:07.720: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 7.350727ms)
Jan 14 07:12:07.729: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 9.819105ms)
Jan 14 07:12:07.730: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 11.515695ms)
Jan 14 07:12:07.730: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 10.613965ms)
Jan 14 07:12:07.730: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 11.526172ms)
Jan 14 07:12:07.732: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 13.046566ms)
Jan 14 07:12:07.732: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 12.537774ms)
Jan 14 07:12:07.732: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 12.920192ms)
Jan 14 07:12:07.733: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 13.970374ms)
Jan 14 07:12:07.733: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 13.036777ms)
Jan 14 07:12:07.734: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 14.313412ms)
Jan 14 07:12:07.734: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 14.376514ms)
Jan 14 07:12:07.734: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 14.271915ms)
Jan 14 07:12:07.735: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 15.855529ms)
Jan 14 07:12:07.744: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 25.254773ms)
Jan 14 07:12:07.744: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 30.474244ms)
Jan 14 07:12:07.770: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 25.503573ms)
Jan 14 07:12:07.770: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 24.806428ms)
Jan 14 07:12:07.770: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 22.88735ms)
Jan 14 07:12:07.774: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 29.525145ms)
Jan 14 07:12:07.774: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 26.887135ms)
Jan 14 07:12:07.774: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 28.844355ms)
Jan 14 07:12:07.774: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 30.115191ms)
Jan 14 07:12:07.774: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 28.164764ms)
Jan 14 07:12:07.774: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 29.460848ms)
Jan 14 07:12:07.774: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 27.555653ms)
Jan 14 07:12:07.774: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 30.430617ms)
Jan 14 07:12:07.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 32.241507ms)
Jan 14 07:12:07.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 31.657087ms)
Jan 14 07:12:07.781: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 35.791004ms)
Jan 14 07:12:07.781: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 34.568183ms)
Jan 14 07:12:07.781: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 34.017682ms)
Jan 14 07:12:07.796: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 13.401415ms)
Jan 14 07:12:07.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 17.216681ms)
Jan 14 07:12:07.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 17.829653ms)
Jan 14 07:12:07.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 18.767228ms)
Jan 14 07:12:07.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 16.860597ms)
Jan 14 07:12:07.801: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 17.713675ms)
Jan 14 07:12:07.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 27.947761ms)
Jan 14 07:12:07.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 27.278983ms)
Jan 14 07:12:07.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 27.649138ms)
Jan 14 07:12:07.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 26.821986ms)
Jan 14 07:12:07.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 26.933438ms)
Jan 14 07:12:07.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 25.832399ms)
Jan 14 07:12:07.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 26.707083ms)
Jan 14 07:12:07.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 27.223787ms)
Jan 14 07:12:07.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 26.797113ms)
Jan 14 07:12:07.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 26.414041ms)
Jan 14 07:12:07.827: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 17.114283ms)
Jan 14 07:12:07.836: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 25.781812ms)
Jan 14 07:12:07.836: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 26.327559ms)
Jan 14 07:12:07.836: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 25.88717ms)
Jan 14 07:12:07.836: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 25.935945ms)
Jan 14 07:12:07.837: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 26.361287ms)
Jan 14 07:12:07.837: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 26.674761ms)
Jan 14 07:12:07.838: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 28.982098ms)
Jan 14 07:12:07.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 29.00827ms)
Jan 14 07:12:07.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 28.300111ms)
Jan 14 07:12:07.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 28.420379ms)
Jan 14 07:12:07.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 28.907652ms)
Jan 14 07:12:07.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 28.823009ms)
Jan 14 07:12:07.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 28.302675ms)
Jan 14 07:12:07.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 28.773572ms)
Jan 14 07:12:07.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 28.623724ms)
Jan 14 07:12:07.870: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 30.440816ms)
Jan 14 07:12:07.874: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 33.480724ms)
Jan 14 07:12:07.874: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 34.446737ms)
Jan 14 07:12:07.874: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 34.277287ms)
Jan 14 07:12:07.874: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 33.954512ms)
Jan 14 07:12:07.874: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 33.905108ms)
Jan 14 07:12:07.874: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 34.746689ms)
Jan 14 07:12:07.874: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 34.640964ms)
Jan 14 07:12:07.874: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 34.43843ms)
Jan 14 07:12:07.874: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 33.819681ms)
Jan 14 07:12:07.874: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 34.429502ms)
Jan 14 07:12:07.876: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 35.431977ms)
Jan 14 07:12:07.876: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 36.499076ms)
Jan 14 07:12:07.882: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 41.822846ms)
Jan 14 07:12:07.882: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 41.787761ms)
Jan 14 07:12:07.882: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 42.229335ms)
Jan 14 07:12:07.893: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 9.831082ms)
Jan 14 07:12:07.894: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 10.908913ms)
Jan 14 07:12:07.898: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 15.419126ms)
Jan 14 07:12:07.909: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 25.333327ms)
Jan 14 07:12:07.909: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 25.142988ms)
Jan 14 07:12:07.909: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 25.265495ms)
Jan 14 07:12:07.909: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 26.855228ms)
Jan 14 07:12:07.909: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 26.671384ms)
Jan 14 07:12:07.909: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 24.870594ms)
Jan 14 07:12:07.910: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 27.445412ms)
Jan 14 07:12:07.910: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 26.760924ms)
Jan 14 07:12:07.910: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 26.376833ms)
Jan 14 07:12:07.910: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 27.591053ms)
Jan 14 07:12:07.911: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 27.733002ms)
Jan 14 07:12:07.911: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 26.798222ms)
Jan 14 07:12:07.920: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 36.259676ms)
Jan 14 07:12:07.931: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 10.659469ms)
Jan 14 07:12:07.939: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 17.344477ms)
Jan 14 07:12:07.946: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 24.238794ms)
Jan 14 07:12:07.946: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 24.195016ms)
Jan 14 07:12:07.947: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 24.686521ms)
Jan 14 07:12:07.947: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 25.058685ms)
Jan 14 07:12:07.947: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 25.18461ms)
Jan 14 07:12:07.947: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 25.831989ms)
Jan 14 07:12:07.947: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 24.105524ms)
Jan 14 07:12:07.947: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 24.385963ms)
Jan 14 07:12:07.947: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 25.028977ms)
Jan 14 07:12:07.947: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 25.791742ms)
Jan 14 07:12:07.947: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 25.699918ms)
Jan 14 07:12:07.947: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 25.559161ms)
Jan 14 07:12:07.947: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 24.903735ms)
Jan 14 07:12:07.948: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 26.018172ms)
Jan 14 07:12:07.962: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 13.220316ms)
Jan 14 07:12:07.964: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 16.260349ms)
Jan 14 07:12:07.964: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 14.625299ms)
Jan 14 07:12:07.964: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 16.047923ms)
Jan 14 07:12:07.964: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 14.489208ms)
Jan 14 07:12:07.966: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 16.802833ms)
Jan 14 07:12:07.966: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 16.956669ms)
Jan 14 07:12:07.966: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 16.74241ms)
Jan 14 07:12:07.966: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 17.549228ms)
Jan 14 07:12:07.966: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 15.919658ms)
Jan 14 07:12:07.966: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 16.671502ms)
Jan 14 07:12:07.974: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 25.868282ms)
Jan 14 07:12:07.975: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 26.630037ms)
Jan 14 07:12:07.975: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 25.387818ms)
Jan 14 07:12:07.975: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 25.259405ms)
Jan 14 07:12:07.975: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 26.137836ms)
Jan 14 07:12:07.985: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 10.632524ms)
Jan 14 07:12:07.989: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 14.280828ms)
Jan 14 07:12:07.989: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 13.641887ms)
Jan 14 07:12:07.989: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 13.552267ms)
Jan 14 07:12:07.989: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 14.107229ms)
Jan 14 07:12:07.993: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 17.103924ms)
Jan 14 07:12:07.999: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 24.013292ms)
Jan 14 07:12:07.999: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 23.500784ms)
Jan 14 07:12:08.004: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 27.467334ms)
Jan 14 07:12:08.004: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 27.787508ms)
Jan 14 07:12:08.004: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 27.652079ms)
Jan 14 07:12:08.004: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 27.481655ms)
Jan 14 07:12:08.004: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 27.461066ms)
Jan 14 07:12:08.004: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 28.021687ms)
Jan 14 07:12:08.004: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 28.351978ms)
Jan 14 07:12:08.004: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 28.826402ms)
Jan 14 07:12:08.020: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 15.780672ms)
Jan 14 07:12:08.020: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 14.935137ms)
Jan 14 07:12:08.020: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 15.299526ms)
Jan 14 07:12:08.021: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 16.104203ms)
Jan 14 07:12:08.021: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 12.575027ms)
Jan 14 07:12:08.021: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 16.813833ms)
Jan 14 07:12:08.021: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 12.953792ms)
Jan 14 07:12:08.021: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 16.415322ms)
Jan 14 07:12:08.021: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 16.749579ms)
Jan 14 07:12:08.021: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 13.243215ms)
Jan 14 07:12:08.027: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 23.145157ms)
Jan 14 07:12:08.027: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 23.070349ms)
Jan 14 07:12:08.031: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 26.099413ms)
Jan 14 07:12:08.031: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 26.980477ms)
Jan 14 07:12:08.031: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 26.055123ms)
Jan 14 07:12:08.031: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 26.769367ms)
Jan 14 07:12:08.042: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 10.770898ms)
Jan 14 07:12:08.043: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 10.924418ms)
Jan 14 07:12:08.043: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 11.236744ms)
Jan 14 07:12:08.043: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 11.408038ms)
Jan 14 07:12:08.043: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 11.491362ms)
Jan 14 07:12:08.044: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 12.217511ms)
Jan 14 07:12:08.044: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 11.909867ms)
Jan 14 07:12:08.052: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 20.813006ms)
Jan 14 07:12:08.052: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 21.117892ms)
Jan 14 07:12:08.052: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 21.268999ms)
Jan 14 07:12:08.052: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 20.96603ms)
Jan 14 07:12:08.053: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 21.182341ms)
Jan 14 07:12:08.053: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 21.270114ms)
Jan 14 07:12:08.058: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 26.907291ms)
Jan 14 07:12:08.058: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 27.269844ms)
Jan 14 07:12:08.058: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 26.252844ms)
Jan 14 07:12:08.076: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 17.068154ms)
Jan 14 07:12:08.076: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 16.727096ms)
Jan 14 07:12:08.076: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 16.817649ms)
Jan 14 07:12:08.076: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 16.761114ms)
Jan 14 07:12:08.079: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 19.441936ms)
Jan 14 07:12:08.079: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 20.287238ms)
Jan 14 07:12:08.079: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 19.624302ms)
Jan 14 07:12:08.079: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 19.710143ms)
Jan 14 07:12:08.079: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 19.560956ms)
Jan 14 07:12:08.079: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 19.484008ms)
Jan 14 07:12:08.079: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 20.183885ms)
Jan 14 07:12:08.079: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 20.288601ms)
Jan 14 07:12:08.079: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 20.891597ms)
Jan 14 07:12:08.079: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 20.630403ms)
Jan 14 07:12:08.079: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 20.420771ms)
Jan 14 07:12:08.094: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 35.371555ms)
Jan 14 07:12:08.104: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 10.038481ms)
Jan 14 07:12:08.105: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 8.805347ms)
Jan 14 07:12:08.105: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 9.167857ms)
Jan 14 07:12:08.111: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 16.07756ms)
Jan 14 07:12:08.111: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 15.087311ms)
Jan 14 07:12:08.111: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 16.798991ms)
Jan 14 07:12:08.111: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 14.923833ms)
Jan 14 07:12:08.111: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 16.38471ms)
Jan 14 07:12:08.111: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 16.313179ms)
Jan 14 07:12:08.111: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 16.167147ms)
Jan 14 07:12:08.111: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 16.554359ms)
Jan 14 07:12:08.117: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 22.85755ms)
Jan 14 07:12:08.117: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 21.644832ms)
Jan 14 07:12:08.117: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 22.864087ms)
Jan 14 07:12:08.117: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 21.451779ms)
Jan 14 07:12:08.117: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 21.497787ms)
Jan 14 07:12:08.129: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 11.005442ms)
Jan 14 07:12:08.129: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 11.367725ms)
Jan 14 07:12:08.130: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 12.622164ms)
Jan 14 07:12:08.130: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 12.797561ms)
Jan 14 07:12:08.131: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 12.035213ms)
Jan 14 07:12:08.131: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 13.160216ms)
Jan 14 07:12:08.131: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 12.801808ms)
Jan 14 07:12:08.131: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 12.620705ms)
Jan 14 07:12:08.132: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 14.752414ms)
Jan 14 07:12:08.132: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 13.984978ms)
Jan 14 07:12:08.132: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 14.475522ms)
Jan 14 07:12:08.140: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 21.405641ms)
Jan 14 07:12:08.140: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 22.481241ms)
Jan 14 07:12:08.140: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 21.880031ms)
Jan 14 07:12:08.140: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 21.980955ms)
Jan 14 07:12:08.144: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 25.04493ms)
Jan 14 07:12:08.154: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 10.339376ms)
Jan 14 07:12:08.154: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 10.466467ms)
Jan 14 07:12:08.155: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 10.854093ms)
Jan 14 07:12:08.155: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 10.606245ms)
Jan 14 07:12:08.155: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 10.963105ms)
Jan 14 07:12:08.159: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 14.730747ms)
Jan 14 07:12:08.166: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 21.109389ms)
Jan 14 07:12:08.166: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 21.118911ms)
Jan 14 07:12:08.166: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 20.974897ms)
Jan 14 07:12:08.166: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 21.983395ms)
Jan 14 07:12:08.166: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 21.733646ms)
Jan 14 07:12:08.170: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 25.227078ms)
Jan 14 07:12:08.170: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 25.789205ms)
Jan 14 07:12:08.170: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 26.504424ms)
Jan 14 07:12:08.170: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 25.158643ms)
Jan 14 07:12:08.170: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 25.244371ms)
Jan 14 07:12:08.183: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 12.75474ms)
Jan 14 07:12:08.183: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 11.690454ms)
Jan 14 07:12:08.183: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 12.152892ms)
Jan 14 07:12:08.183: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 11.572759ms)
Jan 14 07:12:08.183: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 12.070333ms)
Jan 14 07:12:08.183: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 11.720544ms)
Jan 14 07:12:08.183: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 12.670557ms)
Jan 14 07:12:08.186: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 14.74616ms)
Jan 14 07:12:08.186: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 15.592225ms)
Jan 14 07:12:08.186: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 14.14898ms)
Jan 14 07:12:08.188: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 16.31465ms)
Jan 14 07:12:08.188: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 16.452341ms)
Jan 14 07:12:08.188: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 17.496762ms)
Jan 14 07:12:08.193: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 21.903206ms)
Jan 14 07:12:08.193: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 22.044647ms)
Jan 14 07:12:08.193: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 22.313975ms)
Jan 14 07:12:08.209: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 13.87187ms)
Jan 14 07:12:08.209: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 15.035214ms)
Jan 14 07:12:08.209: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 13.917007ms)
Jan 14 07:12:08.209: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 15.946205ms)
Jan 14 07:12:08.209: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 16.114419ms)
Jan 14 07:12:08.209: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 14.451068ms)
Jan 14 07:12:08.210: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 16.202731ms)
Jan 14 07:12:08.210: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 14.774674ms)
Jan 14 07:12:08.211: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 17.122127ms)
Jan 14 07:12:08.212: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 19.172378ms)
Jan 14 07:12:08.212: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 18.022985ms)
Jan 14 07:12:08.212: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 17.878186ms)
Jan 14 07:12:08.212: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 17.215179ms)
Jan 14 07:12:08.212: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 19.163923ms)
Jan 14 07:12:08.212: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 18.603914ms)
Jan 14 07:12:08.218: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 23.148614ms)
Jan 14 07:12:08.231: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 12.391082ms)
Jan 14 07:12:08.231: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 13.381054ms)
Jan 14 07:12:08.232: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 12.383038ms)
Jan 14 07:12:08.232: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 13.768028ms)
Jan 14 07:12:08.241: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 21.367248ms)
Jan 14 07:12:08.241: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 21.276627ms)
Jan 14 07:12:08.241: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 22.054516ms)
Jan 14 07:12:08.241: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 21.615708ms)
Jan 14 07:12:08.245: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 25.290897ms)
Jan 14 07:12:08.245: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 25.922102ms)
Jan 14 07:12:08.245: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 26.532839ms)
Jan 14 07:12:08.245: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 25.606362ms)
Jan 14 07:12:08.245: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 26.460917ms)
Jan 14 07:12:08.245: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 26.368837ms)
Jan 14 07:12:08.245: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 25.684497ms)
Jan 14 07:12:08.245: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 26.700783ms)
Jan 14 07:12:08.256: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 9.549609ms)
Jan 14 07:12:08.257: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:1080/proxy/rewri... (200; 10.374652ms)
Jan 14 07:12:08.257: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:460/proxy/: tls baz (200; 10.88369ms)
Jan 14 07:12:08.257: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:162/proxy/: bar (200; 12.037568ms)
Jan 14 07:12:08.257: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 11.253324ms)
Jan 14 07:12:08.257: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:160/proxy/: foo (200; 10.992483ms)
Jan 14 07:12:08.258: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:462/proxy/: tls qux (200; 11.085246ms)
Jan 14 07:12:08.258: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname2/proxy/: tls qux (200; 11.04568ms)
Jan 14 07:12:08.258: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/proxy-service-lf2f2-7xjtf/proxy/rewriteme"... (200; 11.813504ms)
Jan 14 07:12:08.261: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/https:proxy-service-lf2f2-7xjtf:443/proxy/... (200; 14.891277ms)
Jan 14 07:12:08.264: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-l6mc5/pods/http:proxy-service-lf2f2-7xjtf:1080/proxy/... (200; 17.94007ms)
Jan 14 07:12:08.264: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname1/proxy/: foo (200; 17.840296ms)
Jan 14 07:12:08.268: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname1/proxy/: foo (200; 22.302892ms)
Jan 14 07:12:08.268: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/http:proxy-service-lf2f2:portname2/proxy/: bar (200; 22.198507ms)
Jan 14 07:12:08.268: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/proxy-service-lf2f2:portname2/proxy/: bar (200; 21.953203ms)
Jan 14 07:12:08.268: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-l6mc5/services/https:proxy-service-lf2f2:tlsportname1/proxy/: tls baz (200; 21.582588ms)
STEP: deleting ReplicationController proxy-service-lf2f2 in namespace e2e-tests-proxy-l6mc5, will wait for the garbage collector to delete the pods
Jan 14 07:12:08.327: INFO: Deleting ReplicationController proxy-service-lf2f2 took: 5.373166ms
Jan 14 07:12:08.429: INFO: Terminating ReplicationController proxy-service-lf2f2 pods took: 101.657651ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:12:16.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-l6mc5" for this suite.
Jan 14 07:12:22.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:12:22.613: INFO: namespace: e2e-tests-proxy-l6mc5, resource: bindings, ignored listing per whitelist
Jan 14 07:12:22.630: INFO: namespace e2e-tests-proxy-l6mc5 deletion completed in 6.095876057s

• [SLOW TEST:28.190 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:12:22.630: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-bcef3ea0-17cb-11e9-912e-6a405af5e95c
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:12:24.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ldrmh" for this suite.
Jan 14 07:12:46.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:12:46.842: INFO: namespace: e2e-tests-configmap-ldrmh, resource: bindings, ignored listing per whitelist
Jan 14 07:12:46.853: INFO: namespace e2e-tests-configmap-ldrmh deletion completed in 22.102938878s

• [SLOW TEST:24.222 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:12:46.853: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 14 07:12:46.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-v7fqx'
Jan 14 07:12:47.034: INFO: stderr: ""
Jan 14 07:12:47.034: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Jan 14 07:12:47.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-v7fqx'
Jan 14 07:12:56.425: INFO: stderr: ""
Jan 14 07:12:56.425: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:12:56.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v7fqx" for this suite.
Jan 14 07:13:02.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:13:02.506: INFO: namespace: e2e-tests-kubectl-v7fqx, resource: bindings, ignored listing per whitelist
Jan 14 07:13:02.549: INFO: namespace e2e-tests-kubectl-v7fqx deletion completed in 6.11703214s

• [SLOW TEST:15.696 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:13:02.549: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan 14 07:13:10.659: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2bwbt PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 07:13:10.659: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 07:13:11.254: INFO: Exec stderr: ""
Jan 14 07:13:11.254: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2bwbt PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 07:13:11.254: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 07:13:11.483: INFO: Exec stderr: ""
Jan 14 07:13:11.483: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2bwbt PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 07:13:11.483: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 07:13:11.620: INFO: Exec stderr: ""
Jan 14 07:13:11.620: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2bwbt PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 07:13:11.620: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 07:13:11.811: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan 14 07:13:11.811: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2bwbt PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 07:13:11.811: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 07:13:11.971: INFO: Exec stderr: ""
Jan 14 07:13:11.971: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2bwbt PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 07:13:11.971: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 07:13:12.126: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan 14 07:13:12.126: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2bwbt PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 07:13:12.126: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 07:13:12.257: INFO: Exec stderr: ""
Jan 14 07:13:12.257: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2bwbt PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 07:13:12.257: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 07:13:12.418: INFO: Exec stderr: ""
Jan 14 07:13:12.418: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2bwbt PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 07:13:12.418: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 07:13:12.553: INFO: Exec stderr: ""
Jan 14 07:13:12.553: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2bwbt PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 14 07:13:12.553: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
Jan 14 07:13:12.739: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:13:12.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-2bwbt" for this suite.
Jan 14 07:14:02.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:14:02.877: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-2bwbt, resource: bindings, ignored listing per whitelist
Jan 14 07:14:02.911: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-2bwbt deletion completed in 50.166018538s

• [SLOW TEST:60.363 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:14:02.912: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 14 07:14:03.020: INFO: Waiting up to 5m0s for pod "pod-f8b8099d-17cb-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-ttttk" to be "success or failure"
Jan 14 07:14:03.027: INFO: Pod "pod-f8b8099d-17cb-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.65275ms
Jan 14 07:14:05.033: INFO: Pod "pod-f8b8099d-17cb-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012877263s
STEP: Saw pod success
Jan 14 07:14:05.033: INFO: Pod "pod-f8b8099d-17cb-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:14:05.039: INFO: Trying to get logs from node paaswkr2 pod pod-f8b8099d-17cb-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 07:14:05.068: INFO: Waiting for pod pod-f8b8099d-17cb-11e9-912e-6a405af5e95c to disappear
Jan 14 07:14:05.072: INFO: Pod pod-f8b8099d-17cb-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:14:05.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ttttk" for this suite.
Jan 14 07:14:11.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:14:11.157: INFO: namespace: e2e-tests-emptydir-ttttk, resource: bindings, ignored listing per whitelist
Jan 14 07:14:11.168: INFO: namespace e2e-tests-emptydir-ttttk deletion completed in 6.090114141s

• [SLOW TEST:8.257 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:14:11.168: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 14 07:14:11.254: INFO: Waiting up to 5m0s for pod "pod-fda0ad27-17cb-11e9-912e-6a405af5e95c" in namespace "e2e-tests-emptydir-7z4vv" to be "success or failure"
Jan 14 07:14:11.259: INFO: Pod "pod-fda0ad27-17cb-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.390833ms
Jan 14 07:14:13.262: INFO: Pod "pod-fda0ad27-17cb-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007397582s
STEP: Saw pod success
Jan 14 07:14:13.262: INFO: Pod "pod-fda0ad27-17cb-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:14:13.265: INFO: Trying to get logs from node paaswkr2 pod pod-fda0ad27-17cb-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 07:14:13.283: INFO: Waiting for pod pod-fda0ad27-17cb-11e9-912e-6a405af5e95c to disappear
Jan 14 07:14:13.291: INFO: Pod pod-fda0ad27-17cb-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:14:13.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7z4vv" for this suite.
Jan 14 07:14:19.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:14:19.364: INFO: namespace: e2e-tests-emptydir-7z4vv, resource: bindings, ignored listing per whitelist
Jan 14 07:14:19.402: INFO: namespace e2e-tests-emptydir-7z4vv deletion completed in 6.101144845s

• [SLOW TEST:8.234 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:14:19.402: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 07:14:19.489: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0288eb1d-17cc-11e9-912e-6a405af5e95c" in namespace "e2e-tests-projected-zcl8x" to be "success or failure"
Jan 14 07:14:19.496: INFO: Pod "downwardapi-volume-0288eb1d-17cc-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.877404ms
Jan 14 07:14:21.502: INFO: Pod "downwardapi-volume-0288eb1d-17cc-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013697971s
STEP: Saw pod success
Jan 14 07:14:21.502: INFO: Pod "downwardapi-volume-0288eb1d-17cc-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:14:21.506: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-0288eb1d-17cc-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 07:14:21.525: INFO: Waiting for pod downwardapi-volume-0288eb1d-17cc-11e9-912e-6a405af5e95c to disappear
Jan 14 07:14:21.529: INFO: Pod downwardapi-volume-0288eb1d-17cc-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:14:21.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zcl8x" for this suite.
Jan 14 07:14:27.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:14:27.600: INFO: namespace: e2e-tests-projected-zcl8x, resource: bindings, ignored listing per whitelist
Jan 14 07:14:27.644: INFO: namespace e2e-tests-projected-zcl8x deletion completed in 6.108109424s

• [SLOW TEST:8.241 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:14:27.644: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-07734560-17cc-11e9-912e-6a405af5e95c
STEP: Creating a pod to test consume secrets
Jan 14 07:14:27.738: INFO: Waiting up to 5m0s for pod "pod-secrets-0774173e-17cc-11e9-912e-6a405af5e95c" in namespace "e2e-tests-secrets-nb6mq" to be "success or failure"
Jan 14 07:14:27.745: INFO: Pod "pod-secrets-0774173e-17cc-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.629174ms
Jan 14 07:14:29.749: INFO: Pod "pod-secrets-0774173e-17cc-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011327064s
STEP: Saw pod success
Jan 14 07:14:29.749: INFO: Pod "pod-secrets-0774173e-17cc-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:14:29.753: INFO: Trying to get logs from node paaswkr2 pod pod-secrets-0774173e-17cc-11e9-912e-6a405af5e95c container secret-volume-test: <nil>
STEP: delete the pod
Jan 14 07:14:29.783: INFO: Waiting for pod pod-secrets-0774173e-17cc-11e9-912e-6a405af5e95c to disappear
Jan 14 07:14:29.789: INFO: Pod pod-secrets-0774173e-17cc-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:14:29.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nb6mq" for this suite.
Jan 14 07:14:35.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:14:35.820: INFO: namespace: e2e-tests-secrets-nb6mq, resource: bindings, ignored listing per whitelist
Jan 14 07:14:35.896: INFO: namespace e2e-tests-secrets-nb6mq deletion completed in 6.099240884s

• [SLOW TEST:8.253 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:14:35.896: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 14 07:14:40.015: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:14:40.018: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:14:42.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:14:42.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:14:44.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:14:44.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:14:46.019: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:14:46.023: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:14:48.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:14:48.023: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:14:50.019: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:14:50.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:14:52.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:14:52.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:14:54.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:14:54.021: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:14:56.019: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:14:56.025: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:14:58.019: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:14:58.023: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:15:00.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:15:00.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:15:02.019: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:15:02.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:15:04.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:15:04.022: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:15:06.019: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:15:06.024: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 14 07:15:08.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 14 07:15:08.026: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:15:08.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-nwqjc" for this suite.
Jan 14 07:15:30.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:15:30.070: INFO: namespace: e2e-tests-container-lifecycle-hook-nwqjc, resource: bindings, ignored listing per whitelist
Jan 14 07:15:30.134: INFO: namespace e2e-tests-container-lifecycle-hook-nwqjc deletion completed in 22.09420637s

• [SLOW TEST:54.238 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:15:30.135: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 14 07:15:32.742: INFO: Successfully updated pod "labelsupdate2caf907d-17cc-11e9-912e-6a405af5e95c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:15:36.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2khhs" for this suite.
Jan 14 07:15:58.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:15:58.790: INFO: namespace: e2e-tests-downward-api-2khhs, resource: bindings, ignored listing per whitelist
Jan 14 07:15:58.852: INFO: namespace e2e-tests-downward-api-2khhs deletion completed in 22.086365618s

• [SLOW TEST:28.718 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:15:58.852: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-zb5d5
Jan 14 07:16:02.943: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-zb5d5
STEP: checking the pod's current state and verifying that restartCount is present
Jan 14 07:16:02.946: INFO: Initial restart count of pod liveness-http is 0
Jan 14 07:16:14.986: INFO: Restart count of pod e2e-tests-container-probe-zb5d5/liveness-http is now 1 (12.039785698s elapsed)
Jan 14 07:16:35.026: INFO: Restart count of pod e2e-tests-container-probe-zb5d5/liveness-http is now 2 (32.079743179s elapsed)
Jan 14 07:16:55.057: INFO: Restart count of pod e2e-tests-container-probe-zb5d5/liveness-http is now 3 (52.111015771s elapsed)
Jan 14 07:17:15.094: INFO: Restart count of pod e2e-tests-container-probe-zb5d5/liveness-http is now 4 (1m12.14797002s elapsed)
Jan 14 07:18:25.232: INFO: Restart count of pod e2e-tests-container-probe-zb5d5/liveness-http is now 5 (2m22.285676494s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:18:25.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zb5d5" for this suite.
Jan 14 07:18:31.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:18:31.338: INFO: namespace: e2e-tests-container-probe-zb5d5, resource: bindings, ignored listing per whitelist
Jan 14 07:18:31.372: INFO: namespace e2e-tests-container-probe-zb5d5 deletion completed in 6.110242563s

• [SLOW TEST:152.520 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:18:31.372: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 14 07:18:31.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jphd5'
Jan 14 07:18:31.554: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 14 07:18:31.554: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Jan 14 07:18:33.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-949281363 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-jphd5'
Jan 14 07:18:33.708: INFO: stderr: ""
Jan 14 07:18:33.708: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:18:33.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jphd5" for this suite.
Jan 14 07:18:39.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:18:39.799: INFO: namespace: e2e-tests-kubectl-jphd5, resource: bindings, ignored listing per whitelist
Jan 14 07:18:39.840: INFO: namespace e2e-tests-kubectl-jphd5 deletion completed in 6.125889721s

• [SLOW TEST:8.468 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:18:39.840: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:18:43.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-5n9d9" for this suite.
Jan 14 07:18:49.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:18:50.079: INFO: namespace: e2e-tests-kubelet-test-5n9d9, resource: bindings, ignored listing per whitelist
Jan 14 07:18:50.098: INFO: namespace e2e-tests-kubelet-test-5n9d9 deletion completed in 6.168767346s

• [SLOW TEST:10.258 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:18:50.098: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a3e4e0f2-17cc-11e9-912e-6a405af5e95c
STEP: Creating secret with name s-test-opt-upd-a3e4e12e-17cc-11e9-912e-6a405af5e95c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a3e4e0f2-17cc-11e9-912e-6a405af5e95c
STEP: Updating secret s-test-opt-upd-a3e4e12e-17cc-11e9-912e-6a405af5e95c
STEP: Creating secret with name s-test-opt-create-a3e4e142-17cc-11e9-912e-6a405af5e95c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:18:58.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wv88v" for this suite.
Jan 14 07:19:20.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:19:20.454: INFO: namespace: e2e-tests-projected-wv88v, resource: bindings, ignored listing per whitelist
Jan 14 07:19:20.500: INFO: namespace e2e-tests-projected-wv88v deletion completed in 22.117917862s

• [SLOW TEST:30.402 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:19:20.500: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-b6020bd4-17cc-11e9-912e-6a405af5e95c
STEP: Creating secret with name s-test-opt-upd-b6020c1c-17cc-11e9-912e-6a405af5e95c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b6020bd4-17cc-11e9-912e-6a405af5e95c
STEP: Updating secret s-test-opt-upd-b6020c1c-17cc-11e9-912e-6a405af5e95c
STEP: Creating secret with name s-test-opt-create-b6020c2f-17cc-11e9-912e-6a405af5e95c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:19:24.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jsbq2" for this suite.
Jan 14 07:19:46.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:19:46.795: INFO: namespace: e2e-tests-secrets-jsbq2, resource: bindings, ignored listing per whitelist
Jan 14 07:19:46.800: INFO: namespace e2e-tests-secrets-jsbq2 deletion completed in 22.117682715s

• [SLOW TEST:26.300 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:19:46.800: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-p8p75
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-p8p75
STEP: Deleting pre-stop pod
Jan 14 07:19:55.926: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:19:55.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-p8p75" for this suite.
Jan 14 07:20:33.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:20:34.024: INFO: namespace: e2e-tests-prestop-p8p75, resource: bindings, ignored listing per whitelist
Jan 14 07:20:34.047: INFO: namespace e2e-tests-prestop-p8p75 deletion completed in 38.101287586s

• [SLOW TEST:47.247 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:20:34.047: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 14 07:20:34.117: INFO: Creating deployment "nginx-deployment"
Jan 14 07:20:34.124: INFO: Waiting for observed generation 1
Jan 14 07:20:36.139: INFO: Waiting for all required pods to come up
Jan 14 07:20:36.143: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan 14 07:21:42.161: INFO: Waiting for deployment "nginx-deployment" to complete
Jan 14 07:21:42.168: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan 14 07:21:42.176: INFO: Updating deployment nginx-deployment
Jan 14 07:21:42.176: INFO: Waiting for observed generation 2
Jan 14 07:21:44.183: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 14 07:21:44.187: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 14 07:21:44.191: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 14 07:21:44.202: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 14 07:21:44.202: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 14 07:21:44.206: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 14 07:21:44.213: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan 14 07:21:44.213: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan 14 07:21:44.222: INFO: Updating deployment nginx-deployment
Jan 14 07:21:44.222: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan 14 07:21:44.239: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 14 07:21:44.250: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 14 07:21:46.285: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-2r56l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2r56l/deployments/nginx-deployment,UID:e1a188d9-17cc-11e9-b726-525400ada096,ResourceVersion:70032,Generation:3,CreationTimestamp:2019-01-14 07:20:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-01-14 07:21:43 +0000 UTC 2019-01-14 07:21:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-14 07:21:44 +0000 UTC 2019-01-14 07:20:33 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan 14 07:21:46.291: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-2r56l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2r56l/replicasets/nginx-deployment-65bbdb5f8,UID:0a3264a2-17cd-11e9-b726-525400ada096,ResourceVersion:70028,Generation:3,CreationTimestamp:2019-01-14 07:21:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment e1a188d9-17cc-11e9-b726-525400ada096 0xc00251bc97 0xc00251bc98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 14 07:21:46.291: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan 14 07:21:46.291: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-2r56l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2r56l/replicasets/nginx-deployment-555b55d965,UID:e1a362ab-17cc-11e9-b726-525400ada096,ResourceVersion:70026,Generation:3,CreationTimestamp:2019-01-14 07:20:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment e1a188d9-17cc-11e9-b726-525400ada096 0xc00251bb27 0xc00251bb28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan 14 07:21:46.306: INFO: Pod "nginx-deployment-555b55d965-28bgv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-28bgv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-28bgv,UID:0b7c0347-17cd-11e9-b726-525400ada096,ResourceVersion:70017,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc0017cc877 0xc0017cc878}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017cc8f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017cc9b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.306: INFO: Pod "nginx-deployment-555b55d965-6l57s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6l57s,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-6l57s,UID:0b7bc520-17cd-11e9-b726-525400ada096,ResourceVersion:70020,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc0017cca20 0xc0017cca21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017cca90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017ccab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.306: INFO: Pod "nginx-deployment-555b55d965-6t9bt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6t9bt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-6t9bt,UID:0b6e4b30-17cd-11e9-b726-525400ada096,ResourceVersion:70056,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc0017ccb30 0xc0017ccb31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017ccc60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017ccc80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.306: INFO: Pod "nginx-deployment-555b55d965-76dzd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-76dzd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-76dzd,UID:e1afa5d4-17cc-11e9-b726-525400ada096,ResourceVersion:69712,Generation:0,CreationTimestamp:2019-01-14 07:20:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc0017ccd37 0xc0017ccd38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017cce60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017cce80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:10.244.64.10,StartTime:2019-01-14 07:20:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-14 07:20:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://a7aaf4df388214df5f5cc6bc23423ed126bcba7c3e0d9c466891ae514caba533}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.306: INFO: Pod "nginx-deployment-555b55d965-cc8w6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cc8w6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-cc8w6,UID:0b6bc70f-17cd-11e9-b726-525400ada096,ResourceVersion:69990,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc0017ccf47 0xc0017ccf48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017ccfc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017ccfe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.306: INFO: Pod "nginx-deployment-555b55d965-czj67" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-czj67,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-czj67,UID:0b7b296d-17cd-11e9-b726-525400ada096,ResourceVersion:70018,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc0017cd127 0xc0017cd128}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017cd1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017cd1c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-f2gn7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f2gn7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-f2gn7,UID:0b7499a6-17cd-11e9-b726-525400ada096,ResourceVersion:70002,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc0017cd2f0 0xc0017cd2f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017cd520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017cd540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-f2pdx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f2pdx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-f2pdx,UID:0b7be77f-17cd-11e9-b726-525400ada096,ResourceVersion:70022,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc0017cd600 0xc0017cd601}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017cd670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017cd6a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-ghct2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ghct2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-ghct2,UID:0b7461e4-17cd-11e9-b726-525400ada096,ResourceVersion:70004,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc0017cd950 0xc0017cd951}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fee1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fee1c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-h6kcb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-h6kcb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-h6kcb,UID:e1ac5b5b-17cc-11e9-b726-525400ada096,ResourceVersion:69703,Generation:0,CreationTimestamp:2019-01-14 07:20:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc000fee230 0xc000fee231}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fee2a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fee2c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:10.244.64.12,StartTime:2019-01-14 07:20:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-14 07:20:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://d8f14c6a3bfc47cc0edc3bacc1c537e0a6ec4fd91421e90dafcd30e3fb14ff65}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-pzlng" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pzlng,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-pzlng,UID:e1ac65d4-17cc-11e9-b726-525400ada096,ResourceVersion:69866,Generation:0,CreationTimestamp:2019-01-14 07:20:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc000fee407 0xc000fee408}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paassys1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fee480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fee4a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.103,PodIP:10.244.192.21,StartTime:2019-01-14 07:20:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-14 07:21:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://6c81cae4d47336052036ef8decc5ac1fd0ed5bfce2d46fc94b18f27f6c137b20}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-q25nx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q25nx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-q25nx,UID:0b7473d4-17cd-11e9-b726-525400ada096,ResourceVersion:70066,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc000fee667 0xc000fee668}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fee6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fee700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-r6gg7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-r6gg7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-r6gg7,UID:e1a7e419-17cc-11e9-b726-525400ada096,ResourceVersion:69706,Generation:0,CreationTimestamp:2019-01-14 07:20:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc000feeac7 0xc000feeac8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000feeb40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000feeb60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:10.244.64.13,StartTime:2019-01-14 07:20:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-14 07:20:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://4f9591006d55cafc85fdfe1807840d4070ecd222c3a5843edb6f0225342a0ba0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-svvnz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-svvnz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-svvnz,UID:e1a8c466-17cc-11e9-b726-525400ada096,ResourceVersion:69709,Generation:0,CreationTimestamp:2019-01-14 07:20:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc000feec87 0xc000feec88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000feefd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000feeff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:10.244.64.11,StartTime:2019-01-14 07:20:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-14 07:20:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://63d24ed940f11d56666cf3fad33cd3b1a21489ded82fa82a5ca117ad186c33dd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-swft7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-swft7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-swft7,UID:e1a8b130-17cc-11e9-b726-525400ada096,ResourceVersion:69880,Generation:0,CreationTimestamp:2019-01-14 07:20:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc000fef0b7 0xc000fef0b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paassys1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fef3e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fef400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.103,PodIP:10.244.192.22,StartTime:2019-01-14 07:20:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-14 07:21:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://60dee6fa1a80e017f36ac4384c2faa5e3b98d83081bc94c25cb6b902e74b8676}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-tcvxg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tcvxg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-tcvxg,UID:e1ac3c73-17cc-11e9-b726-525400ada096,ResourceVersion:69877,Generation:0,CreationTimestamp:2019-01-14 07:20:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc000fef527 0xc000fef528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paassys1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fef740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fef760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.103,PodIP:10.244.192.19,StartTime:2019-01-14 07:20:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-14 07:21:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://956e80bbc8971e83607316f2f45e4461dc95ca72b82fc4d9d6d33d3aaee1526a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-wdcjp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wdcjp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-wdcjp,UID:e1af6c81-17cc-11e9-b726-525400ada096,ResourceVersion:69696,Generation:0,CreationTimestamp:2019-01-14 07:20:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc000fef827 0xc000fef828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fef900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fef920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:20:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:10.244.64.9,StartTime:2019-01-14 07:20:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-14 07:20:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://08d91ad4c6b625cc7f1064643e2764b4d38dac075a65488d81246498105cb946}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.307: INFO: Pod "nginx-deployment-555b55d965-wwhws" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wwhws,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-wwhws,UID:0b6e30d9-17cd-11e9-b726-525400ada096,ResourceVersion:70049,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc000fef9e0 0xc000fef9e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fefa50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fefa70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.308: INFO: Pod "nginx-deployment-555b55d965-zfd7m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zfd7m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-zfd7m,UID:0b7c0437-17cd-11e9-b726-525400ada096,ResourceVersion:70023,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc000fefb67 0xc000fefb68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fefbe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fefc00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.308: INFO: Pod "nginx-deployment-555b55d965-znx6x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-znx6x,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-555b55d965-znx6x,UID:0b74866d-17cd-11e9-b726-525400ada096,ResourceVersion:70005,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 e1a362ab-17cc-11e9-b726-525400ada096 0xc000fefcc0 0xc000fefcc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fefd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fefd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.308: INFO: Pod "nginx-deployment-65bbdb5f8-862kf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-862kf,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-862kf,UID:0a45e855-17cd-11e9-b726-525400ada096,ResourceVersion:69943,Generation:0,CreationTimestamp:2019-01-14 07:21:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc000fefdd0 0xc000fefdd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000fefe70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000fefec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:41 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.308: INFO: Pod "nginx-deployment-65bbdb5f8-8qz9x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8qz9x,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-8qz9x,UID:0a44920c-17cd-11e9-b726-525400ada096,ResourceVersion:69942,Generation:0,CreationTimestamp:2019-01-14 07:21:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc000feff90 0xc000feff91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002788010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002788030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:41 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.308: INFO: Pod "nginx-deployment-65bbdb5f8-8tbfp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8tbfp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-8tbfp,UID:0b6f4cd6-17cd-11e9-b726-525400ada096,ResourceVersion:70040,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc0027881d0 0xc0027881d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002788290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027884a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.308: INFO: Pod "nginx-deployment-65bbdb5f8-9vjdj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-9vjdj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-9vjdj,UID:0b6cb1ee-17cd-11e9-b726-525400ada096,ResourceVersion:70029,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc002788560 0xc002788561}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027887d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027887f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.308: INFO: Pod "nginx-deployment-65bbdb5f8-d6kg9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-d6kg9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-d6kg9,UID:0b73aac2-17cd-11e9-b726-525400ada096,ResourceVersion:70063,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc0021f40f0 0xc0021f40f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021f41b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021f41d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.308: INFO: Pod "nginx-deployment-65bbdb5f8-dfhw8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dfhw8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-dfhw8,UID:0b6f651e-17cd-11e9-b726-525400ada096,ResourceVersion:70051,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc0021f4470 0xc0021f4471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021f44f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021f4590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.308: INFO: Pod "nginx-deployment-65bbdb5f8-gq8ks" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gq8ks,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-gq8ks,UID:0b7a3541-17cd-11e9-b726-525400ada096,ResourceVersion:70015,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc0021f4850 0xc0021f4851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021f4940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021f4960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.324: INFO: Pod "nginx-deployment-65bbdb5f8-gxlpg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gxlpg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-gxlpg,UID:0b74475f-17cd-11e9-b726-525400ada096,ResourceVersion:70003,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc0021f49e0 0xc0021f49e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021f4a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021f4a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.324: INFO: Pod "nginx-deployment-65bbdb5f8-jkspz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jkspz,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-jkspz,UID:0b73c5a4-17cd-11e9-b726-525400ada096,ResourceVersion:70067,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc0021f4ca0 0xc0021f4ca1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021f4d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021f4d90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.325: INFO: Pod "nginx-deployment-65bbdb5f8-n7kn8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-n7kn8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-n7kn8,UID:0a365ec7-17cd-11e9-b726-525400ada096,ResourceVersion:69923,Generation:0,CreationTimestamp:2019-01-14 07:21:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc0021f5290 0xc0021f5291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021f53d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021f5630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:41 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.325: INFO: Pod "nginx-deployment-65bbdb5f8-rz77w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rz77w,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-rz77w,UID:0a351c11-17cd-11e9-b726-525400ada096,ResourceVersion:69910,Generation:0,CreationTimestamp:2019-01-14 07:21:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc0021f5bc0 0xc0021f5bc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021f5e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021f5e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:41 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.325: INFO: Pod "nginx-deployment-65bbdb5f8-xlqr5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xlqr5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-xlqr5,UID:0b73e5b9-17cd-11e9-b726-525400ada096,ResourceVersion:70068,Generation:0,CreationTimestamp:2019-01-14 07:21:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc0018360a0 0xc0018360a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001836190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001836400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 14 07:21:46.325: INFO: Pod "nginx-deployment-65bbdb5f8-zdlwf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zdlwf,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-2r56l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2r56l/pods/nginx-deployment-65bbdb5f8-zdlwf,UID:0a35ff42-17cd-11e9-b726-525400ada096,ResourceVersion:69938,Generation:0,CreationTimestamp:2019-01-14 07:21:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0a3264a2-17cd-11e9-b726-525400ada096 0xc0018365c0 0xc0018365c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4h44r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4h44r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4h44r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:paaswkr2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001836640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018366c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 07:21:41 +0000 UTC  }],Message:,Reason:,HostIP:192.168.10.105,PodIP:,StartTime:2019-01-14 07:21:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:21:46.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
Jan 14 07:21:46.335: INFO: Condition Ready of node paassys1 is false, but Node is tainted by NodeController with [{node.kubernetes.io/unreachable  NoSchedule 2019-01-14 07:21:15 +0000 UTC} {node.kubernetes.io/unreachable  NoExecute 2019-01-14 07:21:21 +0000 UTC}]. Failure
Jan 14 07:21:48.377: INFO: Condition Ready of node paassys1 is false, but Node is tainted by NodeController with [{node.kubernetes.io/unreachable  NoSchedule 2019-01-14 07:21:15 +0000 UTC} {node.kubernetes.io/unreachable  NoExecute 2019-01-14 07:21:21 +0000 UTC}]. Failure
Jan 14 07:21:50.345: INFO: Condition Ready of node paassys1 is true, but Node is tainted by NodeController with [{node.kubernetes.io/unreachable  NoExecute 2019-01-14 07:21:21 +0000 UTC}]. Failure
STEP: Destroying namespace "e2e-tests-deployment-2r56l" for this suite.
Jan 14 07:22:00.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:22:00.480: INFO: namespace: e2e-tests-deployment-2r56l, resource: bindings, ignored listing per whitelist
Jan 14 07:22:00.664: INFO: namespace e2e-tests-deployment-2r56l deletion completed in 8.3178942s

• [SLOW TEST:86.617 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:22:00.664: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 14 07:22:00.852: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-8b5g7,SelfLink:/api/v1/namespaces/e2e-tests-watch-8b5g7/configmaps/e2e-watch-test-resource-version,UID:154b4184-17cd-11e9-b726-525400ada096,ResourceVersion:70406,Generation:0,CreationTimestamp:2019-01-14 07:22:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 14 07:22:00.852: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-8b5g7,SelfLink:/api/v1/namespaces/e2e-tests-watch-8b5g7/configmaps/e2e-watch-test-resource-version,UID:154b4184-17cd-11e9-b726-525400ada096,ResourceVersion:70407,Generation:0,CreationTimestamp:2019-01-14 07:22:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:22:00.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-8b5g7" for this suite.
Jan 14 07:22:06.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:22:07.010: INFO: namespace: e2e-tests-watch-8b5g7, resource: bindings, ignored listing per whitelist
Jan 14 07:22:07.053: INFO: namespace e2e-tests-watch-8b5g7 deletion completed in 6.190547301s

• [SLOW TEST:6.389 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:22:07.053: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan 14 07:22:07.280: INFO: Waiting up to 5m0s for pod "client-containers-195bc059-17cd-11e9-912e-6a405af5e95c" in namespace "e2e-tests-containers-272q2" to be "success or failure"
Jan 14 07:22:07.296: INFO: Pod "client-containers-195bc059-17cd-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.515847ms
Jan 14 07:22:09.301: INFO: Pod "client-containers-195bc059-17cd-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020972479s
Jan 14 07:22:11.308: INFO: Pod "client-containers-195bc059-17cd-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027472613s
STEP: Saw pod success
Jan 14 07:22:11.308: INFO: Pod "client-containers-195bc059-17cd-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:22:11.311: INFO: Trying to get logs from node paaswkr2 pod client-containers-195bc059-17cd-11e9-912e-6a405af5e95c container test-container: <nil>
STEP: delete the pod
Jan 14 07:22:11.340: INFO: Waiting for pod client-containers-195bc059-17cd-11e9-912e-6a405af5e95c to disappear
Jan 14 07:22:11.346: INFO: Pod client-containers-195bc059-17cd-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:22:11.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-272q2" for this suite.
Jan 14 07:22:17.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:22:17.444: INFO: namespace: e2e-tests-containers-272q2, resource: bindings, ignored listing per whitelist
Jan 14 07:22:17.496: INFO: namespace e2e-tests-containers-272q2 deletion completed in 6.141924584s

• [SLOW TEST:10.443 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:22:17.496: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 14 07:22:17.595: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1f827c90-17cd-11e9-912e-6a405af5e95c" in namespace "e2e-tests-downward-api-jztb6" to be "success or failure"
Jan 14 07:22:17.602: INFO: Pod "downwardapi-volume-1f827c90-17cd-11e9-912e-6a405af5e95c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.048064ms
Jan 14 07:22:19.608: INFO: Pod "downwardapi-volume-1f827c90-17cd-11e9-912e-6a405af5e95c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013267012s
STEP: Saw pod success
Jan 14 07:22:19.608: INFO: Pod "downwardapi-volume-1f827c90-17cd-11e9-912e-6a405af5e95c" satisfied condition "success or failure"
Jan 14 07:22:19.613: INFO: Trying to get logs from node paaswkr2 pod downwardapi-volume-1f827c90-17cd-11e9-912e-6a405af5e95c container client-container: <nil>
STEP: delete the pod
Jan 14 07:22:19.640: INFO: Waiting for pod downwardapi-volume-1f827c90-17cd-11e9-912e-6a405af5e95c to disappear
Jan 14 07:22:19.644: INFO: Pod downwardapi-volume-1f827c90-17cd-11e9-912e-6a405af5e95c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:22:19.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jztb6" for this suite.
Jan 14 07:22:25.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:22:25.741: INFO: namespace: e2e-tests-downward-api-jztb6, resource: bindings, ignored listing per whitelist
Jan 14 07:22:25.774: INFO: namespace e2e-tests-downward-api-jztb6 deletion completed in 6.114611854s

• [SLOW TEST:8.278 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:22:25.774: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0114 07:22:35.990273      13 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 14 07:22:35.990: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:22:35.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kh5kl" for this suite.
Jan 14 07:23:56.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:23:56.083: INFO: namespace: e2e-tests-gc-kh5kl, resource: bindings, ignored listing per whitelist
Jan 14 07:23:56.130: INFO: namespace e2e-tests-gc-kh5kl deletion completed in 1m20.134153522s

• [SLOW TEST:90.357 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 14 07:23:56.131: INFO: >>> kubeConfig: /tmp/kubeconfig-949281363
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 14 07:26:38.292: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:26:38.298: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:26:40.299: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:26:40.302: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:26:42.298: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:26:42.301: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:26:44.298: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:26:44.301: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:26:46.298: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:26:46.302: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:26:48.298: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:26:48.302: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:26:50.298: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:26:50.303: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:26:52.299: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:26:52.302: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:26:54.299: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:26:54.302: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:26:56.299: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:26:56.309: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:26:58.298: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:26:58.301: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:27:00.298: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:27:00.302: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:27:02.298: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:27:02.302: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:27:04.299: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:27:04.302: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:27:06.298: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:27:06.302: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 14 07:27:08.299: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 14 07:27:08.302: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 14 07:27:08.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-rskk4" for this suite.
Jan 14 07:27:36.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 14 07:27:36.359: INFO: namespace: e2e-tests-container-lifecycle-hook-rskk4, resource: bindings, ignored listing per whitelist
Jan 14 07:27:36.423: INFO: namespace e2e-tests-container-lifecycle-hook-rskk4 deletion completed in 28.11510012s

• [SLOW TEST:220.292 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSJan 14 07:27:36.423: INFO: Running AfterSuite actions on all nodes
Jan 14 07:27:36.441: INFO: Running AfterSuite actions on node 1
Jan 14 07:27:36.441: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5926.908 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h38m48.352341795s
Test Suite Passed
